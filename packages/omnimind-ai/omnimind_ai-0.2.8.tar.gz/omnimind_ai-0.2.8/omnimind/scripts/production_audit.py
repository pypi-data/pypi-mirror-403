#!/usr/bin/env python3
"""
OMNIMIND Comprehensive Production Readiness Test
Tests all modules: Model, Memory, Cognitive, Interface, Training, Export
"""
import os
import sys
import shutil
import traceback

def test_model_creation():
    """Test model creation for all sizes"""
    print("\nğŸ“¦ Testing Model Creation...")
    from omnimind import create_model
    
    for size in ["nano", "micro", "mini"]:
        try:
            model = create_model(size)
            params = model.model.num_parameters
            print(f"  âœ… {size}: {params / 1e6:.1f}M parameters")
        except Exception as e:
            print(f"  âŒ {size}: {e}")
            return False
    return True

def test_tokenizer():
    """Test tokenizers"""
    print("\nğŸ“ Testing Tokenizers...")
    from omnimind import SimpleTokenizer, MultilingualTokenizer
    
    # Simple
    try:
        tok = SimpleTokenizer()
        ids = tok.encode("Hello à¸ªà¸§à¸±à¸ªà¸”à¸µ")
        text = tok.decode(ids)
        print(f"  âœ… SimpleTokenizer: {len(tok)} vocab, encode/decode OK")
    except Exception as e:
        print(f"  âŒ SimpleTokenizer: {e}")
        return False
    
    # Multilingual
    try:
        tok = MultilingualTokenizer()
        test_texts = ["Hello", "à¸ªà¸§à¸±à¸ªà¸”à¸µ", "ä½ å¥½", "ğŸš€"]
        all_ok = all(tok.decode(tok.encode(t)) == t for t in test_texts)
        if all_ok:
            print(f"  âœ… MultilingualTokenizer: {len(tok)} vocab, multilingual OK")
        else:
            print(f"  âš ï¸ MultilingualTokenizer: Some decode failures")
    except Exception as e:
        print(f"  âŒ MultilingualTokenizer: {e}")
        return False
    
    return True

def test_chat_template():
    """Test chat template application"""
    print("\nğŸ’¬ Testing Chat Template...")
    from omnimind import MultilingualTokenizer
    
    try:
        tok = MultilingualTokenizer()
        messages = [
            {"role": "system", "content": "You are OMNIMIND"},
            {"role": "user", "content": "Hello!"},
        ]
        result = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        if "<|im_start|>" in result and "<|im_end|>" in result:
            print(f"  âœ… Chat template works ({len(result)} chars)")
        else:
            print(f"  âš ï¸ Chat template missing markers")
    except Exception as e:
        print(f"  âŒ Chat template: {e}")
        return False
    
    return True

def test_memory_layer():
    """Test memory components"""
    print("\nğŸ§  Testing Memory Layer...")
    try:
        from omnimind.memory.working_memory import WorkingMemory
        from omnimind.memory.episodic_memory import EpisodicMemory
        from omnimind.memory.semantic_memory import SemanticMemory
        
        wm = WorkingMemory()
        wm.add("test", {"content": "Hello"})
        print(f"  âœ… WorkingMemory: add/retrieve OK")
        
        # Episodic (in-memory test)
        em = EpisodicMemory(db_path=":memory:")
        print(f"  âœ… EpisodicMemory: initialized")
        
        # Semantic (fallback mode)
        sm = SemanticMemory(db_path="test_semantic_temp")
        sm.add("Test knowledge", category="test")
        results = sm.search("Test")
        print(f"  âœ… SemanticMemory: add/search OK")
        shutil.rmtree("test_semantic_temp", ignore_errors=True)
        
    except Exception as e:
        print(f"  âŒ Memory: {e}")
        traceback.print_exc()
        return False
    
    return True

def test_cognitive_layer():
    """Test cognitive components"""
    print("\nğŸ¤” Testing Cognitive Layer...")
    try:
        from omnimind.cognitive.thinking_engine import ThinkingEngine
        from omnimind.cognitive.uncertainty_detector import UncertaintyDetector
        from omnimind.cognitive.anti_repetition import AntiRepetition
        
        ud = UncertaintyDetector()
        result = ud.evaluate("I'm not sure about this")
        print(f"  âœ… UncertaintyDetector: confidence {result.overall_score:.2f}")
        
        ar = AntiRepetition()
        print(f"  âœ… AntiRepetition: initialized")
        
        te = ThinkingEngine(uncertainty_detector=ud, anti_repetition=ar)
        print(f"  âœ… ThinkingEngine: initialized")
        
    except Exception as e:
        print(f"  âŒ Cognitive: {e}")
        traceback.print_exc()
        return False
    
    return True

def test_model_export():
    """Test model and tokenizer export"""
    print("\nğŸ’¾ Testing Model Export...")
    export_dir = "test_production_export"
    
    try:
        from omnimind import create_model, MultilingualTokenizer
        
        # Clean up
        if os.path.exists(export_dir):
            shutil.rmtree(export_dir)
        
        model = create_model("nano")
        model.save_pretrained(export_dir)
        
        tok = MultilingualTokenizer()
        tok.save_pretrained(export_dir)
        
        expected_files = [
            "config.json", "model.safetensors", "README.md",
            "vocab.json", "tokenizer_config.json", "tokenizer.json",
            "special_tokens_map.json", "chat_template.jinja"
        ]
        
        missing = [f for f in expected_files if not os.path.exists(os.path.join(export_dir, f))]
        if not missing:
            print(f"  âœ… All {len(expected_files)} files exported")
        else:
            print(f"  âš ï¸ Missing: {missing}")
            
        # Cleanup
        shutil.rmtree(export_dir, ignore_errors=True)
        
    except Exception as e:
        print(f"  âŒ Export: {e}")
        traceback.print_exc()
        shutil.rmtree(export_dir, ignore_errors=True)
        return False
    
    return True

def test_training_dataset():
    """Test training dataset creation"""
    print("\nğŸ“Š Testing Training Dataset...")
    try:
        from omnimind import MultilingualTokenizer, TextDataset, create_dataloader
        import tempfile
        
        # Create temp data file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write("Hello world! This is a test.\n" * 100)
            f.write("à¸ªà¸§à¸±à¸ªà¸”à¸µà¹‚à¸¥à¸! à¸™à¸µà¹ˆà¸„à¸·à¸­à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š\n" * 100)
            temp_path = f.name
        
        tok = MultilingualTokenizer()
        dataset = TextDataset(temp_path, tok, max_seq_len=128)
        
        if len(dataset) > 0:
            print(f"  âœ… TextDataset: {len(dataset)} chunks")
            
            loader = create_dataloader(dataset, batch_size=4)
            batch = next(iter(loader))
            print(f"  âœ… DataLoader: batch shape {batch['input_ids'].shape}")
        else:
            print(f"  âš ï¸ TextDataset: No chunks created (data too small)")
            
        os.unlink(temp_path)
        
    except Exception as e:
        print(f"  âŒ Dataset: {e}")
        traceback.print_exc()
        return False
    
    return True

def test_forward_and_generate():
    """Test forward pass and generation"""
    print("\nğŸ”„ Testing Forward Pass & Generation...")
    try:
        import torch
        from omnimind import create_model
        
        model = create_model("nano")
        
        # Forward
        dummy = torch.randint(0, 1000, (2, 32))
        output = model(dummy)
        print(f"  âœ… Forward: output shape {output['logits'].shape}")
        
        # Generate
        prompt = torch.randint(0, 1000, (1, 8))
        generated = model.generate(prompt, max_new_tokens=16)
        print(f"  âœ… Generate: output shape {generated.shape}")
        
    except Exception as e:
        print(f"  âŒ Forward/Generate: {e}")
        traceback.print_exc()
        return False
    
    return True

def main():
    print("=" * 60)
    print("ğŸš€ OMNIMIND Production Readiness Audit")
    print("=" * 60)
    
    tests = [
        ("Model Creation", test_model_creation),
        ("Tokenizers", test_tokenizer),
        ("Chat Template", test_chat_template),
        ("Memory Layer", test_memory_layer),
        ("Cognitive Layer", test_cognitive_layer),
        ("Model Export", test_model_export),
        ("Training Dataset", test_training_dataset),
        ("Forward & Generate", test_forward_and_generate),
    ]
    
    results = []
    for name, test_fn in tests:
        try:
            passed = test_fn()
            results.append((name, passed))
        except Exception as e:
            print(f"\nâŒ {name} crashed: {e}")
            results.append((name, False))
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ AUDIT SUMMARY")
    print("=" * 60)
    
    passed = sum(1 for _, p in results if p)
    total = len(results)
    
    for name, p in results:
        status = "âœ… PASS" if p else "âŒ FAIL"
        print(f"  {status}: {name}")
    
    print()
    if passed == total:
        print(f"ğŸ‰ All {total} tests PASSED! Project is PRODUCTION READY!")
        return 0
    else:
        print(f"âš ï¸ {passed}/{total} tests passed. Review failures before production.")
        return 1

if __name__ == "__main__":
    sys.exit(main())
