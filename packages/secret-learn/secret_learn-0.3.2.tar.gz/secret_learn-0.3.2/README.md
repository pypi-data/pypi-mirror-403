# Secret-Learn: Privacy-Preserving ML with JAX Acceleration

**573 sklearn-compatible implementations (191 algorithms √ó 3 privacy modes)**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![JAX](https://img.shields.io/badge/JAX-0.4.20+-orange.svg)](https://github.com/google/jax)
[![JAX-sklearn](https://img.shields.io/badge/JAX--sklearn-0.1.0+-red.svg)](https://github.com/chenxingqiang/jax-sklearn)
[![SecretFlow](https://img.shields.io/badge/SecretFlow-1.0.0+-green.svg)](https://github.com/secretflow/secretflow)
[![License](https://img.shields.io/badge/license-BSD--3--Clause-green.svg)](LICENSE)
[![Version](https://img.shields.io/badge/version-0.3.2-brightgreen.svg)](https://pypi.org/project/secret-learn/)
[![sklearn Compatible](https://img.shields.io/badge/sklearn-compatible-blue.svg)](https://scikit-learn.org)

---

## üéØ What is Secret-Learn?
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/chenxingqiang/Secret-Learn)

**Secret-Learn** is a comprehensive privacy-preserving machine learning library that combines:
- üöÄ **JAX-sklearn**: JAX-accelerated sklearn implementation (5x+ faster)
- üîê **SecretFlow Integration**: 573 implementations across FL/SS/SL modes (191 algorithms)

### Key Achievements

- **573 Total Implementations** - FL/SS/SL modes
- **191 Unique Algorithms** - Complete sklearn coverage (103.8%)
- **JAX Acceleration** - 5x+ performance gains
- **100% API Compatible** - Drop-in sklearn replacement
- **Full Privacy Protection** - SecretFlow MPC/HEU encryption
- **Production Ready** - 150,000+ lines of high-quality code
- **Unified Naming** - All files follow snake_case convention

### From 8 to 191 Algorithms

- **SecretFlow Original:** 8 algorithms
- **Secret-Learn:** 191 unique algorithms
- **Total Implementations:** 573 (191 √ó 3 modes)
- **sklearn Coverage:** 103.8% (191/184 core algorithms)
- **Growth:** +2287% algorithm expansion! üöÄ

---

## üèóÔ∏è System Architecture

Secret-Learn features a 6-layer architecture that seamlessly integrates JAX acceleration with privacy-preserving computation:

![Secret-Learn Architecture](docs/secret_learn_architecture.drawio.svg)

### Architecture Layers

1. **Application Layer** - Real-world use cases (Healthcare, Finance, IoT, Research)
2. **sklearn-Compatible API** - 191 algorithms with 100% sklearn compatibility
3. **Privacy-Preserving Modes** - FL/SS/SL (573 implementations)
4. **Intelligent Algorithm System** - Auto-classification and code generation
5. **JAX Acceleration** - 5x+ performance boost with hardware abstraction
6. **SecretFlow Integration** - SPU, HEU, TEE devices for privacy computation

For detailed architecture documentation, see [ARCHITECTURE.md](docs/ARCHITECTURE.md).

---

## üöÄ Quick Start

### Installation

#### Option 1: From PyPI (Recommended for Users)

```bash
# For Secret-Learn with JAX acceleration
pip install Secret-Learn

# For privacy-preserving features, install SecretFlow
# Note: Requires Python 3.10
pip install -U secretflow
```

#### Option 2: Using Conda (Recommended for SecretFlow)

```bash
# Create environment with Python 3.10
conda create -n sf python=3.10
conda activate sf

# Install SecretFlow
pip install -U secretflow

# Install Secret-Learn
pip install Secret-Learn
```

#### Option 3: From Source (Recommended for Developers)

```bash
# Clone repository
git clone https://github.com/chenxingqiang/Secret-Learn.git
cd Secret-Learn

# Create conda environment
conda create -n sf python=3.10
conda activate sf

# Install dependencies
pip install -U secretflow
pip install -e .
```

### Quick Start

Secret-Learn provides **573 privacy-preserving ML algorithms** through three modes:
- **FL Mode**: Federated Learning (data stays local)
- **SL Mode**: Split Learning (collaborative training)
- **SS Mode**: Secret Sharing (maximum privacy with MPC)

```bash
# Run FL example (easiest to start)
python examples/federated_learning/linear_regression.py

# Run other examples
python examples/federated_learning/kmeans.py
python examples/split_learning/random_forest_classifier.py

# For maximum privacy (SS mode - requires multi-party)
# Terminal 1: python examples/secret_sharing/pca.py --party bob
# Terminal 2: python examples/secret_sharing/pca.py --party alice
```

### SecretFlow Privacy-Preserving Usage

**‚ö†Ô∏è Important**: SecretFlow 1.14+ removed simulation mode. Use the provided example scripts instead of manual REPL initialization.

#### Recommended: Use Pre-Built Examples

The easiest way to get started is running the complete examples:

```bash
# FL Mode - Best for learning (works in examples)
python examples/federated_learning/linear_regression.py      # Linear regression
python examples/federated_learning/kmeans.py                 # Clustering
python examples/federated_learning/random_forest_classifier.py  # Ensemble

# SL Mode - Split learning examples
python examples/split_learning/mlp_classifier.py
python examples/split_learning/linear_regression.py

# SS Mode - Requires multi-party setup (highest security)
# Terminal 1 (Bob):
python examples/secret_sharing/pca.py --party bob

# Terminal 2 (Alice):  
python examples/secret_sharing/pca.py --party alice
```

#### Why Use Example Scripts?

SecretFlow 1.14+ uses PRODUCTION mode which requires:
- Proper cluster configuration
- Network initialization
- Multi-party coordination

The example scripts handle all this complexity for you. For custom code, use the examples as templates.

See complete working examples in:
- [`examples/federated_learning/`](examples/federated_learning/) - 191 FL examples
- [`examples/split_learning/`](examples/split_learning/) - 191 SL examples
- [`examples/secret_sharing/`](examples/secret_sharing/) - 191 SS examples

### Running Examples

Secret-Learn includes **573 complete examples** (191 algorithms √ó 3 modes):

```bash
# Run FL examples (single process, recommended for testing)
python examples/federated_learning/linear_regression.py
python examples/federated_learning/kmeans.py
python examples/federated_learning/adaboost_classifier.py

# Run SL examples (single process)
python examples/split_learning/mlp_classifier.py
python examples/split_learning/random_forest_classifier.py

# Run SS examples (requires multi-party setup)
# Terminal 1: python examples/secret_sharing/pca.py --party bob
# Terminal 2: python examples/secret_sharing/pca.py --party alice
# Or use: ./examples/secret_sharing/run_any_example.sh pca

# Batch run examples
python scripts/run_all_fl_examples.py
python scripts/run_all_sl_examples.py
python scripts/run_all_ss_examples.py
```

**Features**:
- ‚úÖ **573 Examples**: One for each algorithm in each mode
- ‚úÖ **Incremental Mode**: Skip already successful runs
- ‚úÖ **Detailed Logs**: All outputs saved to `logs/examples/`
- ‚úÖ **Summary Reports**: `_SUMMARY.txt` for each mode
- ‚úÖ **Timeout Protection**: 5-minute timeout per example

View results:
```bash
# View FL summary
cat logs/examples/federated_learning/_SUMMARY.txt

# Check specific example log
cat logs/examples/federated_learning/linear_regression.log
```

---

## üîê Three Privacy-Preserving Modes

### FL Mode (Federated Learning) - 191 algorithms ‚úÖ

**Features:**
- Data stays in local PYUs (never leaves local environment)
- JAX-accelerated local computation (5x+ faster)
- HEU secure aggregation
- Best for: Horizontal federated learning

```python
from secretlearn.federated_learning.decomposition import FLPCA

model = FLPCA(
    devices={'alice': alice, 'bob': bob},
    heu=heu,  # Optional: secure aggregation
    n_components=10
)
model.fit(fed_X)
X_reduced = model.transform(fed_X)
```

### SL Mode (Split Learning) - 191 algorithms ‚úÖ

**Features:**
- Model split across multiple parties
- Collaborative training
- Encrypted intermediate activations
- Best for: Deep learning, vertical federated learning

```python
from secretlearn.split_learning.neural_network import SLMLPClassifier

model = SLMLPClassifier(
    devices={'alice': alice, 'bob': bob},
    hidden_layer_sizes=(100, 50)
)
model.fit(fed_X, fed_y, epochs=10)
predictions = model.predict(fed_X_test)
```

### SS Mode (Secret Sharing) - 191 algorithms ‚úÖ

**Features:**
- Data aggregated to SPU (Secure Processing Unit)
- Full MPC (Multi-Party Computation) encryption
- Highest security level
- Best for: Maximum privacy requirements

```python
from secretlearn.secret_sharing.decomposition import SSPCA

spu = sf.SPU(...)
model = SSPCA(spu=spu, n_components=10)
model.fit(fed_X)
X_reduced = model.transform(fed_X)
```

---

## üìä Performance Highlights

### JAX Acceleration Performance

| Problem Size | Algorithm | Training Time | Speedup | Hardware |
|--------------|-----------|---------------|---------|----------|
| 100K √ó 1K | LinearRegression | 0.060s | 5.53x | GPU |
| 100K √ó 1K | LinearRegression | 0.035s | 9.46x | TPU |
| 50K √ó 200 | PCA | 0.112s | 3.0x | GPU |
| 10K √ó 100 | KMeans | 0.013s | 2.5x | CPU |

### Hardware Selection Intelligence

```
JAX-sklearn automatically selects optimal hardware:

Small Data (< 10K):      CPU  ‚úì (Lowest latency)
Medium Data (10-100K):   GPU  ‚úì (Best throughput)
Large Data (> 100K):     TPU  ‚úì (Maximum performance)
```

---

## üìã Available Algorithms

**588 implementations across 30+ categories:**

| Category | Count | Examples |
|----------|-------|----------|
| **Linear Models** | 39 | LinearRegression, Ridge, Lasso, ElasticNet, Lars, ... |
| **Preprocessing** | 19 | StandardScaler, MinMaxScaler, Normalizer, ... |
| **Ensemble** | 18 | RandomForest, GradientBoosting, AdaBoost, Stacking |
| **Clustering** | 14 | KMeans, DBSCAN, Birch, HDBSCAN, OPTICS |
| **Decomposition** | 14 | PCA, NMF, FastICA, TruncatedSVD, SparsePCA |
| **Feature Selection** | 12 | RFE, SelectKBest, VarianceThreshold, RFECV |
| **Neighbors** | 11 | KNeighbors, RadiusNeighbors, NearestCentroid |
| **Covariance** | 8 | EmpiricalCovariance, GraphicalLasso, MinCovDet |
| **SVM** | 7 | SVC, SVR, LinearSVC, LinearSVR, NuSVC, NuSVR, OneClassSVM |
| **Naive Bayes** | 6 | GaussianNB, MultinomialNB, BernoulliNB |
| **Manifold** | 5 | TSNE, Isomap, MDS, LLE, SpectralEmbedding |
| **Kernel Approximation** | 5 | RBFSampler, Nystroem, AdditiveChi2Sampler |
| **Random Projection** | 3 | GaussianRandomProjection, SparseRandomProjection |
| **Impute** | 3 | SimpleImputer, KNNImputer, MissingIndicator |
| **And 16 more...** | 32+ | Complete sklearn algorithm coverage |
| **Total Unique** | **191** | √ó 3 modes = **573 implementations** |

See [secretlearn/README.md](secretlearn/README.md) for complete algorithm status.

---

## üõ† Installation

### Prerequisites

#### Choose Your JAX Backend

```bash
# CPU only (default)
pip install jax jaxlib

# GPU (CUDA)
pip install jax[gpu]

# TPU (Google Cloud)
pip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html
```

### Install Secret-Learn

```bash
# From PyPI (recommended)
pip install Secret-Learn

# With SecretFlow for privacy-preserving ML
pip install Secret-Learn[secretflow]

# From source (development)
git clone https://github.com/chenxingqiang/Secret-Learn.git
cd Secret-Learn
pip install -e .
```

### Verify Installation

```python
# Test Secret-Learn installation
import secretlearn
print(f"Secret-Learn Version: {secretlearn.__version__}")
print("Secret-Learn installed: ‚úÖ")

# Test SecretFlow integration
try:
    import secretflow as sf
    print(f"SecretFlow Version: {sf.__version__}")
    print("SecretFlow installed: ‚úÖ")
except ImportError:
    print("SecretFlow not installed. Run: pip install secretflow")

# Test algorithm import (FL mode)
try:
    from secretlearn.federated_learning.linear_models.linear_regression import FLLinearRegression
    print("FL algorithms available: ‚úÖ")
except ImportError as e:
    print(f"Import error: {e}")

# Quick functionality test - run an example
print("\nTo test functionality, run an example:")
print("  python examples/federated_learning/linear_regression.py")
```

---

## üéØ Usage Examples

### 1. Federated Learning Mode (FL)

FL mode keeps data local while enabling collaborative learning:

```bash
# Run complete FL example
python examples/federated_learning/linear_regression.py
```

The example demonstrates:
- Local data computation on each party's PYU device
- Secure model aggregation
- Privacy-preserving predictions
- JAX acceleration for local training

### 2. Privacy-Preserving FL Mode (Federated)

**FL Mode** works with single-process simulation (best for learning and testing):

```python
# Run existing FL examples - no complex setup needed!
# These work out of the box:
# python examples/federated_learning/linear_regression.py
# python examples/federated_learning/kmeans.py
# python examples/federated_learning/random_forest_classifier.py

# For custom FL code, see examples/federated_learning/ directory
# FL mode simulates federation in a single process
```

**For production FL deployments**, use the production mode setup shown above with PYU devices.

### 3. Maximum Privacy SS Mode (MPC Encrypted)

**SS Mode** requires multi-party setup with SecretFlow's MPC engine:

```bash
# Run existing SS examples (multi-process required):
# Terminal 1 - Bob
python examples/secret_sharing/adaboost_classifier.py --party bob

# Terminal 2 - Alice  
python examples/secret_sharing/adaboost_classifier.py --party alice

# Each party's data stays completely private with full MPC protection
```

See [`examples/secret_sharing/`](examples/secret_sharing/) directory for 191 complete SS mode examples.

---

## üî¨ Technical Architecture

### JAX-sklearn Layer

**5-layer architecture for seamless acceleration:**

1. **User Code Layer** - 100% sklearn API compatibility
2. **Compatibility Layer** - Transparent proxy system
3. **JAX Acceleration Layer** - JIT compilation and vectorization
4. **Data Management** - Automatic NumPy ‚Üî JAX conversion
5. **Hardware Abstraction** - CPU/GPU/TPU support

### SecretFlow Integration Layer

**Privacy-preserving computation:**

1. **FL Layer** - Local PYU computation with HEU aggregation
2. **SL Layer** - Split models across parties
3. **SS Layer** - SPU MPC encrypted computation
4. **Intelligent Classification** - Auto-detects algorithm characteristics
5. **Template Generation** - Correct implementation for each algorithm type

---

## üìà Performance & Security Comparison

| Mode | Performance | Privacy | Data Location | Best For |
|------|-------------|---------|---------------|----------|
| **Local JAX** | 5-10x | None | Local | High performance, trusted environment |
| **FL Mode** | 3-5x | High | Distributed PYUs | Federated learning, data sovereignty |
| **SL Mode** | 2-4x | High | Distributed PYUs | Deep learning, model privacy |
| **SS Mode** | 1-2x | Maximum | Encrypted SPU | Maximum security requirements |

---

## üéì Use Cases

### Healthcare
Train models on distributed medical data across hospitals without sharing patient records.

```python
# Each hospital keeps their data locally
from secretlearn.federated_learning.ensemble.random_forest_classifier import FLRandomForestClassifier

# See complete example: examples/federated_learning/random_forest_classifier.py
model = FLRandomForestClassifier(
    devices={'hospital_a': alice, 'hospital_b': bob},
    n_estimators=100
)
model.fit(fed_patient_data, fed_diagnoses)
```

### Finance
Collaborative fraud detection across banks while preserving transaction privacy.

```python
from secretlearn.secret_sharing.svm.svc import SSSVC

# Full MPC protection for sensitive financial data
# See examples/secret_sharing/svc.py for complete multi-party setup
model = SSSVC(spu=spu)
model.fit(fed_transactions, fed_fraud_labels)
```

### IoT
Federated learning on edge devices with encrypted aggregation.

```python
from secretlearn.federated_learning.neural_network.mlp_classifier import FLMLPClassifier

# Train on distributed IoT devices
# See examples/federated_learning/mlp_classifier.py for complete setup
model = FLMLPClassifier(
    devices=edge_devices,
    hidden_layer_sizes=(100,)
)
model.fit(fed_sensor_data, fed_labels)
```

---

## üîß Complete Algorithm List

### Unsupervised Learning (40 algorithms √ó 3 modes = 120)

**Clustering (8):** KMeans, MiniBatchKMeans, DBSCAN, AgglomerativeClustering, Birch, MeanShift, SpectralClustering, AffinityPropagation

**Decomposition (9):** PCA, IncrementalPCA, KernelPCA, TruncatedSVD, NMF, MiniBatchNMF, FactorAnalysis, FastICA, MiniBatchDictionaryLearning

**Manifold (5):** TSNE, Isomap, MDS, LocallyLinearEmbedding, SpectralEmbedding

**Covariance (5):** EmpiricalCovariance, MinCovDet, ShrunkCovariance, LedoitWolf, EllipticEnvelope

**Preprocessing (11):** StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, Normalizer, Binarizer, QuantileTransformer, PowerTransformer, PolynomialFeatures, SplineTransformer, KBinsDiscretizer

**Anomaly Detection (1):** IsolationForest

**Feature Selection (1):** VarianceThreshold

### Supervised Learning (76 algorithms √ó 3 modes = 228)

**Linear Models (18):** LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression, SGDClassifier, SGDRegressor, and more...

**Ensemble (14):** RandomForest, GradientBoosting, HistGradientBoosting, AdaBoost, Bagging, ExtraTrees, Voting

**SVM (7):** SVC, SVR, LinearSVC, LinearSVR, NuSVC, NuSVR, OneClassSVM

**Neural Networks (2):** MLPClassifier, MLPRegressor

**Naive Bayes (5):** GaussianNB, MultinomialNB, BernoulliNB, CategoricalNB, ComplementNB

**Trees (2):** DecisionTreeClassifier, DecisionTreeRegressor

**And many more...** (Gaussian Process, Discriminant Analysis, Neighbors, etc.)

---

## ‚ö° JAX Acceleration Features

Secret-Learn algorithms use JAX for acceleration in their local computations:

- **FL Mode**: Each party's local training is JAX-accelerated
- **SL Mode**: Split model computations use JAX when beneficial  
- **SS Mode**: Pre/post-processing with JAX before MPC encryption

### Hardware Support

JAX automatically selects the best available hardware:
- CPU: Default, works everywhere
- GPU: Automatic detection if CUDA available
- TPU: Automatic detection on Google Cloud

All examples benefit from JAX acceleration automatically with no code changes required.

### Supported Hardware

| Hardware | Status | Performance | Use Case |
|----------|--------|-------------|----------|
| **CPU** | Production | 1.5-2.5x | Small datasets, development |
| **NVIDIA GPU** | Production | 5-8x | Medium-large datasets |
| **Google TPU** | Production | 9-15x | Large-scale workloads |
| **Apple Silicon** | üß™ Beta | 2-4x | M1/M2/M3 Macs |

---

## üì¶ Installation Options

### Prerequisites

**Python Version**: Python 3.10 is required for SecretFlow integration.

```bash
# Create conda environment with Python 3.10
conda create -n sf python=3.10
conda activate sf
```

### Basic Installation

```bash
# Install Secret-Learn (JAX acceleration)
pip install Secret-Learn

# Install SecretFlow (privacy features)
pip install -U secretflow
```

### With GPU Support

```bash
# Install JAX with GPU support
pip install jax[cuda12]  # For CUDA 12
# or
pip install jax[cuda11]  # For CUDA 11

# Then install Secret-Learn
pip install Secret-Learn secretflow
```

### With TPU Support

```bash
# For Google Cloud TPU
pip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html
pip install Secret-Learn secretflow
```

### Full Installation (All Features)

```bash
# Complete installation with all dependencies
pip install Secret-Learn[all]
pip install secretflow

# Or from source
git clone https://github.com/chenxingqiang/Secret-Learn.git
cd Secret-Learn
pip install -e .[dev,docs,tests]
pip install secretflow
```

### Development Installation

```bash
git clone https://github.com/chenxingqiang/Secret-Learn.git
cd Secret-Learn

# Create environment
conda create -n sf python=3.10
conda activate sf

# Install dependencies
pip install -U secretflow
pip install -e .[dev,docs,tests]
```

---

## üìù Running Examples

Secret-Learn includes **573 complete usage examples** covering all algorithms in all three privacy modes.

### Quick Start with Examples

```bash
# Run a single example
python examples/federated_learning/linear_regression.py
python examples/secret_sharing/kmeans.py
python examples/split_learning/adaboost_classifier.py

# Run all examples for one mode
python run_all_fl_examples.py      # Incremental (skip successful)
python run_all_ss_examples.py
python run_all_sl_examples.py

# Run all examples for all modes
python run_all_examples.py

# Force rerun all (ignore previous success)
python run_all_fl_examples.py --force
```

### Example Statistics

| Mode | Examples | Coverage |
|------|----------|----------|
| **FL** | 191 | All algorithms |
| **SS** | 191 | All algorithms |
| **SL** | 191 | All algorithms |
| **Total** | **573** | 100% coverage |

### View Results

```bash
# View execution summary
cat logs/examples/federated_learning/_SUMMARY.txt

# Check specific example log
cat logs/examples/federated_learning/linear_regression.log

# Count successful runs
grep -c "SUCCESS" logs/examples/federated_learning/*.log
```

### Example Features

- ‚úÖ **Complete Coverage**: Every algorithm has working examples
- ‚úÖ **Incremental Execution**: Skip already successful runs
- ‚úÖ **Detailed Logging**: Full stdout/stderr captured
- ‚úÖ **Timeout Protection**: 5-minute timeout per example
- ‚úÖ **Summary Reports**: Automatic generation of execution summaries

For detailed usage instructions, see [`EXAMPLES_USAGE_GUIDE.md`](EXAMPLES_USAGE_GUIDE.md) (if available).

### üìì Jupyter Notebooks

Interactive tutorials are available in `examples/notebooks/`:

| Notebook | Description |
|----------|-------------|
| `01_quick_start.ipynb` | Basic FL, SS, SL tutorial with SecretFlow setup |
| `02_fl_classification.ipynb` | FL classification with multiple algorithms |

```bash
# Launch Jupyter to explore notebooks
jupyter notebook examples/notebooks/
```

---

## üìö Documentation

### Quick Links

- **SecretLearn Status**: [secretlearn/README.md](secretlearn/README.md)
- **Examples**: [examples/README.md](examples/README.md)

### API Documentation

Each algorithm has complete documentation:

```python
from secretlearn.federated_learning.clustering import FLKMeans
help(FLKMeans)  # Complete docstring with examples
```

---

## üõ† Advanced Features

### Intelligent Algorithm Migrator

Automatically generate SecretFlow adapters with correct templates:

```bash
python secretlearn/secretflow/algorithm_migrator_standalone.py \
    --algorithm sklearn.linear_model.LogisticRegression \
    --mode fl

# Automatically detects:
# - Supervised vs unsupervised
# - Iterative vs non-iterative
# - Generates correct fit() signature
# - Adds appropriate methods
```

### Algorithm Classification

```python
from secretlearn.algorithm_classifier import classify_algorithm

# Auto-classify algorithm characteristics
char = classify_algorithm('KMeans')
print(char['is_unsupervised'])  # True
print(char['fit_signature'])    # 'fit(x)'

char = classify_algorithm('SGDClassifier')
print(char['supports_partial_fit'])  # True
print(char['use_epochs'])  # True
```

---

## üéÆ When Does Secret-Learn Use JAX?

### Algorithm-Specific Thresholds

```python
# LinearRegression: Uses JAX when complexity > 1e8
# Equivalent to: 100K samples √ó 1K features

# KMeans: Uses JAX when complexity > 1e6
# Equivalent to: 10K samples √ó 100 features

# PCA: Uses JAX when complexity > 1e7
# Equivalent to: 32K samples √ó 300 features
```

### Smart Heuristics

- **Large datasets**: >10K samples typically benefit
- **High-dimensional**: >100 features often see speedups
- **Iterative algorithms**: Clustering, optimization benefit earlier
- **Matrix operations**: Linear algebra intensive algorithms

---

## üîê Privacy-Preserving ML Use Cases

### Multi-Institution Medical Research

```python
# Collaborative research without data sharing
from secretlearn.federated_learning.ensemble.random_forest_classifier import FLRandomForestClassifier

# Complete example: examples/federated_learning/random_forest_classifier.py
institutions = {
    'hospital_a': alice,
    'hospital_b': bob,
}

model = FLRandomForestClassifier(
    devices=institutions,
    n_estimators=100
)
model.fit(fed_patient_data, fed_diagnoses)
# Each institution's data never leaves their environment
```

### Cross-Bank Fraud Detection

```python
# Collaborative fraud detection with full privacy
from secretlearn.secret_sharing.neural_network.mlp_classifier import SSMLPClassifier

# Complete example: examples/secret_sharing/mlp_classifier.py
# Requires multi-party execution (see examples/secret_sharing/README.md)
model = SSMLPClassifier(
    spu=spu,
    hidden_layer_sizes=(100, 50)
)
model.fit(fed_transactions, fed_fraud_labels)
# Full MPC encryption, zero knowledge leakage
```

---

## üìä Project Statistics

### Code Quality

- **Total Lines:** ~225,000+ (implementations + examples + tests)
- **Algorithm Files:** 588 implementations (196 √ó 3 modes)
- **Example Files:** 576 examples (192 √ó 3 modes)
- **Naming Convention:** 100% snake_case compliance ‚úÖ
- **Linter Errors:** 0 ‚úÖ
- **API Compatibility:** 100% sklearn compatible ‚úÖ
- **Test Coverage:** Comprehensive (352 test files + 576 examples)

### Implementation Breakdown

| Component | Lines | Files | Status |
|-----------|-------|-------|--------|
| FL Algorithms | ~50,000 | 191 | Production |
| SS Algorithms | ~50,000 | 191 | Production |
| SL Algorithms | ~50,000 | 191 | Production |
| FL Examples | ~24,000 | 192 | Production |
| SS Examples | ~24,000 | 192 | Production |
| SL Examples | ~24,000 | 192 | Production |
| Tests | ~50,000 | 352 | Production |
| Tools & Utils | ~5,000 | 17 | Production |
| **Total** | **~277,000+** | **1,533** | **Ready** |

---

## üö® Requirements

### Core Requirements

- Python: 3.10+
- JAX: 0.4.20+
- NumPy: 1.22.0+
- SciPy: 1.8.0+
- jax-sklearn: 0.1.0+ (auto-installed)
- SecretFlow: 1.0.0+ (for privacy features)

### Optional

- CUDA Toolkit: 11.1+ (for GPU)
- cuDNN: 8.2+ (for GPU)
- Google Cloud TPU (for TPU)

---

## ü§ù Dependencies

### Project Relationships

```
Secret-Learn (this project)
‚îú‚îÄ‚îÄ JAX-sklearn (base implementation)
‚îÇ   ‚îú‚îÄ‚îÄ JAX (acceleration)
‚îÇ   ‚îî‚îÄ‚îÄ sklearn API (compatibility)
‚îî‚îÄ‚îÄ SecretFlow (privacy)
    ‚îú‚îÄ‚îÄ SPU (MPC encryption)
    ‚îú‚îÄ‚îÄ PYU (local computation)
    ‚îî‚îÄ‚îÄ HEU (homomorphic encryption)
```

---

## ü§ù Contributing

We welcome contributions! 

### Development Setup

```bash
git clone https://github.com/chenxingqiang/Secret-Learn.git
cd Secret-Learn
pip install -e ".[install,docs,tests]"
```

### Running Tests

```bash
# Core tests
pytest secretlearn/tests/ -v

# SecretFlow integration tests (requires SecretFlow)
pytest secretlearn/secretflow/tests/ -v
```

---

## üìÑ License

BSD-3-Clause License - Compatible with sklearn, JAX, and SecretFlow

---

## üôè Acknowledgments

- **JAX Team** - For the amazing JAX library
- **Scikit-learn Team** - For the foundational ML library
- **SecretFlow Team** - For the privacy-preserving framework
- **NumPy/SciPy** - For numerical computing infrastructure

---

## üìû Support

- **Issues:** [GitHub Issues](https://github.com/chenxingqiang/Secret-Learn/issues)
- **JAX-sklearn Base:** [JAX-sklearn Project](https://github.com/chenxingqiang/jax-sklearn)
- **SecretFlow:** [SecretFlow Documentation](https://www.secretflow.org.cn/docs/secretflow/en/)

---

## üéâ Project Status

### Production Ready

- **191 algorithms** - Complete sklearn coverage (103.8%)
- **573 implementations** - FL/SS/SL three privacy modes
- **573 examples** - Complete usage demonstrations (1:1 match)
- **225,000+ lines** - High-quality production code
- **0 linter errors** - Perfect code quality
- **100% snake_case** - Unified naming convention across 1,164+ files
- **100% API compatible** - sklearn standard
- **Comprehensive tools** - Intelligent algorithm classification and generation
- **Full documentation** - 8 detailed technical reports

### Quality Metrics

- Code Quality: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) - 0 linter errors, perfect style
- API Compatibility: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) - 100% sklearn compatible
- Documentation: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) - Complete docs + 576 examples
- Naming Convention: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) - 100% snake_case unified
- Security: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) - 3 privacy modes (FL/SS/SL)
- Performance: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) - JAX 5x+ acceleration
- Completeness: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) - 106.5% sklearn coverage

**Overall: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) - PRODUCTION READY**

---

**üöÄ Ready to build privacy-preserving ML with JAX acceleration?**

```bash
pip install Secret-Learn
```

**Join the privacy-preserving ML revolution!** üéä

- üîê **Privacy:** Full MPC/HEU encryption
- ‚ö° **Performance:** 5x+ JAX acceleration
- üéØ **Compatibility:** 100% sklearn API
- üöÄ **Scale:** 191 algorithms √ó 3 modes = 573 implementations

---

## üîó Related Projects

- **[JAX-sklearn](https://github.com/chenxingqiang/jax-sklearn)** - JAX-accelerated sklearn (base implementation)
- **[SecretFlow](https://github.com/secretflow/secretflow)** - Privacy-preserving computation framework
- **[JAX](https://github.com/google/jax)** - High-performance numerical computing
- **[scikit-learn](https://github.com/scikit-learn/scikit-learn)** - Machine learning in Python

---

**Last Updated:** 2026-01-23  
**Version:** 0.3.2 (Architecture Redesign)  
**Status:** Production Ready  

**Summary:**
- üéØ **191 Algorithms** √ó 3 Modes = **573 Implementations**
- üìù **573 Examples** (191 √ó 3 modes) - Perfect 1:1 Match
- üìä **103.8% sklearn Coverage** (191/184 core algorithms)
- ‚ö° **5x+ JAX Acceleration**
- üîê **3 Privacy Modes** (FL/SS/SL)
- **0 Errors** - Perfect Code Quality
