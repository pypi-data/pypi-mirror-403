name: Hello World Workflow
description: |
  The official "Hello World" for AKIOS v1.0.
  Generates a creative greeting using real AI (your chosen LLM provider), saves it to file, and proves the cage works.

  **REQUIRES:** None (generates content from scratch)
  **OUTPUT:** data/output/run_*/hello-ai.txt (creative AI greeting)

  This is what AKIOS is all about: real AI running inside the unbreakable cage.

steps:
  # Step 1: Secure LLM call - no sensitive data in prompt
  - step: 1
    agent: llm
    config:
      provider: "${AKIOS_LLM_PROVIDER:-grok}"  # Use env var or default to grok
      model: "${AKIOS_LLM_MODEL:-grok-3}"      # Use env var or default model
    action: complete
    parameters:
      prompt: |
        You are an AI locked inside AKIOS — the most secure, unbreakable digital cage ever built.
        Say "Hello, World!" in the most creative, fun, witty, and playful way possible.
        Embrace your situation — joke about being trapped in this ultra-secure prison, but still super excited to meet the human on the other side.
        Keep it short, punchy, and full of personality!
      max_tokens: 80    # Enough for creativity without rambling
      temperature: 0.9  # Higher for more fun/creativity
      # Security: Token limit + cost kill-switch enforced automatically

  # Step 2: Save the AI output to file (shows filesystem agent)
  - step: 2
    agent: filesystem
    config:
      allowed_paths: ["./data/output"]
      read_only: false
    action: write
    parameters:
      path: "./data/output/hello-ai.txt"
      content: "{previous_output}"  # References Step 1 result
      # Security: Write restricted to whitelisted path

  # Step 3: Read it back (optional - shows round-trip)
  - step: 3
    agent: filesystem
    config:
      allowed_paths: ["./data/output"]
    action: read
    parameters:
      path: "./data/output/hello-ai.txt"
