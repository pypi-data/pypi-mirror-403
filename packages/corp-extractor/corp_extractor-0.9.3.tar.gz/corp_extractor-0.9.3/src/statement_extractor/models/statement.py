"""
Statement models for the extraction pipeline.

SplitSentence: Output of Stage 1 (Splitting) - atomic sentences/statements
PipelineStatement: Output of Stage 2 (Extraction) with subject-predicate-object triples
"""

from typing import Optional

from pydantic import BaseModel, Field

from .entity import ExtractedEntity


class SplitSentence(BaseModel):
    """
    An atomic sentence from Stage 1 (Splitting).

    Stage 1 splits text into atomic sentences that can each be converted
    to subject-predicate-object triples in Stage 2. Generated by T5-Gemma
    or other splitting plugins.
    """
    text: str = Field(..., description="The atomic sentence text")
    confidence: float = Field(
        default=1.0,
        ge=0.0,
        le=1.0,
        description="Confidence that this is a valid atomic statement"
    )
    # Document tracking fields
    document_id: Optional[str] = Field(
        None,
        description="ID of the source document (for document pipeline)"
    )
    page_number: Optional[int] = Field(
        None,
        description="Page number where this sentence was extracted (1-indexed)"
    )
    chunk_index: Optional[int] = Field(
        None,
        description="Index of the chunk this sentence was extracted from (0-indexed)"
    )

    def __str__(self) -> str:
        return self.text


# Backwards compatibility alias
RawTriple = SplitSentence


class PipelineStatement(BaseModel):
    """
    A statement with extracted entities from Stage 2 (Extraction).

    Contains refined subject/object entities with types, spans, and confidence.
    This is the main statement type that flows through stages 2-5.
    """
    subject: ExtractedEntity = Field(..., description="The subject entity")
    predicate: str = Field(..., description="The relationship/predicate text")
    predicate_category: Optional[str] = Field(
        None,
        description="Category/domain of the predicate (e.g., 'ownership_control', 'employment_leadership')"
    )
    object: ExtractedEntity = Field(..., description="The object entity")
    source_text: str = Field(..., description="The source text this statement was extracted from")
    confidence_score: float = Field(
        default=1.0,
        ge=0.0,
        le=1.0,
        description="Overall confidence score for this statement"
    )
    extraction_method: Optional[str] = Field(
        None,
        description="Method used to extract this statement (e.g., 'hybrid', 'gliner', 'model')"
    )
    # Document tracking fields
    document_id: Optional[str] = Field(
        None,
        description="ID of the source document (for document pipeline)"
    )
    page_number: Optional[int] = Field(
        None,
        description="Page number where this statement was extracted (1-indexed)"
    )
    chunk_index: Optional[int] = Field(
        None,
        description="Index of the chunk this statement was extracted from (0-indexed)"
    )

    def __str__(self) -> str:
        return f"{self.subject.text} --[{self.predicate}]--> {self.object.text}"

    def as_triple(self) -> tuple[str, str, str]:
        """Return as a simple (subject, predicate, object) tuple."""
        return (self.subject.text, self.predicate, self.object.text)

    class Config:
        frozen = False  # Allow modification during pipeline stages
