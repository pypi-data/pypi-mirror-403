from pydantic import BaseModel

from elluminate.schemas.llm_config import LLMConfig


class CustomApiInfo(BaseModel):
    provider: str
    api_request_id: str | None = None
    track_request_url: str | None = None


class GenerationMetadata(BaseModel):
    """Metadata about an LLM generation."""

    llm_model_config: LLMConfig
    duration_seconds: float | None = None
    input_tokens: int | None = None
    output_tokens: int | None = None
    # Tokens used for internal reasoning (e.g., OpenAI o-series models, Gemini thinking models).
    # Anthropic extended thinking does not currently expose this separately.
    # output_tokens is the total (reasoning + content); calculate content-only as output_tokens - reasoning_tokens.
    reasoning_tokens: int | None = None
    custom_api_info: CustomApiInfo | None = None

    def __repr__(self) -> str:
        return f"Generation for {self.llm_model_config!s}"
