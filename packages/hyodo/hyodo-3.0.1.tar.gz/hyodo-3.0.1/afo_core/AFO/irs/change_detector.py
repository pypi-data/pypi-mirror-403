"""
Change Detector - ë¬¸ì„œ ë³€ê²½ ê°ì§€ ì—”ì§„

çœ (ì¥ì˜ì‹¤ - Jang Yeong-sil): ì•„í‚¤í…ì²˜ ì„¤ê³„
- í•´ì‹œ ê¸°ë°˜ ë³€ê²½ ê°ì§€
- ì˜í–¥ë„ í‰ê°€
- ë³€ê²½ì‚¬í•­ ë¶„ë¥˜
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any

from .hash_utils import HashUtils

logger = logging.getLogger(__name__)


@dataclass
class ChangeImpact:
    """ë³€ê²½ ì˜í–¥ë„"""

    category: str  # "critical", "high", "medium", "low"
    score: float  # 0.0 ~ 1.0
    areas: list[str] = field(default_factory=list)
    description: str = ""

    def to_dict(self) -> dict[str, Any]:
        return {
            "category": self.category,
            "score": self.score,
            "areas": self.areas,
            "description": self.description,
        }


@dataclass
class ChangeSummary:
    """ë³€ê²½ ìš”ì•½"""

    change_id: str
    document_id: str
    previous_hash: str
    current_hash: str
    detected_at: str
    impact: ChangeImpact
    document_type: str = ""  # IRS ë¬¸ì„œ íƒ€ì… (ì˜ˆ: "IRS Publication 17")
    changes: dict[str, Any] = field(default_factory=dict)
    evidence_bundle_id: str | None = None

    def to_dict(self) -> dict[str, Any]:
        return {
            "change_id": self.change_id,
            "document_id": self.document_id,
            "document_type": self.document_type,
            "previous_hash": self.previous_hash,
            "current_hash": self.current_hash,
            "detected_at": self.detected_at,
            "impact": self.impact.to_dict(),
            "changes": self.changes,
            "evidence_bundle_id": self.evidence_bundle_id,
        }


class ChangeDetector:
    """ë³€ê²½ ê°ì§€ ì—”ì§„"""

    CRITICAL_KEYWORDS = {
        "energy_credit": ["energy", "credit", "2034", "2025", "expiration", "deadline"],
        "ev_credit": ["electric", "vehicle", "credit", "2025", "9", "30", "expiration"],
        "bonus_depreciation": ["bonus", "depreciation", "100%", "100", "january", "permanent"],
        "erc_refund": ["erc", "refund", "2024", "january", "31", "deadline"],
    }

    def __init__(self, hash_algorithm: str = "sha256") -> None:
        self.hash_algorithm = hash_algorithm
        logger.info("Change Detector ì´ˆê¸°í™” ì™„ë£Œ")

    def detect_change(
        self,
        previous_content: str,
        current_content: str,
        document_id: str,
    ) -> ChangeSummary | None:
        """
        ë³€ê²½ ê°ì§€

        Args:
            previous_content: ì´ì „ ì½˜í…ì¸ 
            current_content: í˜„ì¬ ì½˜í…ì¸ 
            document_id: ë¬¸ì„œ ID

        Returns:
            ChangeSummary ë˜ëŠ” None (ë³€ê²½ ì—†ìŒ)
        """
        # í•´ì‹œ ê³„ì‚°
        previous_hash = HashUtils.calculate_hash(previous_content, self.hash_algorithm)
        current_hash = HashUtils.calculate_hash(current_content, self.hash_algorithm)

        # í•´ì‹œ ë¹„êµ
        hash_comparison = HashUtils.compare_hashes(previous_hash, current_hash, self.hash_algorithm)

        if hash_comparison["equal"]:
            logger.info(f"âœ… ë³€ê²½ ì—†ìŒ: {document_id}")
            return None

        # ë³€ê²½ ê°ì§€
        logger.warning(f"ğŸš¨ ë³€ê²½ ê°ì§€: {document_id} (diff_bits={hash_comparison['diff_bits']})")

        # ì˜í–¥ë„ í‰ê°€
        impact = self._assess_impact(
            previous_content,
            current_content,
            document_id,
        )

        # ë³€ê²½ ìš”ì•½ ìƒì„±
        change_summary = ChangeSummary(
            change_id=f"change-{document_id}-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            document_id=document_id,
            previous_hash=previous_hash,
            current_hash=current_hash,
            detected_at=datetime.now().isoformat(),
            impact=impact,
            changes={
                "hash_diff": hash_comparison,
            },
        )

        return change_summary

    def _assess_impact(
        self,
        previous_content: str,
        current_content: str,
        document_id: str,
    ) -> ChangeImpact:
        """
        ì˜í–¥ë„ í‰ê°€

        Args:
            previous_content: ì´ì „ ì½˜í…ì¸ 
            current_content: í˜„ì¬ ì½˜í…ì¸ 
            document_id: ë¬¸ì„œ ID

        Returns:
            ChangeImpact
        """
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì˜í–¥ë„ í‰ê°€
        impact_areas = []
        impact_score = 0.0

        # ì£¼ìš” í‚¤ì›Œë“œ ê²€ìƒ‰
        for category, keywords in self.CRITICAL_KEYWORDS.items():
            for keyword in keywords:
                if keyword.lower() in current_content.lower():
                    impact_areas.append(f"{category}_{keyword}")

        # ì˜í–¥ë„ ê³„ì‚°
        impact_score = min(len(impact_areas) * 0.2, 1.0) if impact_areas else 0.1

        # ì¹´í…Œê³ ë¦¬ ê²°ì •
        if impact_score >= 0.8:
            category = "critical"
        elif impact_score >= 0.6:
            category = "high"
        elif impact_score >= 0.3:
            category = "medium"
        else:
            category = "low"

        impact = ChangeImpact(
            category=category,
            score=impact_score,
            areas=impact_areas,
            description=f"ì˜í–¥ë„: {category} (score: {impact_score:.2f})",
        )

        logger.debug(
            f"ì˜í–¥ë„ í‰ê°€: {document_id}, category={category}, "
            f"score={impact_score:.2f}, areas={len(impact_areas)}"
        )

        return impact

    def batch_detect_changes(
        self,
        documents: dict[str, dict[str, str]],
    ) -> list[ChangeSummary]:
        """
        ë°°ì¹˜ ë³€ê²½ ê°ì§€

        Args:
            documents: ë¬¸ì„œ ë”•ì…”ë„ˆë¦¬
                {
                    "document_id": {
                        "previous": "previous_content",
                        "current": "current_content",
                    },
                }

        Returns:
            ChangeSummary ë¦¬ìŠ¤íŠ¸
        """
        results = []

        for doc_id, doc_contents in documents.items():
            previous_content = doc_contents.get("previous", "")
            current_content = doc_contents.get("current", "")

            if not previous_content or not current_content:
                logger.warning(f"âš ï¸ ì½˜í…ì¸  ì—†ìŒ: {doc_id}")
                continue

            change_summary = self.detect_change(previous_content, current_content, doc_id)

            if change_summary:
                results.append(change_summary)

        logger.info(f"ë°°ì¹˜ ë³€ê²½ ê°ì§€ ì™„ë£Œ: {len(results)}ê°œ ë³€ê²½ ê°ì§€")

        return results


# Convenience Functions
def detect_change(
    previous_content: str,
    current_content: str,
    document_id: str,
    hash_algorithm: str = "sha256",
) -> ChangeSummary | None:
    """ë³€ê²½ ê°ì§€ (í¸ì˜ í•¨ìˆ˜)"""
    detector = ChangeDetector(hash_algorithm)
    return detector.detect_change(previous_content, current_content, document_id)


def batch_detect_changes(
    documents: dict[str, dict[str, str]],
    hash_algorithm: str = "sha256",
) -> list[ChangeSummary]:
    """ë°°ì¹˜ ë³€ê²½ ê°ì§€ (í¸ì˜ í•¨ìˆ˜)"""
    detector = ChangeDetector(hash_algorithm)
    return detector.batch_detect_changes(documents)


# Alias for backward compatibility
ChangeDetection = ChangeSummary

__all__ = [
    "ChangeDetection",
    "ChangeImpact",
    "ChangeSummary",
    "ChangeDetector",
    "detect_change",
    "batch_detect_changes",
]
