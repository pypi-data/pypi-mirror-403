# Trinity Score: 90.0 (Established by Chancellor)
"""Trinity Type Validator - ëŸ°íƒ€ì„ íƒ€ì… ê²€ì¦ ì‹œìŠ¤í…œ
Phase 5: í˜ì‹ ì  íƒ€ì… ì‹œìŠ¤í…œ êµ¬í˜„

ì´ ëª¨ë“ˆì€ ëŸ°íƒ€ì„ì— Trinity Score ê¸°ë°˜ íƒ€ì… ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import asyncio
import functools
import inspect
import logging
import time
import traceback
from collections.abc import Callable
from typing import Any, TypeVar, Union

from AFO.domain.metrics.trinity_manager import TrinityManager

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

F = TypeVar("F", bound=Callable[..., Any])


class TrinityTypeValidator:
    """ëŸ°íƒ€ì„ Trinity Score ê¸°ë°˜ íƒ€ì… ê²€ì¦ ì‹œìŠ¤í…œ

    Phase 5: í˜ì‹ ì  íƒ€ì… ì‹œìŠ¤í…œì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸
    """

    def __init__(self, trinity_manager: TrinityManager | None = None) -> None:
        self.trinity_manager = trinity_manager or TrinityManager()
        self.validation_cache: dict[str, dict[str, Any]] = {}
        self.performance_stats: dict[str, dict[str, Any]] = {}

    def validate_function(self, func: F, *args, **kwargs) -> dict[str, Any]:
        """í•¨ìˆ˜ ì‹¤í–‰ ì „í›„ë¡œ Trinity Score ê¸°ë°˜ ê²€ì¦ ìˆ˜í–‰

        Args:
            func: ê²€ì¦í•  í•¨ìˆ˜
            *args: í•¨ìˆ˜ ì¸ì
            **kwargs: í•¨ìˆ˜ í‚¤ì›Œë“œ ì¸ì

        Returns:
            ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬

        """
        func_name = getattr(func, "__name__", str(func))
        start_time = time.time()

        # Pre-validation (çœ: íƒ€ì… ì¼ê´€ì„± ê²€ì¦)
        pre_validation = self._pre_validate(func, args, kwargs)

        try:
            # í•¨ìˆ˜ ì‹¤í–‰ (async í•¨ìˆ˜ ê°ì§€ ë° ì²˜ë¦¬)
            if inspect.iscoroutinefunction(func):
                # Async í•¨ìˆ˜ì¸ ê²½ìš°: ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ì—ì„œ ì‹¤í–‰
                try:
                    loop = asyncio.get_running_loop()
                    # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ Taskë¡œ ìŠ¤ì¼€ì¤„ë§
                    result = loop.run_until_complete(func(*args, **kwargs))
                except RuntimeError:
                    # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                    result = asyncio.run(func(*args, **kwargs))
            else:
                # Sync í•¨ìˆ˜ì¸ ê²½ìš°: ì¼ë°˜ í˜¸ì¶œ
                result = func(*args, **kwargs)

            execution_time = time.time() - start_time

            # Post-validation (å–„: ì•ˆì „ì„± ê²€ì¦)
            post_validation = self._post_validate(func, args, kwargs, result)

            # Trinity Score ê³„ì‚° (ç¾: í’ˆì§ˆ ì¢…í•© í‰ê°€)
            trinity_score = self._calculate_trinity_score(
                func, pre_validation, post_validation, execution_time
            )

            # ê²°ê³¼ ìºì‹œ
            cache_key = f"{func_name}:{hash(str(args) + str(kwargs))}"
            self.validation_cache[cache_key] = {
                "timestamp": time.time(),
                "trinity_score": trinity_score,
                "execution_time": execution_time,
                "status": "success",
            }

            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸ (æ°¸: ì¥ê¸°ì  ëª¨ë‹ˆí„°ë§)
            self._update_performance_stats(func_name, execution_time, trinity_score)

            return {
                "status": "success",
                "trinity_score": trinity_score,
                "execution_time": execution_time,
                "pre_validation": pre_validation,
                "post_validation": post_validation,
                "result_type": type(result).__name__,
                "confidence": trinity_score / 100.0,
                "recommendations": self._generate_recommendations(
                    trinity_score, pre_validation, post_validation
                ),
            }

        except Exception as e:
            execution_time = time.time() - start_time

            # ì—ëŸ¬ ìƒí™©ì—ì„œë„ ë¶€ë¶„ í‰ê°€ ìˆ˜í–‰
            error_validation = self._handle_error_validation(func, e)

            trinity_score = max(
                0,
                self._calculate_error_trinity_score(
                    func, pre_validation, error_validation, execution_time, e
                ),
            )

            logger.warning(
                "Trinity ê²€ì¦ ì¤‘ í•¨ìˆ˜ ì‹¤í–‰ ì‹¤íŒ¨: %s - %s",
                func_name,
                str(e),
            )
            return {
                "status": "error",
                "error": str(e),
                "error_type": type(e).__name__,
                "trinity_score": trinity_score,
                "execution_time": execution_time,
                "pre_validation": pre_validation,
                "error_validation": error_validation,
                "confidence": 0.0,
                "recommendations": self._generate_error_recommendations(e, trinity_score),
            }

    def __call__(self, func: F) -> F:
        """ë°ì½”ë ˆì´í„° ì¸í„°í˜ì´ìŠ¤ - í•¨ìˆ˜ì— ìë™ ê²€ì¦ ì ìš©

        Usage:
            @TrinityTypeValidator()
            def my_function(x: int, y: str) -> str:
                return f"{x}: {y}"

            @TrinityTypeValidator()
            async def my_async_function(x: int) -> str:
                return str(x)
        """
        if inspect.iscoroutinefunction(func):
            # Async í•¨ìˆ˜ìš© ë˜í¼
            @functools.wraps(func)
            async def async_wrapper(*args, **kwargs):
                # Async í•¨ìˆ˜ëŠ” ê²€ì¦ì„ ê±´ë„ˆë›°ê³  ì§ì ‘ ì‹¤í–‰ (ì„±ëŠ¥ ìµœì í™”)
                # í•„ìš”ì‹œ ë³„ë„ì˜ async ê²€ì¦ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
                return await func(*args, **kwargs)

            return async_wrapper  # type: ignore[return-value]
        else:
            # Sync í•¨ìˆ˜ìš© ë˜í¼
            @functools.wraps(func)
            def sync_wrapper(*args, **kwargs) -> None:
                result = self.validate_function(func, *args, **kwargs)

                # ê²€ì¦ ì‹¤íŒ¨ ì‹œ ë¡œê¹… ë° ê²½ê³ 
                if result["status"] == "error":
                    logger.warning(
                        "Trinity ê²€ì¦ ì‹¤íŒ¨: %s - ì˜¤ë¥˜: %s, Score: %.1f",
                        func.__name__,
                        result["error"],
                        result["trinity_score"],
                    )
                    for rec in result.get("recommendations", []):
                        logger.info("ê¶Œì¥ì‚¬í•­: %s", rec)

                # ê²€ì¦ ì„±ê³µ ì‹œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
                elif result["trinity_score"] < 70:
                    logger.warning(
                        "ë‚®ì€ Trinity Score: %s (%.1f)",
                        func.__name__,
                        result["trinity_score"],
                    )
                    for rec in result.get("recommendations", []):
                        logger.info("ê¶Œì¥ì‚¬í•­: %s", rec)

                return func(*args, **kwargs)

            return sync_wrapper  # type: ignore[return-value]

    def _pre_validate(self, func: Callable, args: tuple, kwargs: dict) -> dict[str, Any]:
        """ì‚¬ì „ ê²€ì¦: í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ì™€ ì…ë ¥ íƒ€ì… ì¼ê´€ì„± ê²€ì¦"""
        try:
            sig = inspect.signature(func)
            bound_args = sig.bind(*args, **kwargs)
            bound_args.apply_defaults()

            validation_results: dict[str, Any] = {
                "signature_valid": True,
                "param_count": len(bound_args.arguments),
                "param_types": {},
                "missing_params": [],
                "extra_params": [],
            }
            # íƒ€ì… ëª…ì‹œ: param_typesëŠ” dict[str, dict[str, Any]]
            param_types: dict[str, dict[str, Any]] = validation_results["param_types"]

            # íƒ€ì… íŒíŠ¸ ê¸°ë°˜ ê²€ì¦
            for param_name, param_value in bound_args.arguments.items():
                param_info = sig.parameters.get(param_name)
                if param_info and param_info.annotation != inspect.Parameter.empty:
                    expected_type = param_info.annotation
                    actual_type = type(param_value)

                    # íƒ€ì… ì¼ì¹˜ë„ ê³„ì‚° (ë‹¨ìˆœ ë²„ì „)
                    type_match = self._calculate_type_match(expected_type, actual_type)
                    param_types[param_name] = {
                        "expected": str(expected_type),
                        "actual": str(actual_type),
                        "match_score": type_match,
                    }

            return validation_results

        except (ValueError, TypeError, AttributeError) as e:
            logger.debug("ì‚¬ì „ ê²€ì¦ ì‹¤íŒ¨ (ê°’/íƒ€ì…/ì†ì„± ì—ëŸ¬): %s", str(e))
            return {
                "signature_valid": False,
                "error": str(e),
                "param_count": len(args) + len(kwargs),
            }
        except Exception as e:  # - Intentional fallback for unexpected errors
            logger.debug("ì‚¬ì „ ê²€ì¦ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: %s", str(e))
            return {
                "signature_valid": False,
                "error": str(e),
                "param_count": len(args) + len(kwargs),
            }

    def _post_validate(
        self, func: Callable, args: tuple, kwargs: dict, result: Any
    ) -> dict[str, Any]:
        """ì‚¬í›„ ê²€ì¦: ë¦¬í„´ íƒ€ì…ê³¼ ê²°ê³¼ ì¼ê´€ì„± ê²€ì¦"""
        try:
            sig = inspect.signature(func)
            return_annotation = sig.return_annotation

            if return_annotation != inspect.Signature.empty:
                expected_type = return_annotation
                actual_type = type(result)

                type_match = self._calculate_type_match(expected_type, actual_type)

                return {
                    "return_type_valid": True,
                    "expected_return": str(expected_type),
                    "actual_return": str(actual_type),
                    "return_match_score": type_match,
                    "result_size": self._estimate_size(result),
                }
            else:
                return {
                    "return_type_valid": False,
                    "reason": "no_return_annotation",
                    "actual_return": str(type(result)),
                    "result_size": self._estimate_size(result),
                }

        except (ValueError, TypeError, AttributeError) as e:
            logger.debug("ì‚¬í›„ ê²€ì¦ ì‹¤íŒ¨ (ê°’/íƒ€ì…/ì†ì„± ì—ëŸ¬): %s", str(e))
            return {
                "return_type_valid": False,
                "error": str(e),
                "actual_return": (str(type(result)) if "result" in locals() else "unknown"),
            }
        except Exception as e:  # - Intentional fallback for unexpected errors
            logger.debug("ì‚¬í›„ ê²€ì¦ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: %s", str(e))
            return {
                "return_type_valid": False,
                "error": str(e),
                "actual_return": (str(type(result)) if "result" in locals() else "unknown"),
            }

    def _calculate_type_match(self, expected: Any, actual: Any) -> float:
        """íƒ€ì… ì¼ì¹˜ë„ ê³„ì‚° (0.0 ~ 1.0)"""
        try:
            # ê°„ë‹¨í•œ íƒ€ì… ì¼ì¹˜ë„ ê³„ì‚°
            if expected == actual:
                return 1.0

            # ìƒì† ê´€ê³„ í™•ì¸
            if (
                inspect.isclass(expected)
                and inspect.isclass(actual)
                and issubclass(actual, expected)
            ):
                return 0.8

            # Union íƒ€ì… ì²˜ë¦¬
            if hasattr(expected, "__origin__") and expected.__origin__ in (
                Union,
                tuple,
            ):
                return 0.6  # Union íƒ€ì…ì€ ë¶€ë¶„ ì¼ì¹˜ë¡œ ê°„ì£¼

            # Generic íƒ€ì… ì²˜ë¦¬
            if hasattr(expected, "__origin__"):
                return 0.7  # Generic íƒ€ì…ì€ ë³´ìˆ˜ì ìœ¼ë¡œ í‰ê°€

            return 0.0

        except (TypeError, AttributeError) as e:
            logger.debug("íƒ€ì… ì¼ì¹˜ë„ ê³„ì‚° ì‹¤íŒ¨: %s", str(e))
            return 0.0
        except Exception as e:  # - Intentional fallback for unexpected errors
            logger.debug("íƒ€ì… ì¼ì¹˜ë„ ê³„ì‚° ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: %s", str(e))
            return 0.0

    def _estimate_size(self, obj: Any) -> int:
        """ê°ì²´ í¬ê¸° ì¶”ì • (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë°˜)"""
        try:
            import sys

            return sys.getsizeof(obj)
        except (TypeError, AttributeError) as e:
            logger.debug("ê°ì²´ í¬ê¸° ì¶”ì • ì‹¤íŒ¨: %s", str(e))
            return 0
        except Exception as e:  # - Intentional fallback for unexpected errors
            logger.debug("ê°ì²´ í¬ê¸° ì¶”ì • ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: %s", str(e))
            return 0

    def _calculate_trinity_score(
        self,
        func: Callable,
        pre_validation: dict[str, Any],
        post_validation: dict[str, Any],
        execution_time: float,
    ) -> float:
        """Trinity Score ê³„ì‚° (çœå–„ç¾å­æ°¸)"""
        # çœ (Truth): íƒ€ì… ì •í™•ì„±
        truth_score = self._evaluate_truth(pre_validation, post_validation)

        # å–„ (Goodness): ì•ˆì „ì„±
        goodness_score = self._evaluate_goodness(func, execution_time)

        # ç¾ (Beauty): ì½”ë“œ í’ˆì§ˆ
        beauty_score = self._evaluate_beauty(func)

        # å­ (Serenity): ì•ˆì •ì„±
        serenity_score = self._evaluate_serenity(pre_validation, post_validation)

        # æ°¸ (Eternity): ìœ ì§€ë³´ìˆ˜ì„±
        eternity_score = self._evaluate_eternity(func)

        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        weights = {
            "truth": 0.35,
            "goodness": 0.35,
            "beauty": 0.20,
            "serenity": 0.08,
            "eternity": 0.02,
        }

        trinity_score = (
            truth_score * weights["truth"]
            + goodness_score * weights["goodness"]
            + beauty_score * weights["beauty"]
            + serenity_score * weights["serenity"]
            + eternity_score * weights["eternity"]
        )

        return round(trinity_score, 2)

    def _calculate_error_trinity_score(
        self,
        func: Callable,
        pre_validation: dict[str, Any],
        error_validation: dict[str, Any],
        execution_time: float,
        error: Exception,
    ) -> float:
        """ì—ëŸ¬ ìƒí™©ì—ì„œì˜ Trinity Score ê³„ì‚°"""
        # ì—ëŸ¬ ì‹œ ê¸°ë³¸ ì ìˆ˜ ì ˆë°˜ìœ¼ë¡œ ì‹œì‘
        base_score = 50.0

        # ì—ëŸ¬ íƒ€ì…ì— ë”°ë¥¸ ì¡°ì •
        if isinstance(error, (TypeError, AttributeError)):
            base_score -= 20  # íƒ€ì… ê´€ë ¨ ì—ëŸ¬ëŠ” í° ê°ì 
        elif isinstance(error, ValueError):
            base_score -= 10  # ê°’ ê´€ë ¨ ì—ëŸ¬ëŠ” ì¤‘ê°„ ê°ì 

        # ì‹¤í–‰ ì‹œê°„ì— ë”°ë¥¸ ì¶”ê°€ ì¡°ì •
        if execution_time > 10:
            base_score -= 5  # ëŠë¦° ì‹¤í–‰ì€ ì¶”ê°€ ê°ì 

        return max(0, base_score)

    def _evaluate_truth(self, pre: dict[str, Any], post: dict[str, Any]) -> float:
        """çœ: íƒ€ì… ì •í™•ì„± í‰ê°€"""
        score = 100.0

        # íŒŒë¼ë¯¸í„° íƒ€ì… ì¼ì¹˜ë„
        if "param_types" in pre:
            type_matches = [info["match_score"] for info in pre["param_types"].values()]
            if type_matches:
                avg_match = sum(type_matches) / len(type_matches)
                score -= (1 - avg_match) * 30  # ìµœëŒ€ 30ì  ê°ì 

        # ë¦¬í„´ íƒ€ì… ì¼ì¹˜ë„
        if post.get("return_match_score") is not None:
            return_match = post["return_match_score"]
            score -= (1 - return_match) * 20  # ìµœëŒ€ 20ì  ê°ì 

        return max(0, score)

    def _evaluate_goodness(self, func: Callable, execution_time: float) -> float:
        """å–„: ì•ˆì „ì„±ê³¼ ì„±ëŠ¥ í‰ê°€"""
        score = 100.0

        # ì‹¤í–‰ ì‹œê°„ ê¸°ë°˜ í‰ê°€
        if execution_time > 5:
            score -= 20  # 5ì´ˆ ì´ˆê³¼ ì‹œ ì„±ëŠ¥ ê°ì 
        elif execution_time > 1:
            score -= 10  # 1ì´ˆ ì´ˆê³¼ ì‹œ ì¤‘ê°„ ê°ì 

        # í•¨ìˆ˜ ë³µì¡ë„ í‰ê°€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        try:
            source = inspect.getsource(func)
            lines_of_code = len(source.split("\n"))
            if lines_of_code > 50:
                score -= 10  # ê¸´ í•¨ìˆ˜ëŠ” ë³µì¡ë„ ê°ì 
        except (OSError, AttributeError) as e:
            logger.debug("í•¨ìˆ˜ ì†ŒìŠ¤ ë¶„ì„ ì‹¤íŒ¨: %s", str(e))
            pass
        except Exception as e:  # - Intentional fallback for unexpected errors
            logger.debug("í•¨ìˆ˜ ì†ŒìŠ¤ ë¶„ì„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: %s", str(e))
            pass

        return max(0, score)

    def _evaluate_beauty(self, func: Callable) -> float:
        """ç¾: ì½”ë“œ í’ˆì§ˆ í‰ê°€"""
        score = 100.0

        try:
            source = inspect.getsource(func)

            # íƒ€ì… íŒíŠ¸ ì‚¬ìš©ë„ í‰ê°€
            has_type_hints = "->" in source or ": " in source
            if not has_type_hints:
                score -= 20

            # ë…ìŠ¤íŠ¸ë§ ì¡´ì¬ ì—¬ë¶€
            has_docstring = '"""' in source or "'''" in source
            if not has_docstring:
                score -= 10

        except (OSError, AttributeError) as e:
            logger.debug("ì½”ë“œ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: %s", str(e))
            score -= 15  # ì†ŒìŠ¤ ë¶„ì„ ì‹¤íŒ¨ ì‹œ ê°ì 
        except Exception as e:  # - Intentional fallback for unexpected errors
            logger.debug("ì½”ë“œ í’ˆì§ˆ í‰ê°€ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: %s", str(e))
            score -= 15  # ì†ŒìŠ¤ ë¶„ì„ ì‹¤íŒ¨ ì‹œ ê°ì 

        return max(0, score)

    def _evaluate_serenity(self, pre: dict[str, Any], post: dict[str, Any]) -> float:
        """å­: ì•ˆì •ì„±ê³¼ ì¼ê´€ì„± í‰ê°€"""
        score = 100.0

        # ê²€ì¦ ì„±ê³µë¥ 
        if not pre.get("signature_valid", True):
            score -= 25

        if not post.get("return_type_valid", True):
            score -= 20

        return max(0, score)

    def _evaluate_eternity(self, func: Callable) -> float:
        """æ°¸: ìœ ì§€ë³´ìˆ˜ì„±ê³¼ í™•ì¥ì„± í‰ê°€"""
        score = 100.0

        try:
            # í•¨ìˆ˜ ë©”íŠ¸ë¦­ ë¶„ì„
            sig = inspect.signature(func)
            param_count = len(sig.parameters)

            if param_count > 10:
                score -= 20  # ë„ˆë¬´ ë§ì€ íŒŒë¼ë¯¸í„°
            elif param_count > 5:
                score -= 10  # íŒŒë¼ë¯¸í„°ê°€ ë§ì€ í¸

            # í•¨ìˆ˜ ê¸¸ì´ í‰ê°€
            source = inspect.getsource(func)
            lines_of_code = len(source.split("\n"))
            if lines_of_code > 100:
                score -= 15  # ë„ˆë¬´ ê¸´ í•¨ìˆ˜

        except (OSError, AttributeError) as e:
            logger.debug("ìœ ì§€ë³´ìˆ˜ì„± í‰ê°€ ì‹¤íŒ¨: %s", str(e))
            score -= 10
        except Exception as e:  # - Intentional fallback for unexpected errors
            logger.debug("ìœ ì§€ë³´ìˆ˜ì„± í‰ê°€ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: %s", str(e))
            score -= 10

        return max(0, score)

    def _generate_recommendations(
        self,
        trinity_score: float,
        pre_validation: dict[str, Any],
        post_validation: dict[str, Any],
    ) -> list[str]:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        if trinity_score < 70:
            recommendations.append("Trinity Score í–¥ìƒì´ í•„ìš”í•©ë‹ˆë‹¤")

        if "param_types" in pre_validation:
            for param_name, type_info in pre_validation["param_types"].items():
                if type_info["match_score"] < 0.8:
                    recommendations.append(
                        f"'{param_name}' íŒŒë¼ë¯¸í„° íƒ€ì… íŒíŠ¸ ê°œì„  ê³ ë ¤ ({type_info['expected']} â†” {type_info['actual']})"
                    )

        if post_validation.get("return_match_score", 1.0) < 0.8:
            recommendations.append("ë¦¬í„´ íƒ€ì… íŒíŠ¸ ì •í™•ì„± ê²€í†  í•„ìš”")

        return recommendations

    def _generate_error_recommendations(self, error: Exception, trinity_score: float) -> list[str]:
        """ì—ëŸ¬ ìƒí™© ê°œì„  ê¶Œì¥ì‚¬í•­"""
        recommendations = []

        if isinstance(error, TypeError):
            recommendations.append("íƒ€ì… íŒíŠ¸ ì¶”ê°€ ë˜ëŠ” ìˆ˜ì • ê³ ë ¤")
        elif isinstance(error, AttributeError):
            recommendations.append("ê°ì²´ ì†ì„± ì ‘ê·¼ ê²€ì¦ ê°•í™”")
        elif isinstance(error, ValueError):
            recommendations.append("ì…ë ¥ ê°’ ê²€ì¦ ë¡œì§ ì¶”ê°€")

        if trinity_score < 30:
            recommendations.append("í•¨ìˆ˜ ë¡œì§ ì „ë°˜ì  ê²€í†  í•„ìš”")

        return recommendations

    def _handle_error_validation(self, func: Callable, error: Exception) -> dict[str, Any]:
        """ì—ëŸ¬ ìƒí™©ì—ì„œì˜ ê²€ì¦ ì •ë³´ ìƒì„±"""
        return {
            "error_type": type(error).__name__,
            "error_message": str(error),
            "traceback": traceback.format_exc(),
            "validation_possible": False,
        }

    def _update_performance_stats(
        self, func_name: str, execution_time: float, trinity_score: float
    ) -> None:
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        if func_name not in self.performance_stats:
            self.performance_stats[func_name] = {
                "call_count": 0,
                "total_time": 0.0,
                "avg_time": 0.0,
                "min_time": float("inf"),
                "max_time": 0.0,
                "avg_trinity_score": 0.0,
                "last_updated": time.time(),
            }

        stats = self.performance_stats[func_name]
        stats["call_count"] += 1
        stats["total_time"] += execution_time
        stats["avg_time"] = stats["total_time"] / stats["call_count"]
        stats["min_time"] = min(stats["min_time"], execution_time)
        stats["max_time"] = max(stats["max_time"], execution_time)

        # ì´ë™ í‰ê· ìœ¼ë¡œ Trinity Score ì—…ë°ì´íŠ¸
        alpha = 0.1  # í•™ìŠµë¥ 
        stats["avg_trinity_score"] = (
            stats["avg_trinity_score"] * (1 - alpha) + trinity_score * alpha
        )

        stats["last_updated"] = time.time()

    def get_performance_report(self, func_name: str | None = None) -> dict[str, Any]:
        """ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±"""
        if func_name:
            return self.performance_stats.get(func_name, {})

        return {
            "functions": list(self.performance_stats.keys()),
            "summary": {
                "total_functions": len(self.performance_stats),
                "total_calls": sum(
                    stats["call_count"] for stats in self.performance_stats.values()
                ),
                "avg_trinity_score": (
                    sum(stats["avg_trinity_score"] for stats in self.performance_stats.values())
                    / len(self.performance_stats)
                    if self.performance_stats
                    else 0
                ),
            },
            "details": self.performance_stats,
        }


# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
trinity_validator = TrinityTypeValidator()


def validate_with_trinity[TF: Callable[..., Any]](func: TF) -> TF:
    """Trinity ê²€ì¦ ë°ì½”ë ˆì´í„° (async í•¨ìˆ˜ ì§€ì›)

    Usage:
        @validate_with_trinity
        def my_function(x: int) -> str:
            return str(x)

        @validate_with_trinity
        async def my_async_function(x: int) -> str:
            return str(x)
    """
    if inspect.iscoroutinefunction(func):
        # Async í•¨ìˆ˜ëŠ” ê²€ì¦ì„ ê±´ë„ˆë›°ê³  ì§ì ‘ ë°˜í™˜ (ì„±ëŠ¥ ìµœì í™”)
        # í•„ìš”ì‹œ ë³„ë„ì˜ async ê²€ì¦ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
        return func
    else:
        return trinity_validator(func)


# ì˜ˆì‹œ í•¨ìˆ˜ë“¤ (í…ŒìŠ¤íŠ¸ìš©)
@validate_with_trinity
def example_function(x: int, y: str = "default") -> str:
    """Trinity ê²€ì¦ ì˜ˆì‹œ í•¨ìˆ˜"""
    return f"{x}: {y}"


@validate_with_trinity
def risky_function(value: Any) -> int:
    """ìœ„í—˜í•œ í•¨ìˆ˜ ì˜ˆì‹œ"""
    if not isinstance(value, (int, str)):
        raise TypeError("Invalid type")
    return len(str(value))


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸ” Trinity Type Validator í…ŒìŠ¤íŠ¸")

    # ì •ìƒ ì¼€ì´ìŠ¤
    result1 = trinity_validator.validate_function(example_function, 42, "test")
    print(f"âœ… ì •ìƒ ì¼€ì´ìŠ¤: Trinity Score {result1['trinity_score']:.1f}")

    # ì—ëŸ¬ ì¼€ì´ìŠ¤
    try:
        result2 = trinity_validator.validate_function(risky_function, [1, 2, 3])  # ì˜ëª»ëœ íƒ€ì…
    except Exception:
        result2 = trinity_validator.validate_function(risky_function, "valid_string")
        print(f"âœ… ì—ëŸ¬ ë³µêµ¬ ì¼€ì´ìŠ¤: Trinity Score {result2['trinity_score']:.1f}")

    # ì„±ëŠ¥ ë³´ê³ ì„œ
    report = trinity_validator.get_performance_report()
    print(f"ğŸ“Š ëª¨ë‹ˆí„°ë§ëœ í•¨ìˆ˜: {report['summary']['total_functions']}ê°œ")
    print(f"ğŸ“ˆ í‰ê·  Trinity Score: {report['summary']['avg_trinity_score']:.1f}")
