from __future__ import annotations

import asyncio
import hashlib
import json
from typing import TYPE_CHECKING, Any

if TYPE_CHECKING:
    from collections.abc import Callable

# Trinity Score: 90.0 (Established by Chancellor)
#!/usr/bin/env python3
"""Redis ìµœì í™” ëª¨ë“ˆ - Pipeline + Lua Script í†µí•©
AFO Ascension Protocol - Phase 1.1

ê¸°ëŠ¥:
- Redis Pipeline ë°°ì¹˜ ì²˜ë¦¬
- Lua Script ì„œë²„ ì¸¡ ì‹¤í–‰ (GET-OR-COMPUTE íŒ¨í„´)
- Async Redis í´ë¼ì´ì–¸íŠ¸ ì§€ì›
- ìºì‹œ íˆíŠ¸ìœ¨ ëª¨ë‹ˆí„°ë§
"""


class OptimizedRedisCache:
    """ìµœì í™”ëœ Redis ìºì‹œ í´ë˜ìŠ¤
    Pipeline + Lua Script + ëª¨ë‹ˆí„°ë§ í†µí•©
    """

    def __init__(self, client: Any | None = None) -> None:
        self.client = client
        self.hit_count = 0
        self.miss_count = 0
        self.pipeline_count = 0

        # Lua Script ë“±ë¡ (GET-OR-COMPUTE íŒ¨í„´)
        self._register_lua_scripts()

    def _register_lua_scripts(self) -> None:
        """Lua ìŠ¤í¬ë¦½íŠ¸ ë“±ë¡"""
        if not self.client:
            return

        # GET-OR-COMPUTE ìŠ¤í¬ë¦½íŠ¸
        self.get_or_compute_script = self.client.register_script(
            """
            local key = KEYS[1]
            local ttl = ARGV[1]

            -- ìºì‹œ í™•ì¸
            local cached = redis.call('GET', key)
            if cached then
                return {'hit', cached}
            end

            -- ì—†ìœ¼ë©´ placeholder ì„¤ì • í›„ miss ë°˜í™˜
            redis.call('SETEX', key, ttl, '__COMPUTING__')
            return {'miss', ''}
        """
        )

        # ë°°ì¹˜ GET ìŠ¤í¬ë¦½íŠ¸
        self.batch_get_script = self.client.register_script(
            """
            local results = {}
            for i, key in ipairs(KEYS) do
                local value = redis.call('GET', key)
                if value and value ~= '__COMPUTING__' then
                    results[i] = value
                else
                    results[i] = false
                end
            end
            return results
        """
        )

    async def get_or_compute(
        self,
        key: str,
        compute_func: Callable[..., Any],
        ttl_seconds: int = 300,
        *args: Any,
        **kwargs: Any,
    ) -> Any:
        """GET-OR-COMPUTE íŒ¨í„´ êµ¬í˜„

        Args:
            key: ìºì‹œ í‚¤
            compute_func: ê³„ì‚° í•¨ìˆ˜ (async)
            ttl_seconds: TTL ì´ˆ
            *args, **kwargs: compute_funcì— ì „ë‹¬í•  ì¸ì

        Returns:
            ê³„ì‚°ëœ ê°’

        """
        if not self.client:
            # Redis ì—†ìœ¼ë©´ ì§ì ‘ ê³„ì‚°
            return await compute_func(*args, **kwargs)

        try:
            # Lua Script ì‹¤í–‰
            result = await self.get_or_compute_script(keys=[key], args=[ttl_seconds])

            if result[0] == "hit":
                self.hit_count += 1
                return json.loads(result[1])

            # MISS - ê³„ì‚° ìˆ˜í–‰
            self.miss_count += 1
            value = await compute_func(*args, **kwargs)

            # ìºì‹œì— ì €ì¥
            await self.client.setex(key, ttl_seconds, json.dumps(value))
            return value

        except Exception as e:
            print(f"Redis GET-OR-COMPUTE ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ì§ì ‘ ê³„ì‚°
            return await compute_func(*args, **kwargs)

    async def batch_get(self, keys: list[str]) -> dict[str, Any]:
        """ë°°ì¹˜ GET ì‘ì—…

        Args:
            keys: í‚¤ ë¦¬ìŠ¤íŠ¸

        Returns:
            {key: value} ë”•ì…”ë„ˆë¦¬

        """
        if not self.client:
            return {}

        try:
            # Lua Scriptë¡œ ë°°ì¹˜ ì¡°íšŒ
            results = await self.batch_get_script(keys=keys)

            self.pipeline_count += 1
            sum(1 for r in results if r is not False)

            return {
                key: json.loads(value) if value is not False else None
                for key, value in zip(keys, results, strict=False)
            }

        except Exception as e:
            print(f"Redis ë°°ì¹˜ GET ì‹¤íŒ¨: {e}")
            return {}

    async def batch_set(self, key_values: dict[str, Any], ttl_seconds: int = 300) -> None:
        """ë°°ì¹˜ SET ì‘ì—…

        Args:
            key_values: {key: value} ë”•ì…”ë„ˆë¦¬
            ttl_seconds: TTL ì´ˆ

        """
        if not self.client:
            return

        try:
            async with self.client.pipeline() as pipe:
                for key, value in key_values.items():
                    pipe.setex(key, ttl_seconds, json.dumps(value))
                await pipe.execute()
                self.pipeline_count += 1

        except Exception as e:
            print(f"Redis ë°°ì¹˜ SET ì‹¤íŒ¨: {e}")

    def get_stats(self) -> dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        total_requests = self.hit_count + self.miss_count
        hit_rate = self.hit_count / total_requests if total_requests > 0 else 0

        return {
            "hit_count": self.hit_count,
            "miss_count": self.miss_count,
            "pipeline_count": self.pipeline_count,
            "hit_rate": hit_rate,
            "total_requests": total_requests,
        }


# ì „ì—­ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
_redis_cache: OptimizedRedisCache | None = None


def get_redis_cache(client: Any | None = None) -> OptimizedRedisCache:
    """ì „ì—­ Redis ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _redis_cache
    if _redis_cache is None:
        _redis_cache = OptimizedRedisCache(client)
    return _redis_cache


# í¸ì˜ í•¨ìˆ˜ë“¤
async def cached_get_or_compute(
    key: str,
    compute_func: Callable[..., Any],
    ttl_seconds: int = 300,
    *args: Any,
    **kwargs: Any,
) -> Any:
    """í¸ì˜ í•¨ìˆ˜ - ìºì‹œëœ GET-OR-COMPUTE"""
    """í¸ì˜ í•¨ìˆ˜ - ìºì‹œëœ GET-OR-COMPUTE"""
    cache = get_redis_cache()
    return await cache.get_or_compute(key, compute_func, ttl_seconds, *args, **kwargs)


async def cached_batch_get(keys: list[str]) -> dict[str, Any]:
    """í¸ì˜ í•¨ìˆ˜ - ìºì‹œëœ ë°°ì¹˜ GET"""
    cache = get_redis_cache()
    return await cache.batch_get(keys)


async def cached_batch_set(key_values: dict[str, Any], ttl_seconds: int = 300) -> None:
    """í¸ì˜ í•¨ìˆ˜ - ìºì‹œëœ ë°°ì¹˜ SET"""
    cache = get_redis_cache()
    return await cache.batch_set(key_values, ttl_seconds)


def get_cache_stats() -> dict[str, Any]:
    """í¸ì˜ í•¨ìˆ˜ - ìºì‹œ í†µê³„ ì¡°íšŒ"""
    cache = get_redis_cache()
    return cache.get_stats()


# ìºì‹œ í‚¤ ìƒì„± í—¬í¼
def make_cache_key(prefix: str, *args: Any, **kwargs: Any) -> str:
    """í‘œì¤€í™”ëœ ìºì‹œ í‚¤ ìƒì„±"""
    key_data = f"{prefix}:{args}:{sorted(kwargs.items())}"
    return hashlib.md5(key_data.encode(), usedforsecurity=False).hexdigest()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    async def test_compute(x: int) -> int:
        await asyncio.sleep(0.1)  # ê³„ì‚° ì‹œë®¬ë ˆì´ì…˜
        return x * 2

    async def main() -> None:
        print("ğŸ§ª Redis ìµœì í™” ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        # ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (Redis ì—°ê²° ì—†ì´ í…ŒìŠ¤íŠ¸)
        OptimizedRedisCache()

        # GET-OR-COMPUTE í…ŒìŠ¤íŠ¸
        print("ğŸ“Š GET-OR-COMPUTE í…ŒìŠ¤íŠ¸...")
        result1 = await cached_get_or_compute("test:1", test_compute, 60, 5)
        result2 = await cached_get_or_compute("test:1", test_compute, 60, 5)  # ìºì‹œ íˆíŠ¸

        print(f"âœ… ê²°ê³¼ 1: {result1}")
        print(f"âœ… ê²°ê³¼ 2 (ìºì‹œ): {result2}")

        # í†µê³„ ì¶œë ¥
        stats = get_cache_stats()
        print(f"ğŸ“ˆ ìºì‹œ í†µê³„: {stats}")

        print("ğŸ‰ Redis ìµœì í™” ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    asyncio.run(main())
