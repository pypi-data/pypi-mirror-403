#!/usr/bin/env python3
"""
Phase 038: ê¹Šì´ ìˆëŠ” ì™„ì„±ë„ - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
Trinity Score ç¾(Beauty) +0.3% ë‹¬ì„±ì„ ìœ„í•œ ì„±ëŠ¥ ìµœì í™”

ê¸°ëŠ¥:
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- ìºì‹œ ì„±ëŠ¥ ë¶„ì„
- API ì‘ë‹µ ì‹œê°„ ëª¨ë‹ˆí„°ë§
- ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™” ì œì•ˆ
"""

import asyncio
import logging
import tempfile
import time
from datetime import UTC, datetime
from typing import Any

import psutil
import redis

# Logger ì •ì˜
logger = logging.getLogger("AFO.PerformanceMonitor")

# ì™•êµ­ ë‚´ë¶€ ëª¨ë“ˆ
try:
    from AFO.config.settings import get_settings
except ImportError:
    logger.warning("AFO modules not found. Using mocks for development.")

    class Settings:
        REDIS_HOST = "localhost"
        REDIS_PORT = 6379
        PROJECT_ROOT = tempfile.gettempdir()
        PERFORMANCE_MONITOR_INTERVAL = 60

    def get_settings() -> None:
        return Settings()

    def calculate_trinity_score() -> None:
        return 85.0


settings = get_settings()


class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""

    def __init__(self) -> None:
        self.start_time = time.time()
        self.api_response_times: list[float] = []
        self.cache_hit_rates: list[float] = []
        self.database_query_times: list[float] = []
        self.memory_usage: list[float] = []
        self.cpu_usage: list[float] = []

    def record_api_response(self, response_time: float) -> None:
        """API ì‘ë‹µ ì‹œê°„ ê¸°ë¡"""
        self.api_response_times.append(response_time)
        # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
        if len(self.api_response_times) > 100:
            self.api_response_times = self.api_response_times[-100:]

    def record_cache_hit_rate(self, hit_rate: float) -> None:
        """ìºì‹œ íˆíŠ¸ìœ¨ ê¸°ë¡"""
        self.cache_hit_rates.append(hit_rate)
        if len(self.cache_hit_rates) > 50:
            self.cache_hit_rates = self.cache_hit_rates[-50:]

    def get_average_response_time(self) -> float:
        """í‰ê·  API ì‘ë‹µ ì‹œê°„ ê³„ì‚°"""
        return (
            sum(self.api_response_times) / len(self.api_response_times)
            if self.api_response_times
            else 0.0
        )

    def get_average_cache_hit_rate(self) -> float:
        """í‰ê·  ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°"""
        return (
            sum(self.cache_hit_rates) / len(self.cache_hit_rates) if self.cache_hit_rates else 0.0
        )

    def get_system_metrics(self) -> dict[str, Any]:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            return {
                "cpu_percent": psutil.cpu_percent(interval=1),
                "memory_percent": psutil.virtual_memory().percent,
                "disk_usage": psutil.disk_usage("/").percent,
                "timestamp": datetime.now(UTC).isoformat(),
            }
        except Exception as e:
            logger.error(f"Failed to collect system metrics: {e}")
            return {"error": str(e)}


class CacheOptimizer:
    """ìºì‹œ ìµœì í™” ì—”ì§„"""

    def __init__(self) -> None:
        try:
            self.redis = redis.Redis(
                host=settings.REDIS_HOST, port=settings.REDIS_PORT, db=0, decode_responses=True
            )
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            self.redis.ping()
            logger.info("âœ… Redis ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.warning(f"âš ï¸ Redis ì—°ê²° ì‹¤íŒ¨: {e}. ìºì‹œ ìµœì í™” ë¹„í™œì„±í™”")
            self.redis = None

    def analyze_cache_performance(self) -> dict[str, Any]:
        """ìºì‹œ ì„±ëŠ¥ ë¶„ì„"""
        if not self.redis:
            return {"error": "Redis not available"}

        try:
            # Redis INFO ëª…ë ¹ìœ¼ë¡œ ìºì‹œ í†µê³„ ìˆ˜ì§‘
            info = self.redis.info()

            total_keys = info.get("db0", {}).get("keys", 0)
            expired_keys = info.get("expired_keys", 0)
            evicted_keys = info.get("evicted_keys", 0)

            # ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚° (ì˜ˆìƒ)
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë³„ë„ ì¹´ìš´í„°ê°€ í•„ìš”
            hit_rate = 0.85  # Mock value - ì‹¤ì œë¡œëŠ” ë³„ë„ ë©”íŠ¸ë¦­ í•„ìš”

            return {
                "total_keys": total_keys,
                "expired_keys": expired_keys,
                "evicted_keys": evicted_keys,
                "hit_rate": hit_rate,
                "memory_usage": info.get("used_memory_human", "0"),
                "recommendations": self._generate_cache_recommendations(hit_rate, total_keys),
            }

        except Exception as e:
            logger.error(f"Cache performance analysis failed: {e}")
            return {"error": str(e)}

    def _generate_cache_recommendations(self, hit_rate: float, total_keys: int) -> list[str]:
        """ìºì‹œ ìµœì í™” ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []

        if hit_rate < 0.8:
            recommendations.append("ìºì‹œ íˆíŠ¸ìœ¨ì´ ë‚®ìŒ - TTL ì •ì±… ì¬ê²€í†  í•„ìš”")
        if total_keys > 10000:
            recommendations.append("í‚¤ ê°œìˆ˜ê°€ ë§ìŒ - ì •ë¦¬ ë° ìµœì í™” í•„ìš”")
        if hit_rate > 0.95:
            recommendations.append("ìºì‹œ ì„±ëŠ¥ ìš°ìˆ˜ - í˜„ì¬ ìµœì  ìƒíƒœ")

        return recommendations

    def optimize_cache_ttl(self, key_pattern: str, new_ttl: int) -> dict[str, Any]:
        """ìºì‹œ TTL ìµœì í™”"""
        if not self.redis:
            return {"error": "Redis not available"}

        try:
            # íŠ¹ì • íŒ¨í„´ì˜ í‚¤ë“¤ì„ ì°¾ì•„ TTL ì¬ì„¤ì •
            keys = self.redis.keys(key_pattern)
            optimized_count = 0

            for key in keys:
                current_ttl = self.redis.ttl(key)
                if current_ttl > 0 and current_ttl > new_ttl:
                    self.redis.expire(key, new_ttl)
                    optimized_count += 1

            return {
                "pattern": key_pattern,
                "keys_found": len(keys),
                "optimized_count": optimized_count,
                "new_ttl": new_ttl,
            }

        except Exception as e:
            logger.error(f"Cache TTL optimization failed: {e}")
            return {"error": str(e)}


class PerformanceMonitor:
    """Phase 038 ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì½”ì–´"""

    def __init__(self) -> None:
        self.metrics = PerformanceMetrics()
        self.cache_optimizer = CacheOptimizer()
        self.monitoring_active = False

    async def start_performance_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        logger.info("ğŸš€ Starting Phase 038 Performance Monitoring")

        self.monitoring_active = True

        while self.monitoring_active:
            try:
                # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                await self._collect_performance_metrics()

                # ìºì‹œ ì„±ëŠ¥ ë¶„ì„
                cache_analysis = self.cache_optimizer.analyze_cache_performance()

                # ìµœì í™” ì œì•ˆ ìƒì„±
                recommendations = self._generate_performance_recommendations(cache_analysis)

                # ê²°ê³¼ ë¡œê¹…
                self._log_performance_report(cache_analysis, recommendations)

                # ëª¨ë‹ˆí„°ë§ ê°„ê²© ëŒ€ê¸°
                await asyncio.sleep(settings.PERFORMANCE_MONITOR_INTERVAL)

            except Exception as e:
                logger.error(f"ğŸ’¥ Performance monitoring error: {e}")
                await asyncio.sleep(60)  # ì—ëŸ¬ ì‹œ 1ë¶„ ëŒ€ê¸°

    async def _collect_performance_metrics(self):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            system_metrics = self.metrics.get_system_metrics()

            # ë©”ëª¨ë¦¬ì— ì €ì¥ (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ íŒŒì¼ì— ì €ì¥)
            self.metrics.memory_usage.append(system_metrics.get("memory_percent", 0))
            self.metrics.cpu_usage.append(system_metrics.get("cpu_percent", 0))

            # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
            if len(self.metrics.memory_usage) > 100:
                self.metrics.memory_usage = self.metrics.memory_usage[-100:]
            if len(self.metrics.cpu_usage) > 100:
                self.metrics.cpu_usage = self.metrics.cpu_usage[-100:]

        except Exception as e:
            logger.error(f"Failed to collect performance metrics: {e}")

    def _generate_performance_recommendations(self, cache_analysis: dict[str, Any]) -> list[str]:
        """ì„±ëŠ¥ ìµœì í™” ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []

        # ìºì‹œ ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œ
        hit_rate = cache_analysis.get("hit_rate", 0)
        if hit_rate < 0.8:
            recommendations.append("ìºì‹œ íˆíŠ¸ìœ¨ ê°œì„ : TTL ì •ì±… ì¡°ì • ë˜ëŠ” ìºì‹œ í¬ê¸° ì¦ê°€")
        elif hit_rate > 0.95:
            recommendations.append("ìºì‹œ ì„±ëŠ¥ ìš°ìˆ˜: í˜„ì¬ ìµœì  ìƒíƒœ ìœ ì§€")

        # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ê¸°ë°˜ ì¶”ì²œ
        avg_memory = (
            sum(self.metrics.memory_usage[-10:]) / len(self.metrics.memory_usage[-10:])
            if self.metrics.memory_usage
            else 0
        )
        avg_cpu = (
            sum(self.metrics.cpu_usage[-10:]) / len(self.metrics.cpu_usage[-10:])
            if self.metrics.cpu_usage
            else 0
        )

        if avg_memory > 80:
            recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: ë©”ëª¨ë¦¬ ìµœì í™” ë˜ëŠ” ë¦¬ì†ŒìŠ¤ í™•ì¥ ê³ ë ¤")
        if avg_cpu > 70:
            recommendations.append("CPU ì‚¬ìš©ë¥  ë†’ìŒ: í”„ë¡œì„¸ìŠ¤ ìµœì í™” ë˜ëŠ” CPU ë¦¬ì†ŒìŠ¤ í™•ì¥ ê³ ë ¤")

        # API ì‘ë‹µ ì‹œê°„ ê¸°ë°˜ ì¶”ì²œ
        avg_response_time = self.metrics.get_average_response_time()
        if avg_response_time > 200:  # 200ms ì´ìƒ
            recommendations.append("API ì‘ë‹µ ì‹œê°„ ê°œì„  í•„ìš”: ìºì‹± ê°•í™” ë˜ëŠ” ì¿¼ë¦¬ ìµœì í™”")

        return recommendations

    def _log_performance_report(
        self, cache_analysis: dict[str, Any], recommendations: list[str]
    ) -> None:
        """ì„±ëŠ¥ ë³´ê³ ì„œ ë¡œê¹…"""
        try:
            report = {
                "timestamp": datetime.now(UTC).isoformat(),
                "cache_analysis": cache_analysis,
                "system_metrics": {
                    "avg_memory_usage": sum(self.metrics.memory_usage[-10:])
                    / len(self.metrics.memory_usage[-10:])
                    if self.metrics.memory_usage
                    else 0,
                    "avg_cpu_usage": sum(self.metrics.cpu_usage[-10:])
                    / len(self.metrics.cpu_usage[-10:])
                    if self.metrics.cpu_usage
                    else 0,
                    "avg_api_response_time": self.metrics.get_average_response_time(),
                    "avg_cache_hit_rate": self.metrics.get_average_cache_hit_rate(),
                },
                "recommendations": recommendations,
            }

            logger.info(
                f"ğŸ“Š Performance Report: CPU={report['system_metrics']['avg_cpu_usage']:.1f}%, "
                f"Memory={report['system_metrics']['avg_memory_usage']:.1f}%, "
                f"API={report['system_metrics']['avg_api_response_time']:.0f}ms"
            )

            if recommendations:
                logger.info(f"ğŸ’¡ Recommendations: {len(recommendations)}ê°œ")
                for rec in recommendations:
                    logger.info(f"   - {rec}")

        except Exception as e:
            logger.error(f"Failed to log performance report: {e}")

    def stop_monitoring(self) -> None:
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        logger.info("ğŸ›‘ Stopping Performance Monitoring")
        self.monitoring_active = False

    def get_performance_report(self) -> dict[str, Any]:
        """í˜„ì¬ ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±"""
        return {
            "cache_analysis": self.cache_optimizer.analyze_cache_performance(),
            "system_metrics": self.metrics.get_system_metrics(),
            "avg_api_response_time": self.metrics.get_average_response_time(),
            "avg_cache_hit_rate": self.metrics.get_average_cache_hit_rate(),
            "generated_at": datetime.now(UTC).isoformat(),
        }


# CLI ì¸í„°í˜ì´ìŠ¤
async def main():
    """CLI ì§„ì…ì """
    import argparse

    parser = argparse.ArgumentParser(description="Phase 038 - Performance Monitor")
    parser.add_argument("--start", action="store_true", help="ì§€ì†ì  ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    parser.add_argument("--report", action="store_true", help="í˜„ì¬ ì„±ëŠ¥ ë³´ê³ ì„œ ì¶œë ¥")
    parser.add_argument("--optimize-cache", action="store_true", help="ìºì‹œ ìµœì í™” ì‹¤í–‰")
    parser.add_argument("--interval", type=int, default=60, help="ëª¨ë‹ˆí„°ë§ ê°„ê²© (ì´ˆ)")

    args = parser.parse_args()

    monitor = PerformanceMonitor()

    if args.start:
        try:
            await monitor.start_performance_monitoring()
        except KeyboardInterrupt:
            monitor.stop_monitoring()
            print("\nMonitoring stopped by user")

    elif args.report:
        report = monitor.get_performance_report()
        print("=== Phase 038 Performance Report ===")
        print(f"Cache Hit Rate: {report.get('avg_cache_hit_rate', 0):.1f}%")
        print(f"API Response Time: {report.get('avg_api_response_time', 0):.0f}ms")
        print(f"Generated: {report.get('generated_at', 'N/A')}")

    elif args.optimize_cache:
        optimizer = CacheOptimizer()
        result = optimizer.optimize_cache_ttl("cache:*", 1800)  # 30ë¶„ TTL
        print(f"Cache optimization result: {result}")

    else:
        parser.print_help()


if __name__ == "__main__":
    asyncio.run(main())
