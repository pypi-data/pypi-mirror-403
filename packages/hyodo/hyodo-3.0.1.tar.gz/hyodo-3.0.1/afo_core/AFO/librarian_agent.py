"""
ğŸ¯ AFO Kingdom Librarian Agent (Phase 80)
ë¬¸ì„œ ì¡°ì‚¬ ë° ì§€ì‹ í†µí•© íŠ¹í™” ì—ì´ì „íŠ¸

ì‘ì„±ì: ìŠ¹ìƒ (Chancellor)
ë‚ ì§œ: 2026-01-22

ì—­í• : Multi-repo ë¶„ì„, ë¬¸ì„œ ê²€ìƒ‰, êµ¬í˜„ ì˜ˆì œ ì œê³µ
ëª¨ë¸: Gemini 3 Flash (Antigravity auth ì‹œ) ë˜ëŠ” Claude Sonnet 4.5
"""

import asyncio
import logging
import time
from dataclasses import dataclass
from typing import Any

from AFO.background_agents import BackgroundAgent

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class KnowledgeEntry:
    """ì§€ì‹ í•­ëª© ë°ì´í„° í´ë˜ìŠ¤"""

    id: str
    source: str  # 'github', 'documentation', 'web', 'local'
    category: str  # 'implementation', 'architecture', 'best_practice', 'example'
    title: str
    content: str
    url: str | None = None
    tags: list[str] = None
    confidence_score: float = 0.0
    last_updated: float = None
    references: list[str] = None

    def __post_init__(self):
        if self.tags is None:
            self.tags = []
        if self.last_updated is None:
            self.last_updated = time.time()
        if self.references is None:
            self.references = []


class LibrarianAgent(BackgroundAgent):
    """
    Librarian Agent: ë¬¸ì„œ ì¡°ì‚¬ ë° ì§€ì‹ í†µí•© íŠ¹í™” ì—ì´ì „íŠ¸

    ì—­í• :
    - Multi-repo ë¶„ì„ ë° ë¬¸ì„œ ê²€ìƒ‰
    - ê´€ë ¨ êµ¬í˜„ ì˜ˆì œ ìë™ ê²€ìƒ‰
    - ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶• ë° ìœ ì§€
    - í¬ë¡œìŠ¤-ë ˆí¼ëŸ°ìŠ¤ ìƒì„±
    """

    def __init__(self):
        super().__init__("librarian", "Librarian Agent")
        self.knowledge_base: dict[str, KnowledgeEntry] = {}
        self.search_cache: dict[str, list[dict[str, Any]]] = {}
        self.repo_index: dict[str, dict[str, Any]] = {}
        self.confidence_threshold = 0.7

        # Antigravity auth í™•ì¸ (Gemini 3 Flash ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€)
        self.has_antigravity_auth = self._check_antigravity_auth()

        # ëª¨ë¸ ì„ íƒ
        self.preferred_model = (
            "gemini-3-flash" if self.has_antigravity_auth else "claude-sonnet-4.5"
        )

        logger.info(f"Librarian Agent initialized with model: {self.preferred_model}")

    def _check_antigravity_auth(self) -> bool:
        """Antigravity ì¸ì¦ ìƒíƒœ í™•ì¸"""
        # ì‹¤ì œë¡œëŠ” í™˜ê²½ ë³€ìˆ˜ë‚˜ ì„¤ì • íŒŒì¼ì—ì„œ í™•ì¸
        # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜
        return False  # ê°œë°œ ë‹¨ê³„ì—ì„œëŠ” Claude ì‚¬ìš©

    async def execute_cycle(self) -> None:
        """
        Librarian Agentì˜ ì£¼ìš” ì‹¤í–‰ ë¡œì§

        ìˆ˜í–‰ ì‘ì—…:
        1. ì§€ì‹ ë² ì´ìŠ¤ ìœ ì§€ë³´ìˆ˜ (ì˜¤ë˜ëœ í•­ëª© ì—…ë°ì´íŠ¸)
        2. ìƒˆë¡œìš´ ê´€ë ¨ ë¬¸ì„œ/ì˜ˆì œ ê²€ìƒ‰
        3. í¬ë¡œìŠ¤-ë ˆí¼ëŸ°ìŠ¤ ì—…ë°ì´íŠ¸
        4. ì§€ì‹ ë² ì´ìŠ¤ ìµœì í™”
        """

        try:
            # 1. ì˜¤ë˜ëœ ì§€ì‹ ì—…ë°ì´íŠ¸
            await self._update_stale_knowledge()

            # 2. ìƒˆë¡œìš´ ê´€ë ¨ ì½˜í…ì¸  ê²€ìƒ‰
            await self._discover_new_content()

            # 3. í¬ë¡œìŠ¤-ë ˆí¼ëŸ°ìŠ¤ ìƒì„±
            await self._generate_cross_references()

            # 4. ì§€ì‹ ë² ì´ìŠ¤ ì •ë¦¬
            await self._optimize_knowledge_base()

            logger.info(
                f"Librarian cycle completed. Knowledge base size: {len(self.knowledge_base)}"
            )

        except Exception as e:
            logger.error(f"Librarian cycle error: {e}")
            self.status.error_count += 1

    async def _update_stale_knowledge(self) -> None:
        """ì˜¤ë˜ëœ ì§€ì‹ í•­ëª© ì—…ë°ì´íŠ¸"""
        current_time = time.time()
        stale_threshold = 7 * 24 * 60 * 60  # 7ì¼

        stale_entries = [
            entry_id
            for entry_id, entry in self.knowledge_base.items()
            if current_time - entry.last_updated > stale_threshold
        ]

        for entry_id in stale_entries[:5]:  # ìµœëŒ€ 5ê°œì”© ì—…ë°ì´íŠ¸
            try:
                await self._refresh_knowledge_entry(entry_id)
            except Exception as e:
                logger.warning(f"Failed to refresh knowledge entry {entry_id}: {e}")

        if stale_entries:
            logger.info(f"Updated {min(5, len(stale_entries))} stale knowledge entries")

    async def _refresh_knowledge_entry(self, entry_id: str) -> None:
        """íŠ¹ì • ì§€ì‹ í•­ëª© ìƒˆë¡œê³ ì¹¨"""
        entry = self.knowledge_base[entry_id]

        if entry.source == "github":
            # GitHub ì €ì¥ì†Œ ì—…ë°ì´íŠ¸ í™•ì¸
            await self._check_repo_updates(entry.url)
        elif entry.source == "web":
            # ì›¹ ë¬¸ì„œ ì—…ë°ì´íŠ¸ í™•ì¸
            await self._check_web_content_updates(entry.url)

        entry.last_updated = time.time()

    async def _discover_new_content(self) -> None:
        """ìƒˆë¡œìš´ ê´€ë ¨ ì½˜í…ì¸  ê²€ìƒ‰"""
        # í˜„ì¬ í”„ë¡œì íŠ¸ì™€ ê´€ë ¨ëœ ì£¼ì œë“¤
        topics = [
            "python async patterns",
            "fastapi best practices",
            "ai agent orchestration",
            "trinity score implementation",
            "background agent patterns",
        ]

        for topic in topics:
            try:
                # ê²€ìƒ‰ ìºì‹œ í™•ì¸
                if topic in self.search_cache:
                    cache_time = self.search_cache[topic].get("timestamp", 0)
                    if time.time() - cache_time < 24 * 60 * 60:  # 24ì‹œê°„ ìºì‹œ
                        continue

                # ìƒˆë¡œìš´ ì½˜í…ì¸  ê²€ìƒ‰
                new_entries = await self._search_topic_content(topic)

                # ìœ ë§í•œ í•­ëª©ë“¤ ì¶”ê°€
                for entry_data in new_entries[:3]:  # í† í”½ë‹¹ ìµœëŒ€ 3ê°œ
                    await self._add_knowledge_entry(entry_data)

                # ìºì‹œ ì—…ë°ì´íŠ¸
                self.search_cache[topic] = {"timestamp": time.time(), "results": new_entries}

            except Exception as e:
                logger.warning(f"Failed to discover content for topic '{topic}': {e}")

    async def _search_topic_content(self, topic: str) -> list[dict[str, Any]]:
        """íŠ¹ì • í† í”½ì— ëŒ€í•œ ì½˜í…ì¸  ê²€ìƒ‰"""
        # ì‹¤ì œë¡œëŠ” brave_web_search, github_search ë“±ì˜ ë„êµ¬ í™œìš©
        # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜

        simulated_results = [
            {
                "source": "github",
                "category": "implementation",
                "title": f"{topic} - Example Implementation",
                "content": f"Implementation example for {topic} with best practices",
                "url": f"https://github.com/example/{topic.replace(' ', '-')}",
                "tags": [topic.split()[0], "example"],
                "confidence_score": 0.85,
            },
            {
                "source": "documentation",
                "category": "best_practice",
                "title": f"{topic} - Best Practices Guide",
                "content": f"Comprehensive guide for {topic} implementation",
                "url": f"https://docs.example.com/{topic.replace(' ', '-')}",
                "tags": [topic.split()[0], "guide", "best-practice"],
                "confidence_score": 0.92,
            },
        ]

        return simulated_results

    async def _generate_cross_references(self) -> None:
        """í¬ë¡œìŠ¤-ë ˆí¼ëŸ°ìŠ¤ ìƒì„±"""
        # ìœ ì‚¬í•œ í•­ëª©ë“¤ ê°„ì˜ ì—°ê²° ìƒì„±
        entries = list(self.knowledge_base.values())

        for i, entry_a in enumerate(entries):
            for entry_b in entries[i + 1 :]:
                if self._are_related(entry_a, entry_b):
                    # ìƒí˜¸ ì°¸ì¡° ì¶”ê°€
                    if entry_b.id not in entry_a.references:
                        entry_a.references.append(entry_b.id)
                    if entry_a.id not in entry_b.references:
                        entry_b.references.append(entry_a.id)

        logger.info("Cross-references generated between related knowledge entries")

    def _are_related(self, entry_a: KnowledgeEntry, entry_b: KnowledgeEntry) -> bool:
        """ë‘ ì§€ì‹ í•­ëª©ì´ ê´€ë ¨ ìˆëŠ”ì§€ íŒë‹¨"""
        # íƒœê·¸ ê¸°ë°˜ ìœ ì‚¬ì„± ê³„ì‚°
        common_tags = set(entry_a.tags) & set(entry_b.tags)
        if len(common_tags) > 0:
            return True

        # ì œëª© ìœ ì‚¬ì„± (ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­)
        title_words_a = set(entry_a.title.lower().split())
        title_words_b = set(entry_b.title.lower().split())
        common_words = title_words_a & title_words_b
        return len(common_words) >= 2  # 2ê°œ ì´ìƒ ê³µí†µ ë‹¨ì–´

    async def _optimize_knowledge_base(self) -> None:
        """ì§€ì‹ ë² ì´ìŠ¤ ìµœì í™”"""
        # ë‚®ì€ ì‹ ë¢°ë„ í•­ëª© ì •ë¦¬
        low_confidence = [
            entry_id
            for entry_id, entry in self.knowledge_base.items()
            if entry.confidence_score < 0.5
        ]

        for entry_id in low_confidence:
            del self.knowledge_base[entry_id]

        # ì¤‘ë³µ í•­ëª© ë³‘í•©
        await self._merge_duplicate_entries()

        # ìºì‹œ ì •ë¦¬
        old_cache_keys = [
            key
            for key, data in self.search_cache.items()
            if time.time() - data.get("timestamp", 0) > 7 * 24 * 60 * 60  # 7ì¼
        ]

        for key in old_cache_keys:
            del self.search_cache[key]

    async def _merge_duplicate_entries(self) -> None:
        """ì¤‘ë³µ í•­ëª© ë³‘í•©"""
        # ê°„ë‹¨í•œ ì¤‘ë³µ ê°ì§€ ë° ë³‘í•© ë¡œì§
        # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì•Œê³ ë¦¬ì¦˜ í•„ìš”
        pass

    async def _add_knowledge_entry(self, entry_data: dict[str, Any]) -> None:
        """ìƒˆë¡œìš´ ì§€ì‹ í•­ëª© ì¶”ê°€"""
        entry_id = f"{entry_data['source']}_{hash(entry_data['title'])}"

        if entry_id in self.knowledge_base:
            # ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸
            existing = self.knowledge_base[entry_id]
            existing.content = entry_data["content"]
            existing.confidence_score = entry_data["confidence_score"]
            existing.last_updated = time.time()
        else:
            # ìƒˆ í•­ëª© ìƒì„±
            entry = KnowledgeEntry(
                id=entry_id,
                source=entry_data["source"],
                category=entry_data["category"],
                title=entry_data["title"],
                content=entry_data["content"],
                url=entry_data.get("url"),
                tags=entry_data.get("tags", []),
                confidence_score=entry_data.get("confidence_score", 0.5),
            )
            self.knowledge_base[entry_id] = entry

    async def get_metrics(self) -> dict[str, Any]:
        """Librarian Agent ë©”íŠ¸ë¦­ ë°˜í™˜"""
        total_entries = len(self.knowledge_base)
        avg_confidence = (
            sum(entry.confidence_score for entry in self.knowledge_base.values()) / total_entries
            if total_entries > 0
            else 0
        )

        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
        category_counts = {}
        for entry in self.knowledge_base.values():
            category_counts[entry.category] = category_counts.get(entry.category, 0) + 1

        # ì†ŒìŠ¤ë³„ ë¶„í¬
        source_counts = {}
        for entry in self.knowledge_base.values():
            source_counts[entry.source] = source_counts.get(entry.source, 0) + 1

        return {
            "agent_type": "librarian",
            "knowledge_base_size": total_entries,
            "avg_confidence_score": avg_confidence,
            "cache_size": len(self.search_cache),
            "category_distribution": category_counts,
            "source_distribution": source_counts,
            "preferred_model": self.preferred_model,
            "antigravity_auth": self.has_antigravity_auth,
        }

    # Public API methods

    async def search_knowledge(
        self, query: str, category: str | None = None, min_confidence: float = 0.0
    ) -> list[KnowledgeEntry]:
        """
        ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            category: íŠ¹ì • ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§
            min_confidence: ìµœì†Œ ì‹ ë¢°ë„ ì ìˆ˜

        Returns:
            ê´€ë ¨ ì§€ì‹ í•­ëª© ë¦¬ìŠ¤íŠ¸
        """
        query_lower = query.lower()
        results = []

        for entry in self.knowledge_base.values():
            if entry.confidence_score < min_confidence:
                continue
            if category and entry.category != category:
                continue
            if (
                query_lower in entry.title.lower()
                or query_lower in entry.content.lower()
                or any(query_lower in tag for tag in entry.tags)
            ):
                results.append(entry)

        # ê´€ë ¨ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (ë‹¨ìˆœ êµ¬í˜„)
        results.sort(key=lambda x: x.confidence_score, reverse=True)
        return results[:10]  # ìµœëŒ€ 10ê°œ ë°˜í™˜

    async def get_implementation_examples(
        self, technology: str, pattern: str
    ) -> list[KnowledgeEntry]:
        """
        íŠ¹ì • ê¸°ìˆ /íŒ¨í„´ì— ëŒ€í•œ êµ¬í˜„ ì˜ˆì œ ê²€ìƒ‰

        Args:
            technology: ê¸°ìˆ ëª… (ì˜ˆ: "fastapi", "asyncio")
            pattern: íŒ¨í„´ (ì˜ˆ: "dependency_injection", "middleware")

        Returns:
            êµ¬í˜„ ì˜ˆì œ ë¦¬ìŠ¤íŠ¸
        """
        query = f"{technology} {pattern} implementation example"
        return await self.search_knowledge(query, category="implementation", min_confidence=0.8)

    async def analyze_repository(self, repo_url: str) -> dict[str, Any]:
        """
        GitHub ì €ì¥ì†Œ ë¶„ì„

        Args:
            repo_url: ì €ì¥ì†Œ URL

        Returns:
            ë¶„ì„ ê²°ê³¼
        """
        # ì‹¤ì œë¡œëŠ” git clone + ë¶„ì„ ìˆ˜í–‰
        # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜

        return {
            "repo_url": repo_url,
            "technologies": ["python", "fastapi", "asyncio"],
            "patterns": ["dependency_injection", "async_patterns"],
            "complexity_score": 7.5,
            "documentation_quality": 8.2,
        }

    async def find_best_practices(self, domain: str) -> list[KnowledgeEntry]:
        """
        íŠ¹ì • ë„ë©”ì¸ì˜ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ê²€ìƒ‰

        Args:
            domain: ë„ë©”ì¸ (ì˜ˆ: "api_design", "error_handling")

        Returns:
            ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ í•­ëª© ë¦¬ìŠ¤íŠ¸
        """
        return await self.search_knowledge(domain, category="best_practice", min_confidence=0.85)


# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
librarian_agent = LibrarianAgent()


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
async def search_knowledge_base(query: str) -> list[KnowledgeEntry]:
    """ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰ ìœ í‹¸ë¦¬í‹°"""
    return await librarian_agent.search_knowledge(query)


async def get_implementation_examples(tech: str, pattern: str) -> list[KnowledgeEntry]:
    """êµ¬í˜„ ì˜ˆì œ ê²€ìƒ‰ ìœ í‹¸ë¦¬í‹°"""
    return await librarian_agent.get_implementation_examples(tech, pattern)


async def analyze_codebase(repo_url: str) -> dict[str, Any]:
    """ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ ìœ í‹¸ë¦¬í‹°"""
    return await librarian_agent.analyze_repository(repo_url)


if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ ë°ëª¨
    async def demo():
        print("ğŸ¯ Librarian Agent Phase 80 ë°ëª¨")
        print("=" * 50)

        # ì´ˆê¸°í™”
        agent = LibrarianAgent()

        # ëª‡ ê°œì˜ ì§€ì‹ í•­ëª© ì¶”ê°€
        sample_entries = [
            {
                "source": "github",
                "category": "implementation",
                "title": "FastAPI Async Patterns",
                "content": "Best practices for async patterns in FastAPI applications",
                "url": "https://github.com/example/fastapi-async",
                "tags": ["fastapi", "async", "python"],
                "confidence_score": 0.9,
            },
            {
                "source": "documentation",
                "category": "best_practice",
                "title": "AI Agent Orchestration Patterns",
                "content": "Comprehensive guide to orchestrating multiple AI agents",
                "url": "https://docs.example.com/ai-orchestration",
                "tags": ["ai", "agents", "orchestration"],
                "confidence_score": 0.95,
            },
        ]

        for entry_data in sample_entries:
            await agent._add_knowledge_entry(entry_data)

        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\nğŸ” ì§€ì‹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
        results = await agent.search_knowledge("async patterns")
        for result in results:
            print(f"  â€¢ {result.title} (ì‹ ë¢°ë„: {result.confidence_score:.2f})")

        # ë©”íŠ¸ë¦­ ì¶œë ¥
        metrics = await agent.get_metrics()
        print("\nğŸ“Š Librarian Agent ë©”íŠ¸ë¦­:")
        print(f"  â€¢ ì§€ì‹ ë² ì´ìŠ¤ í¬ê¸°: {metrics['knowledge_base_size']}")
        print(f"  â€¢ í‰ê·  ì‹ ë¢°ë„: {metrics['avg_confidence_score']:.2f}")
        print(f"  â€¢ ì„ í˜¸ ëª¨ë¸: {metrics['preferred_model']}")
        print(f"  â€¢ Antigravity ì¸ì¦: {metrics['antigravity_auth']}")

        print("\nâœ… Librarian Agent ë°ëª¨ ì™„ë£Œ!")

    asyncio.run(demo())
