# Trinity Score: 98.0 (Integrated Learning System - Complete Wisdom)
"""
í†µí•© í•™ìŠµ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ (Integrated Learning System)

ì˜µì‹œë””ì–¸ ì‚¬ì„œ + LangSmith ì„ ìƒì˜ ì™„ë²½í•œ í˜‘ë ¥ ì‹œìŠ¤í…œ
Context7 ê¸°ë°˜ ì™„ì „í•œ ì§€í”¼ì§€ê¸° ë° í•™ìŠµ ëª¨ë‹ˆí„°ë§ êµ¬í˜„

ì—­í• :
- ì˜µì‹œë””ì–¸ ì‚¬ì„œì™€ LangSmith ì„ ìƒì˜ í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (å­ - Serenity)
- Context7 ì§€ì‹ ë² ì´ìŠ¤ì™€ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì˜ ì™„ë²½í•œ ê²°í•© (çœå–„ç¾æ°¸ - Complete Trinity)
"""

import asyncio
import logging
import uuid
from typing import Any

from AFO.services.learning_types import (
    ComprehensiveAssessment,
    LearnerConfig,
    LearningAnalytics,
    LearningSessionResult,
    LearningStep,
    MonitoringResult,
    StepExecutionResult,
    SystemInitStatus,
    SystemStatusResponse,
)

logger = logging.getLogger(__name__)


class IntegratedLearningSystem:
    """í†µí•© í•™ìŠµ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ - ì˜µì‹œë””ì–¸ ì‚¬ì„œ + LangSmith ì„ ìƒ"""

    def __init__(self) -> None:
        self.obsidian_librarian = None
        self.langsmith_mentor = None
        self.context7_service = None
        self.active_sessions: dict[str, dict[str, Any]] = {}
        self.system_status = "initializing"

    async def initialize_system(self) -> SystemInitStatus:
        """í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ì˜µì‹œë””ì–¸ ì‚¬ì„œ ì´ˆê¸°í™”
            from AFO.services.obsidian_librarian import initialize_obsidian_librarian

            librarian_status = await initialize_obsidian_librarian()

            # LangSmith ì„ ìƒ ì´ˆê¸°í™”
            from AFO.services.langsmith_mentor import initialize_langsmith_mentor

            mentor_status = await initialize_langsmith_mentor()

            # Context7 ì„œë¹„ìŠ¤ ì—°ê²°
            from AFO.services.context7_service import get_context7_instance

            self.context7_service = get_context7_instance()

            # ì»´í¬ë„ŒíŠ¸ ì—°ê²°
            from AFO.services.obsidian_librarian import get_obsidian_librarian

            self.obsidian_librarian = await get_obsidian_librarian()

            from AFO.services.langsmith_mentor import get_langsmith_mentor

            self.langsmith_mentor = await get_langsmith_mentor()

            self.system_status = "active"

            system_status = {
                "status": "fully_integrated",
                "obsidian_librarian": librarian_status,
                "langsmith_mentor": mentor_status,
                "context7_connected": self.context7_service is not None,
                "integration_level": "complete",
            }

            logger.info("ğŸ‰ í†µí•© í•™ìŠµ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì™„ì „ ì´ˆê¸°í™” ì„±ê³µ!")
            logger.info(
                f"   ì˜µì‹œë””ì–¸ ì‚¬ì„œ: {'ì—°ê²°ë¨' if librarian_status.get('status') == 'initialized' else 'ì˜¤ë¥˜'}"
            )
            logger.info(
                f"   LangSmith ì„ ìƒ: {'ì—°ê²°ë¨' if mentor_status.get('status') == 'initialized' else 'ì˜¤ë¥˜'}"
            )
            logger.info(f"   Context7 ì§€ì‹ë² ì´ìŠ¤: {'ì—°ê²°ë¨' if self.context7_service else 'ì˜¤ë¥˜'}")

            return system_status

        except Exception as e:
            self.system_status = "failed"
            logger.error(f"í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return {"status": "failed", "error": str(e)}

    async def conduct_comprehensive_learning_session(
        self, topic: str, learner_config: LearnerConfig | None = None
    ) -> LearningSessionResult:
        """ì™„ì „í•œ í•™ìŠµ ì„¸ì…˜ ìˆ˜í–‰ - ì˜µì‹œë””ì–¸ ì‚¬ì„œ + LangSmith ì„ ìƒì˜ í˜‘ë ¥"""

        session_id = f"learning_session_{uuid.uuid4().hex[:8]}"
        start_time = asyncio.get_event_loop().time()

        try:
            # í•™ìŠµì ì„¤ì • ê¸°ë³¸ê°’
            learner_config = learner_config or {}
            learner_level = learner_config.get("level", "intermediate")
            _focus_areas = learner_config.get("focus_areas", ["truth", "goodness", "beauty"])

            logger.info(f"ğŸš€ í•™ìŠµ ì„¸ì…˜ ì‹œì‘: {topic} (ë ˆë²¨: {learner_level})")

            # === Phase 1: ì˜µì‹œë””ì–¸ ì‚¬ì„œ - í•™ìŠµ ìë£Œ ì¤€ë¹„ ===
            logger.info("ğŸ“š Phase 1: ì˜µì‹œë””ì–¸ ì‚¬ì„œ - í•™ìŠµ ìë£Œ ì¤€ë¹„")
            learning_path = await self.obsidian_librarian.generate_learning_path(
                topic, learner_level=learner_level
            )

            learning_materials = learning_path.get("learning_path", [])
            logger.info(f"   ì¤€ë¹„ëœ í•™ìŠµ ë‹¨ê³„: {len(learning_materials)}ê°œ")

            # === Phase 2: LangSmith ì„ ìƒ - ì‚¬ì „ ëª¨ë‹ˆí„°ë§ ===
            logger.info("ğŸ‘¨â€ğŸ« Phase 2: LangSmith ì„ ìƒ - ì‚¬ì „ ëª¨ë‹ˆí„°ë§")
            baseline_monitoring = await self.langsmith_mentor.monitor_execution(session_id)

            # === Phase 3: ë‹¨ê³„ë³„ í•™ìŠµ ì‹¤í–‰ ===
            logger.info("ğŸ¯ Phase 3: ë‹¨ê³„ë³„ í•™ìŠµ ì‹¤í–‰")

            execution_results = []
            step_monitoring = []

            for step_idx, step in enumerate(learning_materials):
                step_name = step.get("phase", f"Step {step_idx + 1}")
                logger.info(f"   {step_idx + 1}. {step_name} ì‹¤í–‰ ì¤‘...")

                # ê° ë‹¨ê³„ë³„ ì‹¤í–‰
                step_result = await self._execute_learning_step(step, topic, session_id, step_idx)
                execution_results.append(step_result)

                # ë‹¨ê³„ë³„ ëª¨ë‹ˆí„°ë§
                step_analysis = await self.langsmith_mentor.monitor_execution(
                    f"{session_id}_step_{step_idx}"
                )
                step_monitoring.append(step_analysis)

                # ë‹¨ê³„ ì„±ê³µë¥  í™•ì¸
                success_rate = step_analysis.get("performance_analysis", {}).get("success_rate", 0)
                if success_rate < 0.7:
                    logger.warning(f"   âš ï¸ {step_name} ë‚®ì€ ì„±ê³µë¥ : {success_rate:.1%}")
                else:
                    logger.info(f"   âœ… {step_name} ì„±ê³µ: {success_rate:.1%}")

            # === Phase 4: LangSmith ì„ ìƒ - ì¢…í•© ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„ ===
            logger.info("ğŸ“Š Phase 4: LangSmith ì„ ìƒ - ì¢…í•© ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„")
            final_analysis = await self.langsmith_mentor.monitor_execution(session_id)

            # === Phase 5: í•™ìŠµ ì„±ê³¼ ì¢…í•© í‰ê°€ ===
            logger.info("ğŸ† Phase 5: í•™ìŠµ ì„±ê³¼ ì¢…í•© í‰ê°€")
            comprehensive_assessment = self._assess_comprehensive_learning(
                baseline_monitoring,
                final_analysis,
                learning_materials,
                execution_results,
                step_monitoring,
            )

            # === Phase 6: ì˜µì‹œë””ì–¸ ì‚¬ì„œ - í•™ìŠµ ê²°ê³¼ ê¸°ë¡ ===
            logger.info("ğŸ“ Phase 6: ì˜µì‹œë””ì–¸ ì‚¬ì„œ - í•™ìŠµ ê²°ê³¼ ê¸°ë¡")
            _recording_result = await self.obsidian_librarian.record_learning_session(
                {
                    "topic": topic,
                    "trace_id": session_id,
                    "materials_used": learning_materials,
                    "execution_result": {
                        "success": comprehensive_assessment.get("overall_success", False),
                        "steps_completed": len(execution_results),
                        "avg_success_rate": comprehensive_assessment.get(
                            "avg_step_success_rate", 0
                        ),
                    },
                    "performance_analysis": final_analysis,
                    "assessment": comprehensive_assessment,
                }
            )

            # === Phase 7: ìµœì¢… ê²°ê³¼ ì •ë¦¬ ===
            end_time = asyncio.get_event_loop().time()
            session_duration = end_time - start_time

            final_result = {
                "session_id": session_id,
                "topic": topic,
                "learner_config": learner_config,
                "duration_seconds": session_duration,
                "learning_path": learning_path,
                "execution_results": execution_results,
                "baseline_monitoring": baseline_monitoring,
                "final_analysis": final_analysis,
                "comprehensive_assessment": comprehensive_assessment,
                "recommendations": final_analysis.get("recommendations", []),
                "next_learning_suggestions": self._generate_next_learning_suggestions(
                    comprehensive_assessment, topic, learner_level
                ),
            }

            # ì„¸ì…˜ ì €ì¥
            self.active_sessions[session_id] = {
                "topic": topic,
                "start_time": start_time,
                "end_time": end_time,
                "assessment": comprehensive_assessment,
                "final_result": final_result,
            }

            logger.info("ğŸŠ í•™ìŠµ ì„¸ì…˜ ì™„ë£Œ!")
            logger.info(f"   ì´ ì†Œìš”ì‹œê°„: {session_duration:.1f}ì´ˆ")
            logger.info(f"   ìµœì¢… ë“±ê¸‰: {comprehensive_assessment.get('overall_grade', 'N/A')}")
            logger.info(
                f"   Trinity Score ê°œì„ : {comprehensive_assessment.get('trinity_improvement', 0):.1f}ì "
            )

            return final_result

        except Exception as e:
            logger.error(f"í•™ìŠµ ì„¸ì…˜ ì‹¤íŒ¨: {e}")
            return {"error": f"í•™ìŠµ ì„¸ì…˜ ì‹¤íŒ¨: {e}", "session_id": session_id}

    async def _execute_learning_step(
        self, step: LearningStep, topic: str, session_id: str, step_idx: int
    ) -> StepExecutionResult:
        """ê°œë³„ í•™ìŠµ ë‹¨ê³„ ì‹¤í–‰"""
        try:
            step_name = step.get("phase", f"Step {step_idx + 1}")
            materials = step.get("materials", [])

            # Chancellor Graphë¥¼ í†µí•œ í•™ìŠµ ì‹¤í–‰
            from AFO.chancellor_graph import chancellor_graph

            step_prompt = f"""
í•™ìŠµ ë‹¨ê³„: {step_name}
ì£¼ì œ: {topic}
í•™ìŠµ ìë£Œ: {", ".join([m.get("title", "") for m in materials])}

ì´ í•™ìŠµ ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:
1. í•µì‹¬ ê°œë… ì´í•´
2. ì‹¤ì „ ì ìš© ì‚¬ë¡€ í•™ìŠµ
3. ê´€ë ¨ ëª¨ë²” ì‚¬ë¡€ í™•ì¸
"""

            step_result = await chancellor_graph.invoke(
                step_prompt,
                headers={
                    "x-afo-learning-session": "true",
                    "x-afo-learning-step": str(step_idx),
                    "x-afo-session-id": session_id,
                },
            )

            return {
                "step_index": step_idx,
                "step_name": step_name,
                "materials_count": len(materials),
                "execution_result": step_result,
                "success": step_result.get("success", False),
            }

        except Exception as e:
            logger.error(f"í•™ìŠµ ë‹¨ê³„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "step_index": step_idx,
                "step_name": step.get("phase", f"Step {step_idx + 1}"),
                "error": str(e),
                "success": False,
            }

    def _assess_comprehensive_learning(
        self,
        baseline: MonitoringResult,
        final: MonitoringResult,
        materials: list[LearningStep],
        executions: list[StepExecutionResult],
        step_monitoring: list[MonitoringResult],
    ) -> ComprehensiveAssessment:
        """ì¢…í•© í•™ìŠµ ì„±ê³¼ í‰ê°€"""

        # Trinity Score ê°œì„ ë„
        baseline_score = baseline.get("trinity_score", 0)
        final_score = final.get("trinity_score", 0)
        trinity_improvement = final_score - baseline_score

        # ë‹¨ê³„ë³„ ì„±ê³µë¥ 
        step_success_rates = [
            monitoring.get("performance_analysis", {}).get("success_rate", 0)
            for monitoring in step_monitoring
        ]
        avg_step_success_rate = (
            sum(step_success_rates) / len(step_success_rates) if step_success_rates else 0
        )

        # ìë£Œ í™œìš©ë„
        materials_used = sum(len(step.get("materials", [])) for step in materials)
        materials_effective = materials_used > 0

        # ì‹¤í–‰ ì„±ê³µë„
        execution_success = avg_step_success_rate > 0.7

        # ì¢…í•© ë“±ê¸‰ ê³„ì‚°
        overall_grade = self._calculate_overall_learning_grade(
            trinity_improvement,
            materials_effective,
            execution_success,
            avg_step_success_rate,
        )

        # í•™ìŠµ ê°•ì /ì•½ì  ë¶„ì„
        strengths, weaknesses = self._analyze_learning_profile(
            materials, executions, step_monitoring
        )

        return {
            "baseline_trinity_score": baseline_score,
            "final_trinity_score": final_score,
            "trinity_improvement": trinity_improvement,
            "avg_step_success_rate": avg_step_success_rate,
            "materials_effective": materials_effective,
            "execution_success": execution_success,
            "overall_success": execution_success and materials_effective,
            "overall_grade": overall_grade,
            "learning_strengths": strengths,
            "learning_weaknesses": weaknesses,
            "materials_utilization": materials_used,
            "steps_completed": len(executions),
            "assessment_timestamp": asyncio.get_event_loop().time(),
        }

    def _calculate_overall_learning_grade(
        self,
        trinity_improvement: float,
        materials_effective: bool,
        execution_success: bool,
        avg_success_rate: float,
    ) -> str:
        """ì¢…í•© í•™ìŠµ ë“±ê¸‰ ê³„ì‚°"""
        score = 0

        # Trinity Score ê°œì„ ë„ (40ì  ë§Œì )
        if trinity_improvement > 20:
            score += 40
        elif trinity_improvement > 15:
            score += 35
        elif trinity_improvement > 10:
            score += 25
        elif trinity_improvement > 5:
            score += 15
        elif trinity_improvement > 0:
            score += 5

        # ìë£Œ í™œìš©ë„ (20ì )
        if materials_effective:
            score += 20

        # ì‹¤í–‰ ì„±ê³µë„ (25ì )
        success_score = int(avg_success_rate * 25)
        score += success_score

        # ì¼ê´€ì„± ë³´ë„ˆìŠ¤ (15ì )
        if execution_success and materials_effective and trinity_improvement > 0:
            score += 15

        # ë“±ê¸‰ ê²°ì •
        if score >= 90:
            return "S (ì™„ë²½í•œ í•™ìŠµ ë§ˆìŠ¤í„°ë¦¬)"
        elif score >= 80:
            return "A+ (íƒì›”í•œ í•™ìŠµ ì„±ì·¨)"
        elif score >= 70:
            return "A (ìš°ìˆ˜í•œ í•™ìŠµ ì„±ì·¨)"
        elif score >= 60:
            return "B+ (ì–‘í˜¸í•œ í•™ìŠµ ì„±ì·¨)"
        elif score >= 50:
            return "B (ê¸°ì´ˆì ì¸ í•™ìŠµ ì„±ì·¨)"
        elif score >= 40:
            return "C (ì¶”ê°€ í•™ìŠµ í•„ìš”)"
        else:
            return "D (í•™ìŠµ ì¬ì‹œì‘ ê¶Œì¥)"

    def _analyze_learning_profile(
        self,
        materials: list[LearningStep],
        executions: list[StepExecutionResult],
        monitoring: list[MonitoringResult],
    ) -> tuple[list[str], list[str]]:
        """í•™ìŠµ í”„ë¡œí•„ ë¶„ì„ (ê°•ì /ì•½ì )"""
        strengths = []
        weaknesses = []

        # Trinity ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
        trinity_focus = {}
        for material_group in materials:
            for material in material_group.get("materials", []):
                category = material.get("trinity_category", "unknown")
                trinity_focus[category] = trinity_focus.get(category, 0) + 1

        # ê°€ì¥ ë§ì´ í•™ìŠµí•œ ì¹´í…Œê³ ë¦¬ = ê°•ì 
        if trinity_focus:
            top_category = max(trinity_focus.items(), key=lambda x: x[1])
            category_names = {
                "truth": "ê¸°ìˆ ì  í™•ì‹¤ì„± (çœ)",
                "goodness": "ì•ˆì •ì„±ê³¼ ì‹ ë¢°ì„± (å–„)",
                "beauty": "ì‚¬ìš©ì„± ë° ë””ìì¸ (ç¾)",
                "serenity": "ì¡°í™”ì™€ í”„ë¡œì„¸ìŠ¤ (å­)",
                "eternity": "ì§€ì†ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ (æ°¸)",
            }
            strengths.append(f"{category_names.get(top_category[0], top_category[0])} ë¶„ì•¼ ê°•ì ")

        # ì‹¤í–‰ ì„±ê³µë¥  ë¶„ì„
        success_rates = [
            m.get("performance_analysis", {}).get("success_rate", 0) for m in monitoring
        ]
        avg_success = sum(success_rates) / len(success_rates) if success_rates else 0

        if avg_success > 0.8:
            strengths.append("ë†’ì€ ì‹¤í–‰ ì„±ê³µë¥ ")
        elif avg_success < 0.6:
            weaknesses.append("ì‹¤í–‰ ì„±ê³µë¥  í–¥ìƒ í•„ìš”")

        # í•™ìŠµ ìë£Œ í™œìš©ë„
        total_materials = sum(len(step.get("materials", [])) for step in materials)
        if total_materials > 10:
            strengths.append("ê´‘ë²”ìœ„í•œ í•™ìŠµ ìë£Œ í™œìš©")
        elif total_materials < 3:
            weaknesses.append("ë” ë‹¤ì–‘í•œ í•™ìŠµ ìë£Œ íƒìƒ‰ í•„ìš”")

        return strengths, weaknesses

    def _generate_next_learning_suggestions(
        self, assessment: ComprehensiveAssessment, current_topic: str, learner_level: str
    ) -> list[str]:
        """ë‹¤ìŒ í•™ìŠµ ì œì•ˆ ìƒì„±"""
        suggestions = []

        grade = assessment.get("overall_grade", "")
        weaknesses = assessment.get("learning_weaknesses", [])

        # ë“±ê¸‰ ê¸°ë°˜ ì œì•ˆ
        if "S" in grade or "A+" in grade:
            suggestions.append(
                f"ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! {current_topic} ë§ˆìŠ¤í„°ë¦¬ ë‹¬ì„±. ë‹¤ìŒ ë‹¨ê³„ ì£¼ì œë¡œ ë„ì „í•´ë³´ì„¸ìš”."
            )
            if learner_level == "intermediate":
                suggestions.append("Advanced ë ˆë²¨ë¡œ ìƒìŠ¹í•˜ì—¬ ë” ê¹Šì´ ìˆëŠ” í•™ìŠµì„ ì‹œë„í•´ë³´ì„¸ìš”.")
            elif learner_level == "advanced":
                suggestions.append("ë©˜í† ë§ì´ë‚˜ ìƒˆë¡œìš´ ë¶„ì•¼ ê°œì²™ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        elif "A" in grade:
            suggestions.append(
                f"ì˜í–ˆìŠµë‹ˆë‹¤! {current_topic}ì— ëŒ€í•œ ì´í•´ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ì‹¤ì „ ì ìš©ì„ ê°•í™”í•´ë³´ì„¸ìš”."
            )
        elif "B" in grade:
            suggestions.append(
                f"{current_topic}ì— ëŒ€í•œ ê¸°ì´ˆ ì§€ì‹ì´ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¬í™” í•™ìŠµì„ ì§„í–‰í•´ë³´ì„¸ìš”."
            )
        elif "C" in grade:
            suggestions.append(
                f"{current_topic}ì— ëŒ€í•œ ì¶”ê°€ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤. ê¸°ì´ˆ ê°œë…ë¶€í„° ë‹¤ì‹œ ë³µìŠµí•´ë³´ì„¸ìš”."
            )
        else:
            suggestions.append(
                f"{current_topic} í•™ìŠµì„ ì²˜ìŒë¶€í„° ì²´ê³„ì ìœ¼ë¡œ ì§„í–‰í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            )

        # ì•½ì  ê¸°ë°˜ ì œì•ˆ
        for weakness in weaknesses:
            if "ì‹¤í–‰ ì„±ê³µë¥ " in weakness:
                suggestions.append("ì‹¤ì „ ì ìš© ì—°ìŠµì„ í†µí•´ ì‹¤í–‰ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ì„¸ìš”.")
            elif "í•™ìŠµ ìë£Œ" in weakness:
                suggestions.append("ë” ë‹¤ì–‘í•œ ìë£Œæºì„ í™œìš©í•˜ì—¬ í­ë„“ì€ ì‹œê°ì„ ê¸°ë¥´ì„¸ìš”.")
            elif "ì‹œê°„" in weakness:
                suggestions.append("ì§‘ì¤‘ í•™ìŠµ ì‹œê°„ì„ ëŠ˜ë¦¬ê±°ë‚˜ íš¨ìœ¨ì ì¸ í•™ìŠµ ë°©ë²•ì„ ì°¾ì•„ë³´ì„¸ìš”.")

        # Trinity Score ê¸°ë°˜ ì œì•ˆ
        improvement = assessment.get("trinity_improvement", 0)
        if improvement > 15:
            suggestions.append(
                "Trinity Scoreê°€ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤! ìì‹ ê°ì„ ê°€ì§€ê³  ë‹¤ìŒ ë„ì „ì— ì„í•˜ì„¸ìš”."
            )
        elif improvement < 5:
            suggestions.append("Trinity Score ê°œì„ ì„ ìœ„í•´ ë°˜ë³µ í•™ìŠµê³¼ ì‹¤ì „ ì ìš©ì„ ê°•í™”í•´ë³´ì„¸ìš”.")

        return suggestions

    async def get_system_status(self) -> SystemStatusResponse:
        """í†µí•© ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        try:
            librarian_status = (
                await self.obsidian_librarian.get_librarian_status()
                if self.obsidian_librarian
                else {"error": "not connected"}
            )
            mentor_status = (
                await self.langsmith_mentor.get_mentor_status()
                if self.langsmith_mentor
                else {"error": "not connected"}
            )

            return {
                "system_status": self.system_status,
                "active_sessions": len(self.active_sessions),
                "obsidian_librarian": librarian_status,
                "langsmith_mentor": mentor_status,
                "context7_connected": self.context7_service is not None,
                "integration_health": (
                    "excellent" if self.system_status == "active" else "degraded"
                ),
            }
        except Exception as e:
            return {"error": f"ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}"}

    def get_learning_analytics(self) -> LearningAnalytics:
        """í•™ìŠµ ë¶„ì„ ë°ì´í„° ì¡°íšŒ"""
        if not self.active_sessions:
            return {"message": "í™œì„± í•™ìŠµ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤."}

        sessions = list(self.active_sessions.values())

        # í‰ê·  ì„±ê³¼ ê³„ì‚°
        avg_improvement = sum(
            s["assessment"].get("trinity_improvement", 0) for s in sessions
        ) / len(sessions)
        avg_success_rate = sum(
            s["assessment"].get("avg_step_success_rate", 0) for s in sessions
        ) / len(sessions)

        # ê°€ì¥ ì„±ê³µì ì¸ ì„¸ì…˜
        best_session = max(sessions, key=lambda s: s["assessment"].get("final_trinity_score", 0))

        # í•™ìŠµ íŒ¨í„´ ë¶„ì„
        grade_distribution = {}
        for session in sessions:
            grade = session["assessment"].get("overall_grade", "Unknown")
            grade_distribution[grade] = grade_distribution.get(grade, 0) + 1

        return {
            "total_sessions": len(sessions),
            "avg_trinity_improvement": round(avg_improvement, 1),
            "avg_success_rate": round(avg_success_rate, 3),
            "best_session": {
                "topic": best_session["topic"],
                "grade": best_session["assessment"].get("overall_grade"),
                "improvement": best_session["assessment"].get("trinity_improvement", 0),
            },
            "grade_distribution": grade_distribution,
            "recent_topics": [s["topic"] for s in sessions[-5:]],
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
integrated_learning_system = IntegratedLearningSystem()


async def get_integrated_learning_system() -> IntegratedLearningSystem:
    """í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ (ì‹±ê¸€í†¤)"""
    return integrated_learning_system


async def initialize_integrated_learning_system() -> SystemInitStatus:
    """í†µí•© í•™ìŠµ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    return await integrated_learning_system.initialize_system()
