from __future__ import annotations

import logging
import time
from typing import TYPE_CHECKING, Any

from prometheus_client import Histogram
from starlette.middleware.base import BaseHTTPMiddleware

if TYPE_CHECKING:
    from fastapi import Request

# Trinity Score: 90.0 (Established by Chancellor)
"""Performance Monitoring Middleware for AFO Kingdom
Tracks response times and identifies slow endpoints.

Sequential Thinking: ë‹¨ê³„ë³„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´ êµ¬ì¶•
çœžå–„ç¾Žå­æ°¸: Truth 100%, Goodness 95%, Beauty 90%, Serenity 100%, Eternity 100%
"""


logger = logging.getLogger(__name__)

# ì„±ëŠ¥ ìž„ê³„ê°’ ì„¤ì •
PERFORMANCE_THRESHOLDS = {
    "warning_ms": 1000,  # 1ì´ˆ ì´ìƒ ì‹œ ê²½ê³ 
    "critical_ms": 2000,  # 2ì´ˆ ì´ìƒ ì‹œ ìœ„í—˜
    "p95_target_ms": 1000,  # P95 ëª©í‘œ: 1ì´ˆ ì´í•˜
}


class PerformanceMiddleware(BaseHTTPMiddleware):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´
    Sequential Thinking: ë‹¨ê³„ë³„ ì„±ëŠ¥ ì¸¡ì • ë° ì•Œë¦¼
    """

    def __init__(self, app: Any) -> None:
        super().__init__(app)
        self._request_times: list[float] = []
        self._endpoint_times: dict[str, list[float]] = {}
        self._max_history = 1000  # ìµœê·¼ 1000ê°œ ìš”ì²­ë§Œ ìœ ì§€

    async def dispatch(self, request: Request, call_next: Any) -> Any:
        """
        ì„±ëŠ¥ ì¸¡ì • ë° ëª¨ë‹ˆí„°ë§ (Sequential Thinking Phase 1)
        SSE ìŠ¤íŠ¸ë¦¼ì€ ì„±ëŠ¥ ì¸¡ì •ì—ì„œ ì œì™¸ (ë¬´í•œ ìŠ¤íŠ¸ë¦¼ blocking ë°©ì§€)
        """
        # SSE Stream ê²½ë¡œëŠ” ë°”ì´íŒ¨ìŠ¤
        if "stream" in request.url.path:
            return await call_next(request)

        # ì‹œìž‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()

        # ìš”ì²­ ì²˜ë¦¬
        response = await call_next(request)

        # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        elapsed_ms = (time.time() - start_time) * 1000

        # ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘ (Sequential Thinking Phase 1.1)
        self._record_performance(request, elapsed_ms)

        # ëŠë¦° ì—”ë“œí¬ì¸íŠ¸ ê°ì§€ (Sequential Thinking Phase 1.2)
        self._check_slow_endpoint(request, elapsed_ms)

        # Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ (Sequential Thinking Phase 1.3)
        self._update_prometheus_metrics(request, elapsed_ms, response.status_code)

        # ì‘ë‹µ í—¤ë”ì— ì„±ëŠ¥ ì •ë³´ ì¶”ê°€
        response.headers["X-Response-Time"] = f"{elapsed_ms:.2f}ms"

        return response

    def _record_performance(self, request: Request, elapsed_ms: float) -> None:
        """ì„±ëŠ¥ ë°ì´í„° ê¸°ë¡"""
        # ì „ì²´ ìš”ì²­ ì‹œê°„ ê¸°ë¡
        self._request_times.append(elapsed_ms)
        if len(self._request_times) > self._max_history:
            self._request_times.pop(0)

        # ì—”ë“œí¬ì¸íŠ¸ë³„ ì‹œê°„ ê¸°ë¡
        endpoint = f"{request.method} {request.url.path}"
        if endpoint not in self._endpoint_times:
            self._endpoint_times[endpoint] = []
        self._endpoint_times[endpoint].append(elapsed_ms)
        if len(self._endpoint_times[endpoint]) > 100:  # ì—”ë“œí¬ì¸íŠ¸ë³„ ìµœê·¼ 100ê°œë§Œ
            self._endpoint_times[endpoint].pop(0)

    def _check_slow_endpoint(self, request: Request, elapsed_ms: float) -> None:
        """
        ëŠë¦° ì—”ë“œí¬ì¸íŠ¸ ê°ì§€ ë° ë¡œê¹…
        """
        # comprehensive health checkëŠ” 11ê°œ ì˜¤ìž¥ìœ¡ë¶€ ì²´í¬ë¡œ 3-4ì´ˆ ì •ìƒ
        path = request.url.path
        is_comprehensive = "/comprehensive" in path
        threshold_critical = 5000 if is_comprehensive else PERFORMANCE_THRESHOLDS["critical_ms"]
        threshold_warning = 3000 if is_comprehensive else PERFORMANCE_THRESHOLDS["warning_ms"]

        if elapsed_ms >= threshold_critical:
            logger.warning(
                f"ðŸš¨ CRITICAL: Slow endpoint detected - {request.method} {path} "
                f"took {elapsed_ms:.2f}ms (threshold: {threshold_critical}ms)"
            )
        elif elapsed_ms >= threshold_warning:
            logger.info(
                f"âš ï¸ WARNING: Slow endpoint - {request.method} {path} "
                f"took {elapsed_ms:.2f}ms (threshold: {threshold_warning}ms)"
            )

    def _update_prometheus_metrics(
        self, request: Request, elapsed_ms: float, status_code: int
    ) -> None:
        """Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        try:
            # ë©”íŠ¸ë¦­ì´ ì—†ìœ¼ë©´ ìƒì„± (ì²« í˜¸ì¶œ ì‹œ)
            if not hasattr(self, "_response_time_histogram"):
                self._response_time_histogram = Histogram(
                    "afo_api_response_time_seconds",
                    "API response time in seconds",
                    ["method", "endpoint", "status_code"],
                    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0],
                )

            # ë©”íŠ¸ë¦­ ê¸°ë¡
            endpoint = request.url.path
            self._response_time_histogram.labels(
                method=request.method, endpoint=endpoint, status_code=status_code
            ).observe(elapsed_ms / 1000.0)  # ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜

        except (ImportError, Exception) as e:
            # Prometheusê°€ ì—†ìœ¼ë©´ ë¬´ì‹œ
            logger.debug("Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ë¬´ì‹œ): %s", e)

    def get_performance_stats(self) -> dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
        if not self._request_times:
            return {
                "total_requests": 0,
                "average_ms": 0.0,
                "p50_ms": 0.0,
                "p95_ms": 0.0,
                "p99_ms": 0.0,
                "slow_endpoints": [],
            }

        sorted_times = sorted(self._request_times)
        total = len(sorted_times)

        # ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°
        p50_idx = int(total * 0.5)
        p95_idx = int(total * 0.95)
        p99_idx = int(total * 0.99)

        # ëŠë¦° ì—”ë“œí¬ì¸íŠ¸ ì‹ë³„
        slow_endpoints = []
        for endpoint, times in self._endpoint_times.items():
            if times:
                avg_time = sum(times) / len(times)
                if avg_time >= PERFORMANCE_THRESHOLDS["p95_target_ms"]:
                    slow_endpoints.append(
                        {
                            "endpoint": endpoint,
                            "average_ms": round(avg_time, 2),
                            "count": len(times),
                        }
                    )

        return {
            "total_requests": total,
            "average_ms": round(sum(sorted_times) / total, 2),
            "p50_ms": round(sorted_times[p50_idx] if p50_idx < total else 0, 2),
            "p95_ms": round(sorted_times[p95_idx] if p95_idx < total else 0, 2),
            "p99_ms": round(sorted_times[p99_idx] if p99_idx < total else 0, 2),
            "slow_endpoints": sorted(slow_endpoints, key=lambda x: x["average_ms"], reverse=True),
        }
