"""
MyGPT ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬

jangjungwha.com â†” MyGPT ì–‘ë°©í–¥ ì»¨í…ìŠ¤íŠ¸ ë™ê¸°í™”
Upstash Redis ê¸°ë°˜ ì‹¤ì œ ë°ì´í„° ì €ì¥
"""

import json
import logging
from datetime import datetime

from fastapi import APIRouter, HTTPException, Query

from .models import MyGPTContextItem, MyGPTContextsResponse

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/mygpt", tags=["MyGPT"])

# Upstash Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
redis_client = None
try:
    import os

    import redis

    # Upstash Redis ì—°ê²° ì„¤ì •
    upstash_url = os.getenv("UPSTASH_REDIS_REST_URL")
    upstash_token = os.getenv("UPSTASH_REDIS_REST_TOKEN")

    if upstash_url and upstash_token:
        # Upstash REST API ì‚¬ìš©
        from upstash_redis import Redis

        redis_client = Redis(url=upstash_url, token=upstash_token)
        logger.info("âœ… Upstash Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
    else:
        # ë¡œì»¬ Redis í´ë°±
        redis_host = os.getenv("REDIS_HOST", "localhost")
        redis_port = int(os.getenv("REDIS_PORT", "6379"))

        redis_client = redis.Redis(host=redis_host, port=redis_port, decode_responses=True)
        logger.info(f"âœ… ë¡œì»¬ Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”: {redis_host}:{redis_port}")

except ImportError:
    logger.warning("âš ï¸ Redis ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
    redis_client = None
except Exception as e:
    logger.error(f"âŒ Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    redis_client = None

# MyGPT ì»¨í…ìŠ¤íŠ¸ í‚¤
MYGPT_CONTEXTS_KEY = "mygpt:contexts"
MYGPT_NOTEBOOKS_KEY = "mygpt:notebooks"


def get_contexts_from_redis() -> list[MyGPTContextItem]:
    """
    Redisì—ì„œ MyGPT ì»¨í…ìŠ¤íŠ¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    if not redis_client:
        logger.warning("Redis í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ, ë¹ˆ ëª©ë¡ ë°˜í™˜")
        return []

    try:
        # ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        contexts_data = redis_client.get(MYGPT_CONTEXTS_KEY)
        if not contexts_data:
            logger.info("Redisì— ì €ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ")
            return []

        # JSON íŒŒì‹±
        contexts_list = json.loads(contexts_data)
        contexts = []

        for item in contexts_list:
            try:
                context = MyGPTContextItem(
                    id=item["id"],
                    title=item["title"],
                    tags=item.get("tags", []),
                    content_preview=item.get("content_preview", ""),
                    created_at=datetime.fromisoformat(item["created_at"]),
                    updated_at=datetime.fromisoformat(item["updated_at"]),
                )
                contexts.append(context)
            except (KeyError, ValueError) as e:
                logger.warning(f"ì»¨í…ìŠ¤íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {e}, í•­ëª©: {item}")

        logger.info(f"Redisì—ì„œ {len(contexts)}ê°œ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ")
        return contexts

    except Exception as e:
        logger.error(f"Redisì—ì„œ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []


def save_contexts_to_redis(contexts: list[MyGPTContextItem]) -> bool:
    """
    ì»¨í…ìŠ¤íŠ¸ ëª©ë¡ì„ Redisì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    if not redis_client:
        logger.warning("Redis í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ, ì €ì¥í•˜ì§€ ì•ŠìŒ")
        return False

    try:
        # ì»¨í…ìŠ¤íŠ¸ë¥¼ JSONìœ¼ë¡œ ë³€í™˜
        contexts_data = []
        for ctx in contexts:
            contexts_data.append(
                {
                    "id": ctx.id,
                    "title": ctx.title,
                    "tags": ctx.tags,
                    "content_preview": ctx.content_preview,
                    "created_at": ctx.created_at.isoformat(),
                    "updated_at": ctx.updated_at.isoformat(),
                }
            )

        # Redisì— ì €ì¥
        redis_client.set(MYGPT_CONTEXTS_KEY, json.dumps(contexts_data))
        logger.info(f"Redisì— {len(contexts)}ê°œ ì»¨í…ìŠ¤íŠ¸ ì €ì¥")
        return True

    except Exception as e:
        logger.error(f"Redisì— ì»¨í…ìŠ¤íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def get_notebooks_from_redis() -> list[dict]:
    """
    Redisì—ì„œ ë…¸íŠ¸ë¶ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    if not redis_client:
        logger.warning("Redis í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ, ë¹ˆ ëª©ë¡ ë°˜í™˜")
        return []

    try:
        notebooks_data = redis_client.get(MYGPT_NOTEBOOKS_KEY)
        if not notebooks_data:
            logger.info("Redisì— ì €ì¥ëœ ë…¸íŠ¸ë¶ ì—†ìŒ")
            return []

        notebooks = json.loads(notebooks_data)
        logger.info(f"Redisì—ì„œ {len(notebooks)}ê°œ ë…¸íŠ¸ë¶ ë¡œë“œ")
        return notebooks

    except Exception as e:
        logger.error(f"Redisì—ì„œ ë…¸íŠ¸ë¶ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []


# ë°ëª¨ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° (Redis ì—°ê²° ì‹¤íŒ¨ ì‹œ í´ë°±)
DEMO_CONTEXTS = [
    MyGPTContextItem(
        id="o75vEpSlZeNtlMy1bp3jB",
        title="TAX-EASYUP-5165-M (2025 Inflation Update)",
        tags=["tax", "inflation", "2025"],
        content_preview="CPE Depot Easy Update 2025 â€” Inflation Adjustment Baseline...",
        created_at=datetime(2026, 1, 19, 6, 54),
        updated_at=datetime(2026, 1, 19, 6, 54),
    ),
    MyGPTContextItem(
        id="YNHOAXPKiUai_42YK6Uvp",
        title="Tax EasyUp 5165 - 2025 Comprehensive Summary",
        tags=["tax", "CPE", "inflation"],
        content_preview="### ğŸ“˜ 2025 EasyUp 5165 Comprehensive Summary...",
        created_at=datetime(2026, 1, 19, 6, 48),
        updated_at=datetime(2026, 1, 19, 6, 48),
    ),
    MyGPTContextItem(
        id="0jNiduX5sCws2TQM6q7WQ",
        title="Julie CPA Strategy Log",
        tags=["strategy", "julie-cpa"],
        content_preview="Initial entry for Julie CPA project notebook...",
        created_at=datetime(2026, 1, 18, 20, 30),
        updated_at=datetime(2026, 1, 18, 20, 30),
    ),
    MyGPTContextItem(
        id="z5h1SVRxY_efJTCh3vygz",
        title="AICPA_AI_Audit_Template_v1.0",
        tags=["aicpa", "audit", "template"],
        content_preview="Full AICPA AI Audit Standard Template...",
        created_at=datetime(2026, 1, 18, 10, 48),
        updated_at=datetime(2026, 1, 18, 10, 48),
    ),
    MyGPTContextItem(
        id="rHOGg0sel_1I98kkoA7l8",
        title="Julie_CPA_Full_AFO_Integration",
        tags=["julie-cpa", "afo-gpt", "integration"],
        content_preview="AFO GPT (Tax Simulation / Roth Optimizer...",
        created_at=datetime(2026, 1, 17, 1, 41),
        updated_at=datetime(2026, 1, 17, 1, 41),
    ),
]


@router.get("/contexts", response_model=MyGPTContextsResponse)
async def get_mygpt_contexts(
    limit: int = Query(default=5, description="ìµœëŒ€ ê²°ê³¼ ìˆ˜"),
    tag: str | None = Query(default=None, description="íƒœê·¸ í•„í„°"),
) -> MyGPTContextsResponse:
    """
    MyGPT ì»¨í…ìŠ¤íŠ¸ ëª©ë¡ ì¡°íšŒ

    ì‘ì—…:
    1. Upstash Redisì—ì„œ ì»¨í…ìŠ¤íŠ¸ ëª©ë¡ ì¡°íšŒ (ì‹¤ì œ ë°ì´í„° ìš°ì„ )
    2. Redis ì—°ê²° ì‹¤íŒ¨ ì‹œ ë°ëª¨ ë°ì´í„° ì‚¬ìš©
    3. íƒœê·¸ í•„í„°ë§ ì ìš©
    4. í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬
    """
    try:
        # Redisì—ì„œ ì‹¤ì œ ë°ì´í„° ì‹œë„
        contexts = get_contexts_from_redis()

        # Redisì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë°ëª¨ ë°ì´í„° ì‚¬ìš©
        if not contexts:
            logger.info("Redisì— ë°ì´í„° ì—†ìŒ, ë°ëª¨ ë°ì´í„° ì‚¬ìš©")
            contexts = DEMO_CONTEXTS.copy()

            # ë°ëª¨ ë°ì´í„°ë¥¼ Redisì— ì €ì¥ (í–¥í›„ ì‹¤ì œ ë°ì´í„°ë¡œ ëŒ€ì²´ ê°€ëŠ¥)
            if redis_client and len(contexts) > 0:
                save_contexts_to_redis(contexts)

        # íƒœê·¸ í•„í„°ë§
        if tag:
            contexts = [ctx for ctx in contexts if tag in ctx.tags]
            logger.info(f"íƒœê·¸ '{tag}'ë¡œ í•„í„°ë§: {len(contexts)}ê°œ ê²°ê³¼")

        # ê°œìˆ˜ ì œí•œ
        original_count = len(contexts)
        if limit < len(contexts):
            contexts = contexts[:limit]

        logger.info(f"MyGPT ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ: ì´ {original_count}ê°œ ì¤‘ {len(contexts)}ê°œ ë°˜í™˜")
        return MyGPTContextsResponse(contexts=contexts, total=len(contexts), page=1)

    except Exception as e:
        logger.error(f"MyGPT ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Contexts fetch failed: {e!s}")


@router.get("/notebooks", response_model=dict)
async def get_mygpt_notebooks(
    limit: int = Query(default=10, description="ìµœëŒ€ ê²°ê³¼ ìˆ˜"),
) -> dict:
    """
    MyGPT ë…¸íŠ¸ë¶ ëª©ë¡ ì¡°íšŒ

    ì‘ì—…:
    1. Upstash Redisì—ì„œ ë…¸íŠ¸ë¶ ëª©ë¡ ì¡°íšŒ
    2. í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬
    """
    try:
        # Redisì—ì„œ ì‹¤ì œ ë°ì´í„° ì‹œë„
        notebooks = get_notebooks_from_redis()

        # ê°œìˆ˜ ì œí•œ
        original_count = len(notebooks)
        if limit < len(notebooks):
            notebooks = notebooks[:limit]

        logger.info(f"MyGPT ë…¸íŠ¸ë¶ ì¡°íšŒ: ì´ {original_count}ê°œ ì¤‘ {len(notebooks)}ê°œ ë°˜í™˜")

        return {
            "notebooks": notebooks,
            "total": len(notebooks),
            "page": 1,
            "source": "redis" if redis_client else "demo",
        }

    except Exception as e:
        logger.error(f"MyGPT ë…¸íŠ¸ë¶ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Notebooks fetch failed: {e!s}")


@router.get("/status", response_model=dict)
async def get_mygpt_status() -> dict:
    """
    MyGPT Redis ì—°ê²° ìƒíƒœ ì¡°íšŒ
    """
    try:
        status_info = {
            "redis_connected": redis_client is not None,
            "redis_type": "upstash" if os.getenv("UPSTASH_REDIS_REST_URL") else "local",
            "contexts_count": len(get_contexts_from_redis()),
            "notebooks_count": len(get_notebooks_from_redis()),
            "timestamp": datetime.now().isoformat(),
        }

        if redis_client:
            try:
                # Redis ping í…ŒìŠ¤íŠ¸
                redis_client.ping()
                status_info["redis_health"] = "healthy"
            except Exception as e:
                status_info["redis_health"] = f"unhealthy: {e!s}"
        else:
            status_info["redis_health"] = "not_connected"

        logger.info(f"MyGPT ìƒíƒœ ì¡°íšŒ: {status_info}")
        return status_info

    except Exception as e:
        logger.error(f"MyGPT ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Status check failed: {e!s}")


__all__ = ["router"]
