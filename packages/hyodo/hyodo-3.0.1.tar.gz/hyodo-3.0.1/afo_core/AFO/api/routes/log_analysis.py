"""
AFO ì™•êµ­ Log Analysis API Router
Phase 43: The Cybernetic Loop (ììœ¨ ì§„í™”ì˜ ê³ ë¦¬)

ë¡œê·¸ ë¶„ì„ ì‹œìŠ¤í…œì„ ìœ„í•œ REST API ì—”ë“œí¬ì¸íŠ¸ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
Cybernetic Loopì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë¡œ Self-Diagnosticsì™€ í†µí•©ë©ë‹ˆë‹¤.
"""

import logging
from pathlib import Path
from typing import Any

from fastapi import APIRouter, BackgroundTasks, HTTPException, Query
from pydantic import BaseModel, Field

from AFO.serenity.self_diagnostics import SelfDiagnostics
from AFO.services.log_analysis import LogAnalysisService

logger = logging.getLogger(__name__)

# API Router ìƒì„±
router = APIRouter(
    prefix="/logs",
    tags=["log-analysis"],
    responses={404: {"description": "Log analysis endpoint not found"}},
)

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë“¤
log_service = LogAnalysisService()
diagnostics = SelfDiagnostics()


class LogAnalysisRequest(BaseModel):
    """ë¡œê·¸ ë¶„ì„ ìš”ì²­ ëª¨ë¸"""

    log_file_path: str = Field(..., description="ë¶„ì„í•  ë¡œê·¸ íŒŒì¼ì˜ ê²½ë¡œ")
    output_dir: str | None = Field(None, description="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ì„ íƒì‚¬í•­)")
    chunk_size: int | None = Field(100, ge=10, le=1000, description="ì²­í¬ í¬ê¸°")
    enable_diagnostics: bool = Field(True, description="Cybernetic Loop ì§„ë‹¨ í™œì„±í™”")

    class Config:
        json_schema_extra = {
            "example": {
                "log_file_path": "/var/log/application.log",
                "output_dir": "analysis_results",
                "chunk_size": 200,
                "enable_diagnostics": True,
            }
        }


class LogAnalysisResponse(BaseModel):
    """ë¡œê·¸ ë¶„ì„ ì‘ë‹µ ëª¨ë¸"""

    request_id: str
    status: str
    pipeline_result: dict[str, Any]
    cybernetic_impact: dict[str, Any] | None = None
    execution_time: float

    class Config:
        json_schema_extra = {
            "example": {
                "request_id": "log_analysis_123456",
                "status": "completed",
                "pipeline_result": {
                    "chunking": {"status": "success", "chunks_created": 5},
                    "sequential": {"status": "success"},
                    "plugins": {},
                },
                "cybernetic_impact": {
                    "truth_score_change": -0.15,
                    "pain_detection": True,
                },
                "execution_time": 2.34,
            }
        }


@router.post(
    "/analyze",
    response_model=LogAnalysisResponse,
    summary="ë¡œê·¸ íŒŒì¼ ë¶„ì„ ì‹¤í–‰",
    description="""
    ì§€ì •ëœ ë¡œê·¸ íŒŒì¼ì— ëŒ€í•´ ì™„ì „í•œ ë¡œê·¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

    **Cybernetic Loop í†µí•©:**
    - ë¡œê·¸ ë¶„ì„ ê²°ê³¼ê°€ Self-Diagnosticsì— ë°˜ì˜ë©ë‹ˆë‹¤
    - Critical ë¡œê·¸ ê°ì§€ ì‹œ Truth Score ìë™ ì¡°ì •
    - ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
    """,
)
async def analyze_logs(
    request: LogAnalysisRequest,
    background_tasks: BackgroundTasks,
    async_execution: bool = Query(False, description="ë¹„ë™ê¸° ì‹¤í–‰ ì—¬ë¶€"),
) -> LogAnalysisResponse:
    """
    ë¡œê·¸ ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸

    Args:
        request: ë¡œê·¸ ë¶„ì„ ìš”ì²­
        background_tasks: FastAPI ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬
        async_execution: ë¹„ë™ê¸° ì‹¤í–‰ ëª¨ë“œ

    Returns:
        ë¶„ì„ ê²°ê³¼ ì‘ë‹µ
    """
    import time
    import uuid

    request_id = f"log_analysis_{uuid.uuid4().hex[:8]}"
    start_time = time.time()

    logger.info(f"ğŸš€ Starting log analysis request: {request_id}")
    logger.info(f"ğŸ“ Target file: {request.log_file_path}")

    try:
        # ë¡œê·¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not Path(request.log_file_path).exists():
            raise HTTPException(
                status_code=404, detail=f"Log file not found: {request.log_file_path}"
            )

        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ì»¤ìŠ¤í…€ ì¶œë ¥ ë””ë ‰í† ë¦¬)
        service = LogAnalysisService(output_dir=request.output_dir)

        # Cybernetic Loop: ì‚¬ì „ ì§„ë‹¨
        pre_diagnostics = None
        if request.enable_diagnostics:
            logger.info("ğŸ©º Running pre-analysis diagnostics")
            pre_diagnostics = await diagnostics.run_full_diagnosis()
            logger.info(f"ğŸ“Š Pre-analysis Truth Score: {pre_diagnostics['trinity']['truth']:.3f}")

        # ë¡œê·¸ ë¶„ì„ ì‹¤í–‰
        if async_execution:
            # ë¹„ë™ê¸° ì‹¤í–‰: ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬
            background_tasks.add_task(_execute_log_analysis_async, service, request, request_id)

            return LogAnalysisResponse(
                request_id=request_id,
                status="accepted",
                pipeline_result={"message": "Analysis started in background"},
                cybernetic_impact=None,
                execution_time=0.0,
            )

        else:
            # ë™ê¸° ì‹¤í–‰: ì¦‰ì‹œ ì²˜ë¦¬
            pipeline_result = await _execute_log_analysis_async(service, request, request_id)

            # Cybernetic Loop: ì‚¬í›„ ì§„ë‹¨
            post_diagnostics = None
            cybernetic_impact = None

            if request.enable_diagnostics and pre_diagnostics:
                logger.info("ğŸ©º Running post-analysis diagnostics")
                post_diagnostics = await diagnostics.run_full_diagnosis()
                logger.info(
                    f"ğŸ“Š Post-analysis Truth Score: {post_diagnostics['trinity']['truth']:.3f}"
                )

                # Cybernetic Loop íš¨ê³¼ ê³„ì‚°
                cybernetic_impact = _calculate_cybernetic_impact(
                    pre_diagnostics, post_diagnostics, pipeline_result
                )

            execution_time = time.time() - start_time

            return LogAnalysisResponse(
                request_id=request_id,
                status="completed",
                pipeline_result=pipeline_result,
                cybernetic_impact=cybernetic_impact,
                execution_time=execution_time,
            )

    except Exception as e:
        execution_time = time.time() - start_time
        logger.error(f"ğŸ’¥ Log analysis failed: {e}")

        raise HTTPException(status_code=500, detail=f"Log analysis failed: {e!s}")


async def _execute_log_analysis_async(
    service: LogAnalysisService, request: LogAnalysisRequest, request_id: str
) -> dict[str, Any]:
    """ë¡œê·¸ ë¶„ì„ ì‹¤í–‰ (ë¹„ë™ê¸°)"""
    try:
        logger.info(f"ğŸ” Executing log analysis pipeline for {request_id}")

        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        result = service.run_pipeline(request.log_file_path)

        if result["pipeline_status"] == "SUCCESS":
            logger.info(f"âœ… Log analysis completed successfully for {request_id}")
        else:
            logger.warning(f"âš ï¸ Log analysis completed with issues for {request_id}")

        return result

    except Exception as e:
        logger.error(f"ğŸ’¥ Log analysis execution failed for {request_id}: {e}")
        return {"pipeline_status": "FAILED", "error": str(e), "request_id": request_id}


def _calculate_cybernetic_impact(
    pre_diagnostics: dict[str, Any],
    post_diagnostics: dict[str, Any],
    pipeline_result: dict[str, Any],
) -> dict[str, Any]:
    """Cybernetic Loop íš¨ê³¼ ê³„ì‚°"""

    pre_truth = pre_diagnostics["trinity"]["truth"]
    post_truth = post_diagnostics["trinity"]["truth"]

    score_change = pre_truth - post_truth
    score_drop_percentage = (score_change / pre_truth) * 100 if pre_truth > 0 else 0

    # ê³ í†µ ê°ì§€: Truth Score 5% ì´ìƒ í•˜ë½ (API í˜¸ì¶œìš© ê¸°ì¤€)
    pain_detection = score_drop_percentage >= 5.0

    # ë¶„ì„ ì„±ê³µ
    analysis_success = pipeline_result.get("pipeline_status") == "SUCCESS"

    return {
        "pre_truth_score": pre_truth,
        "post_truth_score": post_truth,
        "score_change": score_change,
        "score_drop_percentage": score_drop_percentage,
        "pain_detection": pain_detection,
        "analysis_success": analysis_success,
        "cybernetic_integrity": pain_detection and analysis_success,
    }


@router.get(
    "/health",
    summary="ë¡œê·¸ ë¶„ì„ ì„œë¹„ìŠ¤ ê±´ê°• ìƒíƒœ",
    description="Log Analysis ì„œë¹„ìŠ¤ì˜ í˜„ì¬ ê±´ê°• ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
)
async def get_log_analysis_health():
    """ë¡œê·¸ ë¶„ì„ ì„œë¹„ìŠ¤ ê±´ê°• ìƒíƒœ í™•ì¸"""
    try:
        # ê¸°ë³¸ ê±´ê°• ì²´í¬
        health_status = {
            "service": "log_analysis",
            "status": "healthy",
            "version": "1.0.0",
            "capabilities": [
                "log_chunking",
                "sequential_analysis",
                "plugin_system",
                "cybernetic_loop",
            ],
        }

        # ì¶”ê°€ ìƒíƒœ ì •ë³´
        health_status["diagnostics_available"] = True
        health_status["pipeline_ready"] = True

        return health_status

    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=503, detail="Log analysis service unhealthy")


@router.get(
    "/diagnostics",
    summary="Cybernetic Loop ì§„ë‹¨ ìƒíƒœ",
    description="í˜„ì¬ Self-Diagnostics ìƒíƒœì™€ Truth Scoreë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
)
async def get_cybernetic_diagnostics():
    """Cybernetic Loop ì§„ë‹¨ ìƒíƒœ ì¡°íšŒ"""
    try:
        report = await diagnostics.run_full_diagnosis()

        return {
            "timestamp": report["timestamp"],
            "trinity_scores": report["trinity"],
            "overall_health": report["status"],
            "details": [
                {
                    "lens": detail.lens,
                    "status": detail.status,
                    "score": detail.score,
                    "findings": detail.findings,
                }
                for detail in report["details"]
            ],
        }

    except Exception as e:
        logger.error(f"Diagnostics retrieval failed: {e}")
        raise HTTPException(status_code=500, detail="Failed to retrieve diagnostics")


@router.post(
    "/inject-critical",
    summary="Critical ë¡œê·¸ ì£¼ì… (í…ŒìŠ¤íŠ¸ìš©)",
    description="í…ŒìŠ¤íŠ¸ ëª©ì ìœ¼ë¡œ Critical ë ˆë²¨ ë¡œê·¸ë¥¼ ì‹œìŠ¤í…œì— ì£¼ì…í•©ë‹ˆë‹¤.",
)
async def inject_critical_logs(
    count: int = Query(1, ge=1, le=10, description="ì£¼ì…í•  Critical ë¡œê·¸ ê°œìˆ˜"),
):
    """Critical ë¡œê·¸ ì£¼ì… (í…ŒìŠ¤íŠ¸ìš©)"""
    try:
        # ì„ì‹œ ë¡œê·¸ íŒŒì¼ ìƒì„±
        temp_log = Path("critical_injection_test.log")

        critical_patterns = [
            "[CRITICAL] Database connection timeout",
            "[CRITICAL] Memory allocation failed",
            "[CRITICAL] Authentication service down",
            "[CRITICAL] File system corruption",
            "[CRITICAL] Network partition detected",
        ]

        with open(temp_log, "w") as f:
            for i in range(count):
                pattern = critical_patterns[i % len(critical_patterns)]
                f.write(f"{pattern} (injected #{i + 1})\n")

        logger.warning(f"ğŸ’‰ Injected {count} critical logs for testing")

        return {
            "status": "injected",
            "log_file": str(temp_log),
            "injected_count": count,
            "message": "Critical logs injected. Run diagnostics to verify Cybernetic Loop.",
        }

    except Exception as e:
        logger.error(f"Critical log injection failed: {e}")
        raise HTTPException(status_code=500, detail="Failed to inject critical logs")
