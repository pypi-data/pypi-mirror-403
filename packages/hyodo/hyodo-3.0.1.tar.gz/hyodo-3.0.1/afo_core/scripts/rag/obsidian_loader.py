from __future__ import annotations

import re
import site
import sys
from pathlib import Path
from typing import Optional, Union

import frontmatter
from langchain_core.documents import Document

from config import OBSIDIAN_VAULT_PATH

# Trinity Score: 90.0 (Established by Chancellor)
#!/usr/bin/env python3
"""ì˜µì‹œë””ì–¸ vault ë¬¸ì„œ ë¡œë”
Markdown íŒŒì¼ ë¡œë“œ ë° ë©”íƒ€ë°ì´í„° íŒŒì‹±
"""


# ì‚¬ìš©ì site-packages ê²½ë¡œ ì¶”ê°€

user_site_packages = site.getusersitepackages()
if user_site_packages:
    sys.path.insert(0, user_site_packages)

try:
    HAS_FRONTMATTER = True
except ImportError:
    HAS_FRONTMATTER = False
    print("âš ï¸  frontmatter ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ íŒŒì‹± ì‚¬ìš©")
    print("   ì„¤ì¹˜ ê¶Œì¥: pip install --user python-frontmatter")

try:
    pass  # Placeholder
except ImportError:
    print("âš ï¸  langchain_core ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ì„¤ì¹˜: pip install --user langchain langchain-core")
    sys.exit(1)


class ObsidianLoader:
    """ì˜µì‹œë””ì–¸ vault ë¬¸ì„œ ë¡œë”"""

    def __init__(self, vault_path: str | Path) -> None:
        """Args:
        vault_path: ì˜µì‹œë””ì–¸ vault ê²½ë¡œ

        """
        self.vault_path = Path(vault_path)
        if not self.vault_path.exists():
            raise ValueError(f"Vault path does not exist: {vault_path}")

    def load_documents(self, exclude_patterns: list[str] | None = None) -> list[Document]:
        """vaultì˜ ëª¨ë“  Markdown íŒŒì¼ ë¡œë“œ

        Args:
            exclude_patterns: ì œì™¸í•  íŒŒì¼ íŒ¨í„´ (ì˜ˆ: [".obsidian", "templates"])

        Returns:
            Document ë¦¬ìŠ¤íŠ¸

        """
        if exclude_patterns is None:
            exclude_patterns = [".obsidian", "templates", "dataview-queries"]

        documents = []

        for md_file in self.vault_path.rglob("*.md"):
            # ì œì™¸ íŒ¨í„´ í™•ì¸
            if any(
                pattern in str(md_file.relative_to(self.vault_path)) for pattern in exclude_patterns
            ):
                continue

            try:
                doc = self._load_single_document(md_file)
                if doc:
                    documents.append(doc)
            except Exception as e:
                print(f"âš ï¸  íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {md_file} - {e}")
                continue

        return documents

    def _load_single_document(self, file_path: Path) -> Document | None:
        """ë‹¨ì¼ ë¬¸ì„œ ë¡œë“œ ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        try:
            with open(file_path, encoding="utf-8") as f:
                content = f.read()

            # Frontmatter íŒŒì‹±
            if HAS_FRONTMATTER:
                post = frontmatter.loads(content)
                metadata = post.metadata.copy() if post.metadata else {}
                content = post.content
            else:
                # ê¸°ë³¸ íŒŒì‹± (frontmatter ì—†ì´)
                metadata = {}
                # ê°„ë‹¨í•œ frontmatter íŒŒì‹± ì‹œë„
                if content.startswith("---"):
                    parts = content.split("---", 2)
                    if len(parts) >= 3:
                        # YAML íŒŒì‹± ì‹œë„ (ê°„ë‹¨í•œ ë²„ì „)
                        frontmatter_text = parts[1]
                        content = parts[2]
                        # ê¸°ë³¸ì ì¸ í‚¤-ê°’ ì¶”ì¶œ
                        for line in frontmatter_text.split("\n"):
                            if ":" in line:
                                key, value = line.split(":", 1)
                                key = key.strip()
                                value = value.strip().strip('"').strip("'")
                                metadata[key] = value

            # íŒŒì¼ ê²½ë¡œ ì •ë³´ ì¶”ê°€
            rel_path = file_path.relative_to(self.vault_path)
            metadata["source"] = str(rel_path)
            metadata["file_path"] = str(file_path)
            metadata["file_name"] = file_path.name

            # ì˜µì‹œë””ì–¸ ë§í¬ ì¶”ì¶œ
            links = self._extract_links(content)
            metadata["links"] = links
            metadata["link_count"] = len(links)

            # íƒœê·¸ ì¶”ì¶œ
            tags = self._extract_tags(content, metadata)
            metadata["tags"] = tags

            # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ (ë””ë ‰í† ë¦¬ êµ¬ì¡° ê¸°ë°˜)
            metadata["category"] = str(rel_path.parent) if rel_path.parent != Path() else "root"

            # ë¬¸ì„œ íƒ€ì… ì¶”ì¶œ
            if "type" in metadata:
                metadata["doc_type"] = metadata["type"]
            elif "afo" in str(rel_path):
                metadata["doc_type"] = "afo"
            else:
                metadata["doc_type"] = "general"

            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ì˜µì‹œë””ì–¸ ë§í¬ ì •ê·œí™”)
            content = self._normalize_obsidian_links(content)

            return Document(page_content=content, metadata=metadata)
        except Exception as e:
            print(f"âš ï¸  ë¬¸ì„œ íŒŒì‹± ì‹¤íŒ¨: {file_path} - {e}")
            return None

    def _extract_links(self, content: str) -> list[str]:
        """ì˜µì‹œë””ì–¸ ë§í¬ ì¶”ì¶œ [[ë§í¬]]"""
        link_pattern = r"\[\[([^\]]+)\]\]"
        links = re.findall(link_pattern, content)
        return list(set(links))  # ì¤‘ë³µ ì œê±°

    def _extract_tags(self, content: str, metadata: dict) -> list[str]:
        """íƒœê·¸ ì¶”ì¶œ (#íƒœê·¸ ë˜ëŠ” frontmatter tags)"""
        tags = set()

        # Frontmatterì—ì„œ íƒœê·¸ ì¶”ì¶œ
        if "tags" in metadata:
            if isinstance(metadata["tags"], list):
                tags.update(metadata["tags"])
            elif isinstance(metadata["tags"], str):
                tags.add(metadata["tags"])

        # ë³¸ë¬¸ì—ì„œ íƒœê·¸ ì¶”ì¶œ (#íƒœê·¸)
        tag_pattern = r"#([a-zA-Z0-9_-]+)"
        content_tags = re.findall(tag_pattern, content)
        tags.update(content_tags)

        return list(tags)

    def _normalize_obsidian_links(self, content: str) -> str:
        """ì˜µì‹œë””ì–¸ ë§í¬ë¥¼ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì •ê·œí™”"""
        # [[ë§í¬]] -> ë§í¬
        content = re.sub(r"\[\[([^\]]+)\]\]", r"\1", content)
        # ![ì´ë¯¸ì§€|alt](path) -> alt ë˜ëŠ” path
        content = re.sub(r"!\[([^\]]*)\|?([^\]]*)\]\(([^\)]+)\)", r"\1 \3", content)
        return content

    def load_documents_by_category(self, category: str) -> list[Document]:
        """ì¹´í…Œê³ ë¦¬ë³„ ë¬¸ì„œ ë¡œë“œ"""
        all_docs = self.load_documents()
        return [doc for doc in all_docs if doc.metadata.get("category") == category]

    def load_documents_by_tag(self, tag: str) -> list[Document]:
        """íƒœê·¸ë³„ ë¬¸ì„œ ë¡œë“œ"""
        all_docs = self.load_documents()
        return [doc for doc in all_docs if tag in doc.metadata.get("tags", [])]


def main() -> None:
    """í…ŒìŠ¤íŠ¸"""

    vault_path = OBSIDIAN_VAULT_PATH
    loader = ObsidianLoader(vault_path)

    print("ğŸ“š ì˜µì‹œë””ì–¸ vault ë¬¸ì„œ ë¡œë“œ ì¤‘...")
    documents = loader.load_documents()

    print(f"\nâœ… ì´ {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
    print("\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ë¬¸ì„œ ìˆ˜:")
    categories = {}
    for doc in documents:
        cat = doc.metadata.get("category", "root")
        categories[cat] = categories.get(cat, 0) + 1

    for cat, count in sorted(categories.items()):
        print(f"  - {cat}: {count}ê°œ")

    print("\nğŸ“ ìƒ˜í”Œ ë¬¸ì„œ:")
    if documents:
        sample = documents[0]
        print(f"  íŒŒì¼: {sample.metadata.get('source')}")
        print(f"  íƒœê·¸: {sample.metadata.get('tags', [])}")
        print(f"  ë§í¬: {sample.metadata.get('links', [])[:5]}")
        print(f"  ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {sample.page_content[:200]}...")


if __name__ == "__main__":
    main()
