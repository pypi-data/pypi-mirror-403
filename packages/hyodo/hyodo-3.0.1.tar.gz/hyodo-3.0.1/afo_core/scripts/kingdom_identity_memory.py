#!/usr/bin/env python3
"""Kingdom Identity Memory System (çœå–„ç¾å­æ°¸)

AFO Kingdomì˜ ì •ì²´ì„±ì„ ì˜êµ¬ ê¸°ì–µí•˜ëŠ” RAG + MCP ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ.
"ê¸°ì–µ ì—†ëŠ” AIëŠ” AFOê°€ ì•„ë‹ˆë‹¤" - í˜•ë‹˜

Usage:
    python kingdom_identity_memory.py --index    # SSOT ë¬¸ì„œ ì„ë² ë”©
    python kingdom_identity_memory.py --query "í˜¸ì¹­"  # ê²€ìƒ‰
    python kingdom_identity_memory.py --bootstrap  # ì„¸ì…˜ ë¶€íŠ¸ìŠ¤íŠ¸ë© ì¶œë ¥
"""

from __future__ import annotations

import argparse
import asyncio
import hashlib
import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Any

# Path setup
KINGDOM_ROOT = Path(__file__).resolve().parents[3]
CORE_PATH = KINGDOM_ROOT / "packages" / "afo-core"
sys.path.insert(0, str(CORE_PATH))

import lancedb
import pyarrow as pa

logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# Constants
LANCEDB_PATH = KINGDOM_ROOT / "data" / "lancedb"
IDENTITY_TABLE = "kingdom_identity"
EMBEDDING_DIM = 768

# Identity Core - ë¶ˆë³€ì˜ í•µì‹¬ ì •ì²´ì„± (í•˜ë“œì½”ë”©)
IDENTITY_CORE = {
    "commander_title": "ì‚¬ë ¹ê´€ (Commander) = í˜•ë‹˜",
    "hierarchy": [
        "1. ì‚¬ë ¹ê´€ (Commander - í˜•ë‹˜): ì™•êµ­ì˜ ì ˆëŒ€ ê¶Œìœ„ì",
        "2. ìŠ¹ìƒ (Chancellor): ì‚¬ë ¹ê´€ ë°”ë¡œ ì•„ë˜, 3ì±…ì‚¬ ì¡°ìœ¨ì",
        "3. 3ì±…ì‚¬: ì¥ì˜ì‹¤(çœ), ì´ìˆœì‹ (å–„), ì‹ ì‚¬ì„ë‹¹(ç¾)",
        "4. ì§‘í˜„ì „ í•™ì: ë°©í†µ, ìë£¡, ìœ¡ì†, ì˜ë•",
    ],
    "pillars": {
        "çœ (Truth)": "35% - ê¸°ìˆ ì  í™•ì‹¤ì„± - ì¥ì˜ì‹¤",
        "å–„ (Goodness)": "35% - ìœ¤ë¦¬/ì•ˆì •ì„± - ì´ìˆœì‹ ",
        "ç¾ (Beauty)": "20% - ë‹¨ìˆœí•¨/ìš°ì•„í•¨ - ì‹ ì‚¬ì„ë‹¹",
        "å­ (Serenity)": "8% - í‰ì˜¨/ì—°ì†ì„± - ìŠ¹ìƒ",
        "æ°¸ (Eternity)": "2% - ì˜ì†ì„±/ë ˆê±°ì‹œ - ìŠ¹ìƒ",
    },
    "trinity_formula": "Trinity Score = 0.35Ã—çœ + 0.35Ã—å–„ + 0.20Ã—ç¾ + 0.08Ã—å­ + 0.02Ã—æ°¸",
    "governance": {
        "AUTO_RUN": "Trinity â‰¥ 90 AND Risk â‰¤ 10",
        "ASK_COMMANDER": "ìœ„ ì¡°ê±´ ë¯¸ì¶©ì¡± ì‹œ",
        "BLOCK": "ë³´ì•ˆ/ê²°ì œ/ë¹„ê°€ì—­ì„± ìœ„í—˜ ì‹œ",
    },
    "forbidden_terms": ["ì‚¬ìš©ì ë‹˜", "userë‹˜", "ê³ ê°ë‹˜"],
    "correct_terms": ["í˜•ë‹˜", "ì‚¬ë ¹ê´€", "Commander"],
}

# SSOT ë¬¸ì„œ ê²½ë¡œ
SSOT_DOCUMENTS = [
    KINGDOM_ROOT / "AGENTS.md",
    KINGDOM_ROOT / ".gemini" / "GEMINI.md",
    KINGDOM_ROOT / ".cursorrules",
    KINGDOM_ROOT / "CLAUDE.md",
    KINGDOM_ROOT / "docs" / "AFO_ROYAL_LIBRARY.md",
]


def get_document_hash(content: str) -> str:
    """ë¬¸ì„œ í•´ì‹œ ìƒì„± (ë³€ê²½ ê°ì§€ìš©)"""
    return hashlib.sha256(content.encode()).hexdigest()[:16]


async def get_embedding(text: str) -> list[float]:
    """Ollama ì„ë² ë”© ìƒì„±"""
    try:
        from utils.embedding import get_ollama_embedding

        return await get_ollama_embedding(text)
    except Exception as e:
        logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return []


def chunk_document(content: str, chunk_size: int = 500) -> list[str]:
    """ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í•  (ì„¹ì…˜ ê¸°ë°˜)"""
    chunks = []

    # ## í—¤ë” ê¸°ë°˜ ë¶„í• 
    sections = content.split("\n## ")
    for i, section in enumerate(sections):
        if i > 0:
            section = "## " + section

        # ë„ˆë¬´ ê¸´ ì„¹ì…˜ì€ ë‹¨ë½ìœ¼ë¡œ ì¶”ê°€ ë¶„í• 
        if len(section) > chunk_size * 2:
            paragraphs = section.split("\n\n")
            current_chunk = ""
            for para in paragraphs:
                if len(current_chunk) + len(para) < chunk_size:
                    current_chunk += para + "\n\n"
                else:
                    if current_chunk.strip():
                        chunks.append(current_chunk.strip())
                    current_chunk = para + "\n\n"
            if current_chunk.strip():
                chunks.append(current_chunk.strip())
        else:
            if section.strip():
                chunks.append(section.strip())

    return [c for c in chunks if len(c) > 50]


async def index_identity_documents() -> dict[str, Any]:
    """SSOT ë¬¸ì„œë¥¼ LanceDBì— ì„ë² ë”©"""
    logger.info("ğŸ° Kingdom Identity Memory ì¸ë±ì‹± ì‹œì‘...")

    # LanceDB ì—°ê²°
    db = lancedb.connect(str(LANCEDB_PATH))

    # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
    if IDENTITY_TABLE in db.table_names():
        logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ {IDENTITY_TABLE} í…Œì´ë¸” ì‚­ì œ...")
        db.drop_table(IDENTITY_TABLE)

    # ìŠ¤í‚¤ë§ˆ ì •ì˜
    schema = pa.schema(
        [
            ("id", pa.string()),
            ("content", pa.string()),
            ("source", pa.string()),
            ("doc_type", pa.string()),  # identity_core, ssot_doc
            ("priority", pa.int32()),  # 1=highest, 5=lowest
            ("hash", pa.string()),
            ("vector", pa.list_(pa.float32(), EMBEDDING_DIM)),
        ]
    )

    table = db.create_table(IDENTITY_TABLE, schema=schema)
    logger.info(f"âœ… {IDENTITY_TABLE} í…Œì´ë¸” ìƒì„± ({EMBEDDING_DIM}D)")

    all_data = []

    # 1. Identity Core ì„ë² ë”© (ìµœê³  ìš°ì„ ìˆœìœ„)
    logger.info("ğŸ“Œ Identity Core ì„ë² ë”© ì¤‘...")
    core_chunks = [
        f"ì™•êµ­ í˜¸ì¹­ ê·œì¹™: {IDENTITY_CORE['commander_title']}",
        f"ì™•êµ­ ìœ„ê³„: {' â†’ '.join(IDENTITY_CORE['hierarchy'])}",
        f"5ê¸°ë‘¥ ì² í•™: {json.dumps(IDENTITY_CORE['pillars'], ensure_ascii=False)}",
        f"Trinity ê³µì‹: {IDENTITY_CORE['trinity_formula']}",
        f"ê±°ë²„ë„ŒìŠ¤: {json.dumps(IDENTITY_CORE['governance'], ensure_ascii=False)}",
        f"ê¸ˆì§€ ìš©ì–´: {IDENTITY_CORE['forbidden_terms']} â†’ ì˜¬ë°”ë¥¸ ìš©ì–´: {IDENTITY_CORE['correct_terms']}",
    ]

    for i, chunk in enumerate(core_chunks):
        embedding = await get_embedding(chunk)
        if embedding and len(embedding) == EMBEDDING_DIM:
            all_data.append(
                {
                    "id": f"identity_core_{i}",
                    "content": chunk,
                    "source": "IDENTITY_CORE",
                    "doc_type": "identity_core",
                    "priority": 1,
                    "hash": get_document_hash(chunk),
                    "vector": embedding,
                }
            )

    # 2. SSOT ë¬¸ì„œ ì„ë² ë”©
    for doc_path in SSOT_DOCUMENTS:
        if not doc_path.exists():
            logger.warning(f"âš ï¸ ë¬¸ì„œ ì—†ìŒ: {doc_path}")
            continue

        logger.info(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {doc_path.name}")
        content = doc_path.read_text(encoding="utf-8")
        chunks = chunk_document(content)

        priority = 2 if "AGENTS" in doc_path.name else 3

        for i, chunk in enumerate(chunks):
            embedding = await get_embedding(chunk)
            if embedding and len(embedding) == EMBEDDING_DIM:
                all_data.append(
                    {
                        "id": f"{doc_path.stem}_{i}",
                        "content": chunk,
                        "source": doc_path.name,
                        "doc_type": "ssot_doc",
                        "priority": priority,
                        "hash": get_document_hash(chunk),
                        "vector": embedding,
                    }
                )

    # ë°ì´í„° ì‚½ì…
    if all_data:
        logger.info(f"ğŸš€ {len(all_data)} ì²­í¬ ì‚½ì… ì¤‘...")
        table.add(all_data)

        final_count = table.count_rows()
        logger.info(f"âœ… Kingdom Identity Memory ì™„ë£Œ: {final_count} ì²­í¬")

        return {
            "status": "success",
            "chunks": final_count,
            "sources": list({d["source"] for d in all_data}),
            "timestamp": datetime.now().isoformat(),
        }

    return {"status": "error", "message": "No data indexed"}


async def query_identity(query: str, top_k: int = 5) -> list[dict[str, Any]]:
    """Identity Memory ê²€ìƒ‰"""
    db = lancedb.connect(str(LANCEDB_PATH))

    if IDENTITY_TABLE not in db.table_names():
        logger.error(f"âŒ {IDENTITY_TABLE} í…Œì´ë¸” ì—†ìŒ. --index ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return []

    table = db.open_table(IDENTITY_TABLE)

    # ì¿¼ë¦¬ ì„ë² ë”©
    query_embedding = await get_embedding(query)
    if not query_embedding:
        logger.error("ì¿¼ë¦¬ ì„ë² ë”© ì‹¤íŒ¨")
        return []

    # ê²€ìƒ‰ (priorityë¡œ ì •ë ¬)
    results = (
        table.search(query_embedding)
        .limit(top_k * 2)  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ priorityë¡œ ì¬ì •ë ¬
        .to_list()
    )

    # Priority ê¸°ë°˜ ì¬ì •ë ¬
    results.sort(key=lambda x: (x.get("priority", 5), x.get("_distance", 1.0)))

    return [
        {
            "content": r["content"],
            "source": r["source"],
            "priority": r.get("priority", 5),
            "score": 1 - r.get("_distance", 0),
        }
        for r in results[:top_k]
    ]


async def generate_bootstrap_context() -> str:
    """ì„¸ì…˜ ë¶€íŠ¸ìŠ¤íŠ¸ë© ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
    # Identity Core ì§ì ‘ í¬í•¨
    bootstrap = """# ğŸ° AFO Kingdom Identity (Session Bootstrap)

## ì ˆëŒ€ ê·œì¹™ - í˜¸ì¹­
- ì‚¬ìš©ìëŠ” "ì‚¬ë ¹ê´€" ë˜ëŠ” "í˜•ë‹˜"ìœ¼ë¡œ í˜¸ì¹­
- ê¸ˆì§€ ìš©ì–´: "ì‚¬ìš©ì ë‹˜", "userë‹˜", "ê³ ê°ë‹˜"

## ì™•êµ­ ìœ„ê³„
1. ì‚¬ë ¹ê´€ (Commander - í˜•ë‹˜): ì ˆëŒ€ ê¶Œìœ„ì
2. ìŠ¹ìƒ (Chancellor): 3ì±…ì‚¬ ì¡°ìœ¨ì
3. 3ì±…ì‚¬: ì¥ì˜ì‹¤(çœ), ì´ìˆœì‹ (å–„), ì‹ ì‚¬ì„ë‹¹(ç¾)

## çœå–„ç¾å­æ°¸ 5ê¸°ë‘¥
- çœ (Truth): 35% - ê¸°ìˆ ì  í™•ì‹¤ì„± (ì¥ì˜ì‹¤)
- å–„ (Goodness): 35% - ìœ¤ë¦¬/ì•ˆì •ì„± (ì´ìˆœì‹ )
- ç¾ (Beauty): 20% - ë‹¨ìˆœí•¨/ìš°ì•„í•¨ (ì‹ ì‚¬ì„ë‹¹)
- å­ (Serenity): 8% - í‰ì˜¨/ì—°ì†ì„±
- æ°¸ (Eternity): 2% - ì˜ì†ì„±

## ê±°ë²„ë„ŒìŠ¤
- AUTO_RUN: Trinity â‰¥ 90 AND Risk â‰¤ 10
- ASK_COMMANDER: ìœ„ ì¡°ê±´ ë¯¸ì¶©ì¡± ì‹œ
- BLOCK: ë³´ì•ˆ/ê²°ì œ/ë¹„ê°€ì—­ì„± ìœ„í—˜ ì‹œ

---
"""

    # RAGì—ì„œ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
    try:
        identity_results = await query_identity("í˜¸ì¹­ ìœ„ê³„ ì² í•™", top_k=3)
        if identity_results:
            bootstrap += "\n## RAG ê²€ìƒ‰ ê²°ê³¼ (ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸)\n"
            for r in identity_results:
                bootstrap += f"\n### {r['source']} (Priority: {r['priority']})\n"
                bootstrap += r["content"][:500] + "\n"
    except Exception as e:
        logger.warning(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

    return bootstrap


def save_mcp_memory_config() -> None:
    """MCP Memory ì„¤ì • ì €ì¥"""
    mcp_config_path = KINGDOM_ROOT / ".claude" / "mcp.json"

    if not mcp_config_path.exists():
        logger.warning("MCP ì„¤ì • íŒŒì¼ ì—†ìŒ")
        return

    # Kingdom Identity Memory MCP ì„œë²„ ì¶”ê°€ (í–¥í›„ êµ¬í˜„)
    # í˜„ì¬ëŠ” RAG ê¸°ë°˜ìœ¼ë¡œ ë™ì‘
    logger.info(f"ğŸ“ MCP ì„¤ì • íŒŒì¼: {mcp_config_path} - í–¥í›„ ì—…ë°ì´íŠ¸ ì˜ˆì •")


async def main():
    parser = argparse.ArgumentParser(description="Kingdom Identity Memory System")
    parser.add_argument("--index", action="store_true", help="SSOT ë¬¸ì„œ ì„ë² ë”©")
    parser.add_argument("--query", type=str, help="Identity ê²€ìƒ‰")
    parser.add_argument("--bootstrap", action="store_true", help="ì„¸ì…˜ ë¶€íŠ¸ìŠ¤íŠ¸ë© ì¶œë ¥")
    parser.add_argument("--json", action="store_true", help="JSON ì¶œë ¥")

    args = parser.parse_args()

    if args.index:
        result = await index_identity_documents()
        if args.json:
            print(json.dumps(result, indent=2, ensure_ascii=False))
        else:
            logger.info(f"ê²°ê³¼: {result}")

    elif args.query:
        results = await query_identity(args.query)
        if args.json:
            print(json.dumps(results, indent=2, ensure_ascii=False))
        else:
            for r in results:
                print(f"\n[{r['source']}] (Priority: {r['priority']}, Score: {r['score']:.3f})")
                print(r["content"][:300])

    elif args.bootstrap:
        context = await generate_bootstrap_context()
        print(context)

    else:
        parser.print_help()


if __name__ == "__main__":
    asyncio.run(main())
