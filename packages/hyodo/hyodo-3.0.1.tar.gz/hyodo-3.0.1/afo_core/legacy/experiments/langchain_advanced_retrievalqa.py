from __future__ import annotations

import os

from langchain.document_loaders import TextLoader
from langchain.prompts import PromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain_classic.chains import RetrievalQA
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# Trinity Score: 90.0 (Established by Chancellor)
# âš”ï¸ ì ìˆ˜ëŠ” Truth Engine (scripts/calculate_trinity_score.py)ì—ì„œë§Œ ê³„ì‚°ë©ë‹ˆë‹¤.
# LLMì€ consult_the_lens MCP ë„êµ¬ë¥¼ í†µí•´ ì ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.
# ì´ íŒŒì¼ì€ AFO ì™•êµ­ì˜ çœå–„ç¾å­ ì² í•™ì„ êµ¬í˜„í•©ë‹ˆë‹¤

#!/usr/bin/env python3
"""ì£¼ìœ  ì±…ì‚¬ ì œì•ˆ: Advanced RetrievalQA
í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ + Chain Type + Source Documents
"""


def main() -> None:
    print("=" * 70)
    print("ì£¼ìœ  ì±…ì‚¬ ì œì•ˆ: Advanced RetrievalQA")
    print("=" * 70)
    print()

    # OpenAI API Key í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸  OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   export OPENAI_API_KEY='your-key-here'")
        print()
        print("ğŸ“š DRY RUN ëª¨ë“œ: êµ¬ì¡°ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.\n")
        show_structure()
        return

    # LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
    embeddings = OpenAIEmbeddings()

    # ìƒ˜í”Œ ë¬¸ì„œ ì¤€ë¹„
    print("=" * 70)
    print("ë¬¸ì„œ ì¤€ë¹„ ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„±")
    print("=" * 70)
    print()

    sample_docs = """
    AFO UltimateëŠ” ë‹¤ì¤‘ ì»´í¬ë„ŒíŠ¸ ìë™í™” ë° ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ í”Œë«í¼ì…ë‹ˆë‹¤.
    AFO Soul Engineì€ Python ê¸°ë°˜ ìŒì•… ë¶„ì„ ë° AI ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
    MCP FrontendëŠ” React TypeScript ëŒ€ì‹œë³´ë“œë¡œ n8n ì›Œí¬í”Œë¡œìš° ëª¨ë‹ˆí„°ë§ì„ ì œê³µí•©ë‹ˆë‹¤.
    N8N Custom NodesëŠ” n8n-MCP í†µí•© íŒ¨í‚¤ì§€ë¡œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì—ê²Œ n8n ë…¸ë“œ ë¬¸ì„œë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    LangChainì€ 47ê°œ ë…¸ë“œë¡œ Memory, Retriever, Chain ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    """

    with open("/tmp/afo_docs.txt", "w") as f:
        f.write(sample_docs)

    print("1ï¸âƒ£ ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• ...")
    loader = TextLoader("/tmp/afo_docs.txt")
    docs = loader.load()

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=200, chunk_overlap=50, separators=["\n\n", "\n", ". ", " ", ""]
    )
    texts = splitter.split_documents(docs)
    print(f"   âœ“ {len(texts)}ê°œ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ\n")

    print("2ï¸âƒ£ FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±...")
    vectorstore = FAISS.from_documents(texts, embeddings)
    print("   âœ“ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ\n")

    # ì˜ˆì œ 1: ê¸°ë³¸ RetrievalQA
    print("=" * 70)
    print("ì˜ˆì œ 1: ê¸°ë³¸ RetrievalQA (Stuff Chain)")
    print("=" * 70)
    print()

    qa_basic = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(search_kwargs={"k": 2}),
        return_source_documents=True,
    )

    query1 = "AFO UltimateëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
    print(f"ğŸ‘¤ ì§ˆë¬¸: {query1}")
    result1 = qa_basic({"query": query1})
    print(f"ğŸ¤– ë‹µë³€: {result1['result']}")
    print(f"ğŸ“„ ì†ŒìŠ¤: {len(result1['source_documents'])}ê°œ ë¬¸ì„œ ì°¸ì¡°\n")

    # ì˜ˆì œ 2: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ RetrievalQA
    print("=" * 70)
    print("ì˜ˆì œ 2: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ RetrievalQA")
    print("=" * 70)
    print()

    custom_prompt_template = """ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
    ë‹µì„ ëª¨ë¥´ë©´ "ë¬¸ì„œì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.

    ì»¨í…ìŠ¤íŠ¸:
    {context}

    ì§ˆë¬¸: {question}
    ë‹µë³€:"""

    CUSTOM_PROMPT = PromptTemplate(
        template=custom_prompt_template, input_variables=["context", "question"]
    )

    qa_custom = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        return_source_documents=True,
        chain_type_kwargs={"prompt": CUSTOM_PROMPT},
    )

    query2 = "LangChainì€ ëª‡ ê°œì˜ ë…¸ë“œë¥¼ ì œê³µí•˜ë‚˜ìš”?"
    print(f"ğŸ‘¤ ì§ˆë¬¸: {query2}")
    result2 = qa_custom({"query": query2})
    print(f"ğŸ¤– ë‹µë³€: {result2['result']}")
    print(f"ğŸ“„ ì†ŒìŠ¤: {len(result2['source_documents'])}ê°œ ë¬¸ì„œ ì°¸ì¡°")
    print("   ì°¸ì¡° ë¬¸ì„œ:")
    for i, doc in enumerate(result2["source_documents"][:2], 1):
        preview = doc.page_content[:100].replace("\n", " ")
        print(f"   [{i}] {preview}...")
    print()

    # ì˜ˆì œ 3: Map-Reduce Chain (ê¸´ ë¬¸ì„œìš©)
    print("=" * 70)
    print("ì˜ˆì œ 3: Map-Reduce Chain (ê¸´ ë¬¸ì„œ ìš”ì•½)")
    print("=" * 70)
    print()

    qa_mapreduce = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="map_reduce",
        retriever=vectorstore.as_retriever(search_kwargs={"k": 4}),
        return_source_documents=True,
    )

    query3 = "AFO Ultimateì˜ ì£¼ìš” ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    print(f"ğŸ‘¤ ì§ˆë¬¸: {query3}")
    result3 = qa_mapreduce({"query": query3})
    print(f"ğŸ¤– ë‹µë³€: {result3['result']}")
    print(f"ğŸ“„ ì†ŒìŠ¤: {len(result3['source_documents'])}ê°œ ë¬¸ì„œ ì°¸ì¡°\n")

    print("ğŸ’¡ Map-Reduce íŠ¹ì§•:")
    print("   â€¢ ê° ë¬¸ì„œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬ (Map)")
    print("   â€¢ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„± (Reduce)")
    print("   â€¢ ê¸´ ë¬¸ì„œë‚˜ ë§ì€ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ì— ì í•©\n")

    # ì˜ˆì œ 4: Refine Chain (ì •êµí•œ ë‹µë³€)
    print("=" * 70)
    print("ì˜ˆì œ 4: Refine Chain (ìˆœì°¨ì  ì •ì œ)")
    print("=" * 70)
    print()

    qa_refine = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="refine",
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        return_source_documents=True,
    )

    query4 = "n8nê³¼ LangChainì˜ ê´€ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
    print(f"ğŸ‘¤ ì§ˆë¬¸: {query4}")
    result4 = qa_refine({"query": query4})
    print(f"ğŸ¤– ë‹µë³€: {result4['result']}")
    print(f"ğŸ“„ ì†ŒìŠ¤: {len(result4['source_documents'])}ê°œ ë¬¸ì„œ ì°¸ì¡°\n")

    print("ğŸ’¡ Refine íŠ¹ì§•:")
    print("   â€¢ ì²« ë¬¸ì„œë¡œ ì´ˆê¸° ë‹µë³€ ìƒì„±")
    print("   â€¢ ì´í›„ ë¬¸ì„œë“¤ë¡œ ë‹µë³€ì„ ìˆœì°¨ì ìœ¼ë¡œ ì •ì œ")
    print("   â€¢ ì •êµí•˜ê³  ìƒì„¸í•œ ë‹µë³€ ìƒì„±\n")

    # Chain Type ë¹„êµ
    print("=" * 70)
    print("Chain Type ë¹„êµ ìš”ì•½")
    print("=" * 70)
    print()
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ Chain Type  â”‚ ì¥ì                  â”‚ ì í•©í•œ ê²½ìš°          â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print("â”‚ stuff       â”‚ ë¹ ë¦„, ê°„ë‹¨           â”‚ ì§§ì€ ì»¨í…ìŠ¤íŠ¸        â”‚")
    print("â”‚ map_reduce  â”‚ ë³‘ë ¬ ì²˜ë¦¬, í™•ì¥ì„±    â”‚ ê¸´ ë¬¸ì„œ, ë§ì€ ì²­í¬   â”‚")
    print("â”‚ refine      â”‚ ì •êµí•œ ë‹µë³€          â”‚ ìƒì„¸í•œ ë¶„ì„ í•„ìš”     â”‚")
    print("â”‚ map_rerank  â”‚ ìµœì  ë‹µë³€ ì„ íƒ       â”‚ ëª…í™•í•œ ë‹µë³€ í•„ìš”     â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print()

    print("=" * 70)
    print("âœ“ Advanced RetrievalQA ì˜ˆì œ ì™„ë£Œ")
    print("=" * 70)


def show_structure() -> None:
    """DRY RUN ëª¨ë“œì—ì„œ êµ¬ì¡° í‘œì‹œ"""
    print("ğŸ“ Advanced RetrievalQA êµ¬ì¡°:\n")
    print("  ì˜ˆì œ 1: ê¸°ë³¸ RetrievalQA (stuff)")
    print("    â€¢ ëª¨ë“  ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ í”„ë¡¬í”„íŠ¸ë¡œ")
    print("    â€¢ ë¹ ë¥´ê³  ê°„ë‹¨")
    print()
    print("  ì˜ˆì œ 2: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸")
    print("    â€¢ PromptTemplateë¡œ ë‹µë³€ í˜•ì‹ ì œì–´")
    print("    â€¢ ì–¸ì–´, ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•")
    print()
    print("  ì˜ˆì œ 3: Map-Reduce Chain")
    print("    â€¢ ê° ë¬¸ì„œ ê°œë³„ ì²˜ë¦¬ â†’ ê²°ê³¼ ë³‘í•©")
    print("    â€¢ ê¸´ ë¬¸ì„œ, ë§ì€ ì»¨í…ìŠ¤íŠ¸")
    print()
    print("  ì˜ˆì œ 4: Refine Chain")
    print("    â€¢ ì´ˆê¸° ë‹µë³€ ìƒì„± â†’ ìˆœì°¨ì  ì •ì œ")
    print("    â€¢ ì •êµí•˜ê³  ìƒì„¸í•œ ë‹µë³€")
    print()
    print("ğŸ“Š ë°ì´í„° íë¦„:")
    print("  ì§ˆë¬¸ â†’ [ë²¡í„° ê²€ìƒ‰] â†’ ê´€ë ¨ ë¬¸ì„œ â†’ [Chain ì²˜ë¦¬] â†’ LLM â†’ ë‹µë³€")
    print()
    print("âœ¨ Chain Type ì„ íƒ ê°€ì´ë“œ:")
    print("  â€¢ ì§§ì€ ì»¨í…ìŠ¤íŠ¸ â†’ stuff")
    print("  â€¢ ê¸´ ë¬¸ì„œ â†’ map_reduce")
    print("  â€¢ ì •êµí•œ ë‹µë³€ â†’ refine")
    print("  â€¢ ìµœì  ë‹µë³€ â†’ map_rerank")


if __name__ == "__main__":
    main()
