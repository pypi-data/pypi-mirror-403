from __future__ import annotations

import sys
import traceback
from pathlib import Path
from typing import Union

from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_qdrant import Qdrant
from langchain_text_splitters import CharacterTextSplitter

from AFO.config.settings import get_settings

# Trinity Score: 90.0 (Established by Chancellor)
# âš”ï¸ ì ìˆ˜ëŠ” Truth Engine (scripts/calculate_trinity_score.py)ì—ì„œë§Œ ê³„ì‚°ë©ë‹ˆë‹¤.
# LLMì€ consult_the_lens MCP ë„êµ¬ë¥¼ í†µí•´ ì ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.
# ì´ íŒŒì¼ì€ AFO ì™•êµ­ì˜ çœå–„ç¾å­ ì² í•™ì„ êµ¬í˜„í•©ë‹ˆë‹¤

#!/usr/bin/env python3
"""
n8n ì›Œí¬í”Œë¡œìš° ì •ë³´ë¥¼ AFO RAG ì‹œìŠ¤í…œì— ì¶”ê°€í•˜ëŠ” ê²€ì¦ëœ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python add_workflow_to_rag_verified.py
"""


# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
PROJECT_ROOT = Path(__file__).parent.parent
ENV_FILE = PROJECT_ROOT / ".env"


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (dotenv ì—†ì´ ì§ì ‘ íŒŒì‹±)
def load_env() -> None:
    env_vars = {}
    if ENV_FILE.exists():
        with open(ENV_FILE) as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#") and "=" in line:
                    key, value = line.split("=", 1)
                    env_vars[key] = value
    return env_vars


env = load_env()
OPENAI_API_KEY = env.get("OPENAI_API_KEY")

# LangChain ë° Qdrant ì„í¬íŠ¸ (ChromaDB â†’ Qdrant ë§ˆì´ê·¸ë ˆì´ì…˜)
try:
    pass  # Placeholder
except ImportError as e:
    print(f"âŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
    print("   ì„¤ì¹˜: pip install langchain-qdrant langchain-openai")
    sys.exit(1)

# OpenAI API í‚¤ í™•ì¸
if not OPENAI_API_KEY:
    print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    sys.exit(1)

# Qdrant ì„¤ì • (ChromaDB â†’ Qdrant ë§ˆì´ê·¸ë ˆì´ì…˜)
# ì¤‘ì•™ ì„¤ì • ì‚¬ìš© (Phase 1 ë¦¬íŒ©í† ë§)
try:
    QDRANT_URL = get_settings().QDRANT_URL
except ImportError:
    QDRANT_URL = env.get("QDRANT_URL", "http://localhost:6333")
QDRANT_API_KEY = env.get("QDRANT_API_KEY", None)
COLLECTION_NAME = "afo_workflows"

# ë¬¸ì„œ íŒŒì¼ ê²½ë¡œ
WORKFLOW_DOC_PATH = (
    PROJECT_ROOT / "n8n_workflows" / "modularized" / "N8N_WORKFLOW_RAG_DOCUMENTATION.md"
)


def create_workflow_document() -> None:
    """ì›Œí¬í”Œë¡œìš° ë¬¸ì„œ íŒŒì¼ì„ ì½ì–´ì„œ Documentë¡œ ë³€í™˜"""

    if not WORKFLOW_DOC_PATH.exists():
        print(f"âŒ ì›Œí¬í”Œë¡œìš° ë¬¸ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {WORKFLOW_DOC_PATH}")
        sys.exit(1)

    with open(WORKFLOW_DOC_PATH, encoding="utf-8") as f:
        content = f.read()

    return Document(
        page_content=content,
        metadata={
            "source": str(WORKFLOW_DOC_PATH),
            "workflow_id": "ySdajIsal2qX42ws",
            "workflow_name": "Daily Notion Report",
            "type": "workflow_documentation",
            "category": "automation",
            "tags": [
                "n8n",
                "notion",
                "vibecodehub",
                "daily-report",
                "automation",
                "playwright",
            ],
            "created_at": "2025-01-11",
            "updated_at": "2025-01-11",
        },
    )


def add_to_rag() -> None:
    """ì›Œí¬í”Œë¡œìš° ë¬¸ì„œë¥¼ Qdrantì— ì¶”ê°€ (ChromaDB â†’ Qdrant ë§ˆì´ê·¸ë ˆì´ì…˜)"""

    print("ğŸ“š n8n ì›Œí¬í”Œë¡œìš° ì •ë³´ë¥¼ RAG ì‹œìŠ¤í…œì— ì¶”ê°€ ì¤‘...")
    print(f"   ë¬¸ì„œ íŒŒì¼: {WORKFLOW_DOC_PATH}")
    print(f"   Qdrant URL: {QDRANT_URL}")
    print(f"   ì»¬ë ‰ì…˜: {COLLECTION_NAME}")

    # ì„ë² ë”© ìƒì„±
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

    # ì›Œí¬í”Œë¡œìš° ë¬¸ì„œ ìƒì„±
    workflow_doc = create_workflow_document()

    # í…ìŠ¤íŠ¸ ë¶„í•  (í° ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ)
    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents([workflow_doc])

    print(f"   ë¬¸ì„œ ì²­í¬ ìˆ˜: {len(splits)}ê°œ")

    try:
        # Qdrantì— ë¬¸ì„œ ì¶”ê°€ (ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì‚¬ìš©)
        print("\nğŸ“ Qdrantì— ë¬¸ì„œ ì¶”ê°€ ì¤‘...")
        vectorstore = Qdrant.from_documents(
            documents=splits,
            embedding=embeddings,
            url=QDRANT_URL,
            collection_name=COLLECTION_NAME,
            api_key=QDRANT_API_KEY,
            force_recreate=False,  # ê¸°ì¡´ ì»¬ë ‰ì…˜ ìœ ì§€
        )

        print("âœ… ì›Œí¬í”Œë¡œìš° ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ!")
        print(f"   ì»¬ë ‰ì…˜: {COLLECTION_NAME}")
        print(f"   ì¶”ê°€ëœ ì²­í¬: {len(splits)}ê°œ")
        print(f"   Qdrant URL: {QDRANT_URL}")

        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\nğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì¤‘...")
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
        test_queries = [
            "Daily Notion Report ì›Œí¬í”Œë¡œìš°",
            "vibecodehub ì—°ê²° ë°©ë²•",
            "Playwright ìë™í™”",
        ]

        for query in test_queries:
            results = retriever.get_relevant_documents(query)
            if results:
                print(f"   âœ… '{query}': {len(results)}ê°œ ë¬¸ì„œ ë°œê²¬")
            else:
                print(f"   âš ï¸ '{query}': ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

        return vectorstore

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("   Qdrant ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”: docker Union[ps, grep] qdrant")

        traceback.print_exc()
        raise


def verify_workflow_in_rag(vectorstore) -> None:
    """RAGì— ì›Œí¬í”Œë¡œìš°ê°€ ì œëŒ€ë¡œ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ ê²€ì¦"""

    print("\nğŸ” ìµœì¢… ê²€ì¦ ì¤‘...")

    retriever = vectorstore.as_retriever(search_kwargs={"k": 1})

    # í•µì‹¬ ê²€ìƒ‰ì–´ë¡œ í…ŒìŠ¤íŠ¸
    verification_queries = [
        "Daily Notion Report",
        "ySdajIsal2qX42ws",
        "Notion Query Vibecodehub",
        "n8n API ì—…ë°ì´íŠ¸",
    ]

    success_count = 0
    for query in verification_queries:
        try:
            results = retriever.get_relevant_documents(query)
            if results and len(results) > 0:
                doc = results[0]
                if (
                    "ySdajIsal2qX42ws" in doc.page_content
                    or "Daily Notion Report" in doc.page_content
                ):
                    success_count += 1
                    print(f"   âœ… '{query}': ê²€ìƒ‰ ì„±ê³µ")
                else:
                    print(f"   âš ï¸ '{query}': ê²€ìƒ‰ ê²°ê³¼ ìˆìœ¼ë‚˜ ê´€ë ¨ì„± ë‚®ìŒ")
            else:
                print(f"   âŒ '{query}': ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        except Exception as e:
            print(f"   âŒ '{query}': ì˜¤ë¥˜ - {e}")

    print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼: {success_count}/{len(verification_queries)} ì„±ê³µ")

    if success_count >= len(verification_queries) * 0.75:  # 75% ì´ìƒ ì„±ê³µ
        print("âœ… RAG ì‹œìŠ¤í…œì— ì›Œí¬í”Œë¡œìš° ì •ë³´ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return True
    else:
        print("âš ï¸ ì¼ë¶€ ê²€ìƒ‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")
        return False


def main() -> None:
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        print("=" * 60)
        print("n8n ì›Œí¬í”Œë¡œìš° RAG ì¶”ê°€ ë° ê²€ì¦")
        print("=" * 60)

        # 1. RAGì— ì¶”ê°€
        vectorstore = add_to_rag()

        # 2. ê²€ì¦
        success = verify_workflow_in_rag(vectorstore)

        print("\n" + "=" * 60)
        if success:
            print("âœ… ì™„ë£Œ! ì´ì œ RAG ì‹œìŠ¤í…œì—ì„œ ì›Œí¬í”Œë¡œìš° ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            print("\nì‚¬ìš© ì˜ˆì‹œ:")
            print("  - 'Daily Notion Report ì›Œí¬í”Œë¡œìš°ëŠ” ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?'")
            print("  - 'vibecodehub ì—°ê²° ë°©ë²•ì€?'")
            print("  - 'n8n ë…¸ë“œ ì„¤ì •ì„ Playwrightë¡œ ìë™í™”í•˜ë ¤ë©´?'")
        else:
            print("âš ï¸ ì™„ë£Œë˜ì—ˆì§€ë§Œ ì¼ë¶€ ê²€ì¦ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("=" * 60)

        return 0 if success else 1

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
