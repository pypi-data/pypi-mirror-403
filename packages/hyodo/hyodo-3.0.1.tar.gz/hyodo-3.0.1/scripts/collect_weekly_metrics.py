#!/usr/bin/env python3
"""
AFO Kingdom Weekly Metrics Collector

ì˜ì–´ ë¹„ìœ¨, SSOT ìœ„ë°˜, Chaos í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­ì„ ì£¼ê°„ ë‹¨ìœ„ë¡œ ìˆ˜ì§‘í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
Context7ê³¼ í†µí•©í•˜ì—¬ ê¸°ì¡´ ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œê³¼ ì—°ê²°í•©ë‹ˆë‹¤.
"""

import json
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def get_current_week_info() -> dict[str, str]:
    """í˜„ì¬ ì£¼ ì •ë³´ ë°˜í™˜"""
    today = datetime.now()
    # ISO ì£¼ ë²ˆí˜¸ ê³„ì‚° (ì›”ìš”ì¼ ì‹œì‘)
    year, week_num, _ = today.isocalendar()

    # ì£¼ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ê³„ì‚° (ì›”ìš”ì¼ ~ ì¼ìš”ì¼)
    monday = today - timedelta(days=today.weekday())
    sunday = monday + timedelta(days=6)

    return {
        "week": f"{year:04d}-W{week_num:02d}",
        "start": monday.strftime("%Y-%m-%d"),
        "end": sunday.strftime("%Y-%m-%d"),
        "year": str(year),
        "week_num": f"{week_num:02d}",
    }


def collect_english_ratio_metrics() -> dict[str, Any]:
    """ì˜ì–´ ë¹„ìœ¨ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    # CI ë¡œê·¸ì—ì„œ ì˜ì–´ ë¹„ìœ¨ ê²½ê³  ìˆ˜ì§‘
    english_warnings = []

    # GitHub Actions ë¡œê·¸ ë””ë ‰í† ë¦¬ì—ì„œ ê²€ìƒ‰
    logs_dir = project_root / ".github" / "workflows" / "logs"
    if logs_dir.exists():
        for log_file in logs_dir.glob("*.log"):
            with Path(log_file).open(encoding="utf-8", errors="ignore") as f:
                content = f.read()
                if "English-heavy report detected" in content:
                    english_warnings.append(log_file.name)

    return {
        "total_warnings": len(english_warnings),
        "warning_files": english_warnings[:10],  # ìµœê·¼ 10ê°œë§Œ
        "trend": "monitoring",  # ì¶”ì„¸ ë¶„ì„ì€ ë‹¤ìŒ ë²„ì „ì—ì„œ
    }


def collect_ssot_violation_metrics() -> dict[str, Any]:
    """SSOT ìœ„ë°˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    violations = []

    # CI ë¡œê·¸ì—ì„œ SSOT ìœ„ë°˜ ìˆ˜ì§‘
    logs_dir = project_root / ".github" / "workflows" / "logs"
    if logs_dir.exists():
        for log_file in logs_dir.glob("*.log"):
            with Path(log_file).open(encoding="utf-8", errors="ignore") as f:
                content = f.read()
                if "SSOT violation detected" in content or "Report gate failed" in content:
                    violations.append(log_file.name)

    return {
        "total_violations": len(violations),
        "violation_files": violations[:10],  # ìµœê·¼ 10ê°œë§Œ
        "compliance_rate": max(
            0, 1 - (len(violations) / max(1, len(list(logs_dir.glob("*.log")))))
        ),
        "trend": "monitoring",
    }


def collect_chaos_test_metrics() -> dict[str, Any]:
    """Chaos í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    chaos_results = []

    # Nightly Chaos Lite ì›Œí¬í”Œë¡œìš° ê²°ê³¼ ìˆ˜ì§‘
    workflow_dir = project_root / ".github" / "workflows"
    chaos_log_pattern = "nightly-chaos-lite-*"

    for log_file in workflow_dir.glob(f"{chaos_log_pattern}.log"):
        with Path(log_file).open(encoding="utf-8", errors="ignore") as f:
            content = f.read()
            success = (
                "Chaos #1 - kill one pod (expect self-heal)" in content and "SUCCESS" in content
            )
            chaos_results.append(
                {
                    "date": log_file.stat().st_mtime,
                    "success": success,
                    "log_file": log_file.name,
                }
            )

    success_count = sum(1 for r in chaos_results if r["success"])
    total_count = len(chaos_results)

    return {
        "total_runs": total_count,
        "success_count": success_count,
        "success_rate": success_count / max(1, total_count),
        "recent_results": chaos_results[-7:],  # ìµœê·¼ 7ì¼
        "trend": "stable" if success_count >= total_count * 0.8 else "needs_attention",
    }


def generate_weekly_report(week_info: dict[str, str], metrics: dict[str, Any]) -> str:
    """ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± (Markdown)"""
    return f"""# AFO Kingdom Weekly Metrics Report - {week_info["week"]}

**ê¸°ê°„**: {week_info["start"]} ~ {week_info["end"]}

## ğŸ“Š ë©”íŠ¸ë¦­ ìš”ì•½

### ì˜ì–´ ë¹„ìœ¨ ê²½ê³ 
- **ì´ ê²½ê³  ìˆ˜**: {metrics["english_ratio"]["total_warnings"]}
- **ì¶”ì„¸**: {metrics["english_ratio"]["trend"]}

### SSOT ì¤€ìˆ˜ìœ¨
- **ìœ„ë°˜ ê±´ìˆ˜**: {metrics["ssot_violations"]["total_violations"]}
- **ì¤€ìˆ˜ìœ¨**: {metrics["ssot_violations"]["compliance_rate"]:.1%}
- **ì¶”ì„¸**: {metrics["ssot_violations"]["trend"]}

### Chaos í…ŒìŠ¤íŠ¸ ì•ˆì •ì„±
- **ì´ ì‹¤í–‰ íšŸìˆ˜**: {metrics["chaos_tests"]["total_runs"]}
- **ì„±ê³µë¥ **: {metrics["chaos_tests"]["success_rate"]:.1%}
- **ì¶”ì„¸**: {metrics["chaos_tests"]["trend"]}

## ğŸ“ˆ ìƒì„¸ ë¶„ì„

### ì˜ì–´ ë¹„ìœ¨ ê²½ê³  ë‚´ì—­
{chr(10).join(f"- {f}" for f in metrics["english_ratio"]["warning_files"]) if metrics["english_ratio"]["warning_files"] else "- ê²½ê³  ì—†ìŒ"}

### SSOT ìœ„ë°˜ ë‚´ì—­
{chr(10).join(f"- {f}" for f in metrics["ssot_violations"]["violation_files"]) if metrics["ssot_violations"]["violation_files"] else "- ìœ„ë°˜ ì—†ìŒ"}

### Chaos í…ŒìŠ¤íŠ¸ ê²°ê³¼
{chr(10).join(f"- {r['log_file']}: {'âœ…' if r['success'] else 'âŒ'}" for r in metrics["chaos_tests"]["recent_results"]) if metrics["chaos_tests"]["recent_results"] else "- í…ŒìŠ¤íŠ¸ ê¸°ë¡ ì—†ìŒ"}

---

*ìë™ ìƒì„±ëœ ë³´ê³ ì„œ - {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""


def save_metrics(week_info: dict[str, str], metrics: dict[str, Any]) -> None:
    """ë©”íŠ¸ë¦­ì„ JSONê³¼ Markdownìœ¼ë¡œ ì €ì¥"""
    metrics_dir = project_root / "docs" / "reports" / "_metrics"

    # JSON ì €ì¥
    json_data = {
        "week": week_info["week"],
        "period": {"start": week_info["start"], "end": week_info["end"]},
        "metrics": metrics,
        "generated_at": datetime.now().isoformat(),
    }

    json_file = metrics_dir / f"weekly_metrics_{week_info['week']}.json"
    with Path(json_file).open("w", encoding="utf-8") as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)

    # Markdown ë³´ê³ ì„œ ì €ì¥
    md_report = generate_weekly_report(week_info, metrics)
    md_file = metrics_dir / f"weekly_report_{week_info['week']}.md"
    with Path(md_file).open("w", encoding="utf-8") as f:
        f.write(md_report)

    print(f"âœ… ë©”íŠ¸ë¦­ ì €ì¥ ì™„ë£Œ: {json_file}")
    print(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {md_file}")


def main() -> None:
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ AFO Kingdom Weekly Metrics Collector ì‹œì‘")

    try:
        # ì£¼ ì •ë³´ ìˆ˜ì§‘
        week_info = get_current_week_info()
        print(f"ğŸ“… ëŒ€ìƒ ì£¼: {week_info['week']} ({week_info['start']} ~ {week_info['end']})")

        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        metrics = {
            "english_ratio": collect_english_ratio_metrics(),
            "ssot_violations": collect_ssot_violation_metrics(),
            "chaos_tests": collect_chaos_test_metrics(),
        }

        print("ğŸ“Š ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì™„ë£Œ")
        print(f"  - ì˜ì–´ ê²½ê³ : {metrics['english_ratio']['total_warnings']}ê±´")
        print(f"  - SSOT ìœ„ë°˜: {metrics['ssot_violations']['total_violations']}ê±´")
        print(f"  - Chaos ì„±ê³µë¥ : {metrics['chaos_tests']['success_rate']:.1%}")

        # ì €ì¥
        save_metrics(week_info, metrics)

        print("âœ… ì£¼ê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥ ì™„ë£Œ")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
