#!/usr/bin/env python3
"""
Context7 ë¡œì»¬ ê²€ìƒ‰ê¸° - AFO Kingdom ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰
ì™¸ë¶€ Context7 ëŒ€ì‹  ë¡œì»¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬
"""

import json
from pathlib import Path
from typing import Optional

DOCS_PATH = Path("data/context7_local/afo_kingdom_docs.json")


def load_docs() -> dict:
    """ë¬¸ì„œ ë¡œë“œ"""
    if not DOCS_PATH.exists():
        return {}
    with open(DOCS_PATH) as f:
        return json.load(f)


def search(query: str, topic: Optional[str] = None) -> dict:
    """
    AFO Kingdom ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰

    Args:
        query: ê²€ìƒ‰ì–´
        topic: íŠ¹ì • í† í”½ (onboarding, architecture, api, cache_dna, phase_history, mcp_servers, banana_philosophy, quick_start)

    Returns:
        ê²€ìƒ‰ ê²°ê³¼
    """
    docs = load_docs()
    if not docs:
        return {"error": "ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

    results = []
    query_lower = query.lower()

    topics = docs.get("topics", {})

    # íŠ¹ì • í† í”½ ê²€ìƒ‰
    if topic and topic in topics:
        t = topics[topic]
        results.append(
            {
                "topic": topic,
                "title": t["title"],
                "content": t["content"],
                "keywords": t["keywords"],
                "relevance": 1.0,
            }
        )
    else:
        # ì „ì²´ ê²€ìƒ‰
        for topic_id, t in topics.items():
            # í‚¤ì›Œë“œ ë§¤ì¹­
            keyword_match = any(
                kw.lower() in query_lower or query_lower in kw.lower()
                for kw in t.get("keywords", [])
            )
            # ë‚´ìš© ë§¤ì¹­
            content_match = query_lower in t.get("content", "").lower()
            # ì œëª© ë§¤ì¹­
            title_match = query_lower in t.get("title", "").lower()

            if keyword_match or content_match or title_match:
                relevance = 0.0
                if title_match:
                    relevance += 0.5
                if keyword_match:
                    relevance += 0.3
                if content_match:
                    relevance += 0.2

                results.append(
                    {
                        "topic": topic_id,
                        "title": t["title"],
                        "content": t["content"],
                        "keywords": t["keywords"],
                        "relevance": relevance,
                    }
                )

    # ê´€ë ¨ë„ ìˆœ ì •ë ¬
    results.sort(key=lambda x: -x["relevance"])

    return {
        "library": docs.get("name", "AFO Kingdom"),
        "version": docs.get("version", "Unknown"),
        "query": query,
        "results": results[:5],  # ìƒìœ„ 5ê°œ
        "total": len(results),
        "code_snippets": docs.get("code_snippets", []) if not results else [],
    }


def get_topic(topic: str) -> dict:
    """íŠ¹ì • í† í”½ ê°€ì ¸ì˜¤ê¸°"""
    docs = load_docs()
    topics = docs.get("topics", {})

    if topic in topics:
        return {"success": True, "topic": topic, "data": topics[topic]}

    return {"success": False, "available_topics": list(topics.keys())}


def list_topics() -> list:
    """ì‚¬ìš© ê°€ëŠ¥í•œ í† í”½ ëª©ë¡"""
    docs = load_docs()
    return list(docs.get("topics", {}).keys())


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python context7_local_search.py <ê²€ìƒ‰ì–´>")
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ í† í”½:")
        for t in list_topics():
            print(f"  - {t}")
        sys.exit(1)

    query = " ".join(sys.argv[1:])
    result = search(query)

    print(f"ğŸ” ê²€ìƒ‰: '{query}'")
    print(f"ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬: {result['library']} ({result['version']})")
    print(f"ğŸ“Š ê²°ê³¼: {result['total']}ê°œ\n")

    for r in result["results"]:
        print(f"--- [{r['topic']}] {r['title']} (ê´€ë ¨ë„: {r['relevance']:.1f}) ---")
        print(f"   {r['content'][:200]}...")
        print(f"   í‚¤ì›Œë“œ: {', '.join(r['keywords'])}\n")
