#!/usr/bin/env python3
"""
AFO ì™•êµ­ AI ê¸°ë°˜ ìë™ ë””ë²„ê¹… ì‹œìŠ¤í…œ ì—°êµ¬
ë¨¸ì‹ ëŸ¬ë‹ì„ í™œìš©í•œ ìŠ¤ë§ˆíŠ¸í•œ ì˜¤ë¥˜ ìˆ˜ì •
"""

import re
from collections import defaultdict
from typing import Any, Dict, List, Optional


class AIPoweredDebugger:
    """AI ê¸°ë°˜ ìë™ ë””ë²„ê¹… ì‹œìŠ¤í…œ"""

    def __init__(self) -> None:
        self.error_patterns = self._load_error_patterns()
        self.success_patterns = self._load_success_patterns()
        self.ml_model = self._initialize_ml_model()

    def _load_error_patterns(self) -> Dict[str, List[Dict[str, Any]]]:
        """í•™ìŠµëœ ì˜¤ë¥˜ íŒ¨í„´ ë¡œë“œ"""
        return {
            "undefined_variable": [
                {
                    "pattern": r"request\.",
                    "context": "async function",
                    "solution": "add_request_parameter",
                    "confidence": 0.95,
                },
                {
                    "pattern": r"(\w+)\.(\w+)",
                    "context": "undefined",
                    "solution": "check_import",
                    "confidence": 0.85,
                },
            ],
            "type_mismatch": [
                {
                    "pattern": r"AsyncGenerator.*dict",
                    "context": "return type",
                    "solution": "fix_async_generator_type",
                    "confidence": 0.90,
                }
            ],
            "import_error": [
                {
                    "pattern": r"could not be resolved",
                    "context": "import",
                    "solution": "suggest_import",
                    "confidence": 0.80,
                }
            ],
        }

    def _load_success_patterns(self) -> Dict[str, List[str]]:
        """ì„±ê³µí•œ ìˆ˜ì • íŒ¨í„´ ë¡œë“œ"""
        return {
            "request_parameter": [
                "async def function(request: Request):",
                "from fastapi import Request",
            ],
            "async_generator_type": [
                "-> AsyncGenerator[dict[str, Any], None]",
                "from typing import AsyncGenerator, Any",
            ],
        }

    def _initialize_ml_model(self) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ ML ëª¨ë¸ ì´ˆê¸°í™” (ë£° ê¸°ë°˜)"""
        return {
            "patterns": defaultdict(int),
            "success_rate": defaultdict(float),
            "context_weights": {
                "async": 1.2,
                "import": 1.1,
                "type": 1.0,
                "function": 0.9,
            },
        }

    def analyze_error_with_ai(self, error: Dict[str, Any]) -> Dict[str, Any]:
        """AIë¥¼ í™œìš©í•œ ì˜¤ë¥˜ ë¶„ì„"""
        error_type = error.get("type", "")
        message = error.get("message", "")
        file_path = error.get("file", "")

        # ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        context = self._analyze_context(file_path, error.get("line", 0))

        # íŒ¨í„´ ë§¤ì¹­
        matches = self._find_pattern_matches(error_type, message, context)

        # ML ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°
        best_match = self._select_best_solution(matches, context)

        return {
            "error": error,
            "context": context,
            "matches": matches,
            "best_solution": best_match,
            "confidence": best_match.get("confidence", 0) if best_match else 0,
            "ai_reasoning": self._generate_reasoning(best_match, context),
        }

    def _analyze_context(self, file_path: str, line_no: int) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        context = {
            "file_type": "unknown",
            "function_type": "unknown",
            "imports": [],
            "nearby_code": [],
        }

        try:
            with open(file_path, "r") as f:
                lines = f.readlines()

            # íŒŒì¼ íƒ€ì… ë¶„ì„
            if any("fastapi" in line for line in lines[:20]):
                context["file_type"] = "fastapi_router"
            elif any("async def" in line for line in lines):
                context["file_type"] = "async_module"

            # í•¨ìˆ˜ íƒ€ì… ë¶„ì„
            for i in range(max(0, line_no - 5), min(len(lines), line_no + 5)):
                line = lines[i].strip()
                if "async def" in line:
                    context["function_type"] = "async_function"
                    break
                elif "def " in line:
                    context["function_type"] = "sync_function"
                    break

            # import ë¶„ì„
            context["imports"] = [
                line.strip() for line in lines[:30] if line.strip().startswith(("import", "from"))
            ]

            # ì£¼ë³€ ì½”ë“œ
            context["nearby_code"] = [
                lines[i].strip() for i in range(max(0, line_no - 3), min(len(lines), line_no + 3))
            ]

        except Exception as e:
            context["error"] = str(e)

        return context

    def _find_pattern_matches(
        self, error_type: str, message: str, context: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """íŒ¨í„´ ë§¤ì¹­ ìˆ˜í–‰"""
        matches = []

        patterns = self.error_patterns.get(error_type, [])

        for pattern in patterns:
            if re.search(pattern["pattern"], message):
                # ì»¨í…ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ì ìš©
                confidence = pattern["confidence"]
                context_multiplier = 1.0

                if pattern["context"] in context.get("function_type", ""):
                    context_multiplier = 1.3
                elif pattern["context"] in context.get("file_type", ""):
                    context_multiplier = 1.2

                matches.append(
                    {
                        **pattern,
                        "adjusted_confidence": confidence * context_multiplier,
                        "context_match": pattern["context"] in str(context),
                    }
                )

        return sorted(matches, key=lambda x: x.get("adjusted_confidence", 0), reverse=True)

    def _select_best_solution(
        self, matches: List[Dict[str, Any]], context: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """ìµœì  ì†”ë£¨ì…˜ ì„ íƒ"""
        if not matches:
            return None

        # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ì†”ë£¨ì…˜ ì„ íƒ
        best_match = max(matches, key=lambda x: x.get("adjusted_confidence", 0))

        # ML ëª¨ë¸ ê¸°ë°˜ ì¶”ê°€ ê²€ì¦
        if self._ml_validation(best_match, context):
            return best_match

        return None

    def _ml_validation(self, solution: Dict[str, Any], context: Dict[str, Any]) -> bool:
        """ML ê¸°ë°˜ ì†”ë£¨ì…˜ ê²€ì¦"""
        solution_type = solution.get("solution", "")

        # ì„±ê³µ íŒ¨í„´ í™•ì¸
        _success_patterns = self.success_patterns.get(solution_type, [])

        # ì»¨í…ìŠ¤íŠ¸ ì¼ì¹˜ë„ í™•ì¸
        context_score = 0
        for key, weight in self.ml_model["context_weights"].items():
            if key in str(context).lower():
                context_score += weight

        # ì„±ê³µë¥  ê¸°ë°˜ ìµœì¢… ê²°ì •
        success_rate = self.ml_model["success_rate"].get(solution_type, 0.5)

        return (context_score > 1.5) and (success_rate > 0.7)

    def _generate_reasoning(
        self, solution: Optional[Dict[str, Any]], context: Dict[str, Any]
    ) -> str:
        """AI ì¶”ë¡  ê²°ê³¼ ìƒì„±"""
        if not solution:
            return "ì í•©í•œ ì†”ë£¨ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        reasoning = f"íŒ¨í„´ '{solution.get('pattern', '')}'ì´ ì˜¤ë¥˜ ë©”ì‹œì§€ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤. "
        reasoning += f"ì»¨í…ìŠ¤íŠ¸ '{solution.get('context', '')}'ê°€ "
        reasoning += f"{context.get('function_type', 'unknown')}ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤. "
        reasoning += ".2f"

        return reasoning

    def apply_ai_solution(self, analysis: Dict[str, Any]) -> bool:
        """AI ì†”ë£¨ì…˜ ì ìš©"""
        solution = analysis.get("best_solution")
        error = analysis.get("error")

        if not solution or analysis.get("confidence", 0) < 0.8:
            return False

        solution_type = solution.get("solution")

        # ì†”ë£¨ì…˜ íƒ€ì…ë³„ ì ìš©
        if solution_type == "add_request_parameter":
            return self._apply_add_request_parameter(error)
        elif solution_type == "fix_async_generator_type":
            return self._apply_fix_async_generator_type(error)
        elif solution_type == "suggest_import":
            return self._apply_suggest_import(error)

        return False

    def _apply_add_request_parameter(self, error: Dict[str, Any]) -> bool:
        """request íŒŒë¼ë¯¸í„° ì¶”ê°€ ì ìš© (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)"""
        file_path = error.get("file", "")
        line_no = error.get("line", 0)

        try:
            with open(file_path, "r") as f:
                lines = f.readlines()

            # í•¨ìˆ˜ ì •ì˜ ì°¾ê¸° ë° ìˆ˜ì •
            for i in range(max(0, line_no - 10), min(len(lines), line_no + 10)):
                line = lines[i]
                if "async def" in line and "(" in line and ")" in line:
                    if "request" not in line:
                        # request íŒŒë¼ë¯¸í„° ì¶”ê°€
                        paren_idx = line.find("(")
                        next_paren_idx = line.find(")", paren_idx)
                        if next_paren_idx > paren_idx:
                            params = line[paren_idx + 1 : next_paren_idx]
                            if params.strip():
                                new_params = f"request: Request, {params}"
                            else:
                                new_params = "request: Request"
                            lines[i] = line[: paren_idx + 1] + new_params + line[next_paren_idx:]

                            # FastAPI Request import í™•ì¸ ë° ì¶”ê°€
                            self._ensure_import(lines, "from fastapi import Request")

                            with open(file_path, "w") as f:
                                f.writelines(lines)
                            return True
        except Exception:
            pass
        return False

    def _apply_fix_async_generator_type(self, error: Dict[str, Any]) -> bool:
        """AsyncGenerator íƒ€ì… ìˆ˜ì • ì ìš©"""
        file_path = error.get("file", "")
        line_no = error.get("line", 0)

        try:
            with open(file_path, "r") as f:
                lines = f.readlines()

            # ë¦¬í„´ íƒ€ì… ìˆ˜ì •
            for i in range(max(0, line_no - 5), min(len(lines), line_no + 5)):
                line = lines[i]
                if "-> dict" in line and "async def" in line:
                    lines[i] = line.replace("-> dict", "-> AsyncGenerator[dict[str, Any], None]")

                    # AsyncGenerator import í™•ì¸ ë° ì¶”ê°€
                    self._ensure_import(lines, "from typing import AsyncGenerator, Any")

                    with open(file_path, "w") as f:
                        f.writelines(lines)
                    return True
        except Exception:
            pass
        return False

    def _apply_suggest_import(self, error: Dict[str, Any]) -> bool:
        """import ì œì•ˆ ë° ì ìš©"""
        message = error.get("message", "")

        # ì˜¤ë¥˜ ë©”ì‹œì§€ì—ì„œ ëª¨ë“ˆ ì´ë¦„ ì¶”ì¶œ
        if "sse_starlette" in message:
            return self._add_import(
                error.get("file", ""),
                "from sse_starlette.sse import EventSourceResponse",
            )
        elif "redis" in message:
            return self._add_import(error.get("file", ""), "import redis.asyncio as redis")

        return False

    def _ensure_import(self, lines: List[str], import_statement: str) -> None:
        """import ë¬¸ì´ ì—†ìœ¼ë©´ ì¶”ê°€"""
        for line in lines:
            if import_statement in line:
                return  # ì´ë¯¸ ì¡´ì¬í•¨

        # ì ì ˆí•œ ìœ„ì¹˜ì— ì¶”ê°€
        for i, line in enumerate(lines):
            if line.strip().startswith(("import", "from")):
                continue
            elif line.strip() and not line.strip().startswith("#"):
                lines.insert(i, import_statement + "\n")
                break

    def _add_import(self, file_path: str, import_statement: str) -> bool:
        """íŒŒì¼ì— import ë¬¸ ì¶”ê°€"""
        try:
            with open(file_path, "r") as f:
                lines = f.readlines()

            self._ensure_import(lines, import_statement)

            with open(file_path, "w") as f:
                f.writelines(lines)
            return True
        except Exception:
            return False

    def learn_from_feedback(self, analysis: Dict[str, Any], success: bool) -> None:
        """í”¼ë“œë°±ìœ¼ë¡œë¶€í„° í•™ìŠµ"""
        solution = analysis.get("best_solution", {})
        solution_type = solution.get("solution", "")

        # ì„±ê³µë¥  ì—…ë°ì´íŠ¸
        current_rate = self.ml_model["success_rate"].get(solution_type, 0.5)
        self.ml_model["success_rate"][solution_type] = (
            current_rate + (1.0 if success else 0.0)
        ) / 2


def main() -> None:
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    debugger = AIPoweredDebugger()

    print("ğŸ¤– AFO ì™•êµ­ AI ê¸°ë°˜ ìë™ ë””ë²„ê¹… ì‹œìŠ¤í…œ ì—°êµ¬\n")

    # ìƒ˜í”Œ ì˜¤ë¥˜ë“¤ë¡œ í…ŒìŠ¤íŠ¸
    sample_errors = [
        {
            "type": "undefined_variable",
            "message": '"request" is not defined',
            "file": "packages/afo-core/api/routers/debugging.py",
            "line": 42,
        },
        {
            "type": "type_mismatch",
            "message": "AsyncGenerator type mismatch",
            "file": "packages/afo-core/api/routers/debugging.py",
            "line": 14,
        },
    ]

    print("ğŸ§  AI ê¸°ë°˜ ì˜¤ë¥˜ ë¶„ì„ ì‹¤í–‰\n")

    successful_fixes = 0

    for i, error in enumerate(sample_errors, 1):
        print(f"{i}. ì˜¤ë¥˜ ë¶„ì„: {error.get('message', '')}")

        # AI ë¶„ì„
        analysis = debugger.analyze_error_with_ai(error)

        print(f"   AI ì¶”ë¡ : {analysis.get('ai_reasoning', '')}")
        print(f"   ì‹ ë¢°ë„: {analysis.get('confidence', 0):.2f}")  # ì†”ë£¨ì…˜ ì ìš©
        if analysis.get("confidence", 0) > 0.8:
            success = debugger.apply_ai_solution(analysis)
            if success:
                successful_fixes += 1
                print("   âœ… ìë™ ìˆ˜ì • ì ìš© ì„±ê³µ")
            else:
                print("   âŒ ìë™ ìˆ˜ì • ì ìš© ì‹¤íŒ¨")
        else:
            print("   âš ï¸ ì‹ ë¢°ë„ê°€ ë‚®ì•„ ìˆ˜ë™ ê²€í†  í•„ìš”")

        print()

        # í•™ìŠµ
        debugger.learn_from_feedback(analysis, success if "success" in locals() else False)

    print("ğŸ“Š AI ë””ë²„ê¹… ì—°êµ¬ ê²°ê³¼:")
    print(f"   ë¶„ì„ëœ ì˜¤ë¥˜: {len(sample_errors)}ê°œ")
    print(f"   ìë™ ìˆ˜ì • ì„±ê³µ: {successful_fixes}ê°œ")
    print(
        f"   AI ëª¨ë¸ ì •í™•ë„: í‰ê·  {(sum(debugger.ml_model['success_rate'].values()) / len(debugger.ml_model['success_rate']) * 100):.1f}%"
    )

    print("\nğŸ”® í–¥í›„ ë°œì „ ë°©í–¥:")
    print("1. ë” í° ë°ì´í„°ì…‹ìœ¼ë¡œ íŒ¨í„´ í•™ìŠµ")
    print("2. ë”¥ëŸ¬ë‹ ëª¨ë¸ ì ìš©ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ")
    print("3. ìì—°ì–´ ì²˜ë¦¬ë¡œ ì˜¤ë¥˜ ë©”ì‹œì§€ ì´í•´ í–¥ìƒ")
    print("4. ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ìœ¼ë¡œ ë” ì •í™•í•œ ìˆ˜ì •")
    print("5. ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ì§€ì† í•™ìŠµ")

    print("\nâœ… AI ê¸°ë°˜ ìë™ ë””ë²„ê¹… ì‹œìŠ¤í…œ ì—°êµ¬ ì™„ë£Œ")


if __name__ == "__main__":
    main()
