#!/usr/bin/env python3
"""
AFO ì™•êµ­ Sequential Thinking ë¡œê·¸ ë¶„ì„ê¸°
ê° ë¡œê·¸ ì²­í¬ë¥¼ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•˜ì—¬ ê·¼ë³¸ ì›ì¸ê³¼ í•´ê²° ì „ëµì„ ì œì‹œ

Sequential Thinking ë‹¨ê³„:
1. ì—ëŸ¬ íŒ¨í„´ ì‹ë³„ (Pattern Recognition)
2. ê·¼ë³¸ ì›ì¸ ì¶”ì  (Root Cause Analysis)
3. ì˜í–¥ ë²”ìœ„ í‰ê°€ (Impact Assessment)
4. í•´ê²° ìš°ì„ ìˆœìœ„ ê²°ì • (Priority Setting)
5. ìˆ˜ì • ì „ëµ ì œì•ˆ (Solution Strategy)
"""

import json
import os
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Union


@dataclass
class SequentialAnalysis:
    """Sequential Thinking ë¶„ì„ ê²°ê³¼"""

    chunk_id: str
    step_1_patterns: List[str]  # ì—ëŸ¬ íŒ¨í„´ ì‹ë³„
    step_2_root_causes: List[str]  # ê·¼ë³¸ ì›ì¸ ì¶”ì 
    step_3_impacts: Dict[str, Any]  # ì˜í–¥ ë²”ìœ„ í‰ê°€
    step_4_priorities: Dict[str, str]  # í•´ê²° ìš°ì„ ìˆœìœ„
    step_5_solutions: List[str]  # ìˆ˜ì • ì „ëµ ì œì•ˆ
    confidence_score: float  # ë¶„ì„ ì‹ ë¢°ë„ (0-1)


class SequentialAnalyzer:
    """Sequential Thinking ê¸°ë°˜ ë¡œê·¸ ë¶„ì„ê¸°"""

    def __init__(self, chunks_dir: str = "log_chunks") -> None:
        self.chunks_dir = Path(chunks_dir)
        self.analyses: List[SequentialAnalysis] = []

    def load_chunk(self, chunk_file: str) -> Dict[str, Any]:
        """ì²­í¬ íŒŒì¼ ë¡œë“œ"""
        with open(self.chunks_dir / chunk_file, "r", encoding="utf-8") as f:
            return json.load(f)

    def step_1_identify_patterns(self, lines: List[str]) -> List[str]:
        """ë‹¨ê³„ 1: ì—ëŸ¬ íŒ¨í„´ ì‹ë³„"""
        patterns = []

        # Python Syntax ì—ëŸ¬ íŒ¨í„´
        syntax_patterns = [
            "Expected an indented block",
            "invalid-syntax",
            "Simple statements must be separated",
            "Expected.*newline",
            "Expected.*semicolon",
        ]

        # Import ì—ëŸ¬ íŒ¨í„´
        import_patterns = [
            "is not defined",
            "ImportError",
            "Module level import not at top",
        ]

        # í˜¸í™˜ì„± ì—ëŸ¬ íŒ¨í„´
        compatibility_patterns = [
            "Union.*not defined",
            "Optional.*not defined",
            "TypeVar.*not defined",
        ]

        for line in lines:
            for pattern in syntax_patterns + import_patterns + compatibility_patterns:
                if pattern.lower() in line.lower():
                    if pattern not in patterns:
                        patterns.append(pattern)

        return patterns

    def step_2_trace_root_causes(self, patterns: List[str], lines: List[str]) -> List[str]:
        """ë‹¨ê³„ 2: ê·¼ë³¸ ì›ì¸ ì¶”ì """
        root_causes = []

        # íŒ¨í„´ ê¸°ë°˜ ê·¼ë³¸ ì›ì¸ ë¶„ì„
        if any("indented block" in p for p in patterns):
            root_causes.append("Python í˜¸í™˜ì„± ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨ - ë“¤ì—¬ì“°ê¸° ê·œì¹™ ë³€ê²½")

        if any("not defined" in p for p in patterns):
            # Union/Optional import ëˆ„ë½ í™•ì¸
            union_errors = [line for line in lines if "Union" in line and "not defined" in line]
            optional_errors = [
                line for line in lines if "Optional" in line and "not defined" in line
            ]

            if union_errors or optional_errors:
                root_causes.append("typing ëª¨ë“ˆ import ëˆ„ë½ - Python 3.9+ í˜¸í™˜ì„± ë¬¸ì œ")

        if any("invalid-syntax" in p for p in patterns):
            root_causes.append("êµ¬ë¬¸ ë³€í™˜ ì‹¤íŒ¨ - Union Syntax â†’ í˜¸í™˜ì„± ì½”ë“œ ë³€í™˜ ì˜¤ë¥˜")

        if any("Module level import" in p for p in patterns):
            root_causes.append("import ìˆœì„œ ë³€ê²½ - Python ì‹¤í–‰ ìˆœì„œ ë³€ê²½ìœ¼ë¡œ ì¸í•œ import ìœ„ì¹˜ ì˜¤ë¥˜")

        return root_causes

    def step_3_assess_impacts(self, patterns: List[str], lines: List[str]) -> Dict[str, Any]:
        """ë‹¨ê³„ 3: ì˜í–¥ ë²”ìœ„ í‰ê°€"""
        impacts = {
            "severity": "UNKNOWN",
            "affected_files": 0,
            "affected_lines": len(lines),
            "blocking_deployment": False,
            "affects_core_functionality": False,
        }

        # ì‹¬ê°ë„ í‰ê°€
        critical_patterns = ["Expected an indented block", "invalid-syntax"]
        high_patterns = ["is not defined", "ImportError"]

        if any(p in str(patterns) for p in critical_patterns):
            impacts["severity"] = "CRITICAL"
            impacts["blocking_deployment"] = True
            impacts["affects_core_functionality"] = True
        elif any(p in str(patterns) for p in high_patterns):
            impacts["severity"] = "HIGH"
            impacts["blocking_deployment"] = True

        # íŒŒì¼ ì˜í–¥ ë²”ìœ„ ê³„ì‚°
        file_paths = set()
        for line in lines:
            # íŒŒì¼ ê²½ë¡œ íŒ¨í„´ ì°¾ê¸°
            import re

            file_match = re.search(r"./([^:]+):", line)
            if file_match:
                file_paths.add(file_match.group(1))

        impacts["affected_files"] = len(file_paths)

        return impacts

    def step_4_set_priorities(self, impacts: Dict[str, Any]) -> Dict[str, str]:
        """ë‹¨ê³„ 4: í•´ê²° ìš°ì„ ìˆœìœ„ ê²°ì •"""
        priorities = {
            "immediate_action": "LOW",
            "timeframe": "days",
            "resources_needed": "minimal",
            "risk_level": "low",
        }

        if impacts["severity"] == "CRITICAL":
            priorities.update(
                {
                    "immediate_action": "CRITICAL",
                    "timeframe": "hours",
                    "resources_needed": "immediate attention",
                    "risk_level": "blocks deployment",
                }
            )
        elif impacts["severity"] == "HIGH":
            priorities.update(
                {
                    "immediate_action": "HIGH",
                    "timeframe": "hours",
                    "resources_needed": "developer attention",
                    "risk_level": "affects functionality",
                }
            )

        return priorities

    def step_5_suggest_solutions(
        self, root_causes: List[str], impacts: Dict[str, Any]
    ) -> List[str]:
        """ë‹¨ê³„ 5: ìˆ˜ì • ì „ëµ ì œì•ˆ"""
        solutions = []

        # ê·¼ë³¸ ì›ì¸ ê¸°ë°˜ í•´ê²°ì±… ì œì•ˆ
        for cause in root_causes:
            if "í˜¸í™˜ì„± ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨" in cause:
                solutions.extend(
                    [
                        "Python í˜¸í™˜ì„± ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì¬ì‹¤í–‰",
                        "Union Syntax â†’ Optional[Union[...]] ë³€í™˜ ê²€ì¦",
                        "ë“¤ì—¬ì“°ê¸° ê·œì¹™ ë³€ê²½ì‚¬í•­ ì ìš©",
                    ]
                )

            if "typing ëª¨ë“ˆ import ëˆ„ë½" in cause:
                solutions.extend(
                    [
                        "from typing import Optional, Union ì¶”ê°€",
                        "Python ë²„ì „ë³„ import ì¡°ê±´ë¬¸ êµ¬í˜„",
                        "TYPE_CHECKING ë¸”ë¡ ë‚´ import ì •ë¦¬",
                    ]
                )

            if "êµ¬ë¬¸ ë³€í™˜ ì‹¤íŒ¨" in cause:
                solutions.extend(
                    [
                        "AST ê¸°ë°˜ êµ¬ë¬¸ ë³€í™˜ ë„êµ¬ ê°œë°œ",
                        "ìˆ˜ë™ ê²€ì¦ í›„ ìë™ ë³€í™˜ ì ìš©",
                        "Python ë²„ì „ ë§¤íŠ¸ë¦­ìŠ¤ í…ŒìŠ¤íŠ¸ ì¶”ê°€",
                    ]
                )

            if "import ìˆœì„œ ë³€ê²½" in cause:
                solutions.extend(
                    [
                        "import ìˆœì„œ í‘œì¤€í™”",
                        "ëª¨ë“ˆ ë ˆë²¨ import ìœ„ì¹˜ í†µì¼",
                        "PEP 8 import ì •ë ¬ ì ìš©",
                    ]
                )

        # ì˜í–¥ ë²”ìœ„ ê¸°ë°˜ ì¶”ê°€ í•´ê²°ì±…
        if impacts["affected_files"] > 10:
            solutions.append("ëŒ€ê·œëª¨ íŒŒì¼ ìˆ˜ì • ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ê°œë°œ")

        if impacts["blocking_deployment"]:
            solutions.insert(0, "ğŸš¨ ê¸´ê¸‰: ë°°í¬ ì°¨ë‹¨ í•´ì†Œ ìš°ì„ ")

        return solutions

    def calculate_confidence(self, analysis: SequentialAnalysis) -> float:
        """ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.5  # ê¸°ë³¸ ì‹ ë¢°ë„

        # íŒ¨í„´ ì‹ë³„ ì„±ê³µë„
        if analysis.step_1_patterns:
            confidence += 0.2

        # ê·¼ë³¸ ì›ì¸ ë°œê²¬
        if analysis.step_2_root_causes:
            confidence += 0.2

        # ì˜í–¥ í‰ê°€ ì •í™•ì„±
        if analysis.step_3_impacts["severity"] != "UNKNOWN":
            confidence += 0.1

        return min(confidence, 1.0)

    def analyze_chunk(self, chunk_data: Dict[str, Any]) -> SequentialAnalysis:
        """ì²­í¬ì— ëŒ€í•œ Sequential Thinking ë¶„ì„ ìˆ˜í–‰"""
        chunk_id = chunk_data["chunk_id"]
        lines = chunk_data["lines"]

        # ë‹¨ê³„ë³„ ë¶„ì„ ìˆ˜í–‰
        step_1_patterns = self.step_1_identify_patterns(lines)
        step_2_root_causes = self.step_2_trace_root_causes(step_1_patterns, lines)
        step_3_impacts = self.step_3_assess_impacts(step_1_patterns, lines)
        step_4_priorities = self.step_4_set_priorities(step_3_impacts)
        step_5_solutions = self.step_5_suggest_solutions(step_2_root_causes, step_3_impacts)

        analysis = SequentialAnalysis(
            chunk_id=chunk_id,
            step_1_patterns=step_1_patterns,
            step_2_root_causes=step_2_root_causes,
            step_3_impacts=step_3_impacts,
            step_4_priorities=step_4_priorities,
            step_5_solutions=step_5_solutions,
            confidence_score=0.0,  # ì¼ë‹¨ 0ìœ¼ë¡œ ì„¤ì •, ë‚˜ì¤‘ì— ê³„ì‚°
        )

        analysis.confidence_score = self.calculate_confidence(analysis)

        return analysis

    def analyze_all_chunks(self) -> List[SequentialAnalysis]:
        """ëª¨ë“  ì²­í¬ ë¶„ì„"""
        # Streaming ë°©ì‹ í™œìš©í•˜ì—¬ êµ¬í˜„
        return list(self.analyze_stream_chunks())

    def analyze_stream_chunks(self) -> None:
        """Streaming analysis generator for memory efficiency (TICKET-040)"""
        if not self.chunks_dir.exists():
            return

        # ì²­í¬ íŒŒì¼ë“¤ ì°¾ê¸°
        chunk_files = [
            f for f in os.listdir(self.chunks_dir) if f.startswith("chunk_") and f.endswith(".json")
        ]

        for chunk_file in chunk_files:
            chunk_data = self.load_chunk(chunk_file)
            analysis = self.analyze_chunk(chunk_data)
            self.analyses.append(analysis)
            yield analysis

    def generate_report(self, output_file: str = "sequential_analysis_report.md") -> str:
        """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        report_path = Path(output_file)

        with open(report_path, "w", encoding="utf-8") as f:
            f.write("# AFO ì™•êµ­ Sequential Thinking ë¡œê·¸ ë¶„ì„ ë³´ê³ ì„œ\n\n")
            f.write("## ğŸ“Š ë¶„ì„ ê°œìš”\n\n")
            f.write(f"- ë¶„ì„ëœ ì²­í¬ ìˆ˜: {len(self.analyses)}\n")
            f.write(
                f"- í‰ê·  ì‹ ë¢°ë„: {sum(a.confidence_score for a in self.analyses) / len(self.analyses):.2f}\n\n"
            )

            for analysis in self.analyses:
                f.write(f"## ğŸ” ì²­í¬ {analysis.chunk_id} ë¶„ì„ ê²°ê³¼\n\n")

                f.write("### 1ï¸âƒ£ ì—ëŸ¬ íŒ¨í„´ ì‹ë³„\n")
                for pattern in analysis.step_1_patterns:
                    f.write(f"- {pattern}\n")
                f.write("\n")

                f.write("### 2ï¸âƒ£ ê·¼ë³¸ ì›ì¸ ì¶”ì \n")
                for cause in analysis.step_2_root_causes:
                    f.write(f"- {cause}\n")
                f.write("\n")

                f.write("### 3ï¸âƒ£ ì˜í–¥ ë²”ìœ„ í‰ê°€\n")
                impacts = analysis.step_3_impacts
                f.write(f"- ì‹¬ê°ë„: {impacts['severity']}\n")
                f.write(f"- ì˜í–¥ë°›ì€ íŒŒì¼ ìˆ˜: {impacts['affected_files']}\n")
                f.write(f"- ì˜í–¥ë°›ì€ ë¼ì¸ ìˆ˜: {impacts['affected_lines']}\n")
                f.write(f"- ë°°í¬ ì°¨ë‹¨: {'ì˜ˆ' if impacts['blocking_deployment'] else 'ì•„ë‹ˆì˜¤'}\n")
                f.write("\n")

                f.write("### 4ï¸âƒ£ í•´ê²° ìš°ì„ ìˆœìœ„ ê²°ì •\n")
                priorities = analysis.step_4_priorities
                f.write(f"- ì¦‰ì‹œ ì¡°ì¹˜ ìˆ˜ì¤€: {priorities['immediate_action']}\n")
                f.write(f"- ì˜ˆìƒ ì‹œê°„: {priorities['timeframe']}\n")
                f.write(f"- í•„ìš” ë¦¬ì†ŒìŠ¤: {priorities['resources_needed']}\n")
                f.write(f"- ìœ„í—˜ ìˆ˜ì¤€: {priorities['risk_level']}\n")
                f.write("\n")

                f.write("### 5ï¸âƒ£ ìˆ˜ì • ì „ëµ ì œì•ˆ\n")
                for solution in analysis.step_5_solutions:
                    f.write(f"- {solution}\n")
                f.write("\n")

                f.write(f"### ğŸ¯ ë¶„ì„ ì‹ ë¢°ë„: {analysis.confidence_score:.2f}\n\n")

                f.write("---\n\n")

        return str(report_path)


def main() -> None:
    """CLI ì¸í„°í˜ì´ìŠ¤"""
    import argparse

    parser = argparse.ArgumentParser(description="AFO ì™•êµ­ Sequential Thinking ë¡œê·¸ ë¶„ì„ê¸°")
    parser.add_argument("--chunks-dir", default="log_chunks", help="ì²­í¬ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬")
    parser.add_argument(
        "--output", default="sequential_analysis_report.md", help="ì¶œë ¥ ë³´ê³ ì„œ íŒŒì¼"
    )

    args = parser.parse_args()

    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = SequentialAnalyzer(args.chunks_dir)

    print("ğŸ§  Sequential Thinking ë¡œê·¸ ë¶„ì„ ì‹œì‘...")
    print(f"ğŸ“ ì²­í¬ ë””ë ‰í† ë¦¬: {args.chunks_dir}")

    # ëª¨ë“  ì²­í¬ ë¶„ì„
    analyses = analyzer.analyze_all_chunks()

    print(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(analyses)}ê°œ ì²­í¬ ì²˜ë¦¬")

    # ë³´ê³ ì„œ ìƒì„±
    report_file = analyzer.generate_report(args.output)
    print(f"ğŸ“„ ë³´ê³ ì„œ ìƒì„±: {report_file}")

    # ìš”ì•½ ì¶œë ¥
    sum(a.confidence_score for a in analyses) / len(analyses)
    print(".2f")
    print("\nğŸ¯ ì£¼ìš” í•´ê²° ì „ëµ:")
    for analysis in analyses:
        if analysis.step_4_priorities["immediate_action"] in ["CRITICAL", "HIGH"]:
            print(
                f"  - {analysis.chunk_id}: {analysis.step_5_solutions[0] if analysis.step_5_solutions else 'í•´ê²°ì±… ë¶„ì„ ì¤‘'}"
            )


if __name__ == "__main__":
    main()
