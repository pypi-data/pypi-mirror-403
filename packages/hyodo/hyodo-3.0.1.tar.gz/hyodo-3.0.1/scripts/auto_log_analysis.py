#!/usr/bin/env python3
"""
AFO ì™•êµ­ ìë™ ë¡œê·¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸
ë‹¨ í•œ ì¤„ì˜ ëª…ë ¹ì–´ë¡œ ëª¨ë“  ë¡œê·¸ ë¶„ì„ì„ ìë™í™”

íŒŒì´í”„ë¼ì¸ ë‹¨ê³„:
1. ë¡œê·¸ ì²­í‚¹ (Log Chunker)
2. Sequential ë¶„ì„ (Sequential Analyzer)
3. Context7 ë¶„ë¥˜ (Context7 Classifier)
4. ì¢…í•© ë³´ê³ ì„œ ìƒì„± (Integrated Report)
"""

import argparse
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List


class AutoLogAnalyzer:
    """ìë™ ë¡œê·¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸"""

    def __init__(self, output_dir: str = "analysis_results") -> None:
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

        # ì‹œìŠ¤í…œ ìƒíƒœ ì¶”ì 
        self.pipeline_status = {
            "start_time": None,
            "end_time": None,
            "steps_completed": [],
            "errors": [],
            "performance": {},
        }

    def run_pipeline(
        self,
        log_file: str,
        chunk_method: str = "error_type",
        chunk_size: int = 100,
        generate_report: bool = True,
    ) -> Dict[str, Any]:
        """
        ì™„ì „ ìë™í™”ëœ ë¡œê·¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Args:
            log_file: ë¶„ì„í•  ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
            chunk_method: ì²­í‚¹ ë°©ë²• ('error_type' ë˜ëŠ” 'file')
            chunk_size: ì²­í¬ í¬ê¸°
            generate_report: ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì—¬ë¶€

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        self.pipeline_status["start_time"] = datetime.now().isoformat()

        try:
            print("ğŸš€ AFO ì™•êµ­ ìë™ ë¡œê·¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            print(f"ğŸ“ ëŒ€ìƒ íŒŒì¼: {log_file}")
            print(f"ğŸ“Š ì²­í‚¹ ë°©ë²•: {chunk_method}")
            print(f"ğŸ“ ì²­í¬ í¬ê¸°: {chunk_size}")
            print("-" * 50)

            # ë‹¨ê³„ 1: ë¡œê·¸ ì²­í‚¹
            print("\n1ï¸âƒ£ ë‹¨ê³„ 1: ë¡œê·¸ ì²­í‚¹ ì‹¤í–‰")
            chunk_result = self._run_log_chunker(log_file, chunk_method, chunk_size)

            # ë‹¨ê³„ 2: Sequential ë¶„ì„
            print("\n2ï¸âƒ£ ë‹¨ê³„ 2: Sequential Thinking ë¶„ì„")
            sequential_result = self._run_sequential_analyzer()

            # ë‹¨ê³„ 3: Context7 ë¶„ë¥˜
            print("\n3ï¸âƒ£ ë‹¨ê³„ 3: Context7 ì •ë°€ ë¶„ë¥˜")
            context7_result = self._run_context7_classifier(log_file)

            # ë‹¨ê³„ 4: ì¢…í•© ë³´ê³ ì„œ ìƒì„±
            if generate_report:
                print("\n4ï¸âƒ£ ë‹¨ê³„ 4: ì¢…í•© ë³´ê³ ì„œ ìƒì„±")
                report_result = self._generate_integrated_report(
                    chunk_result, sequential_result, context7_result
                )
            else:
                report_result = {"status": "skipped"}

            # íŒŒì´í”„ë¼ì¸ ì™„ë£Œ
            self.pipeline_status["end_time"] = datetime.now().isoformat()
            self.pipeline_status["steps_completed"] = [
                "log_chunking",
                "sequential_analysis",
                "context7_classification",
                "report_generation",
            ]

            # ìµœì¢… ê²°ê³¼ ì·¨í•©
            final_result = {
                "pipeline_status": "SUCCESS",
                "execution_time": self._calculate_execution_time(),
                "results": {
                    "chunking": chunk_result,
                    "sequential": sequential_result,
                    "context7": context7_result,
                    "report": report_result,
                },
                "output_files": self._get_output_files(),
                "performance_metrics": self._get_performance_metrics(),
            }

            print("\nâœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
            print(f"â±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {final_result['execution_time']}")
            print(f"ğŸ“„ ìƒì„±ëœ íŒŒì¼ ìˆ˜: {len(final_result['output_files'])}")

            return final_result

        except Exception as e:
            self.pipeline_status["errors"].append(str(e))
            self.pipeline_status["end_time"] = datetime.now().isoformat()

            error_result = {
                "pipeline_status": "FAILED",
                "error": str(e),
            }

            print(f"\nâŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return error_result

    def _run_log_chunker(self, log_file: str, method: str, chunk_size: int) -> Dict[str, Any]:
        """ë¡œê·¸ ì²­í‚¹ ë‹¨ê³„ ì‹¤í–‰"""
        start_time = time.time()

        # log_chunker.py ì‹¤í–‰
        cmd = f"python3 scripts/log_chunker.py '{log_file}' --method {method} --chunk-size {chunk_size}"
        exit_code = os.system(cmd)

        execution_time = time.time() - start_time

        if exit_code == 0:
            # ì²­í‚¹ ê²°ê³¼ í™•ì¸
            chunks_dir = Path("log_chunks")
            if chunks_dir.exists():
                chunk_files = list(chunks_dir.glob("chunk_*.json"))
                stats_file = chunks_dir / "statistics.json"

                result = {
                    "status": "success",
                    "chunks_created": len(chunk_files),
                    "execution_time": execution_time,
                    "output_dir": str(chunks_dir),
                }

                # í†µê³„ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ
                if stats_file.exists():
                    with open(stats_file, "r") as f:
                        stats = json.load(f)
                    result["statistics"] = stats

                return result
            else:
                return {"status": "error", "message": "ì²­í¬ ë””ë ‰í† ë¦¬ê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ"}
        else:
            return {"status": "error", "message": f"ì²­í‚¹ ì‹¤íŒ¨ (exit code: {exit_code})"}

    def _run_sequential_analyzer(self) -> Dict[str, Any]:
        """Sequential ë¶„ì„ ë‹¨ê³„ ì‹¤í–‰"""
        start_time = time.time()

        # sequential_analyzer.py ì‹¤í–‰
        report_file = self.output_dir / "sequential_analysis_report.md"
        cmd = (
            f"python3 scripts/sequential_analyzer.py --chunks-dir log_chunks --output {report_file}"
        )
        exit_code = os.system(cmd)

        execution_time = time.time() - start_time

        if exit_code == 0 and report_file.exists():
            return {
                "status": "success",
                "execution_time": execution_time,
                "report_file": str(report_file),
            }
        else:
            return {
                "status": "error",
                "message": f"Sequential ë¶„ì„ ì‹¤íŒ¨ (exit code: {exit_code})",
            }

    def _run_context7_classifier(self, log_file: str) -> Dict[str, Any]:
        """Context7 ë¶„ë¥˜ ë‹¨ê³„ ì‹¤í–‰"""
        start_time = time.time()

        # context7_classifier.py ì‹¤í–‰
        report_file = self.output_dir / "context7_analysis_report.md"
        cmd = f"python3 scripts/context7_classifier.py '{log_file}' --output {report_file}"
        exit_code = os.system(cmd)

        execution_time = time.time() - start_time

        if exit_code == 0 and report_file.exists():
            return {
                "status": "success",
                "execution_time": execution_time,
                "report_file": str(report_file),
            }
        else:
            return {
                "status": "error",
                "message": f"Context7 ë¶„ë¥˜ ì‹¤íŒ¨ (exit code: {exit_code})",
            }

    def _generate_integrated_report(
        self, chunk_result: Dict, sequential_result: Dict, context7_result: Dict
    ) -> Dict[str, Any]:
        """í†µí•© ë³´ê³ ì„œ ìƒì„±"""
        report_file = self.output_dir / "integrated_analysis_report.md"

        with open(report_file, "w", encoding="utf-8") as f:
            f.write("# AFO ì™•êµ­ í†µí•© ë¡œê·¸ ë¶„ì„ ë³´ê³ ì„œ\n\n")
            f.write(f"**ìƒì„± ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # ì‹¤í–‰ ìš”ì•½
            f.write("## ğŸ“Š ì‹¤í–‰ ìš”ì•½\n\n")
            f.write("| ë‹¨ê³„ | ìƒíƒœ | ì‹¤í–‰ ì‹œê°„ | ê²°ê³¼ |\n")
            f.write("|------|------|----------|------|\n")

            steps = [
                ("ë¡œê·¸ ì²­í‚¹", chunk_result),
                ("Sequential ë¶„ì„", sequential_result),
                ("Context7 ë¶„ë¥˜", context7_result),
            ]

            for step_name, result in steps:
                status = "âœ… ì„±ê³µ" if result["status"] == "success" else "âŒ ì‹¤íŒ¨"
                exec_time = f"{result.get('execution_time', 0):.2f}ì´ˆ"
                output = result.get("report_file", result.get("output_dir", "-"))
                f.write(f"| {step_name} | {status} | {exec_time} | {output} |\n")

            f.write("\n")

            # ìƒì„¸ ê²°ê³¼
            f.write("## ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼\n\n")

            # ì²­í‚¹ ê²°ê³¼
            if chunk_result["status"] == "success":
                f.write("### 1ï¸âƒ£ ë¡œê·¸ ì²­í‚¹ ê²°ê³¼\n")
                f.write(f"- ìƒì„±ëœ ì²­í¬ ìˆ˜: {chunk_result.get('chunks_created', 0)}\n")
                if "statistics" in chunk_result:
                    stats = chunk_result["statistics"]
                    f.write(f"- ì´ ì—ëŸ¬ ìˆ˜: {stats.get('total_errors', 0)}\n")
                    f.write(f"- í‰ê·  ì—ëŸ¬/ì²­í¬: {stats.get('avg_errors_per_chunk', 0):.1f}\n")
                f.write("\n")

            # Sequential ê²°ê³¼
            if sequential_result["status"] == "success":
                f.write("### 2ï¸âƒ£ Sequential Thinking ë¶„ì„ ê²°ê³¼\n")
                f.write("- 5ë‹¨ê³„ ì‚¬ê³  ê¸°ë°˜ ê·¼ë³¸ ì›ì¸ ë¶„ì„ ì™„ë£Œ\n")
                f.write("- ì˜í–¥ ë²”ìœ„ ë° í•´ê²° ìš°ì„ ìˆœìœ„ ë¶„ì„ ì™„ë£Œ\n")
                f.write(f"- ë³´ê³ ì„œ: {sequential_result['report_file']}\n")
                f.write("\n")

            # Context7 ê²°ê³¼
            if context7_result["status"] == "success":
                f.write("### 3ï¸âƒ£ Context7 ì •ë°€ ë¶„ë¥˜ ê²°ê³¼\n")
                f.write("- SYNTAX, IMPORT, COMPATIBILITY, TYPE, UNKNOWN ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì™„ë£Œ\n")
                f.write("- ê·¼ë³¸ ì›ì¸ ì¶”ë¡  ë° í•´ê²° ë°©ì•ˆ ì œì•ˆ ì™„ë£Œ\n")
                f.write(f"- ë³´ê³ ì„œ: {context7_result['report_file']}\n")
                f.write("\n")

            # ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­
            f.write("## ğŸ¯ ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­\n\n")

            all_success = all(
                result["status"] == "success"
                for result in [chunk_result, sequential_result, context7_result]
            )

            if all_success:
                f.write("âœ… **ëª¨ë“  ë¶„ì„ ë‹¨ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.**\n\n")
                f.write("**ë‹¤ìŒ ê¶Œê³ ì‚¬í•­:**\n")
                f.write("1. ê°œë³„ ìƒì„¸ ë³´ê³ ì„œë“¤ì„ ê²€í† í•˜ì—¬ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ì´ìŠˆë¶€í„° í•´ê²°\n")
                f.write("2. CRITICAL ë° HIGH ìš°ì„ ìˆœìœ„ ì´ìŠˆë“¤ì„ ì¦‰ì‹œ ì¡°ì¹˜\n")
                f.write("3. ì¬ë°œ ë°©ì§€ë¥¼ ìœ„í•œ ìë™í™” ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶• ê³ ë ¤\n")
                f.write("4. ë¶„ì„ ê²°ê³¼ë¥¼ íŒ€ ë‚´ ê³µìœ í•˜ì—¬ ì§€ì‹ ê³µìœ \n")
            else:
                f.write("âš ï¸ **ì¼ë¶€ ë¶„ì„ ë‹¨ê³„ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.**\n\n")
                f.write("**ê¶Œê³ ì‚¬í•­:**\n")
                f.write("1. ì‹¤íŒ¨í•œ ë‹¨ê³„ë“¤ì˜ ì˜¤ë¥˜ ë¡œê·¸ë¥¼ í™•ì¸\n")
                f.write("2. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­(dependencies)ì„ ì¬í™•ì¸\n")
                f.write("3. ìˆ˜ë™ìœ¼ë¡œ ê°œë³„ ë¶„ì„ ë„êµ¬ë“¤ì„ ì‹¤í–‰í•˜ì—¬ ë¬¸ì œ ì§„ë‹¨\n")

            f.write("\n---\n")
            f.write("*AFO ì™•êµ­ ìë™ ë¡œê·¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì— ì˜í•´ ìƒì„±ë¨*")

        return {
            "status": "success",
            "report_file": str(report_file),
            "all_steps_success": all_success,
        }

    def _calculate_execution_time(self) -> str:
        """ì´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°"""
        if not self.pipeline_status["start_time"] or not self.pipeline_status["end_time"]:
            return "N/A"

        start = datetime.fromisoformat(self.pipeline_status["start_time"])
        end = datetime.fromisoformat(self.pipeline_status["end_time"])
        duration = end - start

        return f"{duration.total_seconds():.2f}ì´ˆ"

    def _get_output_files(self) -> List[str]:
        """ìƒì„±ëœ ëª¨ë“  ì¶œë ¥ íŒŒì¼ ëª©ë¡"""
        output_files = []

        # ë³´ê³ ì„œ íŒŒì¼ë“¤
        for pattern in ["*.md", "*.json"]:
            for file_path in self.output_dir.glob(pattern):
                output_files.append(str(file_path))

        # ì²­í¬ íŒŒì¼ë“¤
        chunks_dir = Path("log_chunks")
        if chunks_dir.exists():
            for file_path in chunks_dir.glob("*"):
                output_files.append(str(file_path))

        return output_files

    def _get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        return {
            "total_steps": len(self.pipeline_status["steps_completed"]),
            "errors_count": len(self.pipeline_status["errors"]),
            "output_files_count": len(self._get_output_files()),
        }


def main() -> None:
    """CLI ì¸í„°í˜ì´ìŠ¤"""
    parser = argparse.ArgumentParser(
        description="AFO ì™•êµ­ ìë™ ë¡œê·¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python3 scripts/auto_log_analysis.py error.log
  python3 scripts/auto_log_analysis.py large_log.txt --chunk-method file --chunk-size 200
  python3 scripts/auto_log_analysis.py debug.log --no-report
        """,
    )

    parser.add_argument("log_file", help="ë¶„ì„í•  ë¡œê·¸ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument(
        "--chunk-method",
        choices=["error_type", "file"],
        default="error_type",
        help="ì²­í‚¹ ë°©ë²• (ê¸°ë³¸: error_type)",
    )
    parser.add_argument(
        "--chunk-size", type=int, default=100, help="ì²­í¬ í¬ê¸° (ë¼ì¸ ìˆ˜, ê¸°ë³¸: 100)"
    )
    parser.add_argument(
        "--output-dir",
        default="analysis_results",
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: analysis_results)",
    )
    parser.add_argument("--no-report", action="store_true", help="ì¢…í•© ë³´ê³ ì„œ ìƒì„±í•˜ì§€ ì•ŠìŒ")

    args = parser.parse_args()

    # ë¶„ì„ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
    analyzer = AutoLogAnalyzer(args.output_dir)
    result = analyzer.run_pipeline(
        args.log_file, args.chunk_method, args.chunk_size, not args.no_report
    )

    # ê²°ê³¼ ì¶œë ¥
    if result["pipeline_status"] == "SUCCESS":
        print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼ë“¤ì´ {args.output_dir} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    else:
        print(f"\nğŸ’¥ ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        sys.exit(1)


if __name__ == "__main__":
    main()
