#!/usr/bin/env python3
"""
AFO ì™•êµ­ ë°±ì—… ë° ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
ì¤‘ìš” ë°ì´í„° ë° ì„¤ì •ì˜ ì•ˆì „í•œ ë°±ì—…/ë³µêµ¬
"""

import json
import shutil
import tarfile
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List


class BackupManager:
    def __init__(self, backup_dir: str = "backups") -> None:
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(exist_ok=True)

        # ë°±ì—… ëŒ€ìƒ ì„¤ì •
        self.backup_targets = {
            "models": {
                "source": "~/.ollama/models",
                "description": "Ollama ëª¨ë¸ íŒŒì¼",
                "critical": True,
            },
            "database": {
                "source": "data",
                "description": "ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼",
                "critical": True,
            },
            "configs": {
                "source": "packages/afo-core/config",
                "description": "ì„¤ì • íŒŒì¼",
                "critical": True,
            },
            "env_files": {
                "source": "*.env*",
                "description": "í™˜ê²½ ë³€ìˆ˜ íŒŒì¼",
                "critical": True,
            },
            "logs": {"source": "logs", "description": "ë¡œê·¸ íŒŒì¼", "critical": False},
            "artifacts": {
                "source": "artifacts",
                "description": "ìƒì„±ëœ ì•„í‹°íŒ©íŠ¸",
                "critical": False,
            },
        }

    def create_backup(self, name: str = None, include_non_critical: bool = False) -> str:
        """ë°±ì—… ìƒì„±"""
        if name is None:
            name = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        backup_path = self.backup_dir / f"{name}.tar.gz"
        temp_dir = self.backup_dir / f"temp_{name}"
        temp_dir.mkdir(exist_ok=True)

        try:
            print(f"ğŸ“¦ ë°±ì—… ìƒì„± ì‹œì‘: {name}")

            # ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = {
                "name": name,
                "timestamp": datetime.now().isoformat(),
                "targets": {},
                "system_info": self._get_system_info(),
            }

            # ê° ëŒ€ìƒ ë°±ì—…
            for target_name, config in self.backup_targets.items():
                if not include_non_critical and not config["critical"]:
                    continue

                try:
                    source_path = Path(config["source"]).expanduser()
                    if source_path.exists():
                        # ëŒ€ìƒ ë””ë ‰í† ë¦¬ ìƒì„±
                        target_dir = temp_dir / target_name
                        target_dir.mkdir(exist_ok=True)

                        if source_path.is_file():
                            shutil.copy2(source_path, target_dir / source_path.name)
                        else:
                            shutil.copytree(
                                source_path,
                                target_dir / source_path.name,
                                dirs_exist_ok=True,
                            )

                        metadata["targets"][target_name] = {
                            "status": "success",
                            "description": config["description"],
                            "size": self._get_dir_size(target_dir),
                        }

                        print(f"  âœ… {target_name}: {config['description']}")
                    else:
                        metadata["targets"][target_name] = {
                            "status": "skipped",
                            "reason": "source not found",
                        }
                        print(f"  âš ï¸ {target_name}: ì†ŒìŠ¤ ì—†ìŒ")

                except Exception as e:
                    metadata["targets"][target_name] = {
                        "status": "error",
                        "error": str(e),
                    }
                    print(f"  âŒ {target_name}: ì˜¤ë¥˜ - {e}")

            # ë©”íƒ€ë°ì´í„° ì €ì¥
            with open(temp_dir / "backup_metadata.json", "w", encoding="utf-8") as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)

            # ì••ì¶•
            print("ğŸ—œï¸ ì••ì¶• ì¤‘...")
            with tarfile.open(backup_path, "w:gz") as tar:
                for item in temp_dir.rglob("*"):
                    if item.is_file():
                        tar.add(item, arcname=item.relative_to(temp_dir))

            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
            shutil.rmtree(temp_dir)

            # ë°±ì—… ì •ë³´ ì¶œë ¥
            backup_size = backup_path.stat().st_size / (1024 * 1024)  # MB
            print(f"ğŸ“¦ ë°±ì—… í¬ê¸°: {backup_size:.1f}MB")
            print(f"ğŸ“ ë°±ì—… ìœ„ì¹˜: {backup_path}")

            return str(backup_path)

        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
            if temp_dir.exists():
                shutil.rmtree(temp_dir)
            raise e

    def list_backups(self) -> List[Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—… ëª©ë¡"""
        backups = []

        for backup_file in self.backup_dir.glob("*.tar.gz"):
            try:
                # ë°±ì—… íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
                backup_info = {
                    "name": backup_file.stem,
                    "path": str(backup_file),
                    "size": backup_file.stat().st_size / (1024 * 1024),  # MB
                    "created": datetime.fromtimestamp(backup_file.stat().st_mtime).isoformat(),
                }
                backups.append(backup_info)
            except Exception:
                continue

        return sorted(backups, key=lambda x: x["created"], reverse=True)

    def restore_backup(self, backup_name: str, target_dir: str = None) -> bool:
        """ë°±ì—… ë³µêµ¬"""
        backup_path = self.backup_dir / f"{backup_name}.tar.gz"

        if not backup_path.exists():
            raise FileNotFoundError(f"ë°±ì—… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {backup_path}")

        if target_dir is None:
            target_dir = f"restore_{backup_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        target_path = Path(target_dir)
        target_path.mkdir(exist_ok=True)

        try:
            print(f"ğŸ“¦ ë°±ì—… ë³µêµ¬ ì‹œì‘: {backup_name}")
            print(f"ğŸ“ ë³µêµ¬ ìœ„ì¹˜: {target_path}")

            # ì••ì¶• í•´ì œ
            with tarfile.open(backup_path, "r:gz") as tar:
                tar.extractall(target_path)

            # ë©”íƒ€ë°ì´í„° í™•ì¸
            metadata_file = target_path / "backup_metadata.json"
            if metadata_file.exists():
                with open(metadata_file, "r", encoding="utf-8") as f:
                    metadata = json.load(f)

                print("ğŸ“‹ ë³µêµ¬ëœ í•­ëª©:")
                for target_name, info in metadata.get("targets", {}).items():
                    if info.get("status") == "success":
                        print(f"  âœ… {target_name}: {info.get('description', '')}")
                    else:
                        print(f"  âš ï¸ {target_name}: {info.get('status', 'unknown')}")

            print("âœ… ë°±ì—… ë³µêµ¬ ì™„ë£Œ")
            return True

        except Exception as e:
            print(f"âŒ ë°±ì—… ë³µêµ¬ ì‹¤íŒ¨: {e}")
            # ë³µêµ¬ ì‹¤íŒ¨ ì‹œ ìƒì„±ëœ ë””ë ‰í† ë¦¬ ì •ë¦¬
            if target_path.exists():
                shutil.rmtree(target_path)
            return False

    def cleanup_old_backups(self, keep_days: int = 30) -> int:
        """ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬"""
        import time

        cutoff_time = time.time() - (keep_days * 24 * 60 * 60)
        removed_count = 0

        for backup_file in self.backup_dir.glob("*.tar.gz"):
            if backup_file.stat().st_mtime < cutoff_time:
                backup_file.unlink()
                removed_count += 1
                print(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ: {backup_file.name}")

        return removed_count

    def _get_system_info(self) -> dict:
        """ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘"""
        try:
            import platform

            return {
                "platform": platform.platform(),
                "python_version": platform.python_version(),
                "hostname": platform.node(),
            }
        except:
            return {"error": "system info unavailable"}

    def _get_dir_size(self, path: Path) -> int:
        """ë””ë ‰í† ë¦¬ í¬ê¸° ê³„ì‚°"""
        total_size = 0
        for item in path.rglob("*"):
            if item.is_file():
                total_size += item.stat().st_size
        return total_size


def main() -> None:
    import argparse

    parser = argparse.ArgumentParser(description="AFO ì™•êµ­ ë°±ì—…/ë³µêµ¬ ë„êµ¬")
    parser.add_argument("action", choices=["backup", "restore", "list", "cleanup"])
    parser.add_argument("--name", help="ë°±ì—… ì´ë¦„")
    parser.add_argument("--target", help="ë³µêµ¬ ëŒ€ìƒ ë””ë ‰í† ë¦¬")
    parser.add_argument(
        "--include-non-critical", action="store_true", help="ì¤‘ìš”í•˜ì§€ ì•Šì€ íŒŒì¼ë„ í¬í•¨"
    )
    parser.add_argument("--keep-days", type=int, default=30, help="ë³´ê´€í•  ë°±ì—… ì¼ìˆ˜ (cleanupìš©)")

    args = parser.parse_args()

    manager = BackupManager()

    try:
        if args.action == "backup":
            backup_path = manager.create_backup(args.name, args.include_non_critical)
            print(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_path}")

        elif args.action == "restore":
            if not args.name:
                print("âŒ ë³µêµ¬í•  ë°±ì—… ì´ë¦„ì„ ì§€ì •í•˜ì„¸ìš” (--name)")
                return

            success = manager.restore_backup(args.name, args.target)
            if success:
                print("âœ… ë³µêµ¬ ì™„ë£Œ")
            else:
                print("âŒ ë³µêµ¬ ì‹¤íŒ¨")

        elif args.action == "list":
            backups = manager.list_backups()
            if backups:
                print("ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—…:")
                for backup in backups:
                    size_mb = backup["size"]
                    print(f"  ğŸ“ {backup['name']} ({size_mb:.1f}MB) - {backup['created'][:19]}")
            else:
                print("ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ ë°±ì—… ì—†ìŒ")

        elif args.action == "cleanup":
            removed = manager.cleanup_old_backups(args.keep_days)
            print(f"ğŸ—‘ï¸ {removed}ê°œì˜ ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œë¨")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    main()
