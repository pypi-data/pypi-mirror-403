"""Silero VAD (Voice Activity Detection) implementation."""

from __future__ import annotations

import logging
import threading
import time
from contextlib import contextmanager
from queue import Empty, Full, Queue
from typing import Callable

import numpy as np

from mic_stream_util.core.audio_config import AudioConfig
from mic_stream_util.core.microphone_manager import MicrophoneStream
from mic_stream_util.speech.models import CallbackEvent, CallbackEventType, SpeechChunk, VADConfig

LOGGER = logging.getLogger(__name__)

# Lazy loading for heavy libraries
_torch: type | None = None
_silero_vad_load_func: Callable[[], object] | None = None


def _get_torch():
    """Lazy import and configure torch."""
    global _torch
    if _torch is None:
        print("Loading torch")
        import torch as torch_module

        # Configure torch for minimal memory usage
        torch_module.set_num_threads(1)
        torch_module.set_grad_enabled(False)  # Disable gradients globally (VAD doesn't need them)
        _torch = torch_module
    return _torch


def _load_silero_vad():
    """Lazy import and load Silero VAD model."""
    global _silero_vad_load_func
    if _silero_vad_load_func is None:
        print("Loading silero vad")
        from silero_vad import load_silero_vad

        _silero_vad_load_func = load_silero_vad
    assert _silero_vad_load_func is not None  # Type narrowing for type checker
    return _silero_vad_load_func()


class CallbackProcessor:
    """Handles callback execution in a separate thread to avoid blocking audio processing."""

    def __init__(self, max_queue_size: int = 256):
        """Initialize the callback processor."""
        self.callback_queue: Queue[CallbackEvent] = Queue(maxsize=max_queue_size)
        self.max_queue_size = max_queue_size
        self.stop_event = threading.Event()
        self.thread: threading.Thread | None = None

        # Callback functions
        self._on_speech_start_cb: Callable[[float], None] | None = None
        self._on_vad_changed_cb: Callable[[float], None] | None = None
        self._on_speech_chunk_cb: Callable[[SpeechChunk, float], None] | None = None
        self._on_speech_ended_cb: Callable[[SpeechChunk], None] | None = None
        self._on_audio_chunk_cb: Callable[[np.ndarray, float], None] | None = None
        self._drop_event_types: set[CallbackEventType] = {CallbackEventType.AUDIO_CHUNK, CallbackEventType.VAD_CHANGED}
        self._dropped_events = 0
        self._processed_events = 0

    def set_callbacks(
        self,
        on_speech_start: Callable[[float], None] | None = None,
        on_vad_changed: Callable[[float], None] | None = None,
        on_speech_chunk: Callable[[SpeechChunk, float], None] | None = None,
        on_audio_chunk: Callable[[np.ndarray, float], None] | None = None,
        on_speech_ended: Callable[[SpeechChunk], None] | None = None,
    ) -> None:
        """Set all callbacks at once for convenience."""
        self._on_speech_start_cb = on_speech_start or self._on_speech_start_cb
        self._on_vad_changed_cb = on_vad_changed or self._on_vad_changed_cb
        self._on_speech_chunk_cb = on_speech_chunk or self._on_speech_chunk_cb
        self._on_audio_chunk_cb = on_audio_chunk or self._on_audio_chunk_cb
        self._on_speech_ended_cb = on_speech_ended or self._on_speech_ended_cb

    def start(self) -> None:
        """Start the callback processing thread."""
        if self.thread is None or not self.thread.is_alive():
            self.stop_event.clear()
            self._dropped_events = 0
            self._processed_events = 0
            self.thread = threading.Thread(target=self._callback_worker, daemon=False)
            self.thread.start()
            LOGGER.debug("Callback processor thread started")

    def stop(self) -> None:
        """Stop the callback processing thread."""
        if self.thread and self.thread.is_alive():
            LOGGER.debug("Stopping callback processor thread...")
            self.stop_event.set()
            self.thread.join(timeout=2.0)
            if self.thread.is_alive():
                LOGGER.warning("Callback processor thread did not terminate cleanly")

        # Drain any pending events to free memory
        drained_count = 0
        while True:
            try:
                self.callback_queue.get_nowait()
                drained_count += 1
            except Empty:
                break

        if drained_count > 0:
            LOGGER.info(f"Drained {drained_count} pending events from callback queue")

        LOGGER.debug(f"Callback processor stats - Processed: {self._processed_events}, Dropped: {self._dropped_events}")
        self.thread = None
        self._dropped_events = 0
        self._processed_events = 0

    def send_event(self, event: CallbackEvent) -> None:
        """Send a callback event to the processing queue."""
        if not self.thread or not self.thread.is_alive():
            return

        drop_on_full = event.event_type in self._drop_event_types

        try:
            if drop_on_full:
                self.callback_queue.put(event, block=False)
            else:
                self.callback_queue.put(event, timeout=0.05)
        except Full:
            if drop_on_full:
                self._dropped_events += 1
                if self._dropped_events % 250 == 1:
                    queue_size = self.callback_queue.qsize()
                    LOGGER.warning("Callback queue is saturated (size: %d/%d); dropped %d %s events", queue_size, self.max_queue_size, self._dropped_events, event.event_type.value)
                return

            # Try to make room by discarding the oldest low-priority event
            try:
                self.callback_queue.get_nowait()
            except Empty:
                pass

            try:
                self.callback_queue.put(event, block=False)
            except Full:
                LOGGER.warning("Callback queue saturated; dropping critical %s event", event.event_type.value)

    def get_queue_size(self) -> int:
        """Get the current size of the callback queue."""
        return self.callback_queue.qsize()

    def _callback_worker(self) -> None:
        """Worker thread that handles callback execution."""
        while not self.stop_event.is_set():
            try:
                # Non-blocking get with timeout
                event = self.callback_queue.get(timeout=0.1)
                self._process_event(event)
            except Exception:
                # Timeout or other exception, continue loop
                continue

    def _process_event(self, event: CallbackEvent) -> None:
        """Process a single callback event."""
        try:
            self._processed_events += 1

            if event.event_type == CallbackEventType.VAD_CHANGED:
                if self._on_vad_changed_cb:
                    self._on_vad_changed_cb(event.data["vad_score"])

            elif event.event_type == CallbackEventType.SPEECH_START:
                if self._on_speech_start_cb:
                    self._on_speech_start_cb(event.data["time"])

            elif event.event_type == CallbackEventType.SPEECH_CHUNK:
                if self._on_speech_chunk_cb:
                    speech_chunk = event.data["speech_chunk"]
                    vad_score = event.data["vad_score"]
                    self._on_speech_chunk_cb(speech_chunk, vad_score)

            elif event.event_type == CallbackEventType.AUDIO_CHUNK:
                if self._on_audio_chunk_cb:
                    audio_chunk = event.data["audio_chunk"]
                    time = event.data["time"]
                    self._on_audio_chunk_cb(audio_chunk, time)

            elif event.event_type == CallbackEventType.SPEECH_ENDED:
                if self._on_speech_ended_cb:
                    speech_chunk = event.data["speech_chunk"]
                    self._on_speech_ended_cb(speech_chunk)

        except Exception as e:
            LOGGER.error(f"Error processing callback event {event.event_type}: {e}", exc_info=True)


class SpeechManager:
    """Manages voice activity detection and speech processing using Silero VAD.

    This class handles real-time audio processing, voice activity detection,
    and provides callbacks for speech events. It maintains buffers for
    pre-speech and post-speech padding to capture complete speech segments.

    Uses threading to separate audio processing from callback execution
    to prevent input overflows when callbacks perform heavy work.

    Attributes:
        audio_config: Configuration for audio input/output
        vad_config: Configuration for voice activity detection
        device: Device to run the VAD model on (CPU/GPU)
        model: The Silero VAD model
        microphone_stream: Manages the audio stream
        callback_processor: Handles callback execution in separate thread
    """

    def __init__(self, audio_config: AudioConfig, vad_config: VADConfig):
        """Initialize the SpeechManager with audio and VAD configuration.

        Args:
            audio_config: Configuration for audio input/output settings
            vad_config: Configuration for voice activity detection parameters
        """
        self.audio_config = audio_config

        # Check that the audio config is valid --> silero only supports 16000Hz with 512 samples or 8000Hz with 256 samples
        if audio_config.sample_rate == 16000:
            if audio_config.num_samples != 512:
                logging.warning("Silero VAD only supports 16000Hz with 512 samples, setting num_samples to 512")
                audio_config.num_samples = 512
        elif audio_config.sample_rate == 8000:
            if audio_config.num_samples != 256:
                logging.warning("Silero VAD only supports 8000Hz with 256 samples, setting num_samples to 256")
                audio_config.num_samples = 256
        else:
            raise ValueError(
                f"Silero VAD only supports 16000Hz with 512 samples or 8000Hz with 256 samples. Got {audio_config.sample_rate}Hz with {audio_config.num_samples} samples"
            )

        self.vad_config = vad_config

        # Device selection (lazy loading torch only when needed)
        # self.device = _get_torch().device("cuda" if _get_torch().cuda.is_available() else "cpu")
        self.device = "cpu"

        # Lazy load Silero VAD model
        self.model = _load_silero_vad()
        if hasattr(self.model, "eval"):
            self.model.eval()  # type: ignore
        if hasattr(self.model, "to"):
            self.model.to(self.device)  # type: ignore

        self.microphone_stream = MicrophoneStream(audio_config)
        self.microphone_stream.set_callback(callback=self._process_audio_chunk)

        # Initialize callback processor
        self.callback_processor = CallbackProcessor()

        # Speech state tracking
        self.was_speaking = False
        self.speech_start_time = 0.0
        self.speech_duration = 0.0
        self.post_speech_counter = 0
        self.vad_score = 0.0
        self.current_time = 0.0

        # Audio padding buffers
        self.pre_speech_buffer: list[np.ndarray] = []
        self.pre_speech_buffer_duration = 0.0
        self.speech_buffer: list[np.ndarray] = []
        self.speech_buffer_duration = 0.0
        self.frame_duration_s = self.audio_config.num_samples / self.audio_config.sample_rate

        # Calculate buffer sizes
        self.pre_speech_chunks_needed = max(1, int(self.vad_config.padding_before_ms / (self.frame_duration_s * 1000)))
        self.post_speech_chunks_needed = max(1, int(self.vad_config.padding_after_ms / (self.frame_duration_s * 1000)))

        # Statistics for monitoring
        self._total_chunks_processed = 0
        self._speech_segments_completed = 0

        # Periodic cache clearing (every N chunks)
        # Balanced interval: frequent enough to prevent leaks, not so frequent to impact performance
        self._cache_clear_interval = 1000  # Clear every 1000 chunks (~30 seconds at 30 Hz)
        self._last_cache_clear = 0

    def is_streaming(self) -> bool:
        """Check if the microphone stream is currently active."""
        return self.microphone_stream.is_streaming()

    def start_stream(self, ignore_already_started: bool = True) -> None:
        """Start the audio stream and begin processing audio chunks."""
        self.callback_processor.start()
        self.microphone_stream.start_stream(ignore_already_started=ignore_already_started)

    def stop_stream(self, ignore_not_started: bool = False) -> None:
        """Stop the audio stream and cease processing audio chunks."""
        LOGGER.info(f"Stopping speech manager - Chunks processed: {self._total_chunks_processed}, Speech segments: {self._speech_segments_completed}")
        LOGGER.info(f"Buffer sizes at stop - Pre-speech: {len(self.pre_speech_buffer)}, Speech: {len(self.speech_buffer)}")

        self.microphone_stream.stop_stream(ignore_not_started=ignore_not_started)
        self.callback_processor.stop()

        # Clear buffers to free memory
        self._clear_buffers()

        # Reset model state to free any accumulated internal state
        try:
            # Reset the VAD model's internal state
            if hasattr(self.model, "reset_states"):
                self.model.reset_states()  # type: ignore[attr-defined]
        except Exception as e:
            LOGGER.debug(f"Could not reset model state: {e}")

        # Clear torch cache (both CUDA and CPU)
        torch = _get_torch()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        # Force Python garbage collection of torch objects
        import gc

        gc.collect()

        LOGGER.debug("Speech manager stopped and cleaned up")

    @contextmanager
    def stream_context(self):
        """Context manager for audio stream lifecycle.

        Yields:
            None: The context manager yields nothing, but manages stream start/stop
        """
        self.start_stream()
        yield
        self.stop_stream()

    def set_on_speech_start_callback(self, cb: Callable[[float], None]) -> None:
        """Set callback for when speech starts.

        Args:
            cb: Callback function that receives the start time of the speech
        """
        self.callback_processor._on_speech_start_cb = cb

    def set_on_vad_changed_callback(self, cb: Callable[[float], None]) -> None:
        """Set callback for VAD score changes.

        Args:
            cb: Callback function that receives the current VAD score (0.0 to 1.0)
        """
        self.callback_processor._on_vad_changed_cb = cb

    def set_on_speech_chunk_callback(self, cb: Callable[[SpeechChunk, float], None]) -> None:
        """Set callback for individual speech chunks during speech detection.

        Args:
            cb: Callback function that receives a SpeechChunk and the current VAD score
        """
        self.callback_processor._on_speech_chunk_cb = cb

    def set_on_audio_chunk_callback(self, cb: Callable[[np.ndarray, float], None]) -> None:
        """Set callback for all audio chunks (before VAD processing).

        Args:
            cb: Callback function that receives the raw audio chunk and timestamp
        """
        self.callback_processor._on_audio_chunk_cb = cb

    def set_on_speech_ended_callback(self, cb: Callable[[SpeechChunk], None]) -> None:
        """Set callback for when a complete speech segment ends.

        Args:
            cb: Callback function that receives the complete SpeechChunk with padding
        """
        self.callback_processor._on_speech_ended_cb = cb

    def set_callbacks(
        self,
        on_speech_start: Callable[[float], None] | None = None,
        on_vad_changed: Callable[[float], None] | None = None,
        on_speech_chunk: Callable[[SpeechChunk, float], None] | None = None,
        on_audio_chunk: Callable[[np.ndarray, float], None] | None = None,
        on_speech_ended: Callable[[SpeechChunk], None] | None = None,
    ) -> None:
        """Set all callbacks at once for convenience.

        Args:
            on_speech_start: Callback for when speech starts
            on_vad_changed: Callback for VAD score changes
            on_speech_chunk: Callback for individual speech chunks
            on_audio_chunk: Callback for all audio chunks
            on_speech_ended: Callback for complete speech segments
        """
        self.callback_processor.set_callbacks(
            on_speech_start=on_speech_start,
            on_vad_changed=on_vad_changed,
            on_speech_chunk=on_speech_chunk,
            on_audio_chunk=on_audio_chunk,
            on_speech_ended=on_speech_ended,
        )

    def _clear_buffers(self) -> None:
        """Clear all internal buffers to free memory."""
        self.pre_speech_buffer.clear()
        self.pre_speech_buffer_duration = 0.0
        self.speech_buffer.clear()
        self.speech_buffer_duration = 0.0
        LOGGER.debug("Cleared speech and pre-speech buffers")

    def get_buffer_stats(self) -> dict[str, int | float]:
        """Get current buffer statistics for monitoring."""
        return {
            "pre_speech_buffer_chunks": len(self.pre_speech_buffer),
            "pre_speech_buffer_duration_s": self.pre_speech_buffer_duration,
            "speech_buffer_chunks": len(self.speech_buffer),
            "speech_buffer_duration_s": self.speech_buffer_duration,
            "callback_queue_size": self.callback_processor.get_queue_size(),
            "callback_queue_max": self.callback_processor.max_queue_size,
            "total_chunks_processed": self._total_chunks_processed,
            "speech_segments_completed": self._speech_segments_completed,
            "dropped_events": self.callback_processor._dropped_events,
            "processed_events": self.callback_processor._processed_events,
        }

    def _add_to_pre_speech_buffer(self, audio_chunk: np.ndarray) -> None:
        """Add audio chunk to pre-speech buffer with duration tracking.

        Note: audio_chunk is assumed to already be a copy, so we don't copy again.
        """
        self.pre_speech_buffer.append(audio_chunk)
        self.pre_speech_buffer_duration += self.frame_duration_s

        # Keep only the most recent chunks needed for padding
        while len(self.pre_speech_buffer) > self.pre_speech_chunks_needed:
            self.pre_speech_buffer.pop(0)
            self.pre_speech_buffer_duration -= self.frame_duration_s

    def _add_speech_audio_chunk(self, audio_chunk: np.ndarray, time: float) -> None:
        """Add audio chunk to speech buffer with duration tracking.

        Note: audio_chunk is assumed to already be a copy, so we don't copy again.
        """
        self.speech_buffer.append(audio_chunk)
        self.speech_buffer_duration += self.frame_duration_s

        # Send speech chunk event to callback processor
        speech_chunk = SpeechChunk(audio_chunk, time, time + self.frame_duration_s, self.frame_duration_s)
        event = CallbackEvent(CallbackEventType.SPEECH_CHUNK, {"speech_chunk": speech_chunk, "vad_score": self.vad_score})
        self.callback_processor.send_event(event)

        if self.vad_config.max_speech_duration_s > 0.0 and self.speech_buffer_duration >= self.vad_config.max_speech_duration_s:
            self._emit_speech_buffer(keep_active=True)

    def _emit_speech_buffer(self, *, keep_active: bool) -> None:
        """Emit the accumulated speech buffer and reset state."""

        if not self.speech_buffer:
            return

        concatenated_audio = np.concatenate(self.speech_buffer)
        speech_chunk = SpeechChunk(
            concatenated_audio,
            self.speech_start_time,
            self.current_time,
            self.speech_buffer_duration,
        )
        event = CallbackEvent(CallbackEventType.SPEECH_ENDED, {"speech_chunk": speech_chunk})
        self.callback_processor.send_event(event)

        self._speech_segments_completed += 1
        LOGGER.debug(f"Speech segment completed: duration={self.speech_buffer_duration:.2f}s, chunks={len(self.speech_buffer)}")

        self.speech_duration = 0.0
        self.post_speech_counter = 0
        self.speech_buffer.clear()
        self.speech_buffer_duration = 0.0

        if keep_active:
            self.speech_start_time = self.current_time
        else:
            self.was_speaking = False

    def _process_audio_chunk(self, audio_chunk: np.ndarray) -> None:
        """Process audio chunk with VAD. This runs in the audio thread and should be fast."""
        try:
            # Update current time
            self.current_time += self.frame_duration_s
            self._total_chunks_processed += 1

            # Make ONE copy of the audio chunk for all subsequent use
            # This avoids multiple copies in buffer additions
            audio_chunk_copy = audio_chunk.copy()

            # Get VAD probability
            # Note: Use inference_mode for maximum memory efficiency
            # This prevents torch from caching any computation graphs
            torch = _get_torch()
            with torch.inference_mode():
                # Create tensor WITHOUT sharing memory (clone to break reference)
                # torch.from_numpy shares memory which might cause the leak
                tensor = torch.from_numpy(audio_chunk_copy).clone().squeeze()
                vad_score = self.model(tensor, self.audio_config.sample_rate).item()  # type: ignore[operator, misc]
                # Explicitly delete tensor before exiting context
                del tensor

            self.vad_score = vad_score

            # Send VAD changed event to callback processor
            event = CallbackEvent(CallbackEventType.VAD_CHANGED, {"vad_score": vad_score})
            self.callback_processor.send_event(event)

            # Send audio chunk event to callback processor
            # Note: Send the copy to avoid reference issues
            event = CallbackEvent(CallbackEventType.AUDIO_CHUNK, {"audio_chunk": audio_chunk_copy, "time": self.current_time})
            self.callback_processor.send_event(event)

            voice_detected = vad_score > self.vad_config.threshold

            # Speech started
            if voice_detected and not self.was_speaking:
                # Send speech start event to callback processor
                event = CallbackEvent(CallbackEventType.SPEECH_START, {"time": self.current_time})
                self.callback_processor.send_event(event)

                self.was_speaking = True
                self.speech_start_time = self.current_time
                self.speech_duration = 0.0
                self.post_speech_counter = 0

                # Add pre-speech padding to speech buffer
                # Pre-speech buffer chunks are already copies
                for chunk in self.pre_speech_buffer:
                    self._add_speech_audio_chunk(chunk, self.current_time)
                self.pre_speech_buffer.clear()
                self.pre_speech_buffer_duration = 0.0

                # Add current chunk (using the copy we made)
                self._add_speech_audio_chunk(audio_chunk_copy, self.current_time)

            # Speech in progress
            elif voice_detected and self.was_speaking:
                self.post_speech_counter = 0
                self._add_speech_audio_chunk(audio_chunk_copy, self.current_time)

            # Speech ended (silence detected)
            elif not voice_detected and self.was_speaking:
                self.post_speech_counter += 1

                # Add current chunk (part of post-speech padding)
                self._add_speech_audio_chunk(audio_chunk_copy, self.current_time)

                # Check if we've reached max silence duration
                if self.post_speech_counter * self.frame_duration_s * 1000 >= self.vad_config.max_silence_ms:
                    self._emit_speech_buffer(keep_active=False)
                    self.post_speech_counter = 0

            # Always add to pre-speech buffer for potential padding
            # Use the copy we made
            self._add_to_pre_speech_buffer(audio_chunk_copy)

            # Periodic cache clearing to prevent torch memory accumulation
            if self._total_chunks_processed - self._last_cache_clear >= self._cache_clear_interval:
                import gc

                gc.collect()

                # Reset model state less frequently to preserve VAD quality
                # Only reset every 4th cache clear (every 60 seconds)
                if (self._total_chunks_processed // self._cache_clear_interval) % 4 == 0:
                    try:
                        if hasattr(self.model, "reset_states"):
                            self.model.reset_states()  # type: ignore[attr-defined]
                            LOGGER.debug(f"Reset model state at chunk {self._total_chunks_processed}")
                    except Exception as e:
                        LOGGER.debug(f"Could not reset model state: {e}")

                self._last_cache_clear = self._total_chunks_processed
                LOGGER.debug(f"Periodic cache clear at chunk {self._total_chunks_processed}")

        except Exception as e:
            print(f"Error processing audio chunk: {e}")
            raise e


if __name__ == "__main__":
    speech = SpeechManager(AudioConfig(device_name="sm900", num_samples=512), VADConfig())

    def vad_changed(vad_score: float) -> None:
        # print(f"VAD score: {vad_score}")
        pass

    def on_audio_chunk(speech_chunk: SpeechChunk, vad_score: float) -> None:
        print(f"Audio chunk: {speech_chunk.duration}, VAD score: {vad_score}")

    def on_speech_ended(speech_chunk: SpeechChunk) -> None:
        print(f"Speech ended: {speech_chunk.duration}")

    speech.set_on_vad_changed_callback(vad_changed)
    speech.set_on_speech_chunk_callback(on_audio_chunk)
    speech.set_on_speech_ended_callback(on_speech_ended)

    speech.start_stream()

    time.sleep(10)
