import time
import atexit
import threading
from threading import Lock, Event
import logging
from typing import Any, Callable, Dict, List, Optional, Tuple, Union

from ..config.dataclasses import (
    RateLimits, UsageSnapshot,
    GlobalStats, KeySummary,
    KeyDetailedStats, ModelAggregatedStats,
    KeyUsage
)
from ..config.enums import RateLimitStrategy
from ..config.log_config import default_logger
from ..config.constants import (
    CLEANUP_INTERVAL_SECONDS,
    HISTORY_LOOKBACK_SECONDS,
    DEFAULT_COOLDOWN_SECONDS,
)
from ..core.utils import get_key_suffix, KeyEntry, normalize_key_entries
from ..usage.usage_logger import AsyncUsageLogger
from ..usage.db_logic import UsageDatabase

class RotatingKeyManager:
    """Manages API key rotation with rate limiting"""

    def __init__(
        self,
        api_keys: List[KeyEntry],
        provider_name: str,
        strategy: RateLimitStrategy,
        db: UsageDatabase,
        logger: Optional[logging.Logger] = None,
        cooldown_seconds: int = DEFAULT_COOLDOWN_SECONDS,
        limit_resolver: Optional[Callable[[str, Optional[str]], RateLimits]] = None,
        api_key_param: str = "api_key",
    ):
        self.provider_name = provider_name
        self.logger = logger or default_logger
        self.strategy = strategy
        self.cooldown_seconds = cooldown_seconds
        self.limit_resolver = limit_resolver
        self.api_key_param = api_key_param

        # Normalize key entries and create KeyUsage objects with params
        normalized = normalize_key_entries(api_keys, api_key_param)
        self.keys = [
            KeyUsage(api_key=primary, strategy=strategy, params=params)
            for primary, params in normalized
        ]
        self.current_index = 0
        self.lock = Lock()

        self.db = db
        self.usage_logger = AsyncUsageLogger(self.db)
        self._hydrate()

        self._stop_event = Event()
        self._start_cleanup()
        atexit.register(self.stop)

        self.logger.info("Initialized %d keys for provider %s.", len(self.keys), provider_name)
    
    def force_rotate_index(self) -> None:
        """
        Force the internal pointer to increment.
        Useful when a key hits a 429 despite local checks passing.
        """
        with self.lock:
            self.current_index = (self.current_index + 1) % len(self.keys)

    def _hydrate(self) -> None:
        """Load historical usage from database to restore state."""
        self.logger.debug("Loading history for provider %s.", self.provider_name)
        all_history = self.db.load_provider_history(self.provider_name, HISTORY_LOOKBACK_SECONDS)
        if not all_history:
            self.logger.info("No history found in DB for %s.", self.provider_name)
            return

        key_map = {get_key_suffix(k.api_key): k for k in self.keys}
        count = 0
        for row in all_history:
            suffix, model_id, ts, tokens = row
            
            if suffix in key_map:
                key_map[suffix].record_usage(model_id, tokens=tokens, timestamp=ts)
                count += 1
        self.logger.info("Hydrated %d records for %s.", 
                    count, self.provider_name)
    
    def _cleanup_loop(self) -> None:
        """Periodically clean deques to prevent memory bloat."""
        while not self._stop_event.is_set():
            try:
                with self.lock:
                    for key in self.keys:
                        for bucket in key.buckets.values():
                            bucket.clean()
                        if self.strategy == RateLimitStrategy.GLOBAL:
                            key.global_bucket.clean()
            except Exception as e:
                self.logger.error("Cleanup loop error: %s", e, exc_info=True)
            time.sleep(CLEANUP_INTERVAL_SECONDS)
    
    def _start_cleanup(self) -> None:
        self._thread = threading.Thread(target=self._cleanup_loop, daemon=True)
        self._thread.start()

    def stop(self) -> None:
        """Stop the cleanup thread and flush logs."""
        self._stop_event.set()
        self.usage_logger.stop()  # Flush logs
        if self._thread.is_alive():
            self._thread.join(timeout=10)

    def get_key(self, model_id: str, default_limits: RateLimits, estimated_tokens: int = 1000) -> Optional[KeyUsage]:
        """
        Get an available API key that can handle the request.

        Args:
            model_id: The model identifier for rate limit lookup
            default_limits: Default limits to use if no per-key override exists
            estimated_tokens: Estimated token usage for this request

        Returns:
            KeyUsage object if a key is available, None otherwise
        """
        with self.lock:
            for offset in range(len(self.keys)):
                idx = (self.current_index + offset) % len(self.keys)
                key: KeyUsage = self.keys[idx]

                if key.is_cooling_down(self.cooldown_seconds):
                    continue

                # Resolve limits for this specific key (supports per-key overrides)
                if self.limit_resolver:
                    key_suffix = get_key_suffix(key.api_key)
                    limits = self.limit_resolver(model_id, key_suffix)
                else:
                    limits = default_limits

                if key.can_use_model(model_id, limits, estimated_tokens):
                    key.reserve(model_id, estimated_tokens)
                    self.current_index = idx
                    return key
            return None
    
    def get_specific_key(self, identifier: Union[int, str], model_id: str, estimated_tokens: int = 1000) -> Optional[KeyUsage]:
        """
        Get a specific key by index or identifier.
        Note: This does NOT check rate limits implicitly to allow 'hard' retrieval,
        but it DOES reserve the estimated tokens to keep tracking accurate.
        """
        with self.lock:
            key, _ = self._find_key(identifier)
            if key:
                key.reserve(model_id, estimated_tokens)
                return key
            return None

    def record_usage(
        self, key_obj: KeyUsage, model_id: str, actual_tokens: int, estimated_tokens: int = 1000
    ) -> None:
        """Record usage for a specific API key."""
        with self.lock:
            key_obj.commit(model_id, actual_tokens, estimated_tokens)
        self.usage_logger.log(self.provider_name, model_id, key_obj.api_key, actual_tokens)

    # --- STATS HELPERS ---

    def _find_key(self, identifier: Union[int, str]) -> Tuple[Optional[KeyUsage], int]:
        """Locate key by index (int) or suffix/full-key (str)."""
        if isinstance(identifier, int):
            if 0 <= identifier < len(self.keys):
                return self.keys[identifier], identifier
        elif isinstance(identifier, str):
            for i, k in enumerate(self.keys):
                if k.api_key == identifier or k.api_key.endswith(identifier):
                    return k, i
        return None, -1

    def get_global_stats(self) -> GlobalStats:
        """Aggregates usage across all keys and models."""
        total = UsageSnapshot()
        keys_summary = []
        with self.lock:
            for i, key in enumerate(self.keys):
                snap = key.get_total_snapshot()
                total = total + snap
                suffix = get_key_suffix(key.api_key)
                keys_summary.append(KeySummary(index=i, suffix=suffix, snapshot=snap))
        return GlobalStats(total=total, keys=keys_summary)

    def get_key_stats(self, identifier: Union[int, str]) -> Optional[KeyDetailedStats]:
        """Stats for a specific key, including per-model breakdown."""
        with self.lock:
            key, idx = self._find_key(identifier)
            if not key:
                return None
            total_snap = key.get_total_snapshot()
            breakdown = {}
            for model, bucket in key.buckets.items():
                breakdown[model] = bucket.get_snapshot()
            suffix = get_key_suffix(key.api_key)
            return KeyDetailedStats(index=idx, suffix=suffix, total=total_snap, breakdown=breakdown)

    def get_model_stats(self, model_id: str) -> ModelAggregatedStats:
        """Aggregates stats for ONE model across ALL keys."""
        total = UsageSnapshot()
        contributing_keys = []
        with self.lock:
            for i, key in enumerate(self.keys):
                if model_id in key.buckets:
                    snap = key.buckets[model_id].get_snapshot()
                    total = total + snap
                    suffix = get_key_suffix(key.api_key)
                    contributing_keys.append(KeySummary(index=i, suffix=suffix, snapshot=snap))
        return ModelAggregatedStats(model_id=model_id, total=total, keys=contributing_keys)

    def get_granular_stats(self, identifier: Union[int, str], model_id: str) -> Optional[KeySummary]:
        """Specific Key + Specific Model."""
        with self.lock:
            key, idx = self._find_key(identifier)
            if not key:
                return None
            suffix = get_key_suffix(key.api_key)
            snap = key.buckets[model_id].get_snapshot() if model_id in key.buckets else UsageSnapshot()
            return KeySummary(index=idx, suffix=suffix, snapshot=snap)
 