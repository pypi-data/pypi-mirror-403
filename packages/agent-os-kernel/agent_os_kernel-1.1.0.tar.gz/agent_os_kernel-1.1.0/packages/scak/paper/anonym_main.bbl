\begin{thebibliography}{11}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bai et~al.(2022)Bai, Kadavath, Kundu, et~al.]{bai2022constitutional}
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, et~al.
\newblock Constitutional ai: Harmlessness from ai feedback.
\newblock \emph{arXiv preprint arXiv:2212.08073}, 2022.

\bibitem[Basiri et~al.(2016)Basiri, Behnam, de~Rooij, et~al.]{basiri2016chaos}
Ali Basiri, Niosha Behnam, Ruud de~Rooij, et~al.
\newblock Chaos engineering, 2016.

\bibitem[Boyd(1987)]{boyd1987discourse}
John~R Boyd.
\newblock \emph{A Discourse on Winning and Losing}.
\newblock Air University Press, 1987.

\bibitem[Hong et~al.(2023)Hong, Zhuge, Chen, Zheng, Cheng, Zhang,
  et~al.]{hong2023metagpt}
Sirui Hong, Mingchen Zhuge, Jiaqi Chen, Xiawu Zheng, Yuheng Cheng, Ceyao Zhang,
  et~al.
\newblock Metagpt: Meta programming for a multi-agent collaborative framework.
\newblock 2023.
\newblock URL \url{https://arxiv.org/abs/2308.00352}.

\bibitem[Lewis et~al.(2020)Lewis, Perez, Piktus, et~al.]{lewis2020retrieval}
Patrick Lewis, Ethan Perez, Aleksandra Piktus, et~al.
\newblock Retrieval-augmented generation for knowledge-intensive nlp tasks.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2020.
\newblock URL \url{https://arxiv.org/abs/2005.11401}.

\bibitem[Liu et~al.(2023)Liu, Lin, Hewitt, et~al.]{liu2023lost}
Nelson~F Liu, Kevin Lin, John Hewitt, et~al.
\newblock Lost in the middle: How language models use long contexts.
\newblock 2023.
\newblock URL \url{https://arxiv.org/abs/2307.03172}.

\bibitem[Madaan et~al.(2023)Madaan, Tandon, Gupta, et~al.]{madaan2023self}
Aman Madaan, Niket Tandon, Prakhar Gupta, et~al.
\newblock Self-refine: Iterative refinement with self-feedback.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2023.
\newblock URL \url{https://arxiv.org/abs/2303.17651}.

\bibitem[Mohtashami and Jaggi(2023)]{mohtashami2023landmark}
Amirkeivan Mohtashami and Martin Jaggi.
\newblock Landmark attention: Random-access infinite context length for
  transformers.
\newblock 2023.
\newblock URL \url{https://arxiv.org/abs/2305.16300}.

\bibitem[Shinn et~al.(2023)Shinn, Cassano, Berman, Gopinath, Narasimhan, and
  Yao]{shinn2023reflexion}
Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik
  Narasimhan, and Shunyu Yao.
\newblock Reflexion: Language agents with verbal reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2023.
\newblock URL \url{https://arxiv.org/abs/2303.11366}.

\bibitem[Wang et~al.(2023)Wang, Xie, Jiang, et~al.]{wang2023voyager}
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, et~al.
\newblock Voyager: An open-ended embodied agent with large language models.
\newblock 2023.
\newblock URL \url{https://arxiv.org/abs/2305.16291}.

\bibitem[Wu et~al.(2023)Wu, Bansal, Zhang, et~al.]{wu2023autogen}
Qingyun Wu, Gagan Bansal, Jieyu Zhang, et~al.
\newblock Autogen: Enabling next-gen llm applications via multi-agent
  conversation.
\newblock \emph{arXiv preprint arXiv:2308.08155}, 2023.

\end{thebibliography}
