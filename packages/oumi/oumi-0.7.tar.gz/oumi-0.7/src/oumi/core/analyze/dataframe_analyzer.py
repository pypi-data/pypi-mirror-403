# Copyright 2025 - Oumi
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from dataclasses import dataclass
from typing import Any

import pandas as pd

from oumi.utils.logging import logger


@dataclass
class DataFrameWithSchema:
    """A DataFrame paired with its schema for analysis.

    Attributes:
        dataframe: The pandas DataFrame to analyze
        schema: Column schema defining types and content types
        name: Optional name for tracking/debugging purposes
    """

    dataframe: pd.DataFrame
    schema: dict
    name: str | None = None


@dataclass
class AnalysisResult:
    """Result of DataFrame analysis containing processed DataFrames.

    Attributes:
        dataframes: Dictionary mapping names to processed DataFrames
        merged_df: DataFrame with merged analysis results from all input DataFrames
        merged_schema: Schema for the merged DataFrame, combining schemas from
            all inputs
    """

    dataframes: dict[str, pd.DataFrame]
    merged_df: pd.DataFrame
    merged_schema: dict

    @property
    def conversations_df(self) -> pd.DataFrame:
        """Get the 'conversations' DataFrame."""
        return self.dataframes.get("conversations", pd.DataFrame())

    @property
    def messages_df(self) -> pd.DataFrame:
        """Get the 'messages' DataFrame."""
        return self.dataframes.get("messages", pd.DataFrame())


class DataFrameAnalyzer:
    """Core DataFrame analysis engine.

    This class encapsulates the essence of analysis: applying sample analyzers
    to pandas DataFrames with column configuration.
    """

    def __init__(
        self,
        sample_analyzers: dict[str, Any],
    ):
        """Initialize the DataFrame analyzer.

        Args:
            sample_analyzers: Dictionary of sample analyzers to apply
        """
        self.sample_analyzers = sample_analyzers

    @staticmethod
    def _update_schema_with_generated_columns(
        generated_schema: dict, schema: dict
    ) -> dict:
        """Update schema with columns generated by analyzers.

        Args:
            generated_schema: Dictionary mapping column names to schema configs
                from analyzer.analyze_sample() return value
            schema: Existing schema dictionary

        Returns:
            Updated schema dictionary with generated columns added
        """
        updated_schema = schema.copy()
        updated_schema.update(generated_schema)
        return updated_schema

    @staticmethod
    def _merge_schema_list(schemas: list[dict]) -> dict:
        """Merge a list of schemas into a single schema.

        When multiple schemas define the same column, the first definition takes
        precedence. This is appropriate for merging schemas from DataFrames that
        are being merged.

        Args:
            schemas: List of schema dictionaries to merge

        Returns:
            Merged schema dictionary containing all columns from all schemas
        """
        merged_schema = {}
        for schema in schemas:
            # Update merged schema, but don't overwrite existing keys
            # This means the first schema's definition for a column takes precedence
            for col, config in schema.items():
                if col not in merged_schema:
                    merged_schema[col] = config
        return merged_schema

    def analyze_dataframe(
        self,
        input_data: DataFrameWithSchema,
    ) -> DataFrameWithSchema:
        """Apply analyzers to a DataFrame.

        Args:
            input_data: DataFrameWithSchema containing DataFrame and its schema
        Returns:
            DataFrameWithSchema with analysis results added and updated schema
        """
        if input_data.dataframe.empty:
            return DataFrameWithSchema(
                dataframe=input_data.dataframe.copy(),
                schema=input_data.schema.copy(),
                name=input_data.name,
            )

        result_df = input_data.dataframe.copy()
        all_generated_schema = {}

        for analyzer_id, analyzer in self.sample_analyzers.items():
            try:
                # Run the analyzer - it returns both the DataFrame and generated schema
                result_df, generated_schema = analyzer.analyze_sample(
                    result_df,
                    schema=input_data.schema,
                )
                all_generated_schema.update(generated_schema)
            except Exception as e:
                logger.warning(f"Analyzer {analyzer_id} failed: {e}")

        # Update schema with columns generated by analyzers
        updated_schema = self._update_schema_with_generated_columns(
            all_generated_schema, input_data.schema
        )

        return DataFrameWithSchema(
            dataframe=result_df,
            schema=updated_schema,
            name=input_data.name,
        )

    def analyze_dataframe_list(
        self,
        input_data_list: list[DataFrameWithSchema],
        merge_on: str | list[str],
    ) -> AnalysisResult:
        """Apply analyzers to a list of DataFrames with their schemas and merge results.

        This is a general method that can handle any number of DataFrames,
        each with its own schema, analyze each one, and then merge them sequentially.

        Args:
            input_data_list: List of DataFrameWithSchema objects to analyze and merge
            merge_on: Column(s) to merge on - can be a string or list of strings
        Returns:
            AnalysisResult with processed DataFrames and final merged result
        """
        if not input_data_list:
            return AnalysisResult(
                dataframes={},
                merged_df=pd.DataFrame(),
                merged_schema={},
            )

        # Apply analyzers to all DataFrames using their respective schemas
        processed_results = []
        dataframes_dict = {}

        for input_data in input_data_list:
            processed_result = self.analyze_dataframe(input_data)
            processed_results.append(processed_result)

            # Store in dictionary with name if provided
            if input_data.name:
                dataframes_dict[input_data.name] = processed_result.dataframe

        processed_dataframes = [result.dataframe for result in processed_results]

        # Merge all DataFrames sequentially
        merged_df = self._merge_dataframe_list(processed_dataframes, merge_on)

        # Merge schemas from all processed results
        schemas = [result.schema for result in processed_results]
        merged_schema = self._merge_schema_list(schemas)

        # Filter merged schema to only include columns that actually exist in merged_df
        merged_schema = {
            col: config
            for col, config in merged_schema.items()
            if col in merged_df.columns
        }

        return AnalysisResult(
            dataframes=dataframes_dict,
            merged_df=merged_df,
            merged_schema=merged_schema,
        )

    def _merge_dataframe_list(
        self,
        dataframes: list[pd.DataFrame],
        merge_on: str | list[str],
    ) -> pd.DataFrame:
        """Merge a list of DataFrames sequentially.

        Args:
            dataframes: List of DataFrames to merge
            merge_on: Column(s) to merge on - can be a string or list of strings
        Returns:
            Final merged DataFrame
        """
        if not dataframes:
            return pd.DataFrame()

        # Filter out empty DataFrames
        non_empty_dfs = [df for df in dataframes if not df.empty]

        if not non_empty_dfs:
            return pd.DataFrame()

        if len(non_empty_dfs) == 1:
            return non_empty_dfs[0].copy()

        # Start with the first DataFrame and merge the rest sequentially
        result_df = non_empty_dfs[0].copy()

        for df in non_empty_dfs[1:]:
            # Normalize merge_on to a list for consistent handling
            merge_columns = [merge_on] if isinstance(merge_on, str) else merge_on

            # Check if all merge columns exist in both DataFrames
            merge_cols_in_result = all(
                col in result_df.columns for col in merge_columns
            )
            merge_cols_in_df = all(col in df.columns for col in merge_columns)

            if merge_cols_in_result and merge_cols_in_df:
                # Merge on the specified column(s)
                result_df = result_df.merge(df, on=merge_columns, how="left")
            else:
                # If merge columns don't exist, just concatenate
                # This handles cases where DataFrames have different structures
                result_df = pd.concat([result_df, df], ignore_index=True)

        return result_df
