"""
Recursor Ingestion Script
Generated by: recursor-sdk init-ingestion

This script:
1.  Crawls your codebase (respecting .gitignore).
2.  Indexes files into your local PostgreSQL database (for immediate vector search).
3.  Syncs files to Recursor (simulating local indexing first + offline queue).

Usage:
    python ingest_codebase.py
"""

import os
import sys
import fnmatch
from typing import List, Optional
from recursor_sdk import RecursorSDK

# Configuration
IGNORE_PATTERNS = [
    ".git", "__pycache__", "node_modules", ".venv", "venv", "dist", "build",
    "*.pyc", "*.pkl", ".DS_Store", ".env"
]
DB_CONNECTION = os.getenv("DATABASE_URL", "postgresql://localhost/your_db")

def load_gitignore(root_dir: str) -> List[str]:
    """Load patterns from .gitignore"""
    gitignore_path = os.path.join(root_dir, ".gitignore")
    patterns = []
    if os.path.exists(gitignore_path):
        with open(gitignore_path, "r") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#"):
                    patterns.append(line)
    return patterns

def is_ignored(path: str, patterns: List[str]) -> bool:
    """Check if file matches ignore patterns"""
    name = os.path.basename(path)
    for pattern in patterns:
        if fnmatch.fnmatch(name, pattern):
            return True
        # Handle directory matches
        if pattern.endswith("/") and name + "/" == pattern:
            return True
    return False

def ingest_codebase(root_dir: str = "."):
    """Main ingestion loop"""
    print(f"üöÄ Starting codebase ingestion from: {os.path.abspath(root_dir)}")
    
    # 1. Initialize SDK (Offline Capabilities Enabled)
    try:
        client = RecursorSDK()
        print("‚úÖ Recursor SDK initialized (Offline Mode Ready)")
    except Exception as e:
        print(f"‚ö†Ô∏è SDK Warning: {e}")
        return

    patterns = IGNORE_PATTERNS + load_gitignore(root_dir)
    file_count = 0

    # 2. Walk Directory
    for root, dirs, files in os.walk(root_dir):
        # Filter directories in-place
        dirs[:] = [d for d in dirs if not is_ignored(d, patterns)]
        
        for file in files:
            if is_ignored(file, patterns):
                continue
                
            file_path = os.path.join(root, file)
            relative_path = os.path.relpath(file_path, root_dir)
            
            try:
                # Read Content
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                
                # 3. Trigger SDK Sync (Local Indexing + Offline Queue)
                # This will print "‚úÖ Indexed locally: ..." to stderr
                client.sync_file(relative_path, content)
                file_count += 1
                
                # Optional: Add your PostgreSQL Vector Insert Logic Here
                # cursor.execute("INSERT INTO codebase_index ...")
                
            except UnicodeDecodeError:
                # Skip binary files
                pass
            except Exception as e:
                print(f"‚ùå Failed to ingest {relative_path}: {e}")

    print(f"\nüéâ Ingestion Complete! {file_count} files processed locally.")
    print("Run this script periodically to keep your local index fresh.")

if __name__ == "__main__":
    ingest_codebase()
