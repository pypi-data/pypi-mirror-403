"""Basic testset generation from documents."""

import random
from dataclasses import dataclass, field
from datetime import datetime
from uuid import uuid4

from evalvault.domain.entities import Dataset, TestCase
from evalvault.domain.services.document_chunker import DocumentChunker


@dataclass
class GenerationConfig:
    """테스트셋 생성 설정."""

    num_questions: int = 10
    chunk_size: int = 500
    chunk_overlap: int = 50
    dataset_name: str = "generated-testset"
    dataset_version: str = "1.0.0"
    metadata: dict = field(default_factory=dict)


class BasicTestsetGenerator:
    """기본 테스트셋 생성기.

    문서에서 청크를 추출하고, 각 청크로부터 질문-답변 쌍을 생성합니다.
    현재는 간단한 추출 기반 생성만 지원합니다.
    """

    def __init__(self):
        """Initialize basic testset generator."""
        pass

    def _chunk_documents(self, documents: list[str], config: GenerationConfig) -> list[str]:
        """Chunk documents into smaller segments.

        Args:
            documents: List of document texts
            config: Generation configuration

        Returns:
            List of text chunks
        """
        chunker = DocumentChunker(
            chunk_size=config.chunk_size,
            overlap=config.chunk_overlap,
        )

        all_chunks = []
        for doc in documents:
            chunks = chunker.chunk(doc)
            all_chunks.extend(chunks)

        return all_chunks

    def _generate_question_from_chunk(self, chunk: str, index: int) -> str:
        """Generate a question from a text chunk.

        This is a basic implementation that creates generic questions.
        Future versions can use LLM-based generation.

        Args:
            chunk: Text chunk to generate question from
            index: Question index for uniqueness

        Returns:
            Generated question
        """
        # Basic question templates
        templates = [
            "이 내용에서 중요한 정보는 무엇인가요?",
            "이 문서는 무엇에 관한 내용인가요?",
            "이 내용을 요약하면 어떻게 되나요?",
            "이 정보의 핵심은 무엇인가요?",
        ]

        # Use index to get consistent but varied questions
        template_idx = index % len(templates)
        return templates[template_idx]

    def generate(self, documents: list[str], config: GenerationConfig) -> Dataset:
        """Generate testset from documents.

        Args:
            documents: List of document texts
            config: Generation configuration

        Returns:
            Generated Dataset with test cases
        """
        if not documents:
            return Dataset(
                name=config.dataset_name,
                version=config.dataset_version,
                test_cases=[],
                metadata={
                    "generated_at": datetime.now().isoformat(),
                    "num_source_documents": 0,
                },
            )

        # Chunk documents
        chunks = self._chunk_documents(documents, config)

        # Sample chunks if we have more than needed
        num_samples = min(config.num_questions, len(chunks))
        sampled_chunks = random.sample(chunks, num_samples) if chunks else []

        # Generate test cases
        test_cases = []
        for i, chunk in enumerate(sampled_chunks):
            test_case = TestCase(
                id=f"gen-{uuid4().hex[:8]}",
                question=self._generate_question_from_chunk(chunk, i),
                answer="",  # Answer will be generated by RAG system
                contexts=[chunk],
                ground_truth=None,  # No ground truth for generated questions
                metadata={
                    "generated": True,
                    "chunk_index": i,
                },
            )
            test_cases.append(test_case)

        # Create dataset
        metadata = {
            "generated_at": datetime.now().isoformat(),
            "num_source_documents": len(documents),
            "num_chunks": len(chunks),
            "chunk_size": config.chunk_size,
            "chunk_overlap": config.chunk_overlap,
        }
        metadata.update(config.metadata)

        return Dataset(
            name=config.dataset_name,
            version=config.dataset_version,
            test_cases=test_cases,
            metadata=metadata,
        )
