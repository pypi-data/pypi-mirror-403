# 부록: 목적/로드맵 재조정 근거 (초안)

> 근거 파일: `README.md`, `docs/handbook/CHAPTERS/00_overview.md`, `docs/handbook/CHAPTERS/08_roadmap.md`, `docs/handbook/EXTERNAL.md`
> 호환성 노트: `docs/ROADMAP.md`, `docs/STATUS.md`는 과거 링크 호환을 위한 deprecated 스텁이다.
> Task 4 산출물: 목적(미션/가치/대상 사용자/Non-goals) + 로드맵/우선순위 재조정 제안

---

## 1) 현재 목적(코드/문서 기반) 관찰

### 1.1 프로젝트 한 줄 정의(문서)
- `README.md`: "평가(Eval) → 분석(Analysis) → 추적(Tracing) → 개선 루프"를 CLI+Web UI로 묶는 플랫폼

### 1.2 상태/제약(문서)
- `docs/handbook/CHAPTERS/00_overview.md`: API/Web UI 실행 모델 및 제약(코드 근거 포함)

### 1.3 로드맵(문서)
- `docs/handbook/CHAPTERS/08_roadmap.md`: 내부 우선순위/DoD/근거
- `docs/handbook/EXTERNAL.md`: 외부 공유용 요약

---

## 2) 우선순위 재조정 원칙

1) "정답"은 문서가 아니라 `코드/테스트/CLI 도움말` (docs 원칙)
2) 사용자 가치 흐름(실행→저장→비교→재현)을 끊지 않는다
3) 산출물(artifacts)과 회귀 게이트(regression gate)는 장기적으로 "팀/CI 재현"의 핵심 기반
4) 외부 공개 파트는 개념/사용 흐름 중심(민감 정보 제외)

---

## 3) 재조정 제안(초안)

### 3.1 미션(1문장)
- "RAG 시스템의 변경이 실제로 개선인지, 왜/어디서 깨지는지, 팀/CI에서 재현 가능하게 검증하는 평가·분석·추적·개선 루프 플랫폼을 제공한다."

### 3.2 대상 사용자(3)
- 내부: RAG를 운영하는 ML/플랫폼/백엔드 엔지니어
- 내부: 품질/회귀를 책임지는 QA/PM
- 외부: RAG 평가/벤치마크를 반복 실행해야 하는 사용자(컨설팅/솔루션/고객사 PoC)

### 3.3 핵심 가치(3)
- 재현성: run_id/DB/리포트/아티팩트로 동일 조건 비교 가능
- 진단 가능성: 어디서 점수가 깨졌는지(모듈/스테이지/메트릭) 추적
- 운영 옵션화: 관측/트레이싱(Phoenix/Langfuse/MLflow)을 필요할 때 켠다

### 3.4 Non-goals(3)
- "RAG 시스템을 대신 구현"하지 않는다(평가/분석/추적/개선 지원)
- "단일 점수로 모든 품질을 대체"하지 않는다(다중 메트릭+근거 기반)
- "특정 벤더/모델에 종속"되지 않는다(OpenAI/Ollama/vLLM 등 옵션화)

---

## 4) 로드맵 재조정(초안)

> 전수 정독 기반으로 추후 구체화(파일/테스트/설정 근거 링크 추가)

### P0 (유지/강화)
- 회귀 게이트와 실행 워크플로의 안정성(데이터셋/메트릭/임계값/리포트)

### P1 (유지/정교화)
- Web UI/CLI의 일관된 사용 흐름(History/Compare/Artifacts)

### P2 (재정의)
- "교과서형 문서(본편+부록)+커버리지 매트릭스"를 통해 시스템을 설명 가능하게 만들기

### P3 (유지)
- 성능(캐시/배치)과 운영 옵션(Phoenix/Langfuse)
