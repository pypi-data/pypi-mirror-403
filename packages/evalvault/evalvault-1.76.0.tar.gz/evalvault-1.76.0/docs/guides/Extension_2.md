# RAG 시스템 데이터 난이도 평가 및 평가용 LLM 파인튜닝 전략 (현실적 관점)

## 1. 데이터 난이도 평가 체계: 근거는 있으나 전제조건이 중요

### 1.1 핵심 전제
- 난이도는 질문/문맥/응답 간 상호작용으로 결정되며, 단일 지표로는 포착이 어렵다.
- Retrieval Complexity(RC)는 질문 난이도와 QA 성능/전문가 판단 간 상관을 보인다는 근거가 있다.
- 그러나 난이도는 “프록시 지표”이며, 실제 운영 데이터와의 상관 검증이 선행되어야 한다.

### 1.2 난이도 축(권장)
- 질문 복잡도: 복합 질문, 다단계 추론, 시간/조건 맥락 포함 여부
- 검색 난이도: 필요한 증거가 여러 문서에 분산되어 있는지, 검색 세트 완전도
- 답변 품질 신호: 정답 라벨/판정 점수, faithfulness/answer relevancy
- 노이즈/도메인 일탈: 검색 결과 부재, 도메인 분류 모델의 저확신

### 1.3 단계적 구현(현실적)
1. v0 (휴리스틱): 질의 길이, 멀티홉 플래그, 검색 성공/실패 여부, top-k 점수 분포
2. v1 (RC 기반): RRCP류 파이프라인을 적용해 RC 추정, 난이도-오류율 상관 검증
3. v2 (난이도 운영): 난이도 분포 드리프트를 KPI로 관리, 난이도 구간별 threshold 분리

### 1.4 노이즈/오류 입력 처리
- 검색 결과 유사도 하한, 결과 0건, 도메인 분류 저확신을 노이즈로 분류
- 노이즈 케이스는 별도 태그로 분리하고, 다운스트림에서 안전 응답으로 처리

### 1.5 EvalVault 연계
- 난이도 점수를 run_id 아티팩트로 저장해 난이도별 성능 추세를 비교 가능하게 한다.
- 난이도 분포 변화가 품질 저하와 연동되는지 검증해 “진짜 원인”인지 확인한다.

### 1.6 도메인별 예시(보험/원전)
- 보험
  - Easy: “자동차 보험 가입 연령은?” (단일 문서 명시)
  - Medium: “운전자 범위 변경 시 보험료가 어떻게 달라지나?” (규정+예외 조합)
  - Hard: “실손보험에서 특정 치료가 비급여일 때 보장 범위는?” (다중 문서/조건 추론)
- 원전
  - Easy: “1차 계통과 2차 계통의 차이는?” (정의성 질문)
  - Medium: “정비 절차의 단계별 요구 사항은?” (절차/조건 조합)
  - Hard: “특정 사고 시나리오에서 안전 계통 동작 순서와 근거는?” (다단계 추론)

---

## 2. 평가용 LLM(as-a-judge) 파인튜닝: 비용 절감 가능, 일반화 리스크 존재

### 2.1 기본 원칙
- 비용 절감은 가능하나, 소형 judge의 일반화/공정성/도메인 이동성은 취약하다.
- judge 품질은 모델 크기보다 라벨 품질/캘리브레이션에 더 좌우된다.

### 2.2 데이터 구성(필수)
- 휴먼 레이블: 질문-문맥-응답과 점수(1~5) 또는 등급 라벨
- 선호도(pairwise): A/B 비교 데이터(가능하면 이유 포함)
- 전문가 정답: 기준 정답과의 일치/누락 평가
- 운영 로그: thumbs up/down, 재질의, 불만족 신호(약한 라벨)

### 2.3 학습 전략(권장)
- SFT로 시작 후, 선호 데이터가 충분하면 DPO 또는 SLiC-HF 추가 적용
- 출력 형식은 JSON 스키마를 고정하여 판정 안정성 확보
- 검증은 GPT-4급 judge와의 일치율, 인간 평가와의 상관을 함께 확인

### 2.4 운영 가드레일
- 캐스케이드 평가: 소형 judge로 대량 처리 후 경계 케이스만 상위 모델로 승격
- 캘리브레이션: 소량 인간 라벨로 점수 보정 및 신뢰구간 제공
- 편향 완화: 위치/형식/지식 편향에 대한 swap/format 랜덤화 테스트

---

## 3. 최신 파인튜닝/효율 기법: “효율”과 “평가 품질”을 분리해 판단

### 3.1 적용 시점 가이드
- QLoRA/LoRA+/LoftQ는 메모리 효율에 유리하지만, 평가 품질 향상은 별도 검증 필요
- LongLoRA/Cartridges/MQA는 장문/서빙 효율에 유리하나 judge 성능 보장을 의미하지 않음
- GaLore는 메모리 절감과 full-update 가능성이 장점이나 운영 복잡도 증가

### 3.2 권장 선택 순서
1. QLoRA + LoRA(또는 LoRA+)로 시작
2. 캘리브레이션/일관성 확보 후에 확장 기법 고려
3. 장문 최적화는 실제 장문 업무에서 병목이 확인된 경우에만 적용

---

## 4. 결론
- 난이도 프로파일링은 유효하지만, “상관 검증 + 운영 KPI화”가 필수 전제다.
- 소형 judge는 비용 절감에 유리하나 일반화/편향/일관성 리스크가 크므로 캘리브레이션과 캐스케이드 운영이 필수다.
- 최신 파인튜닝 기법은 효율성 개선 도구이며, 평가 품질 향상을 보장하지 않는다.

---

## 5. 실행 체크리스트
- 데이터 난이도
  - 난이도 v0 지표가 오류율과 유의미하게 상관되는지 확인
  - 난이도 분포 드리프트가 실제 품질 하락과 연동되는지 검증
- judge
  - 사람 라벨 3–5% 확보 및 캘리브레이션 리포트 생성
  - 캐스케이드 승격 조건(저신뢰/경계 케이스) 정의
- 운영
  - run_id 아티팩트에 난이도/판정 근거 저장 여부 확인
  - 난이도별 threshold 및 대응 정책 문서화

---

## References
- RC metric: https://aclanthology.org/2024.findings-acl.872/
- GRADE difficulty matrix: https://arxiv.org/abs/2508.16994
- QLoRA: https://arxiv.org/abs/2305.14314
- LoftQ: https://arxiv.org/abs/2310.08659
- LoRA+: https://arxiv.org/abs/2402.12354
- LongLoRA: https://arxiv.org/abs/2309.12307
- DPO: https://arxiv.org/abs/2305.18290
- SLiC-HF: https://arxiv.org/abs/2305.10425
- GaLore: https://arxiv.org/abs/2403.03507
- Cartridges: https://arxiv.org/abs/2506.06266
- MQA: https://arxiv.org/abs/1911.02150
- JudgeLM: https://arxiv.org/abs/2310.17631
- Fine-tuned judge limits: https://aclanthology.org/2025.findings-acl.306/
- LLM judge reliability: https://arxiv.org/abs/2412.12509
- LLM judge bias: https://llm-judge-bias.github.io/
