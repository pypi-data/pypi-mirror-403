# EvalVault 환경 설정
# 이 파일을 .env로 복사하고 실제 값을 입력하세요
#
# ┌─────────────────────────────────────────────────────────────┐
# │ 설정 파일 역할 분리                                          │
# ├─────────────────────────────────────────────────────────────┤
# │ .env              → 시크릿, 인프라 설정 (이 파일)             │
# │ config/models.yaml → 모델 프로필 정의 (git 포함)             │
# └─────────────────────────────────────────────────────────────┘

# ================================================
# 프로필 선택
# ================================================
# 사용할 모델 프로필 (config/models.yaml에서 정의)
# - dev: 개발용 경량 모델 (gemma3:1b, qwen3-embedding:0.6b)
# - prod: 운영용 고성능 모델 (gpt-oss-safeguard:20b, qwen3-embedding:8b)
# - openai: OpenAI API 사용 (gpt-5-mini, text-embedding-3-small)
EVALVAULT_PROFILE=dev
# 기본 스토리지: PostgreSQL + pgvector
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5432
# POSTGRES_DATABASE=evalvault
# POSTGRES_USER=postgres
# POSTGRES_PASSWORD=your-password
# POSTGRES_CONNECTION_STRING=postgresql://user:pass@localhost:5432/evalvault
# SQLite를 쓰려면 아래를 명시하세요 (API/CLI 공통)
# DB_BACKEND=sqlite
# EVALVAULT_DB_PATH=data/db/evalvault.db
# 도메인 메모리 DB 경로 (SQLite 전용)
# EVALVAULT_MEMORY_DB_PATH=data/db/evalvault_memory.db

# ================================================
# Ollama 서버 설정 (폐쇄망)
# ================================================
# 프로필이 dev 또는 prod일 때 사용
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=120
# Tool/function calling 지원 모델 (콤마로 구분)
# - 지원 여부 확인: `ollama show <model>` -> Capabilities에 tools 표시
# - 예시: OLLAMA_TOOL_MODELS=gpt-oss:120b,gpt-oss-safeguard:120b,gpt-oss-safeguard:20b
# OLLAMA_TOOL_MODELS=

# 라우팅/챗 모델 (선택)
# OLLAMA_ROUTER_MODEL=gemma3:1b
# OLLAMA_CHAT_MODEL=gemma3:1b
# OLLAMA_CHAT_TIMEOUT_SECONDS=180

# 간단 챗 모드 (RAG/도구 호출 없이 Ollama만 사용)
# EVALVAULT_CHAT_SIMPLE_MODE=true

# RAG 범위/성능 튜닝
# EVALVAULT_RAG_USER_GUIDE_LIMIT=10
# EVALVAULT_RAG_USE_HYBRID=false
# EVALVAULT_RAG_VECTOR_STORE=none
# EVALVAULT_RAG_EMBEDDING_PROFILE=
# EVALVAULT_CHAT_RUN_CONTEXT_ENABLED=false

# ================================================
# OpenAI 설정 (외부망)
# ================================================
# 프로필이 openai일 때 필요
OPENAI_API_KEY=sk-your-api-key-here
# OPENAI_BASE_URL=https://api.openai.com/v1  # 커스텀 엔드포인트 (선택)

# ================================================
# Secret Manager 연동 (선택)
# ================================================
# SECRET_PROVIDER=env|aws|gcp|vault
# 예시: OPENAI_API_KEY=secret://OPENAI_TOKEN

# ================================================
# vLLM 설정 (OpenAI-compatible)
# ================================================
# 프로필이 vllm일 때 필요
# VLLM_BASE_URL=http://localhost:8001/v1
# VLLM_API_KEY=local
# VLLM_MODEL=gpt-oss-120b
# VLLM_EMBEDDING_MODEL=qwen3-embedding:0.6b
# VLLM_EMBEDDING_BASE_URL=http://localhost:8002/v1

# ================================================
# Faithfulness fallback 설정 (선택)
# ================================================
# Ragas faithfulness 실패 시, faithfulness만 더 큰 모델로 재평가합니다.
# FAITHFULNESS_FALLBACK_PROVIDER=ollama
# FAITHFULNESS_FALLBACK_MODEL=gpt-oss-safeguard:20b
# vLLM 예시:
# FAITHFULNESS_FALLBACK_PROVIDER=vllm
# FAITHFULNESS_FALLBACK_MODEL=gpt-oss-120b

# ================================================
# Azure OpenAI 설정 (선택 - 엔터프라이즈)
# ================================================
# AZURE_API_KEY=your-azure-api-key
# AZURE_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_DEPLOYMENT=gpt-4
# AZURE_EMBEDDING_DEPLOYMENT=text-embedding-ada-002
# AZURE_API_VERSION=2024-02-15-preview

# ================================================
# Langfuse 설정 (셀프호스팅)
# ================================================
# LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key
# LANGFUSE_SECRET_KEY=sk-lf-your-secret-key
# LANGFUSE_HOST=http://localhost:3000

# ================================================
# MLflow 설정 (선택)
# ================================================
# MLFLOW_TRACKING_URI=http://localhost:5000
# MLFLOW_EXPERIMENT_NAME=evalvault

# ================================================
# RAG Retriever 설정
# ================================================
# 하이브리드 검색 사용 여부 (BM25 + Dense)
# EVALVAULT_RAG_USE_HYBRID=true
# 벡터 스토어 종류 (pgvector|memory)
# EVALVAULT_RAG_VECTOR_STORE=pgvector
# 임베딩 프로파일 (dev|prod)
# EVALVAULT_RAG_EMBEDDING_PROFILE=dev
# LLM 없이 컨텍스트만 반환
# EVALVAULT_RAG_LLM_ENABLED=false
# pgvector 인덱스 옵션 (성능 튜닝)
# EVALVAULT_RAG_PGVECTOR_INDEX=hnsw  # hnsw|ivfflat|none
# EVALVAULT_RAG_PGVECTOR_INDEX_LISTS=100
# EVALVAULT_RAG_PGVECTOR_HNSW_M=16
# EVALVAULT_RAG_PGVECTOR_HNSW_EF_CONSTRUCTION=64

# ================================================
# API 인증 / CORS / Frontend 설정
# ================================================
# API 토큰(콤마 구분). 비워두면 인증 비활성화
# API_AUTH_TOKENS=token1,token2
# Knowledge API 읽기/쓰기 토큰(콤마 구분). 비워두면 추가 제어 비활성화
# KNOWLEDGE_READ_TOKENS=read-token
# KNOWLEDGE_WRITE_TOKENS=write-token
# 레이트리밋 (기본 비활성화)
# RATE_LIMIT_ENABLED=false
# RATE_LIMIT_REQUESTS=120
# RATE_LIMIT_WINDOW_SECONDS=60
# RATE_LIMIT_BLOCK_THRESHOLD=10
# React 프론트에서 API를 직접 호출할 때만 필요
# CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# Vite 프론트 환경 변수는 frontend/.env에 설정하세요 (둘 중 하나)
# VITE_API_PROXY_TARGET=http://localhost:8000
# VITE_API_BASE_URL=http://localhost:8000/api/v1

# ================================================
# 참고: 모델 설정
# ================================================
# 모델명과 옵션은 config/models.yaml에서 관리합니다.
# 환경변수가 아닌 YAML 파일로 관리하여:
# - 버전 관리 가능 (git)
# - 팀 간 일관된 설정 공유
# - 모델 변경 이력 추적
