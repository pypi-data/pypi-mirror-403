[project]
name = "evalvault"
version = "1.76.0"
description = "RAG evaluation system using Ragas with Phoenix/Langfuse tracing"
readme = "README.md"
requires-python = ">=3.12"
license = { text = "Apache-2.0" }
authors = [
    { name = "EvalVault Contributors" }
]
maintainers = [
    { name = "EvalVault Contributors" }
]
keywords = [
    "rag",
    "evaluation",
    "ragas",
    "langfuse",
    "phoenix",
    "opentelemetry",
    "llm",
    "retrieval-augmented-generation",
    "nlp",
    "machine-learning",
    "ai",
    "testing",
    "observability",
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: Apache Software License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Quality Assurance",
    "Topic :: Software Development :: Testing",
    "Typing :: Typed",
]
dependencies = [
    "ragas==0.4.2",
    "langfuse",
    "instructor",
    "openai",
    "langchain-openai",
    "networkx",
    "pydantic",
    "pydantic-settings",
    "typer",
    "rich",
    "pandas",
    "openpyxl",
    "pypdf>=4.3.0",
    "xlrd", # For reading .xls files (Excel 97-2003)
    "chardet", # For automatic encoding detection in CSV files
    "truststore>=0.10.4",
    "fastapi>=0.128.0",
    "python-multipart",
    "uvicorn>=0.40.0",
    "matplotlib>=3.8.0,<3.9.0",
    "chainlit>=2.9.5",
]

[project.urls]
Homepage = "https://github.com/ntts9990/EvalVault"
Documentation = "https://github.com/ntts9990/EvalVault#readme"
Repository = "https://github.com/ntts9990/EvalVault.git"
Issues = "https://github.com/ntts9990/EvalVault/issues"
Changelog = "https://github.com/ntts9990/EvalVault/releases"

[project.optional-dependencies]
dev = [
    "pytest",
    "pytest-asyncio",
    "pytest-cov",
    "pytest-mock",
    "pytest-xdist",
    "pytest-rerunfailures",
    "pytest-html",
    "ruff",
    "pydeps>=3.0.1",
    "python-multipart",
    # Full feature extras (analysis/korean/postgres/mlflow/phoenix/perf/anthropic/docs/benchmark)
    "scikit-learn>=1.3.0,<1.4.0",
    "xgboost>=2.0.0",
    "anthropic",
    "langchain-anthropic",
    "psycopg[binary]>=3.0.0",
    "pgvector>=0.2.5",
    "mlflow>=2.0.0",
    "arize-phoenix>=8.0.0",
    "openinference-instrumentation-langchain>=0.1.0",
    "opentelemetry-api>=1.20.0",
    "opentelemetry-sdk>=1.20.0",
    "opentelemetry-exporter-otlp>=1.20.0",
    "kiwipiepy>=0.18.0",
    "rank-bm25>=0.2.2",
    "sentence-transformers>=5.2.0",
    "faiss-cpu>=1.8.0",
    "ijson>=3.3.0",
    "lm_eval[api]>=0.4.0",
    "datasets>=2.0.0",
    "mkdocs>=1.5.0",
    "mkdocs-material>=9.5.0",
    "mkdocstrings[python]>=0.24.0",
    "pymdown-extensions>=10.7.0",
]
docs = [
    "mkdocs>=1.5.0",
    "mkdocs-material>=9.5.0",
    "mkdocstrings[python]>=0.24.0",
    "pymdown-extensions>=10.7.0",
]
 web = []
 analysis = [
    "scikit-learn>=1.3.0",
    "xgboost>=2.0.0",
 ]
 anthropic = [
    "anthropic",
    "langchain-anthropic",
 ]
# Phase 1: Visualization dashboard (matplotlib)
dashboard = [
    "matplotlib>=3.8.0,<3.9.0",
]
# Phase 2: Advanced time series analysis (aeon)
timeseries = [
    "aeon>=1.3.0",
    "numba>=0.55.0",
]
postgres = [
    "psycopg[binary]>=3.0.0",
    "pgvector>=0.2.5",
]
mlflow = [
    "mlflow>=2.0.0",
]
phoenix = [
    "arize-phoenix>=8.0.0",
    "openinference-instrumentation-langchain>=0.1.0",
    "opentelemetry-api>=1.20.0",
    "opentelemetry-sdk>=1.20.0",
    "opentelemetry-exporter-otlp>=1.20.0",
]
korean = [
    "kiwipiepy>=0.18.0",              # í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ (Pure Python)
    "rank-bm25>=0.2.2",               # BM25 ê²€ìƒ‰
    "sentence-transformers>=5.2.0",
]
perf = [
    "faiss-cpu>=1.8.0",               # ë²¡í„° ê²€ìƒ‰ ê°€ì† (DenseRetriever FAISS ì¸ë±ìŠ¤)
    "ijson>=3.3.0",                   # JSON ìŠ¤íŠ¸ë¦¬ë° íŒŒì‹± (ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹)
]
benchmark = [
    "lm_eval[api]>=0.4.0",            # lm-evaluation-harness with OpenAI-compatible API (Ollama ë“±)
    "datasets>=2.0.0",                # HuggingFace datasets (KMMLU ë“±)
]
secrets = [
    "boto3",
    "google-cloud-secret-manager",
    "hvac",
]

[project.scripts]
evalvault = "evalvault.adapters.inbound.cli:app"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/evalvault"]

[tool.ruff]
target-version = "py312"
line-length = 100

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W", "UP", "B", "C4", "SIM"]
ignore = [
    "E501",  # Line too long (handled by formatter)
    "B008",  # Do not perform function call in argument defaults (Typer pattern)
    "B904",  # Within except clause, raise with from (Typer Exit pattern)
]

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
# Report generation options (can be overridden via CLI)
addopts = "--tb=short"
# JUnit XML output for CI/CD integration
junit_family = "xunit2"
# Custom markers
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "requires_openai: marks tests that require OpenAI API key",
    "requires_langfuse: marks tests that require Langfuse credentials",
    "requires_phoenix: marks tests that require Phoenix/OpenTelemetry dependencies",
]
filterwarnings = [
    "ignore:tagMap is deprecated.*",
    "ignore:typeMap is deprecated.*",
    "ignore:The phoenix.evals.templating module is deprecated.*",
    "ignore:The 'lia' package has been renamed.*",
    "ignore:`json_encoders` is deprecated.*",
]

[tool.semantic_release]
version_toml = ["pyproject.toml:project.version"]
branch = "main"
build_command = "uv build"
commit_message = "chore(release): {version}\n\nðŸ¤– Automatically generated by python-semantic-release"

[tool.semantic_release.commit_parser_options]
allowed_tags = ["feat", "fix", "perf", "refactor", "build", "chore", "ci", "docs", "style", "test"]
minor_tags = ["feat"]
patch_tags = ["fix", "perf"]

[tool.semantic_release.remote]
type = "github"

[tool.semantic_release.publish]
upload_to_vcs_release = true
