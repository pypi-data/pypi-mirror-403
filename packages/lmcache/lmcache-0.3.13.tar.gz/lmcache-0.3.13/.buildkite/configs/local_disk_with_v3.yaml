workload:
  type: long_doc_qa
  max-inflight-requests: 20
  sleep-time-after-warmup: 20

docker:
  env:
    - "LMCACHE_CHUNK_SIZE=256"
    - "LMCACHE_LOCAL_CPU=False"
    - "LMCACHE_MAX_LOCAL_CPU_SIZE=10"
    - "LMCACHE_MAX_LOCAL_DISK_SIZE=10"
    - "LMCACHE_LOCAL_DISK=\"file:///local/end-to-end-tests/local/\""
    - "LMCACHE_USE_GPU_CONNECTOR_V3=True"

vllm:
  model: "meta-llama/Llama-3.2-1B-Instruct"
  args:
    - "--load-format"
    - "dummy"
    - "--no-enable-prefix-caching"
    - "--kv-transfer-config"
    - "{\"kv_connector\":\"LMCacheConnectorV1\",\"kv_role\":\"kv_both\"}"

checking-fields:
  - query_round_time_per_prompt
