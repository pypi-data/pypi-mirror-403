[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "noesium"
version = "0.2.0"
description = "Towards a cognitive agentic framework"
readme = "README.md"
license = "MIT"
authors = [
    {name = "Xiaming Chen", email = "chenxm35@gmail.com"}
]
maintainers = [
    {name = "Xiaming Chen", email = "chenxm35@gmail.com"}
]
keywords = ["agents", "multi-agent system", "cognition", "artificial intelligence"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Software Development :: Libraries :: Python Modules",
]
requires-python = ">=3.11"
dependencies = [
    "pydantic>=2.0.0",
    "requests>=2.31.0",
    "httpx>=0.28.1",
    "aiohttp>=3.12.15",
    "aiofiles>=24.1.0",
    "anyio>=4.9.0",
    "python-dotenv>=1.1.1",
    "colorlog>=6.8.0",
    "typing-extensions>=4.8.0",
    "deprecated>=1.2.18",
    "psutil>=7.0.0",
    "networkx>=3.5",
    "bubus>=1.5.6",
]

[project.optional-dependencies]
# AI Providers
openai = ["openai>=1.0.0", "instructor>=1.10.0"]
google = [
    "google-genai>=1.5.0", 
    "google-api-python-client>=2.174.0", 
    "google-auth-oauthlib>=1.2.2", 
    "google-auth>=2.40.3"
]
aliyun = ["aliyun-python-sdk-core>=2.13.1,<3.0.0"]
litellm = ["litellm>=1.0.0"]
local-llm = ["ollama>=0.5.3", "llama-cpp-python>=0.3.16", "huggingface-hub>=0.34.4"]

# Frameworks
langchain = [
    "langchain-core>=0.3.72",
    "langchain-text-splitters>=0.3.0",
    "langchain-ollama>=0.2.0",
    "langgraph>=0.5.4",
]

# Database & Vector Stores
postgres = ["psycopg2-binary>=2.9.0", "psycopg2>=2.9.10"] # Use binary for easier install
weaviate = ["weaviate-client>=4,<5", "protobuf>=5,<6"]

# Data Science Tools
datascience = ["matplotlib>=3.8.0", "pexpect>=4.9.0", "ipython>=8.18.0", "pandas>=2.0.0"]

# MCP Support
mcp = ["mcp>=1.0.0"]

# Toolkits
tools = [
    "noesium[google,aliyun,datascience,mcp]",
    "wizsearch>=1.0.1,<2.0.0",
    "arxiv>=2.2.0",
    "pillow>=10.1.0,<12.0",
    "pymupdf>=1.23.0",
    "openpyxl>=3.1.5",
    "wikipedia-api>=0.6.0",
]

# Full installation for power users
all = [
    "noesium[openai,google,local-llm,langchain,postgres,weaviate,tools]"
]

dev = [
    "pytest>=8.2,<9",
    "pytest-cov>=4.0.0",
    "pytest-asyncio>=1.1.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "mypy>=1.10.0",
    "autoflake>=2.3.1",
    "flake8>=7.3.0",
]

[project.urls]
Homepage = "https://github.com/mirasoth/noesium"
Repository = "https://github.com/mirasoth/noesium"

[tool.uv.extra-build-variables."llama-cpp-python"]
CC = "gcc"
CXX = "g++"

[tool.setuptools.packages.find]
include = ["noesium*"]

[tool.black]
line-length = 120

[tool.isort]
profile = "black"
line_length = 120

[tool.pytest.ini_options]
testpaths = ["tests"]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: marks tests as integration tests",
    "unit: marks tests as unit tests",
]

[tool.coverage.run]
source = ["noesium"]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "if self.debug:",
    "if settings.DEBUG",
    "raise AssertionError",
    "raise NotImplementedError",
    "if 0:",
    "if __name__ == .__main__.:",
    "class .*\\bProtocol\\):",
    "@(abc\\.)?abstractmethod",
] 
