"""
TrialHook - FLAML Trial Hook for MLflow Logging

ä½¿ç”¨ FLAML çš„ log æ–‡ä»¶ + helper API è·å–æ‰€æœ‰ trials çš„è¯¦ç»†ä¿¡æ¯ï¼Œ
ä¸ºæ¯ä¸ª trial åˆ›å»º MLflow å­ runï¼Œè®°å½•å®Œæ•´çš„å‚æ•°å’ŒæŒ‡æ ‡ä¿¡æ¯ã€‚

æ•°æ®æ¥æºä¼˜å…ˆçº§ï¼š
1. FLAML log æ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰ trials çš„å®Œæ•´ä¿¡æ¯ï¼‰
2. AutoML.config_historyï¼ˆåªåŒ…å«æ”¹è¿›çš„é…ç½®ï¼‰
3. AutoML._search_statesï¼ˆæ¯ä¸ªä¼°è®¡å™¨çš„æœ€ä½³çŠ¶æ€ï¼‰
4. AutoML çš„å…¶ä»–å±æ€§ï¼ˆbest_estimator, best_config, best_loss ç­‰ï¼‰

è¿™ç§æ–¹æ³•ä¸éœ€è¦ monkey patchingï¼Œæ›´åŠ ç¨³å®šå¯é ã€‚
"""
import mlflow
import time
import os
from typing import Any, Dict, List, Optional
from wedata_automl.utils.print_utils import safe_print


class TrialHook:
    """
    FLAML Trial Hook - ä½¿ç”¨ log æ–‡ä»¶ + helper API è·å–æ‰€æœ‰ trials

    åœ¨ FLAML è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨ä»¥ä¸‹æ•°æ®æºæå–æ‰€æœ‰ trials çš„ä¿¡æ¯ï¼š
    1. FLAML log æ–‡ä»¶ï¼ˆæœ€å®Œæ•´ï¼ŒåŒ…å«æ‰€æœ‰ trialsï¼‰
    2. AutoML.config_historyï¼ˆæ”¹è¿›çš„é…ç½®ï¼‰
    3. AutoML._search_statesï¼ˆæ¯ä¸ªä¼°è®¡å™¨çš„æœ€ä½³çŠ¶æ€ï¼‰
    4. AutoML çš„å…¶ä»–å±æ€§ï¼ˆbest_estimator, best_config, best_loss ç­‰ï¼‰

    ä¸ºæ¯ä¸ª trial åˆ›å»º MLflow å­ run å¹¶è®°å½•å®Œæ•´çš„å‚æ•°å’ŒæŒ‡æ ‡ã€‚

    é€‚ç”¨äºæ‰€æœ‰ä»»åŠ¡ç±»å‹ï¼ˆåˆ†ç±»ã€å›å½’ã€æ—¶åºé¢„æµ‹ï¼‰ã€‚

    æ³¨æ„: è¿™ä¸ªå®ç°ä¸ä½¿ç”¨ monkey patchingï¼Œè€Œæ˜¯åœ¨è®­ç»ƒå®Œæˆåæ‰¹é‡åˆ›å»ºå­ runsã€‚
    """
    
    def __init__(
        self,
        parent_run_id: str,
        features: List[str],
        task: str,
        metric: str,
        enable_logging: bool = True
    ):
        """
        åˆå§‹åŒ– TrialHook

        Args:
            parent_run_id: çˆ¶ run çš„ ID
            features: ç‰¹å¾åˆ—è¡¨
            task: ä»»åŠ¡ç±»å‹ (classification, regression, forecast)
            metric: è¯„ä¼°æŒ‡æ ‡
            enable_logging: æ˜¯å¦å¯ç”¨æ—¥å¿—è®°å½•ï¼ˆé»˜è®¤ Trueï¼‰
        """
        self.parent_run_id = parent_run_id
        self.features = features
        self.task = task
        self.metric = metric
        self.enable_logging = enable_logging

        # å­˜å‚¨æ‰€æœ‰ trial çš„ä¿¡æ¯
        self.trial_runs: List[Dict[str, Any]] = []

        # å­˜å‚¨æœ€ä½³ trial ä¿¡æ¯
        self.best_trial_run_id: Optional[str] = None
        self.best_trial_run_name: Optional[str] = None
        self.best_trial_val_loss: float = float('inf')

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_trials = 0
        self.trials_per_estimator: Dict[str, int] = {}

    def _convert_val_loss_to_metric(self, val_loss: float) -> float:
        """
        å°† FLAML çš„ val_loss è½¬æ¢ä¸ºç”¨æˆ·æŒ‡å®šçš„ metric å€¼

        FLAML å†…éƒ¨ç»Ÿä¸€ä½¿ç”¨ val_lossï¼ˆè¶Šå°è¶Šå¥½ï¼‰ï¼š
        - å¯¹äº"è¶Šå°è¶Šå¥½"çš„æŒ‡æ ‡ï¼ˆå¦‚ log_loss, mseï¼‰: val_loss = metric_value
        - å¯¹äº"è¶Šå¤§è¶Šå¥½"çš„æŒ‡æ ‡ï¼ˆå¦‚ accuracy, f1ï¼‰: val_loss = 1 - metric_value

        æ”¯æŒçš„æŒ‡æ ‡ï¼ˆæŒ‰ä»»åŠ¡ç±»å‹ï¼‰ï¼š
        - åˆ†ç±»: f1, log_loss(é»˜è®¤), precision, accuracy, roc_auc, rmse, mae
        - å›å½’: deviance(é»˜è®¤), rmse, mae, r2, mse
        - é¢„æµ‹: smape(é»˜è®¤), mse, rmse, mae, mdape

        Args:
            val_loss: FLAML çš„ val_loss å€¼

        Returns:
            ç”¨æˆ·æŒ‡å®šçš„ metric å€¼
        """
        # "è¶Šå¤§è¶Šå¥½"çš„æŒ‡æ ‡åˆ—è¡¨ï¼ˆval_loss = 1 - metric_valueï¼‰
        maximize_metrics = [
            # åˆ†ç±»æŒ‡æ ‡
            "accuracy",
            "f1", "macro_f1", "micro_f1", "weighted_f1",
            "precision",
            "recall",
            "roc_auc", "roc_auc_ovr", "roc_auc_ovo", "roc_auc_weighted",
            "ap",
            # å›å½’æŒ‡æ ‡
            "r2",
        ]

        # "è¶Šå°è¶Šå¥½"çš„æŒ‡æ ‡åˆ—è¡¨ï¼ˆval_loss = metric_valueï¼‰
        # åˆ†ç±»: log_loss, rmse, mae
        # å›å½’: deviance, rmse, mae, mse
        # é¢„æµ‹: smape, mse, rmse, mae, mdape

        if self.metric in maximize_metrics:
            # å¯¹äºè¶Šå¤§è¶Šå¥½çš„æŒ‡æ ‡ï¼Œéœ€è¦è½¬æ¢å›æ¥
            return 1 - val_loss
        else:
            # å¯¹äºè¶Šå°è¶Šå¥½çš„æŒ‡æ ‡ï¼Œval_loss å°±æ˜¯åŸå§‹å€¼
            return val_loss

    def log_trials_from_automl(
        self,
        automl_instance,
        log_file_path: Optional[str] = None,
        feature_names: Optional[List[str]] = None,
        time_budget: Optional[int] = None,
        train_time: Optional[float] = None
    ):
        """
        ä» AutoML å®ä¾‹ä¸­æå–æ‰€æœ‰ trials çš„ä¿¡æ¯ï¼Œå¹¶åˆ›å»º MLflow å­ runs

        ä½¿ç”¨å¤šç§æ•°æ®æºï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
        1. FLAML log æ–‡ä»¶ï¼ˆæœ€å®Œæ•´ï¼‰
        2. AutoML.config_historyï¼ˆæ”¹è¿›çš„é…ç½®ï¼‰
        3. AutoML._search_statesï¼ˆæ¯ä¸ªä¼°è®¡å™¨çš„æœ€ä½³çŠ¶æ€ï¼‰

        åŒæ—¶ä½¿ç”¨ AutoML çš„ helper API è·å–é¢å¤–ä¿¡æ¯ï¼š
        - best_estimator: æœ€ä½³ä¼°è®¡å™¨åç§°
        - best_config: æœ€ä½³é…ç½®
        - best_loss: æœ€ä½³æŸå¤±
        - feature_names_in_: ç‰¹å¾åç§°ï¼ˆå¦‚æœ AutoML æ²¡æœ‰ï¼Œåˆ™ä½¿ç”¨ä¼ å…¥çš„ feature_namesï¼‰
        - classes_: åˆ†ç±»ä»»åŠ¡çš„ç±»åˆ«ï¼ˆå¦‚æœæœ‰ï¼‰

        Args:
            automl_instance: FLAML AutoML å®ä¾‹ï¼ˆè®­ç»ƒå®Œæˆåï¼‰
            log_file_path: FLAML è®­ç»ƒæ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¦‚æœ AutoML æ²¡æœ‰ feature_names_in_ æ—¶ä½¿ç”¨ï¼‰
            time_budget: æ—¶é—´é¢„ç®—ï¼ˆç§’ï¼‰ï¼Œå¯é€‰
            train_time: å®é™…è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå¯é€‰
        """
        if not self.enable_logging:
            safe_print("âš ï¸  TrialHook logging is disabled")
            return

        safe_print("", show_timestamp=False, show_level=False)
        safe_print("ğŸ” Extracting trials from FLAML AutoML using log + helper API...")

        # é¦–å…ˆä» AutoML å®ä¾‹è·å–å…¨å±€ä¿¡æ¯ï¼ˆä½¿ç”¨ helper APIï¼‰
        self._extract_global_info_from_automl(automl_instance, feature_names, time_budget, train_time)

        # æ–¹æ³• 1: ä»æ—¥å¿—æ–‡ä»¶è¯»å–ï¼ˆæœ€å®Œæ•´ï¼ŒåŒ…å«æ‰€æœ‰ trialsï¼‰
        if log_file_path and os.path.exists(log_file_path):
            all_trials = self._extract_trials_from_log_file(log_file_path)
            if all_trials:
                safe_print(f"âœ… Found {len(all_trials)} trials from log file")
                # ä½¿ç”¨ AutoML helper API å¢å¼º trial ä¿¡æ¯
                all_trials = self._enrich_trials_with_automl_info(all_trials, automl_instance)
                self._create_trial_runs(all_trials, automl_instance)
                return

        # æ–¹æ³• 2: ä» config_history è¯»å–ï¼ˆåªåŒ…å«æ”¹è¿›çš„é…ç½®ï¼‰
        if hasattr(automl_instance, 'config_history'):
            config_history = automl_instance.config_history
            if config_history:
                all_trials = []
                for iter_num, (estimator, config, time_stamp) in config_history.items():
                    trial_info = {
                        'estimator': estimator,
                        'trial_idx': iter_num,
                        'config': config,
                        'wall_clock_time': time_stamp,
                        'validation_loss': None,  # ä¸å¯ç”¨
                        'trial_time': None,  # ä¸å¯ç”¨
                    }
                    all_trials.append(trial_info)

                safe_print(f"âœ… Found {len(all_trials)} improvement trials from config_history")
                # ä½¿ç”¨ AutoML helper API å¢å¼º trial ä¿¡æ¯
                all_trials = self._enrich_trials_with_automl_info(all_trials, automl_instance)
                self._create_trial_runs(all_trials, automl_instance)
                return

        # æ–¹æ³• 3: ä» _search_states è¯»å–ï¼ˆæ¯ä¸ªä¼°è®¡å™¨çš„æœ€ä½³çŠ¶æ€ï¼‰
        if hasattr(automl_instance, '_search_states'):
            all_trials = self._extract_trials_from_search_states(automl_instance)
            if all_trials:
                safe_print(f"âœ… Found {len(all_trials)} best trials from _search_states")
                # ä½¿ç”¨ AutoML helper API å¢å¼º trial ä¿¡æ¯
                all_trials = self._enrich_trials_with_automl_info(all_trials, automl_instance)
                self._create_trial_runs(all_trials, automl_instance)
                return

        safe_print("âš ï¸  WARNING: No trials found. Consider setting log_file_name in FLAML settings.")
        return

    def _extract_global_info_from_automl(
        self,
        automl_instance,
        feature_names: Optional[List[str]] = None,
        time_budget: Optional[int] = None,
        train_time: Optional[float] = None
    ):
        """
        ä» AutoML å®ä¾‹ä¸­æå–å…¨å±€ä¿¡æ¯ï¼ˆä½¿ç”¨ helper APIï¼‰

        Args:
            automl_instance: FLAML AutoML å®ä¾‹
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¦‚æœ AutoML æ²¡æœ‰ feature_names_in_ æ—¶ä½¿ç”¨ï¼‰
            time_budget: æ—¶é—´é¢„ç®—ï¼ˆç§’ï¼‰ï¼Œå¯é€‰
            train_time: å®é™…è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå¯é€‰
        """
        # æå–å…¨å±€ä¿¡æ¯
        self.automl_best_estimator = getattr(automl_instance, 'best_estimator', None)
        self.automl_best_config = getattr(automl_instance, 'best_config', {})
        self.automl_best_loss = getattr(automl_instance, 'best_loss', None)

        # å®‰å…¨è·å– feature_names_in_ï¼ˆå¯èƒ½ä¸å­˜åœ¨æˆ–ä¸º Noneï¼‰
        # ä¼˜å…ˆä½¿ç”¨ AutoML çš„ feature_names_in_ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ä¼ å…¥çš„ feature_names
        automl_feature_names = getattr(automl_instance, 'feature_names_in_', None)
        if automl_feature_names is not None:
            self.automl_feature_names = automl_feature_names
        elif feature_names is not None:
            self.automl_feature_names = feature_names
        else:
            self.automl_feature_names = []

        self.automl_classes = getattr(automl_instance, 'classes_', None)

        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ time_budgetï¼Œå¦åˆ™å°è¯•ä» AutoML å®ä¾‹è·å–
        if time_budget is not None:
            self.automl_time_budget = time_budget
        else:
            self.automl_time_budget = (
                getattr(automl_instance, '_time_budget', None) or
                getattr(automl_instance, 'time_budget', None) or
                getattr(automl_instance, '_state', {}).get('time_budget', None)
            )

        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ train_timeï¼Œå¦åˆ™å°è¯•ä» AutoML å®ä¾‹è·å–
        if train_time is not None:
            self.automl_train_time = train_time
        else:
            self.automl_train_time = (
                getattr(automl_instance, '_train_time', None) or
                getattr(automl_instance, 'train_time', None) or
                getattr(automl_instance, '_state', {}).get('train_time', None) or
                getattr(automl_instance, '_state', {}).get('total_time_used', None)
            )

        safe_print(f"ğŸ“Š AutoML Global Info (from helper API):")
        safe_print(f"  - Best estimator: {self.automl_best_estimator}")
        safe_print(f"  - Best loss: {self.automl_best_loss}")
        safe_print(f"  - Time budget: {self.automl_time_budget}s")
        safe_print(f"  - Total train time: {self.automl_train_time:.2f}s" if self.automl_train_time else "  - Total train time: N/A")

        # æ˜¾ç¤ºç‰¹å¾æ•°é‡
        # æ³¨æ„ï¼šfeature_names å¯èƒ½æ˜¯ numpy arrayï¼Œä¸èƒ½ç›´æ¥ç”¨åœ¨ if è¯­å¥ä¸­
        if self.automl_feature_names is not None and len(self.automl_feature_names) > 0:
            safe_print(f"  - Feature count: {len(self.automl_feature_names)}")
        else:
            safe_print(f"  - Feature count: N/A")

        # æ˜¾ç¤ºç±»åˆ«
        if self.automl_classes is not None:
            safe_print(f"  - Classes: {list(self.automl_classes)}")

    def _enrich_trials_with_automl_info(
        self,
        trials: List[Dict[str, Any]],
        automl_instance
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ AutoML helper API å¢å¼º trial ä¿¡æ¯

        Args:
            trials: åŸå§‹ trials åˆ—è¡¨
            automl_instance: FLAML AutoML å®ä¾‹

        Returns:
            å¢å¼ºåçš„ trials åˆ—è¡¨
        """
        # ä» _search_states è·å–æ¯ä¸ªä¼°è®¡å™¨çš„è¯¦ç»†ä¿¡æ¯
        search_states = getattr(automl_instance, '_search_states', {})

        for trial in trials:
            estimator = trial.get('estimator')

            # æ ‡è®°æ˜¯å¦ä¸ºæœ€ä½³ trial
            trial['is_best'] = (estimator == self.automl_best_estimator and
                               trial.get('config') == self.automl_best_config)

            # ä» search_states è·å–ä¼°è®¡å™¨çš„è¯¦ç»†ä¿¡æ¯
            if estimator in search_states:
                state = search_states[estimator]
                trial['search_state_info'] = {
                    'sample_size': getattr(state, 'sample_size', None),
                    'ls_ever_converged': getattr(state, 'ls_ever_converged', None),
                    'trained_estimator': getattr(state, 'trained_estimator', None),
                }

        return trials

    def _extract_trials_from_search_states(self, automl_instance) -> List[Dict[str, Any]]:
        """
        ä» AutoML._search_states ä¸­æå–æ¯ä¸ªä¼°è®¡å™¨çš„æœ€ä½³ trial

        Args:
            automl_instance: FLAML AutoML å®ä¾‹

        Returns:
            trials åˆ—è¡¨
        """
        search_states = getattr(automl_instance, '_search_states', {})
        if not search_states:
            return []

        all_trials = []
        for estimator_name, state in search_states.items():
            # è·å–æœ€ä½³é…ç½®
            best_config = getattr(state, 'best_config', {})
            best_loss = getattr(state, 'best_loss', None)

            trial_info = {
                'estimator': estimator_name,
                'trial_idx': 0,  # åªæœ‰ä¸€ä¸ªæœ€ä½³é…ç½®
                'config': best_config,
                'validation_loss': best_loss,
                'trial_time': getattr(state, 'total_time_used', None),
                'wall_clock_time': None,
                'sample_size': getattr(state, 'sample_size', None),
                'is_best_for_estimator': True,
            }
            all_trials.append(trial_info)

        return all_trials

    def _extract_trials_from_log_file(self, log_file_path: str) -> List[Dict[str, Any]]:
        """
        ä» FLAML è®­ç»ƒæ—¥å¿—æ–‡ä»¶ä¸­æå–æ‰€æœ‰ trials

        Args:
            log_file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„

        Returns:
            trials åˆ—è¡¨
        """
        import json

        all_trials = []
        try:
            with open(log_file_path, 'r') as f:
                for line in f:
                    try:
                        data = json.loads(line.strip())
                        # è·³è¿‡ checkpoint è®°å½•ï¼ˆåªæœ‰ä¸€ä¸ªå­—æ®µï¼‰
                        if len(data) == 1:
                            continue

                        # æå– trial ä¿¡æ¯
                        trial_info = {
                            'estimator': data.get('learner'),
                            'trial_idx': data.get('record_id'),
                            'iter_per_learner': data.get('iter_per_learner'),
                            'config': data.get('config'),
                            'validation_loss': data.get('validation_loss'),
                            'trial_time': data.get('trial_time'),
                            'wall_clock_time': data.get('wall_clock_time'),
                            'logged_metric': data.get('logged_metric'),
                            'sample_size': data.get('sample_size'),
                        }
                        all_trials.append(trial_info)
                    except json.JSONDecodeError:
                        continue
        except Exception as e:
            safe_print(f"âš ï¸  WARNING: Failed to read log file: {e}")
            return []

        return all_trials

    def _create_trial_runs(self, all_trials: List[Dict[str, Any]], automl_instance=None):
        """
        ä¸ºæ‰€æœ‰ trials åˆ›å»º MLflow å­ runsï¼ˆä½¿ç”¨å¢å¼ºçš„ä¿¡æ¯ï¼‰

        Args:
            all_trials: æ‰€æœ‰ trials çš„ä¿¡æ¯åˆ—è¡¨ï¼ˆå·²é€šè¿‡ helper API å¢å¼ºï¼‰
            automl_instance: FLAML AutoML å®ä¾‹ï¼ˆå¯é€‰ï¼Œç”¨äºè·å–é¢å¤–ä¿¡æ¯ï¼‰
        """
        safe_print(f"ğŸ“ Creating MLflow child runs for {len(all_trials)} trials...")

        # æŒ‰ä¼°è®¡å™¨åˆ†ç»„ç»Ÿè®¡
        estimator_counts: Dict[str, int] = {}

        # å…¨å±€è®¡æ•°å™¨
        global_count = 0

        for trial in all_trials:
            estimator = trial['estimator']
            config = trial['config']

            # æ›´æ–°è®¡æ•°å™¨
            global_count += 1
            if estimator not in estimator_counts:
                estimator_counts[estimator] = 0
            estimator_counts[estimator] += 1
            local_count = estimator_counts[estimator]

            # ç”Ÿæˆ run åç§°ï¼ˆä½¿ç”¨ä¼˜åŒ–åçš„å‘½åè§„èŒƒï¼šè¡¥é›¶ï¼‰
            run_name = f"trial_{global_count:03d}_{estimator}"

            # æå–æŒ‡æ ‡ä¿¡æ¯ï¼ˆæ”¯æŒä¸¤ç§æ•°æ®æºï¼‰
            val_loss = trial.get('validation_loss') or config.get('val_loss', float('inf'))
            train_time = trial.get('trial_time') or config.get('time_total_s', 0.0)

            try:
                # åˆ›å»ºåµŒå¥— run
                with mlflow.start_run(run_name=run_name, nested=True) as trial_run:
                    trial_run_id = trial_run.info.run_id

                    # è®°å½•åŸºæœ¬å‚æ•°
                    mlflow.log_param("estimator", estimator)
                    mlflow.log_param("trial_number_global", global_count)
                    mlflow.log_param("trial_number_local", local_count)
                    mlflow.log_param("parent_run_id", self.parent_run_id)
                    mlflow.log_param("task", self.task)

                    # è®°å½•æ˜¯å¦ä¸ºæœ€ä½³ trialï¼ˆä»å¢å¼ºä¿¡æ¯ä¸­è·å–ï¼‰
                    is_best = trial.get('is_best', False)
                    mlflow.log_param("is_best_trial", is_best)

                    # è®°å½•è¶…å‚æ•°é…ç½®
                    for key, value in config.items():
                        # è·³è¿‡å†…éƒ¨å­—æ®µå’ŒæŒ‡æ ‡å­—æ®µ
                        if key in ["val_loss", "time_total_s", "trained_estimator", "learner", "FLAML_sample_size"]:
                            continue
                        try:
                            mlflow.log_param(f"hp_{key}", value)
                        except Exception:
                            # æŸäº›å€¼å¯èƒ½æ— æ³•åºåˆ—åŒ–ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                            try:
                                mlflow.log_param(f"hp_{key}", str(value))
                            except Exception:
                                pass  # å¿½ç•¥æ— æ³•è®°å½•çš„å‚æ•°

                    # æ³¨æ„ï¼šä½¿ç”¨ flaml_ å‰ç¼€é¿å…ä¸æœ€ä½³ run çš„æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡æ··æ·†
                    # FLAML çš„ val_loss æ¥è‡ªè®­ç»ƒæ—¶çš„äº¤å‰éªŒè¯ï¼Œä¸æœ€ç»ˆè¯„ä¼°å¯èƒ½æœ‰å·®å¼‚
                    if val_loss != float('inf'):
                        mlflow.log_metric("val_loss", val_loss)

                        # å°† val_loss è½¬æ¢ä¸ºç”¨æˆ·æŒ‡å®šçš„ metric å€¼ï¼Œä½¿ç”¨ flaml_ å‰ç¼€
                        metric_value = self._convert_val_loss_to_metric(val_loss)
                        mlflow.log_metric(f"flaml_{self.metric}", metric_value)

                    if train_time > 0:
                        mlflow.log_metric("train_time", train_time)

                    # è®°å½•é¢å¤–çš„ trial ä¿¡æ¯ï¼ˆä» log æ–‡ä»¶æˆ– search_states è·å–ï¼‰
                    if 'logged_metric' in trial and trial['logged_metric'] is not None:
                        # logged_metric å¯èƒ½æ˜¯ dictï¼Œéœ€è¦å±•å¼€è®°å½•
                        logged_metric = trial['logged_metric']
                        if isinstance(logged_metric, dict):
                            # å¦‚æœæ˜¯ dictï¼Œå±•å¼€è®°å½•æ¯ä¸ªæŒ‡æ ‡
                            for metric_name, metric_value in logged_metric.items():
                                try:
                                    if isinstance(metric_value, (int, float)):
                                        mlflow.log_metric(f"logged_{metric_name}", metric_value)
                                    else:
                                        mlflow.log_param(f"logged_{metric_name}", str(metric_value))
                                except Exception:
                                    pass  # å¿½ç•¥æ— æ³•è®°å½•çš„æŒ‡æ ‡
                        elif isinstance(logged_metric, (int, float)):
                            # å¦‚æœæ˜¯æ•°å­—ï¼Œç›´æ¥è®°å½•
                            mlflow.log_metric("logged_metric", logged_metric)

                    if 'sample_size' in trial and trial['sample_size'] is not None:
                        mlflow.log_param("sample_size", trial['sample_size'])
                    if 'iter_per_learner' in trial and trial['iter_per_learner'] is not None:
                        mlflow.log_param("iter_per_learner", trial['iter_per_learner'])
                    if 'wall_clock_time' in trial and trial['wall_clock_time'] is not None:
                        mlflow.log_metric("wall_clock_time", trial['wall_clock_time'])

                    # è®°å½•ä» search_states è·å–çš„é¢å¤–ä¿¡æ¯
                    if 'search_state_info' in trial:
                        state_info = trial['search_state_info']
                        if state_info.get('sample_size') is not None:
                            mlflow.log_param("search_state_sample_size", state_info['sample_size'])
                        if state_info.get('ls_ever_converged') is not None:
                            mlflow.log_param("ls_ever_converged", state_info['ls_ever_converged'])

                    # è®°å½• tags
                    mlflow.set_tag("trial_type", "best" if is_best else "regular")
                    mlflow.set_tag("estimator_family", estimator)
                    # ğŸ†• æ ‡è®°å­ run æ²¡æœ‰æ³¨å†Œæ¨¡å‹ï¼ˆç”¨äºåç«¯è¿”å›ç©ºæ•°ç»„è€Œä¸æ˜¯ nullï¼‰
                    mlflow.set_tag("wedata.has_registered_model", "false")
                    # ğŸ†• è®¾ç½® datascience.type ä¸º MACHINE_LEARNINGï¼Œå¦åˆ™åç»­æ“ä½œå­ run ä¼šè¢«æœåŠ¡å™¨æ‹’ç»
                    mlflow.set_tag("wedata.datascience.type", "MACHINE_LEARNING")

                    # ğŸ†• è®¾ç½® wedata.projectï¼ˆå¿…é¡»è®¾ç½®ï¼Œå¦åˆ™ DLC ç¯å¢ƒä¸­ run å¯èƒ½æ— æ³•æŒä¹…åŒ–ï¼‰
                    workspace_id = os.environ.get("WEDATA_WORKSPACE_ID", "")
                    if workspace_id:
                        mlflow.set_tag("wedata.project", workspace_id)

                    # ğŸ†• è®¾ç½® mlflow.userï¼ˆå¿…é¡»è®¾ç½®ï¼Œå¦åˆ™ DLC ç¯å¢ƒä¸­ run å¯èƒ½æ— æ³•æŒä¹…åŒ–ï¼‰
                    user_uin = os.environ.get("QCLOUD_SUBUIN") or os.environ.get("QCLOUD_UIN", "")
                    if user_uin:
                        mlflow.set_tag("mlflow.user", user_uin)

                    # å­˜å‚¨ trial ä¿¡æ¯
                    trial_info = {
                        "run_id": trial_run_id,
                        "run_name": run_name,
                        "trial_number_global": global_count,
                        "trial_number_local": local_count,
                        "estimator": estimator,
                        "val_loss": val_loss,
                        "train_time": train_time,
                        "is_best": is_best,
                    }
                    self.trial_runs.append(trial_info)

                # ğŸ†• åœ¨å­ run ç»“æŸåï¼Œåˆ é™¤ mlflow.source.name tag
                # è¿™æ ·åªæœ‰æœ€ä½³å­ run ä¼šä¿ç•™ source.nameï¼ˆé€šè¿‡ set_best_trial_tags è®¾ç½®ï¼‰
                try:
                    client = mlflow.tracking.MlflowClient()
                    client.delete_tag(trial_run_id, "mlflow.source.name")
                except Exception:
                    pass  # tag å¯èƒ½ä¸å­˜åœ¨æˆ–åˆ é™¤å¤±è´¥ï¼Œå¿½ç•¥é”™è¯¯

                # æ›´æ–°æœ€ä½³ trial ä¿¡æ¯
                if val_loss < self.best_trial_val_loss:
                    self.best_trial_val_loss = val_loss
                    self.best_trial_run_id = trial_run_id
                    self.best_trial_run_name = run_name

                # æ‰“å°è¿›åº¦ä¿¡æ¯ï¼ˆæ¯ 10 ä¸ª trial æ‰“å°ä¸€æ¬¡ï¼‰
                if global_count % 10 == 0 or global_count == len(all_trials):
                    safe_print(
                        f"  Progress: {global_count}/{len(all_trials)} trials logged"
                    )

            except Exception as e:
                safe_print(f"âŒ ERROR: Failed to create MLflow run for trial {global_count} ({estimator}): {e}")
                import traceback
                safe_print(f"   Traceback: {traceback.format_exc()}")
                # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª trial
                continue

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.total_trials = global_count
        self.trials_per_estimator = estimator_counts

        safe_print(f"âœ… Successfully created {len(self.trial_runs)} MLflow child runs")

    def get_summary(self) -> Dict[str, Any]:
        """
        è·å– hook çš„ç»Ÿè®¡æ‘˜è¦

        Returns:
            åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        return {
            "total_trials": self.total_trials,
            "trials_per_estimator": dict(self.trials_per_estimator),
            "best_trial_run_id": self.best_trial_run_id,
            "best_trial_run_name": self.best_trial_run_name,
            "best_trial_val_loss": self.best_trial_val_loss,
        }

    def print_summary(self):
        """
        æ‰“å° hook çš„ç»Ÿè®¡æ‘˜è¦
        """
        summary = self.get_summary()

        safe_print("", show_timestamp=False, show_level=False)
        safe_print("=" * 80, show_timestamp=False, show_level=False)
        safe_print("ğŸ“Š TrialHook Summary", show_timestamp=False, show_level=False)
        safe_print("=" * 80, show_timestamp=False, show_level=False)
        safe_print(f"Total trials logged: {summary['total_trials']}")
        safe_print(f"Trials per estimator:")
        for estimator, count in summary['trials_per_estimator'].items():
            safe_print(f"  - {estimator}: {count} trials")
        safe_print(f"Best trial:")
        safe_print(f"  - Run ID: {summary['best_trial_run_id']}")
        safe_print(f"  - Run Name: {summary['best_trial_run_name']}")
        safe_print(f"  - Val Loss: {summary['best_trial_val_loss']:.6f}")
        safe_print("=" * 80, show_timestamp=False, show_level=False)

    def set_best_trial_tags(
        self,
        source_name: Optional[str] = "wedata-automl",
        workspace_id: Optional[str] = None,
        task: Optional[str] = None,
        workflow_id: Optional[str] = None,
        user_uin: Optional[str] = None,
        total_trials_run: Optional[int] = None,
    ) -> bool:
        """
        ä¸ºæœ€ä½³å­ run è®¾ç½®æ‰€æœ‰å¿…è¦çš„ tag

        è®¾ç½®çš„ tag åŒ…æ‹¬ï¼š
        - mlflow.source.name: æ¥æºæ ‡è¯†ï¼ˆå¦‚æœ source_name ä¸º None åˆ™ä¸è®¾ç½®ï¼‰
        - wedata.project: é¡¹ç›® ID
        - wedata.datascience.type: ä»»åŠ¡ç±»å‹
        - wedata.workflowId: å·¥ä½œæµ ID
        - mlflow.user: ç”¨æˆ· UIN
        - wedata.total_trials_run: æ€»è¿è¡Œæ¬¡æ•°
        - wedata.best_run_id: æœ€ä½³å­ run IDï¼ˆæŒ‡å‘è‡ªå·±ï¼‰
        - wedata.best_run_name: æœ€ä½³å­ run åç§°
        - wedata.is_best_trial: æ˜¯å¦ä¸ºæœ€ä½³ trialï¼ˆæ ‡è®°ä¸º trueï¼‰

        Args:
            source_name: è¦è®¾ç½®çš„ source.name å€¼ï¼Œé»˜è®¤ä¸º "wedata-automl"ã€‚
                å¦‚æœä¸º None åˆ™ä¸è®¾ç½® mlflow.source.nameï¼ˆç”¨äº forecast ä»»åŠ¡ï¼‰
            workspace_id: é¡¹ç›® IDï¼Œå¦‚æœä¸º None åˆ™ä»ç¯å¢ƒå˜é‡ WEDATA_WORKSPACE_ID è¯»å–
            task: ä»»åŠ¡ç±»å‹ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨ self.task
            workflow_id: å·¥ä½œæµ IDï¼Œå¦‚æœä¸º None åˆ™ä»ç¯å¢ƒå˜é‡ WEDATA_WORKFLOW_ID è¯»å–
            user_uin: ç”¨æˆ· UINï¼Œå¦‚æœä¸º None åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
            total_trials_run: æ€»è¿è¡Œæ¬¡æ•°ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨ self.total_trials

        Returns:
            æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        if not self.best_trial_run_id:
            safe_print("âš ï¸  No best trial run ID available")
            return False

        try:
            client = mlflow.tracking.MlflowClient()

            # å‡†å¤‡è¦è®¾ç½®çš„ tags
            tags_to_set = {}

            # 1. mlflow.source.nameï¼ˆå¦‚æœ source_name ä¸º None åˆ™ä¸è®¾ç½®ï¼‰
            if source_name is not None:
                tags_to_set["mlflow.source.name"] = source_name

            # 2. wedata.project
            project = workspace_id or os.environ.get("WEDATA_WORKSPACE_ID", "")
            if project:
                tags_to_set["wedata.project"] = project

            # 3. wedata.datascience.type - å¿…é¡»è®¾ç½®ä¸º MACHINE_LEARNINGï¼Œå¦åˆ™æœåŠ¡å™¨ä¼šæ‹’ç»æ“ä½œ
            tags_to_set["wedata.datascience.type"] = "MACHINE_LEARNING"

            # 4. wedata.workflowId
            workflow = workflow_id or os.environ.get("WEDATA_WORKFLOW_ID", "")
            if workflow:
                tags_to_set["wedata.workflowId"] = workflow

            # 5. mlflow.user
            user = user_uin or os.environ.get("WEDATA_USER_UIN") or os.environ.get("USER_UIN", "")
            if user:
                tags_to_set["mlflow.user"] = user

            # 6. wedata.total_trials_run - æ€»è¿è¡Œæ¬¡æ•°
            total_trials = total_trials_run if total_trials_run is not None else self.total_trials
            tags_to_set["wedata.total_trials_run"] = str(total_trials)

            # 7. wedata.best_run_id - æœ€ä½³å­ run IDï¼ˆæŒ‡å‘è‡ªå·±ï¼‰
            tags_to_set["wedata.best_run_id"] = self.best_trial_run_id

            # 8. wedata.best_run_name - æœ€ä½³å­ run åç§°
            if self.best_trial_run_name:
                tags_to_set["wedata.best_run_name"] = self.best_trial_run_name

            # 9. wedata.is_best_trial - æ ‡è®°ä¸ºæœ€ä½³ trial
            tags_to_set["wedata.is_best_trial"] = "true"

            # è®¾ç½®æ‰€æœ‰ tags
            for tag_key, tag_value in tags_to_set.items():
                try:
                    client.set_tag(self.best_trial_run_id, tag_key, tag_value)
                except Exception as tag_err:
                    safe_print(f"âš ï¸  Failed to set tag '{tag_key}': {tag_err}")

            safe_print(f"âœ… Set tags on best trial run: {self.best_trial_run_id}")
            for tag_key, tag_value in tags_to_set.items():
                safe_print(f"   {tag_key}: {tag_value or '(empty)'}")

            return True
        except Exception as e:
            safe_print(f"âš ï¸  Failed to set tags on best trial: {e}")
            return False

    def set_best_trial_source_name(self, source_name: str = "wedata-automl") -> bool:
        """
        ä¸ºæœ€ä½³å­ run è®¾ç½® mlflow.source.name tagï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰

        æ³¨æ„ï¼šæ¨èä½¿ç”¨ set_best_trial_tags() æ–¹æ³•è®¾ç½®æ‰€æœ‰å¿…è¦çš„ tag

        Args:
            source_name: è¦è®¾ç½®çš„ source.name å€¼ï¼Œé»˜è®¤ä¸º "wedata-automl"

        Returns:
            æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        # è°ƒç”¨å®Œæ•´çš„ tag è®¾ç½®æ–¹æ³•
        return self.set_best_trial_tags(source_name=source_name)

    def cleanup_child_runs_source_name(self, experiment_id: str, preserve_best: bool = True) -> int:
        """
        æ¸…ç†å­ run çš„ mlflow.source.name tagï¼Œä¿ç•™æœ€ä½³å­ run çš„ tag

        åœ¨è®­ç»ƒå®Œæˆåè°ƒç”¨æ­¤æ–¹æ³•ï¼Œåˆ é™¤éæœ€ä½³å­ run çš„ mlflow.source.name tagã€‚
        æœ€ä½³å­ run ä¼šä¿ç•™æˆ–è®¾ç½®æ­£ç¡®çš„ source.nameã€‚

        Args:
            experiment_id: MLflow å®éªŒ ID
            preserve_best: æ˜¯å¦ä¿ç•™æœ€ä½³å­ run çš„ source.nameï¼ˆé»˜è®¤ Trueï¼‰

        Returns:
            æˆåŠŸæ¸…ç†çš„å­ run æ•°é‡
        """
        if not self.parent_run_id:
            return 0

        cleaned_count = 0
        try:
            client = mlflow.tracking.MlflowClient()

            # ä½¿ç”¨å·²è®°å½•çš„å­ run IDsï¼ˆä» TrialHook å†…éƒ¨è®°å½•ï¼‰
            # è¿™æ ·å¯ä»¥é¿å… search_runs API çš„å…¼å®¹æ€§é—®é¢˜
            # trial_runs æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« run_id
            child_run_ids = [t.get("run_id") for t in self.trial_runs if t.get("run_id")] if self.trial_runs else []

            if not child_run_ids:
                # å¦‚æœæ²¡æœ‰è®°å½•ï¼Œå°è¯•é€šè¿‡ search_runs æŸ¥æ‰¾ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
                try:
                    child_runs = client.search_runs(
                        experiment_ids=[experiment_id],
                        filter_string=f"tags.`mlflow.parentRunId` = '{self.parent_run_id}'",
                        max_results=1000
                    )
                    child_run_ids = [run.info.run_id for run in child_runs]
                except Exception as search_err:
                    # æŸäº› MLflow æœåŠ¡å™¨å¯èƒ½ä¸æ”¯æŒå¤æ‚çš„ filter
                    safe_print(f"âš ï¸  search_runs failed: {search_err}")
                    # å°è¯•ä¸ä½¿ç”¨ filterï¼Œè·å–æ‰€æœ‰ runs å†è¿‡æ»¤
                    try:
                        all_runs = client.search_runs(
                            experiment_ids=[experiment_id],
                            max_results=1000
                        )
                        child_run_ids = [
                            run.info.run_id for run in all_runs
                            if run.data.tags.get("mlflow.parentRunId") == self.parent_run_id
                        ]
                    except Exception:
                        pass

            # åˆ é™¤éæœ€ä½³å­ run çš„ mlflow.source.name tag
            for run_id in child_run_ids:
                # å¦‚æœæ˜¯æœ€ä½³å­ run ä¸”éœ€è¦ä¿ç•™ï¼Œè·³è¿‡åˆ é™¤
                if preserve_best and run_id == self.best_trial_run_id:
                    continue

                try:
                    run = client.get_run(run_id)
                    if "mlflow.source.name" in run.data.tags:
                        client.delete_tag(run_id, "mlflow.source.name")
                        cleaned_count += 1
                except Exception:
                    pass  # å¿½ç•¥å•ä¸ªåˆ é™¤å¤±è´¥

            if cleaned_count > 0:
                safe_print(f"ğŸ§¹ Cleaned mlflow.source.name from {cleaned_count} non-best child runs")
        except Exception as e:
            safe_print(f"âš ï¸  Failed to cleanup child runs source.name: {e}")

        return cleaned_count

    def register_best_model_to_catalog(
        self,
        model_uri: str,
        model_name: str,
        region: str = "ap-beijing",
        description: Optional[str] = None,
        run_link: Optional[str] = None,
    ) -> Optional[Dict[str, Any]]:
        """
        å°†æœ€ä½³å­ run çš„æ¨¡å‹æ³¨å†Œåˆ° TencentCloud Catalog

        Args:
            model_uri: æ¨¡å‹ URIï¼Œå¦‚ "runs:/{run_id}/model"
            model_name: æ¨¡å‹åç§°ï¼Œæ ¼å¼ä¸º "catalog.schema.model_name"
            region: åœ°åŸŸï¼Œé»˜è®¤ "ap-beijing"
            description: æ¨¡å‹æè¿°
            run_link: MLflow run é“¾æ¥

        Returns:
            æ³¨å†Œç»“æœå­—å…¸ï¼Œå¤±è´¥è¿”å› None
        """
        if not self.best_trial_run_id:
            safe_print("âš ï¸  Catalog æ³¨å†Œè·³è¿‡ï¼šæ²¡æœ‰æœ€ä½³å­ run")
            return None

        try:
            from .catalog_registry import register_model_to_catalog, is_catalog_registry_enabled

            if not is_catalog_registry_enabled():
                safe_print("âš ï¸  Catalog æ³¨å†Œè·³è¿‡ï¼šæœªé…ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡")
                return None

            # æ„å»ºæ¨¡å‹ URIï¼ˆä½¿ç”¨æœ€ä½³å­ run çš„ IDï¼‰
            best_model_uri = model_uri or f"runs:/{self.best_trial_run_id}/model"

            # é¢å¤–çš„ tags
            tags = {
                "task": self.task,
                "metric": self.metric,
                "best_trial_run_name": self.best_trial_run_name or "",
            }

            result = register_model_to_catalog(
                model_uri=best_model_uri,
                model_name=model_name,
                run_id=self.best_trial_run_id,
                run_link=run_link,
                description=description,
                region=region,
                tags=tags,
            )

            return result

        except Exception as e:
            safe_print(f"âš ï¸  Catalog æ³¨å†Œå¤±è´¥: {e}")
            return None

