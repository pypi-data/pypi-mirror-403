"""
FLAMLTrainer - FLAML è®­ç»ƒå™¨

å°è£… FLAML è®­ç»ƒé€»è¾‘ï¼Œæ”¯æŒ Databricks é£æ ¼çš„å‚æ•°
"""
import traceback
from typing import Any, Dict, List, Optional, Union
import logging
import time
import os
import uuid
import tempfile
from datetime import datetime
import pandas as pd
import numpy as np

# ç¦ç”¨ MLflow 2.15+ çš„ LoggedModel åŠŸèƒ½ï¼ˆé¿å…ä¸æ—§ç‰ˆ MLflow æœåŠ¡å™¨ä¸å…¼å®¹ï¼‰
# å¿…é¡»åœ¨ import mlflow ä¹‹å‰è®¾ç½®
os.environ.setdefault("MLFLOW_ENABLE_LOGGED_MODELS", "false")

import mlflow
from sklearn.pipeline import Pipeline as SkPipe

# Robust import for FLAML
try:
    from flaml import AutoML
    import flaml as flaml_pkg
except ImportError:
    try:
        from flaml.automl.automl import AutoML
        import flaml as flaml_pkg
    except ImportError as e:
        raise ImportError(
            "Cannot import AutoML from flaml. "
            "Please install flaml with AutoML support: pip install 'flaml[automl]==2.3.6'"
        ) from e

from wedata_automl.summary import AutoMLSummary
from wedata_automl.utils.sk_pipeline import build_numeric_preprocessor
from wedata_automl.utils.spark_utils import compute_split_and_weights
from wedata_automl.utils.print_utils import safe_print, print_separator, print_header
from wedata_automl.engines.trial_hook import TrialHook

logger = logging.getLogger(__name__)


# ============================================================================
# Log æ–‡ä»¶ç®¡ç†è¾…åŠ©å‡½æ•°
# ============================================================================

def generate_log_file_path(
    base_dir: Optional[str] = None,
    run_id: Optional[str] = None,
    use_timestamp: bool = True,
    use_uuid: bool = True
) -> str:
    """
    ç”Ÿæˆå”¯ä¸€çš„ FLAML log æ–‡ä»¶è·¯å¾„

    è§£å†³çš„é—®é¢˜ï¼š
    1. é¿å…é‡å¤ fit() æ—¶ log è¢«è¦†ç›–
    2. æ”¯æŒå¤šè¿›ç¨‹/å¤šèŠ‚ç‚¹ç¯å¢ƒ
    3. ä¾¿äºæ—¥å¿—ç®¡ç†å’Œæ¸…ç†

    Args:
        base_dir: åŸºç¡€ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨ç³»ç»Ÿä¸´æ—¶ç›®å½•
        run_id: MLflow run IDï¼Œç”¨äºå…³è” log æ–‡ä»¶
        use_timestamp: æ˜¯å¦åœ¨æ–‡ä»¶åä¸­åŒ…å«æ—¶é—´æˆ³
        use_uuid: æ˜¯å¦åœ¨æ–‡ä»¶åä¸­åŒ…å« UUID

    Returns:
        log æ–‡ä»¶çš„å®Œæ•´è·¯å¾„

    Example:
        >>> path = generate_log_file_path()
        >>> # /tmp/wedata_automl/flaml_20251125_143022_abc123_run456.log
    """
    # ç¡®å®šåŸºç¡€ç›®å½•
    if base_dir is None:
        # ä½¿ç”¨ç³»ç»Ÿä¸´æ—¶ç›®å½• + wedata_automl å­ç›®å½•
        base_dir = os.path.join(tempfile.gettempdir(), "wedata_automl", "flaml_logs")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(base_dir, exist_ok=True)

    # æ„å»ºæ–‡ä»¶å
    parts = ["flaml"]

    if use_timestamp:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        parts.append(timestamp)

    if use_uuid:
        short_uuid = str(uuid.uuid4())[:8]
        parts.append(short_uuid)

    if run_id:
        parts.append(f"run{run_id[:8]}")

    filename = "_".join(parts) + ".log"

    return os.path.join(base_dir, filename)


def cleanup_old_log_files(
    base_dir: Optional[str] = None,
    max_age_hours: int = 24,
    max_files: int = 100,
    dry_run: bool = False
) -> int:
    """
    æ¸…ç†æ—§çš„ FLAML log æ–‡ä»¶

    è§£å†³çš„é—®é¢˜ï¼š
    1. é˜²æ­¢ log æ–‡ä»¶ç´¯ç§¯è¿‡å¤š
    2. è‡ªåŠ¨æ¸…ç†è¿‡æœŸçš„ log æ–‡ä»¶

    Args:
        base_dir: åŸºç¡€ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨ç³»ç»Ÿä¸´æ—¶ç›®å½•
        max_age_hours: æœ€å¤§ä¿ç•™æ—¶é—´ï¼ˆå°æ—¶ï¼‰ï¼Œè¶…è¿‡æ­¤æ—¶é—´çš„æ–‡ä»¶å°†è¢«åˆ é™¤
        max_files: æœ€å¤§ä¿ç•™æ–‡ä»¶æ•°ï¼Œè¶…è¿‡æ­¤æ•°é‡çš„æ—§æ–‡ä»¶å°†è¢«åˆ é™¤
        dry_run: æ˜¯å¦åªæ¨¡æ‹Ÿè¿è¡Œï¼ˆä¸å®é™…åˆ é™¤ï¼‰

    Returns:
        åˆ é™¤çš„æ–‡ä»¶æ•°é‡

    Example:
        >>> # åˆ é™¤ 24 å°æ—¶å‰çš„ log æ–‡ä»¶
        >>> count = cleanup_old_log_files(max_age_hours=24)
        >>> print(f"Deleted {count} old log files")
    """
    if base_dir is None:
        base_dir = os.path.join(tempfile.gettempdir(), "wedata_automl", "flaml_logs")

    if not os.path.exists(base_dir):
        return 0

    import glob

    # è·å–æ‰€æœ‰ log æ–‡ä»¶
    log_files = glob.glob(os.path.join(base_dir, "flaml_*.log"))

    if not log_files:
        return 0

    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    log_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)

    deleted_count = 0
    current_time = time.time()
    max_age_seconds = max_age_hours * 3600

    for i, log_file in enumerate(log_files):
        should_delete = False
        reason = ""

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§æ–‡ä»¶æ•°
        if i >= max_files:
            should_delete = True
            reason = f"exceeds max_files ({max_files})"

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§ä¿ç•™æ—¶é—´
        file_age = current_time - os.path.getmtime(log_file)
        if file_age > max_age_seconds:
            should_delete = True
            reason = f"older than {max_age_hours} hours"

        if should_delete:
            if dry_run:
                safe_print(f"[DRY RUN] Would delete: {log_file} ({reason})")
            else:
                try:
                    os.remove(log_file)
                    deleted_count += 1
                    safe_print(f"Deleted old log file: {log_file} ({reason})")
                except Exception as e:
                    safe_print(f"Failed to delete {log_file}: {e}")

    return deleted_count


# ============================================================================
# MLflow Artifact æ—¥å¿—è®°å½•è¾…åŠ©å‡½æ•°
# ============================================================================

def setup_mlflow_user_id() -> str:
    """
    è®¾ç½® MLflow Run çš„ user_id

    ä»ç¯å¢ƒå˜é‡ QCLOUD_UIN è·å–ç”¨æˆ· UINï¼Œå¹¶è®¾ç½®åˆ° MLFLOW_TRACKING_USERNAME ç¯å¢ƒå˜é‡ã€‚
    MLflow åœ¨åˆ›å»º Run æ—¶ä¼šè‡ªåŠ¨ä½¿ç”¨æ­¤ç¯å¢ƒå˜é‡ä½œä¸º RunInfo.user_idã€‚

    Returns:
        ç”¨æˆ· UIN å­—ç¬¦ä¸²
    """
    user_uin = os.environ.get("QCLOUD_SUBUIN", "")
    if user_uin:
        # è®¾ç½® MLFLOW_TRACKING_USERNAMEï¼ŒMLflow ä¼šä½¿ç”¨å®ƒä½œä¸º RunInfo.user_id
        os.environ["MLFLOW_TRACKING_USERNAME"] = user_uin
        safe_print(f"âœ… Set MLFLOW_TRACKING_USERNAME (user_id): {user_uin}")
    else:
        safe_print("âš ï¸  QCLOUD_SUBUIN not found, user_id will be empty")
    return user_uin


def _get_wedata_tags(task: str = "classification") -> Dict[str, str]:
    """
    è·å– WeData å¹³å°ç›¸å…³çš„ tags

    ä»ç¯å¢ƒå˜é‡è¯»å–ä»¥ä¸‹ä¿¡æ¯:
    - WEDATA_WORKSPACE_ID: é¡¹ç›® ID
    - QCLOUD_UIN: ç”¨æˆ· UIN
    - KERNEL_SUBMIT_FORM_WORKFLOW: å·¥ä½œæµ ID

    Args:
        task: ä»»åŠ¡ç±»å‹ (classification/regression/forecast)

    Returns:
        WeData tags å­—å…¸
    """
    # ä»ç¯å¢ƒå˜é‡è·å– WeData ä¿¡æ¯
    workspace_id = os.environ.get("WEDATA_WORKSPACE_ID", "")
    user_uin = os.environ.get("QCLOUD_SUBUIN", "")
    workflow_id = os.environ.get("KERNEL_SUBMIT_FORM_WORKFLOW", "")

    # ä»»åŠ¡ç±»å‹æ˜ å°„
    # datascience_type_map = {
    #     "classification": "AUTOML_CLASSIFICATION",
    #     "regression": "AUTOML_REGRESSION",
    #     "forecast": "AUTOML_PREDICTION",
    # }
    datascience_type = "MACHINE_LEARNING"

    return {
        "wedata.project": workspace_id,
        "wedata.datascience.type": datascience_type,
        "wedata.workflowId": workflow_id,
        "mlflow.user": user_uin,
    }


def set_run_wedata_tags(task: str = "classification") -> None:
    """
    ä¸ºå½“å‰ MLflow Run è®¾ç½® WeData å¹³å°ç›¸å…³çš„ tags

    Args:
        task: ä»»åŠ¡ç±»å‹ (classification/regression/forecast)
    """
    try:
        tags = _get_wedata_tags(task)
        mlflow.set_tags(tags)

        safe_print(f"âœ… Set WeData tags on Run:")
        safe_print(f"   wedata.project: {tags['wedata.project'] or '(empty)'}")
        safe_print(f"   wedata.datascience.type: {tags['wedata.datascience.type']}")
        safe_print(f"   wedata.workflowId: {tags['wedata.workflowId'] or '(empty)'}")
        safe_print(f"   mlflow.user: {tags['mlflow.user'] or '(empty)'}")

    except Exception as e:
        logger.warning(f"Failed to set Run WeData tags: {e}")
        safe_print(f"âš ï¸  Failed to set WeData tags on Run: {e}")


def set_model_version_wedata_tags(
    registered_model_name: str,
    model_version: str,
    task: str = "classification"
) -> None:
    """
    ä¸ºæ³¨å†Œçš„æ¨¡å‹ç‰ˆæœ¬è®¾ç½® WeData å¹³å°ç›¸å…³çš„ tags

    Args:
        registered_model_name: æ³¨å†Œæ¨¡å‹åç§°
        model_version: æ¨¡å‹ç‰ˆæœ¬å·
        task: ä»»åŠ¡ç±»å‹ (classification/regression/forecast)
    """
    try:
        client = mlflow.tracking.MlflowClient()
        tags = _get_wedata_tags(task)

        for tag_key, tag_value in tags.items():
            try:
                client.set_model_version_tag(
                    name=registered_model_name,
                    version=str(model_version),
                    key=tag_key,
                    value=tag_value or ""
                )
            except Exception as e:
                logger.warning(f"Failed to set model version tag {tag_key}: {e}")

        safe_print(f"âœ… Set WeData tags on model version: {registered_model_name} v{model_version}")
        safe_print(f"   wedata.project: {tags['wedata.project'] or '(empty)'}")
        safe_print(f"   wedata.datascience.type: {tags['wedata.datascience.type']}")
        safe_print(f"   mlflow.user: {tags['mlflow.user'] or '(empty)'}")

    except Exception as e:
        logger.warning(f"Failed to set model version WeData tags: {e}")
        safe_print(f"âš ï¸  Failed to set WeData tags on model version: {e}")


def log_feature_list(features: List[str]):
    """è®°å½•ç‰¹å¾åˆ—è¡¨åˆ° MLflow"""
    import json
    mlflow.log_dict({"features": features}, "feature_list.json")


def log_best_config_overall(config: Dict[str, Any]):
    """è®°å½•æœ€ä½³é…ç½®åˆ° MLflow"""
    import json
    mlflow.log_dict(config, "best_config_overall.json")


def log_best_config_per_estimator(config: Dict[str, Any]):
    """è®°å½•æ¯ä¸ªä¼°è®¡å™¨çš„æœ€ä½³é…ç½®åˆ° MLflow"""
    import json
    mlflow.log_dict(config, "best_config_per_estimator.json")


def log_engine_meta(meta: Dict[str, Any]):
    """è®°å½•å¼•æ“å…ƒæ•°æ®åˆ° MLflow"""
    import json
    mlflow.log_dict(meta, "engine_meta.json")


def write_failure_file(
    error: Exception,
    run_id: Optional[str] = None,
    experiment_name: Optional[str] = None,
    task: Optional[str] = None,
    fail_dir: Optional[str] = None,
) -> str:
    """
    åœ¨è®­ç»ƒå¤±è´¥æ—¶å†™å…¥ fail æ–‡ä»¶

    æ–‡ä»¶å‘½åæ ¼å¼: fail_{run_id}_{timestamp}.json
    æ–‡ä»¶å†…å®¹åŒ…å«:
    - error_type: å¼‚å¸¸ç±»å‹
    - error_message: é”™è¯¯ä¿¡æ¯
    - traceback: å®Œæ•´å †æ ˆ
    - run_id: MLflow Run ID
    - experiment_name: å®éªŒåç§°
    - task: ä»»åŠ¡ç±»å‹
    - timestamp: å¤±è´¥æ—¶é—´

    Args:
        error: å¼‚å¸¸å¯¹è±¡
        run_id: MLflow Run IDï¼ˆå¯é€‰ï¼‰
        experiment_name: å®éªŒåç§°ï¼ˆå¯é€‰ï¼‰
        task: ä»»åŠ¡ç±»å‹ï¼ˆå¯é€‰ï¼‰
        fail_dir: fail æ–‡ä»¶ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ä¸´æ—¶ç›®å½•ï¼‰

    Returns:
        ç”Ÿæˆçš„ fail æ–‡ä»¶è·¯å¾„
    """
    import json
    from datetime import datetime

    # ç¡®å®š fail ç›®å½•
    if fail_dir is None:
        fail_dir = os.path.join(tempfile.gettempdir(), "wedata_automl", "fail")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(fail_dir, exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_id_part = run_id[:8] if run_id else "unknown"
    filename = f"fail_{run_id_part}_{timestamp}.json"
    filepath = os.path.join(fail_dir, filename)

    # æ„å»ºå¤±è´¥ä¿¡æ¯
    fail_info = {
        "error_type": type(error).__name__,
        "error_message": str(error),
        "traceback": traceback.format_exc(),
        "run_id": run_id,
        "experiment_name": experiment_name,
        "task": task,
        "timestamp": datetime.now().isoformat(),
    }

    # å†™å…¥æ–‡ä»¶
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(fail_info, f, indent=2, ensure_ascii=False)
        safe_print(f"âŒ Failure recorded: {filepath}")
    except Exception as write_error:
        safe_print(f"âš ï¸  Failed to write failure file: {write_error}")
        # å°è¯•å†™å…¥ç®€åŒ–ç‰ˆæœ¬
        try:
            simple_info = {
                "error_type": type(error).__name__,
                "error_message": str(error)[:1000],
                "timestamp": datetime.now().isoformat(),
            }
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(simple_info, f, indent=2)
        except Exception:
            pass

    return filepath


class TrialLogger:
    """
    FLAML Trial æ—¥å¿—è®°å½•å™¨

    ç”¨äºè®°å½•æ¯ä¸ª trial çš„è¯¦ç»†ä¿¡æ¯åˆ° MLflow
    """

    def __init__(self, parent_run_id: str, features: List[str], task: str, metric: str):
        """
        åˆå§‹åŒ– Trial Logger

        Args:
            parent_run_id: çˆ¶ run çš„ ID
            features: ç‰¹å¾åˆ—è¡¨
            task: ä»»åŠ¡ç±»å‹
            metric: è¯„ä¼°æŒ‡æ ‡
        """
        self.parent_run_id = parent_run_id
        self.features = features
        self.task = task
        self.metric = metric
        self.trial_count = 0
        self.trial_runs = []  # å­˜å‚¨æ‰€æœ‰ trial çš„ä¿¡æ¯

    def log_trial(self, config: Dict[str, Any], estimator: str, val_loss: float, train_time: float):
        """
        è®°å½•å•ä¸ª trial åˆ° MLflow

        Args:
            config: è¶…å‚æ•°é…ç½®
            estimator: ä¼°è®¡å™¨åç§°
            val_loss: éªŒè¯é›†æŸå¤±
            train_time: è®­ç»ƒæ—¶é—´
        """
        self.trial_count += 1

        try:
            # åˆ›å»ºåµŒå¥— run
            with mlflow.start_run(run_name=f"trial_{self.trial_count}_{estimator}", nested=True) as trial_run:
                trial_run_id = trial_run.info.run_id

                # ğŸ†• åˆ é™¤å­ run çš„ mlflow.source.name tagï¼ˆä¸éœ€è¦è®°å½•æ–‡ä»¶è·¯å¾„ï¼‰
                try:
                    mlflow.delete_tag("mlflow.source.name")
                except Exception:
                    pass  # tag å¯èƒ½ä¸å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯

                # è®°å½•å‚æ•°
                mlflow.log_param("estimator", estimator)
                mlflow.log_param("trial_number", self.trial_count)
                mlflow.log_param("parent_run_id", self.parent_run_id)
                mlflow.log_param("primaryMetric", self.metric)  # ğŸ†• è®°å½•ç”¨æˆ·æŒ‡å®šçš„ä¸»è¦è¯„ä¼°æŒ‡æ ‡

                # è®°å½•è¶…å‚æ•°
                for key, value in config.items():
                    try:
                        mlflow.log_param(f"hp_{key}", value)
                    except Exception as e:
                        # æŸäº›å€¼å¯èƒ½æ— æ³•åºåˆ—åŒ–
                        safe_print(f"âš ï¸  DEBUG: Failed to log param hp_{key}={value}: {e}")
                        mlflow.log_param(f"hp_{key}", str(value))

                # è®°å½•æŒ‡æ ‡ - åŒæ—¶è®°å½• val_loss å’Œç”¨æˆ·æŒ‡å®šçš„ metric
                mlflow.log_metric("val_loss", val_loss)
                mlflow.log_metric("train_time", train_time)

                # ğŸ†• å°† val_loss è½¬æ¢ä¸ºç”¨æˆ·æŒ‡å®šçš„ metric å€¼
                metric_value = self._convert_val_loss_to_metric(val_loss)
                mlflow.log_metric(self.metric, metric_value)

                # è®°å½•ç‰¹å¾åˆ—è¡¨
                log_feature_list(self.features)

                # ğŸ†• æ ‡è®°å­ run æ²¡æœ‰æ³¨å†Œæ¨¡å‹ï¼ˆç”¨äºåç«¯è¿”å›ç©ºæ•°ç»„è€Œä¸æ˜¯ nullï¼‰
                mlflow.set_tag("wedata.has_registered_model", "false")

                # å­˜å‚¨ trial ä¿¡æ¯
                trial_info = {
                    "run_id": trial_run_id,
                    "trial_number": self.trial_count,
                    "estimator": estimator,
                    "val_loss": val_loss,
                    "train_time": train_time,
                    "config": config,
                }
                self.trial_runs.append(trial_info)

                safe_print(f"  Trial {self.trial_count:3d} | {estimator:15s} | val_loss={val_loss:.6f} | time={train_time:.2f}s")
        except Exception as e:
            safe_print(f"âŒ DEBUG: Exception in log_trial for trial {self.trial_count}: {e}")
            import traceback
            safe_print(f"   Traceback: {traceback.format_exc()}")
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©å¤–å±‚æ•è·
            raise

    def _convert_val_loss_to_metric(self, val_loss: float) -> float:
        """
        å°† FLAML çš„ val_loss è½¬æ¢ä¸ºç”¨æˆ·æŒ‡å®šçš„ metric å€¼

        FLAML å†…éƒ¨ç»Ÿä¸€ä½¿ç”¨ val_lossï¼ˆè¶Šå°è¶Šå¥½ï¼‰ï¼š
        - å¯¹äº"è¶Šå°è¶Šå¥½"çš„æŒ‡æ ‡ï¼ˆå¦‚ log_loss, mseï¼‰: val_loss = metric_value
        - å¯¹äº"è¶Šå¤§è¶Šå¥½"çš„æŒ‡æ ‡ï¼ˆå¦‚ accuracy, f1ï¼‰: val_loss = 1 - metric_value

        Args:
            val_loss: FLAML çš„ val_loss å€¼

        Returns:
            ç”¨æˆ·æŒ‡å®šçš„ metric å€¼
        """
        # "è¶Šå¤§è¶Šå¥½"çš„æŒ‡æ ‡åˆ—è¡¨
        maximize_metrics = [
            "accuracy", "f1", "macro_f1", "micro_f1", "weighted_f1",
            "roc_auc", "roc_auc_ovr", "roc_auc_ovo", "roc_auc_weighted",
            "precision", "recall", "ap",
            "r2",
        ]

        # å¦‚æœæ˜¯"è¶Šå¤§è¶Šå¥½"çš„æŒ‡æ ‡ï¼Œéœ€è¦è½¬æ¢å›æ¥
        if self.metric in maximize_metrics:
            return 1.0 - val_loss
        else:
            # "è¶Šå°è¶Šå¥½"çš„æŒ‡æ ‡ï¼Œç›´æ¥è¿”å›
            return val_loss

    def get_best_trial(self) -> Dict[str, Any]:
        """
        è·å–æœ€ä½³ trial

        Returns:
            æœ€ä½³ trial çš„ä¿¡æ¯å­—å…¸
        """
        if not self.trial_runs:
            return None

        # æŒ‰ val_loss æ’åºï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        best_trial = min(self.trial_runs, key=lambda x: x["val_loss"])
        return best_trial


# ============================================================================
# Forecast æ¨¡å‹ MLflow PythonModel åŒ…è£…å™¨
# ============================================================================

class ForecastModelWrapper(mlflow.pyfunc.PythonModel):
    """
    æ—¶åºé¢„æµ‹æ¨¡å‹çš„ MLflow PythonModel åŒ…è£…å™¨

    å°† FLAML è®­ç»ƒçš„æ—¶åºé¢„æµ‹æ¨¡å‹åŒ…è£…ä¸ºæ ‡å‡†çš„ MLflow pyfunc æ¨¡å‹ï¼Œ
    æ”¯æŒé€šè¿‡ mlflow.pyfunc.load_model() åŠ è½½å’Œé¢„æµ‹ã€‚

    Attributes:
        model: FLAML è®­ç»ƒçš„æ—¶åºé¢„æµ‹æ¨¡å‹ï¼ˆæˆ– Pipelineï¼‰
        horizon: é¢„æµ‹æ—¶é—´èŒƒå›´
        frequency: æ—¶é—´é¢‘ç‡ï¼ˆD/W/M/H ç­‰ï¼‰
        time_col: æ—¶é—´åˆ—å
        target_col: ç›®æ ‡åˆ—å
        estimator: æœ€ä½³ä¼°è®¡å™¨åç§°

    Example:
        >>> # åŠ è½½æ¨¡å‹
        >>> model = mlflow.pyfunc.load_model("runs:/xxx/model")
        >>> # é¢„æµ‹
        >>> future_dates = pd.DataFrame({"ds": pd.date_range("2024-01-01", periods=6, freq="D")})
        >>> predictions = model.predict(future_dates)
    """

    def __init__(
        self,
        model=None,
        horizon: int = 1,
        frequency: str = "D",
        time_col: str = "ds",
        target_col: str = "y",
        estimator: str = "unknown",
    ):
        """
        åˆå§‹åŒ– ForecastModelWrapper

        Args:
            model: FLAML è®­ç»ƒçš„æ—¶åºé¢„æµ‹æ¨¡å‹
            horizon: é¢„æµ‹æ—¶é—´èŒƒå›´
            frequency: æ—¶é—´é¢‘ç‡
            time_col: æ—¶é—´åˆ—å
            target_col: ç›®æ ‡åˆ—å
            estimator: æœ€ä½³ä¼°è®¡å™¨åç§°
        """
        self.model = model
        self.horizon = horizon
        self.frequency = frequency
        self.time_col = time_col
        self.target_col = target_col
        self.estimator = estimator

    def predict(self, context, model_input: pd.DataFrame) -> pd.DataFrame:
        """
        æ‰§è¡Œé¢„æµ‹

        Args:
            context: MLflow æ¨¡å‹ä¸Šä¸‹æ–‡ï¼ˆåŒ…å« artifacts è·¯å¾„ç­‰ï¼‰
            model_input: è¾“å…¥æ•°æ®ï¼Œåº”åŒ…å«æ—¶é—´åˆ—

        Returns:
            é¢„æµ‹ç»“æœ DataFrameï¼ŒåŒ…å«æ—¶é—´åˆ—å’Œé¢„æµ‹å€¼åˆ—
        """
        if self.model is None:
            raise ValueError("Model not loaded. Please load the model first.")

        # è·å–è¾“å…¥çš„æ—¶é—´åˆ—
        if self.time_col in model_input.columns:
            future_dates = pd.to_datetime(model_input[self.time_col])
        else:
            # å¦‚æœæ²¡æœ‰æ—¶é—´åˆ—ï¼Œä½¿ç”¨é»˜è®¤çš„æœªæ¥æ—¥æœŸ
            future_dates = pd.date_range(
                start=pd.Timestamp.now(),
                periods=self.horizon,
                freq=self.frequency
            )

        # æ„é€ é¢„æµ‹è¾“å…¥
        future_X = pd.DataFrame({self.time_col: future_dates})

        # æ‰§è¡Œé¢„æµ‹
        try:
            predictions = self.model.predict(future_X)
        except Exception as e:
            # æŸäº›æ¨¡å‹å¯èƒ½ä¸æ”¯æŒä¼ å…¥æ—¶é—´åˆ—ï¼Œå°è¯•ç›´æ¥é¢„æµ‹
            try:
                predictions = self.model.predict(model_input)
            except Exception:
                raise ValueError(f"Prediction failed: {e}")

        # ç¡®ä¿é¢„æµ‹ç»“æœé•¿åº¦ä¸è¾“å…¥ä¸€è‡´
        n_predictions = len(future_dates)
        if len(predictions) > n_predictions:
            predictions = predictions[:n_predictions]
        elif len(predictions) < n_predictions:
            # å¡«å……ä¸è¶³çš„éƒ¨åˆ†
            predictions = np.pad(
                predictions,
                (0, n_predictions - len(predictions)),
                mode='edge'
            )

        # æ„é€ è¾“å‡º DataFrame
        result = pd.DataFrame({
            self.time_col: future_dates,
            f"predicted_{self.target_col}": predictions
        })

        return result


class FLAMLTrainer:
    """
    FLAML è®­ç»ƒå™¨
    
    å°è£… FLAML è®­ç»ƒé€»è¾‘ï¼Œæ”¯æŒ Databricks é£æ ¼çš„å‚æ•°
    """
    
    def __init__(
        self,
        task: str,
        target_col: str,
        timeout_minutes: int = 5,
        max_trials: Optional[int] = None,
        metric: str = "auto",
        exclude_cols: Optional[List[str]] = None,
        exclude_frameworks: Optional[List[str]] = None,
        estimator_list: Optional[List[str]] = None,
        sample_weight_col: Optional[str] = None,
        pos_label: Optional[Union[str, int]] = None,
        data_split_col: Optional[str] = None,
        experiment_name: Optional[str] = None,
        experiment_id: Optional[str] = None,
        run_name: Optional[str] = None,
        register_model: bool = True,
        model_name: Optional[str] = None,
        max_concurrent_trials: int = 1,
        use_spark: bool = False,
        custom_hp: Optional[Dict[str, Any]] = None,
        workspace_id: Optional[str] = None,
        log_file_dir: Optional[str] = None,
        auto_cleanup_logs: bool = True,
        log_max_age_hours: int = 24,
        log_max_files: int = 100,
        imputers: Optional[Dict[str, Union[str, Dict[str, Any]]]] = None,
        country_code: Optional[str] = "US",
        feature_store_lookups: Optional[List[Dict[str, Any]]] = None,
        # Catalog æ³¨å†Œå‚æ•°
        register_to_catalog: bool = False,
        catalog_model_name: Optional[str] = None,
        catalog_region: str = "ap-beijing",
        **kwargs
    ):
        """
        åˆå§‹åŒ– FLAML è®­ç»ƒå™¨

        Args:
            task: ä»»åŠ¡ç±»å‹ ("classification" æˆ– "regression")
            target_col: ç›®æ ‡åˆ—å
            timeout_minutes: è¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
            max_trials: æœ€å¤§è¯•éªŒæ¬¡æ•°
            metric: è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºé€‰æ‹©æœ€ä½³æ¨¡å‹
                åˆ†ç±»ä»»åŠ¡å¯é€‰:
                    - 'log_loss': å¯¹æ•°æŸå¤±ï¼ˆé»˜è®¤ï¼Œæ¨èç”¨äºå¤šåˆ†ç±»ï¼‰
                    - 'accuracy': å‡†ç¡®ç‡ï¼ˆé€‚åˆç±»åˆ«å¹³è¡¡çš„æ•°æ®ï¼‰
                    - 'roc_auc': ROC AUCï¼ˆäºŒåˆ†ç±»ï¼‰
                    - 'f1': F1 åˆ†æ•°ï¼ˆäºŒåˆ†ç±»æˆ– macro/micro F1ï¼‰
                    - 'macro_f1': Macro-averaged F1ï¼ˆå¤šåˆ†ç±»ï¼Œç±»åˆ«ä¸å¹³è¡¡ï¼‰
                    - 'micro_f1': Micro-averaged F1ï¼ˆå¤šåˆ†ç±»ï¼‰
                    - 'roc_auc_ovr': One-vs-Rest ROC AUCï¼ˆå¤šåˆ†ç±»ï¼‰
                    - 'roc_auc_ovo': One-vs-One ROC AUCï¼ˆå¤šåˆ†ç±»ï¼‰
                    - 'precision': ç²¾ç¡®ç‡
                    - 'recall': å¬å›ç‡
                    - 'ap': Average Precision
                å›å½’ä»»åŠ¡å¯é€‰:
                    - 'r2': RÂ² åˆ†æ•°
                    - 'mse': å‡æ–¹è¯¯å·®
                    - 'rmse': å‡æ–¹æ ¹è¯¯å·®
                    - 'mae': å¹³å‡ç»å¯¹è¯¯å·®
                    - 'mape': å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®
                æ³¨æ„: FLAML å†…éƒ¨ä¼šå°†æŒ‡æ ‡è½¬æ¢ä¸º val_lossï¼ˆæŸå¤±å€¼ï¼Œè¶Šå°è¶Šå¥½ï¼‰
                      - å¯¹äº"è¶Šå°è¶Šå¥½"çš„æŒ‡æ ‡ï¼ˆå¦‚ log_loss, mseï¼‰: val_loss = metric_value
                      - å¯¹äº"è¶Šå¤§è¶Šå¥½"çš„æŒ‡æ ‡ï¼ˆå¦‚ accuracy, f1ï¼‰: val_loss = 1 - metric_value
            exclude_cols: æ’é™¤çš„åˆ—
            exclude_frameworks: æ’é™¤çš„æ¡†æ¶ï¼ˆå·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ estimator_listï¼‰
            estimator_list: ä¼°è®¡å™¨åˆ—è¡¨ï¼Œé»˜è®¤ Noneï¼ˆä½¿ç”¨æ‰€æœ‰å¯ç”¨ä¼°è®¡å™¨ï¼‰
                å¯é€‰å€¼: ["lgbm", "xgboost", "rf", "extra_tree", "lrl1"]
                ä¾‹å¦‚: ["lgbm", "xgboost"] åªä½¿ç”¨ LightGBM å’Œ XGBoost
                æ³¨æ„: lrl1 ä»…é€‚ç”¨äºåˆ†ç±»ä»»åŠ¡
            sample_weight_col: æ ·æœ¬æƒé‡åˆ—
            pos_label: æ­£ç±»æ ‡ç­¾ï¼ˆäºŒåˆ†ç±»ï¼‰
            data_split_col: æ•°æ®åˆ’åˆ†åˆ—
            experiment_name: MLflow å®éªŒåç§°
            experiment_id: MLflow å®éªŒ ID
            run_name: MLflow run åç§°
            register_model: æ˜¯å¦æ³¨å†Œæ¨¡å‹
            model_name: æ¨¡å‹åç§°
            max_concurrent_trials: å¹¶å‘ trials æ•°é‡ï¼Œé»˜è®¤ 1ï¼ˆé¡ºåºæ‰§è¡Œï¼‰
                - è®¾ç½® > 1 æ—¶ï¼ŒFLAML ä¼šå¹¶è¡Œæ‰§è¡Œå¤šä¸ª trials
                - æœ¬åœ°æ¨¡å¼ï¼šä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œ
                - Spark æ¨¡å¼ï¼šä½¿ç”¨ Spark åˆ†å¸ƒå¼å¹¶è¡Œï¼ˆéœ€è¦è®¾ç½® use_spark=Trueï¼‰
                - æ³¨æ„ï¼šå¹¶å‘ä¼šå¢åŠ å†…å­˜å’Œ CPU ä½¿ç”¨
            use_spark: æ˜¯å¦ä½¿ç”¨ Spark ä½œä¸ºå¹¶è¡Œåç«¯ï¼Œé»˜è®¤ False
                - True: ä½¿ç”¨ Spark åˆ†å¸ƒå¼æ‰§è¡Œ trialsï¼ˆéœ€è¦ Spark é›†ç¾¤ï¼‰
                - False: ä½¿ç”¨æœ¬åœ°å¤šçº¿ç¨‹å¹¶è¡Œ
                - æ³¨æ„ï¼šSpark æ¨¡å¼ä¸æ”¯æŒ GPU è®­ç»ƒ
            custom_hp: è‡ªå®šä¹‰è¶…å‚æ•°æœç´¢ç©ºé—´ï¼Œæ ¼å¼ä¸º {estimator_name: {param_name: search_space}}
                ä¾‹å¦‚: {"lgbm": {"n_estimators": {"domain": range(100, 1000), "init_value": 100}}}
            workspace_id: é¡¹ç›® IDï¼Œç”¨äºå¤šç§Ÿæˆ·éš”ç¦»ï¼ˆè®¾ç½®ä¸ºå®éªŒæ ‡ç­¾ 'wedata.project'ï¼‰
                - ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ workspace_id å‚æ•°
                - å¦‚æœæœªä¼ å…¥ï¼Œåˆ™ä»ç¯å¢ƒå˜é‡ WEDATA_WORKSPACE_ID è¯»å–
                - å¦‚æœéƒ½æœªé…ç½®ï¼Œåˆ™æŠ›å‡º ValueError å¼‚å¸¸
            log_file_dir: FLAML log æ–‡ä»¶å­˜å‚¨ç›®å½•ï¼Œé»˜è®¤ Noneï¼ˆä½¿ç”¨ç³»ç»Ÿä¸´æ—¶ç›®å½•ï¼‰
                - å»ºè®®åœ¨ DLC Spark ç¯å¢ƒä¸‹è®¾ç½®ä¸ºå…±äº«å­˜å‚¨è·¯å¾„ï¼ˆå¦‚ HDFSã€COSï¼‰
                - ä¾‹å¦‚: "/tmp/wedata_automl/logs" æˆ– "hdfs:///user/wedata/logs"
            auto_cleanup_logs: æ˜¯å¦è‡ªåŠ¨æ¸…ç†æ—§çš„ log æ–‡ä»¶ï¼Œé»˜è®¤ True
                - True: æ¯æ¬¡è®­ç»ƒå‰è‡ªåŠ¨æ¸…ç†è¿‡æœŸçš„ log æ–‡ä»¶
                - False: ä¸æ¸…ç†ï¼Œéœ€è¦æ‰‹åŠ¨ç®¡ç†
            log_max_age_hours: log æ–‡ä»¶æœ€å¤§ä¿ç•™æ—¶é—´ï¼ˆå°æ—¶ï¼‰ï¼Œé»˜è®¤ 24
                - è¶…è¿‡æ­¤æ—¶é—´çš„ log æ–‡ä»¶å°†è¢«è‡ªåŠ¨æ¸…ç†
            log_max_files: log æ–‡ä»¶æœ€å¤§ä¿ç•™æ•°é‡ï¼Œé»˜è®¤ 100
                - è¶…è¿‡æ­¤æ•°é‡çš„æ—§ log æ–‡ä»¶å°†è¢«è‡ªåŠ¨æ¸…ç†
            imputers: ç¼ºå¤±å€¼å¡«å……ç­–ç•¥å­—å…¸ï¼Œæ ¼å¼ä¸º {åˆ—å: å¡«å……ç­–ç•¥}ï¼Œé»˜è®¤ None
                - å¡«å……ç­–ç•¥å¯ä»¥æ˜¯å­—ç¬¦ä¸²ï¼š
                    - "auto": è‡ªåŠ¨é€‰æ‹©ï¼ˆé»˜è®¤ä½¿ç”¨ medianï¼‰
                    - "mean": å‡å€¼å¡«å……
                    - "median": ä¸­ä½æ•°å¡«å……
                    - "most_frequent": ä¼—æ•°å¡«å……
                - æˆ–è€…å­—å…¸ï¼ˆç”¨äºå¸¸é‡å¡«å……ï¼‰ï¼š
                    - {"strategy": "constant", "fill_value": <value>}
                - ç¤ºä¾‹ï¼š
                    imputers={
                        "age": "mean",
                        "income": "median",
                        "status": {"strategy": "constant", "fill_value": 0}
                    }
            country_code: èŠ‚å‡æ—¥å›½å®¶ä»£ç ï¼Œé»˜è®¤ "US"ï¼ˆä»… Prophet æ—¶åºé¢„æµ‹ä½¿ç”¨ï¼‰
                - åŒå­—æ¯å›½å®¶/åœ°åŒºä»£ç ï¼ŒæŒ‡å®šä½¿ç”¨å“ªä¸ªå›½å®¶çš„èŠ‚å‡æ—¥
                - è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸² "" å¯å¿½ç•¥èŠ‚å‡æ—¥
                - ç¤ºä¾‹: "US"ï¼ˆç¾å›½ï¼‰, "CN"ï¼ˆä¸­å›½ï¼‰, "JP"ï¼ˆæ—¥æœ¬ï¼‰
            feature_store_lookups: ç‰¹å¾å­˜å‚¨æŸ¥æ‰¾é…ç½®ï¼Œé»˜è®¤ Noneï¼ˆä»…æ—¶åºé¢„æµ‹ä½¿ç”¨ï¼‰
                - æ ¼å¼: [{"table_name": str, "lookup_key": str/list, "timestamp_lookup_key": str}]
                - ç”¨äºä»ç‰¹å¾å­˜å‚¨ä¸­æŸ¥æ‰¾åå˜é‡æ•°æ®
            prediction_result_storage: é¢„æµ‹ç»“æœå­˜å‚¨è·¯å¾„ï¼Œé»˜è®¤ Noneï¼ˆä»…æ—¶åºé¢„æµ‹ä½¿ç”¨ï¼‰
                - DLC ä¸¤æ®µå¼è·¯å¾„ï¼Œå¦‚ "/DataLake/data/"
                - å¦‚æœæä¾›ï¼Œè®­ç»ƒå®Œæˆåä¼šè‡ªåŠ¨æ‰§è¡Œé¢„æµ‹å¹¶ä¿å­˜åˆ° DLC è¡¨
            storage_data_source_id: å­˜å‚¨æ•°æ®æº IDï¼Œé»˜è®¤ None
            storage_data_source_name: å­˜å‚¨æ•°æ®æºåç§°ï¼Œé»˜è®¤ None
            register_to_catalog: æ˜¯å¦å°†æœ€ä½³æ¨¡å‹æ³¨å†Œåˆ° TencentCloud Catalogï¼Œé»˜è®¤ False
                - True: è®­ç»ƒå®Œæˆåè‡ªåŠ¨å°†æœ€ä½³æ¨¡å‹æ³¨å†Œåˆ° Catalog
                - éœ€è¦è®¾ç½®ç›¸å…³ç¯å¢ƒå˜é‡ï¼ˆKERNEL_WEDATA_CLOUD_SDK_SECRET_ID/KEY, TENCENTCLOUD_ENDPOINTï¼‰
            catalog_model_name: Catalog æ¨¡å‹åç§°ï¼Œæ ¼å¼ä¸º "catalog.schema.model_name"
                - å¦‚æœæœªè®¾ç½®ï¼Œå°†è‡ªåŠ¨ç”Ÿæˆ
            catalog_region: Catalog åœ°åŸŸï¼Œé»˜è®¤ "ap-beijing"
            **kwargs: å…¶ä»–å‚æ•°

        Raises:
            ValueError: å¦‚æœ workspace_id æœªé…ç½®ï¼ˆæ—¢æœªä¼ å…¥å‚æ•°ï¼Œä¹Ÿæœªè®¾ç½®ç¯å¢ƒå˜é‡ï¼‰
        """
        self.task = task
        self.target_col = target_col
        self.timeout_minutes = timeout_minutes
        self.max_trials = max_trials
        self.metric = metric if metric != "auto" else self._get_default_metric(task)
        self.exclude_cols = exclude_cols or []
        self.exclude_frameworks = exclude_frameworks or []
        self.estimator_list = estimator_list
        self.sample_weight_col = sample_weight_col
        self.pos_label = pos_label
        self.data_split_col = data_split_col
        self.experiment_name = experiment_name or "wedata_automl"
        self.experiment_id = experiment_id
        self.run_name = run_name or f"flaml_automl_{task}"
        self.register_model = register_model
        self.model_name = model_name
        self.max_concurrent_trials = max_concurrent_trials
        self.use_spark = use_spark
        self.custom_hp = custom_hp
        self.imputers = imputers
        self.country_code = country_code
        self.feature_store_lookups = feature_store_lookups or []

        # é¢„æµ‹ç»“æœå­˜å‚¨å‚æ•°ï¼ˆä»…æ—¶åºé¢„æµ‹ä½¿ç”¨ï¼‰
        self.prediction_result_storage = kwargs.pop("prediction_result_storage", None)
        self.storage_data_source_id = kwargs.pop("storage_data_source_id", None)
        self.storage_data_source_name = kwargs.pop("storage_data_source_name", None)

        # Catalog æ³¨å†Œå‚æ•°
        self.register_to_catalog = register_to_catalog
        self.catalog_model_name = catalog_model_name
        self.catalog_region = catalog_region or os.getenv("QCLOUD_REGION")

        # Log æ–‡ä»¶ç®¡ç†é…ç½®
        self.log_file_dir = log_file_dir
        self.auto_cleanup_logs = auto_cleanup_logs
        self.log_max_age_hours = log_max_age_hours
        self.log_max_files = log_max_files

        # å¤„ç† workspace_idï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·ä¼ å…¥çš„å€¼ï¼Œå¦åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        self.workspace_id = workspace_id or os.environ.get("WEDATA_WORKSPACE_ID")

        # éªŒè¯ workspace_id æ˜¯å¦å­˜åœ¨
        if not self.workspace_id:
            raise ValueError(
                "âŒ æœªé…ç½® Project IDï¼\n"
                "è¯·é€šè¿‡ä»¥ä¸‹ä»»ä¸€æ–¹å¼é…ç½® Project IDï¼š\n"
                "1. ä¼ é€’ workspace_id å‚æ•°ï¼šclassify(..., workspace_id='your_project_id')\n"
                "2. è®¾ç½®ç¯å¢ƒå˜é‡ï¼šexport WEDATA_WORKSPACE_ID='your_project_id'\n"
                "\n"
                "Project ID ç”¨äºå¤šç§Ÿæˆ·éš”ç¦»ï¼Œç¡®ä¿å®éªŒå¯ä»¥é€šè¿‡åç«¯ API æ­£ç¡®æŸ¥è¯¢ã€‚"
            )

        self.kwargs = kwargs

        # å†…éƒ¨çŠ¶æ€
        self.automl = None
        self.pipeline = None
        self.features = None
        self.preprocessor = None
        self.data_source_table = None  # è®°å½•æ•°æ®æºè¡¨åï¼ˆå¦‚æœç”¨æˆ·ä¼ å…¥è¡¨åï¼‰
    
    # æ”¯æŒçš„æŒ‡æ ‡é…ç½®
    SUPPORTED_METRICS = {
        "forecast": {
            "default": "smape",
            "supported": ["smape", "mse", "rmse", "mae", "mdape"]
        },
        "regression": {
            "default": "deviance",
            "supported": ["deviance", "rmse", "mae", "r2", "mse"]
        },
        "classification": {
            "default": "log_loss",
            "supported": ["f1", "log_loss", "precision", "accuracy", "roc_auc", "rmse", "mae"]
        }
    }

    # æ”¯æŒçš„ä¼°è®¡å™¨é…ç½®
    # sklearn æ˜ å°„ä¸º FLAML çš„å…·ä½“ä¼°è®¡å™¨: rf (éšæœºæ£®æ—), extra_tree, lrl1 (L1æ­£åˆ™åŒ–é€»è¾‘å›å½’)
    SUPPORTED_ESTIMATORS = {
        "forecast": {
            # é»˜è®¤ä½¿ç”¨ç»Ÿè®¡æ¨¡å‹ + æ ‘æ¨¡å‹
            "default": ["prophet", "arima", "sarimax"],
            # FLAML ts_forecast æ”¯æŒçš„æ‰€æœ‰ä¼°è®¡å™¨
            "supported": [
                # ç»Ÿè®¡æ¨¡å‹
                "prophet",       # Facebook Prophet
                "arima",         # ARIMA
                "sarimax",       # SARIMAX (å¸¦å­£èŠ‚æ€§çš„ ARIMA)
                "holt-winters",  # Holt-Winters ä¸‰æ¬¡æŒ‡æ•°å¹³æ»‘
                # æ ‘æ¨¡å‹
                "lgbm",          # LightGBM
                "xgboost",       # XGBoost
                "xgb_limitdepth",# XGBoost (é™åˆ¶æ·±åº¦)
                "rf",            # éšæœºæ£®æ—
                "extra_tree",    # ExtraTrees
                "histgb",        # HistGradientBoosting
            ],
        },
        "regression": {
            "default": ["lgbm", "xgboost", "rf", "extra_tree"],
            "supported": ["lgbm", "xgboost", "rf", "extra_tree"],
            # sklearn æ˜ å°„: rf, extra_tree
            # lightgbm æ˜ å°„: lgbm
            # xgboost æ˜ å°„: xgboost
        },
        "classification": {
            "default": ["lgbm", "xgboost", "rf", "extra_tree", "lrl1"],
            "supported": ["lgbm", "xgboost", "rf", "extra_tree", "lrl1"],
            # sklearn æ˜ å°„: rf, extra_tree, lrl1
            # lightgbm æ˜ å°„: lgbm
            # xgboost æ˜ å°„: xgboost
        }
    }

    def _get_default_metric(self, task: str) -> str:
        """è·å–é»˜è®¤æŒ‡æ ‡"""
        if task in self.SUPPORTED_METRICS:
            return self.SUPPORTED_METRICS[task]["default"]
        return "accuracy"

    def _validate_metric(self, task: str, metric: str) -> str:
        """éªŒè¯æŒ‡æ ‡æ˜¯å¦æ”¯æŒ"""
        if task not in self.SUPPORTED_METRICS:
            return metric

        supported = self.SUPPORTED_METRICS[task]["supported"]
        if metric.lower() not in [m.lower() for m in supported]:
            safe_print(f"âš ï¸  Metric '{metric}' is not in supported list for {task}: {supported}")
            safe_print(f"   Using default metric: {self.SUPPORTED_METRICS[task]['default']}")
            return self.SUPPORTED_METRICS[task]["default"]
        return metric.lower()

    def _get_estimator_list(self) -> List[str]:
        """è·å–ä¼°è®¡å™¨åˆ—è¡¨"""
        # ç”¨æˆ·å¯èƒ½ä½¿ç”¨çš„åˆ«åæ˜ å°„åˆ° FLAML ä¼°è®¡å™¨åç§°
        estimator_alias_map = {
            "sklearn": ["rf", "extra_tree", "lrl1"],  # sklearn çš„æ¨¡å‹æ˜ å°„
            "lightgbm": ["lgbm"],
            "xgboost": ["xgboost"],
            "deep-ar": [],  # æš‚ä¸æ”¯æŒ
            "deepar": [],   # æš‚ä¸æ”¯æŒ
        }

        # å¦‚æœç”¨æˆ·æŒ‡å®šäº† estimator_listï¼Œè¿›è¡Œå¤„ç†
        if self.estimator_list:
            expanded_estimators = []
            for est in self.estimator_list:
                est_lower = est.lower()
                if est_lower in estimator_alias_map:
                    expanded_estimators.extend(estimator_alias_map[est_lower])
                    if not estimator_alias_map[est_lower]:
                        safe_print(f"âš ï¸  Estimator '{est}' is not currently supported, skipping")
                else:
                    expanded_estimators.append(est)

            # å¯¹äº forecast ä»»åŠ¡ï¼Œè¿‡æ»¤æ‰ä¸æ”¯æŒçš„ä¼°è®¡å™¨
            if self.task == "forecast":
                supported = self.SUPPORTED_ESTIMATORS["forecast"]["supported"]
                filtered = [e for e in expanded_estimators if e in supported]
                if len(filtered) < len(expanded_estimators):
                    unsupported = [e for e in expanded_estimators if e not in supported]
                    safe_print(f"âš ï¸  Filtered out unsupported forecast estimators: {unsupported}")
                    safe_print(f"   Supported: {supported}")
                return filtered if filtered else self.SUPPORTED_ESTIMATORS["forecast"]["default"]
            return expanded_estimators if expanded_estimators else self.SUPPORTED_ESTIMATORS.get(
                self.task, {"default": ["lgbm", "xgboost"]}
            )["default"]

        # å¦åˆ™ä½¿ç”¨é»˜è®¤åˆ—è¡¨ï¼ˆæ’é™¤ exclude_frameworksï¼‰
        if self.task in self.SUPPORTED_ESTIMATORS:
            all_estimators = self.SUPPORTED_ESTIMATORS[self.task]["default"].copy()
        else:
            all_estimators = ["lgbm", "xgboost", "rf", "extra_tree"]

        # æ’é™¤æŒ‡å®šçš„æ¡†æ¶ï¼ˆå‘åå…¼å®¹ï¼‰
        estimators = [e for e in all_estimators if e not in self.exclude_frameworks]
        return estimators

    def _evaluate_model(
        self,
        X_train: pd.DataFrame,
        y_train: np.ndarray,
        X_val: pd.DataFrame,
        y_val: np.ndarray,
        X_test: pd.DataFrame,
        y_test: np.ndarray
    ) -> Dict[str, float]:
        """
        è¯„ä¼°æ¨¡å‹

        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        metrics = {}

        if self.task == "classification":
            from sklearn.metrics import (
                accuracy_score, f1_score, precision_score, recall_score,
                log_loss as sklearn_log_loss, roc_auc_score
            )

            for name, X, y_true in [
                ("train", X_train, y_train),
                ("val", X_val, y_val),
                ("test", X_test, y_test),
            ]:
                pred = self.pipeline.predict(X)
                # åŸºç¡€æŒ‡æ ‡ï¼ˆä¸éœ€è¦æ¦‚ç‡é¢„æµ‹ï¼‰
                acc = float(accuracy_score(y_true, pred))
                f1 = float(f1_score(y_true, pred, average='weighted', zero_division=0))
                precision = float(precision_score(y_true, pred, average='weighted', zero_division=0))
                recall = float(recall_score(y_true, pred, average='weighted', zero_division=0))

                metrics[f"{name}_accuracy"] = acc
                metrics[f"{name}_f1"] = f1
                metrics[f"{name}_precision"] = precision
                metrics[f"{name}_recall"] = recall

                mlflow.log_metric(f"{name}_accuracy", acc)
                mlflow.log_metric(f"{name}_f1", f1)
                mlflow.log_metric(f"{name}_precision", precision)
                mlflow.log_metric(f"{name}_recall", recall)

                # æ¦‚ç‡ç›¸å…³æŒ‡æ ‡ï¼ˆéœ€è¦ predict_probaï¼‰
                logloss = None
                roc_auc = None
                try:
                    pred_proba = self.pipeline.predict_proba(X)

                    # log_loss
                    logloss = float(sklearn_log_loss(y_true, pred_proba))
                    metrics[f"{name}_log_loss"] = logloss
                    mlflow.log_metric(f"{name}_log_loss", logloss)

                    # roc_aucï¼ˆæ ¹æ®ç±»åˆ«æ•°é‡é€‰æ‹©ä¸åŒç­–ç•¥ï¼‰
                    n_classes = len(np.unique(y_true))
                    if n_classes == 2:
                        # äºŒåˆ†ç±»ï¼šä½¿ç”¨æ­£ç±»æ¦‚ç‡
                        roc_auc = float(roc_auc_score(y_true, pred_proba[:, 1]))
                    else:
                        # å¤šåˆ†ç±»ï¼šä½¿ç”¨ ovr (one-vs-rest) ç­–ç•¥
                        roc_auc = float(roc_auc_score(y_true, pred_proba, multi_class='ovr', average='weighted'))
                    metrics[f"{name}_roc_auc"] = roc_auc
                    mlflow.log_metric(f"{name}_roc_auc", roc_auc)

                except Exception as e:
                    # æŸäº›æ¨¡å‹å¯èƒ½ä¸æ”¯æŒ predict_probaï¼Œæˆ–è€…ç±»åˆ«æ•°æ®ä¸æ»¡è¶³ roc_auc è¦æ±‚
                    logger.debug(f"Failed to compute probability-based metrics for {name}: {e}")

                # æ‰“å°æŒ‡æ ‡æ‘˜è¦
                metric_parts = [f"Accuracy: {acc:.4f}", f"F1: {f1:.4f}"]
                if logloss is not None:
                    metric_parts.append(f"LogLoss: {logloss:.4f}")
                if roc_auc is not None:
                    metric_parts.append(f"ROC-AUC: {roc_auc:.4f}")
                safe_print(f"{name.capitalize():5s} Set - " + " | ".join(metric_parts))

        elif self.task == "regression":
            from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

            for name, X, y_true in [
                ("train", X_train, y_train),
                ("val", X_val, y_val),
                ("test", X_test, y_test),
            ]:
                pred = self.pipeline.predict(X)

                r2 = float(r2_score(y_true, pred))
                mse = float(mean_squared_error(y_true, pred))
                mae = float(mean_absolute_error(y_true, pred))
                rmse = float(np.sqrt(mse))

                # Deviance (Gaussian deviance = sum of squared errors)
                # å¯¹äºé«˜æ–¯åˆ†å¸ƒï¼Œdeviance = 2 * n * MSEï¼Œä½†é€šå¸¸ç›´æ¥ä½¿ç”¨æ€»å¹³æ–¹è¯¯å·®
                n_samples = len(y_true)
                deviance = float(np.sum((y_true - pred) ** 2))

                metrics[f"{name}_r2"] = r2
                metrics[f"{name}_mse"] = mse
                metrics[f"{name}_mae"] = mae
                metrics[f"{name}_rmse"] = rmse
                metrics[f"{name}_deviance"] = deviance

                mlflow.log_metric(f"{name}_r2", r2)
                mlflow.log_metric(f"{name}_mse", mse)
                mlflow.log_metric(f"{name}_mae", mae)
                mlflow.log_metric(f"{name}_rmse", rmse)
                mlflow.log_metric(f"{name}_deviance", deviance)

                safe_print(f"{name.capitalize():5s} Set - RÂ²: {r2:.4f} | RMSE: {rmse:.4f} | MAE: {mae:.4f} | Deviance: {deviance:.4f}")

        return metrics
    
    def _prepare_data(
        self,
        pdf: pd.DataFrame
    ) -> tuple:
        """
        å‡†å¤‡æ•°æ®

        Returns:
            (X_train, y_train, X_val, y_val, X_test, y_test, sample_weight_train)
        """
        # ç¡®å®šç‰¹å¾åˆ—
        disable_cols = set(self.exclude_cols) | {self.target_col}
        if self.sample_weight_col:
            disable_cols.add(self.sample_weight_col)
        if self.data_split_col:
            disable_cols.add(self.data_split_col)

        self.features = [c for c in pdf.columns if c not in disable_cols]

        safe_print(f"Target column: '{self.target_col}'")
        safe_print(f"Feature columns: {len(self.features)} columns")
        if len(self.features) <= 20:
            safe_print(f"  Features: {', '.join(self.features)}")
        else:
            safe_print(f"  First 10 features: {', '.join(self.features[:10])}")
            safe_print(f"  ... and {len(self.features) - 10} more")

        # æ•°æ®åˆ’åˆ†
        safe_print("", show_timestamp=False, show_level=False)
        if self.data_split_col and self.data_split_col in pdf.columns:
            # ä½¿ç”¨ç”¨æˆ·æä¾›çš„åˆ’åˆ†åˆ—
            pdf["_automl_split_col"] = pdf[self.data_split_col]
            safe_print(f"âœ… Using user-provided split column: '{self.data_split_col}'")
        else:
            # è‡ªåŠ¨åˆ’åˆ†
            safe_print(f"Auto-generating train/val/test split (60%/20%/20%)")
            if self.task == "classification":
                safe_print(f"  Using stratified split for classification")
            split_col, sample_weights = compute_split_and_weights(
                y=pdf[self.target_col].values,
                task=self.task,
                train_ratio=0.6,
                val_ratio=0.2,
                test_ratio=0.2,
                stratify=True if self.task == "classification" else False,
                random_state=42,
            )
            pdf["_automl_split_col"] = split_col.values
            pdf["_automl_sample_weight"] = sample_weights.values
            safe_print("âœ… Split generated successfully")

        # åˆ†å‰²æ•°æ®
        train_df = pdf[pdf["_automl_split_col"] == 0]
        val_df = pdf[pdf["_automl_split_col"] == 1]
        test_df = pdf[pdf["_automl_split_col"] == 2]

        X_train = train_df[self.features]
        y_train = train_df[self.target_col].values

        X_val = val_df[self.features]
        y_val = val_df[self.target_col].values

        X_test = test_df[self.features]
        y_test = test_df[self.target_col].values

        # è·å–æ ·æœ¬æƒé‡
        sample_weight_train = None
        if self.sample_weight_col and self.sample_weight_col in train_df.columns:
            # ä½¿ç”¨ç”¨æˆ·æä¾›çš„æ ·æœ¬æƒé‡åˆ—
            sample_weight_train = train_df[self.sample_weight_col].values
            safe_print(f"âœ… Using user-provided sample weights from column: '{self.sample_weight_col}'")
        elif "_automl_sample_weight" in train_df.columns:
            # ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„æ ·æœ¬æƒé‡ï¼ˆç”¨äºç±»åˆ«ä¸å¹³è¡¡ï¼‰
            sample_weight_train = train_df["_automl_sample_weight"].values

        safe_print("", show_timestamp=False, show_level=False)
        safe_print(f"Data split summary:")
        safe_print(f"  Train: {len(train_df):,} samples ({len(train_df)/len(pdf)*100:.1f}%)")
        safe_print(f"  Val:   {len(val_df):,} samples ({len(val_df)/len(pdf)*100:.1f}%)")
        safe_print(f"  Test:  {len(test_df):,} samples ({len(test_df)/len(pdf)*100:.1f}%)")
        safe_print(f"  Total: {len(pdf):,} samples")

        # æ˜¾ç¤ºç›®æ ‡å˜é‡åˆ†å¸ƒï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰
        if self.task == "classification":
            safe_print("", show_timestamp=False, show_level=False)
            safe_print(f"Target distribution in training set:")
            train_dist = pd.Series(y_train).value_counts().sort_index()
            for label, count in train_dist.items():
                safe_print(f"  Class {label}: {count:,} samples ({count/len(y_train)*100:.1f}%)")

        return X_train, y_train, X_val, y_val, X_test, y_test, sample_weight_train

    def _apply_feature_store_lookups(
        self,
        pdf: pd.DataFrame,
        spark=None
    ) -> pd.DataFrame:
        """
        ä½¿ç”¨ wedata-feature-engineering çš„ FeatureStoreClient ä»ç‰¹å¾å­˜å‚¨ä¸­æŸ¥æ‰¾ç‰¹å¾å¹¶åˆå¹¶åˆ°æ•°æ®é›†

        Args:
            pdf: åŸå§‹æ•°æ®é›†
            spark: Spark session

        Returns:
            åˆå¹¶ç‰¹å¾åçš„æ•°æ®é›†

        Note:
            feature_store_lookups æ ¼å¼:
            [
                {
                    "table_name": "feature_store.sales_features",
                    "lookup_key": ["store_id", "product_id"],  # æˆ–å•ä¸ªå­—ç¬¦ä¸²
                    "feature_names": ["feature1", "feature2"],  # å¯é€‰ï¼ŒæŒ‡å®šè¦æŸ¥æ‰¾çš„ç‰¹å¾
                    "timestamp_lookup_key": "date"  # å¯é€‰ï¼Œç”¨äºæ—¶åºç‰¹å¾è¡¨
                }
            ]
        """
        # åˆå§‹åŒ–ç‰¹å¾å­˜å‚¨ç›¸å…³çš„å®ä¾‹å˜é‡
        self._fs_client = None
        self._feature_lookups = None
        self._training_set = None

        if not self.feature_store_lookups:
            return pdf

        if spark is None:
            safe_print("âš ï¸  Spark session not available, skipping feature store lookups")
            return pdf

        try:
            # ä½¿ç”¨ wedata-feature-engineering çš„ FeatureStoreClient
            from wedata.feature_store.client import FeatureStoreClient
            from wedata.feature_store.entities.feature_lookup import FeatureLookup

            self._fs_client = FeatureStoreClient(spark=spark)

            # æ„å»º FeatureLookup åˆ—è¡¨
            self._feature_lookups = []
            for lookup in self.feature_store_lookups:
                table_name = lookup.get("table_name")
                lookup_key = lookup.get("lookup_key")
                feature_names = lookup.get("feature_names")  # å¯é€‰
                timestamp_lookup_key = lookup.get("timestamp_lookup_key")

                if not table_name or not lookup_key:
                    safe_print(f"âš ï¸  Skipping invalid feature store lookup: {lookup}")
                    continue

                safe_print(f"Looking up features from: {table_name}")
                safe_print(f"  Lookup key: {lookup_key}")
                if feature_names:
                    safe_print(f"  Feature names: {feature_names}")
                if timestamp_lookup_key:
                    safe_print(f"  Timestamp key: {timestamp_lookup_key}")

                # åˆ›å»º FeatureLookup å¯¹è±¡
                fl = FeatureLookup(
                    table_name=table_name,
                    lookup_key=lookup_key,
                    feature_names=feature_names,
                    timestamp_lookup_key=timestamp_lookup_key
                )
                self._feature_lookups.append(fl)

            if not self._feature_lookups:
                safe_print("âš ï¸  No valid feature lookups configured")
                return pdf

            # å°† pandas DataFrame è½¬æ¢ä¸º Spark DataFrame
            spark_df = spark.createDataFrame(pdf)
            original_cols = set(pdf.columns)

            # ä½¿ç”¨ FeatureStoreClient åˆ›å»º training set
            # ä¿å­˜ training_set ä¾›åç»­æ¨¡å‹æ³¨å†Œä½¿ç”¨
            self._training_set = self._fs_client.create_training_set(
                df=spark_df,
                feature_lookups=self._feature_lookups,
                label=self.target_col,  # æŒ‡å®šæ ‡ç­¾åˆ—ï¼Œç”¨äºåç»­ log_model
                exclude_columns=[]
            )

            # åŠ è½½åˆå¹¶åçš„æ•°æ®å¹¶è½¬æ¢å› pandas
            augmented_df = self._training_set.load_df()
            pdf = augmented_df.toPandas()

            new_cols = set(pdf.columns) - original_cols
            safe_print(f"âœ… Feature store lookup completed")
            safe_print(f"   Added {len(new_cols)} new columns")
            if new_cols:
                safe_print(f"   New columns: {', '.join(sorted(new_cols)[:5])}" +
                          (f"... (+{len(new_cols) - 5} more)" if len(new_cols) > 5 else ""))

        except ImportError as e:
            safe_print(f"âš ï¸  wedata-feature-engineering not available: {e}")
            safe_print("   Falling back to manual feature lookup...")
            # å›é€€åˆ°æ‰‹åŠ¨æŸ¥æ‰¾
            pdf = self._apply_feature_store_lookups_fallback(pdf, spark)
        except Exception as e:
            safe_print(f"âš ï¸  Feature store lookup failed: {e}")
            logger.warning(f"Feature store lookup failed: {e}")

        safe_print(f"Dataset shape after feature lookups: {pdf.shape}")
        return pdf

    def _apply_feature_store_lookups_fallback(
        self,
        pdf: pd.DataFrame,
        spark
    ) -> pd.DataFrame:
        """
        æ‰‹åŠ¨ç‰¹å¾æŸ¥æ‰¾çš„å›é€€æ–¹æ³•ï¼ˆå½“ wedata-feature-engineering ä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
        """
        for lookup in self.feature_store_lookups:
            table_name = lookup.get("table_name")
            lookup_key = lookup.get("lookup_key")

            if not table_name or not lookup_key:
                continue

            try:
                feature_df = spark.read.table(table_name).toPandas()

                if isinstance(lookup_key, str):
                    lookup_key = [lookup_key]

                missing_in_pdf = [k for k in lookup_key if k not in pdf.columns]
                missing_in_feature = [k for k in lookup_key if k not in feature_df.columns]

                if missing_in_pdf or missing_in_feature:
                    continue

                original_cols = set(pdf.columns)
                pdf = pdf.merge(feature_df, on=lookup_key, how="left")
                new_cols = set(pdf.columns) - original_cols

                safe_print(f"âœ… Added {len(new_cols)} features from {table_name} (fallback)")

            except Exception as e:
                safe_print(f"âš ï¸  Failed to lookup features from {table_name}: {e}")

        return pdf

    def _log_model_with_mlflow(
        self,
        parent_run_id: str,
        registered_model_name: Optional[str] = None,
        X_sample: Optional[pd.DataFrame] = None,
        y_sample: Optional[np.ndarray] = None
    ) -> tuple:
        """
        ä½¿ç”¨æ ‡å‡† MLflow æ–¹å¼è®°å½•å’Œæ³¨å†Œæ¨¡å‹

        Args:
            parent_run_id: çˆ¶ run çš„ ID
            registered_model_name: æ³¨å†Œæ¨¡å‹çš„åç§°ï¼ˆå¯é€‰ï¼‰
            X_sample: ç”¨äºæ¨æ–­ç­¾åçš„è¾“å…¥æ ·æœ¬ï¼ˆå¯é€‰ï¼‰
            y_sample: ç”¨äºæ¨æ–­ç­¾åçš„è¾“å‡ºæ ·æœ¬ï¼ˆå¯é€‰ï¼‰

        Returns:
            (model_uri, model_version) å…ƒç»„
        """
        from mlflow.models import infer_signature

        # æ—¶åºé¢„æµ‹ä»»åŠ¡ä½¿ç”¨ä¸åŒçš„æ—¥å¿—æ–¹å¼
        if self.task == "forecast":
            return self._log_forecast_model(parent_run_id, registered_model_name)

        # æ¨æ–­æ¨¡å‹ç­¾åï¼ˆåˆ†ç±»/å›å½’ä»»åŠ¡ï¼‰
        signature = None
        input_example = None
        if X_sample is not None:
            try:
                # ä½¿ç”¨æ ·æœ¬æ•°æ®æ¨æ–­ç­¾å
                y_pred = self.pipeline.predict(X_sample)
                signature = infer_signature(X_sample, y_pred)
                # å‡†å¤‡ input_exampleï¼ˆå–å‰å‡ è¡Œä½œä¸ºç¤ºä¾‹ï¼‰
                input_example = X_sample.head(5) if len(X_sample) > 5 else X_sample
                safe_print(f"âœ… Model signature inferred successfully")
            except Exception as e:
                safe_print(f"âš ï¸  Failed to infer model signature: {e}")
                signature = None

        # è®°å½•æ¨¡å‹åˆ° MLflow
        # æ³¨æ„ï¼šè¿™é‡Œè®°å½•çš„æ˜¯å®Œæ•´çš„ Pipelineï¼ˆé¢„å¤„ç†å™¨ + æ¨¡å‹ï¼‰ï¼Œè€Œä¸æ˜¯å•ç‹¬çš„æ¨¡å‹
        # è¿™æ ·åœ¨æ¨ç†æ—¶å¯ä»¥ç›´æ¥å¤„ç†åŸå§‹æ•°æ®ï¼Œæ— éœ€é¢å¤–çš„é¢„å¤„ç†æ­¥éª¤
        mlflow.sklearn.log_model(
            sk_model=self.pipeline,
            artifact_path="model",
            signature=signature,
            input_example=input_example,
        )
        model_uri = f"runs:/{parent_run_id}/model"
        safe_print(f"âœ… Model logged to MLflow: {model_uri}")

        # ğŸ†• ä¸å†åœ¨çˆ¶ run ä¸­æ³¨å†Œæ¨¡å‹ï¼Œåªè®°å½•æ¨¡å‹ artifact
        # æ¨¡å‹æ³¨å†Œç”±ç”¨æˆ·åœ¨è®­ç»ƒå®Œæˆåæ‰‹åŠ¨è¿›è¡Œï¼Œæˆ–é€šè¿‡ Catalog æ³¨å†Œ
        model_version = None
        safe_print(f"â„¹ï¸  Model not registered in parent run (artifact only)")
        mlflow.set_tag("wedata.has_registered_model", "false")

        return model_uri, model_version

    def _log_forecast_model(
        self,
        parent_run_id: str,
        registered_model_name: Optional[str] = None,
    ) -> tuple:
        """
        ä½¿ç”¨ mlflow.pyfunc.log_model æ–¹å¼è®°å½•æ—¶åºé¢„æµ‹æ¨¡å‹

        æ—¶åºé¢„æµ‹æ¨¡å‹ï¼ˆå¦‚ ARIMA, Prophetï¼‰ä¸å…¼å®¹ sklearnï¼Œéœ€è¦ä½¿ç”¨ pyfunc æ–¹å¼è®°å½•
        ä½¿ç”¨æ ‡å‡† MLflow pyfunc æ ¼å¼ï¼Œç”Ÿæˆå®Œæ•´çš„ MLmodel ç»“æ„

        Args:
            parent_run_id: çˆ¶ run çš„ ID
            registered_model_name: æ³¨å†Œæ¨¡å‹çš„åç§°ï¼ˆå¯é€‰ï¼‰

        Returns:
            (model_uri, model_version) å…ƒç»„
        """
        from mlflow.models import infer_signature

        # è·å–æ¨¡å‹å…ƒæ•°æ®
        best_estimator = self.automl.best_estimator if hasattr(self.automl, 'best_estimator') else "unknown"
        horizon = self.kwargs.get("horizon", 1)
        frequency = self.kwargs.get("frequency", "D")
        time_col = self.kwargs.get("time_col")
        target_col = self.kwargs.get("target_col") or self.target_col

        # åˆ›å»º ForecastModelWrapper å®ä¾‹
        forecast_wrapper = ForecastModelWrapper(
            model=self.pipeline,
            horizon=horizon,
            frequency=frequency,
            time_col=time_col,
            target_col=target_col,
            estimator=best_estimator,
        )

        # åˆ›å»ºè¾“å…¥ç¤ºä¾‹å’Œç­¾å
        # è¾“å…¥ï¼šåŒ…å«æ—¶é—´åˆ—çš„ DataFrame
        # è¾“å‡ºï¼šé¢„æµ‹å€¼æ•°ç»„
        input_example = pd.DataFrame({
            time_col: pd.date_range(start="2024-01-01", periods=3, freq=frequency)
        })

        # æ¨æ–­ç­¾å
        signature = None
        try:
            # ä½¿ç”¨ç®€å•çš„è¾“å‡ºç¤ºä¾‹
            output_example = pd.DataFrame({
                f"predicted_{target_col}": [0.0] * horizon,
                f"{time_col}": pd.date_range(start="2024-01-01", periods=horizon, freq=frequency)
            })
            signature = infer_signature(input_example, output_example)
            safe_print(f"âœ… Forecast model signature inferred successfully")
        except Exception as e:
            safe_print(f"âš ï¸  Failed to infer forecast model signature: {e}")

        # è·å–é¢å¤–ä¾èµ–ï¼ˆMLflow æ— æ³•è‡ªåŠ¨æ¨æ–­çš„åŒ…ï¼‰
        extra_pip_requirements = self._get_forecast_extra_pip_requirements()

        # ä½¿ç”¨ mlflow.pyfunc.log_model è®°å½•æ¨¡å‹
        # è¿™ä¼šç”Ÿæˆæ ‡å‡†çš„ MLflow æ¨¡å‹ç»“æ„
        mlflow.pyfunc.log_model(
            artifact_path="model",
            python_model=forecast_wrapper,
            signature=signature,
            input_example=input_example,
            extra_pip_requirements=extra_pip_requirements,
            metadata={
                "task": self.task,
                "estimator": best_estimator,
                "horizon": horizon,
                "frequency": frequency,
                "time_col": time_col,
                "target_col": target_col,
            }
        )

        model_uri = f"runs:/{parent_run_id}/model"
        safe_print(f"âœ… Forecast model logged to MLflow (pyfunc): {model_uri}")

        # ğŸ†• ä¸å†åœ¨çˆ¶ run ä¸­æ³¨å†Œæ¨¡å‹ï¼Œåªè®°å½•æ¨¡å‹ artifact
        # æ¨¡å‹æ³¨å†Œç”±ç”¨æˆ·åœ¨è®­ç»ƒå®Œæˆåæ‰‹åŠ¨è¿›è¡Œï¼Œæˆ–é€šè¿‡ Catalog æ³¨å†Œ
        # æ³¨å†Œæ¨¡å‹ï¼ˆå¦‚æœæä¾›äº†æ¨¡å‹åç§°ï¼‰
        model_version = None
        if registered_model_name:
            try:
                # ä½¿ç”¨ mlflow.register_model æ³¨å†Œæ¨¡å‹
                result = mlflow.register_model(
                    model_uri=model_uri,
                    name=registered_model_name
                )
                model_version = result.version
                safe_print(f"âœ… Forecast model registered: '{registered_model_name}' version {model_version}")
                mlflow.set_tag("wedata.has_registered_model", "true")

                # è®¾ç½® WeData å¹³å° tags
                if model_version:
                    set_model_version_wedata_tags(
                        registered_model_name=registered_model_name,
                        model_version=model_version,
                        task=self.task
                    )
            except Exception as e:
                safe_print(f"âš ï¸  Failed to register forecast model: {e}")
                mlflow.set_tag("wedata.has_registered_model", "false")
        else:
            safe_print(f"â„¹ï¸  Model not registered (no model name provided)")
            mlflow.set_tag("wedata.has_registered_model", "false")

        return model_uri, model_version

    def _get_package_version(self, package_name: str) -> Optional[str]:
        """
        è·å–å·²å®‰è£…åŒ…çš„ç‰ˆæœ¬å·

        Args:
            package_name: åŒ…åï¼ˆå¦‚ pandas, numpy, scikit-learnï¼‰

        Returns:
            ç‰ˆæœ¬å·å­—ç¬¦ä¸²ï¼Œå¦‚æœåŒ…æœªå®‰è£…åˆ™è¿”å› None
        """
        try:
            from importlib.metadata import version
            return version(package_name)
        except Exception:
            return None

    def _get_forecast_pip_requirements(self) -> List[str]:
        """
        æ ¹æ®ä½¿ç”¨çš„ä¼°è®¡å™¨åŠ¨æ€ç”Ÿæˆ pip ä¾èµ–åˆ—è¡¨

        ä¸åŒçš„æ—¶åºé¢„æµ‹æ¨¡å‹éœ€è¦ä¸åŒçš„ä¾èµ–ï¼š
        - Prophet: prophet
        - ARIMA/SARIMAX: statsmodels
        - LightGBM: lightgbm
        - XGBoost: xgboost
        - CatBoost: catboost
        - RandomForest/ExtraTrees: scikit-learn

        Args:
            estimator: æœ€ä½³ä¼°è®¡å™¨åç§°

        Returns:
            pip ä¾èµ–åˆ—è¡¨
        """
        extra_requirements = []

        # æ·»åŠ æœ¬åŒ…ï¼ˆåŒ…å« ForecastModelWrapperï¼ŒåŠ è½½æ¨¡å‹æ—¶å¿…éœ€ï¼‰
        pkg_version = self._get_package_version("tencent-wedata3-auto-ml")
        if pkg_version:
            extra_requirements.append(f"tencent-wedata3-auto-ml=={pkg_version}")
        else:
            extra_requirements.append("tencent-wedata3-auto-ml")

        if extra_requirements:
            safe_print(f"ğŸ“¦ Extra pip requirements for forecast model:")
            for req in extra_requirements:
                safe_print(f"   - {req}")

        return extra_requirements

    def _save_forecast_predictions(
        self,
        parent_run_id: str,
        pdf: pd.DataFrame,
        spark=None
    ):
        """
        ä¿å­˜æ—¶åºé¢„æµ‹ç»“æœåˆ° DLC è¡¨

        æ”¯æŒé¢„æµ‹åŒºé—´ï¼ˆprediction intervalï¼‰ï¼š
        - Prophet: åŸç”Ÿæ”¯æŒ yhat_lower, yhat_upper
        - ARIMA/SARIMAX: é€šè¿‡ get_forecast æ”¯æŒç½®ä¿¡åŒºé—´
        - å…¶ä»–æ¨¡å‹: ä»…è¿”å›ç‚¹é¢„æµ‹

        Args:
            parent_run_id: çˆ¶ run ID
            pdf: åŸå§‹æ•°æ®
            spark: Spark session
        """
        safe_print("", show_timestamp=False, show_level=False)
        print_separator()
        safe_print(f"ğŸ“¤ Saving Forecast Predictions")
        print_separator()

        if spark is None:
            safe_print("âš ï¸  Spark session not available, skipping prediction save")
            return

        try:
            from datetime import datetime

            # è·å–æ—¶é—´åˆ—å’Œé¢„æµ‹å‚æ•°
            time_col = self.kwargs.get("time_col")
            target_col = self.kwargs.get("target_col") or self.target_col
            horizon = self.kwargs.get("horizon", 1)
            frequency = self.kwargs.get("frequency", "D")
            best_estimator = self.automl.best_estimator if hasattr(self.automl, 'best_estimator') else "unknown"

            safe_print(f"Best estimator: {best_estimator}")
            safe_print(f"Generating predictions for {horizon} periods...")

            # ç”Ÿæˆæœªæ¥æ—¶é—´åºåˆ—
            future_dates = pd.date_range(
                start=pdf[time_col].max() + pd.Timedelta(1, unit=frequency[0].lower()),
                periods=horizon,
                freq=frequency
            )

            # è·å–é¢„æµ‹å€¼å’Œé¢„æµ‹åŒºé—´
            predictions = None
            predictions_lower = None
            predictions_upper = None

            # Prophet åŸç”Ÿæ”¯æŒé¢„æµ‹åŒºé—´
            if best_estimator == "prophet" and hasattr(self.automl, 'model'):
                try:
                    model = self.automl.model
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ Prophet æ¨¡å‹
                    if hasattr(model, 'model') and hasattr(model.model, 'predict'):
                        prophet_model = model.model
                        # åˆ›å»º future dataframe
                        future_df = prophet_model.make_future_dataframe(periods=horizon, freq=frequency)
                        # è·å–å®Œæ•´é¢„æµ‹ï¼ˆåŒ…å«é¢„æµ‹åŒºé—´ï¼‰
                        forecast_df = prophet_model.predict(future_df)
                        # å–æœ€å horizon è¡Œ
                        forecast_tail = forecast_df.tail(horizon)
                        predictions = forecast_tail['yhat'].values
                        predictions_lower = forecast_tail['yhat_lower'].values
                        predictions_upper = forecast_tail['yhat_upper'].values
                        safe_print(f"âœ… Prophet prediction interval obtained (80% confidence)")
                except Exception as e:
                    safe_print(f"âš ï¸  Failed to get Prophet prediction interval: {e}")

            # ARIMA/SARIMAX æ”¯æŒé¢„æµ‹åŒºé—´
            elif best_estimator in ["arima", "sarimax"] and hasattr(self.automl, 'model'):
                try:
                    model = self.automl.model
                    if hasattr(model, 'model') and hasattr(model.model, 'get_forecast'):
                        arima_model = model.model
                        forecast_result = arima_model.get_forecast(steps=horizon)
                        predictions = forecast_result.predicted_mean.values
                        conf_int = forecast_result.conf_int(alpha=0.2)  # 80% confidence
                        predictions_lower = conf_int.iloc[:, 0].values
                        predictions_upper = conf_int.iloc[:, 1].values
                        safe_print(f"âœ… ARIMA/SARIMAX prediction interval obtained (80% confidence)")
                except Exception as e:
                    safe_print(f"âš ï¸  Failed to get ARIMA prediction interval: {e}")

            # å¦‚æœæ²¡æœ‰è·å–åˆ°é¢„æµ‹åŒºé—´ï¼Œä½¿ç”¨æ™®é€šé¢„æµ‹
            if predictions is None:
                try:
                    # å¯¹äºçº¯æ—¶åºæ¨¡å‹ï¼Œåªä¼ å…¥æœªæ¥æ—¶é—´ç‚¹
                    # FLAML çš„ predict æ–¹æ³•æœŸæœ› X_test ç¬¬ä¸€åˆ—æ˜¯æ—¶é—´åˆ—
                    future_X = pd.DataFrame({time_col: future_dates})
                    predictions = self.automl.predict(future_X)
                    safe_print(f"â„¹ï¸  Using point predictions (no prediction interval for {best_estimator})")
                except Exception as e:
                    # å¯¹äºä½¿ç”¨å¤–ç”Ÿå˜é‡çš„æ¨¡å‹ï¼Œå¯èƒ½ä¼šå¤±è´¥
                    # å› ä¸ºæˆ‘ä»¬æ²¡æœ‰æœªæ¥æ—¶é—´ç‚¹çš„å¤–ç”Ÿå˜é‡
                    safe_print(f"âš ï¸  Failed to predict with future time only: {e}")
                    safe_print(f"   This model may require exogenous features for prediction.")
                    safe_print(f"   Skipping prediction save for {best_estimator}.")
                    return

            # åˆ›å»ºé¢„æµ‹ç»“æœ DataFrame
            pred_df = pd.DataFrame({
                time_col: future_dates,
                f"predicted_{target_col}": predictions,
                "run_id": parent_run_id,
                "predicted_at": datetime.now()
            })

            # æ·»åŠ é¢„æµ‹åŒºé—´ï¼ˆå¦‚æœæœ‰ï¼‰
            if predictions_lower is not None and predictions_upper is not None:
                pred_df[f"predicted_{target_col}_lower"] = predictions_lower
                pred_df[f"predicted_{target_col}_upper"] = predictions_upper
                safe_print(f"âœ… Prediction interval columns added: predicted_{target_col}_lower, predicted_{target_col}_upper")

            # è§£æä¸‰æ®µå¼è¡¨è·¯å¾„: catalog.database.table_prefix -> catalog.database.table_name
            # ä¾‹å¦‚: DataLake.automl_test.sales_predictions -> DataLake.automl_test.sales_predictions_xxx
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            run_id_short = parent_run_id[:8]
            storage_path = self.prediction_result_storage.strip()

            # è§£æä¸‰æ®µå¼è·¯å¾„ (catalog.database.table)
            path_parts = storage_path.split(".")
            if len(path_parts) == 3:
                # catalog.database.table_prefix æ ¼å¼
                catalog, database, table_prefix = path_parts
                table_name = f"{catalog}.{database}.{table_prefix}_{run_id_short}_{timestamp}"
            elif len(path_parts) == 2:
                # database.table_prefix æ ¼å¼
                database, table_prefix = path_parts
                table_name = f"{database}.{table_prefix}_{run_id_short}_{timestamp}"
            else:
                # å•ä¸ªåç§°ï¼Œä½¿ç”¨ default æ•°æ®åº“
                table_name = f"default.{storage_path}_{run_id_short}_{timestamp}"

            safe_print(f"Saving to table: {table_name}")

            # è½¬æ¢ä¸º Spark DataFrame å¹¶ä¿å­˜
            spark_df = spark.createDataFrame(pred_df)
            spark_df.write.mode("overwrite").saveAsTable(table_name)

            # è®°å½•å­˜å‚¨ä½ç½®åˆ° MLflow
            mlflow.log_param("prediction_table", table_name)
            mlflow.set_tag("wedata.prediction_table", table_name)

            safe_print(f"âœ… Predictions saved to: {table_name}")
            safe_print(f"   Rows: {len(pred_df)}")

        except Exception as e:
            safe_print(f"âš ï¸  Failed to save predictions: {e}")
            import traceback
            safe_print(f"   {traceback.format_exc()}")

    # ========================================================================
    # ç§æœ‰æ–¹æ³•ï¼šå®‰å…¨çš„ toPandas è½¬æ¢ï¼ˆå¤„ç†æ—¶åŒºé—®é¢˜ï¼‰
    # ========================================================================
    def _safe_to_pandas(self, spark_df, spark=None) -> pd.DataFrame:
        """
        å®‰å…¨åœ°å°† Spark DataFrame è½¬æ¢ä¸º Pandas DataFrame

        å¤„ç†æ—¶åŒºæ ¼å¼ä¸å…¼å®¹é—®é¢˜ï¼ˆå¦‚ 'GMT+08:00' pytz ä¸è¯†åˆ«ï¼‰

        Args:
            spark_df: Spark DataFrame
            spark: SparkSessionï¼ˆå¯é€‰ï¼Œç”¨äºä¿®æ”¹æ—¶åŒºé…ç½®ï¼‰

        Returns:
            Pandas DataFrame
        """
        try:
            return spark_df.toPandas()
        except Exception as e:
            error_msg = str(e)
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ—¶åŒºæ ¼å¼é—®é¢˜
            if "UnknownTimeZoneError" in error_msg or "GMT" in error_msg:
                safe_print(f"âš ï¸  Timezone format issue detected, attempting fix...")

                # æ–¹æ¡ˆ 1: å°è¯•ä¿®æ”¹ Spark session æ—¶åŒºé…ç½®
                if spark is not None:
                    try:
                        # è·å–å½“å‰æ—¶åŒº
                        current_tz = spark.conf.get("spark.sql.session.timeZone", "UTC")
                        safe_print(f"   Current timezone: {current_tz}")

                        # å°† GMT+XX:XX æ ¼å¼è½¬æ¢ä¸ºæ ‡å‡†æ—¶åŒºå
                        new_tz = self._normalize_timezone(current_tz)
                        if new_tz != current_tz:
                            safe_print(f"   Converting timezone to: {new_tz}")
                            spark.conf.set("spark.sql.session.timeZone", new_tz)

                            try:
                                result = spark_df.toPandas()
                                # æ¢å¤åŸå§‹æ—¶åŒºè®¾ç½®
                                spark.conf.set("spark.sql.session.timeZone", current_tz)
                                safe_print(f"âœ… Successfully converted with timezone fix")
                                return result
                            except Exception:
                                # æ¢å¤åŸå§‹æ—¶åŒºè®¾ç½®
                                spark.conf.set("spark.sql.session.timeZone", current_tz)
                    except Exception as tz_error:
                        safe_print(f"   Timezone fix failed: {tz_error}")

                # æ–¹æ¡ˆ 2: å°† timestamp åˆ—è½¬æ¢ä¸º string å†è½¬æ¢
                safe_print("   Trying alternative: convert timestamps to strings first...")
                try:
                    from pyspark.sql.functions import col
                    from pyspark.sql.types import TimestampType, DateType

                    # æ‰¾å‡ºæ‰€æœ‰ timestamp ç±»å‹çš„åˆ—
                    ts_cols = [
                        field.name for field in spark_df.schema.fields
                        if isinstance(field.dataType, (TimestampType,))
                    ]

                    if ts_cols:
                        safe_print(f"   Timestamp columns found: {ts_cols}")
                        # å°† timestamp åˆ—è½¬æ¢ä¸º string
                        for ts_col in ts_cols:
                            spark_df = spark_df.withColumn(
                                ts_col,
                                col(ts_col).cast("string")
                            )

                        # è½¬æ¢ä¸º Pandas
                        pdf = spark_df.toPandas()

                        # å°† string è½¬å› datetime
                        for ts_col in ts_cols:
                            pdf[ts_col] = pd.to_datetime(pdf[ts_col])

                        safe_print(f"âœ… Successfully converted using string intermediary")
                        return pdf
                    else:
                        # æ²¡æœ‰ timestamp åˆ—ï¼Œç›´æ¥æŠ›å‡ºåŸå§‹é”™è¯¯
                        raise e
                except Exception as alt_error:
                    safe_print(f"   Alternative method failed: {alt_error}")
                    raise e
            else:
                # ä¸æ˜¯æ—¶åŒºé—®é¢˜ï¼Œç›´æ¥æŠ›å‡º
                raise e

    def _normalize_timezone(self, tz_str: str) -> str:
        """
        å°†éæ ‡å‡†æ—¶åŒºæ ¼å¼è½¬æ¢ä¸º pytz å…¼å®¹æ ¼å¼

        Args:
            tz_str: æ—¶åŒºå­—ç¬¦ä¸²ï¼Œå¦‚ 'GMT+08:00'

        Returns:
            æ ‡å‡†æ—¶åŒºåï¼Œå¦‚ 'Asia/Shanghai' æˆ– 'Etc/GMT-8'
        """
        import re

        # å®Œæ•´çš„ GMT åç§»åˆ°æ ‡å‡†æ—¶åŒºæ˜ å°„ï¼ˆä¼˜å…ˆä½¿ç”¨å¸¸ç”¨åŸå¸‚æ—¶åŒºï¼‰
        # æ ¼å¼: (sign, hours, minutes) -> timezone_name
        gmt_to_tz_mapping = {
            # UTC / GMT+0
            ('+', 0, 0): 'UTC',
            ('-', 0, 0): 'UTC',
            # GMT+1 ~ GMT+14
            ('+', 1, 0): 'Europe/Paris',
            ('+', 2, 0): 'Europe/Helsinki',
            ('+', 3, 0): 'Europe/Moscow',
            ('+', 3, 30): 'Asia/Tehran',
            ('+', 4, 0): 'Asia/Dubai',
            ('+', 4, 30): 'Asia/Kabul',
            ('+', 5, 0): 'Asia/Karachi',
            ('+', 5, 30): 'Asia/Kolkata',
            ('+', 5, 45): 'Asia/Kathmandu',
            ('+', 6, 0): 'Asia/Dhaka',
            ('+', 6, 30): 'Asia/Yangon',
            ('+', 7, 0): 'Asia/Bangkok',
            ('+', 8, 0): 'Asia/Shanghai',
            ('+', 8, 45): 'Australia/Eucla',
            ('+', 9, 0): 'Asia/Tokyo',
            ('+', 9, 30): 'Australia/Adelaide',
            ('+', 10, 0): 'Australia/Sydney',
            ('+', 10, 30): 'Australia/Lord_Howe',
            ('+', 11, 0): 'Pacific/Guadalcanal',
            ('+', 12, 0): 'Pacific/Auckland',
            ('+', 12, 45): 'Pacific/Chatham',
            ('+', 13, 0): 'Pacific/Tongatapu',
            ('+', 14, 0): 'Pacific/Kiritimati',
            # GMT-1 ~ GMT-12
            ('-', 1, 0): 'Atlantic/Azores',
            ('-', 2, 0): 'Atlantic/South_Georgia',
            ('-', 3, 0): 'America/Sao_Paulo',
            ('-', 3, 30): 'America/St_Johns',
            ('-', 4, 0): 'America/Halifax',
            ('-', 5, 0): 'America/New_York',
            ('-', 6, 0): 'America/Chicago',
            ('-', 7, 0): 'America/Denver',
            ('-', 8, 0): 'America/Los_Angeles',
            ('-', 9, 0): 'America/Anchorage',
            ('-', 9, 30): 'Pacific/Marquesas',
            ('-', 10, 0): 'Pacific/Honolulu',
            ('-', 11, 0): 'Pacific/Midway',
            ('-', 12, 0): 'Etc/GMT+12',
        }

        # GMT+XX:XX æˆ– GMT-XX:XX æ ¼å¼
        match = re.match(r'GMT([+-])(\d{1,2}):?(\d{2})?', tz_str)
        if match:
            sign = match.group(1)
            hours = int(match.group(2))
            minutes = int(match.group(3)) if match.group(3) else 0

            # å°è¯•ä»æ˜ å°„è¡¨æŸ¥æ‰¾
            key = (sign, hours, minutes)
            if key in gmt_to_tz_mapping:
                return gmt_to_tz_mapping[key]

            # å¯¹äºæ•´å°æ—¶åç§»ï¼Œä½¿ç”¨ Etc/GMT æ ¼å¼
            # æ³¨æ„ï¼šEtc æ—¶åŒºçš„ç¬¦å·æ˜¯åçš„ï¼GMT+8 å¯¹åº” Etc/GMT-8
            if minutes == 0:
                etc_sign = '-' if sign == '+' else '+'
                return f"Etc/GMT{etc_sign}{hours}"

            # å¯¹äºéæ•´å°æ—¶ä¸”ä¸åœ¨æ˜ å°„è¡¨ä¸­çš„ï¼Œè¿”å› UTCï¼ˆé™çº§å¤„ç†ï¼‰
            safe_print(f"âš ï¸  Unknown timezone offset: {tz_str}, falling back to UTC")
            return 'UTC'

        # UTC / Z æ ¼å¼
        if tz_str.upper() in ('UTC', 'Z'):
            return 'UTC'

        # å·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼ˆå¦‚ Asia/Shanghaiï¼‰ï¼Œç›´æ¥è¿”å›
        return tz_str

    # ========================================================================
    # ç§æœ‰æ–¹æ³•ï¼šæ•°æ®åŠ è½½
    # ========================================================================
    def _load_data(self, dataset: Union[pd.DataFrame, Any], spark=None) -> pd.DataFrame:
        """
        åŠ è½½æ•°æ®å¹¶è½¬æ¢ä¸º Pandas DataFrame

        Args:
            dataset: æ•°æ®é›†ï¼ˆè¡¨åã€Spark DataFrame æˆ– Pandas DataFrameï¼‰
            spark: Spark sessionï¼ˆå¦‚æœ dataset æ˜¯è¡¨åï¼‰

        Returns:
            Pandas DataFrame
        """
        if isinstance(dataset, str):
            if spark is None:
                raise ValueError("Spark session is required when dataset is a table name")
            pdf = self._safe_to_pandas(spark.read.table(dataset), spark)
        elif hasattr(dataset, "toPandas"):
            # å°è¯•è·å– SparkSession
            try:
                from pyspark.sql import SparkSession
                spark_session = SparkSession.getActiveSession()
            except Exception:
                spark_session = None
            pdf = self._safe_to_pandas(dataset, spark_session)
        else:
            pdf = dataset

        print_separator()
        safe_print("ğŸ“Š Data Loading", show_timestamp=False, show_level=False)
        print_separator()
        if self.data_source_table:
            safe_print(f"Data source: {self.data_source_table}")
        safe_print(f"Dataset shape: {pdf.shape} (rows Ã— columns)")
        safe_print(f"Memory usage: {pdf.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

        # æ—¶åºé¢„æµ‹ä»»åŠ¡ï¼šè‡ªåŠ¨è½¬æ¢æ—¶é—´åˆ—ä¸º datetime ç±»å‹
        if self.task == "forecast":
            time_col = self.kwargs.get("time_col")
            if time_col and time_col in pdf.columns:
                if not pd.api.types.is_datetime64_any_dtype(pdf[time_col]):
                    safe_print(f"Converting time column '{time_col}' to datetime...")
                    try:
                        pdf[time_col] = pd.to_datetime(pdf[time_col])
                        safe_print(f"âœ… Time column '{time_col}' converted to datetime64")
                    except Exception as e:
                        safe_print(f"âš ï¸  Failed to convert time column: {e}")

        return pdf

    # ========================================================================
    # ç§æœ‰æ–¹æ³•ï¼šMLflow å®éªŒè®¾ç½®
    # ========================================================================
    def _setup_mlflow_experiment(self) -> tuple:
        """
        è®¾ç½® MLflow å®éªŒ

        Returns:
            (experiment, experiment_name, experiment_id)
        """
        safe_print("", show_timestamp=False, show_level=False)
        print_separator()
        safe_print(f"ğŸ“ MLflow Experiment Setup")
        print_separator()

        tracking_uri = mlflow.get_tracking_uri()
        safe_print(f"MLflow Tracking URI: {tracking_uri}")

        if tracking_uri.startswith('file://') and self.workspace_id:
            warning_msg = (
                f"âš ï¸  WARNING: Using local file system MLflow tracking ('{tracking_uri}')\n"
                f"   Local MLflow does not support project ID validation.\n"
                f"   For production use, please set MLflow tracking URI to a remote server:\n"
                f"   Example: mlflow.set_tracking_uri('http://your-mlflow-server:5000')"
            )
            safe_print(warning_msg)
            logger.warning(warning_msg)

        if self.experiment_id:
            experiment = mlflow.get_experiment(self.experiment_id)
            if experiment is None:
                error_msg = (
                    f"âŒ Experiment with ID '{self.experiment_id}' not found.\n"
                    f"Please verify:\n"
                    f"  - The experiment ID is correct\n"
                    f"  - The experiment exists in the MLflow tracking server\n"
                    f"  - MLflow tracking URI: {mlflow.get_tracking_uri()}"
                )
                logger.error(error_msg)
                raise ValueError(error_msg)
            experiment_name = experiment.name
            safe_print(f"Using experiment by ID: {self.experiment_id}")
            safe_print(f"Experiment name: '{experiment_name}'")
        else:
            experiment_name = self.experiment_name

        try:
            mlflow.set_experiment(experiment_name)
        except Exception as e:
            error_msg = (
                f"âŒ Failed to set experiment '{experiment_name}'. Error: {traceback.format_exc()}\n\n"
                f"This may be due to:\n"
                f"  1. MLflow backend permission issues\n"
                f"  2. Project ID '{self.workspace_id}' not found or invalid\n"
                f"  3. MLflow tracking server connection issues\n"
                f"  4. Backend API restrictions (e.g., project validation)\n\n"
                f"Configuration:\n"
                f"  - MLflow tracking URI: {mlflow.get_tracking_uri()}\n"
                f"  - Project ID: {self.workspace_id}\n"
                f"  - Experiment name: {experiment_name}\n\n"
                f"Please verify:\n"
                f"  - The project ID '{self.workspace_id}' exists in the backend\n"
                f"  - You have permission to create experiments in this project\n"
                f"  - The MLflow tracking server is accessible"
            )
            logger.error(error_msg)
            raise ValueError(error_msg) from e

        experiment = mlflow.get_experiment_by_name(experiment_name)

        if experiment is None:
            error_msg = (
                f"âŒ Failed to create or get experiment '{experiment_name}'. "
                f"This may be due to:\n"
                f"  1. MLflow backend permission issues\n"
                f"  2. Project ID '{self.workspace_id}' validation failed\n"
                f"  3. MLflow tracking server connection issues\n"
                f"  4. Backend API restrictions\n\n"
                f"Please check:\n"
                f"  - MLflow tracking URI: {mlflow.get_tracking_uri()}\n"
                f"  - Project ID: {self.workspace_id}\n"
                f"  - Backend server logs for more details"
            )
            logger.error(error_msg)
            raise ValueError(error_msg)

        experiment_id = experiment.experiment_id

        if experiment.creation_time == experiment.last_update_time:
            safe_print(f"âœ… Created new experiment: '{experiment_name}' (ID: {experiment_id})")
        else:
            safe_print(f"âœ… Using existing experiment: '{experiment_name}' (ID: {experiment_id})")

        if self.workspace_id:
            try:
                mlflow.set_experiment_tag("wedata.project", self.workspace_id)
                safe_print(f"âœ… Set project ID tag: 'wedata.project' = '{self.workspace_id}'")
            except Exception as e:
                safe_print(f"âš ï¸  Failed to set project ID tag: {e}")
                logger.warning(f"Failed to set project ID tag: {e}")

        return experiment, experiment_name, experiment_id

    # ========================================================================
    # ç§æœ‰æ–¹æ³•ï¼šæ„å»º FLAML è®¾ç½®
    # ========================================================================
    def _build_flaml_settings(self, log_file_path: str) -> dict:
        """
        æ„å»º FLAML AutoML é…ç½®

        Args:
            log_file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„

        Returns:
            FLAML settings å­—å…¸
        """
        estimator_list = self._get_estimator_list()

        # FLAML ä»»åŠ¡ç±»å‹æ˜ å°„ï¼šæˆ‘ä»¬çš„ "forecast" -> FLAML çš„ "ts_forecast"
        flaml_task = "ts_forecast" if self.task == "forecast" else self.task

        # è·å–æŒ‡æ ‡ï¼ˆå¯èƒ½æ˜¯è‡ªå®šä¹‰æŒ‡æ ‡å‡½æ•°ï¼‰
        metric = self._get_flaml_metric()

        settings = {
            "task": flaml_task,
            "metric": metric,
            "time_budget": int(self.timeout_minutes * 60),
            "eval_method": "holdout",
            "ensemble": False,
            "verbose": 0,
            "estimator_list": estimator_list,
            "seed": 42,
            "log_file_name": log_file_path,
            "mlflow_logging": False,
            "early_stop": False,
            "log_type": "all",
            "n_concurrent_trials": self.max_concurrent_trials,
            "use_spark": self.use_spark,
        }

        if self.max_trials:
            settings["max_iter"] = self.max_trials

        if self.use_spark:
            settings["force_cancel"] = True

        if self.custom_hp:
            settings["custom_hp"] = self.custom_hp
            safe_print(f"Custom hyperparameter search space provided for: {', '.join(self.custom_hp.keys())}")

        if self.task == "forecast" and self.country_code is not None:
            if "prophet" not in settings.get("custom_hp", {}):
                settings.setdefault("custom_hp", {})["prophet"] = {}
            safe_print(f"Country code for holidays: '{self.country_code}' (Prophet only)")

        # æ‰“å°é…ç½®ä¿¡æ¯
        safe_print(f"Task: {self.task} (FLAML task: {flaml_task})")
        safe_print(f"Metric: {self.metric}")
        safe_print(f"Time budget: {self.timeout_minutes} minutes ({int(self.timeout_minutes * 60)} seconds)")
        safe_print(f"Max trials: {self.max_trials if self.max_trials else 'unlimited'}")
        safe_print(f"Concurrent trials: {self.max_concurrent_trials}")
        safe_print(f"Parallel backend: {'Spark' if self.use_spark else 'Local (multi-thread)'}")
        safe_print(f"Estimators: {', '.join(estimator_list)}")
        safe_print(f"Evaluation method: holdout")
        if self.custom_hp:
            safe_print(f"Custom search space: Yes ({len(self.custom_hp)} estimator(s))")

        return settings

    def _get_flaml_metric(self):
        """
        è·å– FLAML å…¼å®¹çš„æŒ‡æ ‡

        FLAML å†…ç½®æ”¯æŒ: rmse, mse, mae, mape, r2, accuracy, log_loss, f1, roc_auc
        è‡ªå®šä¹‰æ”¯æŒ: smape, mdape, deviance, precision

        æ³¨æ„ï¼šå¯¹äºæ—¶åºé¢„æµ‹ä»»åŠ¡ (ts_forecast)ï¼ŒFLAML çš„è‡ªå®šä¹‰æŒ‡æ ‡æ¥å£ä¸åˆ†ç±»/å›å½’ä¸åŒï¼Œ
        å› æ­¤æŸäº›è‡ªå®šä¹‰æŒ‡æ ‡éœ€è¦æ˜ å°„åˆ° FLAML å†…ç½®æŒ‡æ ‡ã€‚

        Returns:
            æŒ‡æ ‡å­—ç¬¦ä¸²æˆ–è‡ªå®šä¹‰æŒ‡æ ‡å‡½æ•°
        """
        # FLAML å†…ç½®æ”¯æŒçš„æŒ‡æ ‡ç›´æ¥è¿”å›
        flaml_builtin_metrics = ["rmse", "mse", "mae", "mape", "r2", "accuracy", "log_loss", "f1", "roc_auc"]
        if self.metric in flaml_builtin_metrics:
            return self.metric

        # å¯¹äºæ—¶åºé¢„æµ‹ä»»åŠ¡ï¼ŒæŸäº›è‡ªå®šä¹‰æŒ‡æ ‡éœ€è¦æ˜ å°„åˆ° FLAML å†…ç½®æŒ‡æ ‡
        # å› ä¸º ts_forecast çš„è¯„ä¼°æ¥å£ä¸åˆ†ç±»/å›å½’ä¸åŒï¼Œè‡ªå®šä¹‰æŒ‡æ ‡å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ
        if self.task == "forecast":
            forecast_metric_mapping = {
                "smape": "mape",  # SMAPE æ˜ å°„åˆ° MAPE (FLAML å†…ç½®)
                "mdape": "mape",  # MDAPE æ˜ å°„åˆ° MAPE (FLAML å†…ç½®)
            }
            if self.metric in forecast_metric_mapping:
                mapped_metric = forecast_metric_mapping[self.metric]
                safe_print(f"â„¹ï¸  For forecast task, metric '{self.metric}' is mapped to FLAML built-in '{mapped_metric}'")
                return mapped_metric

        # éæ—¶åºé¢„æµ‹ä»»åŠ¡çš„è‡ªå®šä¹‰æŒ‡æ ‡
        custom_metrics = {
            "smape": self._smape_metric,
            "mdape": self._mdape_metric,
            "deviance": self._deviance_metric,
            "precision": self._precision_metric,
        }

        if self.metric in custom_metrics:
            return custom_metrics[self.metric]
        else:
            # æœªçŸ¥æŒ‡æ ‡ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨
            safe_print(f"âš ï¸  Metric '{self.metric}' is not a known metric, using as-is")
            return self.metric

    @staticmethod
    def _smape_metric(X_val, y_val, estimator, labels=None, X_train=None, y_train=None,
                      weight_val=None, weight_train=None, *args, **kwargs):
        """
        SMAPE (Symmetric Mean Absolute Percentage Error) è‡ªå®šä¹‰æŒ‡æ ‡

        SMAPE = (1/n) * Î£(|y_pred - y_true| / ((|y_true| + |y_pred|) / 2)) * 100
        èŒƒå›´: 0% - 200%
        """
        import numpy as np
        y_pred = estimator.predict(X_val)
        y_true = np.array(y_val)
        y_pred = np.array(y_pred)

        # é¿å…é™¤é›¶
        denominator = (np.abs(y_true) + np.abs(y_pred)) / 2
        denominator = np.where(denominator == 0, 1e-10, denominator)

        smape = np.mean(np.abs(y_pred - y_true) / denominator) * 100
        return smape, {"smape": smape}

    @staticmethod
    def _mdape_metric(X_val, y_val, estimator, labels=None, X_train=None, y_train=None,
                      weight_val=None, weight_train=None, *args, **kwargs):
        """
        MDAPE (Median Absolute Percentage Error) è‡ªå®šä¹‰æŒ‡æ ‡

        MDAPE = median(|y_pred - y_true| / |y_true|) * 100
        """
        import numpy as np
        y_pred = estimator.predict(X_val)
        y_true = np.array(y_val)
        y_pred = np.array(y_pred)

        # é¿å…é™¤é›¶
        y_true_safe = np.where(y_true == 0, 1e-10, y_true)

        ape = np.abs(y_pred - y_true) / np.abs(y_true_safe) * 100
        mdape = np.median(ape)
        return mdape, {"mdape": mdape}

    @staticmethod
    def _deviance_metric(X_val, y_val, estimator, labels=None, X_train=None, y_train=None,
                         weight_val=None, weight_train=None, *args, **kwargs):
        """
        Deviance (åå·®) è‡ªå®šä¹‰æŒ‡æ ‡ - ç”¨äºå›å½’ä»»åŠ¡

        å¯¹äºé«˜æ–¯åˆ†å¸ƒï¼ŒDeviance ç­‰äº MSE
        Deviance = (1/n) * Î£(y_pred - y_true)^2

        æ³¨æ„ï¼šFLAML ä¼˜åŒ–æ—¶ä¼šæœ€å°åŒ–è¿™ä¸ªå€¼
        """
        import numpy as np
        y_pred = estimator.predict(X_val)
        y_true = np.array(y_val)
        y_pred = np.array(y_pred)

        # è®¡ç®— MSE (å‡æ–¹è¯¯å·®) ä½œä¸º deviance
        deviance = np.mean((y_pred - y_true) ** 2)
        return deviance, {"deviance": deviance}

    @staticmethod
    def _precision_metric(X_val, y_val, estimator, labels=None, X_train=None, y_train=None,
                          weight_val=None, weight_train=None, *args, **kwargs):
        """
        Precision (ç²¾ç¡®ç‡) è‡ªå®šä¹‰æŒ‡æ ‡ - ç”¨äºåˆ†ç±»ä»»åŠ¡

        Precision = TP / (TP + FP)

        æ³¨æ„ï¼šFLAML ä¼˜åŒ–æ—¶ä¼šæœ€å°åŒ– lossï¼Œæ‰€ä»¥è¿”å› 1 - precision
        """
        import numpy as np
        from sklearn.metrics import precision_score

        y_pred = estimator.predict(X_val)
        y_true = np.array(y_val)

        # è®¡ç®— precision (å¤šåˆ†ç±»ä½¿ç”¨ weighted å¹³å‡)
        if len(np.unique(y_true)) > 2:
            precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)
        else:
            precision = precision_score(y_true, y_pred, zero_division=0)

        # è¿”å› 1 - precision ä»¥ä¾¿ FLAML æœ€å°åŒ–
        return 1 - precision, {"precision": precision}

    # ========================================================================
    # ç§æœ‰æ–¹æ³•ï¼šå‡†å¤‡æ—¶åºé¢„æµ‹æ•°æ®
    # ========================================================================
    def _prepare_forecast_data(self, settings: dict) -> dict:
        """
        å‡†å¤‡æ—¶åºé¢„æµ‹ä»»åŠ¡çš„æ•°æ®å’Œ fit å‚æ•°

        è‡ªåŠ¨è¿›è¡Œä»¥ä¸‹é¢„å¤„ç†ï¼š
        1. è½¬æ¢æ—¶é—´åˆ—ä¸º datetime ç±»å‹
        2. æŒ‰æ—¶é—´æ’åº
        3. è‡ªåŠ¨æ¨æ–­é¢‘ç‡ï¼ˆå¦‚æœè®¾ç½®ä¸º "auto" æˆ–æœªè¯†åˆ«ï¼‰
        4. å¡«å……ç¼ºå¤±æ—¶é—´ç‚¹
        5. è®¾ç½®è§„åˆ™é¢‘ç‡ç´¢å¼•

        Args:
            settings: FLAML è®¾ç½®

        Returns:
            fit_kwargs å­—å…¸
        """
        time_col = self.kwargs.get("time_col")
        horizon = self.kwargs.get("horizon", 1)
        frequency = self.kwargs.get("frequency", "auto")  # é»˜è®¤æ”¹ä¸º auto

        # ä½¿ç”¨å®Œæ•´çš„è¿ç»­æ•°æ®
        train_df = self._pdf.copy()

        # ç¡®ä¿æ—¶é—´åˆ—æ˜¯ datetime ç±»å‹
        if time_col and time_col in train_df.columns:
            if not pd.api.types.is_datetime64_any_dtype(train_df[time_col]):
                safe_print(f"Converting time column '{time_col}' to datetime...")
                train_df[time_col] = pd.to_datetime(train_df[time_col])

        # é€‰æ‹©éœ€è¦çš„åˆ—ï¼ˆæ’é™¤å†…éƒ¨åˆ—ï¼‰
        internal_cols = {"_automl_split_col", "_automl_sample_weight"}
        forecast_cols = [time_col, self.target_col] + [
            f for f in self.features if f not in internal_cols and f != time_col
        ]
        forecast_cols = list(dict.fromkeys(forecast_cols))
        train_df_for_flaml = train_df[forecast_cols].copy()

        # æŒ‰æ—¶é—´æ’åºå¹¶å»é‡ï¼ˆä¿ç•™æœ€åä¸€ä¸ªé‡å¤æ—¶é—´ç‚¹ï¼‰
        train_df_for_flaml = train_df_for_flaml.sort_values(by=time_col)
        if train_df_for_flaml[time_col].duplicated().any():
            dup_count = train_df_for_flaml[time_col].duplicated().sum()
            safe_print(f"âš ï¸  Found {dup_count} duplicate timestamps, keeping last occurrence...")
            train_df_for_flaml = train_df_for_flaml.drop_duplicates(subset=[time_col], keep='last')
        train_df_for_flaml = train_df_for_flaml.reset_index(drop=True)

        # ç¼ºå¤±æ—¶é—´ç‚¹è¡¥å…… + è®¾ç½®è§„åˆ™é¢‘ç‡
        train_df_for_flaml = self._fill_missing_timestamps(train_df_for_flaml, time_col, frequency)

        # è·å–å®é™…ä½¿ç”¨çš„é¢‘ç‡ï¼ˆå¯èƒ½æ˜¯è‡ªåŠ¨æ¨æ–­çš„ï¼‰
        actual_freq = frequency
        if hasattr(self, '_inferred_frequency'):
            actual_freq = self._inferred_frequency

        safe_print(f"Forecast task: using dataframe + label mode")
        safe_print(f"  Time column: {time_col}")
        safe_print(f"  Horizon: {horizon}")
        safe_print(f"  Frequency: {actual_freq}")
        safe_print(f"  DataFrame shape: {train_df_for_flaml.shape}")
        safe_print(f"  Date range: {train_df_for_flaml[time_col].min()} to {train_df_for_flaml[time_col].max()}")

        return {
            "dataframe": train_df_for_flaml,
            "label": self.target_col,
            "time_col": time_col,
            "period": horizon,
            **settings,
        }

    def _infer_frequency(self, df: pd.DataFrame, time_col: str) -> str:
        """
        è‡ªåŠ¨æ¨æ–­æ—¶é—´åºåˆ—çš„é¢‘ç‡

        Args:
            df: æ—¶åºæ•°æ® DataFrame
            time_col: æ—¶é—´åˆ—å

        Returns:
            æ¨æ–­å‡ºçš„é¢‘ç‡å­—ç¬¦ä¸²ï¼ˆpandas freq æ ¼å¼ï¼‰
        """
        if len(df) < 2:
            safe_print("âš ï¸  Not enough data points to infer frequency, defaulting to 'D'")
            return "D"

        # è®¡ç®—æ—¶é—´å·®
        time_diffs = df[time_col].diff().dropna()

        if len(time_diffs) == 0:
            return "D"

        # è·å–æœ€å¸¸è§çš„æ—¶é—´å·®
        mode_diff = time_diffs.mode()
        if len(mode_diff) == 0:
            median_diff = time_diffs.median()
        else:
            median_diff = mode_diff.iloc[0]

        # è½¬æ¢ä¸ºç§’
        total_seconds = median_diff.total_seconds()

        # æ¨æ–­é¢‘ç‡
        if total_seconds < 60:  # ç§’çº§
            freq = "S"
        elif total_seconds < 3600:  # åˆ†é’Ÿçº§
            freq = "T"
        elif total_seconds < 86400:  # å°æ—¶çº§
            freq = "H"
        elif total_seconds < 86400 * 7:  # å¤©çº§
            freq = "D"
        elif total_seconds < 86400 * 28:  # å‘¨çº§
            freq = "W"
        elif total_seconds < 86400 * 90:  # æœˆçº§
            freq = "MS"
        elif total_seconds < 86400 * 365:  # å­£åº¦çº§
            freq = "QS"
        else:  # å¹´çº§
            freq = "YS"

        safe_print(f"ğŸ“Š Inferred frequency: {freq} (median interval: {median_diff})")
        return freq

    def _fill_missing_timestamps(self, df: pd.DataFrame, time_col: str, frequency: str) -> pd.DataFrame:
        """
        å¡«å……ç¼ºå¤±çš„æ—¶é—´ç‚¹å¹¶è®¾ç½®è§„åˆ™é¢‘ç‡ï¼ˆå‚è€ƒ Databricks/Azure AutoML ç­–ç•¥ï¼‰

        Args:
            df: æ—¶åºæ•°æ® DataFrame
            time_col: æ—¶é—´åˆ—å
            frequency: æ—¶é—´é¢‘ç‡

        Returns:
            å¡«å……åçš„ DataFrameï¼ˆå¸¦æœ‰è§„åˆ™é¢‘ç‡çš„æ—¶é—´ç´¢å¼•ï¼‰
        """
        freq_map = {
            "D": "D", "days": "D", "day": "D",
            "W": "W", "weeks": "W", "week": "W",
            "M": "MS", "month": "MS", "months": "MS",
            "Q": "QS", "quarter": "QS", "quarters": "QS",
            "Y": "YS", "year": "YS", "years": "YS",
            "H": "H", "hours": "H", "hour": "H", "hr": "H", "h": "H",
            "T": "T", "min": "T", "minute": "T", "minutes": "T", "m": "T",
            "S": "S", "sec": "S", "second": "S", "seconds": "S",
        }

        # å¦‚æœ frequency æ˜¯ "auto" æˆ–æ— æ³•è¯†åˆ«ï¼Œè‡ªåŠ¨æ¨æ–­
        if frequency.lower() == "auto" or frequency not in freq_map:
            safe_print(f"â„¹ï¸  Frequency '{frequency}' not recognized or set to auto, inferring from data...")
            pd_freq = self._infer_frequency(df, time_col)
        else:
            pd_freq = freq_map.get(frequency, "D")

        date_min = df[time_col].min()
        date_max = df[time_col].max()

        # åˆ›å»ºå®Œæ•´çš„æ—¥æœŸèŒƒå›´ï¼ˆå¸¦æœ‰ freq å±æ€§ï¼‰
        full_date_range = pd.date_range(start=date_min, end=date_max, freq=pd_freq)

        existing_dates = set(df[time_col])
        missing_dates = set(full_date_range) - existing_dates

        if missing_dates:
            safe_print(f"âš ï¸  Found {len(missing_dates)} missing time points, filling with forward fill...")

        # è®¾ç½®æ—¶é—´åˆ—ä¸ºç´¢å¼•
        df = df.set_index(time_col)

        # é‡å»ºç´¢å¼•ä¸ºå®Œæ•´çš„æ—¥æœŸèŒƒå›´ï¼ˆè¿™ä¼šè‡ªåŠ¨è®¾ç½® freq å±æ€§ï¼‰
        df = df.reindex(full_date_range)
        df.index.name = time_col

        # ç¡®ä¿ç´¢å¼•æœ‰ freq å±æ€§
        if df.index.freq is None:
            df.index = pd.DatetimeIndex(df.index, freq=pd_freq)
            safe_print(f"âœ… Set time index frequency to: {pd_freq}")

        # å‰å‘å¡«å…… + åå‘å¡«å……
        df = df.ffill().bfill()

        # é‡ç½®ç´¢å¼•
        df = df.reset_index()

        if missing_dates:
            safe_print(f"âœ… Missing time points filled. New shape: {df.shape}")
        else:
            safe_print(f"âœ… Time series regularized with frequency: {pd_freq}")

        return df

    # ========================================================================
    # ç§æœ‰æ–¹æ³•ï¼šæ‰§è¡Œ AutoML è®­ç»ƒ
    # ========================================================================
    def _run_automl_training(self, fit_kwargs: dict) -> float:
        """
        æ‰§è¡Œ FLAML AutoML è®­ç»ƒ

        Args:
            fit_kwargs: FLAML fit å‚æ•°

        Returns:
            è®­ç»ƒè€—æ—¶ï¼ˆç§’ï¼‰
        """
        import logging as py_logging

        # æŠ‘åˆ¶æ—¥å¿—
        flaml_logger = py_logging.getLogger("flaml.automl.logger")
        flaml_automl_logger = py_logging.getLogger("flaml.automl")
        mlflow_logger = py_logging.getLogger("mlflow.tracking._tracking_service.client")
        mlflow_utils_logger = py_logging.getLogger("mlflow.utils")

        original_levels = {
            "flaml": flaml_logger.level,
            "flaml_automl": flaml_automl_logger.level,
            "mlflow": mlflow_logger.level,
            "mlflow_utils": mlflow_utils_logger.level,
        }

        flaml_logger.setLevel(py_logging.WARNING)
        flaml_automl_logger.setLevel(py_logging.WARNING)
        mlflow_logger.setLevel(py_logging.WARNING)
        mlflow_utils_logger.setLevel(py_logging.WARNING)

        safe_print("Training in progress... (FLAML debug logs suppressed)")

        start_time = time.time()
        try:
            self.automl.fit(**fit_kwargs)
        finally:
            flaml_logger.setLevel(original_levels["flaml"])
            flaml_automl_logger.setLevel(original_levels["flaml_automl"])
            mlflow_logger.setLevel(original_levels["mlflow"])
            mlflow_utils_logger.setLevel(original_levels["mlflow_utils"])

        return time.time() - start_time

    # ========================================================================
    # ç§æœ‰æ–¹æ³•ï¼šä¸Šä¼ æ—¥å¿—æ–‡ä»¶
    # ========================================================================
    def _upload_log_file(self, log_file_path: str):
        """ä¸Šä¼  FLAML æ—¥å¿—æ–‡ä»¶åˆ° MLflow"""
        safe_print("", show_timestamp=False, show_level=False)
        safe_print("ğŸ“¤ Uploading FLAML log file to MLflow...")
        try:
            if os.path.exists(log_file_path):
                mlflow.log_artifact(log_file_path, artifact_path="flaml_logs")
                safe_print(f"âœ… Log file uploaded: {os.path.basename(log_file_path)}")

                if self.auto_cleanup_logs:
                    try:
                        os.remove(log_file_path)
                        safe_print(f"âœ… Local log file cleaned up: {log_file_path}")
                    except Exception as e:
                        safe_print(f"âš ï¸  Failed to cleanup local log file: {e}")
            else:
                safe_print(f"âš ï¸  Log file not found: {log_file_path}")
        except Exception as e:
            safe_print(f"âš ï¸  Failed to upload log file: {e}")
            if self.auto_cleanup_logs:
                try:
                    if os.path.exists(log_file_path):
                        os.remove(log_file_path)
                except Exception:
                    pass

    # ========================================================================
    # ç§æœ‰æ–¹æ³•ï¼šæ¨¡å‹è®°å½•å’Œæ³¨å†Œ
    # ========================================================================
    def _log_and_register_model(
        self,
        parent_run_id: str,
        X_train: pd.DataFrame
    ) -> tuple:
        """
        è®°å½•å’Œæ³¨å†Œæ¨¡å‹

        Args:
            parent_run_id: çˆ¶ run ID
            X_train: è®­ç»ƒç‰¹å¾æ•°æ®

        Returns:
            (model_uri, model_version)
        """
        safe_print("", show_timestamp=False, show_level=False)
        print_separator()
        safe_print(f"ğŸ’¾ Model Logging & Registration")
        print_separator()

        # è‡ªåŠ¨ç”Ÿæˆæ¨¡å‹åç§°ï¼šå®éªŒåç§°_projectid_ä»»åŠ¡ç±»å‹_datetime
        if not self.register_model:
            safe_print(f"â„¹ï¸  register_model: {self.register_model}. Model registration Skipped! ")
            return None, None

        if self.model_name:
            registered_model_name = self.model_name
        else:
            # è‡ªåŠ¨ç”Ÿæˆæ¨¡å‹åç§°
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # æ¸…ç†å®éªŒåç§°ï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
            exp_name = self.experiment_name or "automl"
            exp_name_clean = "".join(c if c.isalnum() or c == "_" else "_" for c in exp_name)
            workspace_id = self.workspace_id or "default"
            task_type = self.task or "model"
            registered_model_name = f"{exp_name_clean}_{workspace_id}_{task_type}_{timestamp}"
            safe_print(f"â„¹ï¸  Auto-generated model name: {registered_model_name}")

        model_version = None
        model_uri = None

        # æ—¶åºé¢„æµ‹ä»»åŠ¡ä½¿ç”¨ä¸“ç”¨æ–¹æ³•è®°å½•æ¨¡å‹
        if self.task == "forecast":
            safe_print(f"Using forecast model logging (pickle + artifact)")
            model_uri, model_version = self._log_model_with_mlflow(
                parent_run_id, registered_model_name, X_sample=X_train
            )
            return model_uri, model_version

        has_training_set = hasattr(self, '_training_set') and self._training_set is not None

        if has_training_set:
            safe_print(f"Using FeatureStoreClient.log_model (with feature lineage)")
            try:
                from wedata.feature_store.client import FeatureStoreClient
                from mlflow.models import infer_signature

                signature = None
                input_example = None
                try:
                    X_sample = X_train.head(100) if len(X_train) > 100 else X_train
                    y_pred = self.pipeline.predict(X_sample)
                    signature = infer_signature(X_sample, y_pred)
                    # å‡†å¤‡ input_exampleï¼ˆå–å‰å‡ è¡Œä½œä¸ºç¤ºä¾‹ï¼‰
                    input_example = X_sample.head(5) if len(X_sample) > 5 else X_sample
                    safe_print(f"âœ… Model signature inferred successfully")
                except Exception as e:
                    safe_print(f"âš ï¸  Failed to infer model signature: {e}")

                if not hasattr(self, '_fs_client') or self._fs_client is None:
                    self._fs_client = FeatureStoreClient()

                log_model_kwargs = {
                    "model": self.pipeline,
                    "artifact_path": "model",
                    "flavor": mlflow.sklearn,
                    "registered_model_name": registered_model_name,
                    "signature": signature,
                    "training_set": self._training_set,
                    "input_example": input_example,
                }

                self._fs_client.log_model(**log_model_kwargs)
                model_uri = f"runs:/{parent_run_id}/model"
                safe_print(f"âœ… Model logged to MLflow: {model_uri}")

                if registered_model_name:
                    try:
                        client = mlflow.tracking.MlflowClient()
                        versions = client.search_model_versions(filter_string=f"name='{registered_model_name}'")
                        if versions:
                            model_version = max(v.version for v in versions)
                        safe_print(f"âœ… Model registered: '{registered_model_name}' version {model_version}")
                        mlflow.set_tag("wedata.has_registered_model", "true")
                        # è®¾ç½® WeData å¹³å° tags
                        if model_version:
                            set_model_version_wedata_tags(
                                registered_model_name=registered_model_name,
                                model_version=model_version,
                                task=self.task
                            )
                    except Exception as e:
                        safe_print(f"âš ï¸  Could not get model version: {e}")
                        mlflow.set_tag("wedata.has_registered_model", "true")
                else:
                    safe_print(f"â„¹ï¸  Model not registered (register_model={self.register_model}, model_name={self.model_name})")
                    mlflow.set_tag("wedata.has_registered_model", "false")

            except ImportError:
                safe_print(f"âš ï¸  wedata-feature-engineering not available, falling back to mlflow.sklearn.log_model")
                X_sample = X_train.head(100) if len(X_train) > 100 else X_train
                model_uri, model_version = self._log_model_with_mlflow(
                    parent_run_id, registered_model_name, X_sample=X_sample
                )
            except Exception as e:
                safe_print(f"âš ï¸  FeatureStoreClient.log_model failed: {e}")
                safe_print("   Falling back to mlflow.sklearn.log_model...")
                X_sample = X_train.head(100) if len(X_train) > 100 else X_train
                model_uri, model_version = self._log_model_with_mlflow(
                    parent_run_id, registered_model_name, X_sample=X_sample
                )
        else:
            safe_print(f"Using mlflow.sklearn.log_model")
            X_sample = X_train.head(100) if len(X_train) > 100 else X_train
            model_uri, model_version = self._log_model_with_mlflow(
                parent_run_id, registered_model_name, X_sample=X_sample
            )

        return model_uri, model_version

    # ###############
    # ç§æœ‰æ–¹æ³•ï¼šCatalog æ¨¡å‹è®°å½•å’Œæ³¨å†Œ
    # ###############
    def _log_model_for_catalog(self, model_uri, experiment, best_trial_run_id, trial_hook, best_est):
        """
        å†™å…¥Catalog æ¨¡å‹è®°å½•å’Œæ³¨å†Œ
        :param model_uri: æ¨¡å‹uri
        :param experiment: å®éªŒä¿¡æ¯
        :param best_trial_run_id: æœ€ä½³æ¨¡å‹çš„è¿è¡ŒID
        :param trial_hook: äº§ç‰©Hook
        :param best_est: æœ€ä½³äº§ç‰©
        :return:
        """
        # ================================================================
        # é˜¶æ®µ 11.6: æ³¨å†Œæ¨¡å‹åˆ° TencentCloud Catalogï¼ˆå¯é€‰ï¼‰
        # ================================================================

        if self.register_to_catalog:
            safe_print("", show_timestamp=False, show_level=False)
            print_separator()
            safe_print(f"ğŸ“¦ Registering Model to TencentCloud Catalog")
            print_separator()

            if not model_uri:
                safe_print("Model URI is empty, skipping model registration to Catalog. "
                           "You may need to check the model logging step.", level="WARNING")
                return

            # ç”Ÿæˆ Catalog æ¨¡å‹åç§°ï¼ˆæ ¼å¼ï¼šcatalog.schema.model_nameï¼‰
            if self.catalog_model_name:
                catalog_model_name = self.catalog_model_name
            else:
                # è‡ªåŠ¨ç”Ÿæˆï¼šä» data_source_table è§£æ catalog å’Œ schema
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                exp_name_clean = "".join(
                    c if c.isalnum() or c == "_" else "_" for c in (self.experiment_name or "automl"))
                model_name_part = f"{exp_name_clean}_{self.task}_{timestamp}"

                # ä» data_source_table è§£æ catalog å’Œ schema
                if self.data_source_table:
                    table_parts = self.data_source_table.split('.')
                    if len(table_parts) >= 3:
                        catalog_name = table_parts[0]
                        schema_name = table_parts[1]
                    elif len(table_parts) == 2:
                        catalog_name = os.getenv('TENCENTCLOUD_DEFAULT_CATALOG_NAME', 'default')
                        schema_name = table_parts[0]
                    else:
                        catalog_name = os.getenv('TENCENTCLOUD_DEFAULT_CATALOG_NAME', 'default')
                        schema_name = os.getenv('TENCENTCLOUD_DEFAULT_SCHEMA_NAME', 'default')
                else:
                    # æ²¡æœ‰ data_source_tableï¼Œä½¿ç”¨é»˜è®¤å€¼
                    catalog_name = os.getenv('TENCENTCLOUD_DEFAULT_CATALOG_NAME', 'default')
                    schema_name = os.getenv('TENCENTCLOUD_DEFAULT_SCHEMA_NAME', 'default')

                # æ„å»ºä¸‰æ®µå¼æ¨¡å‹åç§°
                catalog_model_name = f"{catalog_name}.{schema_name}.{model_name_part}"
                safe_print(f"â„¹ï¸  Auto-generated catalog model name: {catalog_model_name}")
                safe_print(f"   Catalog: {catalog_name}, Schema: {schema_name}, Model: {model_name_part}")

            # æ„å»º run link
            tracking_uri = mlflow.get_tracking_uri()
            run_link = f"{tracking_uri}/#/experiments/{experiment.experiment_id}/runs/{best_trial_run_id}"

            # è°ƒç”¨æ³¨å†Œæ–¹æ³•
            catalog_result = trial_hook.register_best_model_to_catalog(
                model_uri=model_uri,
                model_name=catalog_model_name,
                region=self.catalog_region,
                description=f"AutoML {self.task} model - {best_est}",
                run_link=run_link,
            )
            if catalog_result:
                safe_print(
                    f"âœ… Model registered to Catalog: {catalog_model_name} v{catalog_result.get('version')}  ID:{catalog_result.get('model_id')}")
            else:
                safe_print(f"âš ï¸  Catalog registration skipped or failed")
        else:
            safe_print("", show_timestamp=False, show_level=False)
            print_separator()
            safe_print(f"â„¹ï¸  register_to_catalog:{self.register_to_catalog} . Catalog registration skipped")
            print_separator()

        return

    # ========================================================================
    # ç§æœ‰æ–¹æ³•ï¼šåˆ›å»º AutoMLSummary
    # ========================================================================
    def _create_summary(
        self,
        experiment,
        experiment_name: str,
        parent_run_id: str,
        best_trial_run_id: str,
        model_uri: str,
        model_version: str,
        metrics: dict,
        best_est: str,
        best_cfg: dict,
    ) -> AutoMLSummary:
        """åˆ›å»º AutoMLSummary å¯¹è±¡"""
        task_kwargs = {}
        if self.task == "forecast":
            task_kwargs = {
                "time_col": self.kwargs.get("time_col"),
                "horizon": self.kwargs.get("horizon"),
                "frequency": self.kwargs.get("frequency"),
                "identity_col": self.kwargs.get("identity_col"),
            }

        # æ·»åŠ æ•°æ®æºè¡¨åï¼ˆå¦‚æœç”¨æˆ·ä¼ å…¥è¡¨åï¼‰
        if self.data_source_table:
            task_kwargs["data_source_table"] = self.data_source_table

        return AutoMLSummary(
            experiment_id=experiment.experiment_id,
            run_id=parent_run_id,
            best_trial_run_id=best_trial_run_id,
            model_uri=model_uri,
            model_version=model_version,
            metrics=metrics,
            best_estimator=best_est,
            best_params=best_cfg,
            task=self.task,
            mlflow_tracking_uri=mlflow.get_tracking_uri(),
            features=self.features,
            target_col=self.target_col,
            metric=self.metric,
            task_kwargs=task_kwargs,
            workspace_id=self.workspace_id,
            experiment_name=experiment_name,
        )

    # ========================================================================
    # ç§æœ‰æ–¹æ³•ï¼šæ‰“å°æœ€ç»ˆæ€»ç»“
    # ========================================================================
    def _print_final_summary(
        self,
        experiment_name: str,
        experiment_id: str,
        parent_run_id: str,
        best_est: str,
        model_uri: str,
        model_version: str,
        metrics: dict,
    ):
        """æ‰“å°è®­ç»ƒå®Œæˆçš„æœ€ç»ˆæ€»ç»“"""
        safe_print("", show_timestamp=False, show_level=False)
        print_separator()
        safe_print(f"ğŸ‰ Training Pipeline Completed Successfully!")
        print_separator()
        safe_print(f"Experiment: {experiment_name} (ID: {experiment_id})")
        safe_print(f"Run ID: {parent_run_id}")
        safe_print(f"Best Model: {best_est}")
        if self.register_model and self.model_name:
            safe_print(f"Registered Model: {self.model_name} v{model_version}")
        safe_print(f"Model URI: {model_uri}")

        if self.task == "classification":
            test_acc = metrics.get("test_accuracy", 0)
            test_f1 = metrics.get("test_f1", 0)
            safe_print(f"Test Accuracy: {test_acc:.4f}")
            safe_print(f"Test F1 Score: {test_f1:.4f}")
        elif self.task == "regression":
            test_r2 = metrics.get("test_r2", 0)
            test_rmse = metrics.get("test_rmse", 0)
            safe_print(f"Test RÂ²: {test_r2:.4f}")
            safe_print(f"Test RMSE: {test_rmse:.4f}")

        print_separator()

    # ========================================================================
    # ä¸»æ–¹æ³•ï¼šè®­ç»ƒ
    # ========================================================================
    def train(
        self,
        dataset: Union[pd.DataFrame, Any],
        data_source_table: str,
        spark=None
    ) -> AutoMLSummary:
        """
        è®­ç»ƒæ¨¡å‹

        Args:
            dataset: æ•°æ®é›†ï¼ˆPandas DataFrameã€Spark DataFrame æˆ–è¡¨åï¼‰
            data_source_table: æ•°æ®æºè¡¨åï¼ˆä¸‰æ®µå¼ï¼šcatalog.schema.table_nameï¼‰ï¼Œç”¨äº notebook ç”Ÿæˆ
            spark: Spark sessionï¼ˆå¦‚æœ dataset æ˜¯è¡¨åï¼‰

        Returns:
            AutoMLSummary å¯¹è±¡
        """
        # ä¿å­˜æ•°æ®æºè¡¨å
        self.data_source_table = data_source_table
        # ================================================================
        # é˜¶æ®µ 1: æ•°æ®åŠ è½½
        # ================================================================
        pdf = self._load_data(dataset, spark)

        if pdf is None or len(pdf) == 0:
            raise ValueError(
                "Dataset is empty (0 samples). Please check:\n"
                "  1. The data source table exists and contains data\n"
                "  2. The dataset parameter is correctly specified\n"
                "  3. Any data filters or transformations are not removing all rows"
            )
        safe_print(f"âœ… Data loaded: {len(pdf)} samples, {len(pdf.columns)} columns")
        # ================================================================
        # é˜¶æ®µ 2: ç‰¹å¾å­˜å‚¨æŸ¥æ‰¾ï¼ˆå¯é€‰ï¼‰
        # ================================================================
        if self.feature_store_lookups:
            safe_print("", show_timestamp=False, show_level=False)
            print_separator()
            safe_print("ğŸ”— Feature Store Lookups", show_timestamp=False, show_level=False)
            print_separator()
            pdf = self._apply_feature_store_lookups(pdf, spark)

        # ================================================================
        # é˜¶æ®µ 3: æ•°æ®å‡†å¤‡
        # ================================================================
        safe_print("", show_timestamp=False, show_level=False)
        print_separator()
        safe_print("ğŸ”§ Data Preparation", show_timestamp=False, show_level=False)
        print_separator()
        X_train, y_train, X_val, y_val, X_test, y_test, sample_weight_train = self._prepare_data(pdf)
        self._pdf = pdf  # ä¿å­˜ pdf å¼•ç”¨ï¼ˆæ—¶åºé¢„æµ‹ä»»åŠ¡éœ€è¦ï¼‰

        # ================================================================
        # é˜¶æ®µ 4: ç‰¹å¾é¢„å¤„ç†
        # ================================================================
        safe_print("", show_timestamp=False, show_level=False)
        print_separator()
        safe_print(f"âš™ï¸  Feature Preprocessing")
        print_separator()

        if self.imputers:
            safe_print(f"Custom imputers configured for {len(self.imputers)} columns:")
            for col, strategy in self.imputers.items():
                safe_print(f"  - {col}: {strategy}")
        else:
            safe_print(f"Using default imputer: auto (median)")

        self.preprocessor = build_numeric_preprocessor(
            self.features,
            imputers=self.imputers,
            default_imputer="auto"
        )
        X_train_num = self.preprocessor.fit_transform(X_train)
        X_val_num = self.preprocessor.transform(X_val)
        X_test_num = self.preprocessor.transform(X_test)

        safe_print(f"Preprocessor fitted successfully")
        safe_print(f"  - Train set: {X_train_num.shape}")
        safe_print(f"  - Val set:   {X_val_num.shape}")
        safe_print(f"  - Test set:  {X_test_num.shape}")

        # ================================================================
        # é˜¶æ®µ 5: MLflow å®éªŒè®¾ç½®
        # ================================================================
        experiment, experiment_name, experiment_id = self._setup_mlflow_experiment()

        # ================================================================
        # é˜¶æ®µ 6: MLflow Run å’Œ AutoML è®­ç»ƒ
        # ================================================================
        # è®¾ç½® user_idï¼ˆä» QCLOUD_UIN ç¯å¢ƒå˜é‡è·å–ï¼‰
        setup_mlflow_user_id()

        with mlflow.start_run(run_name=self.run_name) as parent_run:
            parent_run_id = parent_run.info.run_id
            safe_print(f"Run name: '{self.run_name}'")
            safe_print(f"Run ID: {parent_run_id}")

            # åˆ é™¤çˆ¶ run çš„ mlflow.source.name tag
            try:
                mlflow.delete_tag("mlflow.source.name")
            except Exception:
                pass

            # è®¾ç½® WeData å¹³å° tags
            set_run_wedata_tags(task=self.task)

            # è®°å½•åŸºæœ¬å‚æ•°
            mlflow.log_params({
                "task": self.task,
                "target_col": self.target_col,
                "timeout_minutes": self.timeout_minutes,
                "metric": self.metric,
                "n_rows": len(pdf),
                "n_features": len(self.features),
            })

            # è®°å½•æ•°æ®æºè¡¨åï¼ˆå¦‚æœç”¨æˆ·ä¼ å…¥è¡¨åï¼‰
            if self.data_source_table:
                mlflow.log_param("data_source_table", self.data_source_table)
                mlflow.set_tag("wedata.data_source_table", self.data_source_table)

            log_feature_list(self.features)
            log_engine_meta({"engine": "flaml", "version": getattr(flaml_pkg, "__version__", "unknown")})

            # ================================================================
            # é˜¶æ®µ 7: FLAML é…ç½®
            # ================================================================
            safe_print("", show_timestamp=False, show_level=False)
            print_separator()
            safe_print(f"ğŸ¤– AutoML Training Configuration")
            print_separator()
            self.automl = AutoML()

            # æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶
            if self.auto_cleanup_logs:
                safe_print("", show_timestamp=False, show_level=False)
                safe_print("ğŸ§¹ Cleaning up old log files...")
                try:
                    deleted_count = cleanup_old_log_files(
                        base_dir=self.log_file_dir,
                        max_age_hours=self.log_max_age_hours,
                        max_files=self.log_max_files,
                        dry_run=False
                    )
                    safe_print(f"âœ… Deleted {deleted_count} old log files" if deleted_count > 0 else "âœ… No old log files to clean up")
                except Exception as e:
                    safe_print(f"âš ï¸  Failed to cleanup old log files: {e}")

            # ç”Ÿæˆæ—¥å¿—æ–‡ä»¶è·¯å¾„
            log_file_path = generate_log_file_path(
                base_dir=self.log_file_dir,
                run_id=parent_run_id,
                use_timestamp=True,
                use_uuid=True
            )
            safe_print(f"ğŸ“ FLAML log file: {log_file_path}")

            # æ„å»º FLAML è®¾ç½®
            settings = self._build_flaml_settings(log_file_path)

            safe_print("", show_timestamp=False, show_level=False)
            print_separator()
            safe_print("ğŸš€ Starting AutoML Training...", show_timestamp=False, show_level=False)
            print_separator()

            # ================================================================
            # é˜¶æ®µ 8: å‡†å¤‡ fit å‚æ•°å¹¶è®­ç»ƒ
            # ================================================================
            safe_print("", show_timestamp=False, show_level=False)
            safe_print("ğŸ”§ Preparing TrialHook to log all trials...")
            trial_hook = TrialHook(
                parent_run_id=parent_run_id,
                features=self.features,
                task=self.task,
                metric=self.metric,
                enable_logging=True
            )

            # å‡†å¤‡ fit å‚æ•°
            if self.task == "forecast":
                fit_kwargs = self._prepare_forecast_data(settings)
            else:
                fit_kwargs = {
                    "X_train": X_train_num,
                    "y_train": y_train,
                    "X_val": X_val_num,
                    "y_val": y_val,
                    **settings,
                }
                if sample_weight_train is not None:
                    fit_kwargs["sample_weight"] = sample_weight_train
                    safe_print(f"Using sample weights for training")

            # æ‰§è¡Œè®­ç»ƒ
            start_time = time.time()
            actual_train_time = self._run_automl_training(fit_kwargs)

            # è®°å½• trials
            trial_hook.log_trials_from_automl(
                self.automl,
                log_file_path=log_file_path,
                feature_names=self.features,
                time_budget=int(self.timeout_minutes * 60),
                train_time=actual_train_time
            )

            # ä¸Šä¼ æ—¥å¿—æ–‡ä»¶
            self._upload_log_file(log_file_path)

            # ================================================================
            # é˜¶æ®µ 9: è®­ç»ƒå®Œæˆåå¤„ç†
            # ================================================================
            elapsed_time = time.time() - start_time
            safe_print("", show_timestamp=False, show_level=False)
            print_separator()
            safe_print("âœ… AutoML Training Completed", show_timestamp=False, show_level=False)
            print_separator()
            safe_print(f"Total training time: {elapsed_time:.1f}s ({elapsed_time/60:.2f} minutes)")

            trial_hook.print_summary()

            # å…ˆä¸ºæœ€ä½³å­ run è®¾ç½®æ‰€æœ‰å¿…è¦çš„ tagï¼ˆåŒ…æ‹¬ mlflow.source.name, wedata.project ç­‰ï¼‰
            # æ³¨æ„ï¼šforecast ä»»åŠ¡ä¸è®¾ç½® source_nameï¼Œå› ä¸ºä¸æ”¯æŒç”Ÿæˆ notebook
            if self.task == "forecast":
                # forecast ä»»åŠ¡ï¼šä¸è®¾ç½® source_nameï¼Œåªè®¾ç½®å…¶ä»– tag
                trial_hook.set_best_trial_tags(
                    source_name=None,  # ä¸è®¾ç½® source.name
                    workspace_id=self.workspace_id,
                    task=self.task,
                )
            else:
                trial_hook.set_best_trial_tags(
                    source_name="wedata-automl",
                    workspace_id=self.workspace_id,
                    task=self.task,
                )
            # ç„¶åæ¸…ç†å…¶ä»–å­ run çš„ mlflow.source.nameï¼ˆä¿ç•™æœ€ä½³å­ runï¼‰
            trial_hook.cleanup_child_runs_source_name(experiment.experiment_id, preserve_best=True)

            # è·å– TrialHook ç»Ÿè®¡ä¿¡æ¯
            hook_summary = trial_hook.get_summary()
            total_trials_run = hook_summary['total_trials']
            best_trial_run_id = hook_summary['best_trial_run_id']
            best_trial_run_name = hook_summary['best_trial_run_name']

            # è®°å½•æœ€ä½³é…ç½®
            best_est = self.automl.best_estimator
            best_cfg = self.automl.best_config
            log_best_config_overall(best_cfg)
            if getattr(self.automl, "best_config_per_estimator", None):
                log_best_config_per_estimator(self.automl.best_config_per_estimator)

            mlflow.log_param("best_estimator", best_est)
            mlflow.log_param("best_trial_run_id", best_trial_run_id)
            mlflow.log_param("total_trials", total_trials_run)

            mlflow.set_tags({
                "wedata.total_trials_run": str(total_trials_run),
                "wedata.best_run_id": best_trial_run_id,
                "wedata.best_run_name": best_trial_run_name,
            })
            safe_print(f"âœ… Tags set: total_trials_run={total_trials_run}, best_run_id={best_trial_run_id}, best_run_name={best_trial_run_name}")

            safe_print("", show_timestamp=False, show_level=False)
            safe_print(f"Best estimator: {best_est}")
            safe_print(f"Best config: {best_cfg}")

            # ================================================================
            # é˜¶æ®µ 10: æ„å»ºç®¡é“å’Œè¯„ä¼°
            # ================================================================
            safe_print("", show_timestamp=False, show_level=False)
            print_separator()
            safe_print(f"ğŸ”¨ Building Serving Pipeline")
            print_separator()

            # æ—¶åºé¢„æµ‹ä»»åŠ¡ä¸æ„å»º sklearn Pipelineï¼ˆæ¨¡å‹éœ€è¦ TimeSeriesDataset æ ¼å¼ï¼‰
            if self.task == "forecast":
                self.pipeline = self.automl.model
                safe_print("Pipeline built: [TimeSeriesEstimator] (forecast mode)")
            else:
                clf = self.automl.model
                self.pipeline = SkPipe([("preprocess", self.preprocessor), ("clf", clf)])
                self.pipeline.fit(X_train, y_train)
                safe_print("Pipeline built: [Preprocessor] -> [Classifier/Regressor]")

            safe_print("", show_timestamp=False, show_level=False)
            print_separator()
            safe_print(f"ğŸ“Š Model Evaluation")
            print_separator()

            # æ—¶åºé¢„æµ‹ä»»åŠ¡è·³è¿‡ä¼ ç»Ÿè¯„ä¼°ï¼ˆè¯„ä¼°åœ¨ FLAML å†…éƒ¨å·²å®Œæˆï¼‰
            # æ—¶åºé¢„æµ‹ä»»åŠ¡ï¼šè®°å½•æœ€ä½³æŸå¤±å’Œè®¡ç®—é¢å¤–æŒ‡æ ‡
            if self.task == "forecast":
                metrics = {"best_loss": self.automl.best_loss}

                # è®°å½• FLAML æœ€ä½³æŸå¤±åˆ° MLflow
                mlflow.log_metric("best_loss", self.automl.best_loss)
                # ç”¨ç”¨æˆ·æŒ‡å®šçš„æŒ‡æ ‡åç§°ä¹Ÿè®°å½•ä¸€ä»½
                if self.metric:
                    mlflow.log_metric(f"best_{self.metric}", self.automl.best_loss)

                # å°è¯•è®¡ç®—æ›´å¤šè¯„ä¼°æŒ‡æ ‡ï¼ˆåŸºäºéªŒè¯é›†ï¼‰
                try:
                    # è·å–éªŒè¯é›†é¢„æµ‹
                    y_val_pred = self.automl.predict(X_val)
                    y_val_true = np.array(y_val)
                    y_val_pred = np.array(y_val_pred)

                    # MSE
                    mse = float(np.mean((y_val_true - y_val_pred) ** 2))
                    metrics["val_mse"] = mse
                    mlflow.log_metric("val_mse", mse)

                    # RMSE
                    rmse = float(np.sqrt(mse))
                    metrics["val_rmse"] = rmse
                    mlflow.log_metric("val_rmse", rmse)

                    # MAE
                    mae = float(np.mean(np.abs(y_val_true - y_val_pred)))
                    metrics["val_mae"] = mae
                    mlflow.log_metric("val_mae", mae)

                    # SMAPE (Symmetric Mean Absolute Percentage Error)
                    denominator = (np.abs(y_val_true) + np.abs(y_val_pred)) / 2
                    denominator = np.where(denominator == 0, 1e-10, denominator)
                    smape = float(np.mean(np.abs(y_val_pred - y_val_true) / denominator) * 100)
                    metrics["val_smape"] = smape
                    mlflow.log_metric("val_smape", smape)

                    # MDAPE (Median Absolute Percentage Error)
                    y_val_true_safe = np.where(y_val_true == 0, 1e-10, y_val_true)
                    ape = np.abs(y_val_pred - y_val_true) / np.abs(y_val_true_safe) * 100
                    mdape = float(np.median(ape))
                    metrics["val_mdape"] = mdape
                    mlflow.log_metric("val_mdape", mdape)

                    safe_print(f"  Validation Metrics:")
                    safe_print(f"    SMAPE: {smape:.4f}% | RMSE: {rmse:.4f} | MAE: {mae:.4f} | MDAPE: {mdape:.4f}%")

                except Exception as e:
                    logger.debug(f"Failed to compute additional forecast metrics: {e}")
                    safe_print(f"  Best loss: {self.automl.best_loss:.4f}")
            else:
                metrics = self._evaluate_model(X_train, y_train, X_val, y_val, X_test, y_test)

            # ================================================================
            # é˜¶æ®µ 11: æ¨¡å‹è®°å½•å’Œæ³¨å†Œ
            # ================================================================

            model_uri, model_version = self._log_and_register_model(parent_run_id, X_train)


            # ================================================================
            # é˜¶æ®µ 11.5: æ—¶åºé¢„æµ‹ç»“æœä¿å­˜ï¼ˆå¯é€‰ï¼‰
            # ================================================================
            if self.task == "forecast" and self.prediction_result_storage:
                self._save_forecast_predictions(
                    parent_run_id=parent_run_id,
                    pdf=pdf,
                    spark=spark
                )

            # ================================================================
            # é˜¶æ®µ 11.6: æ³¨å†Œæ¨¡å‹åˆ° TencentCloud Catalogï¼ˆå¯é€‰ï¼‰
            # ================================================================
            self._log_model_for_catalog(model_uri, experiment, best_trial_run_id, trial_hook, best_est)
            # ================================================================
            # é˜¶æ®µ 12: åˆ›å»º Summary å¹¶è¿”å›
            # ================================================================
            summary = self._create_summary(
                experiment=experiment,
                experiment_name=experiment_name,
                parent_run_id=parent_run_id,
                best_trial_run_id=best_trial_run_id,
                model_uri=model_uri,
                model_version=model_version,
                metrics=metrics,
                best_est=best_est,
                best_cfg=best_cfg,
            )

            self._print_final_summary(
                experiment_name=experiment_name,
                experiment_id=experiment.experiment_id,
                parent_run_id=parent_run_id,
                best_est=best_est,
                model_uri=model_uri,
                model_version=model_version,
                metrics=metrics,
            )

            mlflow_client = mlflow.tracking.MlflowClient()
            mlflow_client.set_experiment_tag(experiment_id, "wedata.experiment.automl.status", "FINISHED")
            mlflow_client.set_experiment_tag(experiment_id, "wedata.experiment.automl.end.timestamp", str(int(time.time() * 1000)))
            return summary

