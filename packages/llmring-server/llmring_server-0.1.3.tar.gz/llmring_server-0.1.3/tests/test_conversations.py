"""Tests for conversation and message management endpoints and services. Covers conversation CRUD, message batching, logging levels, and retention cleanup."""

"""Tests for conversation and message management."""

from uuid import uuid4

import pytest

from llmring_server.models.conversations import (
    ConversationCreate,
    ConversationLogRequest,
    ConversationMetadata,
    ConversationUpdate,
    MessageBatch,
    MessageCreate,
)
from llmring_server.services.conversations import ConversationService


@pytest.mark.asyncio
async def test_create_conversation(test_app):
    """Test creating a new conversation."""
    response = await test_app.post(
        "/api/v1/conversations/",
        json={
            "title": "Test Conversation",
            "system_prompt": "You are a helpful assistant",
            "model_alias": "default",
            "temperature": 0.7,
            "max_tokens": 1000,
        },
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 200
    data = response.json()
    assert data["title"] == "Test Conversation"
    assert data["system_prompt"] == "You are a helpful assistant"
    # api_key_id is optional and can be None for local usage
    assert "api_key_id" in data
    assert "id" in data
    assert "created_at" in data


@pytest.mark.asyncio
async def test_get_conversation(test_app):
    """Test retrieving a conversation."""
    # First create a conversation
    create_response = await test_app.post(
        "/api/v1/conversations/",
        json={
            "title": "Test Get Conversation",
            "model_alias": "default",
        },
        headers={"X-API-Key": "test-project"},
    )
    assert create_response.status_code == 200
    conversation_id = create_response.json()["id"]

    # Get the conversation
    response = await test_app.get(
        f"/api/v1/conversations/{conversation_id}",
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 200
    data = response.json()
    assert data["id"] == conversation_id
    assert data["title"] == "Test Get Conversation"
    assert "messages" in data  # Should include messages by default


@pytest.mark.asyncio
async def test_get_conversation_without_messages(test_app):
    """Test retrieving a conversation without messages."""
    # First create a conversation
    create_response = await test_app.post(
        "/api/v1/conversations/",
        json={
            "title": "Test Without Messages",
            "model_alias": "default",
        },
        headers={"X-API-Key": "test-project"},
    )
    assert create_response.status_code == 200
    conversation_id = create_response.json()["id"]

    # Get the conversation without messages
    response = await test_app.get(
        f"/api/v1/conversations/{conversation_id}?include_messages=false",
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 200
    data = response.json()
    assert data["id"] == conversation_id
    assert data["messages"] == []


@pytest.mark.asyncio
async def test_get_conversation_not_found(test_app):
    """Test getting a non-existent conversation."""
    fake_id = str(uuid4())
    response = await test_app.get(
        f"/api/v1/conversations/{fake_id}",
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 404
    assert "not found" in response.json()["detail"].lower()


@pytest.mark.asyncio
async def test_get_conversation_wrong_api_key(test_app):
    """Test that conversations are isolated by API key."""
    # Create conversation with one API key
    create_response = await test_app.post(
        "/api/v1/conversations/",
        json={
            "title": "Isolated Conversation",
            "model_alias": "default",
        },
        headers={"X-API-Key": "project-1"},
    )
    assert create_response.status_code == 200
    conversation_id = create_response.json()["id"]

    # Try to get it with a different API key
    response = await test_app.get(
        f"/api/v1/conversations/{conversation_id}",
        headers={"X-API-Key": "project-2"},
    )

    assert response.status_code == 404


@pytest.mark.asyncio
async def test_update_conversation(test_app):
    """Test updating a conversation."""
    # Create conversation
    create_response = await test_app.post(
        "/api/v1/conversations/",
        json={
            "title": "Original Title",
            "model_alias": "default",
        },
        headers={"X-API-Key": "test-project"},
    )
    assert create_response.status_code == 200
    conversation_id = create_response.json()["id"]

    # Update it
    response = await test_app.patch(
        f"/api/v1/conversations/{conversation_id}",
        json={
            "title": "Updated Title",
            "temperature": 0.5,
        },
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 200
    data = response.json()
    assert data["title"] == "Updated Title"
    assert data["temperature"] == 0.5


@pytest.mark.asyncio
async def test_list_conversations(test_app):
    """Test listing conversations."""
    # Create multiple conversations
    for i in range(3):
        await test_app.post(
            "/api/v1/conversations/",
            json={
                "title": f"Conversation {i}",
                "model_alias": "default",
            },
            headers={"X-API-Key": "test-list-project"},
        )

    # List them
    response = await test_app.get(
        "/api/v1/conversations/",
        headers={"X-API-Key": "test-list-project"},
    )

    assert response.status_code == 200
    data = response.json()
    assert len(data) >= 3

    # Test pagination
    response = await test_app.get(
        "/api/v1/conversations/?limit=2",
        headers={"X-API-Key": "test-list-project"},
    )

    assert response.status_code == 200
    data = response.json()
    assert len(data) <= 2


@pytest.mark.asyncio
async def test_add_messages_batch(test_app):
    """Test adding messages to a conversation."""
    # Create conversation
    create_response = await test_app.post(
        "/api/v1/conversations/",
        json={
            "title": "Message Test",
            "model_alias": "default",
        },
        headers={"X-API-Key": "test-project"},
    )
    assert create_response.status_code == 200
    conversation_id = create_response.json()["id"]

    # Add messages
    response = await test_app.post(
        f"/api/v1/conversations/{conversation_id}/messages/batch",
        json={
            "conversation_id": conversation_id,
            "messages": [
                {
                    "role": "user",
                    "content": "Hello",
                },
                {
                    "role": "assistant",
                    "content": "Hi there!",
                    "input_tokens": 10,
                    "output_tokens": 5,
                },
            ],
            "logging_level": "full",
        },
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 200
    messages = response.json()
    assert len(messages) == 2
    assert messages[0]["role"] == "user"
    assert messages[0]["content"] == "Hello"
    assert messages[1]["role"] == "assistant"
    assert messages[1]["content"] == "Hi there!"


@pytest.mark.asyncio
async def test_add_messages_metadata_only(test_app):
    """Test adding messages with metadata logging level."""
    # Create conversation
    create_response = await test_app.post(
        "/api/v1/conversations/",
        json={
            "title": "Metadata Test",
            "model_alias": "default",
        },
        headers={"X-API-Key": "test-project"},
    )
    assert create_response.status_code == 200
    conversation_id = create_response.json()["id"]

    # Add messages with metadata logging
    response = await test_app.post(
        f"/api/v1/conversations/{conversation_id}/messages/batch",
        json={
            "conversation_id": conversation_id,
            "messages": [
                {
                    "role": "user",
                    "content": "This content should be hashed",
                },
            ],
            "logging_level": "metadata",
        },
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 200
    messages = response.json()
    assert len(messages) == 1
    assert messages[0]["content"] is None  # Content should be None
    assert messages[0]["content_hash"] is not None  # But hash should exist


@pytest.mark.asyncio
async def test_get_conversation_messages(test_app):
    """Test getting messages for a conversation."""
    # Create conversation and add messages
    create_response = await test_app.post(
        "/api/v1/conversations/",
        json={
            "title": "Messages Test",
            "model_alias": "default",
        },
        headers={"X-API-Key": "test-project"},
    )
    assert create_response.status_code == 200
    conversation_id = create_response.json()["id"]

    # Add some messages
    await test_app.post(
        f"/api/v1/conversations/{conversation_id}/messages/batch",
        json={
            "conversation_id": conversation_id,
            "messages": [
                {"role": "user", "content": "Message 1"},
                {"role": "assistant", "content": "Reply 1"},
                {"role": "user", "content": "Message 2"},
                {"role": "assistant", "content": "Reply 2"},
            ],
            "logging_level": "full",
        },
        headers={"X-API-Key": "test-project"},
    )

    # Get messages
    response = await test_app.get(
        f"/api/v1/conversations/{conversation_id}/messages",
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 200
    messages = response.json()
    assert len(messages) == 4

    # Test pagination
    response = await test_app.get(
        f"/api/v1/conversations/{conversation_id}/messages?limit=2&offset=1",
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 200
    messages = response.json()
    assert len(messages) == 2
    assert messages[0]["content"] == "Reply 1"


@pytest.mark.asyncio
async def test_conversation_stats_update(llmring_db):
    """Test that conversation stats are updated automatically."""
    from llmring_server.config import Settings

    settings = Settings()
    service = ConversationService(llmring_db, settings)

    # Create conversation
    conversation_data = ConversationCreate(
        api_key_id="test-key",  # Set consistent api_key_id
        title="Stats Test",
        model_alias="default",
    )
    conversation = await service.create_conversation(conversation_data)
    assert conversation is not None

    # Add messages with token counts
    batch = MessageBatch(
        conversation_id=conversation.id,
        messages=[
            MessageCreate(
                role="user",
                content="Hello",
            ),
            MessageCreate(
                role="assistant",
                content="Hi!",
                input_tokens=10,
                output_tokens=5,
            ),
        ],
        logging_level="full",
    )
    await service.add_messages_batch(batch)

    # Get updated conversation
    updated = await service.get_conversation(conversation.id, "test-key")
    assert updated is not None
    assert updated.message_count == 2
    assert updated.total_input_tokens == 10
    assert updated.total_output_tokens == 5


@pytest.mark.asyncio
async def test_conversation_requires_auth(test_app):
    """Test that conversation endpoints require authentication."""
    # Try without header
    response = await test_app.post(
        "/api/v1/conversations/",
        json={
            "title": "No Auth",
            "model_alias": "default",
        },
    )
    assert response.status_code == 401

    # Try with empty header
    response = await test_app.post(
        "/api/v1/conversations/",
        json={
            "title": "Empty Auth",
            "model_alias": "default",
        },
        headers={"X-API-Key": ""},
    )
    assert response.status_code == 401

    # Try with whitespace in key
    response = await test_app.post(
        "/api/v1/conversations/",
        json={
            "title": "Bad Auth",
            "model_alias": "default",
        },
        headers={"X-API-Key": "has spaces"},
    )
    assert response.status_code == 400


# =====================================================
# Conversation Logging Endpoint Tests (Phase 6)
# =====================================================


@pytest.mark.asyncio
async def test_log_conversation_full(test_app):
    """Test logging a full conversation with messages and response."""
    log_request = {
        "messages": [{"role": "user", "content": "What is the capital of France?"}],
        "response": {
            "content": "The capital of France is Paris.",
            "model": "gpt-4o",
            "finish_reason": "stop",
            "usage": {
                "prompt_tokens": 10,
                "completion_tokens": 8,
                "total_tokens": 18,
            },
        },
        "metadata": {
            "provider": "openai",
            "model": "gpt-4o",
            "alias": "deep",
            "profile": "default",
            "origin": "llmring-decorator",
            "cost": 0.000054,
            "input_cost": 0.00003,
            "output_cost": 0.000024,
            "input_tokens": 10,
            "output_tokens": 8,
            "cached_tokens": 0,
        },
    }

    response = await test_app.post(
        "/api/v1/conversations/log",
        json=log_request,
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 200
    data = response.json()

    # Verify response structure
    assert "conversation_id" in data
    assert "message_id" in data

    conversation_id = data["conversation_id"]

    # Verify conversation was created
    conv_response = await test_app.get(
        f"/api/v1/conversations/{conversation_id}",
        headers={"X-API-Key": "test-project"},
    )

    assert conv_response.status_code == 200
    conv_data = conv_response.json()

    # Check conversation metadata
    assert "deep" in conv_data["model_alias"] or "openai:gpt-4o" in conv_data["model_alias"]
    assert conv_data["message_count"] == 2  # User message + assistant response
    assert conv_data["total_input_tokens"] == 10
    assert conv_data["total_output_tokens"] == 8
    # Cost should be automatically calculated
    assert conv_data["total_cost"] > 0  # Should have cost

    # Check messages were stored
    assert len(conv_data["messages"]) == 2
    user_msg = conv_data["messages"][0]
    assert user_msg["role"] == "user"
    assert user_msg["content"] == "What is the capital of France?"

    assistant_msg = conv_data["messages"][1]
    assert assistant_msg["role"] == "assistant"
    assert assistant_msg["content"] == "The capital of France is Paris."
    assert assistant_msg["input_tokens"] == 10
    assert assistant_msg["output_tokens"] == 8


@pytest.mark.asyncio
async def test_log_conversation_with_multiple_messages(test_app):
    """Test logging a conversation with multiple input messages."""
    log_request = {
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Hello"},
            {"role": "assistant", "content": "Hi! How can I help?"},
            {"role": "user", "content": "What's 2+2?"},
        ],
        "response": {
            "content": "2 + 2 equals 4.",
            "model": "claude-3-haiku-20240307",
            "finish_reason": "end_turn",
            "usage": {
                "prompt_tokens": 25,
                "completion_tokens": 10,
                "total_tokens": 35,
            },
        },
        "metadata": {
            "provider": "anthropic",
            "model": "claude-3-haiku-20240307",
            "alias": "low_cost",
            "origin": "llmring",
            "input_tokens": 25,
            "output_tokens": 10,
            "cost": 0.000025,
        },
    }

    response = await test_app.post(
        "/api/v1/conversations/log",
        json=log_request,
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 200
    data = response.json()
    conversation_id = data["conversation_id"]

    # Verify all messages were stored
    conv_response = await test_app.get(
        f"/api/v1/conversations/{conversation_id}",
        headers={"X-API-Key": "test-project"},
    )

    conv_data = conv_response.json()
    assert conv_data["message_count"] == 5  # 4 input + 1 response
    assert len(conv_data["messages"]) == 5

    # Verify message order and roles
    assert conv_data["messages"][0]["role"] == "system"
    assert conv_data["messages"][1]["role"] == "user"
    assert conv_data["messages"][2]["role"] == "assistant"
    assert conv_data["messages"][3]["role"] == "user"
    assert conv_data["messages"][4]["role"] == "assistant"
    assert conv_data["messages"][4]["content"] == "2 + 2 equals 4."


@pytest.mark.asyncio
async def test_log_conversation_without_alias(test_app):
    """Test logging conversation when no alias is provided."""
    log_request = {
        "messages": [{"role": "user", "content": "Test message"}],
        "response": {
            "content": "Test response",
            "model": "gemini-pro",
            "finish_reason": "STOP",
            "usage": {
                "prompt_tokens": 5,
                "completion_tokens": 5,
                "total_tokens": 10,
            },
        },
        "metadata": {
            "provider": "google",
            "model": "gemini-pro",
            # No alias provided
            "origin": "test",
            "input_tokens": 5,
            "output_tokens": 5,
        },
    }

    response = await test_app.post(
        "/api/v1/conversations/log",
        json=log_request,
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 200
    data = response.json()

    # Verify conversation uses provider:model as fallback
    conv_response = await test_app.get(
        f"/api/v1/conversations/{data['conversation_id']}",
        headers={"X-API-Key": "test-project"},
    )

    conv_data = conv_response.json()
    assert "google:gemini-pro" in conv_data["model_alias"]


@pytest.mark.asyncio
async def test_log_conversation_with_tool_calls(test_app):
    """Test logging conversation with tool calls."""
    log_request = {
        "messages": [{"role": "user", "content": "What's the weather?"}],
        "response": {
            "content": "Let me check the weather for you.",
            "model": "gpt-4o",
            "finish_reason": "tool_calls",
            "usage": {
                "prompt_tokens": 20,
                "completion_tokens": 15,
                "total_tokens": 35,
            },
            "tool_calls": [
                {
                    "id": "call_123",
                    "type": "function",
                    "function": {
                        "name": "get_weather",
                        "arguments": '{"location": "San Francisco"}',
                    },
                }
            ],
        },
        "metadata": {
            "provider": "openai",
            "model": "gpt-4o",
            "alias": "deep",
            "input_tokens": 20,
            "output_tokens": 15,
            "cost": 0.0001,
        },
    }

    response = await test_app.post(
        "/api/v1/conversations/log",
        json=log_request,
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 200
    data = response.json()

    # Verify tool calls were stored
    conv_response = await test_app.get(
        f"/api/v1/conversations/{data['conversation_id']}",
        headers={"X-API-Key": "test-project"},
    )

    conv_data = conv_response.json()
    assistant_msg = conv_data["messages"][1]
    assert assistant_msg["tool_calls"] is not None
    assert len(assistant_msg["tool_calls"]) == 1
    assert assistant_msg["tool_calls"][0]["function"]["name"] == "get_weather"


@pytest.mark.asyncio
async def test_log_conversation_tracking_disabled(test_app, monkeypatch):
    """Test that logging fails when conversation tracking is disabled."""
    # This would require mocking settings, which depends on the app setup
    # For now, we'll test that the endpoint exists and returns proper errors

    log_request = {
        "messages": [{"role": "user", "content": "Test"}],
        "response": {
            "content": "Response",
            "model": "gpt-4o",
            "finish_reason": "stop",
            "usage": {"prompt_tokens": 1, "completion_tokens": 1, "total_tokens": 2},
        },
        "metadata": {
            "provider": "openai",
            "model": "gpt-4o",
            "input_tokens": 1,
            "output_tokens": 1,
        },
    }

    # This test assumes conversation tracking is enabled
    response = await test_app.post(
        "/api/v1/conversations/log",
        json=log_request,
        headers={"X-API-Key": "test-project"},
    )

    # Should succeed when tracking is enabled
    assert response.status_code == 200


@pytest.mark.asyncio
async def test_log_conversation_missing_auth(test_app):
    """Test that logging requires authentication."""
    log_request = {
        "messages": [{"role": "user", "content": "Test"}],
        "response": {
            "content": "Response",
            "model": "gpt-4o",
            "finish_reason": "stop",
            "usage": {"prompt_tokens": 1, "completion_tokens": 1, "total_tokens": 2},
        },
        "metadata": {
            "provider": "openai",
            "model": "gpt-4o",
            "input_tokens": 1,
            "output_tokens": 1,
        },
    }

    # No X-API-Key header
    response = await test_app.post(
        "/api/v1/conversations/log",
        json=log_request,
    )

    assert response.status_code == 401


@pytest.mark.asyncio
async def test_log_conversation_validates_schema(test_app):
    """Test that the endpoint validates the request schema."""
    # Missing required fields
    invalid_request = {
        "messages": [{"role": "user", "content": "Test"}],
        # Missing response and metadata
    }

    response = await test_app.post(
        "/api/v1/conversations/log",
        json=invalid_request,
        headers={"X-API-Key": "test-project"},
    )

    assert response.status_code == 422  # Validation error
