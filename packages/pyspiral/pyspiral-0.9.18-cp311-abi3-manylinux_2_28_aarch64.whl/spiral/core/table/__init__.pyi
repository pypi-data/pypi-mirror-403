from typing import Any

import pyarrow as pa
from spiral.core.client import Shard, ShuffleConfig

from .manifests import FragmentManifest
from .metastore import PyMetastore
from .spec import ColumnGroup, Key, Operation, Schema, WriteAheadLog

class KeyRange:
    """A right-exclusive range of keys."""

    def __init__(self, *, begin: Key, end: Key): ...

    begin: Key
    end: Key

    def union(self, other: KeyRange) -> KeyRange: ...
    def __or__(self, other: KeyRange) -> KeyRange: ...
    def intersection(self, key_extent: KeyRange) -> KeyRange | None: ...
    def __and__(self, other: KeyRange) -> KeyRange | None: ...
    def contains(self, item: Key) -> bool: ...
    def __contains__(self, item: Key) -> bool: ...
    def is_disjoint(self, key_range: KeyRange) -> bool:
        return self.end <= key_range.begin or self.begin >= key_range.end

    @staticmethod
    def beginning_with(begin: Key) -> KeyRange: ...
    @staticmethod
    def ending_with(end: Key) -> KeyRange: ...
    @staticmethod
    def full() -> KeyRange: ...
    def __reduce__(self) -> tuple[type[KeyRange], tuple[Key, Key]]: ...

class Table:
    def __init__(self, metastore: PyMetastore): ...

    id: str
    root_uri: str
    mount_id: str | None
    key_schema: Schema
    metastore: PyMetastore

    def get_wal(self, *, asof: int | None) -> WriteAheadLog: ...
    def get_schema(self, *, asof: int | None) -> Schema: ...
    def get_snapshot(self, *, asof: int | None) -> Snapshot: ...
    def key(self, key_parts: list) -> Key: ...

class Snapshot:
    """A snapshot of a table at a specific point in time."""

    asof: int
    table: Table
    wal: WriteAheadLog

    def column_groups(self) -> list[ColumnGroup]: ...

class ScanContext:
    def to_bytes_compressed(self) -> bytes: ...
    @staticmethod
    def from_bytes_compressed(compressed: bytes) -> ScanContext: ...
    def to_json(self) -> str: ...
    @staticmethod
    def from_json(json_str: str) -> ScanContext: ...

class MaterializablePlan:
    pass

class EvaluatedExecutablePlan:
    pass

class EvaluatedPlanStream:
    def __next__(self) -> tuple[pa.RecordBatch, EvaluatedExecutablePlan]: ...
    def __iter__(self) -> EvaluatedPlanStream: ...

class Scan:
    def key_schema(self) -> Schema: ...
    def schema(self) -> Schema: ...
    def is_empty(self) -> bool: ...
    def shards(self) -> list[Shard]: ...
    def table_ids(self) -> list[str]: ...
    def context(self) -> ScanContext: ...
    def column_groups(self) -> list[ColumnGroup]: ...
    def key_space_manifest(self, table_id: str) -> FragmentManifest:
        """
        Manifest of the key fragments for the given table id.
        """
        ...
    def column_group_manifest(self, column_group: ColumnGroup) -> FragmentManifest:
        """
        Manifest of the fragments for the given column group.
        """
        ...
    def plan_context(self) -> ScanContext: ...
    def materializable_plan(self) -> MaterializablePlan: ...
    def to_record_batches(
        self,
        *,
        shards: list[Shard] | None = None,
        key_table: pa.Table | pa.RecordBatchReader | None = None,
        batch_readahead: int | None = None,
        batch_aligned: bool = False,
        hide_progress_bar: bool = False,
    ) -> pa.RecordBatchReader: ...
    def to_unordered_record_batches(
        self,
        *,
        shards: list[Shard] | None = None,
        key_table: pa.Table | pa.RecordBatchReader | None = None,
        batch_readahead: int | None = None,
        hide_progress_bar: bool = False,
    ) -> pa.RecordBatchReader: ...
    def to_shuffled_record_batches(
        self,
        *,
        shards: list[Shard] | None = None,
        shuffle: ShuffleConfig | None = None,
        max_batch_size: int | None = None,
        batch_readahead: int | None = None,
        infinite: bool = False,
    ) -> pa.RecordBatchReader:
        # If `infinite` is True, shards are shuffled after exhausted but not before the first pass.
        # Otherwise, shards are not shuffle and shuffle config is only used for shuffle buffer.
        ...
    def evaluate_analyze(
        self,
        *,
        shards: list[Shard] | None = None,
        key_table: pa.Table | pa.RecordBatch | None = None,
        batch_readahead: int | None = None,
    ) -> EvaluatedPlanStream: ...
    def metrics(self) -> dict[str, Any]: ...

class Transaction:
    status: str

    def write(self, table: pa.RecordBatchReader): ...
    def write_push_down(self, table: pa.RecordBatchReader): ...
    def writeback(self, scan: Scan, *, shards: list[Shard] | None = None): ...
    def drop_columns(self, column_paths: list[str]): ...
    def compact_key_space(self): ...
    def ops(self) -> list[Operation]: ...
    def take(self) -> list[Operation]: ...
    def include(self, ops: list[Operation]): ...
    def commit(self): ...
    def abort(self): ...
    def is_empty(self) -> bool: ...
    def snapshot(self) -> Snapshot: ...
