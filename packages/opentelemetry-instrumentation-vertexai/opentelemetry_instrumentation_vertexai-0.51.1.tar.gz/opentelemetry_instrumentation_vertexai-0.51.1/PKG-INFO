Metadata-Version: 2.4
Name: opentelemetry-instrumentation-vertexai
Version: 0.51.1
Summary: OpenTelemetry Vertex AI instrumentation
Project-URL: Repository, https://github.com/traceloop/openllmetry/tree/main/packages/opentelemetry-instrumentation-vertexai
Author-email: Gal Kleinman <gal@traceloop.com>, Nir Gazit <nir@traceloop.com>, Tomer Friedman <tomer@traceloop.com>, Swaroop <maddisaiswaroop@gmail.com>
License-Expression: Apache-2.0
Requires-Python: <4,>=3.10
Requires-Dist: opentelemetry-api<2,>=1.38.0
Requires-Dist: opentelemetry-instrumentation>=0.59b0
Requires-Dist: opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.13
Requires-Dist: opentelemetry-semantic-conventions>=0.59b0
Provides-Extra: instruments
Requires-Dist: google-cloud-aiplatform; extra == 'instruments'
Description-Content-Type: text/markdown

# OpenTelemetry VertexAI Instrumentation

<a href="https://pypi.org/project/opentelemetry-instrumentation-vertexai/">
    <img src="https://badge.fury.io/py/opentelemetry-instrumentation-vertexai.svg">
</a>

This library allows tracing VertexAI prompts and completions sent with the official [VertexAI library](https://github.com/googleapis/python-aiplatform).

## Installation

```bash
pip install opentelemetry-instrumentation-vertexai
```

## Example usage

```python
from opentelemetry.instrumentation.vertexai import VertexAIInstrumentor

VertexAIInstrumentor().instrument()
```

## Privacy

**By default, this instrumentation logs prompts, completions, and embeddings to span attributes**. This gives you a clear visibility into how your LLM application is working, and can make it easy to debug and evaluate the quality of the outputs.

However, you may want to disable this logging for privacy reasons, as they may contain highly sensitive data from your users. You may also simply want to reduce the size of your traces.

To disable logging, set the `TRACELOOP_TRACE_CONTENT` environment variable to `false`.

```bash
TRACELOOP_TRACE_CONTENT=false
```
