#  -*- coding: utf-8 -*-
#
#  Copyright Featrix, Inc 2023-2025
#
#  Proprietary and Confidential.  Unauthorized use, copying or dissemination
#  of these materials is strictly prohibited.
#
"""
I/O utilities for loading and saving EmbeddingSpace objects.
Consolidated from multiple locations to provide a single source of truth.
"""
import io
import os
import pickle
import sys
import time
import traceback
import logging
import pandas as pd
from pathlib import Path
from featrix.neural.embedding_space_utils import find_embedding_space_pickle, get_embedding_space_pickle_filename

try:
    import torch
except ImportError:
    torch = None

logger = logging.getLogger(__name__)

try:
    from featrix.neural.gpu_utils import (
        is_gpu_available,
        is_cuda_available,
        get_gpu_memory_allocated,
        get_gpu_memory_reserved,
        get_max_gpu_memory_allocated,
        get_max_gpu_memory_reserved,
        get_gpu_memory_summary,
        get_gpu_memory_snapshot,
        get_gpu_device_properties,
        empty_gpu_cache,
        ipc_collect_gpu,
        reset_gpu_peak_memory_stats,
        reset_gpu_accumulated_memory_stats,
    )
except ImportError as e:
    # DO NOT SILENTLY SWALLOW THIS - log the actual error so we know why import failed
    import warnings
    warnings.warn(f"‚ùå CRITICAL: Failed to import gpu_utils: {e}. Using fallback GPU functions.", stacklevel=2)
    print(f"‚ùå CRITICAL: io_utils.py failed to import gpu_utils: {e}")
    
    # Fallback if gpu_utils not available
    def is_gpu_available():
        try:
            import torch
            # Check both CUDA and MPS (Apple Silicon)
            return torch.cuda.is_available() or torch.backends.mps.is_available()
        except ImportError:
            return False
    def is_cuda_available():
        try:
            import torch
            return torch.cuda.is_available()
        except ImportError:
            return False
    def get_gpu_memory_allocated():
        return 0.0
    def get_gpu_memory_reserved():
        return 0.0
    def get_max_gpu_memory_allocated():
        return 0.0
    def get_max_gpu_memory_reserved():
        return 0.0
    def get_gpu_memory_summary(*args, **kwargs):
        return ""
    def get_gpu_memory_snapshot():
        return {}
    def get_gpu_device_properties(*args, **kwargs):
        return {}
    def empty_gpu_cache():
        pass
    def ipc_collect_gpu():
        pass
    def reset_gpu_peak_memory_stats():
        pass
    def reset_gpu_accumulated_memory_stats():
        pass


# ==============================================================================
# Disk Space Monitoring and Cleanup
# ==============================================================================

def get_disk_space_gb(path: str) -> tuple[float, float, float]:
    """
    Get disk space info for the filesystem containing the given path.

    Returns:
        tuple: (free_gb, used_gb, total_gb)
    """
    import shutil
    try:
        path = str(path)
        # Get the parent directory if path doesn't exist yet
        check_path = Path(path)
        while not check_path.exists() and check_path.parent != check_path:
            check_path = check_path.parent

        usage = shutil.disk_usage(str(check_path))
        return (
            usage.free / (1024**3),
            usage.used / (1024**3),
            usage.total / (1024**3)
        )
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  Could not get disk space for {path}: {e}")
        return (0.0, 0.0, 0.0)


def check_disk_space(path: str, min_gb: float = 2.0) -> tuple[bool, float]:
    """
    Check if there's enough disk space before writing a file.

    Args:
        path: Path where file will be written
        min_gb: Minimum required free space in GB (default: 2.0)

    Returns:
        tuple: (has_space, free_gb)
    """
    free_gb, _, _ = get_disk_space_gb(path)
    return (free_gb >= min_gb, free_gb)


def find_epoch_checkpoints(checkpoint_dir: str, exclude_best: bool = True) -> list[tuple[Path, int, float]]:
    """
    Find all epoch checkpoint files in a directory.

    Args:
        checkpoint_dir: Directory containing checkpoints
        exclude_best: If True, exclude 'best' checkpoints from results

    Returns:
        List of (path, epoch_num, size_mb) sorted by epoch (oldest first)
    """
    checkpoint_dir = Path(checkpoint_dir)
    if not checkpoint_dir.exists():
        return []

    checkpoints = []

    # Match patterns: *_e-{epoch}.pth, *_e-{epoch}.pt, *_e-{epoch}_b-{batch}.pth
    import re
    epoch_pattern = re.compile(r'_e-(\d+)(?:_b-\d+)?\.(?:pth?|pt)$')

    for f in checkpoint_dir.iterdir():
        if not f.is_file():
            continue

        # Skip best checkpoints
        if exclude_best and 'best' in f.name.lower():
            continue

        match = epoch_pattern.search(f.name)
        if match:
            epoch_num = int(match.group(1))
            size_mb = f.stat().st_size / (1024**2)
            checkpoints.append((f, epoch_num, size_mb))

    # Sort by epoch number (oldest first for deletion)
    checkpoints.sort(key=lambda x: x[1])
    return checkpoints


def cleanup_old_checkpoints(checkpoint_dir: str, keep_best: bool = True, keep_latest_n: int = 2,
                           min_free_gb: float = 2.0, dry_run: bool = False) -> tuple[int, float]:
    """
    Delete old checkpoint files to free up disk space.

    Args:
        checkpoint_dir: Directory containing checkpoints
        keep_best: If True, never delete 'best' checkpoints
        keep_latest_n: Keep this many of the most recent epoch checkpoints
        min_free_gb: Target minimum free space in GB
        dry_run: If True, just report what would be deleted without deleting

    Returns:
        tuple: (files_deleted, mb_freed)
    """
    free_gb, _, _ = get_disk_space_gb(checkpoint_dir)

    if free_gb >= min_free_gb:
        return (0, 0.0)

    checkpoints = find_epoch_checkpoints(checkpoint_dir, exclude_best=keep_best)

    if len(checkpoints) <= keep_latest_n:
        logger.warning(f"‚ö†Ô∏è  Only {len(checkpoints)} checkpoints found, keeping all (need at least {keep_latest_n})")
        return (0, 0.0)

    # Delete oldest first, keep latest N
    to_delete = checkpoints[:-keep_latest_n] if keep_latest_n > 0 else checkpoints

    files_deleted = 0
    mb_freed = 0.0

    for filepath, epoch_num, size_mb in to_delete:
        # Check if we've freed enough space
        current_free, _, _ = get_disk_space_gb(checkpoint_dir)
        if current_free >= min_free_gb:
            logger.info(f"‚úÖ Freed enough space ({current_free:.1f} GB free >= {min_free_gb:.1f} GB target)")
            break

        if dry_run:
            logger.info(f"   [DRY RUN] Would delete: {filepath.name} (epoch {epoch_num}, {size_mb:.1f} MB)")
        else:
            try:
                filepath.unlink()
                logger.info(f"   üóëÔ∏è  Deleted: {filepath.name} (epoch {epoch_num}, {size_mb:.1f} MB)")
                files_deleted += 1
                mb_freed += size_mb
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è  Failed to delete {filepath}: {e}")

    return (files_deleted, mb_freed)


def ensure_disk_space_for_save(save_path: str, estimated_size_mb: float = 500.0,
                               min_free_gb: float = 2.0) -> bool:
    """
    Ensure there's enough disk space before saving a file.
    If space is low, attempts to clean up old checkpoints.

    Args:
        save_path: Path where file will be saved
        estimated_size_mb: Estimated size of file to be saved in MB
        min_free_gb: Minimum free space required after save

    Returns:
        bool: True if there's enough space (or space was freed), False if save should be skipped
    """
    save_path = Path(save_path)
    checkpoint_dir = save_path.parent

    # Check current space
    free_gb, used_gb, total_gb = get_disk_space_gb(str(checkpoint_dir))
    estimated_size_gb = estimated_size_mb / 1024
    required_gb = min_free_gb + estimated_size_gb

    if free_gb >= required_gb:
        return True

    logger.warning(f"‚ö†Ô∏è  LOW DISK SPACE: {free_gb:.1f} GB free, need {required_gb:.1f} GB")
    logger.warning(f"   Total: {total_gb:.1f} GB, Used: {used_gb:.1f} GB ({100*used_gb/total_gb:.1f}%)")

    # Try to clean up old checkpoints
    files_deleted, mb_freed = cleanup_old_checkpoints(
        str(checkpoint_dir),
        keep_best=True,
        keep_latest_n=2,
        min_free_gb=required_gb
    )

    if files_deleted > 0:
        logger.info(f"   üßπ Cleaned up {files_deleted} old checkpoints, freed {mb_freed:.1f} MB")

    # Check space again
    free_gb, _, _ = get_disk_space_gb(str(checkpoint_dir))
    if free_gb >= required_gb:
        logger.info(f"   ‚úÖ Now have {free_gb:.1f} GB free, proceeding with save")
        return True
    else:
        logger.error(f"   ‚ùå Still only {free_gb:.1f} GB free after cleanup, need {required_gb:.1f} GB")
        logger.error(f"   ‚ö†Ô∏è  SKIPPING SAVE to prevent disk full error")
        return False


def _safe_torch_load(file_path, map_location='cpu', weights_only=False):
    """
    Wrapper around torch.load.
    
    Previously had NumPy version compatibility patches, but those were removed
    after standardizing NumPy versions across all compute nodes.
    
    Args:
        file_path: Path to the checkpoint file (can be string or Path object)
        map_location: PyTorch map_location parameter (default: 'cpu')
        weights_only: PyTorch weights_only parameter (default: False)
        
    Returns:
        The loaded checkpoint
    """
    return torch.load(str(file_path), map_location=map_location, weights_only=weights_only)


class CPUUnpickler(pickle.Unpickler):
    """
    Custom unpickler that forces all PyTorch tensors to CPU during unpickling.
    
    This handles PyTorch's persistent storage IDs and maps them to CPU device,
    preventing "RuntimeError: Attempting to deserialize object on a CUDA device"
    errors when loading models trained on GPU machines onto CPU-only machines.
    
    Usage:
        with open('model.pkl', 'rb') as f:
            model = CPUUnpickler(f).load()
    """
    def find_class(self, module, name):
        """
        Intercept tensor restoration and force CPU.
        
        When PyTorch Storage objects are unpickled, they call _load_from_bytes
        which internally calls torch.load. We intercept this and force CPU mapping.
        """
        if module == 'torch.storage' and name == '_load_from_bytes':
            # Wrap the _load_from_bytes function to add map_location
            original_load = super().find_class(module, name)
            def load_with_cpu_mapping(b):
                if torch is not None:
                    return torch.load(io.BytesIO(b), map_location='cpu', weights_only=False)
                else:
                    # Fallback if torch not available - just call original
                    return original_load(b)
            return load_with_cpu_mapping
        return super().find_class(module, name)
    
    def persistent_load(self, pid):
        """
        Handle PyTorch's persistent storage IDs.
        
        PyTorch uses persistent IDs for tensors and storage objects.
        We need to ensure they're loaded onto CPU regardless of where they were saved.
        """
        # If there's a parent persistent_load, call it with CPU context
        # This is a no-op for standard pickle but required for PyTorch storage
        try:
            return super().persistent_load(pid)
        except Exception:
            # If super().persistent_load fails, return pid as-is
            # PyTorch's find_class will handle it
            return pid


def _log_gpu_memory(context: str = "", log_level=logging.INFO):
    """Quick GPU memory logging for tracing memory usage."""
    try:
        if torch is None or not is_gpu_available():
            return
        allocated = get_gpu_memory_allocated()  # GB (returns 0.0 for MPS/CPU)
        reserved = get_gpu_memory_reserved()  # GB (returns 0.0 for MPS/CPU)
        max_allocated = get_max_gpu_memory_allocated()  # GB (returns 0.0 for MPS/CPU)
        logger.log(log_level, f"üìä GPU MEMORY [{context}]: Allocated={allocated:.3f} GB, Reserved={reserved:.3f} GB, Peak={max_allocated:.3f} GB")
    except Exception as e:
        logger.debug(f"Could not log GPU memory: {e}")


def dump_cuda_memory_usage(context: str = ""):
    """
    Dump detailed CUDA memory usage information when OOM occurs.
    This helps debug what's holding VRAM.
    
    Args:
        context: Optional context string describing where the OOM occurred
    """
    try:
        if torch is None or not is_gpu_available():
            logger.warning(f"‚ö†Ô∏è  CUDA not available - cannot dump memory usage")
            return
        
        logger.error("="*80)
        logger.error(f"üîç CUDA MEMORY DUMP {f'({context})' if context else ''}")
        logger.error("="*80)
        
        # Get memory stats
        allocated = get_gpu_memory_allocated()  # GB (returns 0.0 for MPS/CPU)
        reserved = get_gpu_memory_reserved()  # GB (returns 0.0 for MPS/CPU)
        max_allocated = get_max_gpu_memory_allocated()  # GB (returns 0.0 for MPS/CPU)
        max_reserved = get_max_gpu_memory_reserved()  # GB (returns 0.0 for MPS/CPU)
        
        logger.error(f"üìä Current Memory Usage:")
        logger.error(f"   Allocated: {allocated:.2f} GB")
        logger.error(f"   Reserved: {reserved:.2f} GB")
        logger.error(f"   Max Allocated (peak): {max_allocated:.2f} GB")
        logger.error(f"   Max Reserved (peak): {max_reserved:.2f} GB")
        
        # Get detailed memory summary
        try:
            memory_summary = get_gpu_memory_summary(abbreviated=False)
            logger.error(f"\nüìã Detailed Memory Summary:")
            logger.error(memory_summary)
        except Exception as summary_err:
            logger.warning(f"‚ö†Ô∏è  Could not get detailed memory summary: {summary_err}")
        
        # Get memory snapshot (shows what tensors are allocated)
        try:
            memory_snapshot = get_gpu_memory_snapshot()
            if memory_snapshot:
                logger.error(f"\nüì∏ Memory Snapshot Analysis:")
                logger.error(f"   Total active allocations: {len(memory_snapshot)}")
                
                # Group allocations by size to identify patterns
                size_buckets = {
                    '<1MB': 0,
                    '1-10MB': 0,
                    '10-100MB': 0,
                    '100MB-1GB': 0,
                    '>1GB': 0
                }
                total_size_by_bucket = {
                    '<1MB': 0,
                    '1-10MB': 0,
                    '10-100MB': 0,
                    '100MB-1GB': 0,
                    '>1GB': 0
                }
                
                # Find largest allocations
                allocations_with_size = []
                for alloc in memory_snapshot:
                    if isinstance(alloc, dict):
                        total_size = alloc.get('total_size', 0)
                        active_size = alloc.get('active_size', 0)
                        size_mb = total_size / (1024**2)
                        
                        # Bucket by size
                        if size_mb < 1:
                            size_buckets['<1MB'] += 1
                            total_size_by_bucket['<1MB'] += total_size
                        elif size_mb < 10:
                            size_buckets['1-10MB'] += 1
                            total_size_by_bucket['1-10MB'] += total_size
                        elif size_mb < 100:
                            size_buckets['10-100MB'] += 1
                            total_size_by_bucket['10-100MB'] += total_size
                        elif size_mb < 1024:
                            size_buckets['100MB-1GB'] += 1
                            total_size_by_bucket['100MB-1GB'] += total_size
                        else:
                            size_buckets['>1GB'] += 1
                            total_size_by_bucket['>1GB'] += total_size
                        
                        # Track for largest allocations
                        if active_size > 0:
                            allocations_with_size.append((active_size, alloc))
                
                # Show size distribution
                logger.error(f"\nüìä Allocation Size Distribution:")
                for bucket, count in size_buckets.items():
                    if count > 0:
                        size_mb = total_size_by_bucket[bucket] / (1024**2)
                        logger.error(f"   {bucket:12s}: {count:6d} allocations, {size_mb:8.2f} MB total")
                
                # Show top 10 largest allocations
                if allocations_with_size:
                    allocations_with_size.sort(reverse=True, key=lambda x: x[0])
                    logger.error(f"\nüîù Top 10 Largest Active Allocations:")
                    for i, (active_size, alloc) in enumerate(allocations_with_size[:10], 1):
                        size_mb = active_size / (1024**2)
                        total_size_mb = alloc.get('total_size', 0) / (1024**2)
                        segment_type = alloc.get('segment_type', 'unknown')
                        logger.error(f"   {i:2d}. {size_mb:8.2f} MB active / {total_size_mb:8.2f} MB total ({segment_type} pool)")
                        # Show frames if available
                        frames = alloc.get('frames', [])
                        if frames:
                            logger.error(f"       Stack trace:")
                            for frame in frames[:3]:  # First 3 frames
                                filename = frame.get('filename', 'unknown')
                                line = frame.get('line', 'unknown')
                                func = frame.get('function', 'unknown')
                                logger.error(f"         {filename}:{line} in {func}")
                
                # Show first 5 allocations with details (for debugging)
                logger.error(f"\nüîç Sample Allocations (first 5):")
                for i, alloc in enumerate(memory_snapshot[:5], 1):
                    if isinstance(alloc, dict):
                        total_size_mb = alloc.get('total_size', 0) / (1024**2)
                        active_size_mb = alloc.get('active_size', 0) / (1024**2)
                        segment_type = alloc.get('segment_type', 'unknown')
                        blocks = alloc.get('blocks', [])
                        active_blocks = [b for b in blocks if b.get('state') == 'active_allocated']
                        logger.error(f"   {i}. {active_size_mb:.2f} MB / {total_size_mb:.2f} MB ({segment_type}, {len(active_blocks)} active blocks)")
                
                if len(memory_snapshot) > 5:
                    logger.error(f"   ... and {len(memory_snapshot) - 5} more allocations")
        except Exception as snapshot_err:
            logger.warning(f"‚ö†Ô∏è  Could not get memory snapshot: {snapshot_err}")
        
        # Get nvidia-smi output for comparison
        try:
            import subprocess
            nvidia_smi = subprocess.run(
                ['nvidia-smi', '--query-gpu=memory.used,memory.total,utilization.gpu', '--format=csv,noheader,nounits'],
                capture_output=True,
                text=True,
                timeout=5
            )
            if nvidia_smi.returncode == 0:
                logger.error(f"\nüñ•Ô∏è  nvidia-smi GPU Status:")
                for line in nvidia_smi.stdout.strip().split('\n'):
                    if line.strip():
                        parts = line.split(',')
                        if len(parts) >= 3:
                            mem_used = parts[0].strip()
                            mem_total = parts[1].strip()
                            gpu_util = parts[2].strip()
                            logger.error(f"   Memory: {mem_used} MB / {mem_total} MB, Utilization: {gpu_util}%")
        except Exception as smi_err:
            logger.warning(f"‚ö†Ô∏è  Could not get nvidia-smi output: {smi_err}")
        
        logger.error("="*80)
        
    except ImportError:
        logger.warning(f"‚ö†Ô∏è  PyTorch not available - cannot dump CUDA memory usage")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  Failed to dump CUDA memory usage: {e}")


def _reconstruct_codecs_from_encoders(encoder, logger=None):
    """
    Attempt to reconstruct col_codecs from individual encoders in ColumnEncoders.
    This is a fallback for old checkpoints that didn't store col_codecs.
    
    Args:
        encoder: FeatrixTableEncoder with column_encoder
        logger: Optional logger instance
    
    Returns:
        dict of col_codecs if successful, None otherwise
    """
    if logger is None:
        logger = logging.getLogger(__name__)
    
    try:
        if not hasattr(encoder, 'column_encoder'):
            return None
        
        column_encoder = encoder.column_encoder
        if not hasattr(column_encoder, 'encoders'):
            return None
        
        # Get col_types from encoder config if available
        col_types = None
        if hasattr(encoder, 'config') and hasattr(encoder.config, 'col_types'):
            col_types = encoder.config.col_types
        
        if not col_types:
            logger.warning(f"   ‚ö†Ô∏è  Cannot reconstruct codecs: col_types not available in encoder.config")
            return None
        
        # Get col_order from column_encoder
        col_order = getattr(column_encoder, 'col_order', [])
        
        reconstructed_codecs = {}
        
        # Iterate through encoders and try to extract codecs
        for col_name in col_order:
            if col_name not in column_encoder.encoders:
                continue
            
            encoder_obj = column_encoder.encoders[col_name]
            col_type = col_types.get(col_name)
            
            if col_type is None:
                logger.warning(f"   ‚ö†Ô∏è  No col_type for {col_name}, skipping codec reconstruction")
                continue
            
            try:
                from featrix.neural.model_config import ColumnType
                
                if col_type == ColumnType.SET:
                    # Try to extract from SetEncoder
                    if hasattr(encoder_obj, 'member_names') and encoder_obj.member_names:
                        from featrix.neural.set_codec import SetCodec
                        # Reconstruct SetCodec from member_names
                        members = set(encoder_obj.member_names)
                        # Get d_model from encoder config
                        d_model = None
                        if hasattr(encoder_obj, 'config') and hasattr(encoder_obj.config, 'd_model'):
                            d_model = encoder_obj.config.d_model
                        elif hasattr(encoder_obj, 'config') and hasattr(encoder_obj.config, 'd_out'):
                            d_model = encoder_obj.config.d_out
                        if not d_model and hasattr(encoder, 'config'):
                            d_model = encoder.config.d_model
                        if d_model:
                            # Get string_cache if available
                            string_cache = None
                            if hasattr(encoder_obj, '_string_cache_filename') and encoder_obj._string_cache_filename:
                                from featrix.neural.string_codec import get_global_string_cache
                                string_cache = get_global_string_cache(
                                    cache_filename=encoder_obj._string_cache_filename,
                                    initial_values=[],
                                    debug_name=col_name
                                )
                            codec = SetCodec(members=members, enc_dim=d_model, string_cache=string_cache)
                            reconstructed_codecs[col_name] = codec
                            logger.info(f"   ‚úÖ Reconstructed SetCodec for '{col_name}' from {len(members)} members")
                
                elif col_type == ColumnType.SCALAR:
                    # Try to extract from AdaptiveScalarEncoder
                    if hasattr(encoder_obj, 'stats') and encoder_obj.stats:
                        from featrix.neural.scalar_codec import ScalarCodec
                        # Reconstruct ScalarCodec from stats
                        d_model = getattr(encoder_obj, 'd_model', None)
                        if not d_model and hasattr(encoder, 'config'):
                            d_model = encoder.config.d_model
                        if d_model:
                            codec = ScalarCodec(stats=encoder_obj.stats, enc_dim=d_model)
                            reconstructed_codecs[col_name] = codec
                            logger.info(f"   ‚úÖ Reconstructed ScalarCodec for '{col_name}' from stats")
                
                elif col_type == ColumnType.TIMESTAMP:
                    # TimestampCodec doesn't need special reconstruction - create minimal one
                    from featrix.neural.timestamp_codec import TimestampCodec
                    d_model = getattr(encoder_obj, 'd_model', None)
                    if not d_model and hasattr(encoder, 'config'):
                        d_model = encoder.config.d_model
                    if d_model:
                        codec = TimestampCodec(enc_dim=d_model)
                        reconstructed_codecs[col_name] = codec
                        logger.info(f"   ‚úÖ Reconstructed TimestampCodec for '{col_name}'")
                
                elif col_type == ColumnType.FREE_STRING:
                    # StringCodec doesn't need special reconstruction
                    from featrix.neural.string_codec import StringCodec
                    d_model = getattr(encoder_obj, 'd_model', None)
                    if not d_model and hasattr(encoder, 'config'):
                        d_model = encoder.config.d_model
                    if d_model:
                        codec = StringCodec(enc_dim=d_model)
                        reconstructed_codecs[col_name] = codec
                        logger.info(f"   ‚úÖ Reconstructed StringCodec for '{col_name}'")
                
                elif col_type == ColumnType.JSON:
                    # JsonEncoder has codec directly
                    if hasattr(encoder_obj, 'codec') and encoder_obj.codec:
                        reconstructed_codecs[col_name] = encoder_obj.codec
                        logger.info(f"   ‚úÖ Extracted JsonCodec for '{col_name}' from encoder")
                
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è  Failed to reconstruct codec for '{col_name}': {e}")
                continue
        
        if reconstructed_codecs:
            logger.info(f"   ‚úÖ Successfully reconstructed {len(reconstructed_codecs)} codecs from individual encoders")
            return reconstructed_codecs
        else:
            logger.warning(f"   ‚ö†Ô∏è  Could not reconstruct any codecs from individual encoders")
            return None
    
    except Exception as e:
        logger.warning(f"   ‚ö†Ô∏è  Exception during codec reconstruction: {e}")
        return None


def _reconstruct_es_from_checkpoint_dict(checkpoint_dict: dict, es_path: str, logger=None, skip_datasets: bool = False):
    """
    Reconstruct an EmbeddingSpace from a checkpoint dict (OLD FORMAT - for backwards compatibility).
    
    Args:
        checkpoint_dict: Dictionary containing 'model' key with the encoder
        es_path: Path to the checkpoint file (used to extract session_id)
        logger: Optional logger instance
        skip_datasets: If True, create minimal datasets (for SP training)
    
    Returns:
        Reconstructed EmbeddingSpace object
    
    Raises:
        Various exceptions if reconstruction fails
    """
    if logger is None:
        logger = logging.getLogger(__name__)

    # NEW FORMAT: Inference checkpoint with 'encoder' key (has full encoder object + col_codecs)
    if 'encoder' in checkpoint_dict and 'col_codecs' in checkpoint_dict:
        logger.info(f"‚úÖ Inference checkpoint format detected - restoring ES directly")

        from featrix.neural.embedded_space import EmbeddingSpace
        from featrix.neural.input_data_set import FeatrixInputDataSet

        # Create minimal ES shell
        dummy_df = pd.DataFrame()
        dummy_dataset = FeatrixInputDataSet(df=dummy_df, ignore_cols=[], standup_only=True)

        d_model = checkpoint_dict.get('d_model', 128)
        es = EmbeddingSpace(
            train_input_data=dummy_dataset,
            val_input_data=dummy_dataset,
            d_model=d_model,
            skip_pca_init=True,
        )

        # Restore from inference checkpoint
        es.encoder = checkpoint_dict['encoder']
        es.col_codecs = checkpoint_dict['col_codecs']
        es.col_order = checkpoint_dict.get('col_order', [])
        es.column_spec = checkpoint_dict.get('column_spec', {})
        es.d_model = d_model
        es.json_transformations = checkpoint_dict.get('json_transformations', {})
        es.required_child_es_mapping = checkpoint_dict.get('required_child_es_mapping', {})
        es.availableColumns = list(es.col_codecs.keys()) if es.col_codecs else []
        es.schema_history = checkpoint_dict.get('schema_history', [])

        # Restore customer quality trackers if present
        if 'customer_quality_trackers' in checkpoint_dict and checkpoint_dict['customer_quality_trackers']:
            from featrix.neural.customer_quality_tracker import CustomerQualityTracker
            es.customer_quality_trackers = {
                int(epoch): CustomerQualityTracker.from_dict(qt_dict)
                for epoch, qt_dict in checkpoint_dict['customer_quality_trackers'].items()
            }
        else:
            es.customer_quality_trackers = {}

        logger.info(f"‚úÖ ES restored from inference checkpoint (d_model={es.d_model}, {len(es.availableColumns)} columns, {len(es.col_codecs)} codecs)")

        # Set models to eval mode for inference
        try:
            if hasattr(es, 'encoder') and es.encoder is not None:
                es.encoder.eval()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Could not set encoder to eval mode: {e}")

        return es

    # OLD FORMAT: Check if it's a valid checkpoint dict with 'model' key
    if 'model' not in checkpoint_dict:
        raise TypeError(
            f"Loaded a dict from {es_path}, but it doesn't contain a 'model' or 'encoder' key. "
            f"This doesn't appear to be a valid checkpoint dict. Dict keys: {list(checkpoint_dict.keys())}"
        )
    
    # Extract session_id - try multiple strategies
    es_path_obj = Path(es_path)
    es_dir = es_path_obj.parent
    path_parts = es_path_obj.parts
    session_id = None
    
    # Strategy 1: Check for metadata.json in same directory
    metadata_json = es_dir / "metadata.json"
    if metadata_json.exists():
        try:
            import json
            with open(metadata_json, 'r') as f:
                metadata = json.load(f)
            session_id = metadata.get('model_info', {}).get('session_id')
            if session_id:
                logger.info(f"‚úÖ Found session_id in metadata.json: {session_id}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Could not read session_id from metadata.json: {e}")
    
    # Strategy 2: Check if checkpoint_dict itself contains es_config with session_id
    checkpoint_has_full_config = False
    if not session_id and 'es_config' in checkpoint_dict:
        session_id = checkpoint_dict['es_config'].get('session_id')
        if session_id:
            logger.info(f"‚úÖ Found session_id in checkpoint es_config: {session_id}")
        # Check if checkpoint also has input_data - if so, it's fully self-contained
        if 'input_data' in checkpoint_dict and checkpoint_dict['input_data'].get('path'):
            checkpoint_has_full_config = True
            logger.info(f"‚úÖ Checkpoint is self-contained (has es_config + input_data)")
    
    # Strategy 3: Extract from path for 'train_es' directories
    if not session_id and 'train_es' in path_parts:
        train_es_idx = path_parts.index('train_es')
        if train_es_idx > 0:
            session_id = path_parts[train_es_idx - 1]
            logger.info(f"‚úÖ Extracted session_id from train_es path: {session_id}")
    
    # Strategy 4: Try to extract from featrix_output path
    if not session_id and 'featrix_output' in path_parts:
        featrix_idx = path_parts.index('featrix_output')
        if featrix_idx + 1 < len(path_parts):
            session_id = path_parts[featrix_idx + 1]
            logger.info(f"‚úÖ Extracted session_id from featrix_output path: {session_id}")
    
    if not session_id:
        raise ValueError(
            f"Could not extract session_id from checkpoint, metadata.json, or path: {es_path}. "
            f"Path parts: {path_parts}. "
            f"Tried: metadata.json, checkpoint es_config, path parsing"
        )
    
    logger.info(f"üîç Extracted session_id from path: {session_id}")
    
    # If checkpoint has full config (es_config + input_data), use it directly without loading session
    if checkpoint_has_full_config:
        logger.info(f"‚úÖ Using self-contained checkpoint data (no session file needed)")
        input_data_info = checkpoint_dict['input_data']
        input_data_path = Path(input_data_info['path']) if input_data_info.get('path') else None
        column_spec = input_data_info.get('column_spec', {})
        column_overrides = input_data_info.get('column_overrides', {})
        json_transformations = input_data_info.get('json_transformations', {})
        string_cache_path = input_data_info.get('string_cache')
        
        logger.info(f"   Input data: {input_data_path}")
        logger.info(f"   Columns: {len(column_spec)}")
        logger.info(f"   Column overrides: {len(column_overrides)}")
        
        # Skip session loading - use checkpoint data directly
        session = None
    else:
        # Load session to get configuration (old checkpoints without full config)
        logger.info(f"üîç Loading session {session_id} (checkpoint doesn't have full config)...")
        try:
            from lib.session_manager import load_session
            session = load_session(session_id)
        except Exception as e:
            logger.error(f"‚ùå RECONSTRUCTION FAILED: Exception loading session {session_id}")
            logger.error(f"   Exception type: {type(e).__name__}")
            logger.error(f"   Exception message: {e}")
            logger.error(f"   Full traceback:\n{traceback.format_exc()}")
            raise
        
        if not session:
            raise ValueError(f"Session {session_id} not found - cannot reconstruct EmbeddingSpace from checkpoint")
        
        # Get config from session
        column_overrides = session.get('column_overrides', {})
        json_transformations = session.get('json_transformations', {})
        string_cache_path = session.get('strings_cache')
        input_data_path = None
    
    # Get input data path - from checkpoint (if self-contained) or session
    if not checkpoint_has_full_config:
        # Get from session
        sqlite_db_path = session.get('sqlite_db')
    else:
        sqlite_db_path = None  # Already set input_data_path above from checkpoint
    
    if sqlite_db_path and not input_data_path:
        sqlite_db = Path(sqlite_db_path)
        if sqlite_db.exists():
            input_data_path = sqlite_db
            logger.info(f"‚úÖ Found SQLite database from session: {input_data_path}")
    
    # Fallback to input_data field from session (if session exists)
    if not input_data_path and session:
        original_path = session.get('input_data') or session.get('input_filename')
        if original_path:
            input_data_path = Path(original_path)
            if not input_data_path.exists():
                # Try in data_dir
                try:
                    from config import config
                    if hasattr(config, 'data_dir'):
                        input_data_path = Path(config.data_dir) / Path(original_path).name
                except ImportError:
                    pass
            if input_data_path.exists():
                logger.info(f"‚úÖ Found input data: {input_data_path}")
    
    if not skip_datasets and (not input_data_path or not input_data_path.exists()):
        tried_paths = f"sqlite_db: {sqlite_db_path if 'sqlite_db_path' in locals() else 'N/A'}"
        if session:
            tried_paths += f", input_data: {session.get('input_data')}, input_filename: {session.get('input_filename')}"
        raise FileNotFoundError(
            f"Could not find input data file for session {session_id}. "
            f"Tried {tried_paths}"
        )
    
    # Load input data and create datasets (or create dummy datasets if skipping)
    # NOTE: When skip_datasets=True (for SP training), we'll try to extract col_codecs from the encoder
    # after loading it, rather than forcing data file loading. This allows SP training to work even
    # when the original data file is missing or corrupted.
    if skip_datasets:
        # Check if checkpoint has col_codecs at top level - if not, we'll try extracting from encoder later
        if 'col_codecs' in checkpoint_dict:
            if not checkpoint_dict['col_codecs'] or len(checkpoint_dict['col_codecs']) == 0:
                logger.info(f"‚ÑπÔ∏è  Checkpoint has EMPTY col_codecs - will try to extract from encoder after loading")
        else:
            logger.info(f"‚ÑπÔ∏è  Checkpoint missing col_codecs at top level - will try to extract from encoder after loading")
    
    if skip_datasets:
        logger.info(f"‚è≠Ô∏è  Skipping dataset loading (skip_datasets=True) - creating minimal datasets")
        try:
            from featrix.neural.input_data_set import FeatrixInputDataSet
            # Create minimal dummy dataset
            dummy_df = pd.DataFrame()
            train_dataset = FeatrixInputDataSet(df=dummy_df, ignore_cols=[], standup_only=True)
            val_dataset = FeatrixInputDataSet(df=dummy_df, ignore_cols=[], standup_only=True)
        except Exception as e:
            logger.error(f"‚ùå Failed to create dummy datasets: {e}")
            raise
    else:
        logger.info(f"üîç Loading input data from {input_data_path}...")
        try:
            from featrix.neural.input_data_file import FeatrixInputDataFile
            input_data_file = FeatrixInputDataFile(str(input_data_path))
            train_df = input_data_file.df
        except Exception as e:
            logger.error(f"‚ùå RECONSTRUCTION FAILED: Exception loading input data file {input_data_path}")
            logger.error(f"   Exception type: {type(e).__name__}")
            logger.error(f"   Exception message: {e}")
            logger.error(f"   Full traceback:\n{traceback.format_exc()}")
            raise
        
        try:
            from featrix.neural.input_data_set import FeatrixInputDataSet
            train_dataset = FeatrixInputDataSet(
                df=train_df,
                ignore_cols=[],
                limit_rows=None,
                encoder_overrides=column_overrides,
            )
            val_dataset = FeatrixInputDataSet(
                df=train_df,
                ignore_cols=[],
                limit_rows=None,
                encoder_overrides=column_overrides,
            )
        except Exception as e:
            logger.error(f"‚ùå RECONSTRUCTION FAILED: Exception creating datasets")
            logger.error(f"   Exception type: {type(e).__name__}")
            logger.error(f"   Exception message: {e}")
            logger.error(f"   Full traceback:\n{traceback.format_exc()}")
            raise
    
    # Create EmbeddingSpace from config (checkpoint or session)
    logger.info(f"üîç Creating EmbeddingSpace from {'checkpoint' if checkpoint_has_full_config else 'session'} config...")
    
    # Get additional config from session if available
    n_epochs = session.get('n_epochs') if session else None
    d_model_override = session.get('d_model') if session else None
    version_info = session.get('version_info') if session else None
    name = session.get('name') if session else None
    required_child_es_mapping = session.get('required_child_es_mapping', {}) if session else {}
    sqlite_db_path = session.get('sqlite_db') if session else str(input_data_path) if input_data_path else None
    user_metadata = session.get('user_metadata') if session else None
    
    # For self-contained checkpoints, use es_config d_model
    if checkpoint_has_full_config and 'es_config' in checkpoint_dict:
        d_model_override = checkpoint_dict['es_config'].get('d_model')
    
    try:
        from featrix.neural.embedded_space import EmbeddingSpace
        
        # If checkpoint has col_codecs, use them to get vocabulary overrides
        codec_vocabulary_overrides = {}
        if 'col_codecs' in checkpoint_dict:
            logger.info(f"‚úÖ Checkpoint contains col_codecs - extracting vocabularies...")
            for col_name, codec in checkpoint_dict['col_codecs'].items():
                if hasattr(codec, 'vocab'):
                    codec_vocabulary_overrides[col_name] = set(codec.vocab.keys())
            logger.info(f"   Extracted vocabulary for {len(codec_vocabulary_overrides)} columns")
        
        es = EmbeddingSpace(
            train_input_data=train_dataset,
            val_input_data=val_dataset,
            output_debug_label=f"Reconstructed from {'self-contained ' if checkpoint_has_full_config else ''}checkpoint",
            n_epochs=n_epochs,
            d_model=d_model_override,
            encoder_config=None,
            string_cache=string_cache_path,
            json_transformations=json_transformations,
            version_info=version_info,
            output_dir=str(es_dir),
            name=name,
            required_child_es_mapping=required_child_es_mapping,
            sqlite_db_path=sqlite_db_path,
            user_metadata=user_metadata,
            skip_pca_init=True,  # Skip PCA - model is already trained
            codec_vocabulary_overrides=codec_vocabulary_overrides,  # Use checkpoint vocabularies
        )
    except Exception as e:
        logger.error(f"‚ùå RECONSTRUCTION FAILED: Exception creating EmbeddingSpace")
        logger.error(f"   Exception type: {type(e).__name__}")
        logger.error(f"   Exception message: {e}")
        if session:
            logger.error(f"   Session keys: {list(session.keys())}")
            logger.error(f"   n_epochs: {session.get('n_epochs')}, d_model: {session.get('d_model')}")
        else:
            logger.error(f"   Using self-contained checkpoint (no session)")
        logger.error(f"   Full traceback:\n{traceback.format_exc()}")
        raise
    
    # Load the checkpoint model into EmbeddingSpace
    logger.info(f"üîÑ Loading checkpoint model into EmbeddingSpace...")
    try:
        # Check if checkpoint contains state_dict or full model
        checkpoint_model = checkpoint_dict["model"]
        
        # Restore use_bf16 flag from checkpoint if present
        if 'use_bf16' in checkpoint_dict:
            es.use_bf16 = checkpoint_dict['use_bf16']
            if es.use_bf16:
                logger.info(f"   üîã Restored BF16 setting from checkpoint: {es.use_bf16}")
        
        # If checkpoint has col_codecs, use them directly (replaces what __init__ created)
        if 'col_codecs' in checkpoint_dict and checkpoint_dict['col_codecs']:
            logger.info(f"   Replacing ES col_codecs with checkpoint col_codecs ({len(checkpoint_dict['col_codecs'])} codecs)...")
            es.col_codecs = checkpoint_dict['col_codecs']
        else:
            if 'col_codecs' in checkpoint_dict:
                logger.warning(f"   ‚ö†Ô∏è  Checkpoint has col_codecs key but it's EMPTY - will try to extract from encoder after loading")
            else:
                logger.warning(f"   ‚ö†Ô∏è  Checkpoint doesn't contain col_codecs - will try to extract from encoder after loading")
        
        if isinstance(checkpoint_model, dict):
            # It's a state_dict - load it into the encoder
            logger.info(f"   Loading state_dict into encoder...")
            es.encoder.load_state_dict(checkpoint_model)
        else:
            # It's the full model - use it directly
            logger.info(f"   Using full encoder from checkpoint...")
            es.encoder = checkpoint_model
        
        epoch_idx = checkpoint_dict.get("epoch_idx", None)
        if epoch_idx is not None:
            logger.info(f"   Checkpoint epoch: {epoch_idx}")
            if not hasattr(es, 'training_info'):
                es.training_info = {}
            es.training_info['best_checkpoint_epoch'] = epoch_idx
            es.training_info['best_checkpoint_loaded'] = True
        
        # CRITICAL: If col_codecs weren't in checkpoint, try to extract from encoder
        # This handles old checkpoints that didn't save col_codecs separately
        if not es.col_codecs or len(es.col_codecs) == 0:
            logger.warning(f"   ‚ö†Ô∏è  ES col_codecs is empty - attempting to extract from encoder...")
            if hasattr(es.encoder, 'column_encoder') and hasattr(es.encoder.column_encoder, 'col_codecs'):
                col_codecs_attr = getattr(es.encoder.column_encoder, 'col_codecs', None)
                if col_codecs_attr and len(col_codecs_attr) > 0:
                    es.col_codecs = col_codecs_attr
                    logger.info(f"   ‚úÖ Extracted {len(es.col_codecs)} codecs from encoder.column_encoder")
                else:
                    # col_codecs exists but is empty/None - try to reconstruct from individual encoders
                    logger.warning(f"   ‚ö†Ô∏è  encoder.column_encoder.col_codecs exists but is empty - attempting reconstruction from individual encoders...")
                    reconstructed = _reconstruct_codecs_from_encoders(es.encoder, logger=logger)
                    if reconstructed:
                        es.col_codecs = reconstructed
                    else:
                        logger.error(f"   ‚ùå Could not reconstruct codecs from individual encoders")
            elif hasattr(es.encoder, 'col_codecs'):
                col_codecs_attr = getattr(es.encoder, 'col_codecs', None)
                if col_codecs_attr and len(col_codecs_attr) > 0:
                    es.col_codecs = col_codecs_attr
                    logger.info(f"   ‚úÖ Extracted {len(es.col_codecs)} codecs from encoder")
                else:
                    # col_codecs exists but is empty/None - try to reconstruct
                    logger.warning(f"   ‚ö†Ô∏è  encoder.col_codecs exists but is empty - attempting reconstruction from individual encoders...")
                    reconstructed = _reconstruct_codecs_from_encoders(es.encoder, logger=logger)
                    if reconstructed:
                        es.col_codecs = reconstructed
                    else:
                        logger.error(f"   ‚ùå Could not reconstruct codecs from individual encoders")
            else:
                # Last resort: Try to reconstruct from individual encoders
                logger.warning(f"   ‚ö†Ô∏è  encoder.column_encoder.col_codecs doesn't exist - attempting reconstruction from individual encoders...")
                reconstructed = _reconstruct_codecs_from_encoders(es.encoder, logger=logger)
                if reconstructed:
                    es.col_codecs = reconstructed
                    logger.info(f"   ‚úÖ Successfully reconstructed {len(es.col_codecs)} codecs from individual encoders")
                else:
                    # If reconstruction failed, we're stuck
                    logger.error(f"   ‚ùå CRITICAL: Could not extract or reconstruct col_codecs from encoder!")
                    logger.error(f"   Encoder type: {type(es.encoder)}")
                    logger.error(f"   Encoder has column_encoder: {hasattr(es.encoder, 'column_encoder')}")
                    if hasattr(es.encoder, 'column_encoder'):
                        logger.error(f"   column_encoder type: {type(es.encoder.column_encoder)}")
                        logger.error(f"   column_encoder has col_codecs: {hasattr(es.encoder.column_encoder, 'col_codecs')}")
                        if hasattr(es.encoder.column_encoder, 'encoders'):
                            logger.error(f"   column_encoder.encoders: {list(es.encoder.column_encoder.encoders.keys()) if hasattr(es.encoder.column_encoder.encoders, 'keys') else 'N/A'}")
                    logger.error(f"   This checkpoint was saved before col_codecs were properly stored.")
                    if skip_datasets:
                        logger.error(f"   Cannot load data file to recreate codecs (skip_datasets=True for SP training).")
                        raise ValueError(
                            f"Cannot reconstruct EmbeddingSpace: col_codecs not found in checkpoint or encoder, "
                            f"and cannot load data file (skip_datasets=True). "
                            f"This checkpoint may be incompatible with single predictor training."
                        )
                    logger.error(f"   If ES still has empty col_codecs, this is likely a fatal error.")
    except Exception as e:
        logger.error(f"‚ùå RECONSTRUCTION FAILED: Exception loading checkpoint model into EmbeddingSpace")
        logger.error(f"   Exception type: {type(e).__name__}")
        logger.error(f"   Exception message: {e}")
        logger.error(f"   checkpoint_dict['model'] type: {type(checkpoint_dict.get('model', 'N/A'))}")
        logger.error(f"   Full traceback:\n{traceback.format_exc()}")
        raise
    
    # CRITICAL: Comprehensive dimension validation
    # Check ALL encoder components for dimension consistency
    # This crashes HARD if any mismatches are detected (no silent failures!)
    from featrix.neural.dimension_validator import validate_embedding_space_dimensions, DimensionMismatchError
    try:
        validate_embedding_space_dimensions(es, crash_on_mismatch=True)
    except DimensionMismatchError as e:
        logger.error("=" * 80)
        logger.error("üí• FATAL: DIMENSION MISMATCH IN EMBEDDING SPACE")
        logger.error("=" * 80)
        logger.error(f"{e}")
        logger.error("")
        logger.error("This embedding space has inconsistent dimensions and CANNOT be used.")
        logger.error("The checkpoint is corrupted or was trained with mismatched dimensions.")
        logger.error("")
        logger.error("SOLUTION: Retrain the embedding space from scratch with consistent dimensions.")
        logger.error("=" * 80)
        raise
    
    # CRITICAL: Validate col_codecs are not empty (especially important for skip_datasets=True)
    if not es.col_codecs or len(es.col_codecs) == 0:
        if skip_datasets:
            raise ValueError(
                f"Cannot reconstruct EmbeddingSpace: col_codecs are empty after reconstruction. "
                f"This checkpoint is missing col_codecs and they could not be extracted from the encoder. "
                f"Cannot load data file to recreate them (skip_datasets=True for SP training). "
                f"Checkpoint may be incompatible with single predictor training."
            )
        else:
            logger.error(f"‚ùå CRITICAL: ES col_codecs are empty after reconstruction!")
            logger.error(f"   This will likely cause training to fail.")
    
    logger.info(f"‚úÖ Successfully reconstructed EmbeddingSpace from checkpoint dict")
    if es.col_codecs:
        logger.info(f"   col_codecs: {len(es.col_codecs)} codecs")

    # CRITICAL: Set models to eval mode for inference
    try:
        if hasattr(es, 'encoder') and es.encoder is not None:
            es.encoder.eval()
        if es.col_codecs:
            for col_name, codec in es.col_codecs.items():
                if codec is not None and hasattr(codec, 'eval'):
                    codec.eval()
        logger.info("‚úÖ Encoder and codecs set to eval mode for inference")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  Could not set models to eval mode: {e}")

    return es


def load_embedded_space(es_path: str, force_cpu: bool = None, skip_datasets: bool = False):
    """
    Load a pickled embedding space from disk.
    
    This is the consolidated, feature-complete version that handles:
    - GPU cache management
    - CPU version detection and usage
    - Checkpoint dict reconstruction
    - CUDA OOM handling
    - Persistent ID errors
    - torch.load fallback
    
    Args:
        es_path: Path to the embedding space file (.pickle or .pth)
        force_cpu: If True, force CPU loading (sets FEATRIX_FORCE_CPU_SINGLE_PREDICTOR=1).
                   If None, uses existing env var. For backward compatibility.
        skip_datasets: If True, skip loading datasets during reconstruction (for SP training where
                      datasets will be created separately from predictor's own data).
    
    Returns:
        EmbeddingSpace object
    """
    # Handle force_cpu parameter for backward compatibility
    # The old lib/utils.py version set FEATRIX_FORCE_CPU_SENTENCE_MODEL for sentence transformers
    # The new version uses FEATRIX_FORCE_CPU_SINGLE_PREDICTOR for single predictor training
    # We set both to preserve backward compatibility
    if force_cpu is not None:
        if force_cpu:
            os.environ['FEATRIX_FORCE_CPU_SINGLE_PREDICTOR'] = '1'
            os.environ['FEATRIX_FORCE_CPU_SENTENCE_MODEL'] = '1'  # For backward compatibility
        else:
            os.environ.pop('FEATRIX_FORCE_CPU_SINGLE_PREDICTOR', None)
            os.environ.pop('FEATRIX_FORCE_CPU_SENTENCE_MODEL', None)
    # CRITICAL: Clear GPU cache at the VERY START to free up any reserved memory
    # This must happen before ANY unpickling starts, as __setstate__ methods may allocate GPU memory
    try:
        if torch is not None and is_gpu_available():
            empty_gpu_cache()
            ipc_collect_gpu()
            logger.info(f"üßπ Cleared GPU cache at START of load_embedded_space (before any unpickling)")
            _log_gpu_memory("AT START of load_embedded_space (after cache clear)")
    except Exception as e:
        logger.debug(f"Could not clear GPU cache at start: {e}")
    
    # CRITICAL: Check memory BEFORE anything else and force CPU if needed
    # This prevents GPU allocation during unpickling even if we have a "CPU version"
    force_cpu_from_env = os.environ.get('FEATRIX_FORCE_CPU_SINGLE_PREDICTOR') == '1'
    
    # Check GPU memory early and force CPU if memory is tight
    # This must happen BEFORE unpickling starts, as unpickling will try to allocate GPU memory
    if torch is not None and is_gpu_available() and not force_cpu_from_env:
        try:
            allocated = get_gpu_memory_allocated()
            reserved = get_gpu_memory_reserved()
            props = get_gpu_device_properties(0)
            total_memory = (props.total_memory / (1024**3)) if props else 0.0
            free_memory = total_memory - reserved
            reserved_percent = (reserved / total_memory) * 100 if total_memory > 0 else 0
            
            # CRITICAL: If memory is tight, force CPU BEFORE unpickling
            # Even "CPU versions" can trigger GPU allocation during unpickling
            if reserved_percent > 50 or free_memory < 50:
                logger.warning(f"‚ö†Ô∏è  Early memory check: Reserved={reserved_percent:.1f}%, Free={free_memory:.2f} GB")
                logger.warning(f"   Auto-forcing CPU loading to prevent GPU allocation during unpickling")
                force_cpu_from_env = True
                os.environ['FEATRIX_FORCE_CPU_SINGLE_PREDICTOR'] = '1'
                os.environ['FEATRIX_FORCE_CPU_SENTENCE_MODEL'] = '1'
        except Exception as e:
            logger.debug(f"Could not check GPU memory early: {e}")
    
    force_cpu = force_cpu_from_env
    
    # Try to find CPU version - check multiple possible locations
    cpu_version_paths = []
    es_path = str(es_path)
    if es_path.endswith('.pth'):
        # For .pth files, check in the same directory
        es_dir = Path(es_path).parent
        cpu_version_paths = [
            es_dir / "embedding_space_cpu.pickle",
            es_dir / "embedded_space_cpu.pickle",
            es_dir / "best_model_cpu.pickle",
            es_dir / "best_model_package" / "best_model_cpu.pickle",
            es_dir / "best_model_package" / "embedded_space_cpu.pickle",
            es_dir / "best_model_package" / "embedding_space_cpu.pickle",
        ]
    else:
        # For .pickle files, try replacing .pickle with _cpu.pickle or adding _cpu
        cpu_version_paths = [
            es_path.replace('.pickle', '_cpu.pickle'),
            es_path + '_cpu',
            es_path.replace('embedded_space.pickle', 'embedded_space_cpu.pickle'),
            es_path.replace('embedding_space.pickle', 'embedding_space_cpu.pickle'),
        ]
    
    # Check if any CPU version exists
    cpu_version_found = None
    for cpu_path in cpu_version_paths:
        cpu_path_str = str(cpu_path) if hasattr(cpu_path, '__str__') else cpu_path
        if os.path.exists(cpu_path_str):
            cpu_version_found = cpu_path_str
            logger.info(f"‚úÖ CPU version found at {cpu_version_found} - using this instead of GPU version")
            es_path = cpu_version_found
            break
    
    if not cpu_version_found and force_cpu:
        logger.info(f"üîç No CPU version found - will load GPU version and convert to CPU")
    
    # If path is a .pth file (PyTorch checkpoint), try to reconstruct ES from it
    if es_path.endswith('.pth') or es_path.endswith('.pt'):
        es_dir = Path(es_path).parent

        # If given a resume checkpoint (.pth), look for inference checkpoint (.pt)
        # The inference checkpoint has full encoder + col_codecs, resume checkpoint only has state_dict
        if 'checkpoint_resume_training' in es_path or 'foundation_checkpoint' in es_path:
            # First try exact match
            inference_path = es_path.replace('checkpoint_resume_training', 'checkpoint_inference').replace('.pth', '.pt')
            if Path(inference_path).exists():
                logger.info(f"üîç Found inference checkpoint at {inference_path} (instead of resume checkpoint)")
                es_path = inference_path
            else:
                # No exact match - check for BEST checkpoint first, then fall back to latest
                best_inference = es_dir / "checkpoint_inference_BEST.pt"
                if best_inference.exists():
                    logger.info(f"üîç Using BEST inference checkpoint: {best_inference}")
                    es_path = str(best_inference)
                else:
                    # No BEST - find the latest inference checkpoint in the directory
                    inference_checkpoints = sorted(es_dir.glob("checkpoint_inference_e-*.pt"))
                    if inference_checkpoints:
                        latest_inference = inference_checkpoints[-1]
                        logger.info(f"üîç Using latest inference checkpoint: {latest_inference} (requested epoch not found)")
                        es_path = str(latest_inference)
                    else:
                        logger.warning(f"‚ö†Ô∏è  No inference checkpoints found in {es_dir}, will try other methods")

        # Look for embedding_space.pickle first (preferred - faster to load)
        # Use the canonical find function to check for embedding space pickle
        pickle_file = find_embedding_space_pickle(es_dir)
        pickle_found = False

        if pickle_file:
            logger.info(f"üîç Found embedding space pickle at {pickle_file} (instead of .pth file)")
            es_path = str(pickle_file)
            pickle_found = True
        else:
            # Also check best_model_package subdirectory
            best_model_package_dir = es_dir / "best_model_package"
            if best_model_package_dir.exists():
                pickle_file = find_embedding_space_pickle(best_model_package_dir)
                if pickle_file:
                    logger.info(f"üîç Found embedding space pickle at {pickle_file} (instead of .pth file)")
                    es_path = str(pickle_file)
                    pickle_found = True
                # Also check for best_model.pickle as fallback
                elif (best_model_package_dir / "best_model.pickle").exists():
                    logger.info(f"üîç Found best_model.pickle at {best_model_package_dir / 'best_model.pickle'} (instead of .pth file)")
                    es_path = str(best_model_package_dir / "best_model.pickle")
                    pickle_found = True
            
            # Also check for best_model.pickle in the main directory
            if not pickle_found and (es_dir / "best_model.pickle").exists():
                logger.info(f"üîç Found best_model.pickle at {es_dir / 'best_model.pickle'} (instead of .pth file)")
                es_path = str(es_dir / "best_model.pickle")
                pickle_found = True
        
        # If no pickle found, reconstruct from .pth/.pt checkpoint
        if not pickle_found:
            logger.info(f"üì¶ No pickle found - loading checkpoint and reconstructing ES")
            try:
                # Load the checkpoint dict
                pth_path = Path(es_path)
                logger.info(f"üîç Loading checkpoint from {pth_path}...")
                checkpoint_dict = _safe_torch_load(pth_path, map_location='cpu', weights_only=False)

                if not isinstance(checkpoint_dict, dict):
                    raise TypeError(f"Checkpoint is not a dict. Type: {type(checkpoint_dict)}")

                # Inference checkpoint format: has 'encoder' key with full encoder object
                if 'encoder' in checkpoint_dict and 'col_codecs' in checkpoint_dict:
                    logger.info(f"‚úÖ Inference checkpoint format detected - restoring ES directly")

                    from featrix.neural.embedded_space import EmbeddingSpace
                    from featrix.neural.input_data_set import FeatrixInputDataSet

                    # Create minimal ES shell
                    dummy_df = pd.DataFrame()
                    dummy_dataset = FeatrixInputDataSet(df=dummy_df, ignore_cols=[], standup_only=True)

                    d_model = checkpoint_dict.get('d_model', 128)
                    es = EmbeddingSpace(
                        train_input_data=dummy_dataset,
                        val_input_data=dummy_dataset,
                        d_model=d_model,
                        skip_pca_init=True,
                    )

                    # Restore from inference checkpoint
                    es.encoder = checkpoint_dict['encoder']
                    es.col_codecs = checkpoint_dict['col_codecs']
                    es.col_order = checkpoint_dict.get('col_order', [])
                    es.column_spec = checkpoint_dict.get('column_spec', {})
                    es.d_model = d_model
                    es.json_transformations = checkpoint_dict.get('json_transformations', {})
                    es.required_child_es_mapping = checkpoint_dict.get('required_child_es_mapping', {})
                    es.availableColumns = list(es.col_codecs.keys()) if es.col_codecs else []

                    # Restore customer quality trackers if present
                    if 'customer_quality_trackers' in checkpoint_dict and checkpoint_dict['customer_quality_trackers']:
                        from featrix.neural.customer_quality_tracker import CustomerQualityTracker
                        es.customer_quality_trackers = {
                            int(epoch): CustomerQualityTracker.from_dict(qt_dict)
                            for epoch, qt_dict in checkpoint_dict['customer_quality_trackers'].items()
                        }
                    else:
                        es.customer_quality_trackers = {}

                    logger.info(f"‚úÖ ES restored from inference checkpoint (d_model={es.d_model}, {len(es.availableColumns)} columns, {len(es.col_codecs)} codecs)")

                    # CRITICAL: Set models to eval mode for inference
                    try:
                        if es.encoder is not None:
                            es.encoder.eval()
                        if es.col_codecs:
                            for col_name, codec in es.col_codecs.items():
                                if codec is not None and hasattr(codec, 'eval'):
                                    codec.eval()
                        logger.info("‚úÖ Encoder and codecs set to eval mode for inference")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è  Could not set models to eval mode: {e}")

                    return es

                if 'model' not in checkpoint_dict:
                    raise TypeError(f"Checkpoint doesn't contain 'model' or 'encoder' key. Keys: {list(checkpoint_dict.keys())}")

                logger.info(f"‚úÖ Checkpoint loaded. Epoch: {checkpoint_dict.get('epoch_idx', 'unknown')}")

                # Check if checkpoint has es_state (new format) - just restore directly
                if 'es_state' in checkpoint_dict:
                    logger.info(f"‚úÖ Checkpoint contains es_state - restoring ES directly (no reconstruction)")
                    
                    # Create minimal ES shell without datasets
                    from featrix.neural.embedded_space import EmbeddingSpace
                    es_state = checkpoint_dict['es_state']
                    
                    # Create dummy datasets (not used for inference/SP training)
                    from featrix.neural.input_data_set import FeatrixInputDataSet
                    dummy_df = pd.DataFrame()
                    dummy_dataset = FeatrixInputDataSet(df=dummy_df, ignore_cols=[], standup_only=True)
                    
                    # Create ES with minimal args
                    es = EmbeddingSpace(
                        train_input_data=dummy_dataset,
                        val_input_data=dummy_dataset,
                        d_model=es_state['d_model'],
                        skip_pca_init=True,
                    )
                    
                    # Restore all attributes from es_state
                    es.d_model = es_state['d_model']
                    es.column_spec = es_state.get('column_spec', {})
                    es.availableColumns = es_state.get('availableColumns', [])
                    es.n_epochs = es_state.get('n_epochs')
                    es.name = es_state.get('name')
                    es.string_cache = es_state.get('string_cache')
                    es.json_transformations = es_state.get('json_transformations', {})
                    es.required_child_es_mapping = es_state.get('required_child_es_mapping', {})
                    es.user_metadata = es_state.get('user_metadata')
                    es.version_info = es_state.get('version_info')
                    es.output_debug_label = es_state.get('output_debug_label', 'Restored from checkpoint')
                    es.training_info = es_state.get('training_info', {})
                    
                    # Load encoder
                    es.encoder = checkpoint_dict['model']
                    
                    # CRITICAL: Comprehensive dimension validation
                    from featrix.neural.dimension_validator import validate_embedding_space_dimensions, DimensionMismatchError
                    try:
                        validate_embedding_space_dimensions(es, crash_on_mismatch=True)
                    except DimensionMismatchError as e:
                        logger.error("=" * 80)
                        logger.error("üí• FATAL: DIMENSION MISMATCH IN EMBEDDING SPACE")
                        logger.error("=" * 80)
                        logger.error(f"{e}")
                        logger.error("This embedding space has inconsistent dimensions and CANNOT be used.")
                        logger.error("SOLUTION: Retrain the embedding space from scratch.")
                        logger.error("=" * 80)
                        raise
                    
                    # Restore col_codecs from es_state (saved as codec objects)
                    if 'col_codecs' in es_state and es_state['col_codecs']:
                        es.col_codecs = es_state['col_codecs']
                        logger.info(f"   Restored {len(es.col_codecs)} codecs from es_state")
                    elif hasattr(es.encoder, 'column_encoder') and hasattr(es.encoder.column_encoder, 'col_codecs'):
                        col_codecs_attr = getattr(es.encoder.column_encoder, 'col_codecs', None)
                        if col_codecs_attr and len(col_codecs_attr) > 0:
                            es.col_codecs = col_codecs_attr
                            logger.info(f"   Extracted {len(es.col_codecs)} codecs from encoder.column_encoder")
                        else:
                            # col_codecs exists but is empty/None - try to reconstruct
                            logger.warning(f"   ‚ö†Ô∏è  encoder.column_encoder.col_codecs exists but is empty - attempting reconstruction from individual encoders...")
                            reconstructed = _reconstruct_codecs_from_encoders(es.encoder, logger=logger)
                            if reconstructed:
                                es.col_codecs = reconstructed
                            else:
                                logger.error(f"   ‚ùå Could not reconstruct codecs from individual encoders")
                                raise ValueError(
                                    f"Cannot restore EmbeddingSpace from checkpoint: col_codecs not found in es_state or encoder, "
                                    f"and reconstruction from individual encoders failed. "
                                    f"This checkpoint is corrupted or incompatible."
                                )
                    elif hasattr(es.encoder, 'col_codecs'):
                        col_codecs_attr = getattr(es.encoder, 'col_codecs', None)
                        if col_codecs_attr and len(col_codecs_attr) > 0:
                            es.col_codecs = col_codecs_attr
                            logger.info(f"   Extracted {len(es.col_codecs)} codecs from encoder")
                        else:
                            # col_codecs exists but is empty/None - try to reconstruct
                            logger.warning(f"   ‚ö†Ô∏è  encoder.col_codecs exists but is empty - attempting reconstruction from individual encoders...")
                            reconstructed = _reconstruct_codecs_from_encoders(es.encoder, logger=logger)
                            if reconstructed:
                                es.col_codecs = reconstructed
                            else:
                                logger.error(f"   ‚ùå Could not reconstruct codecs from individual encoders")
                                raise ValueError(
                                    f"Cannot restore EmbeddingSpace from checkpoint: col_codecs not found in es_state or encoder, "
                                    f"and reconstruction from individual encoders failed. "
                                    f"This checkpoint is corrupted or incompatible."
                                )
                    else:
                        # Last resort: Try to reconstruct from individual encoders
                        logger.warning(f"   ‚ö†Ô∏è  No col_codecs in es_state or encoder - attempting reconstruction from individual encoders...")
                        reconstructed = _reconstruct_codecs_from_encoders(es.encoder, logger=logger)
                        if reconstructed:
                            es.col_codecs = reconstructed
                            logger.info(f"   ‚úÖ Successfully reconstructed {len(es.col_codecs)} codecs from individual encoders")
                        else:
                            logger.error(f"   ‚ùå CRITICAL: No col_codecs in es_state, encoder.column_encoder, or encoder, and reconstruction failed!")
                            logger.error(f"   es_state keys: {list(es_state.keys())}")
                            logger.error(f"   Encoder type: {type(es.encoder)}")
                            logger.error(f"   Encoder has column_encoder: {hasattr(es.encoder, 'column_encoder')}")
                            if hasattr(es.encoder, 'column_encoder'):
                                logger.error(f"   column_encoder type: {type(es.encoder.column_encoder)}")
                                logger.error(f"   column_encoder has col_codecs: {hasattr(es.encoder.column_encoder, 'col_codecs')}")
                            logger.error(f"   Encoder has col_codecs: {hasattr(es.encoder, 'col_codecs')}")
                            raise ValueError(
                                f"Cannot restore EmbeddingSpace from checkpoint: col_codecs not found in es_state or encoder, "
                                f"and reconstruction from individual encoders failed. "
                                f"This checkpoint is corrupted or incompatible."
                            )
                    
                    # Restore customer quality trackers if present
                    if 'customer_quality_trackers' in es_state and es_state['customer_quality_trackers']:
                        from featrix.neural.customer_quality_tracker import CustomerQualityTracker
                        es.customer_quality_trackers = {
                            int(epoch): CustomerQualityTracker.from_dict(qt_dict)
                            for epoch, qt_dict in es_state['customer_quality_trackers'].items()
                        }
                        logger.info(f"   Restored {len(es.customer_quality_trackers)} quality trackers from checkpoint")
                    else:
                        # Initialize empty dict if not present
                        es.customer_quality_trackers = {}
                    
                    logger.info(f"‚úÖ ES restored from es_state (d_model={es.d_model}, {len(es.availableColumns)} columns, {len(es.col_codecs)} codecs)")
                    
                else:
                    # Old format - use reconstruction
                    logger.info(f"‚ö†Ô∏è  Old checkpoint format - using reconstruction")
                    es = _reconstruct_es_from_checkpoint_dict(checkpoint_dict, str(pth_path), logger=logger, skip_datasets=skip_datasets)
                    
                    if es is None:
                        raise ValueError(f"Reconstruction returned None")
                
                logger.info(f"‚úÖ Successfully reconstructed ES from .pth checkpoint")

                # CRITICAL: Set models to eval mode for inference
                try:
                    if hasattr(es, 'encoder') and es.encoder is not None:
                        es.encoder.eval()
                    if hasattr(es, 'col_codecs') and es.col_codecs:
                        for col_name, codec in es.col_codecs.items():
                            if codec is not None and hasattr(codec, 'eval'):
                                codec.eval()
                    logger.info("‚úÖ Encoder and codecs set to eval mode for inference")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  Could not set models to eval mode: {e}")

                return es
            except Exception as e:
                logger.error(f"‚ùå Failed to reconstruct ES from .pth checkpoint: {e}")
                logger.error(traceback.format_exc())
                raise FileNotFoundError(
                    f"Could not load ES from {es_path}: No pickle file found and reconstruction from .pth failed. "
                    f"Error: {e}"
                )
    
    # Fall back to pickle.load
    # CRITICAL: Aggressively clear GPU memory BEFORE loading to prevent OOM
    # The pickle may contain large models that will try to allocate on GPU during unpickling
    try:
        if torch is not None and is_gpu_available():
            # Multiple passes to force release of reserved memory
            for i in range(3):
                empty_gpu_cache()
                ipc_collect_gpu()
                if i == 0:
                    logger.info(f"üßπ Cleared GPU cache BEFORE loading embedding space (pass {i+1}/3)")
                else:
                    logger.debug(f"üßπ Cleared GPU cache BEFORE loading embedding space (pass {i+1}/3)")
            _log_gpu_memory("AFTER clearing cache, BEFORE loading embedding space")
            
            # Check if we have enough free memory (need at least 20GB free for large models)
            allocated = get_gpu_memory_allocated()
            reserved = get_gpu_memory_reserved()
            props = get_gpu_device_properties(0)
            total_memory = (props.total_memory / (1024**3)) if props else 0.0
            free_memory = total_memory - reserved
            
            logger.info(f"üìä GPU Memory Status: Allocated={allocated:.2f} GB, Reserved={reserved:.2f} GB, Free={free_memory:.2f} GB, Total={total_memory:.2f} GB")
            
            # CRITICAL: Check BOTH free memory AND reserved memory
            # Reserved memory is what PyTorch has allocated from CUDA, even if not actively used
            # If reserved is > 80% of total, we're in danger zone - force CPU
            # Also if free memory is < 50GB, force CPU (we saw 47GB free still OOM)
            reserved_percent = (reserved / total_memory) * 100
            
            if reserved_percent > 80 or free_memory < 50:
                logger.warning(f"‚ö†Ô∏è  CRITICAL: GPU memory too high - Reserved={reserved_percent:.1f}% of total, Free={free_memory:.2f} GB")
                logger.warning(f"   Auto-forcing CPU loading to prevent OOM (embedding space doesn't need GPU for single predictor training)")
                logger.warning(f"   Set FEATRIX_FORCE_CPU_SINGLE_PREDICTOR=1 to always use CPU.")
                force_cpu = True
                os.environ['FEATRIX_FORCE_CPU_SINGLE_PREDICTOR'] = '1'
                os.environ['FEATRIX_FORCE_CPU_SENTENCE_MODEL'] = '1'
            elif reserved_percent > 70 or free_memory < 60:
                logger.warning(f"‚ö†Ô∏è  High GPU memory usage: Reserved={reserved_percent:.1f}% of total, Free={free_memory:.2f} GB")
                logger.warning(f"   Loading may fail with OOM if model is large. Consider using CPU version.")
    except Exception as e:
        logger.debug(f"Could not clear GPU cache before loading: {e}")

    # Check file extension to determine loading strategy
    es_path_obj = Path(es_path)
    file_ext = es_path_obj.suffix.lower()
    use_pickle_directly = file_ext in ['.pickle', '.pkl']  # Standard pickle files
    
    with open(es_path, "rb") as f:
        try:
            # CRITICAL: Use CPUUnpickler (defined at module level) that forces all tensors to CPU
            # This prevents OOM when pickle tries to restore tensors to their original GPU device
            # and prevents "RuntimeError: Attempting to deserialize object on a CUDA device" errors
            
            # Use torch.load with map_location='cpu' to prevent GPU allocation during unpickling
            _log_gpu_memory("BEFORE loading embedding space")
            logger.info(f"üîç Attempting torch.load(map_location='cpu') for {es_path}")
            
            # Temporarily set default tensor type to CPU to prevent GPU allocation during unpickling
            # This is a workaround - pickle will still try to restore to original device, but
            # we'll catch it in __setstate__ and move to CPU
            original_default_tensor_type = None
            if torch is not None:
                try:
                    # Save original default (if it exists)
                    if hasattr(torch, '_C') and hasattr(torch._C, '_get_default_tensor_type'):
                        original_default_tensor_type = torch._C._get_default_tensor_type()
                except:
                    pass
            
            # Save original env var state so we can restore after loading
            # We set force_cpu=1 during unpickling to prevent OOM, but we MUST
            # restore the original value after loading so training can use GPU!
            _original_force_cpu = os.environ.get('FEATRIX_FORCE_CPU_SINGLE_PREDICTOR')
            _user_requested_force_cpu = force_cpu  # True/False/None from user
            
            try:
                # CRITICAL: Set force_cpu flag BEFORE unpickling so __setstate__ methods see it
                # This prevents OOM during unpickling, but we'll clear it after loading
                os.environ['FEATRIX_FORCE_CPU_SINGLE_PREDICTOR'] = '1'
                logger.info(f"üîß Set FEATRIX_FORCE_CPU_SINGLE_PREDICTOR=1 before unpickling (will restore after)")
                
                if torch is not None and not use_pickle_directly:
                    # For .pth/.pt files, try torch.load first
                    logger.info(f"üîß Using _safe_torch_load(map_location='cpu') to force CPU loading")
                    try:
                        result = _safe_torch_load(f, map_location='cpu', weights_only=False)
                    except RuntimeError as torch_err:
                        error_msg = str(torch_err).lower()
                        # If torch.load fails with "invalid magic number", try pickle.load as fallback
                        # This can happen if the file was saved with pickle.dump() using a protocol
                        # that torch.load doesn't fully support, or if it's a pure pickle file
                        if "invalid magic number" in error_msg or "corrupt file" in error_msg:
                            logger.warning(f"‚ö†Ô∏è  torch.load failed with: {torch_err}")
                            logger.info(f"üîÑ Falling back to CPUUnpickler (file may be a standard pickle, not PyTorch format)")
                            f.seek(0)  # Reset file pointer to beginning
                            result = CPUUnpickler(f).load()
                            logger.info(f"‚úÖ Successfully loaded with CPUUnpickler")
                        else:
                            # Re-raise other RuntimeErrors
                            raise
                elif use_pickle_directly:
                    # For .pickle/.pkl files, use CPUUnpickler directly (forces CPU device mapping)
                    logger.info(f"üîß Using CPUUnpickler directly for {file_ext} file")
                    result = CPUUnpickler(f).load()
                else:
                    # torch not available - use CPUUnpickler (safer than regular pickle.load)
                    logger.warning(f"‚ö†Ô∏è  torch not available - using CPUUnpickler")
                    result = CPUUnpickler(f).load()
                
                # CRITICAL: After loading, FORCE PyTorch to release ALL reserved GPU memory
                # PyTorch's allocator may have reserved memory during unpickling even if tensors moved to CPU
                # Only do this if torch is available and CUDA is specifically available (not MPS)
                if torch is not None and is_cuda_available():
                    # Multiple aggressive cache clears
                    for _ in range(5):
                        empty_gpu_cache()
                        ipc_collect_gpu()
                    # Try to reset the allocator completely
                    try:
                        reset_gpu_peak_memory_stats()
                        reset_gpu_accumulated_memory_stats()
                    except:
                        pass
                    logger.info(f"üßπ Aggressively cleared GPU cache after loading (5x empty_cache + stats reset)")
            except RuntimeError as e:
                error_msg = str(e).lower()
                if "out of memory" in error_msg or "CUDA" in error_msg:
                    logger.error(f"‚ùå CUDA OOM during loading: {e}")
                    logger.error(f"   This should NOT happen with map_location='cpu' - possible pickle corruption")
                    raise
                elif "invalid magic number" in error_msg or "corrupt file" in error_msg:
                    logger.error(f"‚ùå Corrupted file detected: {e}")
                    logger.error(f"   File path: {es_path}")
                    logger.error(f"   This usually means:")
                    logger.error(f"   1. The file is incomplete (write was interrupted)")
                    logger.error(f"   2. The file is not a valid pickle/PyTorch checkpoint")
                    logger.error(f"   3. The file was corrupted during save or transfer")
                    # Try to get file info for diagnostics
                    try:
                        if os.path.exists(es_path):
                            file_size = os.path.getsize(es_path)
                            logger.error(f"   File size: {file_size:,} bytes")
                            if file_size == 0:
                                logger.error(f"   ‚ö†Ô∏è  File is empty (0 bytes) - write likely failed")
                        else:
                            logger.error(f"   ‚ö†Ô∏è  File does not exist!")
                    except Exception:
                        pass
                    raise
                else:
                    raise
            except Exception as e:
                # Catch any other exceptions (like pickle errors) and provide better diagnostics
                error_msg = str(e).lower()
                if "invalid magic number" in error_msg or "corrupt file" in error_msg or "pickle" in error_msg:
                    logger.error(f"‚ùå Failed to load file: {e}")
                    logger.error(f"   File path: {es_path}")
                    logger.error(f"   Error type: {type(e).__name__}")
                    try:
                        if os.path.exists(es_path):
                            file_size = os.path.getsize(es_path)
                            logger.error(f"   File size: {file_size:,} bytes")
                    except Exception:
                        pass
                raise
            
            _log_gpu_memory("AFTER loading embedding space")
            
            # CRITICAL: Handle checkpoint dicts - if the pickle contains a dict instead of EmbeddingSpace,
            # we need to reconstruct the EmbeddingSpace from the checkpoint
            from featrix.neural.embedded_space import EmbeddingSpace
            if isinstance(result, dict) and 'model' in result:
                logger.warning(f"‚ö†Ô∏è  Loaded dict instead of EmbeddingSpace - attempting to reconstruct from checkpoint")
                try:
                    result = _reconstruct_es_from_checkpoint_dict(result, es_path, logger)
                except Exception as recon_err:
                    logger.error(f"‚ùå‚ùå‚ùå RECONSTRUCTION FAILED COMPLETELY ‚ùå‚ùå‚ùå")
                    logger.error(f"   Exception type: {type(recon_err).__name__}")
                    logger.error(f"   Exception message: {recon_err}")
                    logger.error(f"   Original es_path: {es_path}")
                    logger.error(f"   Result type: {type(result)}")
                    logger.error(f"   Result keys (if dict): {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
                    logger.error(f"   Full traceback:\n{traceback.format_exc()}")
                    # Re-raise so the outer exception handler can catch it
                    raise
            
            # CRITICAL: Move any GPU models to CPU during loading to avoid CUDA OOM
            # The pickle may contain models that were saved on GPU, which will try to load on GPU
            # If we're in CPU mode, move everything to CPU and save a CPU version for future loads
            if isinstance(result, EmbeddingSpace):
                # Check if anything is on GPU
                has_gpu_components = False
                if hasattr(result, 'encoder') and result.encoder is not None:
                    if list(result.encoder.parameters()):
                        encoder_device = next(result.encoder.parameters()).device
                        if encoder_device.type in ['cuda', 'mps']:
                            has_gpu_components = True
                
                # Check codecs - MOST codecs are stateless (no params), but some have embedded encoders
                # (e.g., JsonCodec has projection layer, URL codec might have encoder)
                # The main GPU state is in embedding_space.encoder, not codecs
                if not has_gpu_components and hasattr(result, 'col_codecs'):
                    for col_name, codec in result.col_codecs.items():
                        # Only check if codec actually has parameters (most don't - they're stateless)
                        if hasattr(codec, 'parameters') and list(codec.parameters()):
                            codec_device = next(codec.parameters()).device
                            if codec_device.type in ['cuda', 'mps']:
                                logger.info(f"   Found GPU parameters in codec '{col_name}' (unusual - most codecs are stateless)")
                                has_gpu_components = True
                                break
                        # Check buffers (some codecs might have buffers even without params)
                        if hasattr(codec, 'buffers') and isinstance(codec, torch.nn.Module):
                            for buffer in codec.buffers():
                                if buffer.device.type in ['cuda', 'mps']:
                                    logger.info(f"   Found GPU buffers in codec '{col_name}' (unusual - most codecs are stateless)")
                                    has_gpu_components = True
                                    break
                            if has_gpu_components:
                                break
                        # Check for embedded encoders (e.g., JsonCodec.projection, URL codec.encoder)
                        if hasattr(codec, 'projection') and codec.projection is not None:
                            if hasattr(codec.projection, 'parameters') and list(codec.projection.parameters()):
                                proj_device = next(codec.projection.parameters()).device
                                if proj_device.type in ['cuda', 'mps']:
                                    logger.info(f"   Found GPU projection in codec '{col_name}'")
                                    has_gpu_components = True
                                    break
                        if hasattr(codec, 'encoder') and codec.encoder is not None:
                            if hasattr(codec.encoder, 'parameters') and list(codec.encoder.parameters()):
                                encoder_device = next(codec.encoder.parameters()).device
                                if encoder_device.type in ['cuda', 'mps']:
                                    logger.info(f"   Found GPU encoder in codec '{col_name}'")
                                    has_gpu_components = True
                                    break
                
                # If we found GPU components and we're in CPU mode, move to CPU and save CPU version
                if has_gpu_components and force_cpu:
                    logger.info(f"üîÑ Embedding space has GPU components - moving to CPU and saving CPU version...")
                    
                    # Move encoder to CPU
                    if hasattr(result, 'encoder') and result.encoder is not None:
                        if list(result.encoder.parameters()):
                            encoder_device = next(result.encoder.parameters()).device
                            if encoder_device.type in ['cuda', 'mps']:
                                logger.info(f"   Moving encoder from {encoder_device} to CPU...")
                                result.encoder = result.encoder.to('cpu')
                                empty_gpu_cache()
                    
                    # Move all codecs to CPU - check BOTH parameters AND buffers
                    if hasattr(result, 'col_codecs'):
                        moved_count = 0
                        for col_name, codec in result.col_codecs.items():
                            codec_has_gpu = False
                            
                            # Check if codec has GPU parameters
                            if hasattr(codec, 'parameters') and list(codec.parameters()):
                                codec_device = next(codec.parameters()).device
                                if codec_device.type in ['cuda', 'mps']:
                                    codec_has_gpu = True
                            
                            # Check if codec has GPU buffers (CRITICAL - buffers can be on GPU!)
                            if not codec_has_gpu and hasattr(codec, 'buffers') and isinstance(codec, torch.nn.Module):
                                for buffer in codec.buffers():
                                    if buffer.device.type in ['cuda', 'mps']:
                                        codec_has_gpu = True
                                        break
                            
                            # Move entire codec to CPU if it has any GPU components
                            if codec_has_gpu:
                                if hasattr(codec, 'cpu'):
                                    codec.to('cpu')  # This moves both parameters AND buffers
                                    moved_count += 1
                                    logger.info(f"   Moved codec '{col_name}' to CPU (has GPU params/buffers)")
                                else:
                                    # Manual move if no .cpu() method
                                    if hasattr(codec, 'parameters'):
                                        for param in codec.parameters():
                                            param.data = param.data.to('cpu')
                                    if hasattr(codec, 'buffers') and isinstance(codec, torch.nn.Module):
                                        for buffer in codec.buffers():
                                            buffer.data = buffer.data.to('cpu')
                                    moved_count += 1
                                    logger.info(f"   Manually moved codec '{col_name}' to CPU")
                            
                            # Also check projection layers
                            if hasattr(codec, 'projection') and codec.projection is not None:
                                proj_has_gpu = False
                                if list(codec.projection.parameters()):
                                    proj_device = next(codec.projection.parameters()).device
                                    if proj_device.type in ['cuda', 'mps']:
                                        proj_has_gpu = True
                                # Check buffers in projection too
                                if not proj_has_gpu and hasattr(codec.projection, 'buffers'):
                                    for buffer in codec.projection.buffers():
                                        if buffer.device.type in ['cuda', 'mps']:
                                            proj_has_gpu = True
                                            break
                                if proj_has_gpu:
                                    codec.projection = codec.projection.to('cpu')
                                    logger.info(f"   Moved projection for '{col_name}' to CPU")
                        
                        if moved_count > 0:
                            logger.info(f"   ‚úÖ Moved {moved_count} codecs to CPU (including buffers)")
                        else:
                            logger.info(f"   ‚ÑπÔ∏è  All codecs already on CPU or have no GPU components")
                    
                    # Save CPU version for future loads - use consistent naming
                    es_path_obj = Path(es_path)
                    if es_path.endswith('.pickle'):
                        cpu_version_path = str(es_path_obj.parent / f"{es_path_obj.stem}_cpu.pickle")
                    else:
                        cpu_version_path = str(es_path_obj.parent / f"{es_path_obj.name}_cpu")
                    
                    logger.info(f"üíæ Saving CPU version to {cpu_version_path}...")
                    try:
                        with open(cpu_version_path, 'wb') as f:
                            pickle.dump(result, f)
                        logger.info(f"‚úÖ CPU version saved to {cpu_version_path} - future loads will use this file")
                    except Exception as save_err:
                        logger.warning(f"‚ö†Ô∏è  Failed to save CPU version: {save_err}")
                    
                    if torch is not None:
                        empty_gpu_cache()
                    _log_gpu_memory("AFTER moving embedding space to CPU")
                    logger.info(f"   ‚úÖ All components moved to CPU")
                elif has_gpu_components:
                    # Models are on GPU - leave them there for GPU training
                    logger.info(f"‚úÖ Embedding space has GPU components - keeping on GPU for training")
            
            logger.info(f"‚úÖ Successfully loaded")
            
            # CRITICAL: Validate col_codecs after loading
            # If the pickle was saved with empty col_codecs (data corruption or incomplete save),
            # we need to recover them from the encoder to prevent "0 codecs" errors during SP training
            if isinstance(result, EmbeddingSpace):
                if not result.col_codecs or len(result.col_codecs) == 0:
                    logger.error(f"‚ùå CRITICAL: Loaded EmbeddingSpace has EMPTY col_codecs!")
                    logger.error(f"   This indicates the pickle file was saved with corrupted/empty codec data.")
                    logger.error(f"   Attempting to recover col_codecs from encoder...")
                    
                    # Try to extract col_codecs from encoder
                    recovered = False
                    if hasattr(result, 'encoder') and result.encoder is not None:
                        if hasattr(result.encoder, 'column_encoder') and hasattr(result.encoder.column_encoder, 'col_codecs'):
                            result.col_codecs = result.encoder.column_encoder.col_codecs
                            logger.info(f"   ‚úÖ Recovered {len(result.col_codecs)} codecs from encoder.column_encoder")
                            recovered = True
                        elif hasattr(result.encoder, 'col_codecs'):
                            result.col_codecs = result.encoder.col_codecs
                            logger.info(f"   ‚úÖ Recovered {len(result.col_codecs)} codecs from encoder")
                            recovered = True
                    
                    if not recovered:
                        logger.error(f"   ‚ùå FAILED to recover col_codecs from encoder")
                        logger.error(f"   Encoder type: {type(result.encoder) if hasattr(result, 'encoder') else 'NO ENCODER'}")
                        if hasattr(result, 'encoder') and result.encoder is not None:
                            logger.error(f"   Encoder has column_encoder: {hasattr(result.encoder, 'column_encoder')}")
                            if hasattr(result.encoder, 'column_encoder'):
                                logger.error(f"   column_encoder has col_codecs: {hasattr(result.encoder.column_encoder, 'col_codecs')}")
                            logger.error(f"   Encoder has col_codecs: {hasattr(result.encoder, 'col_codecs')}")
                        raise ValueError(
                            f"Cannot load embedding space from {es_path}: col_codecs is empty and could not be recovered from encoder. "
                            f"This pickle file is corrupted or was saved incorrectly."
                        )
                else:
                    logger.info(f"   ‚úÖ col_codecs validation passed: {len(result.col_codecs)} codecs loaded")
            
            # CRITICAL: Restore original env var state so training can use GPU!
            # We set force_cpu=1 during unpickling to prevent OOM, but now loading is done
            if _user_requested_force_cpu is True:
                # User explicitly wanted CPU mode - keep env var set
                os.environ['FEATRIX_FORCE_CPU_SINGLE_PREDICTOR'] = '1'
                logger.info(f"üîß User requested force_cpu=True - keeping FEATRIX_FORCE_CPU_SINGLE_PREDICTOR=1")
            elif _user_requested_force_cpu is False:
                # User explicitly wanted GPU mode - clear env var
                os.environ.pop('FEATRIX_FORCE_CPU_SINGLE_PREDICTOR', None)
                os.environ.pop('FEATRIX_FORCE_CPU_SENTENCE_MODEL', None)
                logger.info(f"üîß User requested force_cpu=False - cleared FEATRIX_FORCE_CPU_SINGLE_PREDICTOR (GPU enabled)")
            else:
                # User didn't specify - restore original value
                if _original_force_cpu is not None:
                    os.environ['FEATRIX_FORCE_CPU_SINGLE_PREDICTOR'] = _original_force_cpu
                    logger.info(f"üîß Restored original FEATRIX_FORCE_CPU_SINGLE_PREDICTOR={_original_force_cpu}")
                else:
                    # Original was not set - clear it to enable GPU
                    os.environ.pop('FEATRIX_FORCE_CPU_SINGLE_PREDICTOR', None)
                    os.environ.pop('FEATRIX_FORCE_CPU_SENTENCE_MODEL', None)
                    logger.info(f"üîß Cleared FEATRIX_FORCE_CPU_SINGLE_PREDICTOR (was not set originally - GPU enabled)")
            
            # CRITICAL: Comprehensive dimension validation
            from featrix.neural.embedded_space import EmbeddingSpace
            from featrix.neural.dimension_validator import validate_embedding_space_dimensions, DimensionMismatchError

            if isinstance(result, EmbeddingSpace):
                try:
                    validate_embedding_space_dimensions(result, crash_on_mismatch=True)
                except DimensionMismatchError as e:
                    logger.error("=" * 80)
                    logger.error("üí• FATAL: DIMENSION MISMATCH IN EMBEDDING SPACE")
                    logger.error("=" * 80)
                    logger.error(f"{e}")
                    logger.error("This embedding space has inconsistent dimensions and CANNOT be used.")
                    logger.error("SOLUTION: Retrain the embedding space from scratch.")
                    logger.error("=" * 80)
                    raise

                # Check for __featrix_ columns in codecs (indicates old ES trained before filter)
                if hasattr(result, 'col_codecs') and result.col_codecs:
                    internal_cols = [col for col in result.col_codecs.keys() if col.startswith('__featrix')]
                    if internal_cols:
                        logger.error("=" * 80)
                        logger.error("‚ö†Ô∏è  WARNING: EmbeddingSpace has codecs for internal __featrix_ columns!")
                        logger.error("=" * 80)
                        logger.error(f"   Found: {internal_cols}")
                        logger.error("   This EmbeddingSpace was trained before the __featrix_ filter was added.")
                        logger.error("   These columns are metadata and should NOT be trained on.")
                        logger.error("   RECOMMENDATION: Retrain the EmbeddingSpace from scratch.")
                        logger.error("=" * 80)

            # CRITICAL: Set models to eval mode for inference
            # Training mode causes dropout to be active, leading to non-deterministic encodings
            # This affects: encoder AND all col_codecs (which have MLPs with dropout)
            if isinstance(result, EmbeddingSpace):
                try:
                    if hasattr(result, 'encoder') and result.encoder is not None:
                        result.encoder.eval()
                    # CRITICAL: Set ALL codecs to eval mode
                    # Codecs are nn.Module subclasses with MLPs that have dropout:
                    # - ScalarCodec: linear_mlp, log_mlp, robust_mlp, rank_mlp, etc. (all with dropout=0.1)
                    # - StringCodec: bert_projection, feature_embedding_mlp, merge_mlp (dropout=0.1)
                    # - SetCodec: has embedding MLP with dropout
                    # - Other codecs may also have dropout layers
                    # Calling .eval() on the codec propagates to all sub-modules
                    if hasattr(result, 'col_codecs') and result.col_codecs:
                        for col_name, codec in result.col_codecs.items():
                            if codec is not None and hasattr(codec, 'eval'):
                                codec.eval()
                    logger.info("‚úÖ Encoder and codecs set to eval mode for inference")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  Could not set models to eval mode: {e}")

            return result
        except (AttributeError, pickle.UnpicklingError) as e:
            error_msg = str(e).lower()
            if "persistent_load" in error_msg or "persistent id" in error_msg:
                logger.info(f"‚ÑπÔ∏è  persistent_load error detected (expected), trying Unpickler with handler as fallback")
                # If we get a persistent_load error, try with Unpickler
                f.seek(0)  # Reset file pointer
                unpickler = pickle.Unpickler(f)
                
                # Provide a handler for unknown persistent IDs
                # Protocol 0 requires ASCII strings
                def persistent_load(saved_id):
                    # Convert saved_id to ASCII string - handle all possible types
                    try:
                        # First, ensure saved_id is a string (protocol 0 requirement)
                        if saved_id is None:
                            saved_id_str = "unknown"
                            saved_id = ""  # Return empty string for None
                        elif isinstance(saved_id, bytes):
                            saved_id_str = saved_id.decode('ascii', errors='replace')
                            saved_id = saved_id_str
                        elif not isinstance(saved_id, str):
                            # Convert to string first
                            saved_id_str = str(saved_id)
                            # Then ensure it's ASCII
                            saved_id = saved_id_str.encode('ascii', errors='replace').decode('ascii')
                        else:
                            # It's already a string, ensure it's ASCII
                            saved_id_str = saved_id
                            saved_id = saved_id.encode('ascii', errors='replace').decode('ascii')
                        
                        logger.warning(f"‚ö†Ô∏è  Encountered persistent_id {saved_id_str} (type: {type(saved_id_str)}) in pickle file - returning empty string. This may cause issues if the ID is required.")
                        # Return empty ASCII string
                        return ""
                    except Exception as conv_err:
                        logger.warning(f"‚ö†Ô∏è  Error converting persistent_id to ASCII: {conv_err}, returning empty string")
                        return ""
                
                unpickler.persistent_load = persistent_load
                try:
                    result = unpickler.load()
                    logger.info(f"‚úÖ Successfully loaded with Unpickler and persistent_load handler")
                    
                    # CRITICAL: Check if we got a dict (checkpoint) instead of EmbeddingSpace
                    from featrix.neural.embedded_space import EmbeddingSpace
                    if isinstance(result, dict) and 'model' in result:
                        logger.warning(f"‚ö†Ô∏è  Loaded dict instead of EmbeddingSpace (via Unpickler) - attempting to reconstruct from checkpoint")
                        try:
                            result = _reconstruct_es_from_checkpoint_dict(result, es_path, logger)
                        except Exception as recon_err:
                            logger.error(f"‚ùå‚ùå‚ùå RECONSTRUCTION FAILED COMPLETELY (Unpickler path) ‚ùå‚ùå‚ùå")
                            logger.error(f"   Exception type: {type(recon_err).__name__}")
                            logger.error(f"   Exception message: {recon_err}")
                            logger.error(f"   Full traceback:\n{traceback.format_exc()}")
                            raise
                    
                    # CRITICAL: Restore original env var state so training can use GPU!
                    if _user_requested_force_cpu is True:
                        os.environ['FEATRIX_FORCE_CPU_SINGLE_PREDICTOR'] = '1'
                    elif _user_requested_force_cpu is False:
                        os.environ.pop('FEATRIX_FORCE_CPU_SINGLE_PREDICTOR', None)
                        os.environ.pop('FEATRIX_FORCE_CPU_SENTENCE_MODEL', None)
                    else:
                        if _original_force_cpu is not None:
                            os.environ['FEATRIX_FORCE_CPU_SINGLE_PREDICTOR'] = _original_force_cpu
                        else:
                            os.environ.pop('FEATRIX_FORCE_CPU_SINGLE_PREDICTOR', None)
                            os.environ.pop('FEATRIX_FORCE_CPU_SENTENCE_MODEL', None)
                    logger.info(f"üîß Cleared FEATRIX_FORCE_CPU_SINGLE_PREDICTOR after load (Unpickler path)")
                    
                    # CRITICAL: Comprehensive dimension validation
                    if isinstance(result, EmbeddingSpace):
                        from featrix.neural.dimension_validator import validate_embedding_space_dimensions, DimensionMismatchError
                        try:
                            validate_embedding_space_dimensions(result, crash_on_mismatch=True)
                        except DimensionMismatchError as e:
                            logger.error("=" * 80)
                            logger.error("üí• FATAL: DIMENSION MISMATCH IN EMBEDDING SPACE")
                            logger.error("=" * 80)
                            logger.error(f"{e}")
                            logger.error("This embedding space has inconsistent dimensions and CANNOT be used.")
                            logger.error("SOLUTION: Retrain the embedding space from scratch.")
                            logger.error("=" * 80)
                            raise
                    
                    return result
                except (pickle.UnpicklingError, Exception) as unpickle_err:
                    # Check if this is the protocol 0 ASCII validation error
                    # Protocol 0 validates persistent IDs before calling persistent_load handler,
                    # so we can't intercept non-ASCII IDs with a handler
                    error_msg = str(unpickle_err).lower()
                    if "persistent ids in protocol 0 must be ascii strings" in error_msg or "persistent id" in error_msg and "ascii" in error_msg:
                        logger.info(f"‚ÑπÔ∏è  Protocol 0 ASCII validation error detected - persistent_load handler cannot intercept this. Falling back to torch.load: {unpickle_err}")
                    else:
                        logger.info(f"‚ÑπÔ∏è  Unpickler with persistent_load handler also failed (expected), trying torch.load as last resort: {unpickle_err}")
                    # Last resort: try torch.load again with the file handle
                    if torch is None:
                        raise unpickle_err
                    try:
                        f.seek(0)
                        logger.info(f"üîç Last resort: trying _safe_torch_load with file handle")
                        result = _safe_torch_load(f, map_location='cpu', weights_only=False)
                        logger.info(f"‚úÖ Successfully loaded with _safe_torch_load (file handle)")
                        
                        # CRITICAL: Check if torch.load returned a dict (checkpoint) instead of EmbeddingSpace
                        # If so, we need to reconstruct it using the shared helper
                        from featrix.neural.embedded_space import EmbeddingSpace
                        if isinstance(result, dict) and 'model' in result:
                            logger.warning(f"‚ö†Ô∏è  torch.load returned dict instead of EmbeddingSpace - attempting to reconstruct from checkpoint")
                            try:
                                result = _reconstruct_es_from_checkpoint_dict(result, es_path, logger)
                                logger.info(f"‚úÖ Successfully reconstructed EmbeddingSpace from checkpoint dict (via torch.load)")
                            except Exception as recon_err:
                                logger.error(f"‚ùå‚ùå‚ùå RECONSTRUCTION FAILED COMPLETELY (torch.load path) ‚ùå‚ùå‚ùå")
                                logger.error(f"   Exception type: {type(recon_err).__name__}")
                                logger.error(f"   Exception message: {recon_err}")
                                logger.error(f"   Original es_path: {es_path}")
                                logger.error(f"   Result type: {type(result)}")
                                logger.error(f"   Result keys (if dict): {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
                                logger.error(f"   Full traceback:\n{traceback.format_exc()}")
                                raise
                        
                        # CRITICAL: Restore original env var state so training can use GPU!
                        if _user_requested_force_cpu is True:
                            os.environ['FEATRIX_FORCE_CPU_SINGLE_PREDICTOR'] = '1'
                        elif _user_requested_force_cpu is False:
                            os.environ.pop('FEATRIX_FORCE_CPU_SINGLE_PREDICTOR', None)
                            os.environ.pop('FEATRIX_FORCE_CPU_SENTENCE_MODEL', None)
                        else:
                            if _original_force_cpu is not None:
                                os.environ['FEATRIX_FORCE_CPU_SINGLE_PREDICTOR'] = _original_force_cpu
                            else:
                                os.environ.pop('FEATRIX_FORCE_CPU_SINGLE_PREDICTOR', None)
                                os.environ.pop('FEATRIX_FORCE_CPU_SENTENCE_MODEL', None)
                        logger.info(f"üîß Cleared FEATRIX_FORCE_CPU_SINGLE_PREDICTOR after load (torch.load path)")
                        
                        # CRITICAL: Comprehensive dimension validation
                        if isinstance(result, EmbeddingSpace):
                            from featrix.neural.dimension_validator import validate_embedding_space_dimensions, DimensionMismatchError
                            try:
                                validate_embedding_space_dimensions(result, crash_on_mismatch=True)
                            except DimensionMismatchError as e:
                                logger.error("=" * 80)
                                logger.error("üí• FATAL: DIMENSION MISMATCH IN EMBEDDING SPACE")
                                logger.error("=" * 80)
                                logger.error(f"{e}")
                                logger.error("This embedding space has inconsistent dimensions and CANNOT be used.")
                                logger.error("SOLUTION: Retrain the embedding space from scratch.")
                                logger.error("=" * 80)
                                raise
                        
                        return result
                    except Exception as torch_err2:
                        logger.error(f"‚ùå torch.load (file handle) also failed: {torch_err2}")
                        # Last resort: try _safe_torch_load with file path directly (might work better for some files)
                        if torch is not None:
                            try:
                                logger.info(f"üîç Final attempt: trying _safe_torch_load with file path directly")
                                result = _safe_torch_load(es_path, map_location='cpu', weights_only=False)
                                logger.info(f"‚úÖ Successfully loaded with _safe_torch_load (file path)")
                                
                                # CRITICAL: Check if torch.load returned a dict (checkpoint) instead of EmbeddingSpace
                                from featrix.neural.embedded_space import EmbeddingSpace
                                if isinstance(result, dict) and 'model' in result:
                                    logger.warning(f"‚ö†Ô∏è  torch.load returned dict instead of EmbeddingSpace - attempting to reconstruct from checkpoint")
                                    try:
                                        result = _reconstruct_es_from_checkpoint_dict(result, es_path, logger)
                                        logger.info(f"‚úÖ Successfully reconstructed EmbeddingSpace from checkpoint dict (via torch.load path)")
                                    except Exception as recon_err:
                                        logger.error(f"‚ùå‚ùå‚ùå RECONSTRUCTION FAILED COMPLETELY (torch.load path) ‚ùå‚ùå‚ùå")
                                        logger.error(f"   Exception type: {type(recon_err).__name__}")
                                        logger.error(f"   Exception message: {recon_err}")
                                        logger.error(f"   Full traceback:\n{traceback.format_exc()}")
                                        raise
                                
                                # CRITICAL: Restore original env var state so training can use GPU!
                                if _user_requested_force_cpu is True:
                                    os.environ['FEATRIX_FORCE_CPU_SINGLE_PREDICTOR'] = '1'
                                elif _user_requested_force_cpu is False:
                                    os.environ.pop('FEATRIX_FORCE_CPU_SINGLE_PREDICTOR', None)
                                    os.environ.pop('FEATRIX_FORCE_CPU_SENTENCE_MODEL', None)
                                else:
                                    if _original_force_cpu is not None:
                                        os.environ['FEATRIX_FORCE_CPU_SINGLE_PREDICTOR'] = _original_force_cpu
                                    else:
                                        os.environ.pop('FEATRIX_FORCE_CPU_SINGLE_PREDICTOR', None)
                                        os.environ.pop('FEATRIX_FORCE_CPU_SENTENCE_MODEL', None)
                                logger.info(f"üîß Cleared FEATRIX_FORCE_CPU_SINGLE_PREDICTOR after load (torch.load path)")
                                
                                # CRITICAL: Comprehensive dimension validation
                                if isinstance(result, EmbeddingSpace):
                                    from featrix.neural.dimension_validator import validate_embedding_space_dimensions, DimensionMismatchError
                                    try:
                                        validate_embedding_space_dimensions(result, crash_on_mismatch=True)
                                    except DimensionMismatchError as e:
                                        logger.error("=" * 80)
                                        logger.error("üí• FATAL: DIMENSION MISMATCH IN EMBEDDING SPACE")
                                        logger.error("=" * 80)
                                        logger.error(f"{e}")
                                        logger.error("This embedding space has inconsistent dimensions and CANNOT be used.")
                                        logger.error("SOLUTION: Retrain the embedding space from scratch.")
                                        logger.error("=" * 80)
                                        raise
                                
                                return result
                            except Exception as torch_err3:
                                logger.error(f"‚ùå torch.load (file path) also failed: {torch_err3}")
                                # Check for session manager errors (old pickle files with session references)
                                torch_err2_str = str(torch_err2).lower()
                                torch_err3_str = str(torch_err3).lower()
                                if "session" in torch_err2_str or "session" in torch_err3_str:
                                    error_msg = (
                                        f"Failed to load {es_path}: This appears to be an old pickle file that references "
                                        f"session manager objects that no longer exist. "
                                        f"Original pickle error: {unpickle_err}. "
                                        f"torch.load error: {torch_err3}. "
                                        f"This file was likely created with an older version of the code and cannot be loaded. "
                                        f"You may need to regenerate this embedding space by re-training."
                                    )
                                    logger.error(error_msg)
                                    raise ValueError(error_msg) from torch_err3
                                # If this is a protocol 0 ASCII error, provide a more helpful message
                                if "persistent ids in protocol 0 must be ascii strings" in str(unpickle_err).lower():
                                    error_msg = (
                                        f"Failed to load {es_path}: Protocol 0 pickle file contains non-ASCII persistent IDs. "
                                        f"All loading methods (pickle.load, Unpickler with handler, torch.load) failed. "
                                        f"Original error: {unpickle_err}. "
                                        f"torch.load errors: {torch_err2}, {torch_err3}. "
                                        f"This file may need to be re-saved with a higher pickle protocol."
                                    )
                                    logger.error(error_msg)
                                    raise ValueError(error_msg) from torch_err3
                                raise unpickle_err from torch_err3
                        raise unpickle_err from torch_err2
            raise

