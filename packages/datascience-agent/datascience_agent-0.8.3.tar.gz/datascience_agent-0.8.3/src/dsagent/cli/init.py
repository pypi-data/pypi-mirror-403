"""Setup wizard for DSAgent configuration.

This module provides the `dsagent init` command for interactive
configuration setup.
"""

from __future__ import annotations

from pathlib import Path

from rich.console import Console
from rich.prompt import Prompt, Confirm


def run_init(args) -> int:
    """Run the setup wizard.

    Args:
        args: Namespace with force flag

    Returns:
        Exit code (0 for success)
    """
    console = Console()

    config_dir = Path.home() / ".dsagent"
    env_file = config_dir / ".env"
    mcp_file = config_dir / "mcp.yaml"

    # Check if config already exists
    if config_dir.exists() and not args.force:
        console.print(f"[yellow]Configuration already exists at {config_dir}[/yellow]")
        if not Confirm.ask("Overwrite existing configuration?"):
            console.print("Aborted.")
            return 0

    console.print()
    console.print("[bold cyan]DSAgent Setup Wizard[/bold cyan]")
    console.print()

    # Create config directory
    config_dir.mkdir(parents=True, exist_ok=True)

    # Select LLM provider
    console.print("[bold]Step 1: LLM Provider[/bold]")
    provider = Prompt.ask(
        "Select your LLM provider",
        choices=["openai", "anthropic", "google", "local", "litellm"],
        default="openai"
    )

    env_lines = []

    if provider == "openai":
        api_key = Prompt.ask("Enter your OpenAI API key", password=True)
        env_lines.append(f"OPENAI_API_KEY={api_key}")
        env_lines.append("LLM_MODEL=gpt-4o")

    elif provider == "anthropic":
        api_key = Prompt.ask("Enter your Anthropic API key", password=True)
        env_lines.append(f"ANTHROPIC_API_KEY={api_key}")
        env_lines.append("LLM_MODEL=claude-sonnet-4-5")

    elif provider == "google":
        api_key = Prompt.ask("Enter your Google API key", password=True)
        env_lines.append(f"GOOGLE_API_KEY={api_key}")
        env_lines.append("LLM_MODEL=gemini/gemini-2.5-flash")

    elif provider == "local":
        console.print("Using Ollama for local models")
        env_lines.append("LLM_MODEL=ollama/llama3")

    elif provider == "litellm":
        proxy_url = Prompt.ask(
            "Enter LiteLLM proxy URL",
            default="http://localhost:4000/v1"
        )
        api_key = Prompt.ask("Enter proxy API key (if required)", password=True, default="")
        model = Prompt.ask("Enter default model name", default="gpt-4o")
        env_lines.append(f"LLM_API_BASE={proxy_url}")
        if api_key:
            env_lines.append(f"OPENAI_API_KEY={api_key}")
        env_lines.append(f"LLM_MODEL={model}")

    console.print()

    # MCP tools setup
    console.print("[bold]Step 2: MCP Tools (optional)[/bold]")
    setup_mcp = Confirm.ask("Would you like to configure MCP tools?", default=False)

    mcp_servers = []
    if setup_mcp:
        console.print()
        console.print("Available templates:")
        console.print("  1. brave-search - Web search via Brave Search API")
        console.print("  2. filesystem   - Local file system access")
        console.print("  3. github       - GitHub repository access")
        console.print()

        if Confirm.ask("Add Brave Search?", default=True):
            brave_key = Prompt.ask("Enter your Brave Search API key", password=True)
            env_lines.append(f"BRAVE_API_KEY={brave_key}")
            mcp_servers.append({
                "name": "brave_search",
                "transport": "stdio",
                "command": ["npx", "-y", "@modelcontextprotocol/server-brave-search"],
                "env": {"BRAVE_API_KEY": "${BRAVE_API_KEY}"},
            })

        if Confirm.ask("Add Filesystem access?", default=False):
            mcp_servers.append({
                "name": "filesystem",
                "transport": "stdio",
                "command": ["npx", "-y", "@modelcontextprotocol/server-filesystem", str(Path.home())],
            })

    # Write .env file
    console.print()
    console.print("[bold]Writing configuration...[/bold]")

    with open(env_file, "w") as f:
        f.write("# DSAgent Configuration\n")
        f.write("# Generated by dsagent init\n\n")
        for line in env_lines:
            f.write(line + "\n")

    console.print(f"  [green]Created {env_file}[/green]")

    # Write mcp.yaml if servers configured
    if mcp_servers:
        import yaml
        with open(mcp_file, "w") as f:
            yaml.dump({"servers": mcp_servers}, f, default_flow_style=False)
        console.print(f"  [green]Created {mcp_file}[/green]")

    console.print()
    console.print("[bold green]Setup complete![/bold green]")
    console.print()
    console.print("You can now run:")
    console.print("  [cyan]dsagent[/cyan]              # Start interactive chat")
    console.print("  [cyan]dsagent run \"task\"[/cyan]  # Run a one-shot task")
    if mcp_servers:
        console.print(f"  [cyan]dsagent chat --mcp-config {mcp_file}[/cyan]  # Chat with MCP tools")

    return 0
