import numpy as np
import toml
import json
from typing import Callable, List, Any
from pathlib import Path

from deepx_dock.CONSTANT import PERIODIC_TABLE_SYMBOL_TO_INDEX

# ==============================================================================
# Basic
# ==============================================================================
def load_json_file(file_path):
    with open(file_path) as f:
        return json.load(f)


def dump_json_file(file_path, dict_content):
    with open(file_path, "w") as f:
        json.dump(dict_content, f)


def load_toml_file(file_path):
    with open(file_path, "r") as f:
        config = toml.load(f)
    return config


def dump_toml_file(file_path, dict_content):
    with open(file_path, "w") as f:
        toml.dump(dict_content, f)


# ==============================================================================
# POSCAR
# ==============================================================================
def load_poscar_file(file_path):
    with open(file_path, "r") as f:
        lines = f.readlines()
    # Scale for lattice vector and cartesian coordinates
    scale = [float(x) for x in lines[1].split()]
    scale = np.array([scale[0],scale[0],scale[0]] if len(scale) == 1 else scale)
    assert scale[0] > 0.0 and scale[1] > 0.0 and scale[2] > 0.0, f"in {file_path}, the second line must be positive, but got {scale}."
    # Lattice vector
    lat = np.array([[float(x) for x in line.split()[:3]] for line in lines[2:5]])
    lat *= scale[None, :]
    # Element symbols and number of atoms
    elem_symbols_unique = lines[5].split()
    elem_counts = [int(num) for num in lines[6].split()]
    assert elem_symbols_unique[0].isalpha(), "Invalid POSCAR format, the 6th line should be elements"
    assert len(elem_symbols_unique) == len(elem_counts), f"in {file_path}, the 6th line (element symbols) must has the same length as the 7th line (number of atoms), but got {len(elem_symbols_unique)} and {len(elem_counts)}."
    # Cartesian or Direct coordinates
    coords_mode = "Cartesian" if (lines[7][0].lower() == 'c' or lines[7][0].lower() == 'k') else "Direct"
    # Coordinates
    assert len(lines) >= 8 + sum(elem_counts), f"in {file_path}, the number of lines must be at least 8 + {sum(elem_counts)}, but got {len(lines)}."
    _coords = np.array([[float(x) for x in line.split()[:3]] for line in lines[8:8 + sum(elem_counts)]])
    if coords_mode == "Cartesian":
        cart_coords = _coords * scale[None, :]
        frac_coords = cart_coords @ np.linalg.inv(lat)
    else:
        frac_coords = _coords
        cart_coords = _coords @ lat

    atomic_numbers = []
    for symbol, count in zip(elem_symbols_unique, elem_counts):
        if symbol not in PERIODIC_TABLE_SYMBOL_TO_INDEX:
            raise KeyError(f"unknown element symbol: {symbol}")

        z = PERIODIC_TABLE_SYMBOL_TO_INDEX[symbol]
        atomic_numbers.extend([z] * count)
    atomic_numbers = np.array(atomic_numbers, dtype=int)

    return {
        "lattice": lat,
        "elements_unique": elem_symbols_unique,
        "elements_counts": elem_counts,
        "atomic_numbers": atomic_numbers,
        "cart_coords": cart_coords,
        "frac_coords": frac_coords,
    }


def dump_poscar_file(file_path, structure, direct=False, dump_decimals=-1):
    _lat = structure["lattice"]
    _coords = structure["frac_coords"] if direct else structure["cart_coords"]
    elem_symbol_string = " ".join(structure["elements_unique"])
    elem_num_string = " ".join([str(x) for x in structure["elements_counts"]])
    if dump_decimals > 0:
        lat_save = np.round(_lat, decimals=dump_decimals)
        coords_save = np.round(_coords, decimals=dump_decimals)
    else:
        lat_save = _lat
        coords_save = _coords
    lines = []
    lines.append("POSCAR generated by DeepH-dock \n")
    lines.append("1.0\n")
    lines.append(f"  {lat_save[0][0]}  {lat_save[0][1]}  {lat_save[0][2]}\n")
    lines.append(f"  {lat_save[1][0]}  {lat_save[1][1]}  {lat_save[1][2]}\n")
    lines.append(f"  {lat_save[2][0]}  {lat_save[2][1]}  {lat_save[2][2]}\n")
    lines.append(f"{elem_symbol_string}\n")
    lines.append(f"{elem_num_string}\n")
    lines.append(f"{"Direct" if direct else "Cartesian"}\n")
    for coord in coords_save:
        lines.append(f"    {coord[0]}  {coord[1]}  {coord[2]}\n")
    # Save POSCAR
    with open(file_path, "w") as fw:
        fw.writelines(lines)


# ==============================================================================
# DFT Dir Lister
# ==============================================================================
DEEPX_NECESSARY_FILES = {"POSCAR", "info.json"}

def _defalult_val_check(root_dir: Path, prev_dirname: Path):
    all_files = [str(v.name) for v in root_dir.iterdir()]
    if DEEPX_NECESSARY_FILES.issubset(set(all_files)):
        yield prev_dirname
    else:
        print(f"Skip {prev_dirname} because of missing necessary files.")

def get_data_dir_lister(
    root_dir: Path, depth: int,
    validation_check: Callable = _defalult_val_check,
    prev_dirname: Path | None = None
):
    if prev_dirname is None:
        prev_dirname = Path(".")
    if depth < 0:
        if root_dir.is_dir():
            yield from validation_check(root_dir, prev_dirname)
    else:
        for subdir in root_dir.iterdir():
            subdir_path = root_dir / subdir.name
            next_prev_dirname = prev_dirname / subdir.name
            if subdir_path.is_dir():
                yield from get_data_dir_lister(
                    subdir_path, depth-1, validation_check, next_prev_dirname
                )


# ==============================================================================
# Misc
# ==============================================================================
def list_A_contained_B(A: List[Any], B: List[Any]) -> bool:
    from collections import Counter
    cA = Counter(A)
    cB = Counter(B)
    return all(cB[key] <= cA[key] for key in cB)

