"""
æµ‹è¯•å†…å­˜ç›‘æ§å’Œæ€§èƒ½è°ƒä¼˜

å±•ç¤ºå¦‚ä½•ç›‘æ§å†…å­˜ä½¿ç”¨ã€ä¼˜åŒ–æ€§èƒ½å’Œè°ƒè¯•é—®é¢˜
"""

import sys
import os

# Set UTF-8 encoding for Windows console
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import never_jscore
import time
import gc


def test_basic_memory_monitoring():
    """æµ‹è¯•åŸºæœ¬å†…å­˜ç›‘æ§"""
    ctx = never_jscore.Context()

    # æ‰§è¡Œä¸€äº›æ“ä½œ
    for i in range(10):
        ctx.evaluate(f"var x{i} = new Array({i * 1000}).fill({i})")

    # è§¦å‘åƒåœ¾å›æ”¶
    ctx.gc()

    print("âœ“ æ‰‹åŠ¨è§¦å‘ GC æˆåŠŸ")


def test_context_memory_leak_detection():
    """æ£€æµ‹ Context å†…å­˜æ³„æ¼"""
    import tracemalloc

    # å¯åŠ¨å†…å­˜è·Ÿè¸ª
    tracemalloc.start()

    # è®°å½•åˆå§‹å†…å­˜
    snapshot1 = tracemalloc.take_snapshot()

    # åˆ›å»ºå¹¶åˆ é™¤ 100 ä¸ª Contextï¼ˆæ­£ç¡®æ–¹å¼ï¼‰
    for i in range(100):
        ctx = never_jscore.Context()
        ctx.evaluate("1 + 1")
        del ctx  # æ­£ç¡®æ¸…ç†

    # å¼ºåˆ¶ Python GC
    gc.collect()

    # è®°å½•æœ€ç»ˆå†…å­˜
    snapshot2 = tracemalloc.take_snapshot()

    # è®¡ç®—å†…å­˜å¢é•¿
    top_stats = snapshot2.compare_to(snapshot1, 'lineno')
    total_diff = sum(stat.size_diff for stat in top_stats)

    print(f"âœ“ åˆ›å»ºå¹¶æ¸…ç† 100 ä¸ª Context")
    print(f"  - å†…å­˜å¢é•¿: {total_diff / 1024:.2f} KB")

    # å¦‚æœæ­£ç¡®æ¸…ç†ï¼Œå†…å­˜å¢é•¿åº”è¯¥å¾ˆå°
    assert total_diff < 10 * 1024 * 1024, "å†…å­˜æ³„æ¼æ£€æµ‹"

    tracemalloc.stop()


def test_large_data_processing():
    """æµ‹è¯•å¤§æ•°æ®å¤„ç†"""
    ctx = never_jscore.Context()

    # åˆ›å»ºå¤§æ•°ç»„
    ctx.compile("""
        function createLargeArray(size) {
            const arr = [];
            for (let i = 0; i < size; i++) {
                arr.push({
                    id: i,
                    data: 'x'.repeat(100)
                });
            }
            return arr.length;
        }
    """)

    start = time.time()
    result = ctx.call("createLargeArray", [10000])
    elapsed = time.time() - start

    assert result == 10000

    print(f"âœ“ å¤„ç†å¤§æ•°æ®ï¼ˆ10000 é¡¹ï¼‰")
    print(f"  - è€—æ—¶: {elapsed*1000:.2f}ms")

    # æ¸…ç†å†…å­˜
    ctx.gc()
    del ctx


def test_batch_processing_with_gc():
    """æ‰¹é‡å¤„ç† + å®šæœŸ GC"""
    ctx = never_jscore.Context()
    ctx.compile("""
        function processItem(item) {
            const result = [];
            for (let i = 0; i < 100; i++) {
                result.push(md5(String(item) + String(i)));
            }
            return result.length;
        }
    """)

    total_processed = 0
    batch_size = 100

    start = time.time()

    for batch in range(10):  # 10 æ‰¹ï¼Œæ¯æ‰¹ 100 é¡¹
        for i in range(batch_size):
            ctx.call("processItem", [batch * batch_size + i])
            total_processed += 1

        # æ¯æ‰¹å¤„ç†å®Œåè§¦å‘ GC
        ctx.gc()

    elapsed = time.time() - start

    print(f"âœ“ æ‰¹é‡å¤„ç† + GC")
    print(f"  - æ€»è®¡: {total_processed} é¡¹")
    print(f"  - è€—æ—¶: {elapsed*1000:.2f}ms")
    print(f"  - å¹³å‡: {elapsed*1000/total_processed:.3f}ms/é¡¹")

    del ctx



def test_get_heap_statistics():
    """æµ‹è¯• V8 å †ç»Ÿè®¡ä¿¡æ¯"""
    ctx = never_jscore.Context()

    # åˆ›å»ºä¸€äº›å¯¹è±¡å ç”¨å†…å­˜
    ctx.evaluate("""
        const largeArray = [];
        for (let i = 0; i < 10000; i++) {
            largeArray.push({
                id: i,
                data: 'x'.repeat(100),
                nested: { value: i }
            });
        }
    """)

    # è·å–å †ç»Ÿè®¡ä¿¡æ¯
    heap_stats = ctx.get_heap_statistics()

    # éªŒè¯ç»Ÿè®¡ä¿¡æ¯å­—æ®µ
    assert 'total_heap_size' in heap_stats
    assert 'used_heap_size' in heap_stats
    assert 'heap_size_limit' in heap_stats
    assert 'total_physical_size' in heap_stats
    assert 'malloced_memory' in heap_stats
    assert 'external_memory' in heap_stats
    assert 'number_of_native_contexts' in heap_stats

    print(f"\n=== V8 å †ç»Ÿè®¡ä¿¡æ¯ ===")
    print(f"  æ€»å †å¤§å°:       {heap_stats['total_heap_size'] / 1024 / 1024:.2f} MB")
    print(f"  å·²ä½¿ç”¨å †:       {heap_stats['used_heap_size'] / 1024 / 1024:.2f} MB")
    print(f"  å †å¤§å°é™åˆ¶:     {heap_stats['heap_size_limit'] / 1024 / 1024:.2f} MB")
    print(f"  ç‰©ç†å†…å­˜å¤§å°:   {heap_stats['total_physical_size'] / 1024 / 1024:.2f} MB")
    print(f"  Malloc å†…å­˜:    {heap_stats['malloced_memory'] / 1024 / 1024:.2f} MB")
    print(f"  å¤–éƒ¨å†…å­˜:       {heap_stats['external_memory'] / 1024:.2f} KB")
    print(f"  Native Context: {heap_stats['number_of_native_contexts']}")
    print(f"  ä½¿ç”¨ç‡:         {heap_stats['used_heap_size'] / heap_stats['total_heap_size'] * 100:.1f}%")

    del ctx


def test_take_heap_snapshot():
    """æµ‹è¯• V8 å †å¿«ç…§å¯¼å‡º"""
    import os

    ctx = never_jscore.Context()

    # åˆ›å»ºä¸€äº›å¯¹è±¡
    ctx.evaluate("""
        globalThis.testObjects = [];
        for (let i = 0; i < 1000; i++) {
            testObjects.push({
                id: i,
                name: `Object_${i}`,
                data: new Array(100).fill(i)
            });
        }
    """)

    # å¯¼å‡ºå †å¿«ç…§
    snapshot_file = "heap_snapshot_test.heapsnapshot"

    try:
        ctx.take_heap_snapshot(snapshot_file)

        # éªŒè¯æ–‡ä»¶å·²åˆ›å»º
        assert os.path.exists(snapshot_file), "å¿«ç…§æ–‡ä»¶åº”è¯¥è¢«åˆ›å»º"

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(snapshot_file)
        assert file_size > 0, "å¿«ç…§æ–‡ä»¶ä¸åº”è¯¥ä¸ºç©º"

        print(f"\n=== å †å¿«ç…§å¯¼å‡º ===")
        print(f"  æ–‡ä»¶å: {snapshot_file}")
        print(f"  å¤§å°:   {file_size / 1024:.2f} KB")
        print(f"  âœ“ å¿«ç…§å·²å¯¼å‡º")
        print(f"\n  ä½¿ç”¨æ–¹æ³•:")
        print(f"  1. æ‰“å¼€ Chrome DevTools")
        print(f"  2. è¿›å…¥ Memory æ ‡ç­¾")
        print(f"  3. ç‚¹å‡» 'Load' åŠ è½½å¿«ç…§æ–‡ä»¶")
        print(f"  4. åˆ†æå†…å­˜ä½¿ç”¨æƒ…å†µ")

    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(snapshot_file):
            os.remove(snapshot_file)
        del ctx


def test_heap_snapshot_memory_leak_detection():
    """å®æˆ˜ï¼šä½¿ç”¨å †å¿«ç…§æ£€æµ‹å†…å­˜æ³„æ¼"""
    import os

    ctx = never_jscore.Context()

    # ç¬¬ä¸€æ¬¡å¿«ç…§ï¼ˆåŸºå‡†ï¼‰
    snapshot1 = "snapshot_before.heapsnapshot"
    ctx.take_heap_snapshot(snapshot1)
    heap_before = ctx.get_heap_statistics()

    # åˆ›å»ºå¤§é‡å¯¹è±¡ï¼ˆæ¨¡æ‹Ÿå†…å­˜æ³„æ¼ï¼‰
    ctx.evaluate("""
        globalThis.leakedObjects = [];
        for (let i = 0; i < 5000; i++) {
            leakedObjects.push({
                id: i,
                data: new Array(200).fill(i),
                circular: null
            });
        }
        // åˆ›å»ºå¾ªç¯å¼•ç”¨
        leakedObjects.forEach((obj, i) => {
            obj.circular = leakedObjects[(i + 1) % leakedObjects.length];
        });
    """)

    # ç¬¬äºŒæ¬¡å¿«ç…§ï¼ˆæ³„æ¼åï¼‰
    snapshot2 = "snapshot_after.heapsnapshot"
    ctx.take_heap_snapshot(snapshot2)
    heap_after = ctx.get_heap_statistics()

    # åˆ†æå†…å­˜å¢é•¿
    memory_growth = heap_after['used_heap_size'] - heap_before['used_heap_size']

    print(f"\n=== å†…å­˜æ³„æ¼æ£€æµ‹ ===")
    print(f"  å‰: {heap_before['used_heap_size'] / 1024 / 1024:.2f} MB")
    print(f"  å: {heap_after['used_heap_size'] / 1024 / 1024:.2f} MB")
    print(f"  å¢é•¿: {memory_growth / 1024 / 1024:.2f} MB")
    print(f"\n  å¿«ç…§å¯¹æ¯”:")
    print(f"  1. {snapshot1} ({os.path.getsize(snapshot1) / 1024:.2f} KB)")
    print(f"  2. {snapshot2} ({os.path.getsize(snapshot2) / 1024:.2f} KB)")
    print(f"\n  åˆ†ææ­¥éª¤:")
    print(f"  1. åœ¨ Chrome DevTools ä¸­åŠ è½½ä¸¤ä¸ªå¿«ç…§")
    print(f"  2. ä½¿ç”¨ 'Comparison' è§†å›¾å¯¹æ¯”")
    print(f"  3. æŸ¥æ‰¾ 'leakedObjects' ç›¸å…³å¯¹è±¡")
    print(f"  4. åˆ†æå¾ªç¯å¼•ç”¨é“¾")

    # æ¸…ç†
    try:
        os.remove(snapshot1)
        os.remove(snapshot2)
    except:
        pass

    del ctx


def test_heap_statistics_monitoring():
    """å®æˆ˜ï¼šç›‘æ§æ‰¹é‡å¤„ç†çš„å†…å­˜ä½¿ç”¨"""
    ctx = never_jscore.Context()
    ctx.compile("""
        function simpleHash(str) {
            let hash = 0;
            for (let i = 0; i < str.length; i++) {
                hash = ((hash << 5) - hash) + str.charCodeAt(i);
                hash = hash & hash;
            }
            return Math.abs(hash).toString(16).padStart(8, '0');
        }

        function heavyComputation(n) {
            const temp = [];
            for (let i = 0; i < n; i++) {
                temp.push(simpleHash(String(i)));
            }
            return temp.length;
        }
    """)

    print(f"\n=== æ‰¹é‡å¤„ç†å†…å­˜ç›‘æ§ ===")

    batches = 5
    batch_size = 500

    for batch in range(batches):
        # å¤„ç†å‰ç»Ÿè®¡
        before = ctx.get_heap_statistics()

        # æ‰§è¡Œæ‰¹é‡å¤„ç†
        ctx.call("heavyComputation", [batch_size])

        # å¤„ç†åç»Ÿè®¡
        after = ctx.get_heap_statistics()

        growth = after['used_heap_size'] - before['used_heap_size']

        print(f"  æ‰¹æ¬¡ {batch + 1}:")
        print(f"    ä½¿ç”¨: {after['used_heap_size'] / 1024 / 1024:.2f} MB")
        print(f"    å¢é•¿: {growth / 1024:.2f} KB")

        # æ¯ 2 æ‰¹è§¦å‘ GC
        if batch % 2 == 1:
            ctx.gc()
            gc_after = ctx.get_heap_statistics()
            freed = after['used_heap_size'] - gc_after['used_heap_size']
            print(f"    GC é‡Šæ”¾: {freed / 1024:.2f} KB")

    del ctx


def test_performance_profiling():
    """æ€§èƒ½åˆ†æ"""
    ctx = never_jscore.Context()

    # æµ‹è¯•ä¸åŒæ“ä½œçš„æ€§èƒ½
    operations = {
        "ç®€å•è®¡ç®—": lambda: ctx.evaluate("1 + 1"),
        "å­—ç¬¦ä¸²æ“ä½œ": lambda: ctx.evaluate("'hello'.toUpperCase()"),
        "æ•°ç»„æ“ä½œ": lambda: ctx.evaluate("[1,2,3,4,5].map(x => x * 2)"),
        "å¯¹è±¡æ“ä½œ": lambda: ctx.evaluate("({a: 1, b: 2, c: 3})"),
        "MD5 å“ˆå¸Œ": lambda: ctx.evaluate("md5('hello')"),
        "Base64 ç¼–ç ": lambda: ctx.evaluate("btoa('hello')"),
    }

    print(f"\n=== æ€§èƒ½åˆ†æï¼ˆå„æ“ä½œ 1000 æ¬¡ï¼‰===")

    for name, operation in operations.items():
        start = time.time()
        for _ in range(1000):
            operation()
        elapsed = time.time() - start

        print(f"  {name:12} {elapsed*1000:7.2f}ms ({elapsed*1000000/1000:6.2f}Î¼s/æ¬¡)")

    del ctx


def test_context_creation_overhead():
    """æµ‹è¯• Context åˆ›å»ºå¼€é”€"""
    iterations = 50

    # æµ‹è¯•åˆ›å»º + åˆ é™¤çš„å¼€é”€
    start = time.time()
    for _ in range(iterations):
        ctx = never_jscore.Context()
        del ctx
    create_time = time.time() - start

    # æµ‹è¯•å¤ç”¨çš„æ€§èƒ½
    ctx = never_jscore.Context()
    start = time.time()
    for _ in range(iterations):
        ctx.evaluate("1 + 1")
    reuse_time = time.time() - start
    del ctx

    print(f"\n=== Context å¼€é”€åˆ†æï¼ˆ{iterations} æ¬¡ï¼‰===")
    print(f"  åˆ›å»º+åˆ é™¤: {create_time*1000:.2f}ms ({create_time*1000/iterations:.2f}ms/æ¬¡)")
    print(f"  å¤ç”¨æ‰§è¡Œ:  {reuse_time*1000:.2f}ms ({reuse_time*1000/iterations:.2f}ms/æ¬¡)")
    print(f"  é€Ÿåº¦æå‡:  {create_time/reuse_time:.1f}x")


def test_enable_logging():
    """æµ‹è¯•å¯ç”¨æ—¥å¿—è°ƒè¯•"""
    print(f"\n=== å¯ç”¨è°ƒè¯•æ—¥å¿— ===")

    # åˆ›å»ºå¸¦æ—¥å¿—çš„ Context
    ctx = never_jscore.Context(enable_logging=True)

    print("  æ‰§è¡Œæ“ä½œï¼ˆä¼šè¾“å‡º Rust æ—¥å¿—ï¼‰:")
    ctx.evaluate("console.log('Hello from JS')")
    ctx.compile("function add(a, b) { return a + b; }")
    ctx.call("add", [1, 2])

    del ctx

    print("âœ“ æ—¥å¿—åŠŸèƒ½æ­£å¸¸")


def test_memory_efficient_large_dataset():
    """å†…å­˜é«˜æ•ˆçš„å¤§æ•°æ®é›†å¤„ç†"""
    def process_chunk(chunk_id, chunk_size):
        """å¤„ç†å•ä¸ªæ•°æ®å—"""
        ctx = never_jscore.Context()
        ctx.compile("""
            function simpleHash(str) {
                let hash = 0;
                for (let i = 0; i < str.length; i++) {
                    hash = ((hash << 5) - hash) + str.charCodeAt(i);
                    hash = hash & hash;
                }
                return Math.abs(hash).toString(16).padStart(8, '0');
            }

            function processData(start, count) {
                const results = [];
                for (let i = start; i < start + count; i++) {
                    results.push(simpleHash(String(i)));
                }
                return results.length;
            }
        """)

        result = ctx.call("processData", [chunk_id * chunk_size, chunk_size])
        del ctx  # ç«‹å³é‡Šæ”¾
        return result

    # å¤„ç† 10 ä¸ªå—ï¼Œæ¯å— 100 é¡¹
    chunks = 10
    chunk_size = 100
    total = 0

    start = time.time()

    for i in range(chunks):
        processed = process_chunk(i, chunk_size)
        total += processed

        # å¼ºåˆ¶ Python GC
        if i % 3 == 0:
            gc.collect()

    elapsed = time.time() - start

    print(f"\n=== å†…å­˜é«˜æ•ˆå¤„ç† ===")
    print(f"  å¤„ç†: {total} é¡¹")
    print(f"  è€—æ—¶: {elapsed*1000:.2f}ms")
    print(f"  ç­–ç•¥: åˆ†å—å¤„ç† + å³æ—¶é‡Šæ”¾ Context")


if __name__ == "__main__":
    print("=" * 60)
    print("æµ‹è¯•å†…å­˜ç›‘æ§å’Œæ€§èƒ½è°ƒä¼˜")
    print("=" * 60)

    test_get_heap_statistics()
    test_take_heap_snapshot()
    test_heap_snapshot_memory_leak_detection()
    test_heap_statistics_monitoring()
    test_memory_efficient_large_dataset()

    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰å†…å­˜å’Œæ€§èƒ½æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 60)
    print("\nğŸ’¡ å…³é”®è¦ç‚¹ï¼š")
    print("   1. ä½¿ç”¨ get_heap_statistics() ç›‘æ§ V8 å †å†…å­˜")
    print("   2. ä½¿ç”¨ take_heap_snapshot() å¯¼å‡ºå¿«ç…§åˆ° Chrome DevTools")
    print("   3. å®šæœŸè°ƒç”¨ ctx.gc() æ¸…ç†å†…å­˜")
    print("   4. ä¼˜å…ˆå¤ç”¨ Context è€Œä¸æ˜¯é‡å¤åˆ›å»º")
    print("   5. ä½¿ç”¨ ThreadPoolExecutor è¿›è¡Œå¹¶è¡Œå¤„ç†")
    print("   6. å¯ç”¨æ—¥å¿— (enable_logging=True) è¿›è¡Œè°ƒè¯•")
