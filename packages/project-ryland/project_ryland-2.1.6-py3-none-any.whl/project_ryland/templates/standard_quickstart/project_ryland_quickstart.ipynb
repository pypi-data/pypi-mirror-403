{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Project Ryland Quickstart\n",
    "#### by Justin Vinh | 2025.01.29 | Lindvall Lab @ Dana-Farber Cancer Institute\n",
    "#### GitHub Site (https://github.com/justin-vinh/project_ryland)\n",
    "####\n",
    "This template serves as an easy way to get off the ground quickly with the\n",
    "Project Ryland package. Please read the instructions on GitHub for full use\n",
    "instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_ryland.llm_utils import llm_generation_utils as llm\n",
    "from llm_prompt_gallery.keyword_mappings import example_2_prompt_variables\n",
    "\n",
    "from llm_prompt_gallery import prompt_structs as ps\n",
    "\n",
    "# ==============================================================================\n",
    "# Put in your API details here:\n",
    "ENDPOINT =      \"<endpoint>\"\n",
    "ENTRA_SCOPE =   \"https://cognitiveservices.azure.com/.default\"\n",
    "model_name =    \"gpt-5\"\n",
    "\n",
    "# Put in your prompt details here:\n",
    "use_prompt_gallery = True                       # True/False\n",
    "gallery_path =  \"llm_prompt_gallery\"            # If using the prompt library\n",
    "\n",
    "gallery_prompt = \"example_1_prompt\"             # Prompt name from YAML gallery\n",
    "prompt_text =   \"\"                              # If NOT using the prompt library\n",
    "prompt_struct = ps.AssessCancerDiagnosis        # Prompt struct to force output\n",
    "user_vars =     example_2_prompt_variables      # If using prompt with variables\n",
    "\n",
    "input_file =    \"synthetic_clinical_notes.csv\"  # File path to input CSV file\n",
    "text_column =   \"NOTE_TEXT\"                     # Column to analyze with API\n",
    "\n",
    "# Put in your output details here:\n",
    "output_directory = \"output_tests\"               # path to output folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the API\n",
    "LLM_wrapper = llm.LLM_wrapper(\n",
    "    model_name,\n",
    "    endpoint=ENDPOINT,\n",
    "    entra_scope=ENTRA_SCOPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the LLM generation\n",
    "df = LLM_wrapper.process_text_data(\n",
    "    # Essential to specify\n",
    "    input_file_path=input_file,\n",
    "    text_column=text_column,\n",
    "    format_class=prompt_struct,\n",
    "    use_prompt_gallery=use_prompt_gallery,\n",
    "\n",
    "    # Specify if using the prompt gallery, else put None\n",
    "    prompt_gallery_path=gallery_path,\n",
    "    prompt_to_get=gallery_prompt,\n",
    "    user_prompt_vars=user_vars,\n",
    "\n",
    "    # Specify if NOT using the prompt gallery, else put None\n",
    "    prompt_text=prompt_text,\n",
    "\n",
    "    # Optional to specify\n",
    "    output_dir=output_directory,\n",
    "    flatten=True,\n",
    "    sample_mode=True,\n",
    "    resume=True,\n",
    "    keep_checkpoints=False,\n",
    "    save_every=10,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
