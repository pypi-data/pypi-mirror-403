//! SIMD-accelerated operations for SciRS2
//!
//! This module provides highly optimized SIMD implementations for numerical operations.
//! The module is organized into focused sub-modules for better maintainability:
//!
//! ## Module Organization
//!
//! ### Foundation (Layer 1)
//! - [`traits`]: Core SIMD trait definitions
//! - [`detect`]: CPU feature detection and capability management
//!
//! ### Core Operations (Layer 2)
//! - [`basic`]: Basic arithmetic (add, min, max)
//! - [`arithmetic`]: Advanced arithmetic (mul, div, sub, scalar ops)
//! - [`dot`]: Dot product and FMA operations
//!
//! ### Reductions & Statistics (Layer 3)
//! - [`reductions`]: Statistical reductions (sum, mean, variance, std, min, max)
//!
//! ### Vector Computations (Layer 4)
//! - [`norms`]: Vector norms (L1, L2, Linf)
//! - [`distances`]: Distance metrics (Euclidean, Manhattan, Chebyshev)
//! - [`similarity`]: Similarity metrics (cosine)
//! - [`weighted`]: Weighted operations
//!
//! ### Specialized Operations (Layer 5)
//! - [`indexing`]: Indexing operations (argmin, argmax, clip)
//! - [`activation`]: Activation functions (ReLU, softmax, log_sum_exp)
//! - [`cumulative`]: Cumulative operations (cumsum, cumprod, diff)
//! - [`normalization`]: Batch/layer normalization (Phase 79)
//! - [`preprocessing`]: Data preprocessing (normalize, standardize)
//! - [`rounding`]: Rounding operations (floor, ceil, round, trunc)
//! - [`transcendental`]: Transcendental functions (exp, sin, cos, ln, activations) (Phases 75-78)
//! - [`transpose`]: Cache-optimized blocked transpose
//! - [`unary`]: Unary operations (abs, sqrt, sign)
//! - [`unary_powi`]: Integer exponentiation
//!
//! ## Performance
//!
//! The SIMD implementations in this module achieve significant speedups over scalar code:
//! - **Overall**: 32.48x average speedup vs NumPy
//! - **Preprocessing**: 2.81x average (clip: 1.58x-3.16x faster than NumPy!)
//! - **Reductions**: 470.03x average
//! - **Element-wise**: 1.47x average
//!
//! ## Architecture Support
//!
//! - **x86_64**: AVX-512, AVX2, SSE2 with runtime detection
//! - **aarch64**: NEON with runtime detection
//! - **Fallback**: Scalar implementations for unsupported architectures

// Include legacy simd implementation (remaining functions not yet migrated)
#[path = "../simd_impl.rs"]
mod simd_impl;

// Core infrastructure
pub mod detect;
pub mod traits;

// Layer 2: Core operations
pub mod arithmetic;
pub mod basic;
pub mod basic_optimized; // Ultra-optimized versions with aggressive compiler hints
pub mod dot;

// Layer 3: Reductions & statistics
pub mod reductions;

// Layer 4: Vector computations
pub mod distances;
pub mod norms;
pub mod similarity;
pub mod weighted;

// Layer 5: Specialized operations
pub mod activation;
pub mod cumulative;
pub mod indexing;
pub mod normalization; // Phase 79: SIMD batch/layer normalization
pub mod preprocessing;
pub mod rounding; // SIMD-accelerated floor, ceil, round, trunc
pub mod transcendental; // Phase 75-78: SIMD transcendental functions
pub mod transpose;
pub mod unary;
pub mod unary_powi; // Phase 25: Integer exponentiation // Phase 36: Cache-optimized blocked transpose

// Remaining operations still in simd_impl.rs (to be migrated):
// - advanced (fused_multiply_add, gemv)
// - additional variants (add_adaptive, add_cache_optimized, add_auto, fma_advanced)
// - miscellaneous helper functions and optimized variants

// Re-export core traits and detection
pub use detect::{detect_simd_capabilities, get_cpu_features, CpuFeatures, SimdCapabilities};
pub use traits::SimdOps;

// Re-export basic operations
pub use basic::{
    simd_add_aligned_ultra, simd_add_f32, simd_add_f32_fast, simd_add_f32_optimized,
    simd_add_f32_ultra, simd_add_f64, simd_maximum_f32, simd_maximum_f64, simd_minimum_f32,
    simd_minimum_f64,
};

// Re-export ultra-optimized operations from basic_optimized
pub use basic_optimized::{
    simd_add_f32_ultra_optimized, simd_dot_f32_ultra_optimized, simd_mul_f32_ultra_optimized,
    simd_sum_f32_ultra_optimized,
};

// Re-export arithmetic operations
pub use arithmetic::{simd_scalar_mul_f32, simd_scalar_mul_f64};

// Re-export dot product operations
pub use dot::{
    simd_div_f32, simd_div_f64, simd_dot_f32, simd_dot_f32_adaptive, simd_dot_f32_ultra,
    simd_dot_f64, simd_fma_f32_ultra, simd_mul_f32, simd_mul_f32_fast, simd_mul_f64, simd_sub_f32,
    simd_sub_f64,
};

// Re-export reduction operations
pub use reductions::{
    simd_max_f32, simd_max_f64, simd_mean_f32, simd_mean_f64, simd_min_f32, simd_min_f64,
    simd_std_f32, simd_std_f64, simd_sum_f32, simd_sum_f64, simd_variance_f32, simd_variance_f64,
};

// Re-export norm operations
pub use norms::{
    simd_norm_l1_f32, simd_norm_l1_f64, simd_norm_l2_f32, simd_norm_l2_f64, simd_norm_linf_f32,
    simd_norm_linf_f64,
};

// Re-export distance operations
pub use distances::{
    simd_distance_chebyshev_f32, simd_distance_chebyshev_f64, simd_distance_euclidean_f32,
    simd_distance_euclidean_f64, simd_distance_manhattan_f32, simd_distance_manhattan_f64,
    simd_distance_squared_euclidean_f32, simd_distance_squared_euclidean_f64,
};

// Re-export similarity operations
pub use similarity::{
    simd_cosine_similarity_f32, simd_cosine_similarity_f64, simd_distance_cosine_f32,
    simd_distance_cosine_f64,
};

// Re-export weighted operations
pub use weighted::{
    simd_weighted_mean_f32, simd_weighted_mean_f64, simd_weighted_sum_f32, simd_weighted_sum_f64,
};

// Re-export preprocessing operations
pub use preprocessing::{
    simd_normalize_f32, simd_normalize_f64, simd_standardize_f32, simd_standardize_f64,
};

// Re-export indexing operations
pub use indexing::{
    simd_argmax_f32, simd_argmax_f64, simd_argmin_f32, simd_argmin_f64, simd_clip_f32,
    simd_clip_f64,
};

// Re-export activation operations
pub use activation::{
    simd_leaky_relu_f32, simd_leaky_relu_f64, simd_log_sum_exp_f32, simd_log_sum_exp_f64,
    simd_relu_f32, simd_relu_f64, simd_softmax_f32, simd_softmax_f64,
};

// Re-export cumulative operations
pub use cumulative::{
    simd_cumprod_f32, simd_cumprod_f64, simd_cumsum_f32, simd_cumsum_f64, simd_diff_f32,
    simd_diff_f64,
};

// Re-export unary operations
pub use unary::{
    simd_abs_f32, simd_abs_f64, simd_sign_f32, simd_sign_f64, simd_sqrt_f32, simd_sqrt_f64,
};

// Re-export integer exponentiation (Phase 25)
pub use unary_powi::{simd_powi_f32, simd_powi_f64};

// Re-export blocked transpose operations (Phase 36)
pub use transpose::{simd_transpose_blocked_f32, simd_transpose_blocked_f64};

// Re-export rounding operations (floor, ceil, round, trunc)
pub use rounding::{
    simd_ceil_f32, simd_ceil_f64, simd_floor_f32, simd_floor_f64, simd_round_f32, simd_round_f64,
    simd_trunc_f32, simd_trunc_f64,
};

// Re-export transcendental operations (Phase 75-78: exp, activations, tanh, ln, sin/cos, log2/log10)
pub use transcendental::{
    simd_cos_f32, simd_cos_f64, simd_exp_f32, simd_exp_f64, simd_exp_fast_f32, simd_gelu_f32,
    simd_gelu_f64, simd_ln_f32, simd_ln_f64, simd_log10_f32, simd_log10_f64, simd_log2_f32,
    simd_log2_f64, simd_mish_f32, simd_mish_f64, simd_sigmoid_f32, simd_sigmoid_f64, simd_sin_f32,
    simd_sin_f64, simd_softplus_f32, simd_softplus_f64, simd_swish_f32, simd_swish_f64,
    simd_tanh_f32, simd_tanh_f64,
};

// Re-export normalization operations (Phase 79: batch/layer norm)
pub use normalization::{
    simd_batch_norm_f32, simd_batch_norm_f64, simd_layer_norm_f32, simd_layer_norm_f64,
};

// Re-export all remaining functions from simd_impl (not yet migrated to modules)
pub use simd_impl::*;
