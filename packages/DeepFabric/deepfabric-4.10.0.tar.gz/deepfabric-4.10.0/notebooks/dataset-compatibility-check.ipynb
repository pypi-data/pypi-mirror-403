{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-cell",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h3></h3>\n",
    "<img src=\"https://github.com/always-further/deepfabric/raw/main/assets/logo-light.png\" width=\"20%\">\n",
    "<h3>DeepFabric Dataset Compatibility Checker</h3>\n",
    "<!-- CTA Buttons -->\n",
    "<p>\n",
    "  <a href=\"https://github.com/always-further/deepfabric/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22\">\n",
    "    <img src=\"https://img.shields.io/badge/Contribute-Good%20First%20Issues-green?style=for-the-badge&logo=github\" alt=\"Good First Issues\"/>\n",
    "  </a>\n",
    "  &nbsp;\n",
    "  <a href=\"https://discord.gg/pPcjYzGvbS\">\n",
    "    <img src=\"https://img.shields.io/badge/Chat-Join%20Discord-7289da?style=for-the-badge&logo=discord&logoColor=white\" alt=\"Join Discord\"/>\n",
    "  </a>\n",
    "</p>\n",
    "<!-- Badges -->\n",
    "<p>\n",
    "  <a href=\"https://opensource.org/licenses/Apache-2.0\">\n",
    "    <img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\" alt=\"License\"/>\n",
    "  </a>\n",
    "  <a href=\"https://github.com/always-further/deepfabric/actions/workflows/test.yml\">\n",
    "    <img src=\"https://github.com/always-further/deepfabric/actions/workflows/test.yml/badge.svg\" alt=\"CI Status\"/>\n",
    "  </a>\n",
    "  <a href=\"https://pypi.org/project/deepfabric/\">\n",
    "    <img src=\"https://img.shields.io/pypi/v/deepfabric.svg\" alt=\"PyPI Version\"/>\n",
    "  </a>\n",
    "  <a href=\"https://pepy.tech/project/deepfabric\">\n",
    "    <img src=\"https://static.pepy.tech/badge/deepfabric\" alt=\"Downloads\"/>\n",
    "  </a>\n",
    "  <a href=\"https://discord.gg/pPcjYzGvbS\">\n",
    "    <img src=\"https://img.shields.io/discord/1384081906773131274?color=7289da&label=Discord&logo=discord&logoColor=white\" alt=\"Discord\"/>\n",
    "  </a>\n",
    "</p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad203073",
   "metadata": {},
   "source": [
    "Test if your DeepFabric dataset is compatible with a model's chat template.\n",
    "\n",
    "If you need support with any issues, raise an issue on the [DeepFabric GitHub](https://github.com/always-further/deepfabric/issues/new/) or join the [DeepFabric Discord](https://discord.gg/pPcjYzGvbS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "model_name = \"Qwen/Qwen3-4B-Thinking-2507\"\n",
    "dataset_name = \"alwaysfurther/coding-test-dataset\"\n",
    "dataset_split = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "load-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: alwaysfurther/coding-test-dataset\n",
      "Loaded 40 rows\n",
      "\n",
      "Loading tokenizer: Qwen/Qwen3-4B-Thinking-2507\n",
      "Tokenizer loaded\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(f\"Loading dataset: {dataset_name}\")\n",
    "dataset = load_dataset(dataset_name, split=dataset_split)\n",
    "print(f\"Loaded {len(dataset)} rows\")\n",
    "\n",
    "print(f\"\\nLoading tokenizer: {model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "print(\"Tokenizer loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-test-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "QUICK COMPATIBILITY TEST\n",
      "============================================================\n",
      "Model:   Qwen/Qwen3-4B-Thinking-2507\n",
      "Dataset: alwaysfurther/coding-test-dataset\n",
      "\n",
      "PASS - All 20 sampled rows work with this chat template\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "def clean_message(msg):\n",
    "    \"\"\"Remove null values and empty tool_calls from a message.\"\"\"\n",
    "    cleaned = {}\n",
    "    for key, value in msg.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        if key == \"tool_calls\" and value == []:\n",
    "            continue\n",
    "        cleaned[key] = value\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def format_messages(messages):\n",
    "    \"\"\"Format messages for chat template.\"\"\"\n",
    "    return [clean_message(msg) for msg in messages]\n",
    "\n",
    "\n",
    "def quick_compatibility_test(dataset, tokenizer, sample_size=10):\n",
    "    \"\"\"Quick test: sample rows and check if chat template works.\"\"\"\n",
    "    total = len(dataset)\n",
    "    indices = random.sample(range(total), min(sample_size, total))\n",
    "\n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    errors = []\n",
    "\n",
    "    for idx in indices:\n",
    "        row = dataset[idx]\n",
    "        messages = row.get(\"messages\", [])\n",
    "        tools = row.get(\"tools\")\n",
    "\n",
    "        try:\n",
    "            formatted = format_messages(messages)\n",
    "            if tools:\n",
    "                tokenizer.apply_chat_template(formatted, tools=tools, tokenize=False)\n",
    "            else:\n",
    "                tokenizer.apply_chat_template(formatted, tokenize=False)\n",
    "            passed += 1\n",
    "        except Exception as e:\n",
    "            failed += 1\n",
    "            if len(errors) < 3:  # Keep first 3 unique errors\n",
    "                err_msg = f\"{type(e).__name__}: {str(e)[:100]}\"\n",
    "                if err_msg not in [e[1] for e in errors]:\n",
    "                    errors.append((idx, err_msg))\n",
    "\n",
    "    return passed, failed, errors\n",
    "\n",
    "\n",
    "# Run quick test\n",
    "print(\"=\" * 60)\n",
    "print(\"QUICK COMPATIBILITY TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Model:   {model_name}\")\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print()\n",
    "\n",
    "passed, failed, errors = quick_compatibility_test(dataset, tokenizer, sample_size=20)\n",
    "\n",
    "if failed == 0:\n",
    "    print(f\"PASS - All {passed} sampled rows work with this chat template\")\n",
    "else:\n",
    "    print(f\"FAIL - {failed}/{passed+failed} sampled rows failed\")\n",
    "    print()\n",
    "    print(\"Errors encountered:\")\n",
    "    for idx, err in errors:\n",
    "        print(f\"  Row {idx}: {err}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "details-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Detailed Analysis\n",
    "\n",
    "Run the cells below for more detailed diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Analysis\n",
      "----------------------------------------\n",
      "Total rows: 40\n",
      "Fields: messages, metadata, reasoning, tool_context, tools, agent_context\n",
      "\n",
      "Capabilities:\n",
      "  Conversations:        40 (100%)\n",
      "  Tool definitions:     40 (100%)\n",
      "  Tool calls:           40 (100%)\n",
      "  Reasoning:            40 (100%)\n",
      "  Thinking tags:         0 (0%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_dataset(dataset):\n",
    "    \"\"\"Analyze dataset structure and capabilities.\"\"\"\n",
    "    total = len(dataset)\n",
    "\n",
    "    counts = {\n",
    "        \"messages\": 0,\n",
    "        \"tools\": 0,\n",
    "        \"tool_calls\": 0,\n",
    "        \"reasoning\": 0,\n",
    "        \"thinking_tags\": 0,\n",
    "        \"empty_tool_calls\": 0,\n",
    "    }\n",
    "\n",
    "    for row in dataset:\n",
    "        messages = row.get(\"messages\", [])\n",
    "        if messages:\n",
    "            counts[\"messages\"] += 1\n",
    "\n",
    "            for msg in messages:\n",
    "                if msg.get(\"role\") == \"assistant\":\n",
    "                    tc = msg.get(\"tool_calls\")\n",
    "                    if tc:\n",
    "                        counts[\"tool_calls\"] += 1\n",
    "                        break\n",
    "                    if tc == []:\n",
    "                        counts[\"empty_tool_calls\"] += 1\n",
    "                    content = msg.get(\"content\", \"\") or \"\"\n",
    "                    if \"<think>\" in content:\n",
    "                        counts[\"thinking_tags\"] += 1\n",
    "                        break\n",
    "\n",
    "        if row.get(\"tools\"):\n",
    "            counts[\"tools\"] += 1\n",
    "        if row.get(\"reasoning\"):\n",
    "            counts[\"reasoning\"] += 1\n",
    "\n",
    "    print(\"Dataset Analysis\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total rows: {total}\")\n",
    "    print(f\"Fields: {', '.join(dataset.column_names)}\")\n",
    "    print()\n",
    "    print(\"Capabilities:\")\n",
    "    print(f\"  Conversations:     {counts['messages']:>5} ({100*counts['messages']/total:.0f}%)\")\n",
    "    print(f\"  Tool definitions:  {counts['tools']:>5} ({100*counts['tools']/total:.0f}%)\")\n",
    "    print(f\"  Tool calls:        {counts['tool_calls']:>5} ({100*counts['tool_calls']/total:.0f}%)\")\n",
    "    print(f\"  Reasoning:         {counts['reasoning']:>5} ({100*counts['reasoning']/total:.0f}%)\")\n",
    "    print(f\"  Thinking tags:     {counts['thinking_tags']:>5} ({100*counts['thinking_tags']/total:.0f}%)\")\n",
    "\n",
    "    if counts[\"empty_tool_calls\"] > 0:\n",
    "        print()\n",
    "        print(f\"  [!] Empty tool_calls arrays: {counts['empty_tool_calls']}\")\n",
    "        print(\"      (Some models fail on empty tool_calls - these are stripped during formatting)\")\n",
    "\n",
    "    return counts\n",
    "\n",
    "\n",
    "analysis = analyze_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-row-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0\n",
      "----------------------------------------\n",
      "Fields: {'messages': 'list', 'metadata': 'dict', 'reasoning': 'dict', 'tool_context': 'dict', 'tools': 'list', 'agent_context': 'dict'}\n",
      "Messages: 17\n",
      "Tools: 3\n",
      "\n",
      "Conversation:\n",
      "  0. system: You are an AI assistant with access to file system tools.\n",
      "Wh...\n",
      "  1. user: Can you help me identify the configuration files related to ...\n",
      "  2. assistant:  [tool_calls=1]\n",
      "  3. tool: [\"Dockerfile\",\"main.py\",\"config.json\",\"terraform/main.tf\",\"s... [tool_call_id=mq6emkm13]\n",
      "  4. assistant:  [tool_calls=1]\n",
      "  5. tool: {\n",
      "  \"version\": \"1.0.0\",\n",
      "  \"debug\": true,\n",
      "  \"max_retries\": 3\n",
      "... [tool_call_id=futTCarvJ]\n",
      "  ... (11 more)\n",
      "\n",
      "Applying chat template...\n",
      "SUCCESS\n",
      "\n",
      "Output preview:\n",
      "<|im_start|>system\n",
      "You are an AI assistant with access to file system tools.\n",
      "When given a task:\n",
      "1. Analyze what files need to be read or modified\n",
      "2. Execute file operations with proper paths\n",
      "3. Interpret results and provide clear answers\n",
      "\n",
      "\n",
      "# Tools\n",
      "\n",
      "You may call one or more functions to assist with the user query.\n",
      "\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"function\": {\"description\": \"Read content from a file\", \"name\": \"read_file\", \"parameters\": {\"properties\": {\"file_path\": {\"description\": \"Path to the file to read\", \"type\": \"string\"}, \"content\": null}, \"required\": [\"file_path\"], \"type\": \"object\"}}, \"type\": \"function\"}\n",
      "{\"function\": {\"description\": \"Write content to a file\", \"name\": \"write_file\", \"parameters\": {\"properties\": {\"file_path\": {\"description\": \"Path to the file to write\", \"type\": \"string\"}, \"content\": {\"description\": \"Content to write to the file\", \"type\": \"string\"}}, \"required\": [\"file_path\", \"content\"], \"type\": \"object\"}}, \"type\": \"function\"}\n",
      "{\"function\": {\"description\": \"List all files in the current session\", \"name\": \"list_files\", \"parameters\": {\"properties\": {\"file_path\": null, \"content\": null}, \"required\": [], \"type\": \"object\"}}, \"type\": \"function\"}\n",
      "</tools>\n",
      "\n",
      "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
      "<tool_call>\n",
      "{\"name\": <function-name>, \"arguments\": <args-json-object>}\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "Can you help me identify the config...\n"
     ]
    }
   ],
   "source": [
    "def test_row(row_index):\n",
    "    \"\"\"Test a specific row and show detailed output.\"\"\"\n",
    "    if row_index < 0 or row_index >= len(dataset):\n",
    "        print(f\"Error: index {row_index} out of range (0-{len(dataset)-1})\")\n",
    "        return\n",
    "\n",
    "    row = dataset[row_index]\n",
    "    messages = row.get(\"messages\", [])\n",
    "    tools = row.get(\"tools\")\n",
    "\n",
    "    print(f\"Row {row_index}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Summary\n",
    "    print(\"Fields:\", {k: type(v).__name__ if v else None for k, v in row.items()})\n",
    "    print(f\"Messages: {len(messages)}\")\n",
    "    if tools:\n",
    "        print(f\"Tools: {len(tools)}\")\n",
    "    print()\n",
    "\n",
    "    # Show messages\n",
    "    print(\"Conversation:\")\n",
    "    for i, msg in enumerate(messages[:6]):\n",
    "        role = msg.get(\"role\", \"?\")\n",
    "        content = (msg.get(\"content\") or \"\")[:60]\n",
    "        extras = []\n",
    "        if msg.get(\"tool_calls\"):\n",
    "            extras.append(f\"tool_calls={len(msg['tool_calls'])}\")\n",
    "        elif msg.get(\"tool_calls\") == []:\n",
    "            extras.append(\"tool_calls=[] (empty!)\")\n",
    "        if msg.get(\"tool_call_id\"):\n",
    "            extras.append(f\"tool_call_id={msg['tool_call_id']}\")\n",
    "        extra_str = f\" [{', '.join(extras)}]\" if extras else \"\"\n",
    "        print(f\"  {i}. {role}: {content}...{extra_str}\" if len(content) == 60 else f\"  {i}. {role}: {content}{extra_str}\")\n",
    "    if len(messages) > 6:\n",
    "        print(f\"  ... ({len(messages) - 6} more)\")\n",
    "\n",
    "    # Test template\n",
    "    print()\n",
    "    print(\"Applying chat template...\")\n",
    "    formatted = format_messages(messages)\n",
    "\n",
    "    try:\n",
    "        if tools:\n",
    "            result = tokenizer.apply_chat_template(formatted, tools=tools, tokenize=False)\n",
    "        else:\n",
    "            result = tokenizer.apply_chat_template(formatted, tokenize=False)\n",
    "\n",
    "        print(\"SUCCESS\")\n",
    "        print()\n",
    "        print(\"Output preview:\")\n",
    "        print(result[:1500] + \"...\" if len(result) > 1500 else result)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"FAILED: {type(e).__name__}: {e}\")\n",
    "        print()\n",
    "        print(\"Formatted messages:\")\n",
    "        print(json.dumps(formatted, indent=2))\n",
    "\n",
    "\n",
    "# Test row 0 by default\n",
    "test_row(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capability-probe-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capability Probe\n",
      "--------------------------------------------------\n",
      "Capability      | In Dataset | Template   | Status\n",
      "--------------------------------------------------\n",
      "basic           | Yes        | Yes        | PASS\n",
      "tools           | Yes        | Yes        | PASS\n",
      "tool_calls      | Yes        | Yes        | PASS\n",
      "reasoning       | Yes        | Yes        | PASS\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def find_example(dataset, capability):\n",
    "    \"\"\"Find an example row for a specific capability.\"\"\"\n",
    "    for row in dataset:\n",
    "        messages = row.get(\"messages\", [])\n",
    "\n",
    "        if capability == \"basic\" and messages and len(messages) >= 2:\n",
    "            return row\n",
    "\n",
    "        if capability == \"tools\" and row.get(\"tools\"):\n",
    "            return row\n",
    "\n",
    "        if capability == \"tool_calls\":\n",
    "            for msg in messages:\n",
    "                if msg.get(\"role\") == \"assistant\" and msg.get(\"tool_calls\"):\n",
    "                    return row\n",
    "\n",
    "        if capability == \"reasoning\":\n",
    "            if row.get(\"reasoning\"):\n",
    "                return row\n",
    "            for msg in messages:\n",
    "                if \"<think>\" in (msg.get(\"content\") or \"\"):\n",
    "                    return row\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def probe_capabilities(dataset, tokenizer):\n",
    "    \"\"\"Test each capability type.\"\"\"\n",
    "    capabilities = [\"basic\", \"tools\", \"tool_calls\", \"reasoning\"]\n",
    "    results = {}\n",
    "\n",
    "    print(\"Capability Probe\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Capability':<15} | {'In Dataset':<10} | {'Template':<10} | Status\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for cap in capabilities:\n",
    "        row = find_example(dataset, cap)\n",
    "        has_data = row is not None\n",
    "\n",
    "        if not has_data:\n",
    "            results[cap] = \"skip\"\n",
    "            print(f\"{cap:<15} | {'No':<10} | {'N/A':<10} | SKIP\")\n",
    "            continue\n",
    "\n",
    "        messages = row.get(\"messages\", [])\n",
    "        tools = row.get(\"tools\") if cap == \"tools\" else None\n",
    "        formatted = format_messages(messages)\n",
    "\n",
    "        try:\n",
    "            if tools:\n",
    "                tokenizer.apply_chat_template(formatted, tools=tools, tokenize=False)\n",
    "            else:\n",
    "                tokenizer.apply_chat_template(formatted, tokenize=False)\n",
    "            results[cap] = \"pass\"\n",
    "            print(f\"{cap:<15} | {'Yes':<10} | {'Yes':<10} | PASS\")\n",
    "        except Exception as e:\n",
    "            results[cap] = f\"fail: {e}\"\n",
    "            print(f\"{cap:<15} | {'Yes':<10} | {'No':<10} | FAIL\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    return results\n",
    "\n",
    "\n",
    "probe_results = probe_capabilities(dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-formatted-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: basic\n",
      "==================================================\n",
      "\n",
      "Raw (first 2 messages):\n",
      "[\n",
      "  {\n",
      "    \"content\": \"You are an AI assistant with access to file system tools.\\nWhen given a task:\\n1. Analyze what files need to be read or modified\\n2. Execute file operations with proper paths\\n3. Interpret results and provide clear answers\\n\",\n",
      "    \"role\": \"system\",\n",
      "    \"tool_calls\": null,\n",
      "    \"tool_call_id\": null\n",
      "  },\n",
      "  {\n",
      "    \"content\": \"Can you help me identify the configuration files related to the service mesh observability in my cloud native platform, and guide me on how to enable more observability features?\",\n",
      "    \"role\": \"user\",\n",
      "    \"tool_calls\": null,\n",
      "    \"tool_call_id\": null\n",
      "  }\n",
      "]\n",
      "\n",
      "Formatted (first 2 messages):\n",
      "[\n",
      "  {\n",
      "    \"content\": \"You are an AI assistant with access to file system tools.\\nWhen given a task:\\n1. Analyze what files need to be read or modified\\n2. Execute file operations with proper paths\\n3. Interpret results and provide clear answers\\n\",\n",
      "    \"role\": \"system\"\n",
      "  },\n",
      "  {\n",
      "    \"content\": \"Can you help me identify the configuration files related to the service mesh observability in my cloud native platform, and guide me on how to enable more observability features?\",\n",
      "    \"role\": \"user\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Tools (first one):\n",
      "[\n",
      "  {\n",
      "    \"function\": {\n",
      "      \"description\": \"Read content from a file\",\n",
      "      \"name\": \"read_file\",\n",
      "      \"parameters\": {\n",
      "        \"properties\": {\n",
      "          \"file_path\": {\n",
      "            \"description\": \"Path to the file to read\",\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"content\": null\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"file_path\"\n",
      "        ],\n",
      "        \"type\": \"object\"\n",
      "      }\n",
      "    },\n",
      "    \"type\": \"function\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def show_example(capability):\n",
    "    \"\"\"Show raw vs formatted for a capability.\"\"\"\n",
    "    row = find_example(dataset, capability)\n",
    "    if not row:\n",
    "        print(f\"No {capability} example in dataset\")\n",
    "        return\n",
    "\n",
    "    messages = row.get(\"messages\", [])\n",
    "    formatted = format_messages(messages)\n",
    "\n",
    "    print(f\"Example: {capability}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()\n",
    "    print(\"Raw (first 2 messages):\")\n",
    "    print(json.dumps(messages[:2], indent=2))\n",
    "    print()\n",
    "    print(\"Formatted (first 2 messages):\")\n",
    "    print(json.dumps(formatted[:2], indent=2))\n",
    "\n",
    "    if row.get(\"tools\"):\n",
    "        print()\n",
    "        print(\"Tools (first one):\")\n",
    "        print(json.dumps(row[\"tools\"][:1], indent=2))\n",
    "\n",
    "\n",
    "# Show an example - change to \"tools\", \"tool_calls\", or \"reasoning\"\n",
    "show_example(\"basic\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
