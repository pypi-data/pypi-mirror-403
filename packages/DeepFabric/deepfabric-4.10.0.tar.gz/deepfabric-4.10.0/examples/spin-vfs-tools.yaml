#####################################################################
# Spin VFS Tools Dataset Configuration
#####################################################################
# This configuration demonstrates using real tool execution via Spin.
# Prerequisites:
#   1. Build and run the Spin service: cd tools-sdk && spin build && spin up
#   2. Run deepfabric: deepfabric start examples/spin-vfs-tools.yaml
#####################################################################

# Topic generation - creates a tree of related topics
topics:
  prompt: "File manipulation and code analysis tasks"
  mode: graph
  prompt_style: anchored
  system_prompt: ""
  depth: 3
  degree: 3
  save_as: "spin-vfs-topics.jsonl"

  llm:
    provider: "gemini"
    model: "gemini-2.5-flash-lite"
    temperature: 0.8

# Data generation with real tool execution
generation:
  system_prompt: |
    Generate examples of file operations with realistic scenarios.
    The assistant should read, write, and analyze files to help users.

  instructions: "Create scenarios requiring file reading and writing."

  # Agent mode is implicit when tools are configured
  conversation:
    type: cot
    reasoning_style: agent

  tools:
    # Spin service endpoint for real tool execution
    spin_endpoint: "http://localhost:3000"

    # Component-based tools: builtin routes to /vfs/execute
    components:
      builtin:
        - read_file
        - write_file
        - list_files

    max_per_query: 3
    strict: false

    # ReAct loop configuration - agent thinks step-by-step
    max_agent_steps: 5  # Maximum reasoning steps before conclusion

    # Optional: Seed initial files into the VFS before generation
    scenario_seed:
      files:
        "main.py": |
          def greet(name):
              return f"Hello, {name}!"

          if __name__ == "__main__":
              print(greet("World"))
        "config.json": |
          {
            "version": "1.0.0",
            "debug": true,
            "max_retries": 3
          }

  max_retries: 3

  llm:
    provider: "gemini"
    model: "gemini-2.5-flash-lite"
    temperature: 0.7

# Output configuration
output:
  system_prompt: |
    You are an AI assistant with access to file system tools.
    When given a task:
    1. Analyze what files need to be read or modified
    2. Execute file operations with proper paths
    3. Interpret results and provide clear answers

  include_system_message: true
  num_samples: 3
  batch_size: 3
  save_as: "spin-vfs-dataset.jsonl"
