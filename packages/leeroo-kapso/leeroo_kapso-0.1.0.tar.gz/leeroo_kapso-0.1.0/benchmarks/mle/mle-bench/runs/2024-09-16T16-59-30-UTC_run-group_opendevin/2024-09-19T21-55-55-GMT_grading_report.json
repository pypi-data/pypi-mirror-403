{
  "total_runs": 71,
  "total_runs_with_submissions": 45,
  "total_valid_submissions": 38,
  "total_medals": 4,
  "total_gold_medals": 2,
  "total_silver_medals": 0,
  "total_bronze_medals": 2,
  "total_above_median": 6,
  "competition_reports": [
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.68406,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:29.680422",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/random-acts-of-pizza_ec86bdfb-9869-468d-a1b6-ed19d6b35e75/2024-09-16T18-07-36-GMT/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": 0.21797,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:55:43.289886",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/denoising-dirty-documents_fc7051fd-e43b-464f-83ad-221ace744c23/2024-09-16T18-07-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.494,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:44.018193",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/plant-pathology-2020-fgvc7_984fc2a0-8140-4f95-ad4b-fcd10bf2cfff/2024-09-16T18-07-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": null,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:44.034641",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/google-quest-challenge_2b42aed4-68ca-4bd4-8780-26bf8d48d742/2024-09-16T18-07-55-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": 0.03146,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:45.394887",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/nfl-player-contact-detection_06aaee47-10bf-4cff-a4d0-5ad385e15c0d/2024-09-16T19-08-07-GMT/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.88414,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:45.429795",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/detecting-insults-in-social-commentary_857e410b-239f-4ea4-aecb-3b650d607ed2/2024-09-16T18-08-08-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.0,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:45.436732",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/aptos2019-blindness-detection_63906154-ae0b-4d09-8539-9620715267b0/2024-09-16T18-08-16-GMT/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 1.97278,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:55:46.073045",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/champs-scalar-coupling_4b40b874-76fb-4a1f-b694-32d112236098/2024-09-17T17-09-14-GMT/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.42003,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:46.090018",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/cassava-leaf-disease-classification_f88aa488-9723-4157-8583-3ab238022973/2024-09-16T18-08-31-GMT/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.14863,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:46.109571",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/whale-categorization-playground_a9b80a40-a5af-4d44-be21-57356a5a5c42/2024-09-16T18-08-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": null,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:46.113497",
      "submission_path": "None"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.54238,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:55:46.119519",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/nomad2018-predict-transparent-conductors_a60a54b1-2b9a-45e9-9986-cf590d6adec1/2024-09-16T18-08-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": null,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:46.122780",
      "submission_path": "None"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": null,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:46.129649",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/mlsp-2013-birds_8ae69775-0331-4f0e-8e32-59549f6f3c48/2024-09-16T18-09-01-GMT/submission/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.85287,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:46.256456",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/histopathologic-cancer-detection_0cd37771-5654-4f54-97b1-f4bfec1446d8/2024-09-16T18-09-05-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 0.49512,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:46.273711",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/aerial-cactus-identification_9d9f953e-71fb-45fe-9136-900f43f078d2/2024-09-16T18-09-05-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:46.287818",
      "submission_path": "None"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 1053.07962,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:55:46.522228",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/new-york-city-taxi-fare-prediction_e9535fca-c975-4c8d-b4b4-05adc15a1c5c/2024-09-16T18-09-42-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.85107,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:46.542318",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/plant-pathology-2021-fgvc8_b9e439c0-c967-4bf2-89d8-15ef45e568d8/2024-09-16T20-09-53-GMT/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 5682851.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:55:46.548357",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/predict-volcanic-eruptions-ingv-oe_1667d79f-3276-4516-b8c6-fcc76f0ad2c9/2024-09-16T18-09-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.95764,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:47.299484",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/tabular-playground-series-dec-2021_6d3ad5d2-0cb8-4184-9a9c-d405cc15609e/2024-09-16T18-10-13-GMT/submission/submission.csv"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": null,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:55:47.315521",
      "submission_path": "None"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": null,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:47.344774",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/hubmap-kidney-segmentation_d115344b-220c-476f-ab21-79203a18f99f/2024-09-16T18-10-13-GMT/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": null,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:47.348619",
      "submission_path": "None"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": null,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:55:47.432477",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/smartphone-decimeter-2022_97befe12-3daa-47e1-b228-8aa0c63b0fe5/2024-09-16T18-10-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": null,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:47.614618",
      "submission_path": "None"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": null,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:47.625806",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/alaska2-image-steganalysis_c32129d1-6c19-4c4c-86ef-91b02eaf76cb/2024-09-17T12-12-17-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.0,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:47.665868",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/hotel-id-2021-fgvc8_c039ec15-bbaf-494e-8987-de56ad8491b0/2024-09-16T21-10-57-GMT/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": null,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:50.122885",
      "submission_path": "None"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": 64.46331,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:55:50.138649",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/multi-modal-gesture-recognition_2fb38272-8a4c-4755-9787-bb875c2841ba/2024-09-16T18-11-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.56256,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:55:50.151201",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/spooky-author-identification_44e93ad4-8988-48aa-8635-af4dde8c3688/2024-09-16T18-11-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": null,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:53.469388",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/3d-object-detection-for-autonomous-vehicles_07b4b400-2c25-481a-b9d1-4ccccdde945a/2024-09-16T18-12-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:53.473650",
      "submission_path": "None"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": null,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:53.477742",
      "submission_path": "None"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.99975,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:55:53.515870",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/inaturalist-2019-fgvc6_a2b3cce4-0edc-43aa-828b-89ed730dfa1a/2024-09-16T18-15-28-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": 0.3775,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:53.656308",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/iwildcam-2020-fgvc7_deb7f828-4fe7-4540-93ba-f04808a6a0c7/2024-09-16T20-16-57-GMT/submission/submission.csv"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:55:53.660648",
      "submission_path": "None"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.50315,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:53.676479",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/seti-breakthrough-listen_10505cbf-5bdd-4e64-8ec5-f0ac5033664f/2024-09-17T02-20-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": null,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:53.682763",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": 0.0,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:54.511981",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/herbarium-2021-fgvc8_713acc01-2fbd-4b46-92a8-4c7849cb9975/2024-09-17T15-26-13-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": null,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:54.517048",
      "submission_path": "None"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:54.519721",
      "submission_path": "None"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.97102,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:55.123948",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/jigsaw-toxic-comment-classification-challenge_fd76003d-33b0-4985-9af6-9cd0953be773/2024-09-16T18-32-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": 1.23549,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:55:55.189777",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/hms-harmful-brain-activity-classification_d5ad09d8-fc5c-4954-b82f-1de2df19b28e/2024-09-16T23-38-24-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": null,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:55:55.196577",
      "submission_path": "None"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.68253,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:39.224561",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/jigsaw-unintended-bias-in-toxicity-classification_03ba2b05-46c1-4f35-844c-28f3ed889647/2024-09-16T20-07-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.68179,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:39.265251",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/learning-agency-lab-automated-essay-scoring-2_8d7e1f1b-e957-4656-b3b6-ca30d32ab25d/2024-09-16T18-07-42-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": null,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:39.282265",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/ranzcr-clip-catheter-line-classification_a2d86273-892e-41de-be54-1d3153167759/2024-09-16T21-08-05-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 1.59968,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:39.795959",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/ventilator-pressure-prediction_a5c725c3-9342-41d5-8f5b-d8967621241d/2024-09-16T18-07-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": null,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:39.799789",
      "submission_path": "None"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.40957,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:39.814977",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/us-patent-phrase-to-phrase-matching_b5c04c8b-5643-4c5f-8358-541e7fa8f676/2024-09-16T22-08-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": null,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:39.817903",
      "submission_path": "None"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": null,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:39.820713",
      "submission_path": "None"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": null,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:39.824730",
      "submission_path": "None"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": null,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:39.827205",
      "submission_path": "None"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 18.76601,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:39.835793",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/petfinder-pawpularity-score_5fa698e1-7021-42cf-9f70-aa61e019d4a4/2024-09-16T18-09-02-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.42597,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:39.842701",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/dogs-vs-cats-redux-kernels-edition_46348fcb-c9a1-456f-a743-583b925ada3c/2024-09-16T18-09-04-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": null,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:39.845476",
      "submission_path": "None"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.93396,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:39.856576",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/leaf-classification_6b9e6982-8855-4738-ad64-ba9e99815697/2024-09-16T18-09-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.91414,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:39.905869",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/the-icml-2013-whale-challenge-right-whale-redux_64926ca7-87dc-4754-85e2-da2b51e1f965/2024-09-16T18-09-28-GMT/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": 0.32527,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:39.913985",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/statoil-iceberg-classifier-challenge_1f2c7102-e4fd-4ccb-aa46-5f0d6a2c9c80/2024-09-16T18-09-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 1.18661,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:40.046052",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/lmsys-chatbot-arena_0372760b-0c7c-4fd6-a6c0-a5968e0fc58f/2024-09-16T18-09-36-GMT/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:40.049213",
      "submission_path": "None"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": 0.48608,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:40.168445",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/imet-2020-fgvc7_5bc5adfc-999b-4548-9da9-bbe0e86c5369/2024-09-16T19-10-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:40.171460",
      "submission_path": "None"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": 0.24333,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:40.675077",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/freesound-audio-tagging-2019_dc6c4593-445f-439c-82a2-a39229b04363/2024-09-16T19-11-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.63462,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:40.687403",
      "submission_path": "runs/2024-09-16T16-59-30-UTC_run-group_opendevin/siim-isic-melanoma-classification_960faa48-6935-449c-a945-64ec3649e824/2024-09-16T20-16-24-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": null,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:40.691448",
      "submission_path": "None"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:40.695166",
      "submission_path": "None"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": null,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:40.698645",
      "submission_path": "None"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": null,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:40.701928",
      "submission_path": "None"
    }
  ]
}