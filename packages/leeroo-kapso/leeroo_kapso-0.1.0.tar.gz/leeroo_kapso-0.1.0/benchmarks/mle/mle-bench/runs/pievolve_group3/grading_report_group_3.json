{
  "total_runs": 49,
  "total_runs_with_submissions": 48,
  "total_valid_submissions": 48,
  "total_medals": 45,
  "total_gold_medals": 29,
  "total_silver_medals": 11,
  "total_bronze_medals": 5,
  "total_above_median": 46,
  "competition_reports": [
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": 0.21756,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:11.239765",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-31-43-GMT_run-group_piml_v1__3d-object-detection-for-autonomous-vehicles_unknown_llm_0steps_24hrs_gpu_40cores/3d-object-detection-for-autonomous-vehicles_9bd804a5-d78a-4f70-8bc7-f66f46bc798a/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": 0.59747,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:11.365031",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-31-45-GMT_run-group_piml_v1__iwildcam-2019-fgvc6_unknown_llm_0steps_24hrs_gpu_40cores/iwildcam-2019-fgvc6_65a8de6f-d5e0-4ffb-9278-3cf7e9940619/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": 0.65391,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:12.755042",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-31-49-GMT_run-group_piml_v1__nfl-player-contact-detection_unknown_llm_0steps_24hrs_gpu_40cores/nfl-player-contact-detection_9430de6c-e05f-4c91-bd53-8a7d822bc7ac/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 567791.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-05T10:38:12.836196",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-31-51-GMT_run-group_piml_v1__predict-volcanic-eruptions-ingv-oe_unknown_llm_0steps_24hrs_gpu_40cores/predict-volcanic-eruptions-ingv-oe_2269978c-0642-4cb4-ad8e-a74bc8d1e90d/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": 0.46576,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:14.744067",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-31-59-GMT_run-group_piml_v1__vinbigdata-chest-xray-abnormalities-detection_unknown_llm_0steps_24hrs_gpu_40cores/vinbigdata-chest-xray-abnormalities-detection_7a2ee375-04aa-4ef6-aaed-c2b6b5a17ac6/submission/submission.csv"
    },
    {
      "competition_id": "stanford-covid-vaccine",
      "score": 0.20733,
      "gold_threshold": 0.34728,
      "silver_threshold": 0.35175,
      "bronze_threshold": 0.3534,
      "median_threshold": 0.363095,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-05T10:38:14.947691",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-33-15-GMT_run-group_piml_v1_High_stanford-covid-vaccine_unknown_llm_0steps_24hrs_gpu_40cores/stanford-covid-vaccine_a76fd00b-8004-422e-8039-38ca52786cdc/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 1.0,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:15.018601",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-36-32-GMT_run-group_piml_v1__aerial-cactus-identification_unknown_llm_0steps_24hrs_gpu_40cores/aerial-cactus-identification_49580288-74d3-415b-9faa-bd4fec89ac3b/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.93702,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:15.089443",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-36-34-GMT_run-group_piml_v1__aptos2019-blindness-detection_unknown_llm_0steps_24hrs_gpu_40cores/aptos2019-blindness-detection_99174ac5-2d57-4b7c-b581-09ff2a7420f2/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": 0.00823,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-05T10:38:27.466341",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-36-39-GMT_run-group_piml_v1__denoising-dirty-documents_unknown_llm_0steps_24hrs_gpu_40cores/denoising-dirty-documents_8c0b761d-dd60-4d80-ac84-60539fd71a37/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.95973,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:27.718395",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-36-40-GMT_run-group_piml_v1__detecting-insults-in-social-commentary_unknown_llm_0steps_24hrs_gpu_40cores/detecting-insults-in-social-commentary_f21f17a3-9d4f-47c2-a524-b240b2f88a6a/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.00807,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-05T10:38:27.782154",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-36-44-GMT_run-group_piml_v1__dogs-vs-cats-redux-kernels-edition_unknown_llm_0steps_24hrs_gpu_40cores/dogs-vs-cats-redux-kernels-edition_d2445fbd-558c-431c-8ff8-bd2aa238de56/submission/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.99853,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:27.987408",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-36-47-GMT_run-group_piml_v1__histopathologic-cancer-detection_unknown_llm_0steps_24hrs_gpu_40cores/histopathologic-cancer-detection_972a0641-4785-4d5f-9673-83e737751dcf/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.98782,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:28.460759",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-36-50-GMT_run-group_piml_v1__jigsaw-toxic-comment-classification-challenge_unknown_llm_0steps_24hrs_gpu_40cores/jigsaw-toxic-comment-classification-challenge_258a7e68-231b-40ed-aa85-014845dd134f/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": 0.9361,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:28.529272",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-36-57-GMT_run-group_piml_v1__mlsp-2013-birds_unknown_llm_0steps_24hrs_gpu_40cores/mlsp-2013-birds_c8ba0cc7-1b62-4740-944e-58cf7b3fa447/submission/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.05509,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-05T10:38:28.591307",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-36-58-GMT_run-group_piml_v1__nomad2018-predict-transparent-conductors_unknown_llm_0steps_24hrs_gpu_40cores/nomad2018-predict-transparent-conductors_0f5e5402-a37a-40d0-a0e5-ff58b1ad6695/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.9992,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:28.656231",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-37-02-GMT_run-group_piml_v1__plant-pathology-2020-fgvc7_unknown_llm_0steps_24hrs_gpu_40cores/plant-pathology-2020-fgvc7_1c46c799-efad-4677-8dd2-bcb3afbc7354/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.72123,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:28.719043",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-37-04-GMT_run-group_piml_v1__random-acts-of-pizza_unknown_llm_0steps_24hrs_gpu_40cores/random-acts-of-pizza_9b6f85cc-6326-41da-b59d-23b51e491152/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.92269,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:28.790458",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-37-08-GMT_run-group_piml_v1__siim-isic-melanoma-classification_unknown_llm_0steps_24hrs_gpu_40cores/siim-isic-melanoma-classification_c7fe4e45-59e5-4387-808d-045c102ce23b/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.25475,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-05T10:38:28.868986",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-37-10-GMT_run-group_piml_v1__spooky-author-identification_unknown_llm_0steps_24hrs_gpu_40cores/spooky-author-identification_ab5f76dc-cff8-414c-adae-2f7f72d5cc47/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.96345,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:29.730461",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-37-14-GMT_run-group_piml_v1__tabular-playground-series-dec-2021_unknown_llm_0steps_24hrs_gpu_40cores/tabular-playground-series-dec-2021_fe0e5a35-8e75-453e-8da2-3ab7e6b5cf44/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": 0.99243,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:32.914733",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-37-16-GMT_run-group_piml_v1__text-normalization-challenge-english-language_unknown_llm_0steps_24hrs_gpu_40cores/text-normalization-challenge-english-language_a3396106-3e56-4093-9eb8-c32d9465ecc7/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.99407,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:33.090856",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-37-22-GMT_run-group_piml_v1__the-icml-2013-whale-challenge-right-whale-redux_unknown_llm_0steps_24hrs_gpu_40cores/the-icml-2013-whale-challenge-right-whale-redux_03c4b878-d173-4eb4-b772-753afc591580/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": 6.92927,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-05T10:38:34.613457",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-39-07-GMT_run-group_piml_v1__billion-word-imputation_unknown_llm_0steps_24hrs_gpu_40cores/billion-word-imputation_8e68615d-9148-4fcf-84ab-f3a8ab34ec86/submission/submission.csv"
    },
    {
      "competition_id": "cdiscount-image-classification-challenge",
      "score": 0.72885,
      "gold_threshold": 0.77604,
      "silver_threshold": 0.73526,
      "bronze_threshold": 0.70898,
      "median_threshold": 0.44055,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:34.981469",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-39-14-GMT_run-group_piml_v1__cdiscount-image-classification-challenge_unknown_llm_0steps_24hrs_gpu_40cores/cdiscount-image-classification-challenge_4d03acb7-6dbf-4b66-bb4c-6988aa3ccecf/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.74807,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:35.049542",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-39-18-GMT_run-group_piml_v1__chaii-hindi-and-tamil-question-answering_unknown_llm_0steps_24hrs_gpu_40cores/chaii-hindi-and-tamil-question-answering_56e131bb-a5b5-4ebd-baa2-d2cb399c5435/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": 0.71927,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:35.805415",
      "submission_path": "submission_24hrs/seed3/2025-12-26T11-39-20-GMT_run-group_piml_v1__freesound-audio-tagging-2019_unknown_llm_0steps_24hrs_gpu_40cores/freesound-audio-tagging-2019_760fedda-18f0-4c78-bd0f-22ea904d9c40/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.43666,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:35.897397",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-26-37-GMT_run-group_piml_v1__google-quest-challenge_unknown_llm_0steps_24hrs_gpu_40cores/google-quest-challenge_fb81ce34-5b4d-447b-87ee-d1ade5ad854a/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": 0.82421,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:36.106136",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-28-04-GMT_run-group_piml_v1__iwildcam-2020-fgvc7_unknown_llm_0steps_24hrs_gpu_40cores/iwildcam-2020-fgvc7_c5e735cf-b7ee-4619-9e33-157486a7371e/submission/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.97161,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:36.483366",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-28-04-GMT_run-group_piml_v1__kuzushiji-recognition_unknown_llm_0steps_24hrs_gpu_40cores/kuzushiji-recognition_d6314be8-bf6b-4e5b-8885-410e1b34003a/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 1.00116,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-05T10:38:36.771008",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-28-04-GMT_run-group_piml_v1__lmsys-chatbot-arena_unknown_llm_0steps_24hrs_gpu_40cores/lmsys-chatbot-arena_1a2f334e-8bf7-42ea-82d6-3b8f8410f2ae/submission/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": null,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2026-01-05T10:38:36.813138",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-28-33-GMT_run-group_piml_v1__multi-modal-gesture-recognition_unknown_llm_0steps_24hrs_gpu_40cores/multi-modal-gesture-recognition_65c6476c-1d73-4967-ae08-a7ccbfade477/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": 0.44246,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:37.222159",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-28-35-GMT_run-group_piml_v1__herbarium-2020-fgvc7_unknown_llm_0steps_24hrs_gpu_40cores/herbarium-2020-fgvc7_ae521569-5657-4024-b07d-4ee9f21225db/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": 0.50284,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:37.996015",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-28-35-GMT_run-group_piml_v1__herbarium-2021-fgvc8_unknown_llm_0steps_24hrs_gpu_40cores/herbarium-2021-fgvc8_4e78f741-e991-4eb2-8a75-3732dbe24b68/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.7396,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:38.316266",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-28-35-GMT_run-group_piml_v1__herbarium-2022-fgvc9_unknown_llm_0steps_24hrs_gpu_40cores/herbarium-2022-fgvc9_658e9257-e0b7-44c0-bfb6-5d000b71ab90/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.80234,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:38.466717",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-28-35-GMT_run-group_piml_v1__hotel-id-2021-fgvc8_unknown_llm_0steps_24hrs_gpu_40cores/hotel-id-2021-fgvc8_2353a1aa-95f9-47c6-95df-c55eafcef6ab/submission/submission.csv"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": 0.94574,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:45.625924",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-28-35-GMT_run-group_piml_v1__hubmap-kidney-segmentation_unknown_llm_0steps_24hrs_gpu_40cores/hubmap-kidney-segmentation_aad5033b-1db0-4ebb-93b9-3c0f6418092f/submission/submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.19929,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-05T10:38:45.739868",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-28-35-GMT_run-group_piml_v1__inaturalist-2019-fgvc6_unknown_llm_0steps_24hrs_gpu_40cores/inaturalist-2019-fgvc6_552e9cce-bc9c-4ccf-885e-451589b7fcd3/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.93584,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:45.827462",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-29-04-GMT_run-group_piml_v1__plant-pathology-2021-fgvc8_unknown_llm_0steps_24hrs_gpu_40cores/plant-pathology-2021-fgvc8_0e097a84-cf49-4898-9728-079d8009dbf7/submission/submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.8374,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:45.903778",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-29-04-GMT_run-group_piml_v1__seti-breakthrough-listen_unknown_llm_0steps_24hrs_gpu_40cores/seti-breakthrough-listen_07288130-d245-4f91-99d4-a823a6a5f0d3/submission/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.87361,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:45.978773",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-29-05-GMT_run-group_piml_v1__us-patent-phrase-to-phrase-matching_unknown_llm_0steps_24hrs_gpu_40cores/us-patent-phrase-to-phrase-matching_8b2ba3d7-4a7f-49e1-aa53-4de4ae5347cc/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.61978,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:46.048910",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-29-36-GMT_run-group_piml_v1__whale-categorization-playground_unknown_llm_0steps_24hrs_gpu_40cores/whale-categorization-playground_5051e6fc-8a19-4643-9b51-2b43b2a83d6d/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.90396,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:46.140039",
      "submission_path": "submission_24hrs/seed3/2025-12-27T13-32-30-GMT_run-group_piml_v1_Medium_cassava-leaf-disease-classification_unknown_llm_0steps_24hrs_gpu_40cores/cassava-leaf-disease-classification_28220cbb-7676-4845-ab46-f5d5e75693c2/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": 0.9914,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:50.117562",
      "submission_path": "submission_24hrs/seed3/2025-12-29T10-53-58-GMT_run-group_piml_v1_Low_text-normalization-challenge-russian-language_unknown_llm_0steps_24hrs_gpu_40cores/text-normalization-challenge-russian-language_2786de0b-09e2-4fd7-9dae-5245ab295266/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.85087,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:50.291308",
      "submission_path": "submission_24hrs/seed3/2025-12-29T10-57-59-GMT_run-group_piml_v1_Medium_learning-agency-lab-automated-essay-scoring-2_unknown_llm_0steps_24hrs_gpu_40cores/learning-agency-lab-automated-essay-scoring-2_942b624f-7466-46ba-9fc4-4a2c7d54a8fa/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.71792,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:50.372459",
      "submission_path": "submission_24hrs/seed3/2025-12-29T10-58-28-GMT_run-group_piml_v1_Medium_tweet-sentiment-extraction_unknown_llm_0steps_24hrs_gpu_40cores/tweet-sentiment-extraction_5442f249-85e1-45c9-ad1a-1a8573d8cff0/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.63529,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:50.437085",
      "submission_path": "submission_24hrs/seed3/2025-12-29T11-00-02-GMT_run-group_piml_v1_High_rsna-miccai-brain-tumor-radiogenomic-classification_unknown_llm_0steps_24hrs_gpu_40cores/rsna-miccai-brain-tumor-radiogenomic-classification_15cd283b-b827-47a6-97f4-74d055fb2798/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.00354,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-05T10:38:50.512087",
      "submission_path": "submission_24hrs/seed3/2025-12-29T14-02-27-GMT_run-group_piml_v1_Low_leaf-classification_unknown_llm_0steps_24hrs_gpu_40cores/leaf-classification_916ee4a4-cd64-4310-bdc9-e182551d2f84/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": 0.02745,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-05T10:38:53.874357",
      "submission_path": "submission_24hrs/seed3/2025-12-31T21-38-08-GMT_run-group_piml_v1_Medium_h-and-m-personalized-fashion-recommendations_unknown_llm_0steps_24hrs_gpu_40cores/h-and-m-personalized-fashion-recommendations_16db6046-34d7-4402-8603-a28655c13802/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 17.09576,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-05T10:38:53.982460",
      "submission_path": "submission_24hrs/seed3/2026-01-02T07-41-46-GMT_run-group_piml_v1_Medium_petfinder-pawpularity-score_unknown_llm_0steps_24hrs_gpu_40cores/petfinder-pawpularity-score_c31f0216-a2aa-470b-a01e-a42835a67a84/submission/submission.csv"
    }
  ]
}