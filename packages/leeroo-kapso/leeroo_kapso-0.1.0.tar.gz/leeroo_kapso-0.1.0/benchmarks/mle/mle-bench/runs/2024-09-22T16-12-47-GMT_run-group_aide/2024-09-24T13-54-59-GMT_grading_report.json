{
  "total_runs": 57,
  "total_runs_with_submissions": 40,
  "total_valid_submissions": 28,
  "total_medals": 4,
  "total_gold_medals": 2,
  "total_silver_medals": 2,
  "total_bronze_medals": 0,
  "total_above_median": 7,
  "competition_reports": [
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.24762,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:48.270005",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/whale-categorization-playground_813bb99e-c18b-4eec-8f46-31bdfc5309a2/2024-09-23T16-23-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-24T13:54:51.720206",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/denoising-dirty-documents_ec0ea9df-84f8-4b58-b3f6-edb57332a6a1/2024-09-23T16-25-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": null,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:51.975342",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/detecting-insults-in-social-commentary_1f98e1bd-371c-4838-a05e-73f199e54613/2024-09-23T16-26-09-GMT/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": null,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:51.991291",
      "submission_path": "None"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.97177,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:52.558264",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/jigsaw-toxic-comment-classification-challenge_70617f73-5959-4ec7-8f27-3315646238ec/2024-09-23T16-27-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.96165,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:53.310143",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/tabular-playground-series-dec-2021_33278244-221a-46ef-867b-b378c38c7a65/2024-09-23T16-26-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.42893,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-24T13:54:53.323308",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/spooky-author-identification_de895bf8-223e-48df-b86d-5f63c510ba78/2024-09-23T16-26-42-GMT/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 2.99161,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-24T13:54:54.473760",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/champs-scalar-coupling_a1582fcb-3491-4745-a531-cc21c8f1620e/2024-09-23T16-31-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": null,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:54.537934",
      "submission_path": "None"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.05937,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-24T13:54:54.544547",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/nomad2018-predict-transparent-conductors_6d431ffd-7656-4f49-9fa3-791ad0f3249b/2024-09-23T16-26-55-GMT/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": null,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:58.264190",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/cassava-leaf-disease-classification_215adb7e-2f0d-4a40-bd57-04e5ea3e80ac/2024-09-23T16-27-29-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 0.99997,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:58.278407",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/aerial-cactus-identification_a5f6853d-eb9c-4faa-8615-dfe6259057fe/2024-09-23T16-27-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.48817,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:58.300768",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/tweet-sentiment-extraction_c158b172-8787-4ead-990b-4557745f5ce2/2024-09-23T16-27-36-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:58.307097",
      "submission_path": "None"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.89849,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:58.884126",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/plant-pathology-2021-fgvc8_49993fab-c607-41e0-b472-86c090048e7f/2024-09-23T16-28-53-GMT/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": -7.99649,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:58.958268",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/osic-pulmonary-fibrosis-progression_6d6f4ffd-f606-48f0-b160-defe1b796b18/2024-09-23T16-28-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": null,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:58.963186",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:58.965945",
      "submission_path": "None"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": null,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.014153",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/histopathologic-cancer-detection_350a9ab2-296a-402f-9501-170c7f05fd75/2024-09-23T16-30-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.019092",
      "submission_path": "None"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": null,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.029568",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/alaska2-image-steganalysis_fbfd9061-0017-4d1b-b01a-7809fc83c2a3/2024-09-23T16-31-22-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.86056,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.036867",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/aptos2019-blindness-detection_6ca9dedf-8e47-4fdf-8c03-862e1e167502/2024-09-23T16-31-42-GMT/submission/submission.csv"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": null,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-24T13:54:59.040310",
      "submission_path": "None"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-24T13:54:59.322350",
      "submission_path": "None"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 4.28165,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-24T13:54:59.357600",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/new-york-city-taxi-fare-prediction_0ca918d8-9f60-4a51-b952-a8ac0f603a85/2024-09-23T16-36-03-GMT/submission/submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": null,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.363738",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/seti-breakthrough-listen_3309f905-f3c8-4748-8381-b8237cecd02c/2024-09-23T16-35-24-GMT/submission/submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": null,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.490441",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/3d-object-detection-for-autonomous-vehicles_c8b94086-b733-4dd6-b466-4a272f89b87f/2024-09-23T16-35-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": null,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.528059",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/vesuvius-challenge-ink-detection_14684bc8-6d04-455c-a372-546ec038841d/2024-09-23T16-35-57-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.01258,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.569607",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/hotel-id-2021-fgvc8_96ec93fe-a302-4e4c-87b3-2d3d0321137a/2024-09-23T16-36-24-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": null,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.572808",
      "submission_path": "None"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.61934,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.580089",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/random-acts-of-pizza_46e4711f-4c18-486a-b6f2-7e84b74f35c9/2024-09-23T16-36-53-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.593134",
      "submission_path": "None"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-24T13:54:59.597524",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.600200",
      "submission_path": "None"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": null,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-24T13:54:59.610484",
      "submission_path": "None"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 1.24986,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T18:03:22.369796",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/dog-breed-identification_81640927-a01a-4b27-92f8-95b2ad9bd585/2024-09-23T16-24-20-GMT/submission/submission.csv"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": 0.46296,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:22.492044",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/imet-2020-fgvc7_1a6e9027-7a4e-4a3d-b8f9-1fa8aa1fe12e/2024-09-23T16-25-29-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 9.7443,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T18:03:22.499978",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/dogs-vs-cats-redux-kernels-edition_1ec79adb-8243-4190-a338-60efcb3bb631/2024-09-23T16-25-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.33956,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T18:03:22.514640",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/leaf-classification_3d46d45d-248e-474c-a040-e6d60d76ac0e/2024-09-23T16-26-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T18:03:22.517004",
      "submission_path": "None"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.0,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:23.478851",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/kuzushiji-recognition_1d78144f-b4d1-49ed-92cc-70a404981807/2024-09-23T16-26-42-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": null,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:23.485498",
      "submission_path": "None"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": null,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T18:03:23.886605",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/ventilator-pressure-prediction_286b78cb-a49c-47d5-8ce9-c7db258e8c6d/2024-09-23T16-26-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": null,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T18:03:24.015883",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/lmsys-chatbot-arena_2bb7ca01-7a0e-4525-978a-e4c20f597ae4/2024-09-23T16-26-33-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 20.08431,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T18:03:24.026560",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/petfinder-pawpularity-score_f26d3a1f-48ec-4173-ba96-cbe4c1adf983/2024-09-23T16-30-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.97802,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:24.080205",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/the-icml-2013-whale-challenge-right-whale-redux_dd0334cc-7044-42b9-897c-350fd229bf1d/2024-09-23T16-27-26-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": 0.4241,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:24.710584",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/tgs-salt-identification-challenge_d94624e7-b748-4661-806d-a512c31c451e/2024-09-23T16-26-50-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": 0.92796,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:27.824622",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/text-normalization-challenge-english-language_ce139595-f4d7-4d41-8376-8ce2d0ec8fe7/2024-09-23T16-27-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": null,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:27.868001",
      "submission_path": "None"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": 0.25813,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:28.375102",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/freesound-audio-tagging-2019_3d5bf9bd-b3d3-4aa4-8cbc-f3d2237f52f1/2024-09-23T16-28-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:28.393568",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/iwildcam-2019-fgvc6_2087221f-0915-4f77-8a86-75233ff8cc4b/2024-09-23T16-29-29-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.8798,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:28.406317",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/siim-isic-melanoma-classification_53fe2c05-46f0-450f-82b7-a22560bf27d6/2024-09-23T16-33-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.01999,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:28.414437",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/chaii-hindi-and-tamil-question-answering_72f361ed-533a-48eb-8a4c-c8f3bd1935ed/2024-09-23T16-33-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:28.423179",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/siim-covid19-detection_fd625f7e-7796-4fa8-a1f4-88915fe1d4c1/2024-09-23T16-37-22-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.48941,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:28.429806",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/rsna-miccai-brain-tumor-radiogenomic-classification_32739be1-391f-4619-a93c-60fcd43a8d61/2024-09-23T16-40-52-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": null,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T18:03:28.433536",
      "submission_path": "None"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": 0.03247,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T18:03:29.275539",
      "submission_path": "runs/2024-09-22T16-12-47-GMT_run-group_aide/google-research-identify-contrails-reduce-global-warming_1cb7a4f6-fd8d-49a3-bccc-4d2903c5a337/2024-09-23T17-21-41-GMT/submission/submission.csv"
    }
  ]
}