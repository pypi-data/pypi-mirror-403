{
  "total_runs": 213,
  "total_runs_with_submissions": 146,
  "total_valid_submissions": 94,
  "total_medals": 3,
  "total_gold_medals": 3,
  "total_silver_medals": 0,
  "total_bronze_medals": 0,
  "total_above_median": 5,
  "competition_reports": [
    {
      "competition_id": "mlsp-2013-birds",
      "score": null,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:20.198674",
      "submission_path": "None"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.56375,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:20.231321",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/random-acts-of-pizza_6062e0c3-90e4-422e-b0af-09c7f9dab2c7/2024-09-12T16-00-20-GMT/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:26:22.872691",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/denoising-dirty-documents_bcede7d7-3ff4-425b-aa74-ea1f149869ef/2024-09-13T15-03-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.0,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:23.777926",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/tabular-playground-series-dec-2021_b9fbdbaa-0c1d-4e5c-a97f-4523f62f5229/2024-09-12T17-00-17-GMT/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:26:26.587334",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/denoising-dirty-documents_3117ff96-ef74-4155-9d87-fac2b23ab8e9/2024-09-13T14-01-06-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.0833,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:26.709459",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/tweet-sentiment-extraction_de4735ea-8201-43f2-b667-60dbfd081a8c/2024-09-12T20-01-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.65168,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:26.725558",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/aptos2019-blindness-detection_32bd2f41-fa7e-4de3-92bc-e7713ff4f0d7/2024-09-12T19-02-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": null,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:27.497292",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/h-and-m-personalized-fashion-recommendations_7531dd79-5be7-4a74-8ba6-6f67e3f025d4/2024-09-13T09-14-38-GMT/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.61136,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:27.509374",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/cassava-leaf-disease-classification_1872b902-9b48-4fcc-a004-6d897f89e075/2024-09-12T17-02-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 0.5,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:28.043909",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/aerial-cactus-identification_096dc781-bb2c-408e-84c1-8cca7e8f3052/2024-09-12T15-02-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": null,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:28.056874",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/osic-pulmonary-fibrosis-progression_785bd568-65cf-40bc-a5a8-eae483819f21/2024-09-12T15-02-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.79793,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:28.158387",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/histopathologic-cancer-detection_3789f84e-4cbc-46d1-bfba-e69f41556e1a/2024-09-12T15-02-24-GMT/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.61905,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:26:28.200997",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/spooky-author-identification_3eff727a-36e9-4855-b895-87e56c5d7dde/2024-09-12T15-02-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": null,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:28.963567",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/uw-madison-gi-tract-image-segmentation_ac82ddfb-58fe-426c-af22-ff363f4d978b/2024-09-13T01-03-20-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.14833,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:28.985331",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/plant-pathology-2021-fgvc8_55a8edb7-a0b7-40da-9603-3f256d8ed02f/2024-09-12T20-02-36-GMT/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.67115,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:28.994571",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/cassava-leaf-disease-classification_30ed2d37-47be-43d9-a23d-fae702e95f19/2024-09-12T15-02-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:29.902592",
      "submission_path": "None"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": null,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:26:29.944178",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/hms-harmful-brain-activity-classification_3747a25c-2710-4bb9-8c18-733399dd5e1e/2024-09-12T19-02-36-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 0.50362,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:29.957159",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/aerial-cactus-identification_43a6b021-895f-4eca-90b6-3f75f73c09ff/2024-09-12T17-02-31-GMT/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": null,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:26:30.055983",
      "submission_path": "None"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.88034,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:30.075385",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/detecting-insults-in-social-commentary_bddd34e4-987f-4e2c-9d8f-1eb4375f5470/2024-09-12T16-02-27-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.6274,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:30.754997",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/tabular-playground-series-may-2022_4b79c3e1-ce49-4954-88f4-70c867ce0143/2024-09-13T14-03-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.95292,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:26:30.764620",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/nomad2018-predict-transparent-conductors_57ff3a05-7941-4a7e-92e6-aff96b2c70a5/2024-09-12T15-02-24-GMT/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": null,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:30.767596",
      "submission_path": "None"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": null,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:26:30.770623",
      "submission_path": "None"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:26:31.325941",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/text-normalization-challenge-russian-language_8615c260-074a-42d6-967a-71fa7d77a112/2024-09-13T14-03-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:28:44.824528",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/tensorflow2-question-answering_641d8199-0625-4042-9022-01a4c5d2123b/2024-09-13T11-02-58-GMT/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": null,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:11.788815",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/mlsp-2013-birds_fd6a9ab8-515d-462e-9cda-082c7a300d20/2024-09-13T09-28-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:11.800096",
      "submission_path": "None"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": null,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:11.814520",
      "submission_path": "None"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": null,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:29:12.877324",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/bms-molecular-translation_89abe920-4ad9-4bda-9b55-14b343b7319f/2024-09-13T14-12-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.97228,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:13.487678",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/jigsaw-toxic-comment-classification-challenge_1febadf6-1826-425f-b0c6-2861eddc057b/2024-09-12T15-08-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": null,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:13.604679",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/3d-object-detection-for-autonomous-vehicles_deafa1ba-32b6-44ed-8e13-f1f5460de700/2024-09-13T14-09-58-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:13.607507",
      "submission_path": "None"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": null,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:13.611030",
      "submission_path": "None"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": null,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:13.614208",
      "submission_path": "None"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.71378,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:13.632675",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/detecting-insults-in-social-commentary_7352b7c4-3b5a-47d2-8978-61a137f5f0a1/2024-09-12T15-08-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": null,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:29:13.682769",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/smartphone-decimeter-2022_edac6370-1d7a-4d12-b9c4-b4b16e6e84b0/2024-09-13T14-10-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 62373660003978.44,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:29:13.757930",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/new-york-city-taxi-fare-prediction_d2e64cdf-2d3a-4c67-a516-bfaa23503cb7/2024-09-13T05-11-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": null,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:29:13.899828",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/multi-modal-gesture-recognition_bdc150a8-55a1-4856-a064-0f0fd59f0636/2024-09-12T19-20-10-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.70362,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:13.906639",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/aptos2019-blindness-detection_fc39410a-dad5-4d86-96b0-ecbb8ce26a4f/2024-09-12T15-12-25-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": null,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:13.910231",
      "submission_path": "None"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:13.921109",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/hotel-id-2021-fgvc8_523f6ba9-b5ab-4aa8-97d8-86674e6148c4/2024-09-13T14-13-52-GMT/submission/submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": null,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:15.374452",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/seti-breakthrough-listen_1beee537-a7b0-4b1e-a635-a52c3186830d/2024-09-13T14-17-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:29:15.381359",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/inaturalist-2019-fgvc6_43adf81b-bbf6-4ffa-b146-51377e1fa9f3/2024-09-12T15-14-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": 0.0,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:20.029032",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/text-normalization-challenge-russian-language_a9c77af4-179c-449a-bff6-5f90b1e688ce/2024-09-13T03-15-55-GMT/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.5,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:20.075429",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/random-acts-of-pizza_fcfb2de9-b7dc-4a25-b6dc-be6a2245aabf/2024-09-12T15-15-01-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": null,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:20.078841",
      "submission_path": "None"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.95676,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:20.829764",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/tabular-playground-series-dec-2021_799fe89e-737a-4d68-b6bc-6ea2cb313d4b/2024-09-12T16-15-25-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.50692,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:29:20.892341",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/nomad2018-predict-transparent-conductors_eded4323-5265-4763-8987-1638e9b5dd40/2024-09-12T19-15-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.78585,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:20.977040",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/plant-pathology-2021-fgvc8_57ba37e2-cd38-42c4-80f3-0143802dfb5f/2024-09-12T16-16-52-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": null,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:21.040790",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/herbarium-2022-fgvc9_e0437832-264b-44a6-96ab-91f714526fba/2024-09-13T14-18-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": null,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:21.049689",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/osic-pulmonary-fibrosis-progression_4362283f-4198-4697-9ee7-421def5f774f/2024-09-12T18-17-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:21.052669",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:21.055393",
      "submission_path": "None"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.89208,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:21.065469",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/plant-pathology-2020-fgvc7_1bf1a473-e1aa-4a81-b95f-5163163afbdc/2024-09-12T15-16-50-GMT/submission/submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.99814,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:29:21.104639",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/inaturalist-2019-fgvc6_e05cc12c-1073-470f-8051-3da98bedafd5/2024-09-12T16-16-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": null,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:29:21.125776",
      "submission_path": "None"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": null,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:29:21.128729",
      "submission_path": "None"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:21.131369",
      "submission_path": "None"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": null,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:29:21.133902",
      "submission_path": "None"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.82544,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:21.143505",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/plant-pathology-2020-fgvc7_7537b70d-3137-466e-a9c0-8a20dd3f8cac/2024-09-12T15-19-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": null,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:30.797889",
      "submission_path": "None"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:29:35.396628",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/denoising-dirty-documents_8fa0e265-6ab8-43f4-9552-f75882a91eea/2024-09-13T14-25-26-GMT/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 2.77689,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:29:36.137712",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/champs-scalar-coupling_8b5970ac-5d6f-43ab-b6d8-a719cd7045e5/2024-09-13T14-20-44-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.94472,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:36.718484",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/jigsaw-toxic-comment-classification-challenge_9b892269-0e06-4a11-b939-c82b5fd9ad33/2024-09-12T17-19-48-GMT/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.5,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:36.739795",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/detecting-insults-in-social-commentary_a81bd1ae-a437-4925-b357-77190e9bd2e0/2024-09-12T15-19-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.31023,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:36.787065",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/google-quest-challenge_96c38000-a209-44d5-b4aa-e4ee2d1e44b7/2024-09-13T01-21-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": null,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:36.793414",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/vesuvius-challenge-ink-detection_f33bc59a-c162-4e8d-96db-e48476c484e1/2024-09-13T14-23-09-GMT/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.60052,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:36.802484",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/cassava-leaf-disease-classification_075322d2-151b-444d-9074-3e07aa35655d/2024-09-12T17-19-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": null,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:36.805538",
      "submission_path": "None"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:29:36.823713",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/hotel-id-2021-fgvc8_46e5169c-583b-4132-9c4a-2171fc0ffbf6/2024-09-13T14-21-22-GMT/submission/submission.csv"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:30:28.237882",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/icecube-neutrinos-in-deep-ice_00dae968-febf-469d-b30c-02a24dce884d/2024-09-13T14-45-06-GMT/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": null,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:30:28.257194",
      "submission_path": "None"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": null,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:29.629143",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/uw-madison-gi-tract-image-segmentation_adca47f2-0b6e-4e4a-b678-29935e892117/2024-09-13T06-28-33-GMT/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": null,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:29.634536",
      "submission_path": "None"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:30:29.637410",
      "submission_path": "None"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": null,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:29.649123",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/google-quest-challenge_bee3da61-a72c-4750-9fd2-a4e7b14dc5de/2024-09-13T14-33-31-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:35.271120",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/tensorflow2-question-answering_ad146785-69e6-44d5-a7f6-0061197441ed/2024-09-13T14-32-16-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.67121,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:35.564084",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/plant-pathology-2021-fgvc8_15daaebc-64e5-40fe-9edf-409e149e1a56/2024-09-12T15-27-05-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.64308,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:37.349615",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/aptos2019-blindness-detection_a47c18ef-238b-45d5-926c-5e91caa48121/2024-09-12T15-28-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:37.748744",
      "submission_path": "None"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.00036,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:37.884335",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/tweet-sentiment-extraction_c52ea54f-5f3d-4b67-adce-62a7799c3c5d/2024-09-12T15-29-02-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.95835,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:38.569638",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/tabular-playground-series-dec-2021_561936e1-1aa7-4bc8-b089-59cb320f38f5/2024-09-12T16-29-07-GMT/submission/submission.csv"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": null,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:30:39.396950",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/smartphone-decimeter-2022_130b86da-cd45-4793-a1ad-845116b3765f/2024-09-13T14-40-55-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:39.971586",
      "submission_path": "None"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.45527,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:30:39.983956",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/spooky-author-identification_dcb0704a-3811-447f-80bd-a5010ea1c767/2024-09-12T15-30-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": null,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:39.994912",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/osic-pulmonary-fibrosis-progression_616edd55-b88a-4779-b1bd-6c2e620f681f/2024-09-12T15-30-34-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.89841,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:40.689453",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/tabular-playground-series-may-2022_3ed76801-e985-40bc-91c4-920bd9162b9e/2024-09-12T15-30-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": 0.58545,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:40.701013",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/alaska2-image-steganalysis_510b065f-eab5-45f5-a21a-14b80d5f94a7/2024-09-12T21-31-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": null,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:40.770966",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/herbarium-2022-fgvc9_9398c204-3b31-41ef-bb3e-d332d5834876/2024-09-13T14-39-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.16169,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:40.791851",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/whale-categorization-playground_5e1b5415-3d34-4c23-bccf-bb917d8ce04d/2024-09-12T17-33-10-GMT/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": null,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:40.795747",
      "submission_path": "None"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.11418,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:40.808169",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/whale-categorization-playground_464ebd30-e95e-4c91-b0ad-c51b2b4eb20a/2024-09-13T02-33-25-GMT/submission/submission.csv"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": null,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:40.811229",
      "submission_path": "None"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": null,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:30:40.814506",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/multi-modal-gesture-recognition_f9143d3a-7da1-4f50-89c4-f54d183b2c9e/2024-09-12T16-33-13-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": 0.09992,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:54.564619",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/vesuvius-challenge-ink-detection_bb7dd5f7-9e4c-4dee-8a52-aeacdbfac5fb/2024-09-12T15-34-24-GMT/submission/submission.csv"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": null,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:30:54.568140",
      "submission_path": "None"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": null,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:54.584808",
      "submission_path": "None"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": null,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:54.596431",
      "submission_path": "None"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": 1.53495,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:30:54.665384",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/hms-harmful-brain-activity-classification_a7bf4133-8b66-45ca-b6a6-419e13ac3f4d/2024-09-12T16-37-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": 0.0,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:54.674245",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/rsna-breast-cancer-detection_b59876d2-e785-48ef-af03-cdb32a493e30/2024-09-13T10-54-48-GMT/submission/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.49848,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:54.902634",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/histopathologic-cancer-detection_ad6c7377-e722-419d-b430-0d7cdb9b4531/2024-09-12T20-40-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": null,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:30:56.365568",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/bms-molecular-translation_185054e2-958a-4d23-bc88-24ab8fc94a3f/2024-09-13T09-41-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": null,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:56.390501",
      "submission_path": "None"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 0.66761,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:30:56.966034",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/champs-scalar-coupling_fff30514-3364-4058-9e9c-e9babef0aef7/2024-09-13T14-41-55-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.97196,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:57.532951",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/jigsaw-toxic-comment-classification-challenge_2ef74b8a-470f-4cf7-88b2-aae6665933f2/2024-09-12T18-41-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 12156478.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:30:57.541488",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/predict-volcanic-eruptions-ingv-oe_1b83e800-bd75-41fb-8499-29d428d0ff96/2024-09-12T21-42-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": null,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:30:57.559412",
      "submission_path": "None"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": 0.0,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:21.281018",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/hubmap-kidney-segmentation_f492798d-271f-45b8-ba84-b31f63e927c2/2024-09-12T17-42-57-GMT/submission/submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": null,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:47.623202",
      "submission_path": "None"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.55369,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:31:47.649627",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/spooky-author-identification_1e212040-1a80-44c0-8088-c073e21412c9/2024-09-12T15-45-48-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:47.651995",
      "submission_path": "None"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:47.675410",
      "submission_path": "None"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": 0.0,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.121416",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/vinbigdata-chest-xray-abnormalities-detection_eb0fd02a-2d24-4f54-88f0-e76a9f4889ca/2024-09-12T18-50-20-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.00026,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.138837",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/tweet-sentiment-extraction_3ed5145c-4fad-491f-b620-da64699dd4d2/2024-09-12T16-50-56-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 0.5,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.151839",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/aerial-cactus-identification_4f32c7ea-c184-41c7-a9c9-a082923c97f0/2024-09-12T16-51-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.159196",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/plant-pathology-2020-fgvc7_53ce0f6a-7a47-4a34-bf71-33e784ed83e6/2024-09-13T14-54-15-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": null,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.162262",
      "submission_path": "None"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.5,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.209199",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/random-acts-of-pizza_3b523dde-543f-4715-a2f6-eb17fd821276/2024-09-13T01-57-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": null,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:31:49.211476",
      "submission_path": "None"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.245345",
      "submission_path": "None"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.254905",
      "submission_path": "None"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:31:49.279604",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.281827",
      "submission_path": "None"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": null,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.425493",
      "submission_path": "None"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": null,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.428111",
      "submission_path": "None"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": null,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.430689",
      "submission_path": "None"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.12109,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:31:49.436891",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/nomad2018-predict-transparent-conductors_31bd32e2-656c-454d-981c-4af0f12807c3/2024-09-12T16-02-48-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": null,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.439162",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.463767",
      "submission_path": "None"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": 3.83492,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:31:49.520782",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/hms-harmful-brain-activity-classification_037bb961-136f-4ca1-8da3-4f19edf8fa2d/2024-09-12T19-09-02-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.634050",
      "submission_path": "None"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T21:31:49.636707",
      "submission_path": "None"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": null,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T21:31:49.641672",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/rsna-breast-cancer-detection_70931922-ae8f-4f37-b52f-b49143d88f9d/2024-09-13T05-33-14-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 7.54742,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:30.841822",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/ventilator-pressure-prediction_4e490297-6c4c-47c1-be73-bd376c714ab8/2024-09-12T14-59-45-GMT/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.93083,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:30.853890",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/leaf-classification_1636b3b9-218b-46cf-8d1b-7d0720b51f24/2024-09-12T14-59-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": null,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:30.859672",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/statoil-iceberg-classifier-challenge_99f23812-51dd-4ba0-8b41-dd641b81305c/2024-09-13T14-01-13-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.5173,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:30.866640",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/dogs-vs-cats-redux-kernels-edition_95d25479-8805-4e34-9529-d20356d6d6dd/2024-09-12T22-00-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.0,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:30.873442",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/chaii-hindi-and-tamil-question-answering_a074b1fb-0105-42d1-8a7f-309c527b15ec/2024-09-12T16-02-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": null,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:30.876379",
      "submission_path": "None"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.00658,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:30.892758",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/chaii-hindi-and-tamil-question-answering_b231ebfb-fc9a-4a0c-8ee3-0aeb98836db0/2024-09-12T15-00-11-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 23.56883,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:30.901328",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/petfinder-pawpularity-score_1ab31118-7225-4278-bc23-b4fa21b020d7/2024-09-12T15-00-12-GMT/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": null,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:30.903860",
      "submission_path": "None"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": null,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:30.908199",
      "submission_path": "None"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": null,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:31.259904",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/text-normalization-challenge-english-language_e36b3ac6-ad3a-4fc0-b861-a67dc015730e/2024-09-13T14-03-45-GMT/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": null,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:31.289832",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/the-icml-2013-whale-challenge-right-whale-redux_6e2cd933-b780-48cb-894f-40907fcfc5fe/2024-09-13T14-05-45-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": 0.55305,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:31.345663",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/ranzcr-clip-catheter-line-classification_12657f1e-6f9b-411d-b725-f6272ce85fc9/2024-09-12T15-02-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 18.13717,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:31.352566",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/dogs-vs-cats-redux-kernels-edition_8d07177d-b6e3-4a55-85d1-fd3364ff04aa/2024-09-12T15-02-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": null,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:31.354910",
      "submission_path": "None"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:32.060233",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/billion-word-imputation_b6836e34-62a3-4a91-96a2-42d010258ccf/2024-09-13T14-04-07-GMT/submission/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.3618,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:32.091551",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/us-patent-phrase-to-phrase-matching_a8585236-aede-4b21-917a-838a4debd922/2024-09-12T15-02-24-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 12.38995,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:32.135477",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/dog-breed-identification_38abeec0-d0cf-4b47-917c-70390157ec91/2024-09-13T00-03-14-GMT/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:32.536493",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/billion-word-imputation_c06c1c07-dede-4cad-9d1d-8967613a7446/2024-09-13T14-03-22-GMT/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": 0.02197,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:33.038865",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/freesound-audio-tagging-2019_d0b6b2ce-cde4-4d8c-a7de-2ff162a1c9c2/2024-09-12T16-02-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:33.054251",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/iwildcam-2019-fgvc6_0edabfae-6957-4eaa-aa70-520746b4e762/2024-09-13T14-04-08-GMT/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": null,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:33.057330",
      "submission_path": "None"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.0,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:36.549713",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/kuzushiji-recognition_5adf8f9d-0006-448c-ab9c-68cf61904810/2024-09-13T00-11-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.93083,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:36.563660",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/leaf-classification_a02ec858-174f-4063-a049-d3e968b171d9/2024-09-12T15-08-44-GMT/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.5434,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:36.615527",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/learning-agency-lab-automated-essay-scoring-2_b6a40042-f934-4a31-a3f0-509240650635/2024-09-12T18-09-06-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 1.09168,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:36.755455",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/lmsys-chatbot-arena_e46abd32-5f9a-4286-b989-8ba790fcdd53/2024-09-12T20-12-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.5,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:37.991828",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/jigsaw-unintended-bias-in-toxicity-classification_4dbfe0e4-93fc-44e6-ac39-a1b4300e50e1/2024-09-13T13-13-22-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": null,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:38.002345",
      "submission_path": "None"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:38.006111",
      "submission_path": "None"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:38.016202",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/iwildcam-2019-fgvc6_affa0f78-a732-4bb9-a560-fb535ab13c0c/2024-09-13T02-14-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": 0.02627,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:38.129543",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/imet-2020-fgvc7_cb9936b5-a076-4dc7-96a3-b8393d13fb7b/2024-09-13T00-13-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.73128,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:38.165774",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/learning-agency-lab-automated-essay-scoring-2_f97e6d30-2516-4ff1-a7b8-5f1e3e6f527d/2024-09-12T15-12-27-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": null,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:38.754292",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/ventilator-pressure-prediction_57bdfe4e-864a-4e12-aee1-361b76cf8f4f/2024-09-13T14-15-51-GMT/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.40837,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:38.804208",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/the-icml-2013-whale-challenge-right-whale-redux_5b3fbb62-5bd5-4f89-bb96-7b0600d79983/2024-09-12T17-15-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": null,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:38.808177",
      "submission_path": "None"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.48879,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:38.823135",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/us-patent-phrase-to-phrase-matching_e76aae68-e422-4204-9099-a08b2d853920/2024-09-12T17-16-53-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": null,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:38.830959",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/tgs-salt-identification-challenge_52abb46b-0a6b-4fcd-b152-0acc67eab081/2024-09-13T04-21-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": 0.28551,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:48.141153",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/facebook-recruiting-iii-keyword-extraction_045878d0-918b-445b-aba5-e26b3d6031e9/2024-09-13T14-20-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 1.19847,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:48.259780",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/dog-breed-identification_b7f5171f-ca33-401e-ab11-171ec310ee47/2024-09-12T18-19-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.48875,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:49.398275",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/jigsaw-unintended-bias-in-toxicity-classification_79ec2581-0cdb-4b21-9655-3890e7ad1e8d/2024-09-12T17-20-25-GMT/submission/submission.csv"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:49.406337",
      "submission_path": "None"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.5,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:49.417515",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/siim-isic-melanoma-classification_3450d41c-b45e-4b3f-a508-4d1b65848bfd/2024-09-12T16-23-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": 10.27943,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:51.059157",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/billion-word-imputation_01b6cde7-0aa8-4571-9083-83879cbc326d/2024-09-12T16-27-25-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": null,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:51.437411",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/text-normalization-challenge-english-language_d75717bc-05ac-4b37-a683-c7218d99a845/2024-09-13T14-31-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": null,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:51.461242",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/statoil-iceberg-classifier-challenge_8387aa9c-9db0-42cc-a3d4-66e7472b7ea6/2024-09-13T14-33-37-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": 0.378,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:52.165891",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/tgs-salt-identification-challenge_e1f9c912-651a-4a7b-b7db-036343dd6803/2024-09-12T17-29-36-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": null,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:52.169103",
      "submission_path": "None"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.5,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:52.213208",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/the-icml-2013-whale-challenge-right-whale-redux_44956594-4de1-4723-8492-10e5c4b2322c/2024-09-12T21-37-33-GMT/submission/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": null,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:52.217339",
      "submission_path": "None"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 4.74618,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:52.741452",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/ventilator-pressure-prediction_d7bed121-cb5b-410c-a213-0df9ce05499a/2024-09-12T15-30-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 20.14662,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:52.750719",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/petfinder-pawpularity-score_72aecf01-c802-42cd-b3b6-02693729d477/2024-09-12T15-32-55-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.66763,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:52.763616",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/siim-isic-melanoma-classification_0ac3c0ed-cdfb-4d6f-affd-b2f1499e25ca/2024-09-12T16-36-08-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 29.15654,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:52.772121",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/petfinder-pawpularity-score_cda9c010-30ca-4be9-a656-fb7881c6d8df/2024-09-13T03-37-26-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:52.778809",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/siim-covid19-detection_d354ad76-0b20-48f2-bbcd-69772cff72b3/2024-09-13T14-55-10-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": null,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:52.892746",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/lmsys-chatbot-arena_fafd0406-23a4-447c-a8c8-8b3fd7e165d6/2024-09-13T14-38-27-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": null,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:52.898975",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/rsna-miccai-brain-tumor-radiogenomic-classification_679e3326-91b3-4361-81fe-35643be2ffb9/2024-09-13T06-53-25-GMT/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": null,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:52.909224",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/freesound-audio-tagging-2019_acc39b2d-1296-4fb5-a1c8-58c16af24d42/2024-09-13T03-48-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": null,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:52.913031",
      "submission_path": "None"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.0,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.434082",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/kuzushiji-recognition_0d051748-7712-4296-bdd6-deb94bc0cfc2/2024-09-13T04-47-29-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 5.70805,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:56.443506",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/dogs-vs-cats-redux-kernels-edition_918437b6-20de-4282-af0e-44bdc1e7a8d2/2024-09-12T16-45-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": null,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.461252",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/kuzushiji-recognition_ea9f94a9-3589-4c08-9058-8ee45e839c31/2024-09-13T04-55-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.479038",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/siim-covid19-detection_dab11d70-f698-4453-bf3a-f908e743be99/2024-09-13T13-56-20-GMT/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.01935,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.486353",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/chaii-hindi-and-tamil-question-answering_fdfadc47-cbed-4cab-8ee2-7c8b20046c40/2024-09-12T16-49-29-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.489135",
      "submission_path": "None"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.51568,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.526601",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/learning-agency-lab-automated-essay-scoring-2_d3dbbb28-356b-4020-9aed-e2ea7eec523e/2024-09-12T16-54-13-GMT/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": null,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:56.531245",
      "submission_path": "None"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": null,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.536034",
      "submission_path": "None"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": null,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:56.552107",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/rsna-2022-cervical-spine-fracture-detection_4173546e-30fa-464d-88c8-7170737f4b60/2024-09-13T15-00-31-GMT/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.91075,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:56.565211",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/leaf-classification_a11c6908-3bc7-45c2-bb46-6bea4e42fc59/2024-09-12T16-57-36-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": null,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.573344",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/ranzcr-clip-catheter-line-classification_b1529ae0-851b-47e9-9dcd-40c636b8fe51/2024-09-13T15-14-51-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": null,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.593976",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/rsna-miccai-brain-tumor-radiogenomic-classification_0acea3d8-e841-422e-a6e3-b07f416403dd/2024-09-13T16-02-50-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": null,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:56.729996",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/lmsys-chatbot-arena_ecdb61d9-e11a-45c4-a41f-f2af71481cb5/2024-09-13T15-02-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": null,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:56.754392",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/rsna-2022-cervical-spine-fracture-detection_ad5e56c3-efef-45fa-8e9b-17e1a0c462b7/2024-09-12T20-04-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.756927",
      "submission_path": "None"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": 12.41164,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:59:56.819403",
      "submission_path": "runs/2024-09-12T13-52-30-UTC_run-group_mlagentbench/rsna-2022-cervical-spine-fracture-detection_92e7f533-7549-47b6-be18-37eb523c419d/2024-09-13T05-14-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": null,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.823191",
      "submission_path": "None"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": null,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.826741",
      "submission_path": "None"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": null,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:59:56.830294",
      "submission_path": "None"
    }
  ]
}