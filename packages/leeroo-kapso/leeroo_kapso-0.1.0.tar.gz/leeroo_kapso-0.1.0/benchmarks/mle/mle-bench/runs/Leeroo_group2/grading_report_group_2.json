{
  "total_runs": 40,
  "total_runs_with_submissions": 37,
  "total_valid_submissions": 37,
  "total_medals": 37,
  "total_gold_medals": 18,
  "total_silver_medals": 10,
  "total_bronze_medals": 9,
  "total_above_median": 37,
  "competition_reports": [
    {
      "competition_id": "aerial-cactus-identification",
      "score": 1.0,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:37:00.251798",
      "submission_path": "2/aerial-cactus-identification/final_submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.9239,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:37:00.334821",
      "submission_path": "2/aptos2019-blindness-detection/final_submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": 0.03547,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:37:17.741969",
      "submission_path": "2/denoising-dirty-documents/final_submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.95079,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:37:17.947461",
      "submission_path": "2/detecting-insults-in-social-commentary/final_submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.00377,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:37:18.035813",
      "submission_path": "2/dogs-vs-cats-redux-kernels-edition/final_submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.99635,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:37:18.279902",
      "submission_path": "2/histopathologic-cancer-detection/final_submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": null,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:37:18.328964",
      "submission_path": "2/jigsaw-toxic-comment-classification-challenge/final_submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.00054,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:37:18.409956",
      "submission_path": "2/leaf-classification/final_submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": 0.88775,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:37:18.476230",
      "submission_path": "2/mlsp-2013-birds/final_submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.06067,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:37:18.537689",
      "submission_path": "2/nomad2018-predict-transparent-conductors/final_submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.9985,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:37:18.598695",
      "submission_path": "2/plant-pathology-2020-fgvc7/final_submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.23026,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:37:18.663030",
      "submission_path": "2/spooky-author-identification/final_submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.96299,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:37:20.405422",
      "submission_path": "2/tabular-playground-series-dec-2021/final_submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": 0.99109,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:37:23.763845",
      "submission_path": "2/text-normalization-challenge-english-language/final_submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:37:23.835721",
      "submission_path": "2/text-normalization-challenge-russian-language/final_submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.99056,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:37:23.982367",
      "submission_path": "2/the-icml-2013-whale-challenge-right-whale-redux/final_submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": 0.18038,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:54.789462",
      "submission_path": "2/3d-object-detection-for-autonomous-vehicles/final_submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": 0.4312,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:54.844695",
      "submission_path": "2/iwildcam-2019-fgvc6/final_submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 3405105.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:49:54.860213",
      "submission_path": "2/predict-volcanic-eruptions-ingv-oe/final_submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.58235,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:54.871091",
      "submission_path": "2/rsna-miccai-brain-tumor-radiogenomic-classification/final_submission.csv"
    },
    {
      "competition_id": "stanford-covid-vaccine",
      "score": 0.33643,
      "gold_threshold": 0.34728,
      "silver_threshold": 0.35175,
      "bronze_threshold": 0.3534,
      "median_threshold": 0.363095,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:49:54.993052",
      "submission_path": "2/stanford-covid-vaccine/final_submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": 0.33286,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:57.144063",
      "submission_path": "2/vinbigdata-chest-xray-abnormalities-detection/final_submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.90359,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:57.158344",
      "submission_path": "2/cassava-leaf-disease-classification/final_submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.75104,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:57.170405",
      "submission_path": "2/chaii-hindi-and-tamil-question-answering/final_submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.38529,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:57.206126",
      "submission_path": "2/google-quest-challenge/final_submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": 0.22804,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:57.494929",
      "submission_path": "2/herbarium-2020-fgvc7/final_submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": 0.21226,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:58.115803",
      "submission_path": "2/herbarium-2021-fgvc8/final_submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.72679,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:58.320922",
      "submission_path": "2/herbarium-2022-fgvc9/final_submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.08951,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:58.367063",
      "submission_path": "2/hotel-id-2021-fgvc8/final_submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.12578,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:49:58.399867",
      "submission_path": "2/inaturalist-2019-fgvc6/final_submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": 0.71845,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:58.518606",
      "submission_path": "2/iwildcam-2020-fgvc7/final_submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": null,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:58.526869",
      "submission_path": "2/kuzushiji-recognition/final_submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.84264,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:58.570236",
      "submission_path": "2/learning-agency-lab-automated-essay-scoring-2/final_submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 0.98575,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:49:58.725002",
      "submission_path": "2/lmsys-chatbot-arena/final_submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 16.83145,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:49:58.740242",
      "submission_path": "2/petfinder-pawpularity-score/final_submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.91797,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:58.761795",
      "submission_path": "2/plant-pathology-2021-fgvc8/final_submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.79393,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:58.782825",
      "submission_path": "2/seti-breakthrough-listen/final_submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.71715,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:58.808428",
      "submission_path": "2/tweet-sentiment-extraction/final_submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.86881,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:58.827559",
      "submission_path": "2/us-patent-phrase-to-phrase-matching/final_submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.72205,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:49:58.844303",
      "submission_path": "2/whale-categorization-playground/final_submission.csv"
    }
  ]
}