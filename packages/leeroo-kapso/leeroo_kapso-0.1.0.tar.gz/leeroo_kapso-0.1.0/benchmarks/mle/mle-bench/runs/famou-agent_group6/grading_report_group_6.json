{
    "total_runs": 75,
    "total_runs_with_submissions": 75,
    "total_valid_submissions": 73,
    "total_medals": 44,
    "total_gold_medals": 20,
    "total_silver_medals": 15,
    "total_bronze_medals": 9,
    "total_above_median": 51,
    "competition_reports": [
        {
            "competition_id": "3d-object-detection-for-autonomous-vehicles",
            "score": 0.08332,
            "gold_threshold": 0.139,
            "silver_threshold": 0.053,
            "bronze_threshold": 0.046,
            "median_threshold": 0.042,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721442",
            "submission_path": "workspace/3/3d-object-detection-for-autonomous-vehicles/best/submission.csv"
        },
        {
            "competition_id": "AI4Code",
            "score": 0.81864,
            "gold_threshold": 0.9006,
            "silver_threshold": 0.8598,
            "bronze_threshold": 0.8534,
            "median_threshold": 0.8257,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721471",
            "submission_path": "workspace/3/AI4Code/best/submission.csv"
        },
        {
            "competition_id": "aerial-cactus-identification",
            "score": 1.0,
            "gold_threshold": 1.0,
            "silver_threshold": 1.0,
            "bronze_threshold": 1.0,
            "median_threshold": 0.9991,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721478",
            "submission_path": "workspace/3/aerial-cactus-identification/best/submission.csv"
        },
        {
            "competition_id": "alaska2-image-steganalysis",
            "score": 0.86161,
            "gold_threshold": 0.928,
            "silver_threshold": 0.921,
            "bronze_threshold": 0.915,
            "median_threshold": 0.904,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721482",
            "submission_path": "workspace/3/alaska2-image-steganalysis/best/submission.csv"
        },
        {
            "competition_id": "aptos2019-blindness-detection",
            "score": 0.92149,
            "gold_threshold": 0.930508,
            "silver_threshold": 0.919654,
            "bronze_threshold": 0.914492,
            "median_threshold": 0.888912,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721487",
            "submission_path": "workspace/3/aptos2019-blindness-detection/best/submission.csv"
        },
        {
            "competition_id": "billion-word-imputation",
            "score": 6.72768,
            "gold_threshold": 5.37017,
            "silver_threshold": 5.54372,
            "bronze_threshold": 5.55209,
            "median_threshold": 5.55211,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721491",
            "submission_path": "workspace/3/billion-word-imputation/best/submission.csv"
        },
        {
            "competition_id": "bms-molecular-translation",
            "score": 233.41726,
            "gold_threshold": 0.62,
            "silver_threshold": 1.37,
            "bronze_threshold": 1.99,
            "median_threshold": 5.58,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721495",
            "submission_path": "workspace/3/bms-molecular-translation/best/submission.csv"
        },
        {
            "competition_id": "cassava-leaf-disease-classification",
            "score": 0.90284,
            "gold_threshold": 0.9013,
            "silver_threshold": 0.8992,
            "bronze_threshold": 0.8978,
            "median_threshold": 0.8909,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721498",
            "submission_path": "workspace/3/cassava-leaf-disease-classification/best/submission.csv"
        },
        {
            "competition_id": "cdiscount-image-classification-challenge",
            "score": 0.68976,
            "gold_threshold": 0.77604,
            "silver_threshold": 0.73526,
            "bronze_threshold": 0.70898,
            "median_threshold": 0.44055,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721502",
            "submission_path": "workspace/3/cdiscount-image-classification-challenge/best/submission.csv"
        },
        {
            "competition_id": "chaii-hindi-and-tamil-question-answering",
            "score": 0.75387,
            "gold_threshold": 0.76305,
            "silver_threshold": 0.73984,
            "bronze_threshold": 0.73725,
            "median_threshold": 0.72756,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721506",
            "submission_path": "workspace/3/chaii-hindi-and-tamil-question-answering/best/submission.csv"
        },
        {
            "competition_id": "champs-scalar-coupling",
            "score": 1.47213,
            "gold_threshold": -2.87509,
            "silver_threshold": -2.03119,
            "bronze_threshold": -1.90122,
            "median_threshold": -0.9529,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721509",
            "submission_path": "workspace/3/champs-scalar-coupling/best/submission.csv"
        },
        {
            "competition_id": "denoising-dirty-documents",
            "score": 0.01342,
            "gold_threshold": 0.01794,
            "silver_threshold": 0.02609,
            "bronze_threshold": 0.04517,
            "median_threshold": 0.07325,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721513",
            "submission_path": "workspace/3/denoising-dirty-documents/best/submission.csv"
        },
        {
            "competition_id": "detecting-insults-in-social-commentary",
            "score": 0.95526,
            "gold_threshold": 0.83321,
            "silver_threshold": 0.82307,
            "bronze_threshold": 0.79111,
            "median_threshold": 0.77842,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721517",
            "submission_path": "workspace/3/detecting-insults-in-social-commentary/best/submission.csv"
        },
        {
            "competition_id": "dog-breed-identification",
            "score": 0.29637,
            "gold_threshold": 0.0005,
            "silver_threshold": 0.00539,
            "bronze_threshold": 0.04598,
            "median_threshold": 0.47205,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721520",
            "submission_path": "workspace/3/dog-breed-identification/best/submission.csv"
        },
        {
            "competition_id": "dogs-vs-cats-redux-kernels-edition",
            "score": 0.00334,
            "gold_threshold": 0.03882,
            "silver_threshold": 0.05038,
            "bronze_threshold": 0.06127,
            "median_threshold": 0.12216,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721524",
            "submission_path": "workspace/3/dogs-vs-cats-redux-kernels-edition/best/submission.csv"
        },
        {
            "competition_id": "facebook-recruiting-iii-keyword-extraction",
            "score": 0.35209,
            "gold_threshold": 0.79479,
            "silver_threshold": 0.76177,
            "bronze_threshold": 0.71345,
            "median_threshold": 0.60685,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721528",
            "submission_path": "workspace/3/facebook-recruiting-iii-keyword-extraction/best/submission.csv"
        },
        {
            "competition_id": "freesound-audio-tagging-2019",
            "score": 0.70594,
            "gold_threshold": 0.74399,
            "silver_threshold": 0.7181,
            "bronze_threshold": 0.69233,
            "median_threshold": 0.54819,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": true,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721531",
            "submission_path": "workspace/3/freesound-audio-tagging-2019/best/submission.csv"
        },
        {
            "competition_id": "google-quest-challenge",
            "score": 0.39921,
            "gold_threshold": 0.42278,
            "silver_threshold": 0.39597,
            "bronze_threshold": 0.37496,
            "median_threshold": 0.357205,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721535",
            "submission_path": "workspace/3/google-quest-challenge/best/submission.csv"
        },
        {
            "competition_id": "google-research-identify-contrails-reduce-global-warming",
            "score": 0.07215,
            "gold_threshold": 0.71059,
            "silver_threshold": 0.6936,
            "bronze_threshold": 0.67929,
            "median_threshold": 0.63819,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721538",
            "submission_path": "workspace/3/google-research-identify-contrails-reduce-global-warming/best/submission.csv"
        },
        {
            "competition_id": "h-and-m-personalized-fashion-recommendations",
            "score": 0.02416,
            "gold_threshold": 0.03354,
            "silver_threshold": 0.02517,
            "bronze_threshold": 0.02394,
            "median_threshold": 0.02177,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": true,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721542",
            "submission_path": "workspace/3/h-and-m-personalized-fashion-recommendations/best/submission.csv"
        },
        {
            "competition_id": "herbarium-2020-fgvc7",
            "score": 0.38883,
            "gold_threshold": 0.63151,
            "silver_threshold": 0.2805,
            "bronze_threshold": 0.05334,
            "median_threshold": 0.05334,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721546",
            "submission_path": "workspace/3/herbarium-2020-fgvc7/best/submission.csv"
        },
        {
            "competition_id": "herbarium-2021-fgvc8",
            "score": 0.19442,
            "gold_threshold": 0.54332,
            "silver_threshold": 0.41067,
            "bronze_threshold": 0.13026,
            "median_threshold": 0.05155,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": true,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721549",
            "submission_path": "workspace/3/herbarium-2021-fgvc8/best/submission.csv"
        },
        {
            "competition_id": "herbarium-2022-fgvc9",
            "score": 0.59754,
            "gold_threshold": 0.84602,
            "silver_threshold": 0.75373,
            "bronze_threshold": 0.5965,
            "median_threshold": 0.22549,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": true,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721553",
            "submission_path": "workspace/3/herbarium-2022-fgvc9/best/submission.csv"
        },
        {
            "competition_id": "histopathologic-cancer-detection",
            "score": 0.99577,
            "gold_threshold": 0.9835,
            "silver_threshold": 0.9798,
            "bronze_threshold": 0.9738,
            "median_threshold": 0.9477,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721556",
            "submission_path": "workspace/3/histopathologic-cancer-detection/best/submission.csv"
        },
        {
            "competition_id": "hms-harmful-brain-activity-classification",
            "score": 0.75213,
            "gold_threshold": 0.290807,
            "silver_threshold": 0.353323,
            "bronze_threshold": 0.375383,
            "median_threshold": 0.473828,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721560",
            "submission_path": "workspace/3/hms-harmful-brain-activity-classification/best/submission.csv"
        },
        {
            "competition_id": "hotel-id-2021-fgvc8",
            "score": 0.56723,
            "gold_threshold": 0.7205,
            "silver_threshold": 0.39,
            "bronze_threshold": 0.0216,
            "median_threshold": 0.0006,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721564",
            "submission_path": "workspace/3/hotel-id-2021-fgvc8/best/submission.csv"
        },
        {
            "competition_id": "hubmap-kidney-segmentation",
            "score": 0.99525,
            "gold_threshold": 0.9484,
            "silver_threshold": 0.9455,
            "bronze_threshold": 0.9439,
            "median_threshold": 0.0,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721567",
            "submission_path": "workspace/3/hubmap-kidney-segmentation/best/submission.csv"
        },
        {
            "competition_id": "icecube-neutrinos-in-deep-ice",
            "score": null,
            "gold_threshold": 0.977306,
            "silver_threshold": 1.007885,
            "bronze_threshold": 1.018571,
            "median_threshold": 1.019959,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721571",
            "submission_path": "workspace/3/icecube-neutrinos-in-deep-ice/best/submission.csv"
        },
        {
            "competition_id": "imet-2020-fgvc7",
            "score": 0.64028,
            "gold_threshold": 0.696,
            "silver_threshold": 0.649,
            "bronze_threshold": 0.649,
            "median_threshold": 0.627,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721575",
            "submission_path": "workspace/3/imet-2020-fgvc7/best/submission.csv"
        },
        {
            "competition_id": "inaturalist-2019-fgvc6",
            "score": 0.16009,
            "gold_threshold": 0.15955,
            "silver_threshold": 0.26058,
            "bronze_threshold": 0.39028,
            "median_threshold": 0.43478,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721579",
            "submission_path": "workspace/3/inaturalist-2019-fgvc6/best/submission.csv"
        },
        {
            "competition_id": "iwildcam-2019-fgvc6",
            "score": 0.40365,
            "gold_threshold": 0.212,
            "silver_threshold": 0.129,
            "bronze_threshold": 0.114,
            "median_threshold": 0.108,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721582",
            "submission_path": "workspace/3/iwildcam-2019-fgvc6/best/submission.csv"
        },
        {
            "competition_id": "iwildcam-2020-fgvc7",
            "score": 0.83619,
            "gold_threshold": 0.778,
            "silver_threshold": 0.688,
            "bronze_threshold": 0.594,
            "median_threshold": 0.524,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721586",
            "submission_path": "workspace/3/iwildcam-2020-fgvc7/best/submission.csv"
        },
        {
            "competition_id": "jigsaw-toxic-comment-classification-challenge",
            "score": 0.98678,
            "gold_threshold": 0.9874,
            "silver_threshold": 0.98668,
            "bronze_threshold": 0.98639,
            "median_threshold": 0.98079,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721590",
            "submission_path": "workspace/3/jigsaw-toxic-comment-classification-challenge/best/submission.csv"
        },
        {
            "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
            "score": 0.78315,
            "gold_threshold": 0.94608,
            "silver_threshold": 0.94304,
            "bronze_threshold": 0.94088,
            "median_threshold": 0.93417,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721593",
            "submission_path": "workspace/3/jigsaw-unintended-bias-in-toxicity-classification/best/submission.csv"
        },
        {
            "competition_id": "kuzushiji-recognition",
            "score": 0.87493,
            "gold_threshold": 0.903,
            "silver_threshold": 0.8,
            "bronze_threshold": 0.658,
            "median_threshold": 0.5985,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721597",
            "submission_path": "workspace/3/kuzushiji-recognition/best/submission.csv"
        },
        {
            "competition_id": "leaf-classification",
            "score": 0.01094,
            "gold_threshold": 0.0,
            "silver_threshold": 0.00791,
            "bronze_threshold": 0.01526,
            "median_threshold": 0.108345,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": true,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721600",
            "submission_path": "workspace/3/leaf-classification/best/submission.csv"
        },
        {
            "competition_id": "learning-agency-lab-automated-essay-scoring-2",
            "score": 0.84015,
            "gold_threshold": 0.83583,
            "silver_threshold": 0.83518,
            "bronze_threshold": 0.83471,
            "median_threshold": 0.828265,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721604",
            "submission_path": "workspace/3/learning-agency-lab-automated-essay-scoring-2/best/submission.csv"
        },
        {
            "competition_id": "lmsys-chatbot-arena",
            "score": 1.0005,
            "gold_threshold": 0.98392,
            "silver_threshold": 0.99277,
            "bronze_threshold": 1.00283,
            "median_threshold": 1.05212,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": true,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721607",
            "submission_path": "workspace/3/lmsys-chatbot-arena/best/submission.csv"
        },
        {
            "competition_id": "mlsp-2013-birds",
            "score": 0.95163,
            "gold_threshold": 0.93527,
            "silver_threshold": 0.90038,
            "bronze_threshold": 0.87372,
            "median_threshold": 0.86572,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721611",
            "submission_path": "workspace/3/mlsp-2013-birds/best/submission.csv"
        },
        {
            "competition_id": "multi-modal-gesture-recognition",
            "score": 0.24156,
            "gold_threshold": 0.13304,
            "silver_threshold": 0.1769,
            "bronze_threshold": 0.24926,
            "median_threshold": 0.322,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": true,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721614",
            "submission_path": "workspace/3/multi-modal-gesture-recognition/best/submission.csv"
        },
        {
            "competition_id": "new-york-city-taxi-fare-prediction",
            "score": 5.04806,
            "gold_threshold": 2.83377,
            "silver_threshold": 2.88191,
            "bronze_threshold": 2.92371,
            "median_threshold": 3.59741,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721618",
            "submission_path": "workspace/3/new-york-city-taxi-fare-prediction/best/submission.csv"
        },
        {
            "competition_id": "nfl-player-contact-detection",
            "score": 0.68767,
            "gold_threshold": 0.78167,
            "silver_threshold": 0.72203,
            "bronze_threshold": 0.69652,
            "median_threshold": 0.69139,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721621",
            "submission_path": "workspace/3/nfl-player-contact-detection/best/submission.csv"
        },
        {
            "competition_id": "nomad2018-predict-transparent-conductors",
            "score": 0.05946,
            "gold_threshold": 0.05589,
            "silver_threshold": 0.06229,
            "bronze_threshold": 0.06582,
            "median_threshold": 0.06988,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721625",
            "submission_path": "workspace/3/nomad2018-predict-transparent-conductors/best/submission.csv"
        },
        {
            "competition_id": "osic-pulmonary-fibrosis-progression",
            "score": -8.42463,
            "gold_threshold": -6.8412,
            "silver_threshold": -6.8533,
            "bronze_threshold": -6.8683,
            "median_threshold": -6.8993,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721628",
            "submission_path": "workspace/3/osic-pulmonary-fibrosis-progression/best/submission.csv"
        },
        {
            "competition_id": "petfinder-pawpularity-score",
            "score": 17.06002,
            "gold_threshold": 16.95041,
            "silver_threshold": 17.06636,
            "bronze_threshold": 17.0971,
            "median_threshold": 17.702984999999998,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721631",
            "submission_path": "workspace/3/petfinder-pawpularity-score/best/submission.csv"
        },
        {
            "competition_id": "plant-pathology-2020-fgvc7",
            "score": 0.98973,
            "gold_threshold": 0.97836,
            "silver_threshold": 0.97465,
            "bronze_threshold": 0.97361,
            "median_threshold": 0.94852,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721635",
            "submission_path": "workspace/3/plant-pathology-2020-fgvc7/best/submission.csv"
        },
        {
            "competition_id": "plant-pathology-2021-fgvc8",
            "score": 0.91449,
            "gold_threshold": 0.8612,
            "silver_threshold": 0.85305,
            "bronze_threshold": 0.83508,
            "median_threshold": 0.754445,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721638",
            "submission_path": "workspace/3/plant-pathology-2021-fgvc8/best/submission.csv"
        },
        {
            "competition_id": "predict-volcanic-eruptions-ingv-oe",
            "score": 3936087.0,
            "gold_threshold": 3971366.0,
            "silver_threshold": 4808057.0,
            "bronze_threshold": 4999330.0,
            "median_threshold": 6300677.0,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721642",
            "submission_path": "workspace/3/predict-volcanic-eruptions-ingv-oe/best/submission.csv"
        },
        {
            "competition_id": "random-acts-of-pizza",
            "score": 0.80063,
            "gold_threshold": 0.97908,
            "silver_threshold": 0.76482,
            "bronze_threshold": 0.6921,
            "median_threshold": 0.5995950000000001,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721645",
            "submission_path": "workspace/3/random-acts-of-pizza/best/submission.csv"
        },
        {
            "competition_id": "ranzcr-clip-catheter-line-classification",
            "score": 0.96231,
            "gold_threshold": 0.97357,
            "silver_threshold": 0.97152,
            "bronze_threshold": 0.9709,
            "median_threshold": 0.9675,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721649",
            "submission_path": "workspace/3/ranzcr-clip-catheter-line-classification/best/submission.csv"
        },
        {
            "competition_id": "rsna-2022-cervical-spine-fracture-detection",
            "score": 0.5571,
            "gold_threshold": 0.2767,
            "silver_threshold": 0.49,
            "bronze_threshold": 0.5212,
            "median_threshold": 0.5223,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721652",
            "submission_path": "workspace/3/rsna-2022-cervical-spine-fracture-detection/best/submission.csv"
        },
        {
            "competition_id": "rsna-breast-cancer-detection",
            "score": 0.30548,
            "gold_threshold": 0.49,
            "silver_threshold": 0.43,
            "bronze_threshold": 0.41,
            "median_threshold": 0.28,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721656",
            "submission_path": "workspace/3/rsna-breast-cancer-detection/best/submission.csv"
        },
        {
            "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
            "score": 0.60588,
            "gold_threshold": 0.60096,
            "silver_threshold": 0.5815,
            "bronze_threshold": 0.57449,
            "median_threshold": 0.52553,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721659",
            "submission_path": "workspace/3/rsna-miccai-brain-tumor-radiogenomic-classification/best/submission.csv"
        },
        {
            "competition_id": "seti-breakthrough-listen",
            "score": 0.81639,
            "gold_threshold": 0.79806,
            "silver_threshold": 0.78095,
            "bronze_threshold": 0.77439,
            "median_threshold": 0.75889,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721663",
            "submission_path": "workspace/3/seti-breakthrough-listen/best/submission.csv"
        },
        {
            "competition_id": "siim-covid19-detection",
            "score": 0.51323,
            "gold_threshold": 0.623,
            "silver_threshold": 0.609,
            "bronze_threshold": 0.601,
            "median_threshold": 0.586,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721666",
            "submission_path": "workspace/3/siim-covid19-detection/best/submission.csv"
        },
        {
            "competition_id": "siim-isic-melanoma-classification",
            "score": 0.92964,
            "gold_threshold": 0.9455,
            "silver_threshold": 0.9401,
            "bronze_threshold": 0.937,
            "median_threshold": 0.9128,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721669",
            "submission_path": "workspace/3/siim-isic-melanoma-classification/best/submission.csv"
        },
        {
            "competition_id": "smartphone-decimeter-2022",
            "score": 6.26602,
            "gold_threshold": 1.768,
            "silver_threshold": 2.119,
            "bronze_threshold": 3.068,
            "median_threshold": 3.3280000000000003,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721673",
            "submission_path": "workspace/3/smartphone-decimeter-2022/best/submission.csv"
        },
        {
            "competition_id": "spooky-author-identification",
            "score": 0.21679,
            "gold_threshold": 0.16506,
            "silver_threshold": 0.26996,
            "bronze_threshold": 0.29381,
            "median_threshold": 0.418785,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721676",
            "submission_path": "workspace/3/spooky-author-identification/best/submission.csv"
        },
        {
            "competition_id": "stanford-covid-vaccine",
            "score": 0.25382,
            "gold_threshold": 0.34728,
            "silver_threshold": 0.35175,
            "bronze_threshold": 0.3534,
            "median_threshold": 0.363095,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721680",
            "submission_path": "workspace/3/stanford-covid-vaccine/best/submission.csv"
        },
        {
            "competition_id": "statoil-iceberg-classifier-challenge",
            "score": 0.19071,
            "gold_threshold": 0.11374,
            "silver_threshold": 0.13753,
            "bronze_threshold": 0.14552,
            "median_threshold": 0.20371,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721683",
            "submission_path": "workspace/3/statoil-iceberg-classifier-challenge/best/submission.csv"
        },
        {
            "competition_id": "tabular-playground-series-dec-2021",
            "score": 0.95986,
            "gold_threshold": 0.9566,
            "silver_threshold": 0.95658,
            "bronze_threshold": 0.95658,
            "median_threshold": 0.95342,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721687",
            "submission_path": "workspace/3/tabular-playground-series-dec-2021/best/submission.csv"
        },
        {
            "competition_id": "tabular-playground-series-may-2022",
            "score": 0.9629,
            "gold_threshold": 0.99823,
            "silver_threshold": 0.99822,
            "bronze_threshold": 0.99818,
            "median_threshold": 0.972675,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721690",
            "submission_path": "workspace/3/tabular-playground-series-may-2022/best/submission.csv"
        },
        {
            "competition_id": "tensorflow-speech-recognition-challenge",
            "score": 0.35857,
            "gold_threshold": 0.90485,
            "silver_threshold": 0.89627,
            "bronze_threshold": 0.88793,
            "median_threshold": 0.77722,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721694",
            "submission_path": "workspace/3/tensorflow-speech-recognition-challenge/best/submission.csv"
        },
        {
            "competition_id": "tensorflow2-question-answering",
            "score": 0.57105,
            "gold_threshold": 0.68578,
            "silver_threshold": 0.62872,
            "bronze_threshold": 0.61913,
            "median_threshold": 0.59639,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721697",
            "submission_path": "workspace/3/tensorflow2-question-answering/best/submission.csv"
        },
        {
            "competition_id": "text-normalization-challenge-english-language",
            "score": 0.99059,
            "gold_threshold": 0.99724,
            "silver_threshold": 0.99135,
            "bronze_threshold": 0.99038,
            "median_threshold": 0.99037,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": true,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721701",
            "submission_path": "workspace/3/text-normalization-challenge-english-language/best/submission.csv"
        },
        {
            "competition_id": "text-normalization-challenge-russian-language",
            "score": 0.9735,
            "gold_threshold": 0.99012,
            "silver_threshold": 0.98232,
            "bronze_threshold": 0.97592,
            "median_threshold": 0.97591,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721704",
            "submission_path": "workspace/3/text-normalization-challenge-russian-language/best/submission.csv"
        },
        {
            "competition_id": "tgs-salt-identification-challenge",
            "score": 0.8011,
            "gold_threshold": 0.89097,
            "silver_threshold": 0.87163,
            "bronze_threshold": 0.85918,
            "median_threshold": 0.81665,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721708",
            "submission_path": "workspace/3/tgs-salt-identification-challenge/best/submission.csv"
        },
        {
            "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
            "score": 0.98074,
            "gold_threshold": 0.98961,
            "silver_threshold": 0.95017,
            "bronze_threshold": 0.90521,
            "median_threshold": 0.86521,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721711",
            "submission_path": "workspace/3/the-icml-2013-whale-challenge-right-whale-redux/best/submission.csv"
        },
        {
            "competition_id": "tweet-sentiment-extraction",
            "score": 0.71902,
            "gold_threshold": 0.72689,
            "silver_threshold": 0.71752,
            "bronze_threshold": 0.71705,
            "median_threshold": 0.71378,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": true,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721715",
            "submission_path": "workspace/3/tweet-sentiment-extraction/best/submission.csv"
        },
        {
            "competition_id": "us-patent-phrase-to-phrase-matching",
            "score": 0.87439,
            "gold_threshold": 0.87,
            "silver_threshold": 0.863,
            "bronze_threshold": 0.8616,
            "median_threshold": 0.851,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721718",
            "submission_path": "workspace/3/us-patent-phrase-to-phrase-matching/best/submission.csv"
        },
        {
            "competition_id": "uw-madison-gi-tract-image-segmentation",
            "score": 0.72403,
            "gold_threshold": 0.87917,
            "silver_threshold": 0.87139,
            "bronze_threshold": 0.86699,
            "median_threshold": 0.85499,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721721",
            "submission_path": "workspace/3/uw-madison-gi-tract-image-segmentation/best/submission.csv"
        },
        {
            "competition_id": "ventilator-pressure-prediction",
            "score": 0.41042,
            "gold_threshold": 0.1119,
            "silver_threshold": 0.1338,
            "bronze_threshold": 0.1364,
            "median_threshold": 0.1638,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": false,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": true,
            "created_at": "2025-12-26T09:18:38.721725",
            "submission_path": "workspace/3/ventilator-pressure-prediction/best/submission.csv"
        },
        {
            "competition_id": "vesuvius-challenge-ink-detection",
            "score": null,
            "gold_threshold": 0.779927,
            "silver_threshold": 0.725248,
            "bronze_threshold": 0.660027,
            "median_threshold": 0.418442,
            "any_medal": false,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721728",
            "submission_path": "workspace/3/vesuvius-challenge-ink-detection/best/submission.csv"
        },
        {
            "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
            "score": 0.35329,
            "gold_threshold": 0.289,
            "silver_threshold": 0.257,
            "bronze_threshold": 0.243,
            "median_threshold": 0.223,
            "any_medal": true,
            "gold_medal": true,
            "silver_medal": false,
            "bronze_medal": false,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721732",
            "submission_path": "workspace/3/vinbigdata-chest-xray-abnormalities-detection/best/submission.csv"
        },
        {
            "competition_id": "whale-categorization-playground",
            "score": 0.43883,
            "gold_threshold": 0.56236,
            "silver_threshold": 0.44852,
            "bronze_threshold": 0.40515,
            "median_threshold": 0.32788,
            "any_medal": true,
            "gold_medal": false,
            "silver_medal": false,
            "bronze_medal": true,
            "above_median": true,
            "submission_exists": true,
            "valid_submission": true,
            "is_lower_better": false,
            "created_at": "2025-12-26T09:18:38.721735",
            "submission_path": "workspace/3/whale-categorization-playground/best/submission.csv"
        }
    ]
}