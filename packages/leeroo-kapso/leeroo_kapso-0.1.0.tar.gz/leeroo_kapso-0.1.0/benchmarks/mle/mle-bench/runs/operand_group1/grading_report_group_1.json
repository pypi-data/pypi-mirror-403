{
  "total_runs": 75,
  "total_runs_with_submissions": 23,
  "total_valid_submissions": 52,
  "total_medals": 30,
  "total_gold_medals": 9,
  "total_silver_medals": 4,
  "total_bronze_medals": 17,
  "total_above_median": 33,
  "competition_reports": [
    {
      "competition_id": "aerial-cactus-identification",
      "score": 1.0,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-09T23:59:22.403352",
      "submission_path": "/app/agent_run_states/aerial-cactus-identification-20250909-223202/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.9039,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-01T18:02:27.491684",
      "submission_path": "/app/agent_run_states/aptos2019-blindness-detection-20250901-023554/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.89836,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.50045,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": null,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-25T04:35:59.197427",
      "submission_path": "/app/agent_run_states/chaii-hindi-and-tamil-question-answering-20250924-045236/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 1.99777,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": 0.01884,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-05T22:29:30.711445",
      "submission_path": "/app/agent_run_states/denoising-dirty-documents-20250905-222218/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.90942,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-09T02:58:17.252687",
      "submission_path": "/app/agent_run_states/detecting-insults-in-social-commentary-spray-20250909-024523/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 0.53653,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": null,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-06T22:45:27.219837",
      "submission_path": "/app/agent_run_states/dog-breed-identification-20250905-224800/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.02172,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-08T22:19:00.848224",
      "submission_path": "/app/agent_run_states/dogs-vs-cats-redux-kernels-edition-spray-20250908-040738/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": null,
      "gold_threshold": null,
      "silver_threshold": null,
      "bronze_threshold": null,
      "median_threshold": null,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": 0.68063,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-08-12T12:46:46.669754",
      "submission_path": "/app/agent_run_states/freesound-audio-tagging-2019/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.4105,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": 0.09606,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": 0.13696,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.65859,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.93029,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-08-12T16:16:08.342576",
      "submission_path": "/app/agent_run_states/histopathologic-cancer-detection/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.22754,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": 0.27955,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.13767,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": 0.39804,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": 0.64072,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.98047,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-08-12T13:44:35.723254",
      "submission_path": "/app/agent_run_states/jigsaw-toxic-comment-classification-challenge/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.70567,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.00948,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-09T14:50:46.098377",
      "submission_path": "/app/agent_run_states/leaf-classification-spray-20250909-033436/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.83013,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": 0.88378,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-08T03:27:30.478204",
      "submission_path": "/app/agent_run_states/mlsp-2013-birds-spray-20250908-000706/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": 0.5383,
      "gold_threshold": 0.1641,
      "silver_threshold": 0.17763,
      "bronze_threshold": 0.26608,
      "median_threshold": 0.349595,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 4.69105,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-08-23T19:59:10.033311",
      "submission_path": "/app/agent_run_states/new-york-city-taxi-fare-prediction/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.06136,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-09T04:28:02.096440",
      "submission_path": "/app/agent_run_states/nomad2018-predict-transparent-conductors-spray-20250909-035925/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": -7.19604,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 17.07046,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.98425,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-08T20:00:47.765377",
      "submission_path": "/app/agent_run_states/plant-pathology-2020-fgvc7-20250908-012834/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.91287,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 4945395.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.70063,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": 0.95833,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": null,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-12T05:03:34.556888",
      "submission_path": "/app/agent_run_states/ranzcr-clip-catheter-line-classification-spray-20250911-051254/submission.csv"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": 0.69315,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": 0.06863,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.52149,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": 0.20071,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.76117,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-08-25T00:01:03.503595",
      "submission_path": "/app/agent_run_states/siim-isic-melanoma-classification/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.28528,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-08-09T00:14:55.773418",
      "submission_path": "/home/ram_tryoperand_com/simon/agent_run_states/spooky-author-identification/submission.csv"
    },
    {
      "competition_id": "stanford-covid-vaccine",
      "score": 0.33921,
      "gold_threshold": 0.34728,
      "silver_threshold": 0.35175,
      "bronze_threshold": 0.3534,
      "median_threshold": 0.363095,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.96194,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-06T21:32:05.896662",
      "submission_path": "/app/agent_run_states/tabular-playground-series-dec-2021-20250906-203840/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.69736,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": null,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-12T21:25:41.783161",
      "submission_path": "/app/agent_run_states/tabular-playground-series-may-2022-spray-20250911-165145/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": 0.99059,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-08T21:01:27.835960",
      "submission_path": "/app/agent_run_states/text-normalization-challenge-english-language-20250908-205456/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": 0.97968,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-09T03:57:16.561390",
      "submission_path": "/app/agent_run_states/text-normalization-challenge-russian-language-spray-20250909-024401/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.9103,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-09-09T05:00:39.149855",
      "submission_path": "/app/agent_run_states/the-icml-2013-whale-challenge-right-whale-redux-spray-20250909-040125/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.71958,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.45894,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 17.65486,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": 0.11077,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.40842,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": false,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": null,
      "submission_path": "None"
    }
  ]
}