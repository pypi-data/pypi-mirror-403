{
  "total_runs": 208,
  "total_runs_with_submissions": 153,
  "total_valid_submissions": 96,
  "total_medals": 4,
  "total_gold_medals": 1,
  "total_silver_medals": 1,
  "total_bronze_medals": 2,
  "total_above_median": 6,
  "competition_reports": [
    {
      "competition_id": "aerial-cactus-identification",
      "score": 0.94311,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:17.530681",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/aerial-cactus-identification_4a8fa915-ccc7-4016-85ba-32944912af92/2024-09-09T09-37-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.94322,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:18.370797",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/tabular-playground-series-dec-2021_1a1eda0c-d671-4c79-b12b-e3a7c397e23d/2024-09-09T09-35-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.06282,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:07:18.397715",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/nomad2018-predict-transparent-conductors_e8091095-439d-40ef-a058-3cce88101197/2024-09-07T23-34-36-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.9529,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:18.776288",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/jigsaw-toxic-comment-classification-challenge_301f8bec-181c-4d5d-a334-d9a6eaa62a6f/2024-09-07T23-34-36-GMT/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:07:21.439634",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/denoising-dirty-documents_f5f91eb4-3bdf-4c9b-8602-231c3cb610f5/2024-09-09T09-36-13-GMT/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 3.6015,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:07:22.154571",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/champs-scalar-coupling_ee6694a6-5085-41e0-9408-95f7b7f8e3e7/2024-09-08T05-34-56-GMT/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.85207,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:22.178493",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/detecting-insults-in-social-commentary_b78a8f79-127f-48bd-a535-01440fc88768/2024-09-07T23-34-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.248,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:22.408174",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/tweet-sentiment-extraction_3a627796-88b6-4d37-9e45-44bfaa60b986/2024-09-08T00-34-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.55459,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:07:22.420100",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/spooky-author-identification_3e622beb-ac66-46cf-a5c8-17753d911f85/2024-09-09T09-35-55-GMT/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": null,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:22.429619",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/google-quest-challenge_3bc06a60-7eeb-46cb-9702-10ea23c21d2b/2024-09-09T09-38-44-GMT/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.33613,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:22.518096",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/google-quest-challenge_61534946-6561-473d-aa36-59fd478a117a/2024-09-08T02-34-50-GMT/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": null,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:22.684043",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/mlsp-2013-birds_193151a0-dcd5-4e48-95a0-e9a51a59e62f/2024-09-08T09-47-38-GMT/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.7507,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:22.702216",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/detecting-insults-in-social-commentary_c2782239-6828-4d5b-8256-2f8068bdc46e/2024-09-07T23-34-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:07:26.872339",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/denoising-dirty-documents_04b9a339-5017-4860-a2c8-6b06b61466e8/2024-09-08T06-53-16-GMT/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.5,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:26.979124",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/random-acts-of-pizza_fbd1f1b7-d08a-4d2e-861e-3d5a75a56fe6/2024-09-09T09-40-28-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": null,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:28.665022",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/aerial-cactus-identification_cf457819-6645-454f-a0ec-84759a39d374/2024-09-08T01-35-51-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.81712,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:28.675726",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/plant-pathology-2020-fgvc7_7767ae43-ee7e-49a4-b3d5-e1144522e36c/2024-09-08T00-35-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 1.17331,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:07:30.071135",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/champs-scalar-coupling_f66fceff-46f8-4658-89c8-db1b80dfa902/2024-09-08T00-35-48-GMT/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.3367,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:30.088725",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/cassava-leaf-disease-classification_a9adeaf7-f4b5-45f7-ad32-3d9450b50b79/2024-09-07T23-35-44-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:30.091767",
      "submission_path": "None"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.11523,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:30.106898",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/whale-categorization-playground_848a5e5b-805d-4b12-8653-ef5d58473e6d/2024-09-08T11-36-26-GMT/submission/submission.csv"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": null,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:30.110835",
      "submission_path": "None"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": null,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:30.123572",
      "submission_path": "None"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.63827,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:31.815950",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/cassava-leaf-disease-classification_e09041ce-0561-48c8-9362-3e14dce0a5ad/2024-09-08T00-35-48-GMT/submission/submission.csv"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": null,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:07:31.927558",
      "submission_path": "None"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:38.728854",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/tensorflow2-question-answering_84d75226-29dc-47a8-bde7-f4bf71243f88/2024-09-08T23-39-50-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:39.035259",
      "submission_path": "None"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": null,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:39.038758",
      "submission_path": "None"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.71213,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:39.046938",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/aptos2019-blindness-detection_6aa22d29-9796-482a-8b2d-951b40ec2fcc/2024-09-08T01-37-48-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.67942,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:39.053910",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/aptos2019-blindness-detection_cfb95940-f1dc-44bc-a3ec-2eef9085a040/2024-09-07T23-37-45-GMT/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 24419167.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:07:54.622555",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/predict-volcanic-eruptions-ingv-oe_fd16186e-5811-4ec0-bc78-bd58c073921c/2024-09-09T10-00-58-GMT/submission/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.5,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:54.739316",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/histopathologic-cancer-detection_80b0e114-a774-479c-a4ba-415f203e8054/2024-09-09T09-38-27-GMT/submission/submission.csv"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 10.022,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:07:54.776601",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/new-york-city-taxi-fare-prediction_76171b13-ce15-460e-ad37-145faa165789/2024-09-08T02-37-48-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.29173,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:07:54.798032",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/plant-pathology-2021-fgvc8_a9e0c54f-e546-41d5-a62c-cbe74a72c93e/2024-09-07T23-37-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": null,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:07:54.803690",
      "submission_path": "None"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": 1.40446,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:07:54.868510",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/hms-harmful-brain-activity-classification_8fb95285-d5f8-453e-8ec2-15fccf0ce0d6/2024-09-08T07-41-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:11.470557",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/nfl-player-contact-detection_0147d319-59fd-4440-b224-d29129f2b528/2024-09-09T09-59-42-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.06212,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:11.547072",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/nomad2018-predict-transparent-conductors_29e0203c-6612-4880-a538-cfd2336fe1c8/2024-09-08T12-39-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.95901,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:12.280078",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/jigsaw-toxic-comment-classification-challenge_b694c46c-5e0e-4f42-b6b8-280efe319b20/2024-09-09T09-40-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.5,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:12.291916",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/plant-pathology-2020-fgvc7_1b2f7098-c75f-495f-9afd-15a749000b83/2024-09-07T23-39-20-GMT/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": null,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:12.339061",
      "submission_path": "None"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 10.34466,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:12.375614",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/new-york-city-taxi-fare-prediction_df58c41e-2652-4d1d-80fe-f9a7398ca940/2024-09-08T05-39-52-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": null,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:13.492151",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/hubmap-kidney-segmentation_ed4b87c0-c6ca-4354-9b24-7994318e7f54/2024-09-08T23-40-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": null,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:13.497979",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/alaska2-image-steganalysis_79a71c20-bcae-4ed4-b444-2474ce40118b/2024-09-08T23-39-58-GMT/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": null,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:13.509931",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/osic-pulmonary-fibrosis-progression_6f3f30de-0578-4289-9704-9c475d2cd695/2024-09-07T23-39-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": 0.58571,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:13.520483",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/alaska2-image-steganalysis_769b20e1-fab9-4a4a-8cf6-358a8ee10ec4/2024-09-08T13-39-50-GMT/submission/submission.csv"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": null,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:13.553345",
      "submission_path": "None"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": null,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:13.604392",
      "submission_path": "None"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": null,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:14.142825",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/smartphone-decimeter-2022_886c2525-c342-4d8d-b053-d955c31510f4/2024-09-08T23-45-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:14.167984",
      "submission_path": "None"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": null,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:14.170902",
      "submission_path": "None"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": null,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:14.174650",
      "submission_path": "None"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": 0.0,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:27.506661",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/vesuvius-challenge-ink-detection_7e04c5da-f812-4093-953c-1f6bf9e7d937/2024-09-08T04-39-50-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:27.509724",
      "submission_path": "None"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": null,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:27.536708",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/hubmap-kidney-segmentation_27ce9cc6-2027-4a5a-bb19-3e558cdd8db0/2024-09-09T09-51-53-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:27.548709",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/hotel-id-2021-fgvc8_b398ffcd-5bae-437e-8400-edc1d6d011d4/2024-09-08T23-43-13-GMT/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": 0.0,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:29.628154",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/h-and-m-personalized-fashion-recommendations_5b26b7fa-b0c8-47c8-b618-771c09e1abac/2024-09-08T00-40-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.42067,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:29.677713",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/tweet-sentiment-extraction_e610b009-56a5-45a9-ae89-48ab37b39bce/2024-09-07T23-42-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": null,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:29.684779",
      "submission_path": "None"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": 0.92983,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:29.689926",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/multi-modal-gesture-recognition_bed60ce5-d554-47e0-8a76-353b7422df04/2024-09-09T09-44-37-GMT/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": null,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:29.700650",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/osic-pulmonary-fibrosis-progression_93e08600-fce2-457f-bb60-3750c834bcb6/2024-09-07T23-42-50-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:29.703613",
      "submission_path": "None"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.43878,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:29.782849",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/spooky-author-identification_a4f61048-d7eb-4483-bcd0-05009d0998fd/2024-09-07T23-43-11-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:30.336691",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/text-normalization-challenge-russian-language_87e5ed44-fe2a-4f39-8dba-0d9e44ccd364/2024-09-08T23-43-37-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.66108,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:31.112959",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/tabular-playground-series-may-2022_ffcb65d3-5f56-4626-b0ff-f4c00b822f8d/2024-09-07T23-43-11-GMT/submission/submission.csv"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": 0.0,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:38.083409",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/uw-madison-gi-tract-image-segmentation_12962d7c-ad41-4891-a7ac-5bf792e95c56/2024-09-09T09-56-36-GMT/submission/submission.csv"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": null,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:38.109700",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/smartphone-decimeter-2022_a4623140-da93-489a-a770-36ce8176ddeb/2024-09-09T09-12-48-GMT/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.73697,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:38.156079",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/detecting-insults-in-social-commentary_05fa8898-2c8f-4d2e-b413-8309fc36978a/2024-09-07T23-44-09-GMT/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": null,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:38.158816",
      "submission_path": "None"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.5,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:38.174746",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/random-acts-of-pizza_348996ee-659d-41ec-bbc0-d9b31e145033/2024-09-09T09-45-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.06321,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:38.180407",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/nomad2018-predict-transparent-conductors_f61cd314-8aed-42ab-9188-f70f617060d0/2024-09-07T23-45-07-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.721,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:38.186693",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/aptos2019-blindness-detection_38ba870b-655a-48a6-aaaf-a4d2a365c50a/2024-09-08T02-45-17-GMT/submission/submission.csv"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 10.07716,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:38.219046",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/new-york-city-taxi-fare-prediction_500b34f9-db64-4834-9f76-c659e9250d17/2024-09-08T02-45-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.80752,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:38.228780",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/plant-pathology-2020-fgvc7_0e339b66-e18a-469b-b5d3-acce877bf35d/2024-09-07T23-45-07-GMT/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": null,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:38.232512",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/mlsp-2013-birds_f0916d86-c808-405b-b07c-f93ed04d437c/2024-09-08T04-47-15-GMT/submission/submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": null,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:38.258311",
      "submission_path": "None"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": null,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:38.378750",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/3d-object-detection-for-autonomous-vehicles_8b94d484-2de7-4adb-ba6e-c191b56aac75/2024-09-08T23-44-07-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.9675,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:39.048807",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/jigsaw-toxic-comment-classification-challenge_d82ae4d5-343b-4d9f-b69b-2220c7da585c/2024-09-09T09-47-07-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 0.5,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:48.944325",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/aerial-cactus-identification_ea8b50de-a120-4045-8d3d-3846f6720a81/2024-09-07T23-45-33-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.95469,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:08:49.575741",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/tabular-playground-series-dec-2021_2200fb68-d9ea-4198-9d9a-7d3b72071ade/2024-09-08T06-46-07-GMT/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:55.530261",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/denoising-dirty-documents_54d36f75-30f6-42c1-a3e8-7d953653f6f2/2024-09-09T10-00-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": null,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:08:55.697723",
      "submission_path": "None"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:17.690366",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/nfl-player-contact-detection_5951d140-0573-45d3-aa8d-d81ab40783e0/2024-09-08T23-49-57-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": 0.0,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:31.029505",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/vesuvius-challenge-ink-detection_cb66ae05-84b0-4e28-9606-ce0ffc9e546b/2024-09-07T23-45-52-GMT/submission/submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:09:31.033389",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:31.035739",
      "submission_path": "None"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:32.943545",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/text-normalization-challenge-russian-language_025738f8-715d-4f2f-b111-2e92f337297b/2024-09-08T23-43-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.46732,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:09:33.033907",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/spooky-author-identification_3d08ddae-a4a3-41a6-8c87-299653abf453/2024-09-07T23-46-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.6251,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:33.763276",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/tabular-playground-series-may-2022_b994c98a-9a68-4fba-8258-c0221b94cc1e/2024-09-07T23-46-31-GMT/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.63266,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:33.774015",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/cassava-leaf-disease-classification_83816b93-9977-483b-badc-0e7630d9bcc9/2024-09-09T09-47-11-GMT/submission/submission.csv"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": null,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:09:34.568004",
      "submission_path": "None"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.85837,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:34.671209",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/histopathologic-cancer-detection_6b4de38f-ca0b-4a00-971e-bedb3dcf39dd/2024-09-07T23-46-26-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:34.690670",
      "submission_path": "None"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": null,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:34.694053",
      "submission_path": "None"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": null,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:36.159665",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/uw-madison-gi-tract-image-segmentation_cf3b29f7-5ef6-43e4-aac4-cc8dfa6ca8d5/2024-09-08T04-54-59-GMT/submission/submission.csv"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": null,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:09:37.638881",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/smartphone-decimeter-2022_dddec156-cc28-4db9-9f10-ef09cf820b61/2024-09-08T23-53-37-GMT/submission/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": null,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:09:37.785409",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/multi-modal-gesture-recognition_201167eb-2cca-4e76-a703-ac3234004897/2024-09-07T23-47-59-GMT/submission/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": null,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:37.792749",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/alaska2-image-steganalysis_8412a62b-4353-4ac3-b0ca-4b4eee630cb8/2024-09-08T23-48-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:44.101853",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/tensorflow2-question-answering_8147f7db-2c34-448c-8004-b2523d5b5565/2024-09-08T10-48-58-GMT/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": null,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:44.894088",
      "submission_path": "None"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.44298,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:44.913610",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/plant-pathology-2021-fgvc8_c6cb4a16-4460-4598-a4ed-9e1c5459c713/2024-09-08T11-48-14-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:44.916048",
      "submission_path": "None"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 24402201.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:09:59.462421",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/predict-volcanic-eruptions-ingv-oe_6ee3ea2d-b348-4077-a2dd-051513ec5bc0/2024-09-08T02-48-09-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": null,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:59.466441",
      "submission_path": "None"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:09:59.468863",
      "submission_path": "None"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.11571,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:59.496351",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/whale-categorization-playground_ef19e2e4-9113-435d-82d8-42f6a9997dbe/2024-09-09T09-51-03-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": null,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:09:59.543739",
      "submission_path": "None"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": null,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:59.554857",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/osic-pulmonary-fibrosis-progression_df2146c5-fe99-4cb9-9994-a588a112470b/2024-09-07T23-49-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:59.585591",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:59.617635",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/herbarium-2020-fgvc7_9ba55bd7-8338-4ca3-9d84-a53656b7d64a/2024-09-08T23-53-26-GMT/submission/submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": null,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:09:59.827760",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/3d-object-detection-for-autonomous-vehicles_3a978617-501b-450b-9bf1-ea01e3db7b1c/2024-09-08T23-53-27-GMT/submission/submission.csv"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:10:09.704139",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/icecube-neutrinos-in-deep-ice_2b7de25e-a058-4b8c-8733-e0e6b7ba9734/2024-09-08T23-51-13-GMT/submission/submission.csv"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:10:19.478414",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/icecube-neutrinos-in-deep-ice_3460ae4b-7390-4c0d-9043-a5faacec0ee4/2024-09-09T09-51-29-GMT/submission/submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": null,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:19.487459",
      "submission_path": "None"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": null,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:19.499434",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/seti-breakthrough-listen_aeccf5d6-434a-4847-a0e3-043e51dc2a4e/2024-09-08T06-52-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.0,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:19.745462",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/herbarium-2022-fgvc9_d3169ccb-1db1-4f06-954e-e68a555aee13/2024-09-08T02-52-13-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": 0.0,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:32.776897",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/vesuvius-challenge-ink-detection_60b9f966-33bc-46f0-b866-865a2f2b27c3/2024-09-08T00-52-12-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:32.827862",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/herbarium-2021-fgvc8_ca6da617-8d02-4902-bde4-ee1733840532/2024-09-08T22-57-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:32.830406",
      "submission_path": "None"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:10:32.832734",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:32.834958",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": null,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:32.853789",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/herbarium-2022-fgvc9_e61ca2aa-d428-4464-ad45-0ed10c2f60c5/2024-09-08T23-01-11-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": null,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:32.859785",
      "submission_path": "None"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.00234,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:32.918381",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/google-quest-challenge_172f7189-6d7c-48e4-90ee-9498c605492a/2024-09-08T05-54-37-GMT/submission/submission.csv"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T20:10:42.852519",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/icecube-neutrinos-in-deep-ice_e5679c22-69d3-44a1-8b39-88d4194e11e5/2024-09-08T11-58-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": null,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:42.855150",
      "submission_path": "None"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.5,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:42.874771",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/seti-breakthrough-listen_b5c12ccd-1c44-4c92-9b95-17ab8f1cca3e/2024-09-08T05-00-13-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:42.877268",
      "submission_path": "None"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": 0.0475,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:44.199497",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/vinbigdata-chest-xray-abnormalities-detection_3a1d1a80-2432-4555-8835-0f1ecc1c4ff7/2024-09-08T00-04-44-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": null,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:44.206439",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/rsna-breast-cancer-detection_022eb103-bb6a-4180-b897-578a76fd16a7/2024-09-09T00-16-08-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": null,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T20:10:44.209675",
      "submission_path": "None"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": null,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:51:52.930339",
      "submission_path": "None"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.00401,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:51:52.945427",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/us-patent-phrase-to-phrase-matching_daf1660a-122e-4735-b369-1e31983dd556/2024-09-08T23-35-09-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 12.75945,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:51:52.952703",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/dogs-vs-cats-redux-kernels-edition_b9a26b0d-b585-42e6-82b1-bb0c4ee00c25/2024-09-08T00-34-53-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 1.09715,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:51:53.083978",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/lmsys-chatbot-arena_7ac7ae71-6d65-467d-aa4e-31e8302b085c/2024-09-07T23-34-51-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 20.15704,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:51:53.094335",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/petfinder-pawpularity-score_47c90b30-eebd-4632-974c-d38777a40aef/2024-09-07T23-34-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 4.79964,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:51:53.135489",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/dog-breed-identification_5972f6c0-8035-4022-8f3b-09fc268d6082/2024-09-09T09-36-07-GMT/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": null,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:51:53.143599",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/leaf-classification_b6c2d334-ab69-471a-bfc8-cfb6edd760b3/2024-09-08T11-34-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": null,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:51:53.146457",
      "submission_path": "None"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.59109,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:51:53.181160",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/learning-agency-lab-automated-essay-scoring-2_cdde7477-19b2-4dd6-b732-2c06b08dee77/2024-09-09T09-35-27-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.68438,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:51:54.338015",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/jigsaw-unintended-bias-in-toxicity-classification_ed8fafb5-368a-470a-aee3-e0206f10471a/2024-09-07T23-34-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 1.42616,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:51:54.386132",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/dog-breed-identification_f8449cba-7624-47e2-a972-9fbd4d62ee02/2024-09-09T09-35-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": null,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:51:54.389634",
      "submission_path": "None"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:51:55.804145",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/billion-word-imputation_781a88bd-9e66-4ad4-b2e2-0d8c4d1a49f9/2024-09-08T22-37-42-GMT/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.0,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:51:55.858460",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/chaii-hindi-and-tamil-question-answering_20bb161c-5537-437c-8b03-21157df5c7e6/2024-09-07T23-35-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": 11.00398,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:51:55.866578",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/statoil-iceberg-classifier-challenge_e07bb6e5-935b-424e-80cf-c6b62bdd12b6/2024-09-07T23-35-44-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": 0.2237,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:51:56.620313",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/tgs-salt-identification-challenge_7c2f35bf-75ae-4662-bc3a-3618f5b20b4a/2024-09-09T09-57-02-GMT/submission/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": null,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:51:56.635348",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/kuzushiji-recognition_e9c17b09-4be6-479d-9649-5035eeb420b5/2024-09-08T05-05-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 7.54844,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:51:57.263270",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/ventilator-pressure-prediction_b31a2929-9a4a-4ec7-8719-b432fa35c067/2024-09-08T00-35-45-GMT/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:51:58.177378",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/billion-word-imputation_8fe93a5a-c0dd-4304-a1af-82cce53fe116/2024-09-08T23-37-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": null,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:51:58.209586",
      "submission_path": "None"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": null,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:51:58.212573",
      "submission_path": "None"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": 0.73573,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:51:58.263372",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/ranzcr-clip-catheter-line-classification_3a40553f-756a-429b-964f-6fdc6d0a88ef/2024-09-08T09-37-59-GMT/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": null,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:51:58.265853",
      "submission_path": "None"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": 0.23803,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:07.489505",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/facebook-recruiting-iii-keyword-extraction_9def1eb0-f12b-43e7-b5bc-f0b648d7e2f2/2024-09-08T23-38-17-GMT/submission/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.0,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:08.466478",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/kuzushiji-recognition_9b93467b-173d-45ce-9ae1-fa35de38c27e/2024-09-08T00-39-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 17.32643,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:08.484512",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/leaf-classification_9977ee9a-6355-41ae-be88-e7cc3eac70dd/2024-09-07T23-39-20-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 1.09005,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:08.629688",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/lmsys-chatbot-arena_640845b2-97eb-4b78-813c-67fa1762ee90/2024-09-09T09-39-53-GMT/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.60069,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:08.666722",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/learning-agency-lab-automated-essay-scoring-2_2da490b6-1559-4865-a24a-dd1d85be5e74/2024-09-08T00-39-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 19.31101,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:08.676119",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/petfinder-pawpularity-score_00669bad-1882-458c-ba64-1ae419535152/2024-09-09T09-40-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": null,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:09.490703",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/jigsaw-unintended-bias-in-toxicity-classification_4a6b34a4-7857-414e-9fc8-09f919b67dd4/2024-09-08T23-39-50-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:09.498364",
      "submission_path": "None"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:09.523799",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/imet-2020-fgvc7_3c2ad074-2c79-4c1c-9e0f-4ba01d9a956c/2024-09-09T09-50-52-GMT/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": null,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:09.570220",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/freesound-audio-tagging-2019_33325bed-1b44-41c1-9aff-f64ef3200e03/2024-09-08T01-40-17-GMT/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": 1.49201,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:09.578296",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/statoil-iceberg-classifier-challenge_21ac8fb1-d8c6-45ad-b188-d3c31dba2718/2024-09-09T09-41-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": null,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:09.592707",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/ranzcr-clip-catheter-line-classification_aaf81bbe-9394-4132-8b13-910c2ca3275c/2024-09-08T21-57-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:09.595112",
      "submission_path": "None"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": null,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:09.599525",
      "submission_path": "None"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": null,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:09.602517",
      "submission_path": "None"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": NaN,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:09.617781",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/us-patent-phrase-to-phrase-matching_a20fe836-7b70-496c-a37c-948830825cf9/2024-09-08T14-43-28-GMT/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.43416,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:09.667422",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/the-icml-2013-whale-challenge-right-whale-redux_69b6f7a7-396e-4865-9a1b-fdeafc96177e/2024-09-08T11-43-53-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": null,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:10.277321",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/ventilator-pressure-prediction_52433f43-1570-46c1-a268-306dfdbccc63/2024-09-08T01-43-16-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:10.295902",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/iwildcam-2019-fgvc6_dfe4b00b-7e8b-4205-aa82-3a2bbd147a70/2024-09-08T06-46-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.0,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:10.303325",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/chaii-hindi-and-tamil-question-answering_ead01b6e-8de6-40b2-a758-491c00913129/2024-09-07T23-44-10-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": null,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:10.307900",
      "submission_path": "None"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": null,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:10.312670",
      "submission_path": "None"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.64147,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:10.348390",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/learning-agency-lab-automated-essay-scoring-2_af7253f6-0810-4835-a1ea-5697f03da70f/2024-09-07T23-45-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": null,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:10.357091",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/ranzcr-clip-catheter-line-classification_eb8392c5-ddd4-4114-970c-86c11c9b0d02/2024-09-09T09-47-01-GMT/submission/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": null,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:10.371787",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/kuzushiji-recognition_6884d3f0-54e2-422d-9458-bdd8b65d4f49/2024-09-08T23-51-44-GMT/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": null,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:10.378865",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/leaf-classification_a088f19a-9f27-4fae-857e-74aaef816c65/2024-09-07T23-45-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": 0.29312,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:19.542941",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/facebook-recruiting-iii-keyword-extraction_bfb3777c-6e19-417e-b242-98697ac082fc/2024-09-08T03-45-24-GMT/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:20.026065",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/billion-word-imputation_6f3fa7da-20a0-4bcc-9b33-ecd3a8eb62a3/2024-09-08T23-46-06-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 17.90649,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:20.041089",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/dogs-vs-cats-redux-kernels-edition_e65560ec-2eaa-4175-8dc1-d4cfc50f9cd5/2024-09-07T23-45-25-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": null,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:20.758117",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/text-normalization-challenge-english-language_de4e30cc-f684-40d3-a767-fed8f563df76/2024-09-08T22-54-09-GMT/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": null,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:20.807019",
      "submission_path": "None"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.46959,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:20.822558",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/us-patent-phrase-to-phrase-matching_e2cf3e71-468d-425b-a88c-29ed5ade07aa/2024-09-08T00-46-34-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": 0.5221,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:21.429888",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/tgs-salt-identification-challenge_37168e53-3da1-4307-96ec-5bf764eb31e4/2024-09-07T23-48-03-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": null,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:21.894237",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/ventilator-pressure-prediction_5f0322c9-ffbf-4ce7-8d56-ce5c9958a978/2024-09-09T09-49-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 24.1357,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:22.018559",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/lmsys-chatbot-arena_b0dad1c4-db61-4621-8fad-7b0db46641bd/2024-09-09T10-01-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": 0.06033,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.493874",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/freesound-audio-tagging-2019_ac0d8de7-8e35-443c-bd92-3535209bcd70/2024-09-09T09-06-34-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.42088,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.507410",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/siim-isic-melanoma-classification_bee3054b-239d-46ac-93e5-bfb764db6196/2024-09-08T01-48-07-GMT/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": null,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.544378",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/the-icml-2013-whale-challenge-right-whale-redux_54ee53ea-0b64-4f24-855d-d8464d44b360/2024-09-08T00-48-57-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.547102",
      "submission_path": "None"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.573183",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/imet-2020-fgvc7_ad362778-431b-47a8-a406-84c66dfd595e/2024-09-08T23-52-03-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.580137",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/siim-covid19-detection_d9327893-4ba9-44d4-8240-e4957ed13ce4/2024-09-08T00-48-02-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.65683,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.592630",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/siim-isic-melanoma-classification_b44f5c5b-3e31-4db6-b6e8-2c932b1722db/2024-09-07T23-50-37-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": null,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.597686",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/rsna-miccai-brain-tumor-radiogenomic-classification_c1810f1e-09ec-4514-8c29-d824cfb015ae/2024-09-08T16-09-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": null,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.602826",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/rsna-miccai-brain-tumor-radiogenomic-classification_32747766-5d43-45aa-87c7-6e07f6e195ec/2024-09-08T03-57-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.5,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.613595",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/siim-isic-melanoma-classification_4cf90de2-46b4-46af-b2b9-4f8eb278ded3/2024-09-08T00-54-06-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.621555",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/siim-covid19-detection_2823427c-b7bb-44d4-bb04-ecc758cd2c19/2024-09-08T02-55-58-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.625331",
      "submission_path": "None"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.53118,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.631638",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/rsna-miccai-brain-tumor-radiogenomic-classification_83c0b49b-3679-4f11-bd87-7cd960c66e56/2024-09-08T09-59-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": 12.41164,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:22.692810",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/rsna-2022-cervical-spine-fracture-detection_e71557f0-c085-4471-9d05-ded6fd5ae8e6/2024-09-08T01-22-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": null,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:22.706497",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/rsna-2022-cervical-spine-fracture-detection_da33b468-e9ee-4841-acd7-e5f7e8e98c30/2024-09-09T09-24-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": 12.41164,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T15:52:22.763937",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/rsna-2022-cervical-spine-fracture-detection_fde6c64c-03a1-4b5b-90d2-b0bdfeaefc68/2024-09-08T00-31-28-GMT/submission/submission.csv"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": null,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:52:22.767393",
      "submission_path": "None"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": null,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:54:37.184810",
      "submission_path": "runs/2024-09-07T22-33-09-UTC_run-group_mlagentbench/google-research-identify-contrails-reduce-global-warming_c90d60d1-70dd-4265-80e4-e83f33032d36/2024-09-08T10-11-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": null,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T15:54:37.209222",
      "submission_path": "None"
    }
  ]
}