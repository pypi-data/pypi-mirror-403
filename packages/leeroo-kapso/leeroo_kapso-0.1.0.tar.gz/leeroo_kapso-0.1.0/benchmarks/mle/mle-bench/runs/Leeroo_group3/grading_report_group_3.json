{
  "total_runs": 40,
  "total_runs_with_submissions": 37,
  "total_valid_submissions": 37,
  "total_medals": 37,
  "total_gold_medals": 13,
  "total_silver_medals": 12,
  "total_bronze_medals": 12,
  "total_above_median": 37,
  "competition_reports": [
    {
      "competition_id": "aerial-cactus-identification",
      "score": 1.0,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:29.825581",
      "submission_path": "3/aerial-cactus-identification/final_submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.94113,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:29.833961",
      "submission_path": "3/aptos2019-blindness-detection/final_submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": 0.03728,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:58:42.772215",
      "submission_path": "3/denoising-dirty-documents/final_submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.94402,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:42.911436",
      "submission_path": "3/detecting-insults-in-social-commentary/final_submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.00763,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:58:42.918898",
      "submission_path": "3/dogs-vs-cats-redux-kernels-edition/final_submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.99846,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:43.028606",
      "submission_path": "3/histopathologic-cancer-detection/final_submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.98647,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:43.510156",
      "submission_path": "3/jigsaw-toxic-comment-classification-challenge/final_submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.00274,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:58:43.529901",
      "submission_path": "3/leaf-classification/final_submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": 0.89452,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:43.536175",
      "submission_path": "3/mlsp-2013-birds/final_submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.06063,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:58:43.542581",
      "submission_path": "3/nomad2018-predict-transparent-conductors/final_submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.99734,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:43.550999",
      "submission_path": "3/plant-pathology-2020-fgvc7/final_submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.28408,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:58:43.563374",
      "submission_path": "3/spooky-author-identification/final_submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.96298,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:44.264348",
      "submission_path": "3/tabular-playground-series-dec-2021/final_submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": 0.99076,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:47.033561",
      "submission_path": "3/text-normalization-challenge-english-language/final_submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:47.069014",
      "submission_path": "3/text-normalization-challenge-russian-language/final_submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.95746,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:47.119092",
      "submission_path": "3/the-icml-2013-whale-challenge-right-whale-redux/final_submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": 0.049,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:58.702590",
      "submission_path": "3/3d-object-detection-for-autonomous-vehicles/final_submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": 0.15404,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:58.751465",
      "submission_path": "3/iwildcam-2019-fgvc6/final_submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 4528081.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:58:58.758711",
      "submission_path": "3/predict-volcanic-eruptions-ingv-oe/final_submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.58294,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:58:58.765546",
      "submission_path": "3/rsna-miccai-brain-tumor-radiogenomic-classification/final_submission.csv"
    },
    {
      "competition_id": "stanford-covid-vaccine",
      "score": 0.31701,
      "gold_threshold": 0.34728,
      "silver_threshold": 0.35175,
      "bronze_threshold": 0.3534,
      "median_threshold": 0.363095,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:58:58.879558",
      "submission_path": "3/stanford-covid-vaccine/final_submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": 0.26924,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:00.110285",
      "submission_path": "3/vinbigdata-chest-xray-abnormalities-detection/final_submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.90247,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:00.120125",
      "submission_path": "3/cassava-leaf-disease-classification/final_submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.7436,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:00.127415",
      "submission_path": "3/chaii-hindi-and-tamil-question-answering/final_submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.37989,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:00.153241",
      "submission_path": "3/google-quest-challenge/final_submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": 0.39891,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:00.430087",
      "submission_path": "3/herbarium-2020-fgvc7/final_submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": 0.18174,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:01.020786",
      "submission_path": "3/herbarium-2021-fgvc8/final_submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.78479,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:01.219104",
      "submission_path": "3/herbarium-2022-fgvc9/final_submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.28803,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:01.257230",
      "submission_path": "3/hotel-id-2021-fgvc8/final_submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.12572,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:59:01.298773",
      "submission_path": "3/inaturalist-2019-fgvc6/final_submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": 0.64182,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:01.414979",
      "submission_path": "3/iwildcam-2020-fgvc7/final_submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": null,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:01.419146",
      "submission_path": "3/kuzushiji-recognition/final_submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.89453,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:01.452218",
      "submission_path": "3/learning-agency-lab-automated-essay-scoring-2/final_submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 0.98522,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:59:01.573110",
      "submission_path": "3/lmsys-chatbot-arena/final_submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 17.06824,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T13:59:01.583289",
      "submission_path": "3/petfinder-pawpularity-score/final_submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.9313,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:01.600920",
      "submission_path": "3/plant-pathology-2021-fgvc8/final_submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.80989,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:01.617523",
      "submission_path": "3/seti-breakthrough-listen/final_submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": null,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:01.621071",
      "submission_path": "3/tweet-sentiment-extraction/final_submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.86352,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:01.635523",
      "submission_path": "3/us-patent-phrase-to-phrase-matching/final_submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.44326,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T13:59:01.648528",
      "submission_path": "3/whale-categorization-playground/final_submission.csv"
    }
  ]
}