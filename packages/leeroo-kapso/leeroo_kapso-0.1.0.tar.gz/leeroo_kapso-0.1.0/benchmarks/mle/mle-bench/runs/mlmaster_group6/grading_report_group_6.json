{
  "total_runs": 75,
  "total_runs_with_submissions": 72,
  "total_valid_submissions": 72,
  "total_medals": 41,
  "total_gold_medals": 16,
  "total_silver_medals": 17,
  "total_bronze_medals": 8,
  "total_above_median": 47,
  "competition_reports": [
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": 0.08213,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:28:36.492970",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/3d-object-detection-for-autonomous-vehicles/4a280363-f5ec-4736-a474-22fbbf3dd0da/submission/submission.csv"
    },
    {
      "competition_id": "AI4Code",
      "score": 0.72678,
      "gold_threshold": 0.9006,
      "silver_threshold": 0.8598,
      "bronze_threshold": 0.8534,
      "median_threshold": 0.8257,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:04.426863",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/AI4Code/7bd4b3c7-790f-4774-9fe3-5916825fd118/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 1.0,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:15.198667",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/aerial-cactus-identification/2712b0d6-db9b-473c-862b-e766c9e6b6ed/submission/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": 0.59786,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:04.447820",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/alaska2-image-steganalysis/89a1337b-6a1c-4d0a-b0fe-196ceb55ce5b/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.9302,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:15.233303",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/aptos2019-blindness-detection/6dace557-3c66-4caf-9558-939d31cd1edd/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:34:07.134534",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/billion-word-imputation/c7ab41cf-2d6f-4f6d-8dc9-c781892110a9/submission/submission.csv"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": 59.56518,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:29:08.302053",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/bms-molecular-translation/0413d00e-1f7c-4779-8cbf-f1e5f86d71ed/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.89723,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:01.113136",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/cassava-leaf-disease-classification/31614346-f39a-400a-bb48-ad38a0547851/submission/submission.csv"
    },
    {
      "competition_id": "cdiscount-image-classification-challenge",
      "score": 0.48088,
      "gold_threshold": 0.77604,
      "silver_threshold": 0.73526,
      "bronze_threshold": 0.70898,
      "median_threshold": 0.44055,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:34:07.029499",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/cdiscount-image-classification-challenge/4c8e3249-b274-433f-be32-73fb4c162141/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.7439,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:28:51.424599",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/chaii-hindi-and-tamil-question-answering/fd955a52-518e-4387-8145-d1a7c0e0e0b2/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 1.5836,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:33:58.759986",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/champs-scalar-coupling/7d7a894d-e2ea-4f01-b392-a27850aa6234/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": 0.01696,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:27:35.170260",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/denoising-dirty-documents/ee6fce69-9a80-4cd0-8d61-dbbc8de6037f/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.95901,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:15.223228",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/detecting-insults-in-social-commentary/f8923a5f-176b-433f-846f-3a98a9641e3c/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 0.39463,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:33:13.397194",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/dog-breed-identification/f6a00f75-63d4-4e3e-9a4c-3b693591cafc/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.00307,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:28:39.901454",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/dogs-vs-cats-redux-kernels-edition/2446d6f9-6cc0-44f3-8451-83423699c4fd/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": 0.45912,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:33:57.937375",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/facebook-recruiting-iii-keyword-extraction/c51d0785-7237-4aeb-bda8-9d185cf4efcd/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": 0.71762,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:21.067976",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/freesound-audio-tagging-2019/7b224fee-8e9a-47ee-a348-0c668e809be5/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.40278,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:28:36.537573",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/google-quest-challenge/8548be1e-4932-4ff6-ad7e-9b145ef61640/submission/submission.csv"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": 0.06962,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:10.059962",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/google-research-identify-contrails-reduce-global-warming/5760b7a1-88e0-403a-8904-c1be58a79954/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": 0.02825,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:18.695279",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/h-and-m-personalized-fashion-recommendations/858d1b71-e629-4dfb-b98c-0318508a6f12/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": 0.30818,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:00.831498",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/herbarium-2020-fgvc7/327e8551-f5bb-415d-ab2c-43f576287331/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": 0.43014,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:28:58.252547",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/herbarium-2021-fgvc8/dac4e204-44c7-4d84-8419-017f1869e70d/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.0,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:01.099734",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/herbarium-2022-fgvc9/7393cd38-0b0a-41b1-824c-9d1138b90eeb/submission/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.99846,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:28:51.412122",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/histopathologic-cancer-detection/1c3261de-925a-4607-aa4e-9696c9568819/submission/submission.csv"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": 0.90024,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:33:13.339921",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/hms-harmful-brain-activity-classification/939bb78a-b246-4d8e-a08b-74295fd880a7/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.31199,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:20.260658",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/hotel-id-2021-fgvc8/dea20b85-b145-4dd2-ab84-15c97c4f47c4/submission/submission.csv"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": 0.94826,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:28:51.269432",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/hubmap-kidney-segmentation/e0e4afb8-3af7-41fe-bc1b-c958c21d87ff/submission/submission.csv"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": 1.56335,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:33:47.317957",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/icecube-neutrinos-in-deep-ice/b515e9ee-9a09-4c3f-9923-6757bda17d63/submission/submission.csv"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": 0.57981,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:01.502802",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/imet-2020-fgvc7/fdf14bb0-2ed4-4111-9697-8ad1bbe1f5ce/submission/submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.28925,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:27:19.920555",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/inaturalist-2019-fgvc6/579856f6-a487-4a28-b118-d2830c0f0f85/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": 0.37281,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:20.330313",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/iwildcam-2019-fgvc6/97276bb1-7b1d-44a5-9516-baaf00a28090/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": 0.72936,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:35.485231",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/iwildcam-2020-fgvc7/e5e57ec6-587a-4383-af00-3165ac7bfd75/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.98651,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:28:51.865279",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/jigsaw-toxic-comment-classification-challenge/388a2aa1-8cc6-4c0a-b61e-3434589dadd2/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.79693,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:34:00.983042",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/jigsaw-unintended-bias-in-toxicity-classification/e92fc1d6-dee0-4845-91a9-a95bb9b95d8c/submission/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.85336,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:28:53.208382",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/kuzushiji-recognition/3b4e6886-5c9a-47fd-9f4f-edcafd7ab3ab/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.00882,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:27:15.153908",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/leaf-classification/2fd829ef-d0f6-4282-8452-b30e7c5dc7ea/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.82888,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:01.206407",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/learning-agency-lab-automated-essay-scoring-2/e325ec9d-36e9-4ed5-bd00-b65357ce157b/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 1.00254,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:29:00.402204",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/lmsys-chatbot-arena/4b173546-8b23-4ce3-a58c-c8ae9596d91b/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": 0.90808,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:20.195227",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/mlsp-2013-birds/f8d5c186-3898-4c9d-8db7-3730192a1ed2/submission/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": 0.35726,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:29:01.168701",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/multi-modal-gesture-recognition/152098cb-71d7-4880-8376-36dc56422b80/submission/submission.csv"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 4.78924,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:34:06.006351",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/new-york-city-taxi-fare-prediction/4c6899b8-2446-4bd2-9ddd-5f7101690bd1/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:34:07.146580",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/nfl-player-contact-detection/8db1156d-93cd-4675-aca7-d847a873991a/submission/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.0623,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:28:51.280503",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/nomad2018-predict-transparent-conductors/08fe06fe-ae44-46d4-99c1-7d3b72b54a98/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": -7.07087,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:08.423198",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/osic-pulmonary-fibrosis-progression/96edd50b-fe35-4b57-ae75-4f85a535ca17/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 17.02373,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:28:51.437127",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/petfinder-pawpularity-score/99e44fcc-7676-465f-9fa5-497cf14d7296/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.99518,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:15.171403",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/plant-pathology-2020-fgvc7/28b61a6f-52a0-464d-a19c-ae194da27782/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.9079,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:19.991327",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/plant-pathology-2021-fgvc8/c2d10746-f035-4f0d-ac05-935b9bedc3c6/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 2436791.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:27:35.360690",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/predict-volcanic-eruptions-ingv-oe/d4b363da-aec7-4c99-804c-7d35c0be0114/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.79874,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:19.865670",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/random-acts-of-pizza/b9d608fc-632e-4729-ae26-f9cf49ffc47a/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": 0.93195,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:34:07.092801",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/ranzcr-clip-catheter-line-classification/bfed66fe-ae30-4d8e-b867-c4cffd97d5d1/submission/submission.csv"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": 0.54539,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:29:01.280344",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/rsna-2022-cervical-spine-fracture-detection/cffeb287-64d7-468f-a3a5-c3013db4dad6/submission/submission.csv"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": 0.0556,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:02.342090",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/rsna-breast-cancer-detection/c01ce442-b1fd-4950-b747-0309e108a105/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.63059,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:15.181953",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/rsna-miccai-brain-tumor-radiogenomic-classification/42e3c77c-9d41-4717-854e-888b6496af3f/submission/submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.85744,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:20.213939",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/seti-breakthrough-listen/6c353541-2fe2-4593-ace4-76ee27fd7078/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": 0.32873,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:01.321402",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/siim-covid19-detection/d2390d6c-2e88-47ca-87ed-b30a403dfb2b/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.89449,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:34:06.024491",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/siim-isic-melanoma-classification/29128927-8dba-4f8e-9b0c-655971dc99c1/submission/submission.csv"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": 5.9418,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:33:47.490614",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/smartphone-decimeter-2022/ca6433f2-3cb3-40b5-a53e-d750ce91df83/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.22934,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:27:20.275587",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/spooky-author-identification/f169353b-3b73-4768-b875-a7119416f064/submission/submission.csv"
    },
    {
      "competition_id": "stanford-covid-vaccine",
      "score": 0.2472,
      "gold_threshold": 0.34728,
      "silver_threshold": 0.35175,
      "bronze_threshold": 0.3534,
      "median_threshold": 0.363095,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:27:20.096310",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/stanford-covid-vaccine/a57e82c4-371e-4e56-9903-52a31d71f0e5/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": 0.1763,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:34:07.106714",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/statoil-iceberg-classifier-challenge/9694598d-7885-4ba3-bd6c-1237686c165a/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.96292,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:19.854530",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tabular-playground-series-dec-2021/2575bb97-4f5a-41c1-a722-805515ad82b5/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.99591,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:33:59.628676",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tabular-playground-series-may-2022/640e6e87-d74a-490e-8cdb-997210903f64/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow-speech-recognition-challenge",
      "score": 0.35285,
      "gold_threshold": 0.90485,
      "silver_threshold": 0.89627,
      "bronze_threshold": 0.88793,
      "median_threshold": 0.77722,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:34:07.129596",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tensorflow-speech-recognition-challenge/52a5f2e8-aef2-44c0-9c98-7ecbdad29b74/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:34:07.141302",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tensorflow2-question-answering/8f37e4a8-8484-47b2-bbd0-e3f38b1ee3ec/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": 0.99247,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:28:39.825606",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/text-normalization-challenge-english-language/2c521c9e-fe4a-4c87-aaa7-eae7a5c3364d/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": 0.98171,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:28:57.257413",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/text-normalization-challenge-russian-language/2e0ac745-b102-4e4d-8d8b-f6908348eaac/submission/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": 0.7703,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:02.327736",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tgs-salt-identification-challenge/03d993ee-a0bc-4715-a9d4-4d3464f1cc4a/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.9906,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:20.186329",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/the-icml-2013-whale-challenge-right-whale-redux/8b87b1a3-0d1d-4d03-a8ee-89a3c423ddc1/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.72034,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:28:53.235883",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tweet-sentiment-extraction/c5077335-67e5-499f-892a-50334177ea7a/submission/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.87062,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:20.117372",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/us-patent-phrase-to-phrase-matching/43321e13-c142-406c-8311-2aaa9ffdf245/submission/submission.csv"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": 0.10038,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:33:13.201762",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/uw-madison-gi-tract-image-segmentation/d8740ac0-64b8-4706-aa8f-95e9c9bca3da/submission/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 0.5552,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T07:34:06.725360",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/ventilator-pressure-prediction/a6840969-8c8a-4356-bb9b-299acb6e3361/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": 0.21857,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:34:05.959968",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/vesuvius-challenge-ink-detection/7c4cc711-18fa-4027-af66-025273a2e0db/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": 0.33498,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:29:00.257381",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/vinbigdata-chest-xray-abnormalities-detection/c769eaa3-b28a-496f-b6f5-0cc72f303b9c/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.54774,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T07:27:20.134237",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/whale-categorization-playground/add97bf5-90bd-4d89-8054-1ae9c57819be/submission/submission.csv"
    }
  ]
}