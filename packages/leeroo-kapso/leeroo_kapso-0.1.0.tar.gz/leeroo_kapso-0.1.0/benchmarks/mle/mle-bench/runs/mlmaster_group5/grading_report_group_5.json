{
  "total_runs": 75,
  "total_runs_with_submissions": 70,
  "total_valid_submissions": 70,
  "total_medals": 40,
  "total_gold_medals": 14,
  "total_silver_medals": 18,
  "total_bronze_medals": 8,
  "total_above_median": 46,
  "competition_reports": [
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": 0.08133,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:29.877308",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/3d-object-detection-for-autonomous-vehicles/2b24c585-8dce-45e6-bcf2-053e3d3f6293/submission/submission.csv"
    },
    {
      "competition_id": "AI4Code",
      "score": 0.7268,
      "gold_threshold": 0.9006,
      "silver_threshold": 0.8598,
      "bronze_threshold": 0.8534,
      "median_threshold": 0.8257,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:59.965827",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/AI4Code/07f944d5-3fb8-497f-a83f-67b2ab7f3309/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 1.0,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:48.221577",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/aerial-cactus-identification/219fcb99-ac47-4fbd-b903-001956b1cbc0/submission/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": 0.68592,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:59.987104",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/alaska2-image-steganalysis/313d3f8a-d505-43fd-a146-dd8f66a26925/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.91935,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:48.233996",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/aptos2019-blindness-detection/39535895-3ade-4a2a-b557-0ad2f3e115ca/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:50:55.499339",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/billion-word-imputation/e4c794a1-6a1a-4331-90cf-287c58f6e1ee/submission/submission.csv"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": 81.38006,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:50:03.339044",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/bms-molecular-translation/289bf034-6702-4aa9-b61b-662c552278ca/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.89686,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:51.018242",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/cassava-leaf-disease-classification/d89575ff-ad34-462e-ab17-61d2c890f1c3/submission/submission.csv"
    },
    {
      "competition_id": "cdiscount-image-classification-challenge",
      "score": 0.36007,
      "gold_threshold": 0.77604,
      "silver_threshold": 0.73526,
      "bronze_threshold": 0.70898,
      "median_threshold": 0.44055,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:55.383394",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/cdiscount-image-classification-challenge/0a7f24ee-cab5-44ea-ae24-2acd81900ce9/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.72158,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:51.029394",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/chaii-hindi-and-tamil-question-answering/d6505d95-5ed9-4e8f-9c2a-348a02ad66de/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 1.46037,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:50:46.760338",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/champs-scalar-coupling/847c009a-06eb-49d6-9704-2998ad8bdb03/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": 0.01977,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:48:07.998056",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/denoising-dirty-documents/11a30648-a2e8-4609-8f19-6b291abc76e1/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.95874,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:52.304803",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/detecting-insults-in-social-commentary/41b7f3cf-b357-472d-b4ed-fa3dce53af3f/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 0.44414,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:50:34.265802",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/dog-breed-identification/5c2ba325-bb8e-492c-a93f-781f8c2412f1/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.00307,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:49:33.358551",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/dogs-vs-cats-redux-kernels-edition/b4ff577c-3398-44d9-8cee-899511096af4/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": 0.45492,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:45.840415",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/facebook-recruiting-iii-keyword-extraction/87969608-d38c-4569-85d3-c373bf333f31/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": 0.70573,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:54.413395",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/freesound-audio-tagging-2019/42ae1add-800d-4c89-b665-95e3ad934810/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.40276,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:33.396701",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/google-quest-challenge/3d9551a4-8f28-4645-8b98-c392dbc62bc1/submission/submission.csv"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": 0.09556,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:05.004058",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/google-research-identify-contrails-reduce-global-warming/1684b344-e5fd-447f-abf6-bdfb9c99907d/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": 0.02783,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:52.242200",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/h-and-m-personalized-fashion-recommendations/746df7e2-e60f-47ef-b7a4-c9520b60836c/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": 0.31243,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:36.334748",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/herbarium-2020-fgvc7/1fe0abbc-2834-47b6-855c-ff0bda7ec40a/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": 0.43014,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:37.326004",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/herbarium-2021-fgvc8/46e0391a-56ff-45b9-a914-ac7d21be298c/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.69611,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:35.177681",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/herbarium-2022-fgvc9/1903e2d6-949a-4d65-9b0a-935d37e42e73/submission/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.99843,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:48:08.525907",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/histopathologic-cancer-detection/b1ee15a1-4d80-4c23-9856-03b7fb831fef/submission/submission.csv"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": null,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:50:55.522939",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/hms-harmful-brain-activity-classification/0ecb33cc-52b2-4bf5-8dba-a822ccb13ffb/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.05161,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:53.323177",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/hotel-id-2021-fgvc8/6c2b3881-c181-44f4-8839-0f27b483337b/submission/submission.csv"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": 0.94172,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:51.003899",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/hubmap-kidney-segmentation/e2b08f19-58b8-45d4-b04c-21113ba0866b/submission/submission.csv"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:50:55.506804",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/icecube-neutrinos-in-deep-ice/1c3e848b-55a0-4beb-b35c-dc2c613fe99c/submission/submission.csv"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": 0.55444,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:56.996305",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/imet-2020-fgvc7/e715003a-fe41-42a9-80b3-9a7efc29f791/submission/submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.28758,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:47:54.475621",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/inaturalist-2019-fgvc6/cd99c239-2e4d-488b-b596-b9579353d7d8/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": 0.40376,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:48:08.249548",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/iwildcam-2019-fgvc6/a349916b-4bb2-4697-b01b-61ae8c73c677/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": 0.72465,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:48:08.391353",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/iwildcam-2020-fgvc7/4978b34d-c131-4526-b3a5-b0c041227a2d/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.98681,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:35.890913",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/jigsaw-toxic-comment-classification-challenge/7791f211-e099-4d1c-a374-bd12a2db5b93/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.83829,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:49.059574",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/jigsaw-unintended-bias-in-toxicity-classification/d5ec145c-e856-478f-920c-1b1548122ebb/submission/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.84671,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:34.802701",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/kuzushiji-recognition/37045efb-3f3a-4b0a-8fcc-59ee13ed9d66/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.0069,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:47:48.201094",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/leaf-classification/367704c0-3c75-4353-9da8-36ac358ce111/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.83556,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:36.372009",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/learning-agency-lab-automated-essay-scoring-2/f4cadaa4-0b00-43f3-b59f-75ddaa245aca/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 1.0026,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:49:39.410391",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/lmsys-chatbot-arena/9da2251c-6fb4-445a-8683-e43767b95d21/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": 0.88073,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:53.608344",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/mlsp-2013-birds/a4362562-e55d-4eb9-a5b5-c3c68c386838/submission/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": 0.77772,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:49:51.057534",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/multi-modal-gesture-recognition/04ab8b74-eda0-4756-96fa-5034c8346f50/submission/submission.csv"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 4.23841,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:50:54.286359",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/new-york-city-taxi-fare-prediction/1bf560a5-5662-4d05-af31-a09a707413de/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": 0.69232,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:52.523876",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/nfl-player-contact-detection/98821c5a-ace1-469f-a335-dc7bd92b54a4/submission/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.06231,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:49:33.406826",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/nomad2018-predict-transparent-conductors/6d58f697-3dd9-4e80-86d9-f7c23426f113/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": -7.06674,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:03.443750",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/osic-pulmonary-fibrosis-progression/9052eeeb-02e2-48a9-8d6c-962ca1b417be/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 17.0645,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:49:35.191369",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/petfinder-pawpularity-score/a382222d-de1b-497b-8264-ff57d7f55ed2/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.99634,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:48.169604",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/plant-pathology-2020-fgvc7/b416d01a-44f9-487a-b574-2fe7334cab5c/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.89916,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:53.485258",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/plant-pathology-2021-fgvc8/ee87a0af-596f-4446-9a39-a543a28499cd/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 2421341.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:48:08.402774",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/predict-volcanic-eruptions-ingv-oe/23ae4627-1d6a-4ad2-ad2e-03e5fe4aef67/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.79956,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:53.235067",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/random-acts-of-pizza/b4d7a0a5-3296-4f4e-a8ec-432bb0856236/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": 0.8985,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:55.455853",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/ranzcr-clip-catheter-line-classification/2e4a8fa9-faba-4e54-ad3a-978e9723e801/submission/submission.csv"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": 0.55653,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:49:56.813211",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/rsna-2022-cervical-spine-fracture-detection/e757afc9-90dc-485a-8805-9c51fc2153b0/submission/submission.csv"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": null,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:55.529793",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/rsna-breast-cancer-detection/3a1ad74b-1b59-4356-b3c4-e6abb96a2a7e/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.63882,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:48.181064",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/rsna-miccai-brain-tumor-radiogenomic-classification/2816f68f-c88b-4e17-91d9-65756b771c86/submission/submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.85954,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:53.563737",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/seti-breakthrough-listen/a8980257-d425-45f0-b363-26fa67cbbf84/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": 0.41302,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:56.844497",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/siim-covid19-detection/973752a2-a69f-44ab-9580-1f3e1f35eeeb/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.81027,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:54.311683",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/siim-isic-melanoma-classification/27577ecf-1cf6-45b9-b6a3-ef9300992723/submission/submission.csv"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": 52.90396,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:50:34.442317",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/smartphone-decimeter-2022/ad02adb3-5b6e-4815-87be-f503ff5f83c2/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.22857,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:47:53.623371",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/spooky-author-identification/b0e4d145-faf0-4222-aa86-69ed4eaf3234/submission/submission.csv"
    },
    {
      "competition_id": "stanford-covid-vaccine",
      "score": 0.25125,
      "gold_threshold": 0.34728,
      "silver_threshold": 0.35175,
      "bronze_threshold": 0.3534,
      "median_threshold": 0.363095,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:47:53.461048",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/stanford-covid-vaccine/675741c1-0b69-40f4-b211-4a4a3e566a8d/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": 0.18411,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:50:55.469715",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/statoil-iceberg-classifier-challenge/b3ae212f-2b1e-4195-93e2-cc78b87c45f2/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.96311,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:53.223090",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tabular-playground-series-dec-2021/9cd99ca0-131f-476c-8010-2500521155ee/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.99248,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:47.620489",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tabular-playground-series-may-2022/4773f69e-4964-4072-83e1-be8e5bc0c383/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow-speech-recognition-challenge",
      "score": 0.3527,
      "gold_threshold": 0.90485,
      "silver_threshold": 0.89627,
      "bronze_threshold": 0.88793,
      "median_threshold": 0.77722,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:55.493378",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tensorflow-speech-recognition-challenge/daef94a9-2cee-4ee8-ba39-b7961690264d/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:55.514144",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tensorflow2-question-answering/5830acfb-5fa4-4575-a6da-ce70b1aa07c5/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": 0.99155,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:33.299063",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/text-normalization-challenge-english-language/77901cd0-a603-462d-96f9-313820d63112/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": 0.88943,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:56.629478",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/text-normalization-challenge-russian-language/9361f260-9c98-47a7-b5f5-6159313b4ac6/submission/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": 0.7718,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:57.811766",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tgs-salt-identification-challenge/313a474a-0c82-4f01-b78c-97bf16291af6/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.9891,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:53.543633",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/the-icml-2013-whale-challenge-right-whale-redux/75af9460-e584-44f2-be89-778b9ebfa99a/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.71882,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:35.216311",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tweet-sentiment-extraction/7c932376-4842-479c-b831-cbedc7e486ef/submission/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.87062,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:53.598968",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/us-patent-phrase-to-phrase-matching/b8ba7344-6d5d-4135-9bb6-5e79f74d69f8/submission/submission.csv"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": 0.76376,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:34.202467",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/uw-madison-gi-tract-image-segmentation/b5f79664-562d-40ce-a735-884b722f41f4/submission/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 0.84855,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-15T06:50:55.039068",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/ventilator-pressure-prediction/7142578f-3163-4931-b64b-867b1592000d/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": 0.24858,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:50:54.231244",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/vesuvius-challenge-ink-detection/b3a7ee04-87a8-48f5-a5c3-3d0c1552f094/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": 0.32882,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:49:39.275906",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/vinbigdata-chest-xray-abnormalities-detection/776ab640-e19f-4843-91ab-00825a731d72/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.53719,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-15T06:47:53.581165",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/whale-categorization-playground/225c1ac5-d225-4e07-ac9a-1239d415738f/submission/submission.csv"
    }
  ]
}