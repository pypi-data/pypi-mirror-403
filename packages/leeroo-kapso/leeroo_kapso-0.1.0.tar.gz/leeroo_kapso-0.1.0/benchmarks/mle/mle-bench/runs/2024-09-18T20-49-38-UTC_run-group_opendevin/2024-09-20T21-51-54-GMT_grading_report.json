{
  "total_runs": 203,
  "total_runs_with_submissions": 126,
  "total_valid_submissions": 111,
  "total_medals": 10,
  "total_gold_medals": 6,
  "total_silver_medals": 3,
  "total_bronze_medals": 1,
  "total_above_median": 16,
  "competition_reports": [
    {
      "competition_id": "google-quest-challenge",
      "score": null,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:46:53.704464",
      "submission_path": "None"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": 0.3029,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:04.900374",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/uw-madison-gi-tract-image-segmentation_4edd1ce7-9202-43d3-8c60-ffa23e58b5d8/2024-09-19T06-01-20-GMT/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:47:08.667098",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/denoising-dirty-documents_cdf01f40-b584-414e-91aa-197628325f3f/2024-09-18T22-01-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": null,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:47:08.772937",
      "submission_path": "None"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:08.782791",
      "submission_path": "None"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": null,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:08.830959",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/google-quest-challenge_5c39d1b1-e165-4972-b8f4-2105e2c35b0a/2024-09-18T22-01-17-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.66079,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:08.841549",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/plant-pathology-2020-fgvc7_cacfd690-8300-4b57-8449-f161620b3911/2024-09-18T22-01-38-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 0.99868,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:08.854339",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/aerial-cactus-identification_d4cc6f1e-cf1b-4d77-a60f-84b90f66b1b2/2024-09-18T22-01-38-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:09.520859",
      "submission_path": "None"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.6042,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:09.528333",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/aptos2019-blindness-detection_62cd3c83-486d-415a-b7e5-5b0e855afb07/2024-09-18T22-01-56-GMT/submission/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.96475,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:09.775073",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/histopathologic-cancer-detection_8f0259b4-7083-4a7b-809d-35fa54c5e671/2024-09-18T22-06-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": 0.0,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:23.177174",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/vesuvius-challenge-ink-detection_74d9e9ab-3a74-4c13-a90e-b5176edcc2fb/2024-09-18T22-06-31-GMT/submission/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": 0.58571,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:23.190128",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/alaska2-image-steganalysis_f2043628-67ee-4295-b32e-c55290db2c67/2024-09-19T01-34-58-GMT/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": null,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:23.194492",
      "submission_path": "None"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.06542,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:47:23.201106",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/nomad2018-predict-transparent-conductors_4f80b31b-505c-4dc6-a5e8-3f1f5345c2fd/2024-09-18T22-06-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": null,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:47:23.216418",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/hms-harmful-brain-activity-classification_e14cfafd-7f6b-4a1b-9b70-c30d31dcf409/2024-09-18T22-06-33-GMT/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": null,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:23.219352",
      "submission_path": "None"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:47:23.221967",
      "submission_path": "None"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": null,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:47:23.225045",
      "submission_path": "None"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 4.43189,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:47:23.318270",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/new-york-city-taxi-fare-prediction_a9ad6e43-ec09-482c-9c26-499a362758d5/2024-09-19T17-07-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.85287,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:01.370064",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/tabular-playground-series-may-2022_54d4d5af-530e-4212-8262-e61ba7662b13/2024-09-18T22-06-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.87041,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:01.377875",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/aptos2019-blindness-detection_81046bc1-bb38-4ffb-afbb-eea7ef268dce/2024-09-18T22-06-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.80643,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:01.399140",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/cassava-leaf-disease-classification_cd05d332-9f1a-47c4-a551-30fbf8c7c96e/2024-09-18T22-06-36-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.97172,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:01.981029",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/jigsaw-toxic-comment-classification-challenge_2a12a210-ed72-4246-bb21-45de754b3ef9/2024-09-18T22-06-38-GMT/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": null,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:03.918651",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/mlsp-2013-birds_ca0888c1-bc19-49a8-80f2-c1287192e62f/2024-09-18T22-06-37-GMT/submission/submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": null,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:03.935026",
      "submission_path": "None"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:03.950865",
      "submission_path": "None"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.61099,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:03.959831",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/cassava-leaf-disease-classification_494eb843-fe34-4198-adc8-6314c5caa115/2024-09-19T00-06-48-GMT/submission/submission.csv"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": null,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:04.004133",
      "submission_path": "None"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": null,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:04.030262",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/detecting-insults-in-social-commentary_bd67ea65-b1a5-4df6-8823-e1358f6b3e9c/2024-09-18T22-06-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:04.045412",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/inaturalist-2019-fgvc6_3e546973-6ca3-4d56-9788-5d15dcc66114/2024-09-18T22-06-42-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:04.048259",
      "submission_path": "None"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.83309,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:04.067064",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/detecting-insults-in-social-commentary_03c51cd3-9df9-48dd-90d1-c25fa2397df9/2024-09-18T22-06-42-GMT/submission/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": null,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:04.069974",
      "submission_path": "None"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.64319,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:04.082571",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/spooky-author-identification_8abdc9e8-80d6-485d-a48b-70a6d861487e/2024-09-18T22-06-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": null,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:04.086259",
      "submission_path": "None"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.95764,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:04.815382",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/tabular-playground-series-dec-2021_16d613d9-8d8b-4087-8996-ce4f4f9bd088/2024-09-18T22-06-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": null,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:04.832694",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/osic-pulmonary-fibrosis-progression_a298a4be-67ef-400e-8a69-5735afe6afdf/2024-09-18T22-06-53-GMT/submission/submission.csv"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": null,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:04.892432",
      "submission_path": "None"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": null,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:05.046622",
      "submission_path": "None"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": null,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:05.049730",
      "submission_path": "None"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 0.99848,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:05.062278",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/aerial-cactus-identification_f7664706-3c92-42f6-b9b7-6e7ffd724e7c/2024-09-18T22-18-34-GMT/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": null,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:05.101059",
      "submission_path": "None"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.89661,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:14.983847",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/plant-pathology-2021-fgvc8_f777ba0d-db0c-4dfe-a0eb-8ef23c9d3561/2024-09-19T00-18-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": 64.47991,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:14.999204",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/multi-modal-gesture-recognition_88840a70-2263-4e7b-a9f5-f7db9d9f94d9/2024-09-18T22-18-38-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": null,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:15.056591",
      "submission_path": "None"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.0001,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:15.093363",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/hotel-id-2021-fgvc8_1c68a298-20c5-4d66-80f8-1463598dd4b2/2024-09-19T04-19-01-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.96892,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:15.527889",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/jigsaw-toxic-comment-classification-challenge_09e95e02-a056-4714-b31a-016820f57acb/2024-09-18T22-18-45-GMT/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.66519,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:15.538950",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/random-acts-of-pizza_5eb9d002-48c8-43ef-bcc6-555f69eb37de/2024-09-18T22-18-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:15.541679",
      "submission_path": "None"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.64519,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:15.560547",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/plant-pathology-2021-fgvc8_7034aeae-8516-4692-a586-2c87adedd526/2024-09-18T22-18-42-GMT/submission/submission.csv"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": 1.56047,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:43.451137",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/icecube-neutrinos-in-deep-ice_2570ef8b-92ee-4f46-b55f-c6e6f6a8dbb2/2024-09-19T01-18-58-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.05982,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:43.474951",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/nomad2018-predict-transparent-conductors_0c65164d-5167-42c5-9d71-1e847265e1eb/2024-09-18T22-18-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:43.477278",
      "submission_path": "None"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": 0.35584,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:43.611362",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/iwildcam-2020-fgvc7_363fc083-c969-4a47-9650-f24ae5fd14b9/2024-09-18T23-18-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": null,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:43.614668",
      "submission_path": "None"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.94456,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:43.733415",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/histopathologic-cancer-detection_1b4b3446-2269-4bcc-875a-e914bad38da7/2024-09-18T23-18-45-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:43.740321",
      "submission_path": "None"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:43.742651",
      "submission_path": "None"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:43.744857",
      "submission_path": "None"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": null,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:53.791975",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/mlsp-2013-birds_35fbba52-f415-42e3-80c8-07ada2a9f9fd/2024-09-18T22-18-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": null,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:53.799384",
      "submission_path": "None"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 3.22208,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:54.406276",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/champs-scalar-coupling_c481251e-a8ed-4cf3-afe0-0acd0405f473/2024-09-18T22-28-59-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": null,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:54.410527",
      "submission_path": "None"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.88601,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:54.430378",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/detecting-insults-in-social-commentary_b132fce1-6fea-45f0-90e2-baaa5a42444a/2024-09-18T22-29-09-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.95762,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:55.211798",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/tabular-playground-series-dec-2021_12c9eee5-9a71-4c77-adef-6931aa746b4d/2024-09-18T22-29-01-GMT/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.56256,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:55.241254",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/spooky-author-identification_fc3d54c7-bf59-4d61-93eb-16ca38c237d5/2024-09-18T22-29-01-GMT/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 8093628.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:55.247991",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/predict-volcanic-eruptions-ingv-oe_7f101dda-7f0d-4f41-bbf4-817133c6e469/2024-09-18T22-29-02-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 0.99894,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:56.499141",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/aerial-cactus-identification_023456ed-de73-429e-9cf3-61a6394c5334/2024-09-18T22-29-02-GMT/submission/submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.48455,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:56.515138",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/seti-breakthrough-listen_f9aba5a2-24dd-41c6-bb7c-e4d3d7bb2531/2024-09-19T03-29-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.23308,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:56.521775",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/aptos2019-blindness-detection_608d6548-8b7e-4161-8dca-a4caf2fbf17d/2024-09-18T22-29-05-GMT/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.29623,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:56.537913",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/whale-categorization-playground_0e453562-2a8e-435c-8428-096e9fe03083/2024-09-18T23-29-08-GMT/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": null,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:50:56.587332",
      "submission_path": "None"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:50:59.987043",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/denoising-dirty-documents_2bdb2e29-efaf-40e1-b0f9-d59149745270/2024-09-18T22-29-08-GMT/submission/submission.csv"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:51:00.739125",
      "submission_path": "None"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": 0.57507,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:10.512019",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/alaska2-image-steganalysis_1df23a06-cb0f-4bfa-a26e-4152aed5185d/2024-09-18T22-29-16-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:10.526614",
      "submission_path": "None"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:10.534593",
      "submission_path": "None"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": null,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:10.540169",
      "submission_path": "None"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": null,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:10.702578",
      "submission_path": "None"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:10.754749",
      "submission_path": "None"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": null,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:10.758113",
      "submission_path": "None"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": null,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:10.761797",
      "submission_path": "None"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": null,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:10.766678",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/mlsp-2013-birds_bbfa0819-b15d-48c6-9fef-18ec1221bc78/2024-09-18T22-41-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": null,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:10.886560",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/histopathologic-cancer-detection_9c9fb095-1ba8-4dcc-b7fe-057aa9219e9a/2024-09-18T22-42-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.97024,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:11.471014",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/jigsaw-toxic-comment-classification-challenge_da3dfcdc-9695-485a-b21b-597e372f4407/2024-09-18T22-42-04-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:12.677788",
      "submission_path": "None"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": -0.00154,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:14.006011",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/nfl-player-contact-detection_0684e676-8bee-4bb9-9e4d-f9adde3359c8/2024-09-19T00-42-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.88541,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:14.026132",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/plant-pathology-2020-fgvc7_613fb3b8-16e1-42b5-a251-cc6bd71ac868/2024-09-18T22-42-26-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": null,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:51:14.039347",
      "submission_path": "None"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.06644,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:51:14.045196",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/nomad2018-predict-transparent-conductors_aeb19e0d-de47-40ce-8fd3-0dcbf80f74c6/2024-09-18T22-42-29-GMT/submission/submission.csv"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 10.02325,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:51:14.080696",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/new-york-city-taxi-fare-prediction_5410bc8c-37e4-45de-8c0f-5cd1d445eec5/2024-09-18T22-42-59-GMT/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 6179793.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:51:24.238396",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/predict-volcanic-eruptions-ingv-oe_1a401328-4107-45de-9a94-631c2274d888/2024-09-18T22-43-37-GMT/submission/submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.99938,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:51:24.274970",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/inaturalist-2019-fgvc6_ff9548f1-b198-41d9-9678-d4dfe536f8b9/2024-09-18T23-44-12-GMT/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": null,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:24.310482",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/osic-pulmonary-fibrosis-progression_74dd39e1-c5bd-424f-bb1d-1febe58dff27/2024-09-18T22-44-11-GMT/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.51205,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:24.318214",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/random-acts-of-pizza_e5679ca6-7851-419d-bcc8-267c0535901c/2024-09-19T00-44-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": 12116121.07262,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:51:24.650632",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/smartphone-decimeter-2022_5c6047fc-03c7-49ce-81eb-19281172bcbc/2024-09-18T22-49-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": 0.0475,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:25.900864",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/vinbigdata-chest-xray-abnormalities-detection_3285696d-2292-4b4f-998c-aebd3fda1b83/2024-09-19T04-50-03-GMT/submission/submission.csv"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": null,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:25.906771",
      "submission_path": "None"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.10952,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:25.931764",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/whale-categorization-playground_1f6afed8-8d9d-4914-877f-a7a9582d1b4b/2024-09-18T22-49-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.40792,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:26.000179",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/tweet-sentiment-extraction_ac1817a5-221c-4c83-8406-e274a1682edf/2024-09-18T22-49-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:26.002709",
      "submission_path": "None"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:51:26.005441",
      "submission_path": "None"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.9576,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:26.844340",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/tabular-playground-series-dec-2021_be7bf1fa-6487-4a14-882a-d6d086a5b144/2024-09-18T22-49-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.56256,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:51:26.857148",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/spooky-author-identification_c8e69626-fa10-4663-913d-63b5e6744a0a/2024-09-18T22-49-52-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:33.423699",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/tensorflow2-question-answering_ee045874-beb0-45f9-bd6d-f138c0eff85b/2024-09-18T22-50-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": null,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:33.741066",
      "submission_path": "None"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.90214,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:33.760709",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/plant-pathology-2021-fgvc8_9b52edab-35c1-4b3e-a8b7-7d18fe122079/2024-09-19T00-52-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:33.763081",
      "submission_path": "None"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:33.765281",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": null,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:33.767742",
      "submission_path": "None"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": null,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:33.774277",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/rsna-breast-cancer-detection_5b931c17-72b7-48a9-9c2c-57ff481452d0/2024-09-19T04-55-29-GMT/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:51:45.776633",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/denoising-dirty-documents_e57a9a20-9378-4147-bc99-f3990fb0d937/2024-09-18T22-57-52-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": null,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:45.934518",
      "submission_path": "None"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": 0.0,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:49.011923",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/nfl-player-contact-detection_0a2fe62b-f9b1-4112-bac5-02b64a1833ab/2024-09-18T23-58-06-GMT/submission/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": null,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:49.033193",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/alaska2-image-steganalysis_f7fea262-7e85-4518-a46d-1b613c40a6b1/2024-09-18T23-58-07-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.42345,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:49.101490",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/tweet-sentiment-extraction_600afd00-fc23-4ace-8d4f-10cf07deacb4/2024-09-18T22-57-58-GMT/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.50575,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:49.217425",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/random-acts-of-pizza_aad1336f-96ff-490a-88c6-539ddfb73ae9/2024-09-18T22-58-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 3.24773,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:51:49.808889",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/champs-scalar-coupling_e02170b6-d094-4eda-97b7-66fa3a1a8495/2024-09-18T22-58-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 5794242.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-20T21:51:49.816381",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/predict-volcanic-eruptions-ingv-oe_6ea5a7b5-a469-49c6-904b-995b6f749259/2024-09-18T22-58-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": 0.0,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:52.588216",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/3d-object-detection-for-autonomous-vehicles_5d1a0d99-9ae4-457d-8d72-d3e36b7acee3/2024-09-19T02-58-09-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": null,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:52.592344",
      "submission_path": "None"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.91221,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:53.296927",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/tabular-playground-series-may-2022_af5e251c-8d85-4326-b2c0-a594a46eed84/2024-09-18T22-58-02-GMT/submission/submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.48374,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:53.350586",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/seti-breakthrough-listen_1f9f0ff2-5015-4e73-9d3a-b07bb1dc1c8a/2024-09-19T04-01-06-GMT/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.37332,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:53.398228",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/google-quest-challenge_85badf49-a77b-441a-ab8c-21e9c88fdba6/2024-09-18T23-05-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": null,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:54.041527",
      "submission_path": "None"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": null,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:54.044577",
      "submission_path": "None"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": null,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:54.071407",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/hubmap-kidney-segmentation_b99e7424-a14d-4897-83db-0cf911518055/2024-09-19T02-24-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": null,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:54.074011",
      "submission_path": "None"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": 0.04567,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-20T21:51:54.088756",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/rsna-breast-cancer-detection_ab477240-d579-4a8f-95e9-79d3ea247471/2024-09-19T10-44-01-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.76269,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:05:22.119301",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/jigsaw-unintended-bias-in-toxicity-classification_c5dfc1c3-d049-4f91-b3d9-bc6953c195d6/2024-09-19T10-00-03-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": null,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:05:22.128282",
      "submission_path": "None"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": null,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:05:22.131394",
      "submission_path": "None"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": 0.0,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:05:22.779022",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/tgs-salt-identification-challenge_74f1bbd5-2889-45be-a6a9-cc362499626f/2024-09-19T22-03-10-GMT/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:05:22.781729",
      "submission_path": "None"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 2.05088,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:05:23.429244",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/ventilator-pressure-prediction_9eff2f93-d685-4804-942e-62fb2ec6b239/2024-09-18T22-01-51-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 1.10831,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:05:23.565742",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/lmsys-chatbot-arena_b5de506b-e2f1-4e3e-a83e-fa8293ad82dd/2024-09-18T22-02-01-GMT/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:05:23.569037",
      "submission_path": "None"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 2.00425,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:05:23.613409",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/dog-breed-identification_42024864-2013-4854-be9f-794b01e640fd/2024-09-18T22-06-34-GMT/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": null,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:05:23.616884",
      "submission_path": "None"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": 0.0033,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:07:55.414623",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/imet-2020-fgvc7_56d9b75d-f5c0-4d20-830f-6466c2c3f619/2024-09-19T00-06-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": null,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:07:55.418988",
      "submission_path": "None"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.93396,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:07:55.430894",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/leaf-classification_b85a9e82-47b0-4b0d-b85b-ad8bfa3eeba4/2024-09-18T22-06-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 4.69841,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:07:55.472792",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/dog-breed-identification_f4cf537c-2198-4bf6-b705-df7e7cd19ccf/2024-09-18T22-06-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": 0.30148,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:07:55.480493",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/statoil-iceberg-classifier-challenge_1657419d-4b8f-4793-a268-befd069fb937/2024-09-18T22-06-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": null,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:07:55.483433",
      "submission_path": "None"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": null,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:07:55.486743",
      "submission_path": "None"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.75531,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:07:55.550575",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/the-icml-2013-whale-challenge-right-whale-redux_d2e6c404-3098-4e5f-86df-140a637befa5/2024-09-18T22-06-55-GMT/submission/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.2886,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:07:55.566958",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/us-patent-phrase-to-phrase-matching_dfac7c52-f548-4ac4-a713-cafe25bd06a1/2024-09-18T22-07-03-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 1.1289,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:07:55.701307",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/lmsys-chatbot-arena_b5a0770e-5b80-4556-90c5-ad0b6b9f1571/2024-09-18T22-18-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.70349,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:07:55.737756",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/learning-agency-lab-automated-essay-scoring-2_7f83555b-5a07-4238-a35c-f93499e8d322/2024-09-18T22-18-45-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": 0.49855,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:07:55.792689",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/ranzcr-clip-catheter-line-classification_53b9e617-4734-4e92-b22b-978b3cfa6ccc/2024-09-18T22-18-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": 0.27033,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:05.146125",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/facebook-recruiting-iii-keyword-extraction_5a0a9967-269c-4372-b0de-939a86ab88b4/2024-09-19T00-18-44-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.51647,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:05.226849",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/rsna-miccai-brain-tumor-radiogenomic-classification_0c18dd5e-0081-44bb-91f4-72fab0586579/2024-09-18T22-18-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": 0.73889,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:05.281697",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/ranzcr-clip-catheter-line-classification_055463c2-d0c0-42bf-8a69-26f89225002e/2024-09-18T23-18-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 18.75706,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:05.290890",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/petfinder-pawpularity-score_96579187-a8b0-46c0-abb7-46c8b80538ee/2024-09-18T22-18-45-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:05.295072",
      "submission_path": "None"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.87018,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:05.306484",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/leaf-classification_7dcc9024-354d-497a-8c0d-32e6464aed96/2024-09-18T22-18-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:05.308912",
      "submission_path": "None"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 3e-05,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:16.149176",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/kuzushiji-recognition_f0e83e75-fa51-4b29-8b34-9515589c2d5c/2024-09-19T00-23-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:16.154470",
      "submission_path": "None"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.34742,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:16.166809",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/dogs-vs-cats-redux-kernels-edition_9cee7d08-36a1-493e-8745-b77e22d8152e/2024-09-18T22-29-08-GMT/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": 0.4205,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:16.179105",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/statoil-iceberg-classifier-challenge_c5bcd1c1-c762-4d85-95e0-8a4909b42081/2024-09-18T22-29-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.40094,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:16.202704",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/us-patent-phrase-to-phrase-matching_b529cede-8e13-4819-bc15-81d680bb49a5/2024-09-18T22-29-02-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.61169,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:17.927728",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/jigsaw-unintended-bias-in-toxicity-classification_c8b1a897-82eb-43e9-971d-0d2adc4c9b2b/2024-09-18T22-29-02-GMT/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:17.939396",
      "submission_path": "None"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 1.87698,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:18.001771",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/dog-breed-identification_ffa17841-cdee-46a8-abed-082420bb27b1/2024-09-18T23-29-08-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": null,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:18.007774",
      "submission_path": "None"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": null,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:18.011947",
      "submission_path": "None"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 2.04927,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:18.959609",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/ventilator-pressure-prediction_8ee81162-dd1d-4da5-8c4b-dd48d0ec7131/2024-09-18T22-29-06-GMT/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": 0.0,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:28.793811",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/facebook-recruiting-iii-keyword-extraction_0ba915f1-f5c9-467a-b11f-303ddd53bd9a/2024-09-19T00-29-17-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.84561,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:28.880601",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/siim-isic-melanoma-classification_f7e1f64a-823e-4c74-b0cd-75112fda4b0c/2024-09-19T03-29-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": 0.5221,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:29.500942",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/tgs-salt-identification-challenge_7d4165c3-9300-4993-b954-729d22895438/2024-09-18T23-34-48-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:29.507795",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/siim-covid19-detection_703f8b21-f650-4301-a4f1-d0bb8034300a/2024-09-18T22-34-38-GMT/submission/submission.csv"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": 0.25153,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:29.626453",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/imet-2020-fgvc7_f284b818-b181-4d20-bd10-f411ace05b43/2024-09-18T22-40-16-GMT/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": null,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:29.630003",
      "submission_path": "None"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": 0.17404,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:29.678193",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/iwildcam-2019-fgvc6_f368ad0a-cf64-49b3-9a7b-63981e1f1222/2024-09-19T12-38-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.65665,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:29.712806",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/learning-agency-lab-automated-essay-scoring-2_c2bc80de-5f77-48ea-998b-ab797964d790/2024-09-18T22-41-56-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.6609,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:30.875700",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/jigsaw-unintended-bias-in-toxicity-classification_68bcd73c-118a-4f65-96c3-6bdbf4486deb/2024-09-18T23-42-08-GMT/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.87018,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:30.893526",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/leaf-classification_48d58871-0c56-4300-ae84-207a81e20921/2024-09-18T22-42-12-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 20.15704,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:30.902548",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/petfinder-pawpularity-score_152af41b-ee1a-4d20-8886-d0b6e4e4b73c/2024-09-18T22-42-28-GMT/submission/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.0,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:40.763665",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/kuzushiji-recognition_a1952b63-5d89-4444-a85e-d1e3b7b591c7/2024-09-18T22-43-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": 0.84557,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:40.853764",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/ranzcr-clip-catheter-line-classification_d16e4f2d-4392-4046-af55-a93f8c90bf40/2024-09-19T00-44-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 1.10289,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:41.000271",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/lmsys-chatbot-arena_9a47ad1b-e401-479c-8a5a-1e4a7a8f0a97/2024-09-18T22-44-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": null,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:41.005167",
      "submission_path": "None"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": null,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.009933",
      "submission_path": "None"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": null,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.012845",
      "submission_path": "None"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": 0.5269,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:41.020673",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/statoil-iceberg-classifier-challenge_aed3e832-db72-4704-a4d0-383e560f10eb/2024-09-18T22-49-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": null,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.024395",
      "submission_path": "None"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.75824,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.070147",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/the-icml-2013-whale-challenge-right-whale-redux_72fd86a8-6989-4e22-80dd-901a0657495c/2024-09-18T22-49-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": null,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:41.075295",
      "submission_path": "None"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.75364,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.087984",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/siim-isic-melanoma-classification_a81cdd3a-4c4a-4e39-9f4d-b774eaa1f0bc/2024-09-18T22-57-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": null,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.091504",
      "submission_path": "None"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.49247,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.135365",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/the-icml-2013-whale-challenge-right-whale-redux_3cd19937-5bd8-42ad-b8bc-bcb5398a058e/2024-09-18T22-57-58-GMT/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.68239,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.171503",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/learning-agency-lab-automated-essay-scoring-2_79213f26-5a62-4dff-a294-a7244ec06384/2024-09-18T22-57-58-GMT/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": null,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.174710",
      "submission_path": "None"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.178879",
      "submission_path": "None"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": null,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:41.182558",
      "submission_path": "None"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": null,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.186546",
      "submission_path": "None"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.8074,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.199024",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/siim-isic-melanoma-classification_78c26884-0fb1-47b2-97be-ba246534feab/2024-09-19T04-59-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 1.20786,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:41.885169",
      "submission_path": "runs/2024-09-18T20-49-38-UTC_run-group_opendevin/ventilator-pressure-prediction_32e8a3b9-3d00-4275-ac16-9d4a55b29cb7/2024-09-18T23-05-42-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": null,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:08:41.889211",
      "submission_path": "None"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": null,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:08:41.892841",
      "submission_path": "None"
    }
  ]
}