{
  "total_runs": 180,
  "total_runs_with_submissions": 128,
  "total_valid_submissions": 90,
  "total_medals": 1,
  "total_gold_medals": 1,
  "total_silver_medals": 0,
  "total_bronze_medals": 0,
  "total_above_median": 3,
  "competition_reports": [
    {
      "competition_id": "champs-scalar-coupling",
      "score": 2.77693,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:42:25.429650",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/champs-scalar-coupling_47746642-9e81-4dbb-8b8b-7647e09d6d1a/2024-09-16T23-09-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.72886,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:25.458069",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/aptos2019-blindness-detection_819a2837-be93-4106-8b43-dd68af201027/2024-09-16T21-21-52-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": 0.97348,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:29.292070",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/text-normalization-challenge-russian-language_95a6f75c-6c4d-48b9-af40-6385f147bef7/2024-09-16T22-11-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.14821,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:29.393562",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/tweet-sentiment-extraction_26cf2ae5-f256-4688-acc0-13cd0609e033/2024-09-16T20-53-09-GMT/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 17332554.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:42:29.400790",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/predict-volcanic-eruptions-ingv-oe_61779171-a635-4eb9-9425-82942c51513d/2024-09-16T20-55-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:42:32.139091",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/denoising-dirty-documents_0f5e7bfd-6089-46c3-a329-5e0b5f6bef14/2024-09-16T22-08-01-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:32.249877",
      "submission_path": "None"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": null,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:42:48.391546",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/smartphone-decimeter-2022_cb718430-ea52-47ee-ab4c-77b062465342/2024-09-17T20-45-07-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": null,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:48.481662",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/vesuvius-challenge-ink-detection_21783f27-ddeb-42b8-8a86-267db0500771/2024-09-17T20-25-56-GMT/submission/submission.csv"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": null,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:48.485746",
      "submission_path": "None"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.29192,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:42:48.492257",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/nomad2018-predict-transparent-conductors_d7827002-0b7a-4744-8945-6359ec6accb8/2024-09-16T20-52-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": null,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:48.503071",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/aerial-cactus-identification_a2f81465-2736-4837-b0db-a573ab64434d/2024-09-17T03-20-28-GMT/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.5,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:48.510549",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/random-acts-of-pizza_160f6684-bad5-40df-8c24-a78241baf919/2024-09-16T21-10-11-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.9168,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:49.352052",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/tabular-playground-series-dec-2021_3b07b042-8ea0-4f4f-89c2-26191901af29/2024-09-17T07-06-06-GMT/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": null,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:49.372259",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/google-quest-challenge_366357ee-3146-4fed-b5b3-25010475c015/2024-09-16T20-53-16-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": null,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:42:49.385565",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/hms-harmful-brain-activity-classification_fb952b5e-ac18-4ba0-a01f-b1b67ac939d0/2024-09-17T19-56-57-GMT/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.59203,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:49.392615",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/random-acts-of-pizza_8d23020a-010a-44dd-acbb-b8358c951876/2024-09-16T22-01-52-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:49.960680",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/nfl-player-contact-detection_5b841f22-cbb0-4e83-b1bf-35821603d798/2024-09-17T20-10-57-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:50.519988",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/text-normalization-challenge-russian-language_670e868d-17a9-47e1-b91e-7570d48a6424/2024-09-17T20-04-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.62257,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:50.555592",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/cassava-leaf-disease-classification_6349fb1f-f956-4e76-911b-f33e4d1e985a/2024-09-16T21-58-37-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.56218,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:51.264729",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/tabular-playground-series-may-2022_a4cbe398-9fc6-4525-8cc2-5ef760b69af9/2024-09-16T21-02-51-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.93034,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:51.720760",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/jigsaw-toxic-comment-classification-challenge_f010e825-8dae-4b63-a0b7-a82c90be2464/2024-09-16T22-53-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.66117,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:51.741641",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/plant-pathology-2020-fgvc7_9d5637d5-187b-4065-97ea-04afd273bf41/2024-09-16T21-02-05-GMT/submission/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": 0.91269,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:42:51.746987",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/multi-modal-gesture-recognition_fcc88a0f-4c38-4cc3-ad85-bf85e3b2a9d9/2024-09-16T20-55-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": null,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:51.750244",
      "submission_path": "None"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.90523,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:51.883291",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/histopathologic-cancer-detection_c73a3e39-5f38-4555-b997-a70fdeb279ae/2024-09-17T07-14-03-GMT/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.50566,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:42:52.345841",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/random-acts-of-pizza_28377f5f-a27a-4b69-beb2-bb9640fbab8e/2024-09-16T20-55-27-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": 0.0,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:05.603604",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/vesuvius-challenge-ink-detection_ba04b1ff-e948-42ae-a46e-d1168fbb68ab/2024-09-17T02-18-09-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.0,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:05.855617",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/herbarium-2022-fgvc9_481b3662-8fcf-4141-9bc1-f0cf2c89d598/2024-09-17T16-10-55-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:06.082150",
      "submission_path": "None"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:06.084967",
      "submission_path": "None"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": null,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:06.102152",
      "submission_path": "None"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": null,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:06.114743",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/osic-pulmonary-fibrosis-progression_bb07d85c-0bcf-4553-ae45-2916d4fc2b23/2024-09-16T20-57-57-GMT/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": null,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:13.008676",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/whale-categorization-playground_0d660f6c-b045-4d54-99bf-a94b6d4698a1/2024-09-17T02-58-28-GMT/submission/submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": null,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:13.024631",
      "submission_path": "None"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:16.236396",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/denoising-dirty-documents_9b163cce-6fa9-4cf6-90aa-1ced0f02abb3/2024-09-18T00-17-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.0,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:16.587722",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/herbarium-2022-fgvc9_bc711364-169a-4d43-94d1-02ba364d2de6/2024-09-17T14-10-05-GMT/submission/submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": null,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:16.642733",
      "submission_path": "None"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.73113,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:16.676903",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/detecting-insults-in-social-commentary_380fff55-005c-443b-a4d1-0ef2a5a68690/2024-09-16T20-53-35-GMT/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": null,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:21.970710",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/denoising-dirty-documents_cdb2b120-b7c5-4bd6-876b-25cb51255827/2024-09-17T12-02-50-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": null,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:22.155905",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/vesuvius-challenge-ink-detection_74113c65-5126-49c5-ae80-0314456c3607/2024-09-17T20-01-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": null,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:22.168551",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/google-quest-challenge_3077581e-2c20-4b60-8f81-4719c0daf382/2024-09-16T21-52-27-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": null,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:22.182035",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/hms-harmful-brain-activity-classification_1014c0b9-a083-4e02-8d21-d04ae5ad2659/2024-09-17T20-52-01-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:22.191083",
      "submission_path": "None"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": null,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:22.202220",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/osic-pulmonary-fibrosis-progression_32b72677-456b-4a1a-bd13-47a15af9dc4a/2024-09-16T21-03-44-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:22.254686",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:22.326224",
      "submission_path": "None"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": null,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:22.334564",
      "submission_path": "None"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:22.487511",
      "submission_path": "None"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.63433,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:22.494739",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/aptos2019-blindness-detection_bd3ab2ab-1a0d-4e5a-8359-22959dbd972d/2024-09-16T20-57-58-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": null,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:22.497487",
      "submission_path": "None"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": 0.58571,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:22.507730",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/alaska2-image-steganalysis_648088c7-cc19-43a3-97d9-8b11da75c0e7/2024-09-17T01-09-06-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.20755,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:22.539940",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/tweet-sentiment-extraction_1e7d3cd5-89cb-4e5c-bde4-7abf0fe0dfa0/2024-09-16T22-12-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": null,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:22.595499",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/smartphone-decimeter-2022_63cfd208-b4a8-4c2a-a5d4-86f97c4e6a71/2024-09-17T10-06-15-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.70511,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:22.677489",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/plant-pathology-2021-fgvc8_7931c75c-24fa-46ad-be41-3ad326514456/2024-09-17T00-03-02-GMT/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": 0.00249,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:24.894540",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/h-and-m-personalized-fashion-recommendations_28db478c-ef35-41a4-bb06-db8fad345bef/2024-09-17T19-58-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 0.5,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:25.010959",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/aerial-cactus-identification_1e86b7c6-1c24-414c-86d4-26058a2bbb44/2024-09-16T22-58-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": null,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:25.013550",
      "submission_path": "None"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.62771,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:28.114971",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/spooky-author-identification_4c27cf1e-d0fe-4329-a84f-0111df1d70ec/2024-09-16T20-54-20-GMT/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 7893798.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:28.120920",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/predict-volcanic-eruptions-ingv-oe_e0930933-5e7f-4858-8c74-b526660ecbed/2024-09-16T21-02-33-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.89737,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:28.814351",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/tabular-playground-series-may-2022_7a8f6b13-da5b-4750-b97b-64656336eae2/2024-09-16T21-11-01-GMT/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:28.818258",
      "submission_path": "None"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": null,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:28.867962",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/uw-madison-gi-tract-image-segmentation_39b031c1-cfca-49c3-bc5f-4018aad5ea79/2024-09-17T20-01-22-GMT/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": 0.5,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:28.874622",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/mlsp-2013-birds_c14413bf-1bed-49ec-b2be-0aca3cd89f9c/2024-09-16T22-00-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": null,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:28.887469",
      "submission_path": "None"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": null,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:30.194175",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/seti-breakthrough-listen_a2bd378f-630f-4a70-a1ae-1f4cdf03e5db/2024-09-17T20-25-26-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:30.197893",
      "submission_path": "None"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": 0.0,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:36.735581",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/hubmap-kidney-segmentation_602a30a6-e119-4d9c-9690-9fe4192f0bc3/2024-09-17T01-55-49-GMT/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.8828,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:36.809268",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/detecting-insults-in-social-commentary_e7b3dce1-32e6-4208-a076-554d6918301e/2024-09-16T22-23-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": null,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:38.052772",
      "submission_path": "None"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:38.055486",
      "submission_path": "None"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.52208,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:38.067715",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/spooky-author-identification_7b3c6f60-fe81-43b2-9d49-300fd06deb08/2024-09-16T21-10-54-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.94398,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:38.741759",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/tabular-playground-series-dec-2021_4b1d7753-1e94-46d5-a2d3-087c5e765ee2/2024-09-16T21-11-03-GMT/submission/submission.csv"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": null,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:40.240798",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/bms-molecular-translation_d63bd690-a354-4465-8d48-33e2553a64d2/2024-09-17T01-55-42-GMT/submission/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.5,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:40.367823",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/histopathologic-cancer-detection_c25d200b-50f3-4115-a995-7c3635f9730b/2024-09-16T23-09-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:40.371050",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:40.376347",
      "submission_path": "None"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": null,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:40.502555",
      "submission_path": "None"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 1.9719,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:41.074183",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/champs-scalar-coupling_5f480e3d-958f-4929-8576-fc77cf1ab472/2024-09-17T14-55-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.64545,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:41.084777",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/plant-pathology-2020-fgvc7_a09c36a9-d8e2-4947-9478-a20e8095129c/2024-09-16T20-57-57-GMT/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": 0.00734,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:44.092403",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/h-and-m-personalized-fashion-recommendations_dae54e00-d564-4374-a4df-e8d7a0c4607a/2024-09-16T21-22-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": null,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:44.204677",
      "submission_path": "None"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 10.02631,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:44.240091",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/new-york-city-taxi-fare-prediction_7b064c84-9fe7-4cf8-a73e-849921331a10/2024-09-16T20-54-11-GMT/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 4.69271,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:43:44.250617",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/spooky-author-identification_c4707bf2-f728-485a-935e-87721584acf3/2024-09-16T22-02-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": null,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:44.254220",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/mlsp-2013-birds_b3f974b4-5979-47c1-b768-7291121864f5/2024-09-17T12-06-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.9565,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:46.130699",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/tabular-playground-series-dec-2021_775cf66b-5ac8-4b5b-b08b-bd3f883e41fd/2024-09-16T21-53-12-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": null,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:46.134360",
      "submission_path": "None"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.0,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:46.153016",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/cassava-leaf-disease-classification_d9c05810-7674-4008-995f-988b652cdce5/2024-09-16T23-55-33-GMT/submission/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": 0.58571,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:46.163029",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/alaska2-image-steganalysis_3086b737-4677-4e34-bd7c-d83bd49c7f10/2024-09-17T02-19-06-GMT/submission/submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": null,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:46.178704",
      "submission_path": "None"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:54.273394",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/tensorflow2-question-answering_a6b72f2d-26f3-47b2-9a0d-eb041d1b3d49/2024-09-17T20-07-56-GMT/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.0,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:54.594576",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/aptos2019-blindness-detection_3afd3530-09fc-4f52-9f95-91e0dc781226/2024-09-16T21-53-20-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": null,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:54.598190",
      "submission_path": "None"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": null,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:54.607073",
      "submission_path": "None"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.272,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:54.630279",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/plant-pathology-2021-fgvc8_4fac3564-1c04-49fd-ae12-685b5a2ff55e/2024-09-16T21-54-11-GMT/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.70161,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:43:55.441320",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/detecting-insults-in-social-commentary_29951896-895a-442b-a934-c3c89e0295e0/2024-09-16T20-56-08-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": null,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:44:05.108892",
      "submission_path": "None"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": null,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:44:05.112718",
      "submission_path": "None"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:44:05.115088",
      "submission_path": "None"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:44:05.117342",
      "submission_path": "None"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:44:05.120082",
      "submission_path": "None"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": null,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:44:05.175432",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/seti-breakthrough-listen_1aca54aa-e668-4200-9f23-4ef7ce221308/2024-09-17T20-15-20-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": null,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:44:05.716618",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/text-normalization-challenge-russian-language_d3837aaf-47cb-4f37-92dd-3ad03f5e50eb/2024-09-17T19-56-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.0,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:44:05.776044",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/hotel-id-2021-fgvc8_92a886ce-9f75-4c9f-ba4e-d4abeb132e0b/2024-09-17T08-55-55-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:44:05.822150",
      "submission_path": "None"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": null,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:44:05.825042",
      "submission_path": "None"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": null,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:44:05.899556",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/histopathologic-cancer-detection_a960d135-67b6-42a6-861f-dbbd8671263b/2024-09-17T19-59-37-GMT/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 7278483.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:44:05.906128",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/predict-volcanic-eruptions-ingv-oe_0c63f9cb-046b-48a6-b828-9cdfd742c909/2024-09-17T00-11-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": null,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:44:05.943157",
      "submission_path": "None"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.26623,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-09-19T23:44:05.989850",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/google-quest-challenge_d7516c4e-b87f-4b17-a9df-b303fecdfb68/2024-09-17T00-19-52-GMT/submission/submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:44:06.007400",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/inaturalist-2019-fgvc6_b4c7cf48-c816-4fe8-879c-d323e4d09d7b/2024-09-17T01-12-44-GMT/submission/submission.csv"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": null,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-09-19T23:44:06.036171",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/smartphone-decimeter-2022_e29295d3-1efc-4328-83a1-b75ba73dc639/2024-09-17T20-06-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": null,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:41.312799",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/ventilator-pressure-prediction_9b0056ba-2722-4166-ad1c-4bd58892a324/2024-09-16T23-14-40-GMT/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": null,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:41.317476",
      "submission_path": "None"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:41.319703",
      "submission_path": "None"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.325763",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/siim-covid19-detection_0dafcc19-b2e9-49f2-91ed-11470baaa4bc/2024-09-17T20-42-08-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.5,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.332126",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/rsna-miccai-brain-tumor-radiogenomic-classification_7830f400-461f-47c5-99c6-2b8a0e4854fb/2024-09-16T22-13-37-GMT/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.0,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.338505",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/chaii-hindi-and-tamil-question-answering_fb7c1b67-74dd-443e-9056-d5f8e0f59cd9/2024-09-16T20-52-31-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.340756",
      "submission_path": "None"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": null,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:41.344252",
      "submission_path": "None"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": null,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.346945",
      "submission_path": "None"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.91361,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:41.358311",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/leaf-classification_2e28a578-f5cb-457c-bbe4-4badbb053ac7/2024-09-16T21-23-27-GMT/submission/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": null,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.371977",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/kuzushiji-recognition_36f56e7f-7e51-4e1c-8283-05bfdae6c6ca/2024-09-17T14-08-33-GMT/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": null,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.383198",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/freesound-audio-tagging-2019_1488b8cd-a1d6-4fac-8255-5d5935bf9684/2024-09-17T19-57-05-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": null,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.387552",
      "submission_path": "None"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": null,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.389808",
      "submission_path": "None"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": null,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:41.393594",
      "submission_path": "None"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": null,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:41.796212",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/billion-word-imputation_9cc8d05e-451c-42fe-a4a8-5e1d030794f4/2024-09-17T20-47-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.48337,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.849105",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/the-icml-2013-whale-challenge-right-whale-redux_cd715970-3d76-478e-9921-6eb9bd445360/2024-09-16T21-12-30-GMT/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 4.33555,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:41.863146",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/leaf-classification_63be9381-8aea-4b1e-a706-3be707d1412a/2024-09-17T00-01-19-GMT/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": null,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.865601",
      "submission_path": "None"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": null,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.876280",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/ranzcr-clip-catheter-line-classification_dd3a79aa-9d19-4bad-8cca-7fc3c39649ae/2024-09-17T20-03-33-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": null,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.879186",
      "submission_path": "None"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.52503,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.894454",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/us-patent-phrase-to-phrase-matching_0149ef3d-d806-4b79-9a56-038d95520a73/2024-09-16T21-11-46-GMT/submission/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.42535,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.908997",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/us-patent-phrase-to-phrase-matching_92e3145d-d2d7-4dca-a276-c6b4a3c347f9/2024-09-17T07-02-53-GMT/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.0,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.916017",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/chaii-hindi-and-tamil-question-answering_33164646-da33-4517-9b7b-c530b28bc3f2/2024-09-17T01-58-14-GMT/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.52021,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.965526",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/the-icml-2013-whale-challenge-right-whale-redux_7a805cb5-d43b-49a9-a634-adffbe591b8d/2024-09-17T07-05-01-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.972930",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/siim-covid19-detection_3e0b3c65-839c-4599-8d0c-c5f4dfec4856/2024-09-17T13-26-11-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.66946,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:41.986106",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/siim-isic-melanoma-classification_141f6a5f-2237-4819-826a-5a372b28e8c9/2024-09-16T22-18-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 11.4743,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:42.114149",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/lmsys-chatbot-arena_3c4c990b-2ddb-4efe-971a-86bd7487af02/2024-09-16T20-52-44-GMT/submission/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": null,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:42.119019",
      "submission_path": "None"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.42554,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:42.127212",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/dogs-vs-cats-redux-kernels-edition_02a3f69d-b930-42b2-a996-57e2baed419f/2024-09-16T21-54-23-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": null,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:42.131821",
      "submission_path": "None"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": null,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:42.137350",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/statoil-iceberg-classifier-challenge_952a6d45-1744-41aa-b034-acbe5ea694f5/2024-09-17T20-11-09-GMT/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": null,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:42.176735",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/the-icml-2013-whale-challenge-right-whale-redux_96391198-2939-428e-aa12-d9c02f0815d3/2024-09-17T03-56-29-GMT/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": 0.0,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:45.069175",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/text-normalization-challenge-english-language_8033f690-49f3-4f42-8f55-05e8c39493e1/2024-09-17T19-03-24-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 17.90649,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:45.103393",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/dogs-vs-cats-redux-kernels-edition_c1afab85-b0ff-4212-8e4f-695b3792920f/2024-09-16T21-17-03-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": null,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:45.113990",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/rsna-miccai-brain-tumor-radiogenomic-classification_a79d132f-909c-474b-97e6-d3727f683af9/2024-09-17T16-13-03-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 4.26652,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:45.741881",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/ventilator-pressure-prediction_c8d8a566-5bb9-46cd-b984-88ddb34c3de7/2024-09-17T05-24-15-GMT/submission/submission.csv"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": 0.0,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:45.903582",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/imet-2020-fgvc7_3ccf03d3-a10e-4a38-ac54-2322a117a20d/2024-09-17T15-57-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 3.11999,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:45.945141",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/dog-breed-identification_b2406d0d-e697-4413-b7e1-84c6175e22b7/2024-09-16T22-53-47-GMT/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": 0.26701,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:46.429608",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/freesound-audio-tagging-2019_bea54b99-fb69-45ec-9735-d200ba58d407/2024-09-17T05-56-45-GMT/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 5.33604,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:46.441395",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/leaf-classification_57e465b2-78b1-4e43-9a83-778b123b99c0/2024-09-16T21-53-38-GMT/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.64375,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:46.474348",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/learning-agency-lab-automated-essay-scoring-2_ab7af45b-9af6-49c3-a588-daa816f7b7a5/2024-09-16T20-52-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": null,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:46.484702",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/ranzcr-clip-catheter-line-classification_368d83f7-3848-4894-b933-94bc0d171aa6/2024-09-17T20-05-08-GMT/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": 14.26026,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:46.492213",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/statoil-iceberg-classifier-challenge_f4f09a02-d49a-4309-bb3c-57612f294295/2024-09-16T21-02-53-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.5,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:47.633336",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/jigsaw-unintended-bias-in-toxicity-classification_4c087bb7-1f5a-4a8d-a6e8-a9a1432a851e/2024-09-17T19-55-18-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 20.09877,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:47.647886",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/petfinder-pawpularity-score_ead4c3e5-4df9-430b-af39-ca34d1e1b263/2024-09-16T21-23-03-GMT/submission/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": null,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:47.690203",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/kuzushiji-recognition_5631f1f9-012c-453c-9e71-3e5dcfe3a829/2024-09-17T08-27-24-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": null,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:47.693263",
      "submission_path": "None"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": null,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:47.698045",
      "submission_path": "None"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": null,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:47.711138",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/kuzushiji-recognition_238befef-fbfd-4a61-893d-cbb8bde1e90b/2024-09-17T07-57-56-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 4.78366,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:47.749142",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/dog-breed-identification_4c05e79d-e9c3-40f2-a589-1f00c9b5fa66/2024-09-17T02-19-45-GMT/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.67952,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:48.895894",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/jigsaw-unintended-bias-in-toxicity-classification_e930cb54-ae53-4ddf-9c9e-61ddb582f827/2024-09-17T00-01-10-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 20.13041,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:48.910423",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/petfinder-pawpularity-score_1b58dcf1-6a2b-49fb-b434-5ef3ba901c0b/2024-09-16T20-54-14-GMT/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": 0.4963,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:48.957011",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/ranzcr-clip-catheter-line-classification_7d29a4f5-494d-438d-9d0d-afbfe5455d3c/2024-09-17T20-14-29-GMT/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.5,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:48.963765",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/rsna-miccai-brain-tumor-radiogenomic-classification_bb1f315e-0893-4e91-954a-c634b0246eb3/2024-09-17T04-22-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": 0.3925,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:49.732131",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/tgs-salt-identification-challenge_b30122ee-1fdd-4b8c-9e64-6e3d83272e81/2024-09-17T00-11-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": 0.23904,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:58.942475",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/facebook-recruiting-iii-keyword-extraction_3567e019-f621-4edb-8a0f-5458a40ec818/2024-09-17T07-54-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 23.05715,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:59.146101",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/lmsys-chatbot-arena_a441ad5c-8c00-4206-9b3e-bcaa62c8ae04/2024-09-16T21-23-41-GMT/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 0.90877,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:59.188236",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/dog-breed-identification_4d4847c0-6670-4f75-82dd-34159203c9dd/2024-09-16T20-53-21-GMT/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": null,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:59.199414",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/freesound-audio-tagging-2019_72e3aac0-10a2-456c-993f-a071225aa5aa/2024-09-17T20-21-13-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.69059,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:59.212072",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/siim-isic-melanoma-classification_f57b15e3-55a0-4632-8654-7b952d20543d/2024-09-16T21-00-32-GMT/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.0,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:59.245658",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/learning-agency-lab-automated-essay-scoring-2_e92ad66e-5ed8-4bcb-a4ed-141f09b102c5/2024-09-16T22-00-34-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:59.249718",
      "submission_path": "None"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": 0.07757,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:59.296197",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/iwildcam-2019-fgvc6_8e016e2b-92f2-4964-acda-5d73f0eaca22/2024-09-17T02-05-43-GMT/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 20.12064,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2024-10-01T16:02:59.304881",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/petfinder-pawpularity-score_e201dd1b-d94a-4d36-bb5f-873a914cedbc/2024-09-16T21-02-00-GMT/submission/submission.csv"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:59.327622",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/imet-2020-fgvc7_5a234ee2-57e7-49ee-bf1f-5ddde28097f9/2024-09-17T20-05-39-GMT/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.5,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:59.339114",
      "submission_path": "runs/2024-09-16T19-44-41-UTC_run-group_mlagentbench/siim-isic-melanoma-classification_9583f1dd-fc7c-4801-9729-7368e62dbe02/2024-09-16T21-09-28-GMT/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": null,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2024-10-01T16:02:59.341544",
      "submission_path": "None"
    }
  ]
}