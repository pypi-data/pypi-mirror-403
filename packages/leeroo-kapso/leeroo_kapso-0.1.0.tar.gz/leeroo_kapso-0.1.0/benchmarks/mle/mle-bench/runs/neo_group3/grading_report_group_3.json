{
  "total_runs": 75,
  "total_runs_with_submissions": 69,
  "total_valid_submissions": 61,
  "total_medals": 25,
  "total_gold_medals": 9,
  "total_silver_medals": 8,
  "total_bronze_medals": 8,
  "total_above_median": 29,
  "competition_reports": [
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": 0.0,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:22:32.473565",
      "submission_path": "/workspace/run_3_dirs/3d-object-detection-for-autonomous-vehicles_df68ed59-34bd-4bac-a3cd-b5296fb4bc64/submission.csv"
    },
    {
      "competition_id": "AI4Code",
      "score": 0.40432,
      "gold_threshold": 0.9006,
      "silver_threshold": 0.8598,
      "bronze_threshold": 0.8534,
      "median_threshold": 0.8257,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:22:34.274252",
      "submission_path": "/workspace/run_3_dirs/AI4Code_90ee88ce-cd2d-48f8-92d0-311548e170f2/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 1.0,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:22:34.293236",
      "submission_path": "/workspace/run_3_dirs/aerial-cactus-identification_5e45b70f-de34-427e-8044-c09e2b4b74b1/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": null,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:22:34.303337",
      "submission_path": "/workspace/run_3_dirs/alaska2-image-steganalysis_b178a245-d24b-4c8e-8166-1644e16f417d/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.92498,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:22:34.311791",
      "submission_path": "/workspace/run_3_dirs/aptos2019-blindness-detection_4e920aad-d516-4fe3-89b6-b480a9a58eaa/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": 7.04183,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:22:35.533714",
      "submission_path": "/workspace/run_3_dirs/billion-word-imputation_c8a49040-2092-46d4-aba9-28e229dd1108/submission.csv"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": 263.52592,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:22:39.596929",
      "submission_path": "/workspace/run_3_dirs/bms-molecular-translation_fa7bdd01-a21a-4812-9d2b-a5a59767b57a/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.89126,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:22:39.641582",
      "submission_path": "/workspace/run_3_dirs/cassava-leaf-disease-classification_df8aea23-73b4-4682-9917-51cd61eafd74/submission.csv"
    },
    {
      "competition_id": "cdiscount-image-classification-challenge",
      "score": 5e-05,
      "gold_threshold": 0.77604,
      "silver_threshold": 0.73526,
      "bronze_threshold": 0.70898,
      "median_threshold": 0.44055,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:22:39.893303",
      "submission_path": "/workspace/run_3_dirs/cdiscount-image-classification-challenge_62c99709-0c66-4977-9068-b51c2c894add/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.72366,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:22:39.908249",
      "submission_path": "/workspace/run_3_dirs/chaii-hindi-and-tamil-question-answering_04278e51-8e63-4e6c-a296-a3bf2edd259b/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 1.23153,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:22:40.475350",
      "submission_path": "/workspace/run_3_dirs/champs-scalar-coupling_c459ae3c-fa1c-43b1-8638-c0dcd268f7d0/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": 0.27562,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:22:54.026690",
      "submission_path": "/workspace/run_3_dirs/denoising-dirty-documents_48000fef-35e0-416a-85ce-8953a4301f97/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": null,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:22:54.205336",
      "submission_path": "."
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 0.54577,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:22:54.257455",
      "submission_path": "/workspace/run_3_dirs/dog-breed-identification_d83d2a4d-ecfc-4bb6-9fc6-b1a9e6138a57/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.02127,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:22:54.266434",
      "submission_path": "/workspace/run_3_dirs/dogs-vs-cats-redux-kernels-edition_1bf70557-9a8a-4c76-b5ab-50eaf18fe54c/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": 0.53506,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:04.685831",
      "submission_path": "/workspace/run_3_dirs/facebook-recruiting-iii-keyword-extraction_4a7b7159-9388-48a6-b505-ac02d061792a/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": 0.59279,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:05.285025",
      "submission_path": "/workspace/run_3_dirs/freesound-audio-tagging-2019_ff8859de-5dcb-4957-a59c-eee65612a3c8/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.39179,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:05.314409",
      "submission_path": "/workspace/run_3_dirs/google-quest-challenge_14b52978-5d2d-4c08-bc56-2f67206412d9/submission.csv"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": null,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:05.331448",
      "submission_path": "/workspace/run_3_dirs/google-research-identify-contrails-reduce-global-warming_b700f2bd-0a55-48f6-bc2d-7b19c460490c/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": 0.00011,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:08.627436",
      "submission_path": "/workspace/run_3_dirs/h-and-m-personalized-fashion-recommendations_f3a35aed-20a1-4cbd-8e09-e1fce47f6c75/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": 0.19473,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:08.967468",
      "submission_path": "/workspace/run_3_dirs/herbarium-2020-fgvc7_23babdf4-f9a6-43ba-8db3-cd841d92bc14/submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": 0.00059,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:09.551400",
      "submission_path": "/workspace/run_3_dirs/herbarium-2021-fgvc8_3a5d412f-bb80-4492-8726-6136c3b3cd46/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.7735,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:09.761111",
      "submission_path": "/workspace/run_3_dirs/herbarium-2022-fgvc9_5a0b8376-1610-4d74-94f1-a00406532ab0/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.98195,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:09.885895",
      "submission_path": "/workspace/run_3_dirs/histopathologic-cancer-detection_37533544-d52b-45d3-bf25-b47d2b8d9979/submission.csv"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": 0.83488,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:09.941734",
      "submission_path": "/workspace/run_3_dirs/hms-harmful-brain-activity-classification_26d34448-9e19-49cd-b651-9934131104ac/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.25573,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:09.989221",
      "submission_path": "/workspace/run_3_dirs/hotel-id-2021-fgvc8_d1dd5e1a-2653-4c6f-b90f-f0f3addff938/submission.csv"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": 0.04782,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:21.672226",
      "submission_path": "/workspace/run_3_dirs/hubmap-kidney-segmentation_b606f84c-1ec6-4523-91a4-b2b841bd23b1/submission.csv"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": null,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:21.677964",
      "submission_path": "."
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": 0.55472,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:21.875891",
      "submission_path": "/workspace/run_3_dirs/imet-2020-fgvc7_26a01800-2779-4e6f-a50a-7ac4c8cb9b71/submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.19454,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:21.920961",
      "submission_path": "/workspace/run_3_dirs/inaturalist-2019-fgvc6_3c34570f-a6af-478a-82d4-45112889043f/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": 0.47775,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:21.969435",
      "submission_path": "/workspace/run_3_dirs/iwildcam-2019-fgvc6_7d395484-8ffc-4288-9b56-6c532b397efb/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": 0.67829,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:22.102138",
      "submission_path": "/workspace/run_3_dirs/iwildcam-2020-fgvc7_bde311f3-ab45-4e6b-9c2b-9aac0fa6d134/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.98652,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:22.495792",
      "submission_path": "/workspace/run_3_dirs/jigsaw-toxic-comment-classification-challenge_882cdd3f-d605-40d0-b5f1-adad950dc93b/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.81502,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:23.765797",
      "submission_path": "/workspace/run_3_dirs/jigsaw-unintended-bias-in-toxicity-classification_45e99160-5ef1-4fe7-acd5-8a631197f311/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.54163,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:26.712429",
      "submission_path": "/workspace/run_3_dirs/kuzushiji-recognition_33752e5a-1a0b-4813-a259-9e3392b54807/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.25334,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:26.754432",
      "submission_path": "/workspace/run_3_dirs/leaf-classification_837ac46c-d443-4bf8-baae-76432ed0dc55/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.83742,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:26.793852",
      "submission_path": "/workspace/run_3_dirs/learning-agency-lab-automated-essay-scoring-2_7c455472-8fe7-480e-97d6-a68294f523a9/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 0.99092,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:26.932898",
      "submission_path": "/workspace/run_3_dirs/lmsys-chatbot-arena_e53ff293-5c9c-4a1c-809d-84745c93ee3c/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": 0.86774,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:26.940509",
      "submission_path": "/workspace/run_3_dirs/mlsp-2013-birds_15932a39-160f-4367-94a2-4c6fef1dff61/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": 0.95019,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:26.945901",
      "submission_path": "/workspace/run_3_dirs/multi-modal-gesture-recognition_b34009a4-ae08-4705-b90c-ad002baa8cd1/submission.csv"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": null,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:26.949367",
      "submission_path": "."
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": null,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:29.248247",
      "submission_path": "/workspace/run_3_dirs/nfl-player-contact-detection_6a016340-5871-4bdb-a67d-9a0f84320983/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.05978,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:29.304894",
      "submission_path": "/workspace/run_3_dirs/nomad2018-predict-transparent-conductors_1ee464b0-1a85-4c78-9883-3c55e0b16931/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": -8.65883,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:29.365825",
      "submission_path": "/workspace/run_3_dirs/osic-pulmonary-fibrosis-progression_382bb287-ac90-4b8a-9f30-9a6ca835aaa8/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 18.77071,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:29.376376",
      "submission_path": "/workspace/run_3_dirs/petfinder-pawpularity-score_a7778a4c-ca21-4bbe-94bf-5ab28b4def6d/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.98572,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:29.386474",
      "submission_path": "/workspace/run_3_dirs/plant-pathology-2020-fgvc7_204f88ed-a92c-45ab-8360-e8d01f405400/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.90062,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:29.407028",
      "submission_path": "/workspace/run_3_dirs/plant-pathology-2021-fgvc8_4bf1ceb3-106f-414f-af6d-3709196472dd/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 2902638.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:29.413794",
      "submission_path": "/workspace/run_3_dirs/predict-volcanic-eruptions-ingv-oe_597b460f-a365-4ffd-a291-94e81ce8459b/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.69417,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:29.421220",
      "submission_path": "/workspace/run_3_dirs/random-acts-of-pizza_3ec06e43-fed2-40ef-8ea1-e4ab11248b14/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": 0.8558,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:29.478803",
      "submission_path": "/workspace/run_3_dirs/ranzcr-clip-catheter-line-classification_87955cb2-eb2f-4269-aec2-5eedcd78dd4a/submission.csv"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": null,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:29.501366",
      "submission_path": "/workspace/run_3_dirs/rsna-2022-cervical-spine-fracture-detection_95818fab-23ed-4f46-8ba4-6fd7c6a031cf/submission.csv"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": null,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:29.506410",
      "submission_path": "."
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.58824,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:29.513604",
      "submission_path": "/workspace/run_3_dirs/rsna-miccai-brain-tumor-radiogenomic-classification_eacb0844-a8d3-421c-8c5f-29e931670aba/submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.79164,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:29.531657",
      "submission_path": "/workspace/run_3_dirs/seti-breakthrough-listen_c92fb0cc-f72e-44b8-bb2d-1e55e78aec06/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": null,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:29.538997",
      "submission_path": "/workspace/run_3_dirs/siim-covid19-detection_bc9c367a-96c1-4b1b-bee6-988c97e0637e/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": null,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:29.546652",
      "submission_path": "/workspace/run_3_dirs/siim-isic-melanoma-classification_f62c9483-91bd-4c52-be9f-1f55492e17cd/submission.csv"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": 3122773.6564,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:29.678940",
      "submission_path": "/workspace/run_3_dirs/smartphone-decimeter-2022_d765d833-3218-4d6d-9822-c592adc23ade/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.27069,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:29.692015",
      "submission_path": "/workspace/run_3_dirs/spooky-author-identification_31a8103f-4b7e-4913-85e8-2abd0b4565b7/submission.csv"
    },
    {
      "competition_id": "stanford-covid-vaccine",
      "score": 0.28491,
      "gold_threshold": 0.34728,
      "silver_threshold": 0.35175,
      "bronze_threshold": 0.3534,
      "median_threshold": 0.363095,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:29.784874",
      "submission_path": "/workspace/run_3_dirs/stanford-covid-vaccine_069a4c02-2468-4aa4-bdf8-a51ffd419c8f/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": 0.30405,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:23:29.794117",
      "submission_path": "/workspace/run_3_dirs/statoil-iceberg-classifier-challenge_2b17bf9f-5a16-4598-90b8-daca970f6c9f/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.95837,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:30.608069",
      "submission_path": "/workspace/run_3_dirs/tabular-playground-series-dec-2021_d75ab606-adf7-4680-b168-d460a577beb6/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.95357,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:31.384958",
      "submission_path": "/workspace/run_3_dirs/tabular-playground-series-may-2022_2e2abdb7-c4db-4d28-804e-26c241387d0f/submission.csv"
    },
    {
      "competition_id": "tensorflow-speech-recognition-challenge",
      "score": 0.34065,
      "gold_threshold": 0.90485,
      "silver_threshold": 0.89627,
      "bronze_threshold": 0.88793,
      "median_threshold": 0.77722,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:31.404561",
      "submission_path": "/workspace/run_3_dirs/tensorflow-speech-recognition-challenge_6c940b5d-665e-48e4-ae20-888a8b262c31/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": 0.57117,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:43.536952",
      "submission_path": "/workspace/run_3_dirs/tensorflow2-question-answering_9d8427d5-fd2c-4752-b011-b88b2a459ccc/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": 0.94635,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:46.908673",
      "submission_path": "/workspace/run_3_dirs/text-normalization-challenge-english-language_d2dfa176-b27c-4435-9092-e98081bcc32a/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": 0.6861,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:50.946990",
      "submission_path": "/workspace/run_3_dirs/text-normalization-challenge-russian-language_91941477-29d6-4cfe-8150-622a2b705154/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": null,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:51.005753",
      "submission_path": "/workspace/run_3_dirs/tgs-salt-identification-challenge_cc13293f-b4a0-48aa-8609-f746f5d49869/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": null,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:51.009004",
      "submission_path": "."
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.70981,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:51.031339",
      "submission_path": "/workspace/run_3_dirs/tweet-sentiment-extraction_cd729ecb-0b7c-4758-a3ed-68751205fe9e/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.82922,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:23:51.047051",
      "submission_path": "/workspace/run_3_dirs/us-patent-phrase-to-phrase-matching_0c43816c-fb8d-4bec-9663-f4d3e4389fb2/submission.csv"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": 0.44372,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:24:05.893276",
      "submission_path": "/workspace/run_3_dirs/uw-madison-gi-tract-image-segmentation_c5c6f69c-eb61-44d0-86e4-f96e1814681f/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 4.22046,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-07-28T21:24:06.590783",
      "submission_path": "/workspace/run_3_dirs/ventilator-pressure-prediction_fc83d825-b40c-4b05-b71c-f38b138c81e3/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": null,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:24:06.601726",
      "submission_path": "/workspace/run_3_dirs/vesuvius-challenge-ink-detection_379a5438-22cb-4688-8583-afaf925b9ec3/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": null,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:24:06.607695",
      "submission_path": "."
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.42718,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-07-28T21:24:06.622469",
      "submission_path": "/workspace/run_3_dirs/whale-categorization-playground_90288f2a-3271-41f1-8ab5-9784d8c9a94b/submission.csv"
    }
  ]
}