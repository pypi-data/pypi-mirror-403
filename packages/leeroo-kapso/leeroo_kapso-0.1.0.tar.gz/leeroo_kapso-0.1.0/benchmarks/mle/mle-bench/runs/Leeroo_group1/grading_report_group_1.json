{
  "total_runs": 40,
  "total_runs_with_submissions": 40,
  "total_valid_submissions": 40,
  "total_medals": 40,
  "total_gold_medals": 17,
  "total_silver_medals": 12,
  "total_bronze_medals": 11,
  "total_above_median": 40,
  "competition_reports": [
    {
      "competition_id": "aerial-cactus-identification",
      "score": 1.0,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:47:33.692863",
      "submission_path": "1/aerial-cactus-identification/final_submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.92766,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:47:33.718855",
      "submission_path": "1/aptos2019-blindness-detection/final_submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": 0.02076,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T11:47:52.621380",
      "submission_path": "1/denoising-dirty-documents/final_submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.81738,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:47:52.876579",
      "submission_path": "1/detecting-insults-in-social-commentary/final_submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.00077,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T11:47:52.894556",
      "submission_path": "1/dogs-vs-cats-redux-kernels-edition/final_submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.9949,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:47:53.071482",
      "submission_path": "1/histopathologic-cancer-detection/final_submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.98715,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:47:54.316405",
      "submission_path": "1/jigsaw-toxic-comment-classification-challenge/final_submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.00078,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T11:47:54.357292",
      "submission_path": "1/leaf-classification/final_submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": 0.92366,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:47:54.370711",
      "submission_path": "1/mlsp-2013-birds/final_submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.06368,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T11:47:54.384031",
      "submission_path": "1/nomad2018-predict-transparent-conductors/final_submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.99269,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:47:54.403001",
      "submission_path": "1/plant-pathology-2020-fgvc7/final_submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.24736,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T11:47:54.428771",
      "submission_path": "1/spooky-author-identification/final_submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.96201,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:47:56.451267",
      "submission_path": "1/tabular-playground-series-dec-2021/final_submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": 0.99059,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:48:00.611410",
      "submission_path": "1/text-normalization-challenge-english-language/final_submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": 0.97599,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:48:05.826836",
      "submission_path": "1/text-normalization-challenge-russian-language/final_submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.99068,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:48:05.996035",
      "submission_path": "1/the-icml-2013-whale-challenge-right-whale-redux/final_submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": 0.05922,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:03.102042",
      "submission_path": "1/3d-object-detection-for-autonomous-vehicles/final_submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": 0.49255,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:03.190407",
      "submission_path": "1/iwildcam-2019-fgvc6/final_submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 3483970.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T11:51:03.219024",
      "submission_path": "1/predict-volcanic-eruptions-ingv-oe/final_submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.58,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:03.239406",
      "submission_path": "1/rsna-miccai-brain-tumor-radiogenomic-classification/final_submission.csv"
    },
    {
      "competition_id": "stanford-covid-vaccine",
      "score": 0.34647,
      "gold_threshold": 0.34728,
      "silver_threshold": 0.35175,
      "bronze_threshold": 0.3534,
      "median_threshold": 0.363095,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T11:51:03.427787",
      "submission_path": "1/stanford-covid-vaccine/final_submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": 0.28434,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:05.139862",
      "submission_path": "1/vinbigdata-chest-xray-abnormalities-detection/final_submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.90695,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:05.161743",
      "submission_path": "1/cassava-leaf-disease-classification/final_submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.82768,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:05.180255",
      "submission_path": "1/chaii-hindi-and-tamil-question-answering/final_submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.42268,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:05.235619",
      "submission_path": "1/google-quest-challenge/final_submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": 0.25403,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:05.682907",
      "submission_path": "1/herbarium-2020-fgvc7/final_submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": 0.3493,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:06.644792",
      "submission_path": "1/herbarium-2021-fgvc8/final_submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.63184,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:06.967619",
      "submission_path": "1/herbarium-2022-fgvc9/final_submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.52182,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:07.041077",
      "submission_path": "1/hotel-id-2021-fgvc8/final_submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.35879,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T11:51:07.110638",
      "submission_path": "1/inaturalist-2019-fgvc6/final_submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": 0.71829,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:07.306369",
      "submission_path": "1/iwildcam-2020-fgvc7/final_submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.66068,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:07.848134",
      "submission_path": "1/kuzushiji-recognition/final_submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.84067,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:07.929904",
      "submission_path": "1/learning-agency-lab-automated-essay-scoring-2/final_submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 0.97911,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T11:51:08.246187",
      "submission_path": "1/lmsys-chatbot-arena/final_submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 17.09548,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-07T11:51:08.271078",
      "submission_path": "1/petfinder-pawpularity-score/final_submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.92606,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:08.306483",
      "submission_path": "1/plant-pathology-2021-fgvc8/final_submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.84299,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:08.338564",
      "submission_path": "1/seti-breakthrough-listen/final_submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.71854,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:08.376043",
      "submission_path": "1/tweet-sentiment-extraction/final_submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.87625,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:08.405736",
      "submission_path": "1/us-patent-phrase-to-phrase-matching/final_submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.64662,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-07T11:51:08.432494",
      "submission_path": "1/whale-categorization-playground/final_submission.csv"
    }
  ]
}