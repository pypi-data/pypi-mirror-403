{
  "total_runs": 52,
  "total_runs_with_submissions": 52,
  "total_valid_submissions": 52,
  "total_medals": 47,
  "total_gold_medals": 28,
  "total_silver_medals": 12,
  "total_bronze_medals": 7,
  "total_above_median": 49,
  "competition_reports": [
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.90284,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:45.375807",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-54-42-GMT_run-group_piml_v1__split_0_unknown_llm_0steps_24hrs_gpu_40cores/cassava-leaf-disease-classification_006bb52a-fc1f-415e-94aa-88edc34e6298/submission/submission.csv"
    },
    {
      "competition_id": "cdiscount-image-classification-challenge",
      "score": 0.7152,
      "gold_threshold": 0.77604,
      "silver_threshold": 0.73526,
      "bronze_threshold": 0.70898,
      "median_threshold": 0.44055,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:45.985384",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-54-43-GMT_run-group_piml_v1__split_1_unknown_llm_0steps_24hrs_gpu_40cores/cdiscount-image-classification-challenge_ffc5ae61-6ef1-4d1c-9a08-4c1024ca764f/submission/submission.csv"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": 0.94911,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:54.651769",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-54-48-GMT_run-group_piml_v1__split_10_unknown_llm_0steps_24hrs_gpu_40cores/hubmap-kidney-segmentation_570ab8e2-0bcc-4deb-ad84-1053bd9097e7/submission/submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.21997,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:40:54.826933",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-54-49-GMT_run-group_piml_v1__split_11_unknown_llm_0steps_24hrs_gpu_40cores/inaturalist-2019-fgvc6_bd4a0d11-3a36-487e-9e0b-a4e5e54f7c93/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": 0.80123,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:55.042674",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-54-54-GMT_run-group_piml_v1__split_12_unknown_llm_0steps_24hrs_gpu_40cores/iwildcam-2020-fgvc7_e457025e-becd-4ff5-8674-89da73ede191/submission/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.915,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:55.500877",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-54-56-GMT_run-group_piml_v1__split_13_unknown_llm_0steps_24hrs_gpu_40cores/kuzushiji-recognition_78ffb43c-a27c-446e-8e09-6888feefdcfd/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.84855,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:55.701673",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-55-00-GMT_run-group_piml_v1__split_14_unknown_llm_0steps_24hrs_gpu_40cores/learning-agency-lab-automated-essay-scoring-2_64bdf7bc-34aa-48f8-ad67-37dc8d95b4b3/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 1.00264,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:40:56.059938",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-55-01-GMT_run-group_piml_v1__split_15_unknown_llm_0steps_24hrs_gpu_40cores/lmsys-chatbot-arena_37dabb7b-c062-4d54-a8ab-e831c3b8b305/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 17.0719,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:40:56.205169",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-55-06-GMT_run-group_piml_v1__split_16_unknown_llm_0steps_24hrs_gpu_40cores/petfinder-pawpularity-score_32e7fcc0-480b-4edc-8d47-de958bc5e628/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.94047,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:56.355089",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-55-07-GMT_run-group_piml_v1__split_17_unknown_llm_0steps_24hrs_gpu_40cores/plant-pathology-2021-fgvc8_4947ca93-c027-418d-8f89-22d211b6a955/submission/submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.88027,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:56.524066",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-55-12-GMT_run-group_piml_v1__split_18_unknown_llm_0steps_24hrs_gpu_40cores/seti-breakthrough-listen_9e1beeeb-f451-45c4-b246-8718ab232d02/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.72214,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:56.665323",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-55-13-GMT_run-group_piml_v1__split_19_unknown_llm_0steps_24hrs_gpu_40cores/tweet-sentiment-extraction_ad20fcdf-6b20-4bad-8dae-c4d12a823eed/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.75997,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:56.773792",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-55-18-GMT_run-group_piml_v1__split_2_unknown_llm_0steps_24hrs_gpu_40cores/chaii-hindi-and-tamil-question-answering_ceae4d62-1785-402a-91a8-79d3125ca485/submission/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.87472,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:56.920542",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-55-20-GMT_run-group_piml_v1__split_20_unknown_llm_0steps_24hrs_gpu_40cores/us-patent-phrase-to-phrase-matching_10ebd3db-6f7f-4dae-b589-ae35c372dddd/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.68011,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:57.047358",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-55-24-GMT_run-group_piml_v1__split_21_unknown_llm_0steps_24hrs_gpu_40cores/whale-categorization-playground_7d606c2b-474e-4c78-8e21-d45dd529b9dd/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.42842,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:57.181971",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-55-30-GMT_run-group_piml_v1__split_4_unknown_llm_0steps_24hrs_gpu_40cores/google-quest-challenge_bcb2c88f-1deb-4349-8f3c-b15d004e83e8/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": 0.57257,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:57.655556",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-55-37-GMT_run-group_piml_v1__split_6_unknown_llm_0steps_24hrs_gpu_40cores/herbarium-2020-fgvc7_1acd5bd7-d144-4454-8349-57d035b150aa/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": 0.46775,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:58.499498",
      "submission_path": "submission_24hrs/seed1/2025-12-20T21-55-38-GMT_run-group_piml_v1__split_7_unknown_llm_0steps_24hrs_gpu_40cores/herbarium-2021-fgvc8_43a4b698-c8aa-4a26-a35f-ad846ee0d448/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.74398,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:58.884232",
      "submission_path": "submission_24hrs/seed1/2025-12-20T22-27-01-GMT_run-group_piml_v1__split_8_unknown_llm_0steps_24hrs_gpu_40cores/herbarium-2022-fgvc9_24120e09-efba-4432-84a3-06a9f1e27101/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.75729,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:59.091671",
      "submission_path": "submission_24hrs/seed1/2025-12-20T22-27-01-GMT_run-group_piml_v1__split_9_unknown_llm_0steps_24hrs_gpu_40cores/hotel-id-2021-fgvc8_ef68165b-19e0-4538-b2eb-26e98009bf94/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 1.0,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:59.206954",
      "submission_path": "submission_24hrs/seed1/2025-12-23T03-13-14-GMT_run-group_piml_v1__aerial-cactus-identification_unknown_llm_0steps_24hrs_gpu_40cores/aerial-cactus-identification_80edd3a8-d605-4ba5-8936-4498f7b1dbb0/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.9291,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:40:59.334731",
      "submission_path": "submission_24hrs/seed1/2025-12-23T03-13-16-GMT_run-group_piml_v1__aptos2019-blindness-detection_unknown_llm_0steps_24hrs_gpu_40cores/aptos2019-blindness-detection_2bbbf7d2-f641-4c50-aab2-ae921ed79eba/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": 0.00986,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:41:11.809264",
      "submission_path": "submission_24hrs/seed1/2025-12-23T03-13-20-GMT_run-group_piml_v1__denoising-dirty-documents_unknown_llm_0steps_24hrs_gpu_40cores/denoising-dirty-documents_ddecb0d7-9a65-4518-9ce1-f5ef9eb3a210/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.958,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:41:12.101968",
      "submission_path": "submission_24hrs/seed1/2025-12-23T03-13-22-GMT_run-group_piml_v1__detecting-insults-in-social-commentary_unknown_llm_0steps_24hrs_gpu_40cores/detecting-insults-in-social-commentary_1e8a5951-afd7-46d7-80a1-64f90e37a865/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 0.29443,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:41:12.339332",
      "submission_path": "submission_24hrs/seed1/2025-12-23T03-13-27-GMT_run-group_piml_v1__dog-breed-identification_unknown_llm_0steps_24hrs_gpu_40cores/dog-breed-identification_cd934b31-c821-469b-9427-5d2eb39059b2/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.00398,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:41:12.455068",
      "submission_path": "submission_24hrs/seed1/2025-12-23T03-13-28-GMT_run-group_piml_v1__dogs-vs-cats-redux-kernels-edition_unknown_llm_0steps_24hrs_gpu_40cores/dogs-vs-cats-redux-kernels-edition_81075a18-0d17-4289-b62f-91b6a2a1affd/submission/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.99785,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:41:12.733736",
      "submission_path": "submission_24hrs/seed1/2025-12-23T03-13-32-GMT_run-group_piml_v1__histopathologic-cancer-detection_unknown_llm_0steps_24hrs_gpu_40cores/histopathologic-cancer-detection_293cd9f0-5baa-4ff8-839b-c6da85de4484/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.98784,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:41:13.381710",
      "submission_path": "submission_24hrs/seed1/2025-12-23T03-13-34-GMT_run-group_piml_v1__jigsaw-toxic-comment-classification-challenge_unknown_llm_0steps_24hrs_gpu_40cores/jigsaw-toxic-comment-classification-challenge_c1a4b23b-8f2a-448b-8885-3637db4bf169/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": 0.93215,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:41:13.503312",
      "submission_path": "submission_24hrs/seed1/2025-12-23T03-13-44-GMT_run-group_piml_v1__mlsp-2013-birds_unknown_llm_0steps_24hrs_gpu_40cores/mlsp-2013-birds_bb6afbe9-0250-4863-bca9-cc6b6aba959f/submission/submission.csv"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 4.56837,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:41:13.700142",
      "submission_path": "submission_24hrs/seed1/2025-12-24T05-02-11-GMT_run-group_piml_v1__new-york-city-taxi-fare-prediction_unknown_llm_0steps_24hrs_gpu_40cores/new-york-city-taxi-fare-prediction_b3420f4e-1869-4b74-81c5-32c92b32faea/submission/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.05576,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:41:13.826286",
      "submission_path": "submission_24hrs/seed1/2025-12-24T05-02-11-GMT_run-group_piml_v1__nomad2018-predict-transparent-conductors_unknown_llm_0steps_24hrs_gpu_40cores/nomad2018-predict-transparent-conductors_f1de1b4f-eb99-4069-be7a-6d7832ff17fe/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.99825,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:41:13.963881",
      "submission_path": "submission_24hrs/seed1/2025-12-24T05-02-12-GMT_run-group_piml_v1__plant-pathology-2020-fgvc7_unknown_llm_0steps_24hrs_gpu_40cores/plant-pathology-2020-fgvc7_b18ec4ec-f775-44f2-9ef5-8d0ad55e6d6b/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": 0.96337,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:41:14.179250",
      "submission_path": "submission_24hrs/seed1/2025-12-24T05-02-18-GMT_run-group_piml_v1__ranzcr-clip-catheter-line-classification_unknown_llm_0steps_24hrs_gpu_40cores/ranzcr-clip-catheter-line-classification_0d37e035-a050-402b-b3b3-5098fa0144d5/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.25307,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:41:14.295965",
      "submission_path": "submission_24hrs/seed1/2025-12-24T05-02-25-GMT_run-group_piml_v1__spooky-author-identification_unknown_llm_0steps_24hrs_gpu_40cores/spooky-author-identification_02414d03-a446-42be-8a23-c4c379c32c90/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.96334,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:41:15.229714",
      "submission_path": "submission_24hrs/seed1/2025-12-24T05-02-26-GMT_run-group_piml_v1__tabular-playground-series-dec-2021_unknown_llm_0steps_24hrs_gpu_40cores/tabular-playground-series-dec-2021_18a8e5e6-85fc-4c8b-8d5b-415193478fb8/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.99665,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:41:16.217445",
      "submission_path": "submission_24hrs/seed1/2025-12-24T05-02-30-GMT_run-group_piml_v1__tabular-playground-series-may-2022_unknown_llm_0steps_24hrs_gpu_40cores/tabular-playground-series-may-2022_81ba71b4-6f09-4f37-874b-25873c17e319/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": 0.99524,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:41:19.461736",
      "submission_path": "submission_24hrs/seed1/2025-12-24T05-02-33-GMT_run-group_piml_v1__text-normalization-challenge-english-language_unknown_llm_0steps_24hrs_gpu_40cores/text-normalization-challenge-english-language_abd32b73-8732-4197-8ba8-b512a6c333ee/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.99276,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:41:19.714203",
      "submission_path": "submission_24hrs/seed1/2025-12-24T05-05-43-GMT_run-group_piml_v1_Low_the-icml-2013-whale-challenge-right-whale-redux_unknown_llm_0steps_24hrs_gpu_40cores/the-icml-2013-whale-challenge-right-whale-redux_fd772071-37e8-4f32-bb2a-da946ba1ecdd/submission/submission.csv"
    },
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": 0.17724,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:46:40.216057",
      "submission_path": "submission_24hrs/seed1/2025-12-25T08-01-56-GMT_run-group_piml_v1__3d-object-detection-for-autonomous-vehicles_unknown_llm_0steps_24hrs_gpu_40cores/3d-object-detection-for-autonomous-vehicles_8a3ff190-02be-41d6-a459-90c9c0b6477f/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": 0.67087,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:46:40.451205",
      "submission_path": "submission_24hrs/seed1/2025-12-25T08-01-57-GMT_run-group_piml_v1__iwildcam-2019-fgvc6_unknown_llm_0steps_24hrs_gpu_40cores/iwildcam-2019-fgvc6_3921df86-077f-4b10-b8bc-1f8ad3e6bcd4/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": 0.67193,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:46:42.643577",
      "submission_path": "submission_24hrs/seed1/2025-12-25T08-02-01-GMT_run-group_piml_v1__nfl-player-contact-detection_unknown_llm_0steps_24hrs_gpu_40cores/nfl-player-contact-detection_30815ea1-b117-47f2-8c21-e870fd3fabd9/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 611025.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:46:42.731728",
      "submission_path": "submission_24hrs/seed1/2025-12-25T08-02-03-GMT_run-group_piml_v1__predict-volcanic-eruptions-ingv-oe_unknown_llm_0steps_24hrs_gpu_40cores/predict-volcanic-eruptions-ingv-oe_e95afd41-9984-4c48-acdb-619abcd546fe/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": 0.34062,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:46:47.497834",
      "submission_path": "submission_24hrs/seed1/2025-12-25T08-02-13-GMT_run-group_piml_v1__vinbigdata-chest-xray-abnormalities-detection_unknown_llm_0steps_24hrs_gpu_40cores/vinbigdata-chest-xray-abnormalities-detection_7fcd7473-b5d1-4e09-a179-d8bc28388a9a/submission/submission.csv"
    },
    {
      "competition_id": "stanford-covid-vaccine",
      "score": 0.21274,
      "gold_threshold": 0.34728,
      "silver_threshold": 0.35175,
      "bronze_threshold": 0.3534,
      "median_threshold": 0.363095,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:46:47.829861",
      "submission_path": "submission_24hrs/seed1/2025-12-25T08-06-16-GMT_run-group_piml_v1_High_stanford-covid-vaccine_unknown_llm_0steps_24hrs_gpu_40cores/stanford-covid-vaccine_df1c6652-d0e1-45a1-b773-ff5daab78f09/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.60529,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:46:47.909558",
      "submission_path": "submission_24hrs/seed1/2025-12-25T08-06-58-GMT_run-group_piml_v1_High_rsna-miccai-brain-tumor-radiogenomic-classification_unknown_llm_0steps_24hrs_gpu_40cores/rsna-miccai-brain-tumor-radiogenomic-classification_e1d867b4-d23e-462e-b3c6-746859d9f0d4/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": 0.98128,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:46:55.273161",
      "submission_path": "submission_24hrs/seed1/2025-12-29T07-16-01-GMT_run-group_piml_v1_Low_text-normalization-challenge-russian-language_unknown_llm_0steps_24hrs_gpu_40cores/text-normalization-challenge-russian-language_5e9c88bd-0757-41a2-922a-28b1f4f38792/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.70777,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:46:55.495704",
      "submission_path": "submission_24hrs/seed1/2025-12-29T10-49-58-GMT_run-group_piml_v1_Low_random-acts-of-pizza_unknown_llm_0steps_24hrs_gpu_40cores/random-acts-of-pizza_feeffa74-8642-45b8-b4a9-2833c825524f/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.00091,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:46:55.591571",
      "submission_path": "submission_24hrs/seed1/2025-12-29T13-10-05-GMT_run-group_piml_v1_Low_leaf-classification_unknown_llm_0steps_24hrs_gpu_40cores/leaf-classification_097d6eb7-0fac-4394-b82d-a5507106add9/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": 0.02695,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:47:01.635481",
      "submission_path": "submission_24hrs/seed1/2025-12-29T14-09-39-GMT_run-group_piml_v1_Medium_h-and-m-personalized-fashion-recommendations_unknown_llm_0steps_24hrs_gpu_40cores/h-and-m-personalized-fashion-recommendations_2c1e2547-ef1c-4406-96d9-c73a7966e55d/submission/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": 0.13123,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2026-01-04T15:47:01.774666",
      "submission_path": "submission_24hrs/seed1/2025-12-31T21-21-08-GMT_run-group_piml_v1_Medium_multi-modal-gesture-recognition_unknown_llm_0steps_24hrs_gpu_40cores/multi-modal-gesture-recognition_3fc47f61-fcbf-4a7c-a1ef-a18adb0e4d50/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": 0.72487,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:47:03.310612",
      "submission_path": "submission_24hrs/seed1/2025-12-31T21-21-10-GMT_run-group_piml_v1_Medium_freesound-audio-tagging-2019_unknown_llm_0steps_24hrs_gpu_40cores/freesound-audio-tagging-2019_25b02faf-7280-4c59-b666-64f43f85531d/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.93965,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2026-01-04T15:47:03.408955",
      "submission_path": "submission_24hrs/seed1/2026-01-02T07-55-45-GMT_run-group_piml_v1_Low_siim-isic-melanoma-classification_unknown_llm_0steps_24hrs_gpu_40cores/siim-isic-melanoma-classification_b6e68c10-7caf-4414-b7fb-a12e62390790/submission/submission.csv"
    }
  ]
}