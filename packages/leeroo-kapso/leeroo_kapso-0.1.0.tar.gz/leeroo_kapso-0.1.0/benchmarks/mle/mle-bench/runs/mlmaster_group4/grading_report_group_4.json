{
  "total_runs": 75,
  "total_runs_with_submissions": 73,
  "total_valid_submissions": 73,
  "total_medals": 46,
  "total_gold_medals": 14,
  "total_silver_medals": 23,
  "total_bronze_medals": 9,
  "total_above_median": 49,
  "competition_reports": [
    {
      "competition_id": "3d-object-detection-for-autonomous-vehicles",
      "score": 0.05466,
      "gold_threshold": 0.139,
      "silver_threshold": 0.053,
      "bronze_threshold": 0.046,
      "median_threshold": 0.042,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:46:56.653488",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/3d-object-detection-for-autonomous-vehicles/2a366498-1f16-4457-9f1f-addd3ab682fe/submission/submission.csv"
    },
    {
      "competition_id": "AI4Code",
      "score": 0.71664,
      "gold_threshold": 0.9006,
      "silver_threshold": 0.8598,
      "bronze_threshold": 0.8534,
      "median_threshold": 0.8257,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:14.671495",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/AI4Code/07df314a-682b-4ecf-9ffb-dd548d7cb954/submission/submission.csv"
    },
    {
      "competition_id": "aerial-cactus-identification",
      "score": 1.0,
      "gold_threshold": 1.0,
      "silver_threshold": 1.0,
      "bronze_threshold": 1.0,
      "median_threshold": 0.9991,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:31.884164",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/aerial-cactus-identification/a21d2e78-b2df-4fb1-ac9d-3934cfeebf04/submission/submission.csv"
    },
    {
      "competition_id": "alaska2-image-steganalysis",
      "score": 0.64071,
      "gold_threshold": 0.928,
      "silver_threshold": 0.921,
      "bronze_threshold": 0.915,
      "median_threshold": 0.904,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:14.693762",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/alaska2-image-steganalysis/8a331989-f56b-47e0-b7e3-37df3b06cb5f/submission/submission.csv"
    },
    {
      "competition_id": "aptos2019-blindness-detection",
      "score": 0.92285,
      "gold_threshold": 0.930508,
      "silver_threshold": 0.919654,
      "bronze_threshold": 0.914492,
      "median_threshold": 0.888912,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:31.925172",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/aptos2019-blindness-detection/a2dbcfe5-621f-4451-842a-01e208f87076/submission/submission.csv"
    },
    {
      "competition_id": "billion-word-imputation",
      "score": 9.12801,
      "gold_threshold": 5.37017,
      "silver_threshold": 5.54372,
      "bronze_threshold": 5.55209,
      "median_threshold": 5.55211,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:48:27.207405",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/billion-word-imputation/eb819f10-dd74-444e-893e-83bdd48c0e0d/submission/submission.csv"
    },
    {
      "competition_id": "bms-molecular-translation",
      "score": 59.678,
      "gold_threshold": 0.62,
      "silver_threshold": 1.37,
      "bronze_threshold": 1.99,
      "median_threshold": 5.58,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:47:18.488438",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/bms-molecular-translation/9df25eed-3e0c-4920-a602-7f6a69831b3e/submission/submission.csv"
    },
    {
      "competition_id": "cassava-leaf-disease-classification",
      "score": 0.89985,
      "gold_threshold": 0.9013,
      "silver_threshold": 0.8992,
      "bronze_threshold": 0.8978,
      "median_threshold": 0.8909,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:04.727875",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/cassava-leaf-disease-classification/c6bd5527-4772-4de0-952d-d0cbc11c46f1/submission/submission.csv"
    },
    {
      "competition_id": "cdiscount-image-classification-challenge",
      "score": 0.3508,
      "gold_threshold": 0.77604,
      "silver_threshold": 0.73526,
      "bronze_threshold": 0.70898,
      "median_threshold": 0.44055,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:48:28.429935",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/cdiscount-image-classification-challenge/14b70489-f697-4843-b69d-4ffe0a816033/submission/submission.csv"
    },
    {
      "competition_id": "chaii-hindi-and-tamil-question-answering",
      "score": 0.73884,
      "gold_threshold": 0.76305,
      "silver_threshold": 0.73984,
      "bronze_threshold": 0.73725,
      "median_threshold": 0.72756,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:05.369305",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/chaii-hindi-and-tamil-question-answering/48dd0e26-ce38-4fa4-bd36-985bc8efdcec/submission/submission.csv"
    },
    {
      "competition_id": "champs-scalar-coupling",
      "score": 1.44972,
      "gold_threshold": -2.87509,
      "silver_threshold": -2.03119,
      "bronze_threshold": -1.90122,
      "median_threshold": -0.9529,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:48:18.354913",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/champs-scalar-coupling/b354ceaa-ce98-4f75-9c1d-599194a203e7/submission/submission.csv"
    },
    {
      "competition_id": "denoising-dirty-documents",
      "score": 0.02374,
      "gold_threshold": 0.01794,
      "silver_threshold": 0.02609,
      "bronze_threshold": 0.04517,
      "median_threshold": 0.07325,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:45:47.614620",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/denoising-dirty-documents/9cc1e3d5-430d-4429-afb3-1de2a9426b1d/submission/submission.csv"
    },
    {
      "competition_id": "detecting-insults-in-social-commentary",
      "score": 0.95873,
      "gold_threshold": 0.83321,
      "silver_threshold": 0.82307,
      "bronze_threshold": 0.79111,
      "median_threshold": 0.77842,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:31.915768",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/detecting-insults-in-social-commentary/02788b18-2669-4879-9c19-c575f5a21a9f/submission/submission.csv"
    },
    {
      "competition_id": "dog-breed-identification",
      "score": 0.44656,
      "gold_threshold": 0.0005,
      "silver_threshold": 0.00539,
      "bronze_threshold": 0.04598,
      "median_threshold": 0.47205,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:47:34.152389",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/dog-breed-identification/c3ce7303-c011-474a-8dac-c5afee17d619/submission/submission.csv"
    },
    {
      "competition_id": "dogs-vs-cats-redux-kernels-edition",
      "score": 0.00309,
      "gold_threshold": 0.03882,
      "silver_threshold": 0.05038,
      "bronze_threshold": 0.06127,
      "median_threshold": 0.12216,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:46:59.988445",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/dogs-vs-cats-redux-kernels-edition/7f1f4bb3-4281-4ea4-bf40-d3bd38d88e58/submission/submission.csv"
    },
    {
      "competition_id": "facebook-recruiting-iii-keyword-extraction",
      "score": 0.43537,
      "gold_threshold": 0.79479,
      "silver_threshold": 0.76177,
      "bronze_threshold": 0.71345,
      "median_threshold": 0.60685,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:48:17.539895",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/facebook-recruiting-iii-keyword-extraction/1cf6e2d3-64e4-4ebe-9d1e-48f6a96bc040/submission/submission.csv"
    },
    {
      "competition_id": "freesound-audio-tagging-2019",
      "score": 0.70069,
      "gold_threshold": 0.74399,
      "silver_threshold": 0.7181,
      "bronze_threshold": 0.69233,
      "median_threshold": 0.54819,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:34.189014",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/freesound-audio-tagging-2019/91bf37cc-2a77-4097-b29f-c515c5fa5a38/submission/submission.csv"
    },
    {
      "competition_id": "google-quest-challenge",
      "score": 0.40276,
      "gold_threshold": 0.42278,
      "silver_threshold": 0.39597,
      "bronze_threshold": 0.37496,
      "median_threshold": 0.357205,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:58.525281",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/google-quest-challenge/d745167f-502d-4c75-8787-8ab31d80d3f4/submission/submission.csv"
    },
    {
      "competition_id": "google-research-identify-contrails-reduce-global-warming",
      "score": 0.05305,
      "gold_threshold": 0.71059,
      "silver_threshold": 0.6936,
      "bronze_threshold": 0.67929,
      "median_threshold": 0.63819,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:20.002278",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/google-research-identify-contrails-reduce-global-warming/a0c853e6-01bf-4ec9-a919-7bdf7ffe0016/submission/submission.csv"
    },
    {
      "competition_id": "h-and-m-personalized-fashion-recommendations",
      "score": 0.02845,
      "gold_threshold": 0.03354,
      "silver_threshold": 0.02517,
      "bronze_threshold": 0.02394,
      "median_threshold": 0.02177,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:31.823204",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/h-and-m-personalized-fashion-recommendations/b806dbdb-fdb5-4872-8dec-751615d4724a/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2020-fgvc7",
      "score": 0.30571,
      "gold_threshold": 0.63151,
      "silver_threshold": 0.2805,
      "bronze_threshold": 0.05334,
      "median_threshold": 0.05334,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:08.656850",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/herbarium-2020-fgvc7/b30c1ed4-8e1d-42f0-8d96-8a6c77443212/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2021-fgvc8",
      "score": 0.43034,
      "gold_threshold": 0.54332,
      "silver_threshold": 0.41067,
      "bronze_threshold": 0.13026,
      "median_threshold": 0.05155,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:06.322444",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/herbarium-2021-fgvc8/ebc947ea-09b7-4fe2-a91a-46c9c50d84cd/submission/submission.csv"
    },
    {
      "competition_id": "herbarium-2022-fgvc9",
      "score": 0.69354,
      "gold_threshold": 0.84602,
      "silver_threshold": 0.75373,
      "bronze_threshold": 0.5965,
      "median_threshold": 0.22549,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:00.335860",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/herbarium-2022-fgvc9/1da060c9-d50f-40cc-9ad6-9c47dbf2391c/submission/submission.csv"
    },
    {
      "competition_id": "histopathologic-cancer-detection",
      "score": 0.99397,
      "gold_threshold": 0.9835,
      "silver_threshold": 0.9798,
      "bronze_threshold": 0.9738,
      "median_threshold": 0.9477,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:04.711976",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/histopathologic-cancer-detection/8a67229f-b87c-42ff-a943-2aa574ee68b8/submission/submission.csv"
    },
    {
      "competition_id": "hms-harmful-brain-activity-classification",
      "score": 1.37948,
      "gold_threshold": 0.290807,
      "silver_threshold": 0.353323,
      "bronze_threshold": 0.375383,
      "median_threshold": 0.473828,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:47:34.094314",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/hms-harmful-brain-activity-classification/2d76a920-8cae-4278-a401-2a9e3e3288e1/submission/submission.csv"
    },
    {
      "competition_id": "hotel-id-2021-fgvc8",
      "score": 0.4911,
      "gold_threshold": 0.7205,
      "silver_threshold": 0.39,
      "bronze_threshold": 0.0216,
      "median_threshold": 0.0006,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:33.260630",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/hotel-id-2021-fgvc8/44dd0404-9641-4f2b-abcc-bc5678f2cb01/submission/submission.csv"
    },
    {
      "competition_id": "hubmap-kidney-segmentation",
      "score": 0.94682,
      "gold_threshold": 0.9484,
      "silver_threshold": 0.9455,
      "bronze_threshold": 0.9439,
      "median_threshold": 0.0,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:58.485146",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/hubmap-kidney-segmentation/7059c2bd-ddb4-4092-b9cc-f8b4de4d4c8a/submission/submission.csv"
    },
    {
      "competition_id": "icecube-neutrinos-in-deep-ice",
      "score": 1.57623,
      "gold_threshold": 0.977306,
      "silver_threshold": 1.007885,
      "bronze_threshold": 1.018571,
      "median_threshold": 1.019959,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:48:07.490965",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/icecube-neutrinos-in-deep-ice/44e0fb4d-69e0-4e9c-9b62-d127d069039c/submission/submission.csv"
    },
    {
      "competition_id": "imet-2020-fgvc7",
      "score": null,
      "gold_threshold": 0.696,
      "silver_threshold": 0.649,
      "bronze_threshold": 0.649,
      "median_threshold": 0.627,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:48:28.529618",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/imet-2020-fgvc7/7ec53271-c998-4192-bec2-f27a53aa339c/submission/submission.csv"
    },
    {
      "competition_id": "inaturalist-2019-fgvc6",
      "score": 0.28755,
      "gold_threshold": 0.15955,
      "silver_threshold": 0.26058,
      "bronze_threshold": 0.39028,
      "median_threshold": 0.43478,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:45:31.985240",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/inaturalist-2019-fgvc6/33555beb-ee99-4bcd-80d4-87b4cfc4cf83/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2019-fgvc6",
      "score": 0.38268,
      "gold_threshold": 0.212,
      "silver_threshold": 0.129,
      "bronze_threshold": 0.114,
      "median_threshold": 0.108,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:34.249134",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/iwildcam-2019-fgvc6/c722271d-23b7-4900-9f6b-c63fe1f46317/submission/submission.csv"
    },
    {
      "competition_id": "iwildcam-2020-fgvc7",
      "score": 0.71091,
      "gold_threshold": 0.778,
      "silver_threshold": 0.688,
      "bronze_threshold": 0.594,
      "median_threshold": 0.524,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:33.416948",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/iwildcam-2020-fgvc7/9fbfc52e-48a2-4ac6-9032-b9f02d0e7a9f/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-toxic-comment-classification-challenge",
      "score": 0.98688,
      "gold_threshold": 0.9874,
      "silver_threshold": 0.98668,
      "bronze_threshold": 0.98639,
      "median_threshold": 0.98079,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:05.179957",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/jigsaw-toxic-comment-classification-challenge/d74fa5d7-0f08-48b4-8c4f-60b5480ded20/submission/submission.csv"
    },
    {
      "competition_id": "jigsaw-unintended-bias-in-toxicity-classification",
      "score": 0.78336,
      "gold_threshold": 0.94608,
      "silver_threshold": 0.94304,
      "bronze_threshold": 0.94088,
      "median_threshold": 0.93417,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:48:20.571406",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/jigsaw-unintended-bias-in-toxicity-classification/10e282a7-7864-4095-a5b0-a8645719d28d/submission/submission.csv"
    },
    {
      "competition_id": "kuzushiji-recognition",
      "score": 0.7708,
      "gold_threshold": 0.903,
      "silver_threshold": 0.8,
      "bronze_threshold": 0.658,
      "median_threshold": 0.5985,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:11.520231",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/kuzushiji-recognition/82b30620-4526-49e0-89ac-e1dec2f137e9/submission/submission.csv"
    },
    {
      "competition_id": "leaf-classification",
      "score": 0.01002,
      "gold_threshold": 0.0,
      "silver_threshold": 0.00791,
      "bronze_threshold": 0.01526,
      "median_threshold": 0.108345,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:45:27.898779",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/leaf-classification/9ba8dba1-7613-4234-8bab-bd8d002a9015/submission/submission.csv"
    },
    {
      "competition_id": "learning-agency-lab-automated-essay-scoring-2",
      "score": 0.83592,
      "gold_threshold": 0.83583,
      "silver_threshold": 0.83518,
      "bronze_threshold": 0.83471,
      "median_threshold": 0.828265,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:11.592569",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/learning-agency-lab-automated-essay-scoring-2/2194f149-5f30-48d1-a0fd-a6e6cd39d4fb/submission/submission.csv"
    },
    {
      "competition_id": "lmsys-chatbot-arena",
      "score": 1.00191,
      "gold_threshold": 0.98392,
      "silver_threshold": 0.99277,
      "bronze_threshold": 1.00283,
      "median_threshold": 1.05212,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:47:05.331660",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/lmsys-chatbot-arena/154e4222-a293-423c-b121-96db1f7e5adc/submission/submission.csv"
    },
    {
      "competition_id": "mlsp-2013-birds",
      "score": 0.9204,
      "gold_threshold": 0.93527,
      "silver_threshold": 0.90038,
      "bronze_threshold": 0.87372,
      "median_threshold": 0.86572,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:33.212269",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/mlsp-2013-birds/16af1ad6-8484-4ef5-a024-5f269484ecf5/submission/submission.csv"
    },
    {
      "competition_id": "multi-modal-gesture-recognition",
      "score": 0.14837,
      "gold_threshold": 0.13304,
      "silver_threshold": 0.1769,
      "bronze_threshold": 0.24926,
      "median_threshold": 0.322,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:47:11.549037",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/multi-modal-gesture-recognition/3bf2ed30-9d47-49f2-bfa7-505949d2c111/submission/submission.csv"
    },
    {
      "competition_id": "new-york-city-taxi-fare-prediction",
      "score": 5.07885,
      "gold_threshold": 2.83377,
      "silver_threshold": 2.88191,
      "bronze_threshold": 2.92371,
      "median_threshold": 3.59741,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:48:25.809114",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/new-york-city-taxi-fare-prediction/ed361684-32db-40dc-9c7a-165371e8108f/submission/submission.csv"
    },
    {
      "competition_id": "nfl-player-contact-detection",
      "score": 0.70671,
      "gold_threshold": 0.78167,
      "silver_threshold": 0.72203,
      "bronze_threshold": 0.69652,
      "median_threshold": 0.69139,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:10.064387",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/nfl-player-contact-detection/da7f81ed-64d5-46dd-8db0-62f65f8ae841/submission/submission.csv"
    },
    {
      "competition_id": "nomad2018-predict-transparent-conductors",
      "score": 0.06193,
      "gold_threshold": 0.05589,
      "silver_threshold": 0.06229,
      "bronze_threshold": 0.06582,
      "median_threshold": 0.06988,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:47:00.347601",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/nomad2018-predict-transparent-conductors/5dc7a80e-5e5c-4119-88dd-16308fddce39/submission/submission.csv"
    },
    {
      "competition_id": "osic-pulmonary-fibrosis-progression",
      "score": -7.20141,
      "gold_threshold": -6.8412,
      "silver_threshold": -6.8533,
      "bronze_threshold": -6.8683,
      "median_threshold": -6.8993,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:18.615379",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/osic-pulmonary-fibrosis-progression/84d8ec50-0c99-465e-b356-74c00dea367a/submission/submission.csv"
    },
    {
      "competition_id": "petfinder-pawpularity-score",
      "score": 17.04037,
      "gold_threshold": 16.95041,
      "silver_threshold": 17.06636,
      "bronze_threshold": 17.0971,
      "median_threshold": 17.702984999999998,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:47:04.742019",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/petfinder-pawpularity-score/8440f1ee-b73f-4ef1-89d5-25c7c09ab011/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2020-fgvc7",
      "score": 0.99518,
      "gold_threshold": 0.97836,
      "silver_threshold": 0.97465,
      "bronze_threshold": 0.97361,
      "median_threshold": 0.94852,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:27.879372",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/plant-pathology-2020-fgvc7/5cb04b44-2dee-42d0-92b6-fc6f54060b2e/submission/submission.csv"
    },
    {
      "competition_id": "plant-pathology-2021-fgvc8",
      "score": 0.90658,
      "gold_threshold": 0.8612,
      "silver_threshold": 0.85305,
      "bronze_threshold": 0.83508,
      "median_threshold": 0.754445,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:33.020105",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/plant-pathology-2021-fgvc8/ddd16743-f671-4ef4-be7d-58c83f2e1550/submission/submission.csv"
    },
    {
      "competition_id": "predict-volcanic-eruptions-ingv-oe",
      "score": 2449412.0,
      "gold_threshold": 3971366.0,
      "silver_threshold": 4808057.0,
      "bronze_threshold": 4999330.0,
      "median_threshold": 6300677.0,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:45:47.777744",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/predict-volcanic-eruptions-ingv-oe/033f8d81-9b14-449d-8c28-9a2c74b6e5ac/submission/submission.csv"
    },
    {
      "competition_id": "random-acts-of-pizza",
      "score": 0.80324,
      "gold_threshold": 0.97908,
      "silver_threshold": 0.76482,
      "bronze_threshold": 0.6921,
      "median_threshold": 0.5995950000000001,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:32.933274",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/random-acts-of-pizza/2657d651-fd33-45db-8fbb-511615c6f857/submission/submission.csv"
    },
    {
      "competition_id": "ranzcr-clip-catheter-line-classification",
      "score": 0.90728,
      "gold_threshold": 0.97357,
      "silver_threshold": 0.97152,
      "bronze_threshold": 0.9709,
      "median_threshold": 0.9675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:48:28.491343",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/ranzcr-clip-catheter-line-classification/b0e73275-9443-47c8-b3fd-e05e8b3a4ea2/submission/submission.csv"
    },
    {
      "competition_id": "rsna-2022-cervical-spine-fracture-detection",
      "score": 0.5513,
      "gold_threshold": 0.2767,
      "silver_threshold": 0.49,
      "bronze_threshold": 0.5212,
      "median_threshold": 0.5223,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:47:11.736855",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/rsna-2022-cervical-spine-fracture-detection/0024f897-085e-498f-ad89-15a145b5d5aa/submission/submission.csv"
    },
    {
      "competition_id": "rsna-breast-cancer-detection",
      "score": 0.04646,
      "gold_threshold": 0.49,
      "silver_threshold": 0.43,
      "bronze_threshold": 0.41,
      "median_threshold": 0.28,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:12.509057",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/rsna-breast-cancer-detection/f5a6690e-fe2d-4984-834b-5f35b25f6f10/submission/submission.csv"
    },
    {
      "competition_id": "rsna-miccai-brain-tumor-radiogenomic-classification",
      "score": 0.64824,
      "gold_threshold": 0.60096,
      "silver_threshold": 0.5815,
      "bronze_threshold": 0.57449,
      "median_threshold": 0.52553,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:31.893444",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/rsna-miccai-brain-tumor-radiogenomic-classification/b4b82dc2-da3b-4d56-90e3-efd26264a26f/submission/submission.csv"
    },
    {
      "competition_id": "seti-breakthrough-listen",
      "score": 0.8513,
      "gold_threshold": 0.79806,
      "silver_threshold": 0.78095,
      "bronze_threshold": 0.77439,
      "median_threshold": 0.75889,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:32.952231",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/seti-breakthrough-listen/c4299417-d8e8-4075-9fe1-ec3c23c06933/submission/submission.csv"
    },
    {
      "competition_id": "siim-covid19-detection",
      "score": 0.38508,
      "gold_threshold": 0.623,
      "silver_threshold": 0.609,
      "bronze_threshold": 0.601,
      "median_threshold": 0.586,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:11.771492",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/siim-covid19-detection/3aa26f10-eb96-4323-8550-b0961515bf88/submission/submission.csv"
    },
    {
      "competition_id": "siim-isic-melanoma-classification",
      "score": 0.85964,
      "gold_threshold": 0.9455,
      "silver_threshold": 0.9401,
      "bronze_threshold": 0.937,
      "median_threshold": 0.9128,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:48:27.243402",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/siim-isic-melanoma-classification/65de0fd2-d110-46a9-976d-5db234d46a33/submission/submission.csv"
    },
    {
      "competition_id": "smartphone-decimeter-2022",
      "score": 7.21826,
      "gold_threshold": 1.768,
      "silver_threshold": 2.119,
      "bronze_threshold": 3.068,
      "median_threshold": 3.3280000000000003,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:48:07.667837",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/smartphone-decimeter-2022/87280185-bd7c-4ae0-b818-71454479e8a9/submission/submission.csv"
    },
    {
      "competition_id": "spooky-author-identification",
      "score": 0.22934,
      "gold_threshold": 0.16506,
      "silver_threshold": 0.26996,
      "bronze_threshold": 0.29381,
      "median_threshold": 0.418785,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:45:33.277225",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/spooky-author-identification/850682b7-bc9d-488d-a2fb-10405402fffc/submission/submission.csv"
    },
    {
      "competition_id": "stanford-covid-vaccine",
      "score": 0.25125,
      "gold_threshold": 0.34728,
      "silver_threshold": 0.35175,
      "bronze_threshold": 0.3534,
      "median_threshold": 0.363095,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:45:33.122132",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/stanford-covid-vaccine/571cc5de-cf52-48f8-ad91-3ee211d8b253/submission/submission.csv"
    },
    {
      "competition_id": "statoil-iceberg-classifier-challenge",
      "score": 0.20136,
      "gold_threshold": 0.11374,
      "silver_threshold": 0.13753,
      "bronze_threshold": 0.14552,
      "median_threshold": 0.20371,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:48:28.503160",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/statoil-iceberg-classifier-challenge/237d1032-6d57-4bcc-a497-d215926aa85a/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-dec-2021",
      "score": 0.96326,
      "gold_threshold": 0.9566,
      "silver_threshold": 0.95658,
      "bronze_threshold": 0.95658,
      "median_threshold": 0.95342,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:32.921710",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tabular-playground-series-dec-2021/dd7cecab-3d6d-4a24-b3dd-fa575a2325a9/submission/submission.csv"
    },
    {
      "competition_id": "tabular-playground-series-may-2022",
      "score": 0.99472,
      "gold_threshold": 0.99823,
      "silver_threshold": 0.99822,
      "bronze_threshold": 0.99818,
      "median_threshold": 0.972675,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:48:19.220383",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tabular-playground-series-may-2022/54c91242-cbfa-4ded-ac36-d989cfe1ca79/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow-speech-recognition-challenge",
      "score": 0.353,
      "gold_threshold": 0.90485,
      "silver_threshold": 0.89627,
      "bronze_threshold": 0.88793,
      "median_threshold": 0.77722,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:48:28.525053",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tensorflow-speech-recognition-challenge/5a867ebd-7134-4b2c-b5de-1cf3aa89e3ce/submission/submission.csv"
    },
    {
      "competition_id": "tensorflow2-question-answering",
      "score": null,
      "gold_threshold": 0.68578,
      "silver_threshold": 0.62872,
      "bronze_threshold": 0.61913,
      "median_threshold": 0.59639,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": false,
      "valid_submission": false,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:48:28.535668",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tensorflow2-question-answering/2cd1d57b-1d8d-48b1-9f8a-7fe15f6d3ea3/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-english-language",
      "score": 0.99281,
      "gold_threshold": 0.99724,
      "silver_threshold": 0.99135,
      "bronze_threshold": 0.99038,
      "median_threshold": 0.99037,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:46:59.932958",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/text-normalization-challenge-english-language/4fd67f3d-e8fb-4b62-bd61-14e3277b7e2b/submission/submission.csv"
    },
    {
      "competition_id": "text-normalization-challenge-russian-language",
      "score": 0.98125,
      "gold_threshold": 0.99012,
      "silver_threshold": 0.98232,
      "bronze_threshold": 0.97592,
      "median_threshold": 0.97591,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": true,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:04.494483",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/text-normalization-challenge-russian-language/f42bdcaa-aff2-40ce-860c-378910ff3f0a/submission/submission.csv"
    },
    {
      "competition_id": "tgs-salt-identification-challenge",
      "score": 0.5221,
      "gold_threshold": 0.89097,
      "silver_threshold": 0.87163,
      "bronze_threshold": 0.85918,
      "median_threshold": 0.81665,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:12.494831",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tgs-salt-identification-challenge/139d7b54-fd91-418d-9d3e-7ff058a24309/submission/submission.csv"
    },
    {
      "competition_id": "the-icml-2013-whale-challenge-right-whale-redux",
      "score": 0.98767,
      "gold_threshold": 0.98961,
      "silver_threshold": 0.95017,
      "bronze_threshold": 0.90521,
      "median_threshold": 0.86521,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:33.184373",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/the-icml-2013-whale-challenge-right-whale-redux/1103ffbf-2b12-4bef-ad6f-9140b345e038/submission/submission.csv"
    },
    {
      "competition_id": "tweet-sentiment-extraction",
      "score": 0.7219,
      "gold_threshold": 0.72689,
      "silver_threshold": 0.71752,
      "bronze_threshold": 0.71705,
      "median_threshold": 0.71378,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:05.357916",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/tweet-sentiment-extraction/39423acd-f9b6-47ae-8131-c84f51d4cb12/submission/submission.csv"
    },
    {
      "competition_id": "us-patent-phrase-to-phrase-matching",
      "score": 0.86811,
      "gold_threshold": 0.87,
      "silver_threshold": 0.863,
      "bronze_threshold": 0.8616,
      "median_threshold": 0.851,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:45:33.202716",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/us-patent-phrase-to-phrase-matching/4d184606-528c-411e-b0c8-9a487736a01d/submission/submission.csv"
    },
    {
      "competition_id": "uw-madison-gi-tract-image-segmentation",
      "score": 0.46208,
      "gold_threshold": 0.87917,
      "silver_threshold": 0.87139,
      "bronze_threshold": 0.86699,
      "median_threshold": 0.85499,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:34.025288",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/uw-madison-gi-tract-image-segmentation/7c0763e8-1803-4c0f-a329-f651f97fbeea/submission/submission.csv"
    },
    {
      "competition_id": "ventilator-pressure-prediction",
      "score": 0.54686,
      "gold_threshold": 0.1119,
      "silver_threshold": 0.1338,
      "bronze_threshold": 0.1364,
      "median_threshold": 0.1638,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": true,
      "created_at": "2025-12-14T17:48:28.089299",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/ventilator-pressure-prediction/ebcd7764-8047-42d9-84e8-bb900a2d5373/submission/submission.csv"
    },
    {
      "competition_id": "vesuvius-challenge-ink-detection",
      "score": 0.30099,
      "gold_threshold": 0.779927,
      "silver_threshold": 0.725248,
      "bronze_threshold": 0.660027,
      "median_threshold": 0.418442,
      "any_medal": false,
      "gold_medal": false,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": false,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:48:25.764005",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/vesuvius-challenge-ink-detection/71c1e2a7-d933-4e32-a285-cd48cf9b49d9/submission/submission.csv"
    },
    {
      "competition_id": "vinbigdata-chest-xray-abnormalities-detection",
      "score": 0.34325,
      "gold_threshold": 0.289,
      "silver_threshold": 0.257,
      "bronze_threshold": 0.243,
      "median_threshold": 0.223,
      "any_medal": true,
      "gold_medal": true,
      "silver_medal": false,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:08.225308",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/vinbigdata-chest-xray-abnormalities-detection/40a80eed-ac4a-4b22-889a-bf82e81e22c2/submission/submission.csv"
    },
    {
      "competition_id": "whale-categorization-playground",
      "score": 0.47755,
      "gold_threshold": 0.56236,
      "silver_threshold": 0.44852,
      "bronze_threshold": 0.40515,
      "median_threshold": 0.32788,
      "any_medal": true,
      "gold_medal": false,
      "silver_medal": true,
      "bronze_medal": false,
      "above_median": true,
      "submission_exists": true,
      "valid_submission": true,
      "is_lower_better": false,
      "created_at": "2025-12-14T17:47:08.675894",
      "submission_path": "/data/xinyu/mlmaster-sandbox/runs/whale-categorization-playground/8a625eae-d7af-4370-8c71-a3698735fb3a/submission/submission.csv"
    }
  ]
}