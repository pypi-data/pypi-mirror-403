# SGR Agent Core - Configuration Template
# Copy this file to config.yaml and fill in your data

# LLM Configuration
llm:
  api_key: "your-openai-api-key-here"  # Your OpenAI API key
  base_url: "https://api.openai.com/v1"  # API base URL
  model: "gpt-4o-mini"  # Model name
  max_tokens: 8000  # Max output tokens
  temperature: 0.4  # Temperature (0.0-1.0)
  # proxy: "socks5://127.0.0.1:1081"  # Optional proxy (socks5:// or http://)

# Search Configuration (Tavily)
search:
  tavily_api_key: "your-tavily-api-key-here"  # Tavily API key (get at tavily.com)
  tavily_api_base_url: "https://api.tavily.com"  # Tavily API URL
  max_searches: 4  # Max search operations
  max_results: 10  # Max  results in search query
  content_limit: 1500  # Content char limit per source

# Execution Settings
execution:
  max_clarifications: 3  # Max clarification requests
  max_iterations: 10  # Max agent iterations
  mcp_context_limit: 15000  # Max context length from MCP server response
  logs_dir: "logs"  # Directory for saving agent execution logs
  reports_dir: "reports"  # Directory for saving agent reports

# Prompts Configuration
# prompts:
#   # Option 1: Use file paths (absolute or relative to project root)
#   system_prompt_file: "path/to/your/system_prompt.txt"
#   initial_user_request_file: "path/to/your/initial_user_request.txt"
#   clarification_response_file: "path/to/your/clarification_response.txt"

#  # Option 2: Provide prompts directly as strings
#   system_prompt_str: "Your custom system prompt here..."
#   initial_user_request_str: "Your custom initial request template..."
#   clarification_response_str: "Your custom clarification template..."

  # Note: If both file and string are provided, string takes precedence

# MCP (Model Context Protocol) Configuration
mcp:
  mcpServers:
    deepwiki:
      url: "https://mcp.deepwiki.com/mcp"

    # Add more MCP servers here:
    # your_server:
    #   url: "https://your-mcp-server.com/mcp"
    #   headers:
    #     Authorization: "Bearer your-token"


# Note: The 'agents' field is optional and can be loaded from either:
# - This config.yaml file
# - Any separate file by GlobalConfig.definitions_from_yaml method
# See examples in agents.yaml.example for agent configuration options

tools:
  # Core tools (base_class defaults to sgr_agent_core.tools.*)
  my_custom_tool:
    base_class: path.to.my.tools.CustomTool
  my_other_tool:
    base_class: "name_of_tool_class_in_registry"

agents:
  custom_research_agent:
    base_class: "sgr_agent_core.agents.sgr_agent.SGRAgent"
    # Optional: Override LLM settings for this agent
    llm:
      model: "gpt-4o"
      temperature: 0.3
      max_tokens: 16000
      # api_key: "your-custom-api-key"  # Optional: use different API key
      # base_url: "https://api.openai.com/v1"  # Optional: use different endpoint
      # proxy: "http://127.0.0.1:8080"  # Optional: use proxy

    # Optional: Override search settings
    search:
      max_results: 15
      max_pages: 8
      content_limit: 2000

    # Optional: Execution configuration
    execution:
      max_steps: 8
      max_iterations: 15
      max_clarifications: 5
      max_searches: 6
      mcp_context_limit: 20000
      logs_dir: "logs/custom_agent"
      reports_dir: "reports/custom_agent"

    # Optional: MCP configuration
    mcp:
      mcpServers:
        deepwiki:
          url: "https://mcp.deepwiki.com/mcp"

    # Tools this agent can use (must be registered in tool registry)
    tools:
      - "WebSearchTool"
      - "ExtractPageContentTool"
      - "CreateReportTool"
      - "ClarificationTool"
      - "GeneratePlanTool"
      - "AdaptPlanTool"
      - "FinalAnswerTool"
      - "my_custom_tool"
      - "my_other_tool"
