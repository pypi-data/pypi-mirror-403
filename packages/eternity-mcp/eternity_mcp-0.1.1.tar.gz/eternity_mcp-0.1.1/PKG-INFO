Metadata-Version: 2.4
Name: eternity-mcp
Version: 0.1.1
Summary: Your eternal second brain, running locally. Private, fast, and built for AI agents that actually remember.
License: MIT License
         
         Copyright (c) 2026 danttis
         
         Permission is hereby granted, free of charge, to any person obtaining a copy
         of this software and associated documentation files (the "Software"), to deal
         in the Software without restriction, including without limitation the rights
         to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
         copies of the Software, and to permit persons to whom the Software is
         furnished to do so, subject to the following conditions:
         
         The above copyright notice and this permission notice shall be included in all
         copies or substantial portions of the Software.
         
         THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
         IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
         FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
         AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
         LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
         OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
         SOFTWARE.
License-File: LICENSE
Author: Junior Dantas
Author-email: juniordante01@gmail.com
Requires-Python: >=3.12
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Dist: chromadb
Requires-Dist: fastapi
Requires-Dist: jinja2
Requires-Dist: pypdf
Requires-Dist: python-multipart
Requires-Dist: requests
Requires-Dist: sentence-transformers
Requires-Dist: uvicorn[standard]
Description-Content-Type: text/markdown

# ğŸ§  Eternity MCP

**Your Eternal Second Brain, Running Locally.**

`Eternity  MCP` is a lightweight, privacy-focused memory server designed to provide long-term memory for LLMs and AI agents using the Model Context Protocol (MCP).

It combines structured storage (SQLite) with semantic vector search (ChromaDB), enabling agents to persist and retrieve text, PDF documents, and chat histories across sessions using natural language queries.

Built to run fully locally, Eternity integrates seamlessly with MCP-compatible clients, LangChain, LangGraph, and custom LLM pipelines, giving agents a durable and private memory layer.

---

## ğŸš€ Why Eternity?

Building agents that "remember" is hard. Most solutions rely on expensive cloud vector databases or complex setups. **Eternity** solves this by being:

*   **ğŸ”’ Private & Local**: Runs entirely on your machine. No data leaves your network.
*   **âš¡ fast & Lightweight**: Built on FastAPI and ChromaDB.
*   **ğŸ”Œ Agent-Ready**: Perfect for LangGraph, LangChain, or direct LLM integration.
*   **ğŸ“„ Multi-Modal**: Ingests raw text and PDF documents automatically.
*   **ğŸ” Semantic Search**: Finds matches by *meaning*, not just keywords.

![interface.png](https://raw.githubusercontent.com/danttis/eternity/refs/heads/main/interface.png)


## ğŸ“¦ Installation

You can install Eternity directly from PyPI (coming soon) or from source:

```bash
# From source
git clone https://github.com/danttis/eternity-mcp.git
cd eternity
```

## ğŸ› ï¸ Usage

### 1. Start the Server
Run the server in a terminal. It will host the API and the Memory UI.

```bash
eternity
```
*Server runs at `http://localhost:8000`*

### 2. Client Usage (Python)

You can interact with Eternity using simple HTTP requests.

```python
import requests

ETERNITY_URL = "http://localhost:8000"

# ğŸ’¾ Store a memory
requests.post("{ETERNITY_URL}/add", data={
    "content": "The project deadline is next Friday.",
    "tags": "work,deadline"
})

# ğŸ” Search memory
response = requests.get("{ETERNITY_URL}/search", params={"q": "When is the deadline?"})
print(response.json())
```

### 3. Integration with LangGraph/AI Agents

Eternity shines when connected to an LLM. Here is a simple pattern for an agent with long-term memory:

1.  **Recall**: Before answering, search Eternity for context.
2.  **Generate**: Feed the retrieved context to the LLM.
3.  **Memorize**: Save the useful parts of the interaction back to Eternity.

*(See [`langgraph_agent.py`](langgraph_agent.py) in the repo for a full, working example using Ollama/Groq).*

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
| :--- | :--- | :--- |
| `GET` | `/` | Web UI to view recent memories. |
| `POST` | `/add` | Add text or file (PDF). Params: `content`, `tags`, `file`. |
| `GET` | `/search` | Semantic search. Params: `q` (query text). |

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


## ğŸŒŸ Inspiration

This project was inspired by [Supermemory](https://github.com/supermemoryai/supermemory). We admire their vision for a second brain and their open-source spirit.

---
*Created by [Junior Dantas](https://github.com/danttis) with a little help from AI :)*








