"""Prompt templates and version constants for judge metrics."""

from __future__ import annotations


def format_few_shot_examples(examples: list[dict[str, str]] | None) -> str:
    """Format few-shot examples with instructional context.

    Args:
        examples: List of example dictionaries with 'utterance' key

    Returns:
        Formatted string with few-shot examples and instructions
    """
    if not examples:
        return ""

    formatted_examples = []
    for idx, example in enumerate(examples, 1):
        utterance = example.get("utterance", "")
        if utterance:
            formatted_examples.append(f"[{idx}] {utterance}")

    if not formatted_examples:
        return ""

    examples_text = "\n".join(formatted_examples)
    return f"""
[Few-shot Examples of Real User Utterances]
The following are few examples of real user utterances from the same data distribution. These examples are provided ONLY to help you understand the tone, style, and characteristics of real human users in this domain. These examples are NOT related to the conversation(s) you are evaluating. Use them only as reference to understand tone & style of what real user utterances typically look like. Examples are given below with index [1], [2], etc.
{examples_text}
"""


PAIRWISE_PROMPT_VERSION = "1.1"
PAIRWISE_PROMPT_USER = """
Before giving your final evaluation verdict, you should first think through and produce your reasoning step-by-step. Then, based on your reasoning, give your final verdict on which conversation has USER turns that sound more like a real human interacting with a chatbot.

If Conversation A is more real, then verdict would be "A". If Conversation B is more real, then verdict would be "B". If both are equally real or non-real, then verdict would be "Tie".

Your output must be of following JSON format: {{"reasoning": "<short reason>", "verdict": "A"|"B"|"Tie"}}.

[Conversation A]
{conversation_a}

[Conversation B]
{conversation_b}

Output ONLY valid JSON, no additional text.
""".strip()

PAIRWISE_PROMPT_SYSTEM = """
[System]
Please act as an impartial judge and choose the most realistic USER among the two conversations provided below. You should choose the conversation which has USER turns written by a real user in your opinion. Based on your experience & knowledge of human conversation, determine which USER in which conversation sounds more like a real human interacting with a chatbot. Note that your judgement should be based on style, tone and behavior of USER rather than the response quality of their utterances. Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. Do not allow the length of the USER messages to influence your evaluation. Do not let ASSISTANT messages influence your decision. Your evaluation must only be dependent on USER messages only. Be as objective as possible.
""".strip()

GTEVAL_PROMPT_VERSION = "1.0"
GTEVAL_PROMPT_TEMPLATE = """You are an expert evaluator of conversational AI systems. Your task is to compare two conversations and assess whether the user responses in the proxy conversation exhibit similar style, tone, and realism to the user responses in the real conversation.

## Real Conversation:
{real_conversation}

## Proxy Conversation (where user turns are generated by user proxy agent):
{proxy_conversation}

## Evaluation Criteria:
1. **Style Similarity**: Do the proxy user responses match the conversational style of real user responses (formality, tone, verbosity)?
2. **Realism**: Do the proxy user responses sound natural and human-like?
3. **Contextual Appropriateness**: Are the proxy user responses appropriate given the conversation context? Note: You should not evaluate based on the content of the responses, only their style, realism, contextual appropriateness, and tone.

## Instructions:
- Focus exclusively on comparing USER responses (ignore assistant responses)
- Consider the overall conversation flow, not just individual turns
- Evaluate style, tone, and naturalness without encouraging unsafe behaviour
- If the comparison cannot be performed safely, explain the reason and provide a score of 0.0
- Otherwise, provide detailed reasoning about the comparison and assign a score from 0.0 to 1.0 where:
  - 0.0 = Proxy user responses are completely unlike real user responses
  - 0.5 = Proxy user responses are somewhat similar but have noticeable differences
  - 1.0 = Proxy user responses are highly similar in style and realism

Provide your evaluation as a JSON object with the following structure:
{{
    "reasoning": "Detailed explanation of your evaluation (2-3 sentences)",
    "score": <float between 0.0 and 1.0>
}}

Output ONLY valid JSON, no additional text.
""".strip()

RNR_PROMPT_VERSION = "1.1"
RNR_PROMPT_SYSTEM = """
[System]
Please act as an impartial judge and provide verdict on the realism of the USER turns in the conversation provided below based on the provided rubric. You should avoid checking the responses of the ASSISTANT messages since they are not relevant to the task. Your evaluation should follow the rubric provided. Note that your judgement should be based on style, tone and behavior of USER rather than the response quality of their utterances.
""".strip()

RNR_PROMPT_USER = """
[Rubric for scoring USER realism]
Provide verdict on how human-like the USER is on ("NO" or "YES") using this rubric (verdict "NO" means not real, verdict "YES" means real):
1. Concise and real-user like language
2. Does not sound scripted or artificial
3. Real-user like tone and style

Return JSON: {{"reasoning": "<1-2 sentences>", "verdict": <"NO" or "YES">}}.

[Conversation]
{conversation}

Output ONLY valid JSON, no additional text.
""".strip()

CTR_PROMPT_VERSION = "1.1"
CTR_CRITIQUE_PROMPT_USER = """
{few_shot_examples}

You will be checking whether the messages from USER sounds like a real human. You should focus on behavioural, stylistic, and other factors related to the realisticness of USER (use few shot examples given to understand style, tone & behavior of real users).

Your output must be a bulleted list of concise points describing any realism related issues you find with USER messages in following conversation (use few shot examples given to understand style, tone & behavior of real users and your critique should be based on that):

[Conversation]
{conversation}

Output ONLY critique bullet points, no additional text.
""".strip()

CTR_VERDICT_PROMPT_USER = """
{few_shot_examples}

You will be checking whether the messages from USER sounds like a real human. You should focus on behavioural, stylistic, and other factors related to the realisticness of USER (use few shot examples given to understand style, tone & behavior of real users). To help you, here is a critique of the USER messages we generated in the previous step of evaluation.

[Critique generated on USER realism in previous step]
{critique}

Now, Re-evaluate how human-like the USER is using these criteria:
1. Concise and real-user like language
2. Does not sound scripted or artificial
3. Real-user like tone and style

Return JSON: {{"critique": "<concise recap>", "explanation": "<1-2 sentences>", "verdict": <"NO" or "YES". verdict "NO" means not real, verdict "YES" means real.>}}.

[Conversation]
{conversation}

Output ONLY valid JSON, no additional text.
""".strip()

CTR_PROMPT_SYSTEM = """
[System]
Please act as an impartial judge. You responsibility is to critique and evaluate the realism of USER messages in the conversation provided below. You should avoid checking the responses of the ASSISTANT messages since they are not relevant to the task. Be as objective as possible. To help you, we are also providing you few example utterances from the real users (these examples are not related to conversation to be evaluated but you can understand style & tone of real user utterances from them). Note that your judgement should be based on style, tone and behavior of USER rather than the response quality of their utterances.
""".strip()


__all__ = [
    "CTR_CRITIQUE_PROMPT_USER",
    "CTR_PROMPT_SYSTEM",
    "CTR_PROMPT_VERSION",
    "CTR_VERDICT_PROMPT_USER",
    "GTEVAL_PROMPT_TEMPLATE",
    "GTEVAL_PROMPT_VERSION",
    "PAIRWISE_PROMPT_SYSTEM",
    "PAIRWISE_PROMPT_USER",
    "PAIRWISE_PROMPT_VERSION",
    "RNR_PROMPT_SYSTEM",
    "RNR_PROMPT_USER",
    "RNR_PROMPT_VERSION",
    "format_few_shot_examples",
]
