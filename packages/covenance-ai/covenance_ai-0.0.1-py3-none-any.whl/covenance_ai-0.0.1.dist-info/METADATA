Metadata-Version: 2.4
Name: covenance-ai
Version: 0.0.1
Summary: Online LLM clients for OpenAI, Google Gemini, Mistral, Anthropic Claude, and OpenRouter (Covenance reservation)
Author: Ilya Kamen
License: MIT
Keywords: anthropic,gemini,llm,mistral,openai,openrouter
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Utilities
Requires-Python: >=3.10
Requires-Dist: anthropic
Requires-Dist: google-genai
Requires-Dist: mistralai
Requires-Dist: openai
Requires-Dist: pydantic
Requires-Dist: python-dotenv
Provides-Extra: dev
Requires-Dist: build; extra == 'dev'
Requires-Dist: pre-commit; extra == 'dev'
Requires-Dist: pytest; extra == 'dev'
Requires-Dist: pytest-cov; extra == 'dev'
Requires-Dist: ruff; extra == 'dev'
Requires-Dist: twine; extra == 'dev'
Description-Content-Type: text/markdown

# solidflow

Unified, structured LLM calls for OpenAI, Gemini, Mistral, Anthropic, and OpenRouter.

## API keys
Set environment variables:
- OPENAI_API_KEY
- GEMINI_API_KEY (or GOOGLE_API_KEY)
- MISTRAL_API_KEY
- ANTHROPIC_API_KEY
- OPENROUTER_API_KEY
If a `.env` file is present in the working directory, it is loaded automatically
without overriding existing environment variables.

## Call logging
- LLM call timing records are always captured; access in-process via `solidflow.get_llm_call_records()`.
- Persist records by setting `SOLIDFLOW_LLM_CALL_RECORDS_DIR` or calling `solidflow.set_llm_call_records_dir(...)`
  (records are appended to `llm_call_records.jsonl` in that folder).
- To visualize, run `python scripts/export_llm_calls.py` then open `scripts/llm_calls.html` in a browser.
