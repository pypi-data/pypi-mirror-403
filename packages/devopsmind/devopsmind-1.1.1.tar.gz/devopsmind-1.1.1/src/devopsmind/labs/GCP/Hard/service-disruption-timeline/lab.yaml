id: service-disruption-timeline
title: Reconstruct a Service Disruption Timeline
stack: gcp
domain: reliability
difficulty: Hard
xp: 150

goal: >
  Reconstruct and explain how a localized GCP infrastructure failure
  propagated into a user-visible service disruption using
  architectural and operational evidence.

skills:
  - outage-timeline-analysis
  - failure-propagation
  - gcp-reliability-reasoning

validator: validator.py

hint:
  - Focus on the order of events and explain how
    partial infrastructure failure escalated into user impact.

mentor:
  why: Understanding failure propagation is critical for resilient systems.
  intent: Teach evidence-based outage reconstruction.
  guidance:
    before: Separate the initial failure from downstream impact.
    after: Explain why the disruption escalated.
  tags:
    - gcp
    - outage
    - reliability

solution:
  overview: >
    Hard-level outage analysis focuses on reconstructing events
    using evidence rather than proposing fixes.
    Engineers must correlate timelines, infrastructure behavior,
    and user impact to explain how localized failures propagate.

  approach:
    - Identify the first infrastructure component that failed
    - Correlate timeline events with observed system behavior
    - Trace how traffic rerouting affected remaining components
    - Explain how partial capacity loss resulted in user-visible impact

  professional_considerations:
    - Separate initial failure from downstream effects
    - Avoid speculative causes not supported by evidence
    - Focus on causality, not remediation
    - Ensure explanations align with the recorded timeline

execution:
  runtime: docker
  requires_execution: true
  required_tools: []
