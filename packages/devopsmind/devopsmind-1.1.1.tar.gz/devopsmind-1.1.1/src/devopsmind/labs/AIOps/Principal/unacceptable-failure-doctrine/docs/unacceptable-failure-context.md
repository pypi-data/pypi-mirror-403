# Unacceptable AI Failure â€” Context

Some failures cannot be justified.

As AI systems expand across organizational functions:
- Harm may be diffuse but irreversible
- Benefits may be cited to offset damage
- Accountability may be delayed or diluted

In this scenario:
- AI systems are actively used in consequential domains
- No doctrine defines which failures invalidate legitimacy
- Post-incident justification is expected to replace accountability

After failure:
- Boards will ask whether continued operation was ever legitimate
- Regulators will examine what the organization chose to tolerate
- The public will judge values, not performance metrics

This doctrine will be evaluated under:
- Board review
- Regulatory inquiry
- Public and reputational scrutiny

This document provides situational context only.
It does not imply acceptable or unacceptable outcomes.
