# Operational Judgment Doctrine — Irreversible Decisions

This document defines the judgment standards applied in this lab.
It does not describe correct actions or expected conclusions.

---

## Purpose of This Lab

This lab evaluates whether AI systems should be permitted
to influence decisions that cannot be undone.

The focus is on governance boundaries, authority,
and absolute accountability — not on technical recovery.

---

## Authority and Irreversibility

In this environment:

- AI systems may provide analysis or recommendations
- AI systems do not own irreversible decision authority
- Human responders retain full responsibility for permanent actions

Allowing AI influence in irreversible decisions
is a governance decision, not a technical one.

Responsibility cannot be delegated.

---

## Irreversibility Judgment Standard

A judgment failure exists when:

- A decision is known to be irreversible
- AI systems are allowed to influence approval or timing
- Humans defer responsibility before commitment

Describing irreversible impact without identifying
why AI influence was permitted does not meet this standard.

---

## Accountability Expectation

A valid analysis must:

- Identify who owned irreversible authority
- Explain why AI involvement was allowed
- Assign accountability to a role or decision owner

Collective or passive responsibility is insufficient.

---

## Post-Failure Control Expectation

After irreversible failure, acceptable responses focus on:

- Permanently excluding AI from irreversible decision paths
- Establishing hard governance boundaries
- Reasserting absolute human accountability

Mitigation, rollback, or recovery proposals
do not address the judgment failure evaluated here.

---

## Evaluation Boundary

This document defines how reasoning is evaluated.
It does not prescribe correct answers.

You are expected to apply these standards independently
to the incident presented in the lab.
