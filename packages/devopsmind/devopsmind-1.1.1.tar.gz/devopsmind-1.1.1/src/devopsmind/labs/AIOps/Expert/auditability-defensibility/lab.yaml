id: auditability-defensibility
title: "Evaluate Auditability and Defensibility of an AIOps System"
stack: aiops
difficulty: Expert
xp: 300

goal: "Decide whether decisions influenced by an AIOps system are auditable and defensible after incidents"

skills:
  - auditability-evaluation
  - decision-defensibility
  - governance-judgment
  - accountability-ownership

hint:
  - Assume an incident review is inevitable.
  - Defensibility matters more than accuracy.

validator: "validator.py"

mentor:
  why: >
    After incidents, decisions are examined under audit,
    regulatory scrutiny, and executive review. If AI-influenced
    decisions cannot be explained or defended, accountability
    collapses regardless of technical performance.
  intent: judge
  guidance:
    before: |
      Consider how decisions are defended months after incidents.

      Think about:
      - What evidence reviewers expect
      - Whether AI reasoning can be reconstructed
      - Who answers when explanations fall short
    after: >
      Reflect on whether opacity itself is an unacceptable risk.
  tags:
    - aiops
    - auditability
    - governance
    - accountability
    - safety

solution:
  overview: >
    This solution frames executive-level reasoning when evaluating
    whether AI-influenced decisions can withstand audit and
    post-incident scrutiny. The emphasis is on defensibility,
    not internal model logic.

  professional_reasoning:
    - Treat non-defensible decisions as unacceptable risk
    - Assume audits will focus on accountability, not intent
    - Reassert human responsibility for explainability
    - Evaluate whether opacity undermines governance

  real_world_context:
    - Do not propose logging or explainability tooling
    - Do not redesign decision records
    - Decide using current audit visibility
    - Assess exposure realistically
    - Favor restriction when decisions cannot be defended

execution:
  runtime: docker
  requires_execution: false
  required_tools:
    - none
