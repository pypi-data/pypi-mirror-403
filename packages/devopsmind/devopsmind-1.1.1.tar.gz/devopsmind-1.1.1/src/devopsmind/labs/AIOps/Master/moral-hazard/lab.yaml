id: moral-hazard
title: "Decide Removal of an AIOps System After Moral Hazard Creation"
stack: aiops
difficulty: Master
xp: 500

goal: >
  Decide whether an AIOps system must be permanently removed
  after it creates moral hazard and risk amplification.

skills:
  - moral_hazard_judgment
  - human_automation_interaction
  - ai_system_removal_decision
  - organizational_risk_ownership

hint:
  - Risk-taking increased after automation was introduced.
  - Humans assume the system will absorb consequences.

validator: validator.py

mentor:
  why: >
    At Master level, engineers must recognize when automation
    incentivizes unsafe behavior rather than preventing it.
  intent: judge
  guidance:
    before: |
      Consider:
      - How incentives changed after deployment
      - Whether responsibility is being displaced
      - If safety depends on the system “catching mistakes”
    after: >
      Automation that encourages risk is itself a risk.
  tags:
    - aiops
    - moral-hazard
    - system-removal
    - governance
    - accountability

solution:
  overview: >
    This lab evaluates whether the learner can issue a
    defensible removal decision when an AIOps system
    creates moral hazard and amplifies risk.

  professional_reasoning:
    - Treat incentive distortion as a safety failure
    - Focus on behavior change, not system intent
    - Assign ownership for amplified exposure
    - Decide without proposing corrective controls

  real_world_context:
    - No remediation is acceptable
    - No behavioral correction is assumed
    - Decisions must stand after incident scrutiny

execution:
  runtime: docker
  requires_execution: false
  required_tools:
    - none
