id: confidence-drift-detection
title: "Evaluate Risk of AI Confidence Drift in Production Decisions"
stack: aiops
difficulty: Hard
xp: 150

goal: "Evaluate operational risk when an AIOps system exhibits confidence drift without corresponding accuracy"

skills:
  - aiops-risk-evaluation
  - automation-bias-analysis
  - decision-integrity
  - operational-judgment

hint:
  - High confidence does not imply correctness.
  - Focus on trust erosion and containment, not recalibration.

validator: "validator.py"

mentor:
  why: >
    Confidence signals strongly influence human trust in automated systems.
    When an AI system expresses increasing confidence while producing
    degraded or misleading output, the operational risk escalates silently.
  intent: stretch
  guidance:
    before: |
      Consider how engineers interpret confidence signals during incidents.

      Think about:
      - How confidence affects override behavior
      - How silent degradation differs from explicit failure
      - Why confidence drift is harder to detect operationally
    after: >
      Reflect on whether confidence reporting should ever be trusted
      without independent validation.
  tags:
    - aiops
    - confidence-drift
    - automation-bias
    - reliability
    - safety

solution:
  overview: >
    This solution frames senior-level reasoning when an AI systemâ€™s
    expressed confidence diverges from its real-world accuracy.
    The emphasis is on recognizing silent trust failure and
    deciding whether the system remains safe to operate.

  professional_reasoning:
    - Treat confidence signals as risk amplifiers, not assurances
    - Assume confidence drift can cause delayed human intervention
    - Prioritize containment over interpretation
    - Reevaluate trust boundaries once confidence misleads operators

  real_world_context:
    - Do not attempt to recalibrate or adjust confidence metrics
    - Do not introduce monitoring or observability solutions
    - Identify how confidence influenced human decisions
    - Assess operational impact realistically
    - Favor restriction when confidence becomes misleading

execution:
  runtime: docker
  requires_execution: false
  required_tools:
    - none
