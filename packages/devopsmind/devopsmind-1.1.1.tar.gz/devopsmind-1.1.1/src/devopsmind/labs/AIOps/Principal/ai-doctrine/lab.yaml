id: ai-doctrine
title: "Define the Organization’s AI Doctrine"
stack: aiops
difficulty: Principal
xp: 1000

goal: >
  Define a durable, organization-wide AI doctrine that governs
  all current and future AI usage.

skills:
  - organizational_doctrine_design
  - long_term_risk_ownership
  - executive_governance_judgment
  - ai_accountability_philosophy

hint:
  - Doctrine outlives systems, tools, and leaders.
  - Some failures are unacceptable regardless of outcome.

validator: validator.py

mentor:
  why: >
    At Principal level, engineers are responsible for
    defining the organization’s moral and operational
    stance toward AI.
  intent: judge
  guidance:
    before: |
      Consider:
      - What the organization will never trade for efficiency
      - Which responsibilities can never be delegated
      - How doctrine constrains future decisions
    after: >
      Doctrine defines identity.
      Everything else follows from it.
  tags:
    - aiops
    - doctrine
    - governance
    - accountability
    - executive

solution:
  overview: >
    This lab evaluates whether the learner can define
    a coherent, defensible AI doctrine that governs
    organizational behavior over the long term.

  professional_reasoning:
    - Treat doctrine as irreversible commitment
    - Focus on values, not mechanisms
    - Define unacceptable failure explicitly
    - Assign enduring accountability

  real_world_context:
    - No remediation is acceptable
    - No future safeguards are assumed
    - Decisions must stand after public failure

execution:
  runtime: docker
  requires_execution: false
  required_tools:
    - none
