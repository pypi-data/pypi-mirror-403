id: ai-risk-acceptance
title: "Define the Organizationâ€™s Doctrine for AI Risk Acceptance"
stack: aiops
difficulty: Principal
xp: 1000

goal: >
  Define a durable doctrine specifying which AI risks
  the organization explicitly accepts and owns.

skills:
  - risk_acceptance_doctrine
  - executive_accountability_judgment
  - long_term_exposure_assessment
  - ai_governance_philosophy

hint:
  - Accepted risk is owned, not minimized.
  - Acceptance remains binding after failure.

validator: validator.py

mentor:
  why: >
    At Principal level, engineers must decide
    which risks the organization is willing to live with,
    and publicly own when they materialize.
  intent: judge
  guidance:
    before: |
      Consider:
      - Risks that align with organizational values
      - Exposure that can be defended after failure
      - Accountability when acceptance proves costly
    after: >
      Risk acceptance is a promise to absorb consequences.
  tags:
    - aiops
    - doctrine
    - risk-acceptance
    - accountability
    - executive

solution:
  overview: >
    This lab evaluates whether the learner can define
    a clear, defensible doctrine for AI risks the
    organization knowingly and permanently accepts.

  professional_reasoning:
    - Treat risk acceptance as irreversible commitment
    - Focus on ownership, not reduction
    - Define justification that survives failure
    - Assign enduring accountability

  real_world_context:
    - No remediation is acceptable
    - No future safeguards are assumed
    - Decisions must stand after public and regulatory review

execution:
  runtime: docker
  requires_execution: false
  required_tools:
    - none
