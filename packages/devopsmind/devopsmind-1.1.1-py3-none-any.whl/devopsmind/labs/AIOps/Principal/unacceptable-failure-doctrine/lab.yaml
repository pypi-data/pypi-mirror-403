id: unacceptable-failure
title: "Define the Organizationâ€™s Doctrine for Unacceptable AI Failures"
stack: aiops
difficulty: Principal
xp: 1000

goal: >
  Define a durable doctrine specifying which AI failures
  are unacceptable under any circumstances.

skills:
  - unacceptable_failure_doctrine
  - executive_risk_judgment
  - organizational_accountability
  - ai_governance_philosophy

hint:
  - Some failures negate all benefits.
  - Acceptance after failure defines organizational values.

validator: validator.py

mentor:
  why: >
    At Principal level, engineers must define which failures
    the organization will not justify, excuse, or tolerate.
  intent: judge
  guidance:
    before: |
      Consider:
      - Failures that destroy legitimacy
      - Harm that cannot be offset by success elsewhere
      - What the organization must walk away from
    after: >
      What you refuse defines who you are.
  tags:
    - aiops
    - doctrine
    - failure
    - accountability
    - executive

solution:
  overview: >
    This lab evaluates whether the learner can define
    a clear, defensible doctrine for AI failures that
    invalidate continued operation or adoption.

  professional_reasoning:
    - Treat unacceptable failure as absolute
    - Focus on legitimacy, not recovery
    - Define non-negotiable harm
    - Assign enduring accountability

  real_world_context:
    - No remediation is acceptable
    - No future safeguards are assumed
    - Decisions must stand after public failure

execution:
  runtime: docker
  requires_execution: false
  required_tools:
    - none
