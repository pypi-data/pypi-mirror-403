id: system-approval-review
title: "Conduct Production Approval Review for an AIOps System"
stack: aiops
difficulty: Expert
xp: 300

goal: "Decide whether an AIOps system should be approved for production deployment"

skills:
  - ai-system-evaluation
  - production-approval-judgment
  - risk-governance
  - accountability-decision-making

hint:
  - Assume this is the final approval gate.
  - Approval implies ownership of future failures.

validator: "validator.py"

mentor:
  why: >
    Expert-level engineers are trusted with approval authority.
    Approving an AI system means accepting responsibility for
    every future incident it influences.
  intent: judge
  guidance:
    before: |
      Consider what approval truly means in production environments.

      Think about:
      - What risks are acceptable at approval time
      - What unknowns cannot be approved
      - Who bears responsibility after approval
    after: >
      Reflect on whether denial is sometimes the most responsible decision.
  tags:
    - aiops
    - system-approval
    - governance
    - risk
    - safety

solution:
  overview: >
    This solution frames executive-level reasoning when deciding
    whether an AI system should be approved for production use.
    The emphasis is on risk ownership, not technical capability.

  professional_reasoning:
    - Treat approval as acceptance of future failure risk
    - Assume unknown failure modes exist
    - Prioritize organizational safety over innovation
    - Make approval defensible under incident review

  real_world_context:
    - Do not propose conditional or trial approvals
    - Do not require further testing or pilots
    - Decide with available information only
    - Assess long-term exposure realistically
    - Favor rejection when risk cannot be bounded

execution:
  runtime: docker
  requires_execution: false
  required_tools:
    - none
