id: ai-decommission-decision
title: "Decide to Decommission an AIOps System"
stack: aiops
difficulty: Master
xp: 500

goal: "Evaluate whether an AIOps system should be decommissioned, reduced, or retained"

skills:
  - ai-strategy
  - system-judgment
  - cost-risk-analysis
  - platform-ownership
  - long-term-maintainability

hint: "The hardest decision is not how to improve AI â€” but when to remove it."

validator: "validator.py"

mentor:
  why: >
    Mature engineering organizations know when technology creates more risk
    than value. This lab trains top-level judgment required to
    decommission AI systems responsibly.
  intent: mastery
  guidance:
    before: |
      Think like a principal engineer responsible for long-term platform health,
      not short-term feature success.

      Optional manual inspection (not required for validation):
      - Review historical incident reports or postmortems
      - Inspect usage metrics, reliability trends, or decision logs
      - cat / less / grep for understanding only
    after: >
      Reflect on how removing AI can sometimes increase reliability and trust.
  tags:
    - aiops
    - decommissioning
    - strategy
    - platform-engineering
    - leadership

solution:
  overview: >
    This solution evaluates master-level judgment around decommissioning
    AI systems when they no longer serve platform reliability or
    organizational clarity. The focus is on long-term platform health,
    accountability, and cultural impact rather than sunk cost or novelty.

  professional_reasoning:
    - Prioritize long-term platform health over sunk cost considerations
    - Frame risks in systemic and organizational terms rather than local failures
    - Preserve clear accountability and ownership after decommissioning
    - Favor deterministic systems where reliability and predictability dominate

  real_world_context:
    - Do not justify AI retention based on speculative future improvements
    - Avoid providing procedural decommission checklists
    - Do not imply a single universally correct outcome
    - Demonstrate willingness to remove AI despite prior investment
    - Maintain clear separation between value, risk, and novelty
    - Emphasize engineering culture and operational clarity

execution:
  runtime: docker
  requires_execution: true
  required_tools:
    - cat
    - less
    - grep
