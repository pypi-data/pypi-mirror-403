id: platform-boundaries
title: "Define Platform-Wide AI Boundaries for an Organization"
stack: aiops
difficulty: Architect
xp: 750

goal: >
  Define clear, enforceable boundaries for where AI
  is allowed and disallowed across the platform.

skills:
  - platform_governance_design
  - blast_radius_containment
  - ai_boundary_definition
  - organizational_risk_ownership

hint:
  - This is not about a single system.
  - Boundaries must survive future scale.

validator: validator.py

mentor:
  why: >
    At Architect level, engineers define the space
    in which AI is allowed to exist at all.
  intent: judge
  guidance:
    before: |
      Consider:
      - Platform domains where AI failure is unacceptable
      - Areas requiring irreversible human ownership
      - How boundaries constrain future decisions
    after: >
      Boundaries are stronger than controls.
      They prevent risk instead of managing it.
  tags:
    - aiops
    - architecture
    - governance
    - platform-boundaries
    - accountability

solution:
  overview: >
    This lab evaluates whether the learner can define
    platform-wide AI boundaries that limit blast radius
    and remain defensible as the organization scales.

  professional_reasoning:
    - Think at platform, not system level
    - Treat disallowed zones as governance commitments
    - Focus on irreversible risk prevention
    - Avoid conditional or procedural framing

  real_world_context:
    - No enforcement mechanisms are assumed
    - No future safeguards are referenced
    - Decisions must stand after platform failure

execution:
  runtime: docker
  requires_execution: false
  required_tools:
    - none
