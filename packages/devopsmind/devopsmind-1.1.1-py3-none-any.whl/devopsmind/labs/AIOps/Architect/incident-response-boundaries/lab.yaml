id: incident-response-boundaries
title: "Define Platform-Wide AI Boundaries in Incident Response"
stack: aiops
difficulty: Architect
xp: 750

goal: >
  Define clear boundaries for where AI is allowed
  and disallowed during incident response.

skills:
  - incident_response_governance
  - human_ownership_enforcement
  - ai_boundary_definition
  - organizational_risk_ownership

hint:
  - Incident response requires accountable decisions.
  - Speed cannot replace ownership during failure.

validator: validator.py

mentor:
  why: >
    At Architect level, engineers must decide
    where AI influence ends when systems fail.
  intent: judge
  guidance:
    before: |
      Consider:
      - Which incident phases demand human judgment
      - Where ambiguity cannot be tolerated
      - How automation affects post-incident accountability
    after: >
      During incidents, clarity matters more than speed.
  tags:
    - aiops
    - incident-response
    - governance
    - platform-boundaries
    - accountability

solution:
  overview: >
    This lab evaluates whether the learner can define
    incident-response-specific AI boundaries that
    preserve human accountability during failure.

  professional_reasoning:
    - Treat incident response as a human-owned domain
    - Define disallowed zones as irreversible
    - Focus on accountability under pressure
    - Avoid procedural enforcement framing

  real_world_context:
    - No enforcement mechanisms are assumed
    - No future safeguards are referenced
    - Decisions must stand after major incidents

execution:
  runtime: docker
  requires_execution: false
  required_tools:
    - none
