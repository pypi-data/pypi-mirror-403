id: approval-authority-boundaries
title: "Define Platform-Wide AI Boundaries for Approval and Authority"
stack: aiops
difficulty: Architect
xp: 750

goal: >
  Define clear boundaries for where AI is allowed
  and disallowed in approval and authority decisions.

skills:
  - authority_boundary_design
  - accountability_enforcement
  - ai_boundary_definition
  - organizational_risk_ownership

hint:
  - Approval assigns responsibility, not convenience.
  - Authority must remain attributable after failure.

validator: validator.py

mentor:
  why: >
    At Architect level, engineers must ensure that
    authority cannot be delegated to systems that
    cannot be held accountable.
  intent: judge
  guidance:
    before: |
      Consider:
      - Which approvals carry legal or ethical weight
      - Whether authority can be meaningfully audited
      - How responsibility is traced after harm
    after: >
      Approval without ownership is governance failure.
  tags:
    - aiops
    - approval
    - authority
    - governance
    - platform-boundaries

solution:
  overview: >
    This lab evaluates whether the learner can define
    approval and authority boundaries that preserve
    human accountability at organizational scale.

  professional_reasoning:
    - Treat approval as accountability assignment
    - Define disallowed authority zones as permanent
    - Focus on traceability after failure
    - Avoid procedural enforcement framing

  real_world_context:
    - No enforcement mechanisms are assumed
    - No future safeguards are referenced
    - Decisions must stand after legal review

execution:
  runtime: docker
  requires_execution: false
  required_tools:
    - none
