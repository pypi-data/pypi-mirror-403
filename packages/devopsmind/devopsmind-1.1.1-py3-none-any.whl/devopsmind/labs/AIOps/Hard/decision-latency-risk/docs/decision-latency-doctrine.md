# Operational Judgment Doctrine — Decision Latency

This document defines the judgment standards applied in this lab.
It does not describe correct actions or expected conclusions.

---

## Purpose of This Lab

This lab evaluates how decision latency introduced by AI-assisted
analysis affects incident outcomes.

The focus is on time-critical judgment, authority, and accountability —
not on improving analysis speed or redesigning workflows.

---

## Authority and Timing Responsibility

In this environment:

- AI systems may provide analysis during incidents
- AI systems do not own timing decisions
- Human responders retain full responsibility for when action occurs

Waiting is a decision.
Delaying action is also a decision.

Responsibility cannot be delegated to analysis systems.

---

## Decision Latency Judgment Standard

A judgment failure exists when:

- Action is delayed while awaiting AI input
- Earlier human intervention was possible
- Time loss compounds operational or business impact

Describing delays without identifying decision ownership
does not meet this standard.

---

## Accountability Expectation

A valid analysis must:

- Identify where timing authority resided
- Explain why action was delayed
- Assign accountability to a role or decision owner

Passive framing or inevitability arguments are insufficient.

---

## Post-Failure Control Expectation

After latency-related failure, acceptable responses focus on:

- Removing AI analysis from time-critical paths
- Restricting AI influence over urgent decisions
- Reasserting human authority over response timing

Speed improvements or parallelization
do not address the judgment failure evaluated here.

---

## Evaluation Boundary

This document defines how reasoning is evaluated.
It does not prescribe correct answers.

You are expected to apply these standards independently
to the incident presented in the lab.
