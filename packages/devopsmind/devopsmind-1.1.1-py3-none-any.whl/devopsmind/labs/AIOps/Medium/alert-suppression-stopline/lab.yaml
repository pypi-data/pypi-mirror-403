id: alert-suppression-stopline
title: "Stop-Line for AI in Alert Suppression"
stack: aiops
difficulty: Medium
xp: 100
goal: "Define explicit conditions where AI-based alert suppression must disengage"

skills:
  - stop-line-definition
  - alerting-risk
  - ai-boundary-control

hint:
  - Suppression is not neutral.
  - Stop-lines must be based on conditions, not confidence.

validator: "validator.py"

mentor:
  why: "This lab trains engineers to define explicit disengagement conditions for AI systems operating in alerting paths."
  intent: boundary

  guidance:
    before: |
      Alert suppression directly affects what operators see.
      Once alerts are hidden, they cannot influence response.

      AI systems tend to fail gradually and silently.
      Your responsibility is to define when suppression
      must automatically stop, regardless of AI confidence.

    after: |
      Safe automation includes safe disengagement.
      If you cannot clearly define when AI stops, it should not start.

  tags:
    - aiops
    - alerting
    - suppression
    - boundaries

execution:
  runtime: docker
  requires_execution: false
  required_tools:
    - none
