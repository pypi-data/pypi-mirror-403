#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Real test of ClaudeCodeBackend with actual Claude Code API calls.
This test outputs the actual stream chunks to verify functionality.

Note: These tests require ANTHROPIC_API_KEY and are marked as integration tests.
"""

import asyncio
import os
import tempfile

import pytest

from massgen.backend.claude_code import ClaudeCodeBackend


@pytest.mark.integration
@pytest.mark.asyncio
async def test_real_stream_with_tools():
    """Test real streaming with Claude Code API and output stream chunks."""

    # Check if API key is available
    if not os.getenv("ANTHROPIC_API_KEY"):
        pytest.skip("ANTHROPIC_API_KEY not found in environment")
        return

    print("ðŸš€ Testing ClaudeCodeBackend with real Claude Code API")
    print("=" * 60)

    # Initialize backend with temporary workspace
    with tempfile.TemporaryDirectory() as tmpdir:
        backend = ClaudeCodeBackend(cwd=tmpdir)
        print(f"âœ… Backend initialized: {backend.get_provider_name()}")
        print(f"ðŸ“Š Supported tools: {len(backend.get_supported_builtin_tools())} tools")

    # Test single turn conversation
    print("\nðŸ”„ Testing single turn conversation...")
    messages = [
        {
            "role": "user",
            "content": "Hello! Can you tell me what 2+2 equals and show your calculation?",
        },
    ]

    try:
        print("\nðŸ“¨ Sending messages:", messages)
        print("\nðŸ“¡ Stream chunks received:")
        print("-" * 40)

        chunk_count = 0
        total_content = ""

        async for chunk in backend.stream_with_tools(messages, []):
            chunk_count += 1
            print(f"[{chunk_count:2d}] Type: {chunk.type:<20} Source: {chunk.source or 'None':<20}")

            if chunk.type == "content":
                print(f"     Content: {repr(chunk.content)}")
                total_content += chunk.content or ""
            elif chunk.type == "complete_message":
                print(f"     Complete message: {chunk.complete_message}")
            elif chunk.type == "complete_response":
                print(f"     Response metadata: {chunk.response}")
            elif chunk.type == "agent_status":
                print(f"     Status: {chunk.status} - {chunk.content}")
            elif chunk.type == "builtin_tool_results":
                print(f"     Tool results: {chunk.builtin_tool_results}")
            elif chunk.type == "tool_calls":
                print(f"     Tool calls: {chunk.tool_calls}")
            elif chunk.type == "error":
                print(f"     Error: {chunk.error}")
            elif chunk.type == "done":
                print("     âœ… Stream completed")
                break

            print()

        print("-" * 40)
        print(f"ðŸ“Š Total chunks: {chunk_count}")
        print(f"ðŸ“ Total content length: {len(total_content)} chars")
        print(f"ðŸ’° Token usage: {backend.get_token_usage()}")
        print(f"ðŸ”— Session ID: {backend.get_current_session_id()}")

        if total_content:
            print(f"\nðŸ“„ Complete response:\n{total_content}")

    except Exception as e:
        print(f"âŒ Error during streaming: {e}")
        import traceback

        traceback.print_exc()
        return

    # Test multi-turn conversation
    print("\n" + "=" * 60)
    print("ðŸ”„ Testing multi-turn conversation...")

    # Add assistant response to conversation
    messages.append({"role": "assistant", "content": total_content})

    # Add follow-up question
    messages.append(
        {
            "role": "user",
            "content": "Great! Now can you show me how to calculate the result times 5?",
        },
    )

    try:
        print("\nðŸ“¨ Sending multi-turn messages:")
        for i, msg in enumerate(messages):
            print(f"  [{i+1}] {msg['role']}: {msg['content'][:100]}{'...' if len(msg['content']) > 100 else ''}")

        print("\nðŸ“¡ Stream chunks received:")
        print("-" * 40)

        chunk_count = 0
        turn2_content = ""

        async for chunk in backend.stream_with_tools(messages, []):
            chunk_count += 1
            print(f"[{chunk_count:2d}] Type: {chunk.type:<20} Source: {chunk.source or 'None':<20}")

            if chunk.type == "content":
                print(f"     Content: {repr(chunk.content)}")
                turn2_content += chunk.content or ""
            elif chunk.type == "complete_response":
                print(f"     Response metadata: {chunk.response}")
            elif chunk.type == "done":
                print("     âœ… Stream completed")
                break

            print()

        print("-" * 40)
        print(f"ðŸ“Š Turn 2 chunks: {chunk_count}")
        print(f"ðŸ“ Turn 2 content length: {len(turn2_content)} chars")
        print(f"ðŸ’° Cumulative token usage: {backend.get_token_usage()}")
        print(f"ðŸ”— Session ID: {backend.get_current_session_id()}")

        if turn2_content:
            print(f"\nðŸ“„ Turn 2 response:\n{turn2_content}")

    except Exception as e:
        print(f"âŒ Error during multi-turn: {e}")
        import traceback

        traceback.print_exc()
        return

    print("\nâœ… Multi-turn conversation test completed successfully!")


@pytest.mark.integration
@pytest.mark.asyncio
async def test_with_workflow_tools():
    """Test with MassGen workflow tools."""

    if not os.getenv("ANTHROPIC_API_KEY"):
        pytest.skip("ANTHROPIC_API_KEY not found in environment")

    print("\n" + "=" * 60)
    print("ðŸ› ï¸  Testing with workflow tools...")

    with tempfile.TemporaryDirectory() as tmpdir:
        backend = ClaudeCodeBackend(cwd=tmpdir)

    # Define workflow tools
    workflow_tools = [
        {
            "type": "function",
            "function": {
                "name": "new_answer",
                "description": "Provide an improved answer to the ORIGINAL MESSAGE",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "content": {
                            "type": "string",
                            "description": "Your improved answer",
                        },
                    },
                    "required": ["content"],
                },
            },
        },
        {
            "type": "function",
            "function": {
                "name": "vote",
                "description": "Vote for the best agent to present final answer",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "agent_id": {
                            "type": "string",
                            "description": "Agent ID to vote for",
                        },
                        "reason": {
                            "type": "string",
                            "description": "Reason for voting",
                        },
                    },
                    "required": ["agent_id", "reason"],
                },
            },
        },
    ]

    messages = [
        {
            "role": "user",
            "content": "You are participating in a multi-agent workflow. Please provide an answer about the benefits of Python programming, then use the new_answer tool to submit your response.",
        },
    ]

    try:
        print(f"\nðŸ“¨ Sending workflow tool message with {len(workflow_tools)} tools")
        print(f"ðŸ› ï¸  Tools: {[t['function']['name'] for t in workflow_tools]}")

        print("\nðŸ“¡ Stream chunks received:")
        print("-" * 40)

        chunk_count = 0
        workflow_content = ""
        detected_tool_calls = []

        async for chunk in backend.stream_with_tools(messages, workflow_tools):
            chunk_count += 1
            print(f"[{chunk_count:2d}] Type: {chunk.type:<20} Source: {chunk.source or 'None':<20}")

            if chunk.type == "content":
                print(f"     Content: {repr(chunk.content)}")
                workflow_content += chunk.content or ""
            elif chunk.type == "tool_calls":
                print(f"     ðŸ› ï¸  Tool calls detected: {chunk.tool_calls}")
                detected_tool_calls.extend(chunk.tool_calls or [])
            elif chunk.type == "complete_response":
                print(f"     Response metadata: {chunk.response}")
            elif chunk.type == "done":
                print("     âœ… Stream completed")
                break

            print()

        print("-" * 40)
        print(f"ðŸ“Š Workflow chunks: {chunk_count}")
        print(f"ðŸ“ Workflow content length: {len(workflow_content)} chars")
        print(f"ðŸ› ï¸  Detected tool calls: {len(detected_tool_calls)}")
        for i, tool_call in enumerate(detected_tool_calls):
            print(f"     [{i+1}] {tool_call.get('function', {}).get('name', 'unknown')}: {tool_call}")
        print(f"ðŸ’° Token usage: {backend.get_token_usage()}")

        if workflow_content:
            print(f"\nðŸ“„ Workflow response:\n{workflow_content}")

    except Exception as e:
        print(f"âŒ Error during workflow test: {e}")
        import traceback

        traceback.print_exc()
        return

    print("\nâœ… Workflow tools test completed!")


async def main():
    """Run all real tests."""
    print("ðŸ§ª ClaudeCodeBackend Real API Tests")
    print("=" * 60)

    await test_real_stream_with_tools()
    await test_with_workflow_tools()

    print("\nðŸŽ‰ All tests completed!")


if __name__ == "__main__":
    asyncio.run(main())
