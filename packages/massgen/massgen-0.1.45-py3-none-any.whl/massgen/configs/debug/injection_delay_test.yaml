# Debug config for testing mid-stream injection with delay
# Run with: uv run massgen --config massgen/configs/debug/injection_delay_test.yaml "Create a simple poem and write it into a file"

agents:
  - id: "agent_a"
    backend:
      type: "chatcompletion"
      model: "openai/gpt-5-mini"
      base_url: "https://openrouter.ai/api/v1"
      reasoning:
        effort: "medium"
        # summary: "auto"
      # type: "grok"
      # model: "grok-4-1-fast-reasoning"
      # type: "gemini"
      # model: "gemini-3-flash-preview"
      cwd: "workspace"  # Required for filesystem mode
      enable_mcp_command_line: true
      command_line_execution_mode: "docker"
      command_line_docker_enable_sudo: true

  - id: "agent_b"
    backend:
      type: "openai"
      model: "gpt-5.2"
      text:
        verbosity: "medium"
      reasoning:
        effort: "medium"
      # type: "claude_code"
      # model: "claude-sonnet-4-5"
      # max_thinking_tokens: 1024  # to test reasoning in buffer
      cwd: "workspace"  # Required for filesystem mode
      enable_mcp_command_line: true
      command_line_execution_mode: "docker"
      command_line_docker_enable_sudo: true
      debug_delay_seconds: 30  # Delay in seconds after N tool calls
      debug_delay_after_n_tools: 2  # Apply delay after 2 tool calls (allows agent_a to finish first)

orchestrator:
  snapshot_storage: "snapshots"
  agent_temporary_workspace: "temp_workspaces"
  max_new_answers_per_agent: 3

  coordination:
    # Enable task planning
    enable_agent_task_planning: true
    task_planning_filesystem_mode: true
