"""
Task-based Context Management

åŸºäº Task çš„ä¸Šä¸‹æ–‡ç®¡ç†ï¼Œæ•´åˆ LoomMemory å’Œ EventBusã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä»å¤šä¸ªæ¥æºæ”¶é›†ä¸Šä¸‹æ–‡ï¼ˆMemory + EventBusï¼‰
2. å°† Task è½¬æ¢ä¸º LLM æ¶ˆæ¯æ ¼å¼
3. æ™ºèƒ½å‹ç¼©å’Œæ€»ç»“
4. ç²¾ç¡®çš„ token æ§åˆ¶
5. ä¸Šä¸‹æ–‡é¢„ç®—åˆ†é…ï¼ˆContext Budgeterï¼‰

è®¾è®¡ç†å¿µï¼š
- é˜²æ­¢ä¸Šä¸‹æ–‡è…åŒ–
- æœ€å¤§åŒ–æ™ºèƒ½
- æ”¯æŒé•¿æ—¶é—´ä»»åŠ¡
"""

from abc import ABC, abstractmethod
from dataclasses import dataclass
from datetime import UTC, datetime
from typing import TYPE_CHECKING, Any, cast

from loom.memory.tokenizer import TokenCounter
from loom.protocol import Task

if TYPE_CHECKING:
    from loom.config.knowledge import KnowledgeBaseProvider
    from loom.events.event_bus import EventBus
    from loom.fractal.memory import FractalMemory
    from loom.fractal.memory import MemoryScope
    from loom.memory.core import LoomMemory


# ==================== ä¸Šä¸‹æ–‡é¢„ç®—åˆ†é…å™¨ ====================


@dataclass
class BudgetAllocation:
    """
    ä¸Šä¸‹æ–‡é¢„ç®—åˆ†é…ç»“æœ

    Attributes:
        l1_tokens: L1å±‚ï¼ˆæœ€è¿‘ä»»åŠ¡ï¼‰åˆ†é…çš„tokenæ•°
        l2_tokens: L2å±‚ï¼ˆé‡è¦ä»»åŠ¡ï¼‰åˆ†é…çš„tokenæ•°
        l3_l4_tokens: L3/L4å±‚ï¼ˆæ‘˜è¦/å‘é‡ï¼‰åˆ†é…çš„tokenæ•°
        eventbus_tokens: EventBusäº‹ä»¶åˆ†é…çš„tokenæ•°
        system_tokens: ç³»ç»Ÿæç¤ºè¯é¢„ç•™çš„tokenæ•°
    """

    l1_tokens: int = 0
    l2_tokens: int = 0
    l3_l4_tokens: int = 0
    eventbus_tokens: int = 0
    system_tokens: int = 0

    @property
    def total(self) -> int:
        """æ€»åˆ†é…tokenæ•°"""
        return self.l1_tokens + self.l2_tokens + self.l3_l4_tokens + self.eventbus_tokens


@dataclass
class BudgetConfig:
    """
    ä¸Šä¸‹æ–‡é¢„ç®—é…ç½®

    Attributes:
        l1_ratio: L1å±‚åˆ†é…æ¯”ä¾‹ï¼ˆé»˜è®¤30%ï¼‰
        l2_ratio: L2å±‚åˆ†é…æ¯”ä¾‹ï¼ˆé»˜è®¤25%ï¼Œç”¨äºBusç›¸å…³ä¸Šä¸‹æ–‡ï¼‰
        l3_l4_ratio: L3/L4å±‚åˆ†é…æ¯”ä¾‹ï¼ˆé»˜è®¤20%ï¼‰
        direct_min_items: Directæœ€å°ä¿ç•™æ¡æ•°ï¼ˆé»˜è®¤1ï¼‰
        bus_min_items: Busæœ€å°ä¿ç•™æ¡æ•°ï¼ˆé»˜è®¤2ï¼‰
        system_reserve: ç³»ç»Ÿæç¤ºè¯é¢„ç•™æ¯”ä¾‹ï¼ˆé»˜è®¤15%ï¼‰
    """

    l1_ratio: float = 0.30
    l2_ratio: float = 0.25
    l3_l4_ratio: float = 0.20
    direct_min_items: int = 1
    bus_min_items: int = 2
    system_reserve: float = 0.15


@dataclass
class EventCandidate:
    """
    äº‹ä»¶å€™é€‰é¡¹ï¼ˆç”¨äºæ’åºï¼‰

    Attributes:
        task: äº‹ä»¶Taskå¯¹è±¡
        score: ç»¼åˆè¯„åˆ†
        time_score: æ—¶é—´è¡°å‡åˆ†æ•°
        action_score: åŠ¨ä½œæƒé‡åˆ†æ•°
        relevance_score: ç›¸å…³æ€§åˆ†æ•°
        node_score: èŠ‚ç‚¹æƒé‡åˆ†æ•°
    """

    task: Task
    score: float = 0.0
    time_score: float = 0.0
    action_score: float = 0.0
    relevance_score: float = 0.0
    node_score: float = 0.0


class ContextBudgeter:
    """
    ä¸Šä¸‹æ–‡é¢„ç®—åˆ†é…å™¨

    è´Ÿè´£æ™ºèƒ½åˆ†é…ä¸Šä¸‹æ–‡tokené¢„ç®—åˆ°ä¸åŒå±‚çº§ï¼Œå¹¶å¯¹äº‹ä»¶å€™é€‰è¿›è¡Œæ’åºã€‚

    é¢„ç®—åˆ†é…ç­–ç•¥ï¼š
    - L1ï¼ˆæœ€è¿‘ä»»åŠ¡ + Directï¼‰: 30% - ä¿è¯ç›´è¿ä¸æœ€è¿‘ä¸Šä¸‹æ–‡çš„å®Œæ•´æ€§
    - L2ï¼ˆBusç›¸å…³ï¼‰: 25% - ä¿ç•™è·¨èŠ‚ç‚¹ç›¸å…³ä¿¡æ¯
    - L3/L4ï¼ˆæ‘˜è¦/å‘é‡ï¼‰: 20% - é•¿æœŸè®°å¿†æ£€ç´¢

    äº‹ä»¶æ’åºç­–ç•¥ï¼š
    - æ—¶é—´è¡°å‡ï¼ˆ40%ï¼‰: è¶Šè¿‘çš„äº‹ä»¶æƒé‡è¶Šé«˜
    - åŠ¨ä½œæƒé‡ï¼ˆ25%ï¼‰: thinking > tool_call > other
    - ç›¸å…³æ€§ï¼ˆ20%ï¼‰: å…³é”®è¯/embeddingåŒ¹é…
    - èŠ‚ç‚¹æƒé‡ï¼ˆ15%ï¼‰: çˆ¶èŠ‚ç‚¹ > å…„å¼ŸèŠ‚ç‚¹ > å…¶ä»–
    """

    def __init__(
        self,
        token_counter: TokenCounter,
        max_tokens: int = 4000,
        config: BudgetConfig | None = None,
    ):
        """
        åˆå§‹åŒ–ä¸Šä¸‹æ–‡é¢„ç®—åˆ†é…å™¨

        Args:
            token_counter: Tokenè®¡æ•°å™¨
            max_tokens: æœ€å¤§tokenæ•°
            config: é¢„ç®—é…ç½®ï¼ˆå¯é€‰ï¼‰
        """
        self.token_counter = token_counter
        self.max_tokens = max_tokens
        self.config = self._normalize_config(config or BudgetConfig())

        # åŠ¨ä½œç±»å‹æƒé‡
        self._action_weights = {
            "node.thinking": 1.0,
            "node.tool_call": 0.8,
            "node.planning": 0.9,
            "node.error": 0.7,
            "execute": 0.6,
        }

    def _normalize_config(self, config: BudgetConfig) -> BudgetConfig:
        """å½’ä¸€åŒ–æ¯”ä¾‹é…ç½®ï¼Œé¿å…é”™è¯¯é…ç½®å¯¼è‡´é¢„ç®—å¤±çœŸ"""
        l1 = max(0.0, config.l1_ratio)
        l2 = max(0.0, config.l2_ratio)
        l3 = max(0.0, config.l3_l4_ratio)

        total = l1 + l2 + l3
        if total <= 0:
            return BudgetConfig()

        l1 /= total
        l2 /= total
        l3 /= total
        direct_min_items = int(max(0, config.direct_min_items))
        bus_min_items = int(max(0, config.bus_min_items))

        return BudgetConfig(
            l1_ratio=l1,
            l2_ratio=l2,
            l3_l4_ratio=l3,
            direct_min_items=direct_min_items,
            bus_min_items=bus_min_items,
            system_reserve=config.system_reserve,
        )

    def allocate_budget(self, system_prompt_tokens: int = 0) -> BudgetAllocation:
        """
        åˆ†é…ä¸Šä¸‹æ–‡é¢„ç®—

        Args:
            system_prompt_tokens: ç³»ç»Ÿæç¤ºè¯å ç”¨çš„tokenæ•°

        Returns:
            é¢„ç®—åˆ†é…ç»“æœ
        """
        # è®¡ç®—å¯ç”¨tokenï¼ˆæ‰£é™¤ç³»ç»Ÿæç¤ºè¯ï¼‰
        available = self.max_tokens - system_prompt_tokens

        if available <= 0:
            return BudgetAllocation(system_tokens=system_prompt_tokens)

        # æŒ‰æ¯”ä¾‹åˆ†é…
        return BudgetAllocation(
            l1_tokens=int(available * self.config.l1_ratio),
            l2_tokens=int(available * self.config.l2_ratio),
            l3_l4_tokens=int(available * self.config.l3_l4_ratio),
            system_tokens=system_prompt_tokens,
        )

    def rank_events(
        self,
        events: list[Task],
        current_task: Task,
        current_node_id: str | None = None,
        parent_node_id: str | None = None,
        keywords: list[str] | None = None,
    ) -> list[EventCandidate]:
        """
        å¯¹äº‹ä»¶å€™é€‰è¿›è¡Œæ’åº

        æ’åºç­–ç•¥ï¼š
        - æ—¶é—´è¡°å‡ï¼ˆ40%ï¼‰: è¶Šè¿‘çš„äº‹ä»¶æƒé‡è¶Šé«˜
        - åŠ¨ä½œæƒé‡ï¼ˆ25%ï¼‰: thinking > tool_call > other
        - ç›¸å…³æ€§ï¼ˆ20%ï¼‰: å…³é”®è¯åŒ¹é…
        - èŠ‚ç‚¹æƒé‡ï¼ˆ15%ï¼‰: çˆ¶èŠ‚ç‚¹ > å…„å¼ŸèŠ‚ç‚¹ > å…¶ä»–

        Args:
            events: äº‹ä»¶åˆ—è¡¨
            current_task: å½“å‰ä»»åŠ¡
            current_node_id: å½“å‰èŠ‚ç‚¹ID
            parent_node_id: çˆ¶èŠ‚ç‚¹ID
            keywords: ç›¸å…³å…³é”®è¯åˆ—è¡¨

        Returns:
            æ’åºåçš„äº‹ä»¶å€™é€‰åˆ—è¡¨
        """
        if not events:
            return []

        if keywords is None:
            content = current_task.parameters.get("content", "")
            keywords = self._fallback_keywords(content)

        candidates = []
        now = datetime.now(UTC)

        for event in events:
            candidate = EventCandidate(task=event)

            # 1. æ—¶é—´è¡°å‡åˆ†æ•°ï¼ˆ40%æƒé‡ï¼‰
            candidate.time_score = self._calc_time_score(event, now)

            # 2. åŠ¨ä½œæƒé‡åˆ†æ•°ï¼ˆ25%æƒé‡ï¼‰
            candidate.action_score = self._calc_action_score(event)

            # 3. ç›¸å…³æ€§åˆ†æ•°ï¼ˆ20%æƒé‡ï¼‰
            candidate.relevance_score = self._calc_relevance_score(event, keywords)

            # 4. èŠ‚ç‚¹æƒé‡åˆ†æ•°ï¼ˆ15%æƒé‡ï¼‰
            candidate.node_score = self._calc_node_score(event, current_node_id, parent_node_id)

            # ç»¼åˆè¯„åˆ†
            candidate.score = (
                candidate.time_score * 0.40
                + candidate.action_score * 0.25
                + candidate.relevance_score * 0.20
                + candidate.node_score * 0.15
            )

            candidates.append(candidate)

        # æŒ‰åˆ†æ•°é™åºæ’åº
        candidates.sort(key=lambda c: c.score, reverse=True)
        return candidates

    def _calc_time_score(self, event: Task, now: datetime) -> float:
        """è®¡ç®—æ—¶é—´è¡°å‡åˆ†æ•°"""
        if not event.created_at:
            return 0.5  # æ— æ—¶é—´æˆ³ï¼Œç»™ä¸­ç­‰åˆ†æ•°

        # è®¡ç®—æ—¶é—´å·®ï¼ˆç§’ï¼‰
        delta = (now - event.created_at).total_seconds()

        # æŒ‡æ•°è¡°å‡ï¼šåŠè¡°æœŸä¸º1å°æ—¶ï¼ˆ3600ç§’ï¼‰
        half_life = 3600
        return 2 ** (-delta / half_life)

    def _calc_action_score(self, event: Task) -> float:
        """è®¡ç®—åŠ¨ä½œæƒé‡åˆ†æ•°"""
        return self._action_weights.get(event.action, 0.5)

    def _calc_relevance_score(self, event: Task, keywords: list[str] | None) -> float:
        """è®¡ç®—ç›¸å…³æ€§åˆ†æ•°ï¼ˆåŸºäºå…³é”®è¯åŒ¹é…ï¼‰"""
        embedded_score = event.metadata.get("_relevance_score")
        if isinstance(embedded_score, int | float):
            return float(embedded_score)
        if not keywords:
            return 0.5  # æ— å…³é”®è¯ï¼Œç»™ä¸­ç­‰åˆ†æ•°

        # ä»äº‹ä»¶å†…å®¹ä¸­æå–æ–‡æœ¬
        content = event.parameters.get("content", "")
        if not content:
            return 0.3

        # è®¡ç®—å…³é”®è¯åŒ¹é…ç‡
        content_lower = content.lower()
        matches = sum(1 for kw in keywords if kw.lower() in content_lower)
        return min(1.0, matches / len(keywords))

    def _fallback_keywords(self, text: str) -> list[str]:
        """æ— å¤–éƒ¨åˆ†è¯å™¨æ—¶çš„ç®€å•å…³é”®è¯æå–ï¼ˆå«ä¸­æ–‡äºŒ/ä¸‰å…ƒç»„ï¼‰"""
        import re

        if not text:
            return []
        words = re.findall(r"\w+", text.lower())
        stopwords = {"the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for"}
        keywords = [w for w in words if w not in stopwords and len(w) > 2]

        if not keywords:
            cjk_sequences = re.findall(r"[\u4e00-\u9fff]+", text)
            cjk_terms: list[str] = []
            for seq in cjk_sequences:
                if len(seq) <= 1:
                    continue
                for i in range(len(seq) - 1):
                    cjk_terms.append(seq[i : i + 2])
                for i in range(len(seq) - 2):
                    cjk_terms.append(seq[i : i + 3])
            keywords = list(dict.fromkeys(cjk_terms))[:20]

        return list(dict.fromkeys(keywords))

    def _calc_node_score(
        self,
        event: Task,
        current_node_id: str | None,
        parent_node_id: str | None,
    ) -> float:
        """è®¡ç®—èŠ‚ç‚¹æƒé‡åˆ†æ•°"""
        event_node_id = event.parameters.get("node_id")

        if not event_node_id:
            return 0.3

        # çˆ¶èŠ‚ç‚¹äº‹ä»¶æƒé‡æœ€é«˜
        if parent_node_id and event_node_id == parent_node_id:
            return 1.0

        # å½“å‰èŠ‚ç‚¹äº‹ä»¶æ¬¡ä¹‹
        if current_node_id and event_node_id == current_node_id:
            return 0.8

        # å…¶ä»–èŠ‚ç‚¹
        return 0.5


# ==================== æ¥å£å®šä¹‰ ====================


class ContextSource(ABC):
    """
    ä¸Šä¸‹æ–‡æºæŠ½è±¡æ¥å£

    å®šä¹‰ä»ä¸åŒæ¥æºè·å–ä¸Šä¸‹æ–‡çš„ç»Ÿä¸€æ¥å£ã€‚
    """

    @abstractmethod
    async def get_context(
        self,
        current_task: Task,
        max_items: int = 10,
    ) -> list[Task]:
        """
        è·å–ä¸Šä¸‹æ–‡ Task åˆ—è¡¨

        Args:
            current_task: å½“å‰ä»»åŠ¡
            max_items: æœ€å¤§è¿”å›æ•°é‡

        Returns:
            ç›¸å…³çš„ Task åˆ—è¡¨
        """
        pass


# ==================== æ¶ˆæ¯è½¬æ¢å™¨ ====================


class MessageConverter:
    """
    Task â†’ LLM Message è½¬æ¢å™¨

    å°†ä¸åŒç±»å‹çš„ Task è½¬æ¢ä¸º LLM API æ¶ˆæ¯æ ¼å¼ã€‚
    """

    def convert_task_to_message(self, task: Task) -> dict[str, str] | None:
        """
        å°†å•ä¸ª Task è½¬æ¢ä¸ºæ¶ˆæ¯

        Args:
            task: Task å¯¹è±¡

        Returns:
            LLM æ¶ˆæ¯å­—å…¸ï¼Œå¦‚æœä¸åº”è¯¥åŒ…å«åˆ™è¿”å› None
        """
        action = task.action
        params = task.parameters

        # æ ¹æ® action ç±»å‹è½¬æ¢
        if action == "node.thinking":
            # æ€è€ƒè¿‡ç¨‹ â†’ assistant æ¶ˆæ¯
            content = params.get("content", "")
            if content:
                return {"role": "assistant", "content": content}

        elif action == "node.tool_call":
            # å·¥å…·è°ƒç”¨ â†’ assistant æ¶ˆæ¯
            tool_name = params.get("tool_name", "")
            tool_args = params.get("tool_args", {})
            return {"role": "assistant", "content": f"[Calling {tool_name}({tool_args})]"}

        elif action == "node.message":
            # èŠ‚ç‚¹æ¶ˆæ¯ â†’ assistant æ¶ˆæ¯
            content = params.get("content") or params.get("message", "")
            if content:
                role = params.get("context_role")
                if role in {"system", "assistant", "user"}:
                    return {"role": role, "content": content}
                return {"role": "assistant", "content": f"[Direct message] {content}"}

        elif action == "node.delegation_request":
            # å§”æ´¾è¯·æ±‚ â†’ assistant æ¶ˆæ¯ï¼ˆé¿å…æ··æ·†ä¸ºç”¨æˆ·æŒ‡ä»¤ï¼‰
            subtask = (
                params.get("subtask")
                or params.get("subtask_description")
                or params.get("content", "")
            )
            source = task.source_agent or params.get("source_agent") or "unknown"
            if subtask:
                return {
                    "role": "assistant",
                    "content": f"[Delegation request from {source}] {subtask}",
                }

        elif action == "node.delegation_response":
            # å§”æ´¾å“åº” â†’ assistant æ¶ˆæ¯
            result = params.get("result") or params.get("content", "")
            source = task.source_agent or params.get("source_agent") or "unknown"
            if result:
                return {
                    "role": "assistant",
                    "content": f"[Delegation response from {source}] {result}",
                }

        elif action == "node.planning":
            # è§„åˆ’äº‹ä»¶ â†’ system æ¶ˆæ¯ï¼ˆä½œä¸ºä¸Šä¸‹æ–‡ï¼Œè®©å­èŠ‚ç‚¹çœ‹åˆ°çˆ¶èŠ‚ç‚¹çš„è®¡åˆ’ï¼‰
            goal = params.get("goal", "")
            steps = params.get("steps", [])
            reasoning = params.get("reasoning", "")
            step_count = params.get("step_count", len(steps))

            if not goal and not steps:
                return None

            content = f"[Parent Plan] Goal: {goal}\n"
            if reasoning:
                content += f"Reasoning: {reasoning}\n"
            content += f"Steps ({step_count}):\n"
            for idx, step in enumerate(steps, 1):
                content += f"  {idx}. {step}\n"

            return {"role": "system", "content": content}

        elif action == "execute":
            # ä»»åŠ¡æ‰§è¡Œ â†’ user æ¶ˆæ¯
            content = params.get("content", "")
            if content:
                return {"role": "user", "content": content}

        # å…¶ä»–ç±»å‹æš‚ä¸è½¬æ¢
        return None

    def convert_tasks_to_messages(
        self,
        tasks: list[Task],
    ) -> list[dict[str, str]]:
        """
        æ‰¹é‡è½¬æ¢ Task ä¸ºæ¶ˆæ¯

        Args:
            tasks: Task åˆ—è¡¨

        Returns:
            æ¶ˆæ¯åˆ—è¡¨
        """
        messages = []
        for task in tasks:
            msg = self.convert_task_to_message(task)
            if msg:
                messages.append(msg)
        return messages


# ==================== ä¸Šä¸‹æ–‡æºå®ç° ====================


class MemoryContextSource(ContextSource):
    """
    ä» LoomMemory è·å–ä¸Šä¸‹æ–‡

    ä¼˜å…ˆçº§ï¼šL2 (å·¥ä½œè®°å¿†) > L1 (æœ€è¿‘ä»»åŠ¡)
    """

    def __init__(self, memory: "LoomMemory"):
        self.memory = memory

    async def get_context(
        self,
        current_task: Task,
        max_items: int = 10,
    ) -> list[Task]:
        """è·å–è®°å¿†ä¸­çš„ç›¸å…³ä»»åŠ¡"""
        # 1. ä¼˜å…ˆä» L2 è·å–ï¼ˆé‡è¦ä»»åŠ¡ï¼‰
        l2_tasks = self.memory.get_l2_tasks(
            limit=max_items // 2, session_id=current_task.session_id
        )

        # 2. ä» L1 è·å–æœ€è¿‘ä»»åŠ¡
        l1_tasks = self.memory.get_l1_tasks(
            limit=max_items // 2, session_id=current_task.session_id
        )

        # 3. åˆå¹¶å»é‡
        seen_ids = set()
        context_tasks = []

        for task in l2_tasks + l1_tasks:
            if task.task_id not in seen_ids:
                context_tasks.append(task)
                seen_ids.add(task.task_id)

        return context_tasks[:max_items]


class FractalMemoryContextSource(ContextSource):
    """
    ä» FractalMemory è·å–è·¨èŠ‚ç‚¹å…±äº«ä¸Šä¸‹æ–‡

    è¯»å– INHERITED / SHARED / GLOBAL ä½œç”¨åŸŸï¼Œæ³¨å…¥ä¸ºç³»ç»Ÿæ¶ˆæ¯ã€‚
    """

    def __init__(
        self,
        fractal_memory: "FractalMemory",
        scopes: list["MemoryScope"] | None = None,
        max_items: int = 6,
        include_additional: bool = True,
        max_additional: int = 4,
    ):
        self.fractal_memory = fractal_memory
        self.scopes = scopes or []
        self.max_items = max_items
        self.include_additional = include_additional
        self.max_additional = max_additional

        if not self.scopes:
            from loom.fractal.memory import MemoryScope

            self.scopes = [MemoryScope.INHERITED, MemoryScope.SHARED, MemoryScope.GLOBAL]

    async def get_context(
        self,
        current_task: Task,
        max_items: int = 10,
    ) -> list[Task]:
        limit = min(max_items, self.max_items)
        entries: list[tuple[str, str]] = []  # (label, entry_id)

        root_context_id = current_task.parameters.get("root_context_id")
        root_content = ""
        if root_context_id:
            entries.append(("ROOT GOAL", root_context_id))
            root_entry = await self.fractal_memory.read(root_context_id)
            if root_entry and root_entry.content:
                root_content = str(root_entry.content)

        parent_task_id = current_task.parameters.get("parent_task_id")
        parent_content = ""
        if parent_task_id:
            entries.append(("PARENT TASK", f"task:{parent_task_id}:content"))
            parent_entry = await self.fractal_memory.read(f"task:{parent_task_id}:content")
            if parent_entry and parent_entry.content:
                parent_content = str(parent_entry.content)

        tasks: list[Task] = []
        seen_ids: set[str] = set()

        async def _append_entry(label: str, entry_id: str) -> None:
            if entry_id in seen_ids:
                return
            entry = await self.fractal_memory.read(entry_id)
            if not entry:
                return
            content = entry.content
            if content is None or content == "":
                return
            seen_ids.add(entry_id)
            scope_label = entry.scope.value if hasattr(entry, "scope") else "shared"
            if label == "ROOT GOAL":
                message = f"[ROOT GOAL - MUST FOLLOW] {content}"
            elif label == "PARENT TASK":
                message = f"[PARENT TASK - MUST ALIGN] {content}"
            else:
                message = f"[{label}] {content}"
            tasks.append(
                Task(
                    task_id=f"fractal:{entry_id}",
                    action="node.message",
                    parameters={
                        "content": message,
                        "context_role": "system",
                        "memory_id": entry_id,
                        "scope": scope_label,
                        "label": label,
                    },
                    session_id=current_task.session_id,
                )
            )

        # High priority: root goal + parent task
        for label, entry_id in entries:
            if len(tasks) >= limit:
                break
            await _append_entry(label, entry_id)

        # Optional: include additional shared/inherited/global context (ranked)
        if self.include_additional and len(tasks) < limit:
            content = current_task.parameters.get("content", "") or current_task.action
            query_text = " ".join(part for part in [root_content, parent_content, str(content)] if part)
            keywords = self._extract_keywords(query_text)
            candidates: list[tuple[float, Any]] = []

            for scope in self.scopes:
                scope_entries = await self.fractal_memory.list_by_scope(scope)
                for entry in scope_entries:
                    if entry.id in seen_ids:
                        continue
                    entry_content = str(entry.content or "")
                    if not entry_content:
                        continue
                    score = self._score_entry(entry_content, keywords, entry.scope)
                    candidates.append((score, entry))

            # Rank within scopes
            by_scope: dict[str, list[tuple[float, Any]]] = {"shared": [], "inherited": [], "global": []}
            for score, entry in candidates:
                scope_key = entry.scope.value if hasattr(entry, "scope") else "shared"
                by_scope.setdefault(scope_key, []).append((score, entry))

            for scope_key in by_scope:
                by_scope[scope_key].sort(key=lambda x: x[0], reverse=True)

            remaining = min(limit - len(tasks), self.max_additional)
            if remaining > 0:
                # Per-scope caps to balance signal vs. noise
                weights = [("shared", 0.5), ("inherited", 0.3), ("global", 0.2)]
                caps: dict[str, int] = {}
                used = 0
                for scope_key, weight in weights:
                    cap = int(remaining * weight)
                    cap = min(cap, len(by_scope.get(scope_key, [])))
                    caps[scope_key] = cap
                    used += cap

                # Distribute leftover slots by priority
                leftover = remaining - used
                if leftover > 0:
                    for scope_key, _ in weights:
                        if leftover <= 0:
                            break
                        available = len(by_scope.get(scope_key, [])) - caps.get(scope_key, 0)
                        if available <= 0:
                            continue
                        take = min(available, leftover)
                        caps[scope_key] = caps.get(scope_key, 0) + take
                        leftover -= take

                for scope_key, _ in weights:
                    for _, entry in by_scope.get(scope_key, [])[: caps.get(scope_key, 0)]:
                        await _append_entry(entry.scope.value.upper(), entry.id)

        return tasks

    def _extract_keywords(self, text: str) -> set[str]:
        import re

        if not text:
            return set()
        words = re.findall(r"\w+", text.lower())
        stopwords = {"the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for"}
        return {w for w in words if w not in stopwords and len(w) > 2}

    def _score_entry(
        self,
        content: str,
        keywords: set[str],
        scope: "MemoryScope",
    ) -> float:
        scope_weights = {
            "shared": 1.0,
            "inherited": 0.9,
            "global": 0.7,
        }
        scope_weight = scope_weights.get(scope.value, 0.8)

        if not keywords:
            return scope_weight

        content_lower = content.lower()
        hits = sum(1 for kw in keywords if kw in content_lower)
        overlap = hits / max(len(keywords), 1)

        # Penalize overly long entries to avoid bloating context
        length_penalty = 0.0
        if len(content) > 400:
            length_penalty = min(0.2, (len(content) - 400) / 2000)

        return (0.7 * overlap) + (0.3 * scope_weight) - length_penalty




# ==================== æ ¸å¿ƒç®¡ç†å™¨ ====================


class TaskContextManager:
    """
    åŸºäº Task çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨

    æ•´åˆ LoomMemory å’Œ EventBusï¼Œæä¾›æ™ºèƒ½çš„ä¸Šä¸‹æ–‡æ„å»ºã€‚
    """

    def __init__(
        self,
        token_counter: TokenCounter,
        sources: list[ContextSource],
        converter: MessageConverter | None = None,
        max_tokens: int = 4000,
        system_prompt: str = "",
        knowledge_base: "KnowledgeBaseProvider | None" = None,
        node_id: str | None = None,
        budgeter: ContextBudgeter | None = None,
        budget_config: BudgetConfig | dict[str, float | int] | None = None,
    ):
        """åˆå§‹åŒ–ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        self.token_counter = token_counter
        self.sources = sources
        self.converter = converter or MessageConverter()
        self.max_tokens = max_tokens
        self.system_prompt = system_prompt
        self.knowledge_base = knowledge_base
        self.node_id = node_id
        if budgeter:
            self.budgeter = budgeter
        else:
            config = budget_config
            if isinstance(config, dict):
                config = BudgetConfig(**cast(dict[str, Any], config))
            self.budgeter = ContextBudgeter(token_counter, max_tokens=max_tokens, config=config)






    async def build_context(
        self,
        current_task: Task,
    ) -> list[dict[str, str]]:
        """
        æ„å»º LLM ä¸Šä¸‹æ–‡ï¼ˆç®€åŒ–ç‰ˆ - åªä» Memory è·å–ï¼‰

        åŸºäº A4 å…¬ç†ï¼ˆè®°å¿†å±‚æ¬¡å…¬ç†ï¼‰ï¼š
        - åªä» Memory çš„ L1/L2 è·å–æ•°æ®
        - æŒ‰ session_id è¿‡æ»¤
        - è½¬æ¢ä¸º LLM æ¶ˆæ¯
        - Token é¢„ç®—æ§åˆ¶

        Args:
            current_task: å½“å‰æ­£åœ¨å¤„ç†çš„ä»»åŠ¡

        Returns:
            OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        """
        # 1. è®¡ç®—é¢„ç®—åˆ†é…
        system_tokens = (
            self.token_counter.count_messages([{"role": "system", "content": self.system_prompt}])
            if self.system_prompt
            else 0
        )
        allocation = self.budgeter.allocate_budget(system_prompt_tokens=system_tokens)

        # 2. ä» Memory è·å–ä¸Šä¸‹æ–‡ï¼ˆåªæŸ¥è¯¢ Memoryï¼Œä¸æŸ¥è¯¢ EventBusï¼‰
        context_tasks: list[Task] = []
        for source in self.sources:
            tasks = await source.get_context(current_task, max_items=20)
            context_tasks.extend(tasks)

        # 3. æŒ‰ session_id è¿‡æ»¤
        if current_task.session_id:
            context_tasks = [t for t in context_tasks if t.session_id == current_task.session_id]

        # 4. å»é‡
        seen_ids = set()
        unique_tasks = []
        for task in context_tasks:
            if task.task_id not in seen_ids:
                unique_tasks.append(task)
                seen_ids.add(task.task_id)

        # 5. è½¬æ¢ä¸º LLM æ¶ˆæ¯
        context_messages = self.converter.convert_tasks_to_messages(unique_tasks)

        # 6. å¤–éƒ¨çŸ¥è¯†åº“æŸ¥è¯¢ï¼ˆå¯é€‰ï¼‰
        knowledge_messages: list[dict[str, str]] = []
        if self.knowledge_base:
            query = current_task.action
            knowledge_items = await self.knowledge_base.query(query, limit=3)
            for item in knowledge_items:
                knowledge_messages.append(
                    {
                        "role": "system",
                        "content": f"ğŸ“š Knowledge: {item.content}\n(Source: {item.source})",
                    }
                )

        # 7. æ·»åŠ å½“å‰ä»»åŠ¡
        current_task_messages = self.converter.convert_tasks_to_messages([current_task])

        # 8. åˆå¹¶æ¶ˆæ¯
        final_messages: list[dict[str, str]] = []
        if self.system_prompt:
            final_messages.append({"role": "system", "content": self.system_prompt})

        final_messages.extend(context_messages)
        final_messages.extend(knowledge_messages)
        final_messages.extend(current_task_messages)

        # 9. Token é™åˆ¶å¤„ç†
        return self._fit_to_token_limit(final_messages)

    def _fit_to_token_limit(self, messages: list[dict[str, str]]) -> list[dict[str, str]]:
        """
        ç¡®ä¿æ¶ˆæ¯åˆ—è¡¨ä¸è¶…è¿‡ token é™åˆ¶

        ç­–ç•¥ï¼š
        1. å§‹ç»ˆä¿ç•™æ‰€æœ‰å¼€å¤´çš„ System Messages
        2. å§‹ç»ˆä¿ç•™æœ€å N æ¡æ¶ˆæ¯ (Recent)
        3. å¦‚æœè¶…å‡ºï¼Œä¸¢å¼ƒä¸­é—´çš„æ¶ˆæ¯
        """
        current_tokens = self.token_counter.count_messages(messages)
        if current_tokens <= self.max_tokens:
            return messages

        # åˆ†ç¦»å¼€å¤´çš„ System æ¶ˆæ¯
        system_messages: list[dict[str, str]] = []
        idx = 0
        while idx < len(messages) and messages[idx].get("role") == "system":
            system_messages.append(messages[idx])
            idx += 1
        other_messages = messages[idx:]

        # è®¡ç®— System token
        system_tokens = self.token_counter.count_messages(system_messages) if system_messages else 0
        available_tokens = self.max_tokens - system_tokens

        if available_tokens <= 0:
            # æç«¯æƒ…å†µï¼šç³»ç»Ÿæç¤ºè¯éƒ½æ”¾ä¸ä¸‹ï¼Œåªè¿”å› System Message
            return system_messages if system_messages else []

        # ä»åå¾€å‰æ·»åŠ ï¼Œç›´åˆ°å¡«æ»¡
        kept_messages: list[dict[str, str]] = []
        current_count = 0

        for msg in reversed(other_messages):
            msg_tokens = self.token_counter.count_messages([msg])
            if current_count + msg_tokens > available_tokens:
                break
            kept_messages.insert(0, msg)
            current_count += msg_tokens

        if system_messages:
            return system_messages + kept_messages
        return kept_messages
