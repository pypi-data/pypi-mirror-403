{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Drift Detection with IBM Qiskit Runtime\n",
    "\n",
    "This notebook demonstrates **production monitoring and drift detection** workflows.\n",
    "\n",
    "We:\n",
    "1. Build a **calibration-sensitive benchmark circuit**\n",
    "2. Establish a **baseline** run (your \"known-good\" reference)\n",
    "3. Execute **candidate** runs under different conditions\n",
    "4. Use devqubit to:\n",
    "   - capture artifacts and device snapshots\n",
    "   - compute distribution distance (**TVD**)\n",
    "   - enforce a **VerifyPolicy** (CI/CD-style)\n",
    "   - generate a **JUnit** report\n",
    "\n",
    "> We use **FakeManilaV2** (local testing mode, no IBM credentials needed).  \n",
    "> In production, point the same code at a real backend/session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import entry_points\n",
    "\n",
    "if not any(\n",
    "    ep.name == \"qiskit-runtime\" for ep in entry_points(group=\"devqubit.adapters\")\n",
    "):\n",
    "    raise ImportError(\n",
    "        \"devqubit Qiskit Runtime adapter is not installed.\\n\"\n",
    "        \"Install with: pip install 'devqubit[qiskit-runtime]'\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Qiskit Runtime adapter available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit_ibm_runtime import SamplerV2\n",
    "from qiskit_ibm_runtime.fake_provider import FakeManilaV2\n",
    "\n",
    "# Check for Aer (optional, enables drift simulation)\n",
    "try:\n",
    "    from qiskit_aer import AerSimulator\n",
    "    from qiskit_aer.noise import NoiseModel, depolarizing_error\n",
    "\n",
    "    AER_AVAILABLE = True\n",
    "except ImportError:\n",
    "    AER_AVAILABLE = False\n",
    "\n",
    "from devqubit import Config, set_config, track\n",
    "from devqubit.compare import diff, verify_baseline, VerifyPolicy\n",
    "from devqubit.runs import set_baseline, load_run, get_baseline, list_runs\n",
    "from devqubit.ci import write_junit\n",
    "\n",
    "print(f\"Aer available: {AER_AVAILABLE} (needed for calibration drift simulation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-description",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Configuration for drift detection:\n",
    "\n",
    "| Parameter | Value | Purpose |\n",
    "|-----------|-------|--------|\n",
    "| `SHOTS_BASELINE` | 4096 | High precision for reference |\n",
    "| `TVD_THRESHOLD` | 0.03 | Maximum allowed distribution drift |\n",
    "| `DRIFT_DEPOL_1Q` | 0.01 | 1-qubit depolarizing error for drift simulation |\n",
    "| `DRIFT_DEPOL_2Q` | 0.03 | 2-qubit depolarizing error for drift simulation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PROJECT = \"production_monitoring\"\n",
    "N_QUBITS = 3\n",
    "OPTIMIZATION_LEVEL = 2\n",
    "SEED = 42\n",
    "\n",
    "# Shots for different scenarios\n",
    "SHOTS_BASELINE = 4096\n",
    "SHOTS_LOW = 256\n",
    "SHOTS_HIGH = 8192\n",
    "\n",
    "# Drift detection threshold\n",
    "TVD_THRESHOLD = 0.03\n",
    "\n",
    "# Drift simulation parameters (for Aer)\n",
    "DRIFT_DEPOL_1Q = 0.01\n",
    "DRIFT_DEPOL_2Q = 0.03\n",
    "\n",
    "# Workspace\n",
    "WORKSPACE = Path(\".devqubit_drift_demo\")\n",
    "if WORKSPACE.exists():\n",
    "    shutil.rmtree(WORKSPACE)\n",
    "WORKSPACE.mkdir(parents=True)\n",
    "\n",
    "set_config(Config(root_dir=WORKSPACE))\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Backend (local testing mode)\n",
    "fake_backend = FakeManilaV2()\n",
    "print(f\"Backend: {fake_backend.name} ({fake_backend.num_qubits} qubits)\")\n",
    "print(f\"TVD threshold: {TVD_THRESHOLD:.1%}\")\n",
    "print(f\"Workspace: {WORKSPACE.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Benchmark Circuit\n",
    "\n",
    "We design a **calibration-sensitive benchmark** that responds to:\n",
    "- Gate errors (RX, RZ rotations)\n",
    "- Crosstalk (CNOT gates)\n",
    "- Readout errors (measurement)\n",
    "\n",
    "The output distribution becomes our \"health signal\" over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_benchmark_circuit(n_qubits: int) -> QuantumCircuit:\n",
    "    \"\"\"Create a calibration-sensitive benchmark circuit.\"\"\"\n",
    "    qc = QuantumCircuit(n_qubits, name=\"calibration_benchmark\")\n",
    "\n",
    "    # Layer 1: superposition\n",
    "    for q in range(n_qubits):\n",
    "        qc.h(q)\n",
    "\n",
    "    # Layer 2: entanglement chain\n",
    "    for q in range(n_qubits - 1):\n",
    "        qc.cx(q, q + 1)\n",
    "\n",
    "    # Layer 3: rotations (gate-error sensitive)\n",
    "    for q in range(n_qubits):\n",
    "        qc.rz(np.pi / 4, q)\n",
    "        qc.rx(np.pi / 3, q)\n",
    "\n",
    "    # Layer 4: more entanglement (depth)\n",
    "    for q in range(n_qubits - 1):\n",
    "        qc.cx(q, q + 1)\n",
    "\n",
    "    qc.measure_all()\n",
    "    return qc\n",
    "\n",
    "\n",
    "def concentration_topk(counts: dict, k: int = 3) -> float:\n",
    "    \"\"\"Fraction of probability in top-k outcomes.\"\"\"\n",
    "    total = sum(counts.values())\n",
    "    top = sorted(counts.values(), reverse=True)[:k]\n",
    "    return sum(top) / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "def shannon_entropy(counts: dict) -> float:\n",
    "    \"\"\"Shannon entropy in bits.\"\"\"\n",
    "    total = sum(counts.values())\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    probs = np.array(list(counts.values())) / total\n",
    "    return float(-np.sum(probs * np.log2(probs + 1e-12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transpile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and transpile circuit once\n",
    "circuit = create_benchmark_circuit(N_QUBITS)\n",
    "print(\"Original circuit:\")\n",
    "print(circuit.draw())\n",
    "\n",
    "pm = generate_preset_pass_manager(\n",
    "    backend=fake_backend,\n",
    "    optimization_level=OPTIMIZATION_LEVEL,\n",
    ")\n",
    "circuit_isa = pm.run(circuit)\n",
    "\n",
    "print(\"\\nTranspiled (ISA) circuit:\")\n",
    "print(circuit_isa.draw(fold=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-transpilation",
   "metadata": {},
   "source": [
    "### Transpilation in devqubit\n",
    "\n",
    "**Qiskit Runtime V2 primitives require ISA-compatible circuits** - they do not perform layout, routing, or translation internally.\n",
    "\n",
    "devqubit handles this automatically with three transpilation modes:\n",
    "\n",
    "| Mode | Behavior |\n",
    "|------|----------|\n",
    "| `'auto'` (default) | Transpile only if circuit is not ISA-compatible |\n",
    "| `'managed'` | Always transpile through devqubit |\n",
    "| `'manual'` | Never transpile (user is responsible) |\n",
    "\n",
    "**How it works:** When you call `run.wrap(sampler)`, devqubit checks if each circuit is ISA-compatible with the backend target. If not (in `'auto'` or `'managed'` mode), it transpiles using `generate_preset_pass_manager`.\n",
    "\n",
    "**In this notebook:** We transpile manually to show the ISA circuit for educational purposes. devqubit will detect that the circuit is already ISA-compatible and skip re-transpilation.\n",
    "\n",
    "```python\n",
    "# Option A: Manual transpilation (what we do here)\n",
    "circuit_isa = pm.run(circuit)\n",
    "job = tracked_sampler.run([circuit_isa])\n",
    "\n",
    "# Option B: Let devqubit transpile (simpler)\n",
    "job = tracked_sampler.run([circuit])  # devqubit transpiles in 'auto' mode\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Establish Baseline\n",
    "\n",
    "A baseline is the \"known-good\" distribution we compare against later.\n",
    "\n",
    "**Important:** We use `run.wrap()` to track the sampler execution. This captures:\n",
    "- Circuit artifacts\n",
    "- Device snapshot\n",
    "- Execution metadata\n",
    "- Result counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sampler(mode, shots: int) -> SamplerV2:\n",
    "    \"\"\"Create a SamplerV2 with specified shot budget.\"\"\"\n",
    "    sampler = SamplerV2(mode=mode)\n",
    "    sampler.options.default_shots = shots\n",
    "    return sampler\n",
    "\n",
    "\n",
    "def run_benchmark(\n",
    "    *,\n",
    "    project: str,\n",
    "    sampler: SamplerV2,\n",
    "    circuit: QuantumCircuit,\n",
    "    params: dict,\n",
    "    tags: dict,\n",
    ") -> str:\n",
    "    \"\"\"Execute benchmark with full devqubit tracking.\"\"\"\n",
    "\n",
    "    with track(project=project) as run:\n",
    "        # Wrap the sampler to capture execution context\n",
    "        tracked_sampler = run.wrap(sampler)\n",
    "\n",
    "        run.log_params(params)\n",
    "        run.set_tags(tags)\n",
    "\n",
    "        # Execute via tracked sampler\n",
    "        job = tracked_sampler.run([circuit], devqubit_transpilation_mode=\"manual\")\n",
    "        pub_result = job.result()[0]\n",
    "        counts = pub_result.data.meas.get_counts()\n",
    "\n",
    "        # Log distribution metrics\n",
    "        run.log_metrics(\n",
    "            {\n",
    "                \"concentration_top3\": concentration_topk(counts, k=3),\n",
    "                \"unique_outcomes\": len(counts),\n",
    "                \"entropy_bits\": shannon_entropy(counts),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return run.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_sampler = make_sampler(mode=fake_backend, shots=SHOTS_BASELINE)\n",
    "\n",
    "baseline_id = run_benchmark(\n",
    "    project=PROJECT,\n",
    "    sampler=baseline_sampler,\n",
    "    circuit=circuit_isa,\n",
    "    params={\n",
    "        \"circuit_name\": \"calibration_benchmark\",\n",
    "        \"n_qubits\": N_QUBITS,\n",
    "        \"shots\": SHOTS_BASELINE,\n",
    "        \"optimization_level\": OPTIMIZATION_LEVEL,\n",
    "        \"backend\": fake_backend.name,\n",
    "    },\n",
    "    tags={\"role\": \"baseline\", \"scenario\": \"reference\"},\n",
    ")\n",
    "\n",
    "# Register as project baseline\n",
    "set_baseline(PROJECT, baseline_id)\n",
    "print(f\"Baseline run set: {baseline_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "### 3. Inspect Device Snapshot & Fingerprints\n",
    "\n",
    "devqubit captures a **device snapshot** that helps answer:\n",
    "- Did the hardware configuration/calibration change between runs?\n",
    "- Is this the same circuit structure?\n",
    "\n",
    "**Fingerprints** enable fast comparison without loading full artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inspect-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_rec = load_run(baseline_id)\n",
    "\n",
    "print(\"Device Snapshot\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "device_snap = baseline_rec.record.get(\"device_snapshot\", {})\n",
    "if device_snap:\n",
    "    print(f\"Backend:     {device_snap.get('backend_name')}\")\n",
    "    print(f\"Captured at: {device_snap.get('captured_at', 'N/A')[:19]}\")\n",
    "    print(f\"Qubits:      {device_snap.get('num_qubits')}\")\n",
    "\n",
    "    cal = device_snap.get(\"calibration\", {})\n",
    "    if cal:\n",
    "        print(\"\\nCalibration summary (median):\")\n",
    "        for key in (\"t1_us\", \"t2_us\", \"readout_error\"):\n",
    "            if key in cal:\n",
    "                print(f\"  {key:>14s}: {cal[key].get('median', 'N/A')}\")\n",
    "else:\n",
    "    print(\"(Device snapshot not available for this backend)\")\n",
    "\n",
    "print(\"\\nFingerprints:\")\n",
    "for key, value in baseline_rec.fingerprints.items():\n",
    "    print(f\"  {key}: {value[:48]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "### 4. Candidate Runs (Production Scenarios)\n",
    "\n",
    "We run the same circuit under different conditions:\n",
    "\n",
    "| Scenario | Shots | Backend | Expected Result |\n",
    "|----------|-------|---------|----------------|\n",
    "| `low_shots` | 256 | FakeManila | Higher TVD (shot noise) |\n",
    "| `stable` | 4096 | FakeManila | Should pass |\n",
    "| `high_shots` | 8192 | FakeManila | Lower TVD |\n",
    "| `calibration_drift` | 4096 | Aer + noise | Should fail (drift) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drift-backend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_drift_backend(depol_1q: float, depol_2q: float, seed: int):\n",
    "    \"\"\"Create Aer backend with extra depolarizing noise (drift simulation).\"\"\"\n",
    "    if not AER_AVAILABLE:\n",
    "        return None\n",
    "\n",
    "    noise_model = NoiseModel()\n",
    "\n",
    "    # IBM basis gates after transpilation\n",
    "    noise_model.add_all_qubit_quantum_error(\n",
    "        depolarizing_error(depol_1q, 1), [\"rz\", \"sx\", \"x\", \"id\"]\n",
    "    )\n",
    "    noise_model.add_all_qubit_quantum_error(depolarizing_error(depol_2q, 2), [\"cx\"])\n",
    "\n",
    "    return AerSimulator(noise_model=noise_model, seed_simulator=seed)\n",
    "\n",
    "\n",
    "# Build scenarios\n",
    "scenarios = [\n",
    "    {\n",
    "        \"name\": \"low_shots\",\n",
    "        \"desc\": \"Reduced shot budget\",\n",
    "        \"shots\": SHOTS_LOW,\n",
    "        \"mode\": fake_backend,\n",
    "        \"backend_name\": fake_backend.name,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"stable\",\n",
    "        \"desc\": \"Normal operation\",\n",
    "        \"shots\": SHOTS_BASELINE,\n",
    "        \"mode\": fake_backend,\n",
    "        \"backend_name\": fake_backend.name,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"high_shots\",\n",
    "        \"desc\": \"Higher precision run\",\n",
    "        \"shots\": SHOTS_HIGH,\n",
    "        \"mode\": fake_backend,\n",
    "        \"backend_name\": fake_backend.name,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Add drift scenario if Aer available\n",
    "drift_backend = make_drift_backend(DRIFT_DEPOL_1Q, DRIFT_DEPOL_2Q, SEED)\n",
    "if drift_backend:\n",
    "    scenarios.append(\n",
    "        {\n",
    "            \"name\": \"calibration_drift\",\n",
    "            \"desc\": \"Simulated calibration degradation (Aer noise)\",\n",
    "            \"shots\": SHOTS_BASELINE,\n",
    "            \"mode\": drift_backend,\n",
    "            \"backend_name\": \"aer_simulator\",\n",
    "        }\n",
    "    )\n",
    "    print(\"Added Aer-based drift scenario.\")\n",
    "else:\n",
    "    print(\"Drift scenario skipped (qiskit-aer not installed).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "candidates",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_ids = []\n",
    "\n",
    "print(\"\\nExecuting production scenarios...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for sc in scenarios:\n",
    "    sampler = make_sampler(mode=sc[\"mode\"], shots=sc[\"shots\"])\n",
    "\n",
    "    run_id = run_benchmark(\n",
    "        project=PROJECT,\n",
    "        sampler=sampler,\n",
    "        circuit=circuit_isa,\n",
    "        params={\n",
    "            \"circuit_name\": \"calibration_benchmark\",\n",
    "            \"n_qubits\": N_QUBITS,\n",
    "            \"shots\": sc[\"shots\"],\n",
    "            \"optimization_level\": OPTIMIZATION_LEVEL,\n",
    "            \"backend\": sc[\"backend_name\"],\n",
    "            \"scenario_description\": sc[\"desc\"],\n",
    "        },\n",
    "        tags={\"role\": \"candidate\", \"scenario\": sc[\"name\"]},\n",
    "    )\n",
    "\n",
    "    candidate_ids.append({\"name\": sc[\"name\"], \"run_id\": run_id})\n",
    "    print(f\"{sc['name']:>18s} -> {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "### 5. Drift Analysis (TVD)\n",
    "\n",
    "**Total Variation Distance** measures how different two distributions are:\n",
    "\n",
    "$\\text{TVD}(P, Q) = \\frac{1}{2} \\sum_x |P(x) - Q(x)|$\n",
    "\n",
    "| TVD | Interpretation |\n",
    "|-----|---------------|\n",
    "| 0.00 | Identical distributions |\n",
    "| 0.01-0.02 | Expected shot noise |\n",
    "| 0.03-0.05 | Investigate |\n",
    "| > 0.05 | Significant drift |\n",
    "\n",
    "devqubit computes TVD automatically in `diff()` and `verify_baseline()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drift-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Drift Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Threshold: TVD ≤ {TVD_THRESHOLD:.1%}\\n\")\n",
    "\n",
    "for cand in candidate_ids:\n",
    "    comp = diff(baseline_id, cand[\"run_id\"])\n",
    "\n",
    "    sc = load_run(cand[\"run_id\"]).tags.get(\"scenario\", \"?\")\n",
    "    tvd = comp.tvd\n",
    "\n",
    "    if tvd is None:\n",
    "        print(f\"{sc:>18s}: TVD not available\")\n",
    "        continue\n",
    "\n",
    "    status = \"[OK] OK\" if tvd <= TVD_THRESHOLD else \"[!] DRIFT\"\n",
    "    print(f\"{sc:>18s}: TVD = {tvd:.4f}  {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "### 6. CI/CD Verification (Policy)\n",
    "\n",
    "In pipelines you want **automated pass/fail**. Define a `VerifyPolicy`:\n",
    "\n",
    "```python\n",
    "# Example CI usage:\n",
    "result = verify_baseline(candidate_id, project=PROJECT, policy=policy)\n",
    "assert result.ok, f\"Drift detected: {result.failures}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_policy = VerifyPolicy(\n",
    "    params_must_match=False,  # Allow different shot counts\n",
    "    program_must_match=True,  # Same circuit required\n",
    "    fingerprint_must_match=False,  # Hardware snapshots can change\n",
    "    tvd_max=TVD_THRESHOLD,\n",
    ")\n",
    "\n",
    "print(\"CI/CD Verification\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "verification_results = []\n",
    "\n",
    "for cand in candidate_ids:\n",
    "    candidate_rec = load_run(cand[\"run_id\"])\n",
    "    sc = candidate_rec.tags.get(\"scenario\", \"?\")\n",
    "\n",
    "    result = verify_baseline(\n",
    "        candidate=candidate_rec,\n",
    "        project=PROJECT,\n",
    "        policy=production_policy,\n",
    "    )\n",
    "\n",
    "    verification_results.append({\"name\": sc, \"result\": result})\n",
    "\n",
    "    status = \"[OK] PASSED\" if result.ok else \"[X] FAILED\"\n",
    "    print(f\"\\n{sc}: {status}\")\n",
    "\n",
    "    if not result.ok:\n",
    "        for failure in result.failures:\n",
    "            print(f\"  └─ {failure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "### 7. JUnit Report\n",
    "\n",
    "Export to JUnit XML for CI systems (Jenkins, GitHub Actions, GitLab CI, Azure DevOps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the last scenario's result\n",
    "last_result = verification_results[-1][\"result\"]\n",
    "\n",
    "junit_path = WORKSPACE / \"test-results.xml\"\n",
    "write_junit(last_result, junit_path)\n",
    "\n",
    "print(f\"JUnit report written to: {junit_path}\")\n",
    "print(\"\\n--- test-results.xml ---\")\n",
    "print(junit_path.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "### 8. Detailed Comparison\n",
    "\n",
    "When something fails, get a human-readable diff for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-diff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline vs. last candidate\n",
    "last_candidate_id = candidate_ids[-1][\"run_id\"]\n",
    "comparison = diff(baseline_id, last_candidate_id)\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9",
   "metadata": {},
   "source": [
    "### 9. Monitoring Dashboard\n",
    "\n",
    "A simple dashboard pulling all runs from the registry and verifying against baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dashboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = list_runs(project=PROJECT)\n",
    "baseline_info = get_baseline(PROJECT)\n",
    "\n",
    "print(\"Production Monitoring Dashboard\")\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"Baseline: {baseline_info['run_id'][:16]}... (set: {baseline_info['set_at'][:10]})\"\n",
    ")\n",
    "print(f\"Policy: TVD ≤ {TVD_THRESHOLD:.1%}\\n\")\n",
    "\n",
    "print(\n",
    "    f\"{'Run ID':<18} {'Role':<10} {'Scenario':<18} {'Entropy':>8} {'TVD':>8} {'Status':>8}\"\n",
    ")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for run_info in all_runs:\n",
    "    rec = load_run(run_info[\"run_id\"])\n",
    "    role = rec.tags.get(\"role\", \"N/A\")\n",
    "    scenario = rec.tags.get(\"scenario\", \"-\")\n",
    "    entropy = rec.metrics.get(\"entropy_bits\", 0.0)\n",
    "\n",
    "    if role == \"candidate\":\n",
    "        v = verify_baseline(candidate=rec, project=PROJECT, policy=production_policy)\n",
    "        comp = diff(baseline_id, rec.run_id)\n",
    "        tvd_str = f\"{comp.tvd:.4f}\" if comp.tvd else \"N/A\"\n",
    "        status = \"[OK]\" if v.ok else \"[!]\"\n",
    "    else:\n",
    "        tvd_str = \"-\"\n",
    "        status = \"REF\"\n",
    "\n",
    "    print(\n",
    "        f\"{rec.run_id[:16]:<18} {role:<10} {scenario:<18} {entropy:>8.3f} {tvd_str:>8} {status:>8}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|--------|\n",
    "| **Benchmark circuit** | Calibration-sensitive health signal |\n",
    "| **Transpilation** | devqubit auto-transpiles non-ISA circuits (or use manual) |\n",
    "| **run.wrap()** | Capture execution context automatically |\n",
    "| **Device snapshot** | Track hardware/calibration changes |\n",
    "| **Fingerprints** | Fast comparison without full data |\n",
    "| **TVD analysis** | Quantify distribution drift |\n",
    "| **VerifyPolicy** | Automated pass/fail for CI/CD |\n",
    "| **JUnit export** | Integration with CI systems |\n",
    "\n",
    "**Key insight:** The `calibration_drift` scenario shows real drift detection — extra depolarizing noise changes the distribution enough to exceed our threshold, triggering a verification failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(WORKSPACE)\n",
    "print(f\"Workspace cleaned up: {WORKSPACE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142db2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
