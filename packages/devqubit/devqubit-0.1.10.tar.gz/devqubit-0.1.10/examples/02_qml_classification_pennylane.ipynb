{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Quantum Machine Learning with PennyLane\n",
    "\n",
    "This notebook demonstrates devqubit tracking for **QML classification experiments**.\n",
    "\n",
    "**What you'll see:**\n",
    "- Two encoding architectures: **Angle Encoding** vs **IQP Encoding**\n",
    "- Training curves (loss, accuracy)\n",
    "- Architecture comparison with bar chart\n",
    "- Decision boundary visualization\n",
    "\n",
    "**The problem:** Binary classification of 2D points (inside vs outside a circle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import entry_points\n",
    "\n",
    "if not any(ep.name == \"pennylane\" for ep in entry_points(group=\"devqubit.adapters\")):\n",
    "    raise ImportError(\n",
    "        \"devqubit Pennylane adapter is not installed.\\n\"\n",
    "        \"Install with: pip install 'devqubit[pennylane]'\"\n",
    "    )\n",
    "else:\n",
    "    print(\"PennyLane adapter available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "\n",
    "from devqubit import Config, set_config, track\n",
    "from devqubit.compare import diff\n",
    "from devqubit.runs import load_run, list_groups, list_runs_in_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-description",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "We use 3-qubit variational classifiers with two encoding strategies:\n",
    "\n",
    "| Architecture | Encoding | Variational Part |\n",
    "|--------------|----------|------------------|\n",
    "| **Angle Encoding** | RY/RZ rotations (data re-uploading) | Rot gates per layer |\n",
    "| **IQP Encoding** | Hadamard + RZ + IsingZZ interactions | StronglyEntanglingLayers |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PROJECT = \"qml_classification\"\n",
    "N_QUBITS = 3\n",
    "N_SAMPLES = 500\n",
    "N_EPOCHS = 50\n",
    "LR = 0.3\n",
    "SEED = 42\n",
    "\n",
    "# Workspace\n",
    "WORKSPACE = Path(\".devqubit_qml_demo\")\n",
    "if WORKSPACE.exists():\n",
    "    shutil.rmtree(WORKSPACE)\n",
    "\n",
    "set_config(Config(root_dir=WORKSPACE))\n",
    "\n",
    "np.random.seed(SEED)\n",
    "pnp.random.seed(SEED)\n",
    "print(f\"Workspace: {WORKSPACE.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "### 1. Dataset: Circle Classification\n",
    "\n",
    "Binary classification of 2D points:\n",
    "- **Class 0**: outside circle (radius > 0.5)\n",
    "- **Class 1**: inside circle (radius < 0.5)\n",
    "\n",
    "This is a classic non-linear classification problem that quantum classifiers can handle well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_circle_data(n_samples: int, seed: int):\n",
    "    \"\"\"Generate 2D binary classification data.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = n_samples // 2\n",
    "\n",
    "    # Class 1: inside\n",
    "    θ_in = rng.uniform(0, 2 * np.pi, n)\n",
    "    r_in = rng.uniform(0, 0.45, n)\n",
    "    X_in = np.column_stack([r_in * np.cos(θ_in), r_in * np.sin(θ_in)])\n",
    "\n",
    "    # Class 0: outside\n",
    "    θ_out = rng.uniform(0, 2 * np.pi, n)\n",
    "    r_out = rng.uniform(0.6, 1.0, n)\n",
    "    X_out = np.column_stack([r_out * np.cos(θ_out), r_out * np.sin(θ_out)])\n",
    "\n",
    "    X = np.vstack([X_out, X_in])\n",
    "    y = np.hstack([np.zeros(n), np.ones(n)])\n",
    "    perm = rng.permutation(len(y))\n",
    "    return X[perm], y[perm].astype(int)\n",
    "\n",
    "\n",
    "def train_test_split(X, y, test_frac=0.2, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = rng.permutation(len(y))\n",
    "    n_test = int(len(y) * test_frac)\n",
    "    return X[idx[n_test:]], X[idx[:n_test]], y[idx[n_test:]], y[idx[:n_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f44dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_circle_data(N_SAMPLES, SEED)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, 0.2, SEED)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples:     {len(X_test)}\")\n",
    "print(f\"Class balance:    {y_train.mean():.1%} positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(\n",
    "    X_train[y_train == 0, 0],\n",
    "    X_train[y_train == 0, 1],\n",
    "    c=\"tab:blue\",\n",
    "    s=15,\n",
    "    alpha=0.6,\n",
    "    label=\"Outside\",\n",
    ")\n",
    "ax.scatter(\n",
    "    X_train[y_train == 1, 0],\n",
    "    X_train[y_train == 1, 1],\n",
    "    c=\"tab:orange\",\n",
    "    s=15,\n",
    "    alpha=0.6,\n",
    "    label=\"Inside\",\n",
    ")\n",
    "ax.add_patch(plt.Circle((0, 0), 0.5, fill=False, linestyle=\"--\", color=\"gray\"))\n",
    "ax.set_xlim(-1.2, 1.2)\n",
    "ax.set_ylim(-1.2, 1.2)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "### 2. Two Classifier Architectures\n",
    "\n",
    "- Angle Encoding (Data Re-uploading): simple rotations encode features at each layer, good for learning radial patterns.\n",
    "- IQP Encoding: uses ZZ interactions to encode feature products, can capture more complex correlations.\n",
    "\n",
    "We measure ⟨Z⟩ and map it to class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectures",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_angle_classifier(n_layers, dev):\n",
    "    \"\"\"Data re-uploading classifier with angle encoding.\"\"\"\n",
    "\n",
    "    @qml.qnode(dev, diff_method=\"backprop\")\n",
    "    def circuit(x, params):\n",
    "        x0, x1 = x[..., 0], x[..., 1]\n",
    "        r2 = x0**2 + x1**2  # radial feature\n",
    "\n",
    "        for layer in range(n_layers):\n",
    "            # Re-upload features\n",
    "            qml.RY(pnp.pi * x0, wires=0)\n",
    "            qml.RZ(pnp.pi * x1, wires=0)\n",
    "            qml.RY(pnp.pi * r2, wires=0)\n",
    "            # Trainable rotation\n",
    "            qml.Rot(params[layer, 0], params[layer, 1], params[layer, 2], wires=0)\n",
    "\n",
    "        return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "    return circuit, (n_layers, 3)\n",
    "\n",
    "\n",
    "def create_iqp_classifier(n_layers, dev):\n",
    "    \"\"\"IQP-style encoding with entangling variational layers.\"\"\"\n",
    "\n",
    "    @qml.qnode(dev, diff_method=\"backprop\")\n",
    "    def circuit(x, params):\n",
    "        x0, x1 = x[..., 0], x[..., 1]\n",
    "        r2 = x0**2 + x1**2\n",
    "\n",
    "        # IQP encoding\n",
    "        for w in range(3):\n",
    "            qml.Hadamard(wires=w)\n",
    "        qml.RZ(pnp.pi * x0, wires=0)\n",
    "        qml.RZ(pnp.pi * x1, wires=1)\n",
    "        qml.RZ(pnp.pi * r2, wires=2)\n",
    "\n",
    "        # Feature interactions\n",
    "        qml.IsingZZ(pnp.pi * x0 * x1, wires=[0, 1])\n",
    "        qml.IsingZZ(pnp.pi * x1 * r2, wires=[1, 2])\n",
    "        qml.IsingZZ(pnp.pi * x0 * r2, wires=[0, 2])\n",
    "\n",
    "        # Variational layers\n",
    "        qml.StronglyEntanglingLayers(params, wires=[0, 1, 2])\n",
    "\n",
    "        return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "    return circuit, (n_layers, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "### 3. Training function\n",
    "\n",
    "We define a training function that:\n",
    "- Optimizes the variational parameters using gradient descent\n",
    "- Logs loss and accuracy at each epoch\n",
    "- Tracks the best model by validation accuracy\n",
    "\n",
    "This mirrors typical ML training loops but with quantum circuit evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-fn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(circuit, param_shape, run):\n",
    "    \"\"\"Train and log metrics to devqubit.\"\"\"\n",
    "    X_tr, y_tr = pnp.asarray(X_train), pnp.asarray(y_train)\n",
    "    X_te, y_te = pnp.asarray(X_test), pnp.asarray(y_test)\n",
    "\n",
    "    params = pnp.random.uniform(-np.pi, np.pi, param_shape, requires_grad=True)\n",
    "    opt = qml.AdamOptimizer(stepsize=LR)\n",
    "\n",
    "    def predict(X, p):\n",
    "        return (circuit(X, p) + 1) / 2\n",
    "\n",
    "    def loss_fn(p):\n",
    "        preds = pnp.clip(predict(X_tr, p), 1e-7, 1 - 1e-7)\n",
    "        return -pnp.mean(y_tr * pnp.log(preds) + (1 - y_tr) * pnp.log(1 - preds))\n",
    "\n",
    "    def accuracy(p, X, y):\n",
    "        preds = np.asarray(predict(X, p))\n",
    "        return float(np.mean((preds > 0.5) == np.asarray(y)))\n",
    "\n",
    "    history = {\"loss\": [], \"train_acc\": [], \"test_acc\": []}\n",
    "    best_acc, best_params = 0, params\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        params, loss = opt.step_and_cost(loss_fn, params)\n",
    "        train_acc = accuracy(params, X_tr, y_tr)\n",
    "        test_acc = accuracy(params, X_te, y_te)\n",
    "\n",
    "        history[\"loss\"].append(float(loss))\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        run.log_metric(\"loss\", float(loss), step=epoch)\n",
    "        run.log_metric(\"train_acc\", train_acc, step=epoch)\n",
    "        run.log_metric(\"test_acc\", test_acc, step=epoch)\n",
    "\n",
    "        if test_acc > best_acc:\n",
    "            best_acc, best_params = test_acc, params\n",
    "\n",
    "    return best_params, best_acc, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "### 4. Baseline Run\n",
    "\n",
    "Train a 2-layer classifier as our baseline. We log:\n",
    "- Architecture parameters\n",
    "- Epoch-by-epoch metrics\n",
    "- Final trained weights as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "with track(project=PROJECT, run_name=\"baseline_angle\") as run:\n",
    "    dev = qml.device(\"default.qubit\", wires=N_QUBITS)\n",
    "    tracked_dev = run.wrap(dev)\n",
    "\n",
    "    circuit, param_shape = create_angle_classifier(2, tracked_dev)\n",
    "\n",
    "    run.log_params(\n",
    "        {\n",
    "            \"architecture\": \"angle_encoding\",\n",
    "            \"n_layers\": 2,\n",
    "            \"n_qubits\": N_QUBITS,\n",
    "            \"lr\": LR,\n",
    "        }\n",
    "    )\n",
    "    run.set_tags({\"role\": \"baseline\"})\n",
    "\n",
    "    print(\"Training Angle Encoding (2 layers)...\")\n",
    "    best_params, best_acc, baseline_history = train_classifier(\n",
    "        circuit, param_shape, run\n",
    "    )\n",
    "\n",
    "    run.log_metrics({\"best_test_acc\": best_acc})\n",
    "    run.log_json(\n",
    "        \"trained_params\",\n",
    "        {\"values\": np.asarray(best_params).tolist()},\n",
    "        role=\"model\",\n",
    "    )\n",
    "    baseline_id = run.run_id\n",
    "\n",
    "print(f\"Baseline accuracy: {best_acc:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axes[0].plot(baseline_history[\"loss\"], \"o-\", markersize=3)\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Training Loss\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(baseline_history[\"train_acc\"], \"o-\", markersize=3, label=\"Train\")\n",
    "axes[1].plot(baseline_history[\"test_acc\"], \"s-\", markersize=3, label=\"Test\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Accuracy\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. Architecture Sweep\n",
    "\n",
    "How many variational layers do we need? Which ansatz is better for our problem? Let's sweep over different circuits and depths to compare.\n",
    "\n",
    "Using `group_id` keeps these runs organized together. All runs:\n",
    "- Share the same group for easy querying\n",
    "- Use identical random seed for fair comparison\n",
    "- Vary only the number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweep",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [\n",
    "    (\"angle_encoding\", create_angle_classifier, 2),\n",
    "    (\"angle_encoding\", create_angle_classifier, 3),\n",
    "    (\"iqp_encoding\", create_iqp_classifier, 2),\n",
    "    (\"iqp_encoding\", create_iqp_classifier, 3),\n",
    "]\n",
    "\n",
    "sweep_results = []\n",
    "sweep_params = {}  # Store for decision boundary\n",
    "\n",
    "print(\"Architecture Sweep\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for arch_name, builder, n_layers in architectures:\n",
    "    with track(\n",
    "        project=PROJECT, group_id=\"arch_sweep\", group_name=\"Architecture Comparison\"\n",
    "    ) as run:\n",
    "        dev = qml.device(\"default.qubit\", wires=N_QUBITS)\n",
    "        tracked_dev = run.wrap(dev)\n",
    "\n",
    "        circuit, param_shape = builder(n_layers, tracked_dev)\n",
    "        n_params = int(np.prod(param_shape))\n",
    "\n",
    "        run.log_params(\n",
    "            {\n",
    "                \"architecture\": arch_name,\n",
    "                \"n_layers\": n_layers,\n",
    "                \"n_params\": n_params,\n",
    "            }\n",
    "        )\n",
    "        run.set_tags({\"role\": \"sweep\"})\n",
    "\n",
    "        print(f\"  {arch_name} (L={n_layers}, params={n_params})...\", end=\" \")\n",
    "        best_params, best_acc, _ = train_classifier(circuit, param_shape, run)\n",
    "\n",
    "        run.log_metrics({\"best_test_acc\": best_acc})\n",
    "        run.log_json(\n",
    "            \"trained_params\",\n",
    "            {\"values\": np.asarray(best_params).tolist()},\n",
    "            role=\"model\",\n",
    "        )\n",
    "\n",
    "        sweep_results.append(\n",
    "            {\n",
    "                \"arch\": arch_name,\n",
    "                \"layers\": n_layers,\n",
    "                \"acc\": best_acc,\n",
    "                \"run_id\": run.run_id,\n",
    "            }\n",
    "        )\n",
    "        sweep_params[(arch_name, n_layers)] = (best_params, builder)\n",
    "\n",
    "        print(f\"{best_acc:.1%}\")\n",
    "\n",
    "best = max(sweep_results, key=lambda r: r[\"acc\"])\n",
    "print(f\"\\n=> Best: {best['arch']} L={best['layers']} ({best['acc']:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-sweep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart comparison\n",
    "labels = [\n",
    "    f\"{r['arch'].replace('_encoding','')}\\nL={r['layers']}\" for r in sweep_results\n",
    "]\n",
    "accs = [r[\"acc\"] for r in sweep_results]\n",
    "colors = [\"tab:blue\" if \"angle\" in r[\"arch\"] else \"tab:orange\" for r in sweep_results]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "bars = ax.bar(labels, accs, color=colors, edgecolor=\"black\", alpha=0.8)\n",
    "ax.set_ylabel(\"Test Accuracy\")\n",
    "ax.set_title(\"Architecture Comparison\")\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.axhline(\n",
    "    y=best[\"acc\"],\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.5,\n",
    "    label=f\"Best: {best['acc']:.1%}\",\n",
    ")\n",
    "ax.legend()\n",
    "ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, accs):\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.02,\n",
    "        f\"{acc:.0%}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "Let's visualize what the best model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decision-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_params_final, best_builder = sweep_params[(best[\"arch\"], best[\"layers\"])]\n",
    "eval_circuit, _ = best_builder(\n",
    "    best[\"layers\"], qml.device(\"default.qubit\", wires=N_QUBITS)\n",
    ")\n",
    "\n",
    "# Create prediction grid\n",
    "xx, yy = np.meshgrid(np.linspace(-1.2, 1.2, 50), np.linspace(-1.2, 1.2, 50))\n",
    "grid = np.column_stack([xx.ravel(), yy.ravel()])\n",
    "grid_preds = ((np.array(eval_circuit(grid, best_params_final)) + 1) / 2).reshape(\n",
    "    xx.shape\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "contour = ax.contourf(xx, yy, grid_preds, levels=20, cmap=\"RdYlBu\", alpha=0.7)\n",
    "ax.contour(xx, yy, grid_preds, levels=[0.5], colors=\"k\", linewidths=2)\n",
    "ax.scatter(\n",
    "    X_test[y_test == 0, 0],\n",
    "    X_test[y_test == 0, 1],\n",
    "    c=\"tab:blue\",\n",
    "    s=20,\n",
    "    edgecolors=\"k\",\n",
    "    linewidths=0.5,\n",
    "    label=\"Outside\",\n",
    ")\n",
    "ax.scatter(\n",
    "    X_test[y_test == 1, 0],\n",
    "    X_test[y_test == 1, 1],\n",
    "    c=\"tab:orange\",\n",
    "    s=20,\n",
    "    edgecolors=\"k\",\n",
    "    linewidths=0.5,\n",
    "    label=\"Inside\",\n",
    ")\n",
    "ax.add_patch(\n",
    "    plt.Circle(\n",
    "        (0, 0),\n",
    "        0.5,\n",
    "        fill=False,\n",
    "        linestyle=\"--\",\n",
    "        color=\"gray\",\n",
    "        linewidth=1.5,\n",
    "    )\n",
    ")\n",
    "ax.set_xlim(-1.2, 1.2)\n",
    "ax.set_ylim(-1.2, 1.2)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(f\"Decision Boundary: {best['arch']} (L={best['layers']})\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "plt.colorbar(contour, ax=ax, label=\"P(inside)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "### 6. Compare Runs\n",
    "\n",
    "Let's compare our baseline (2 layers) with the best configuration from the sweep.\n",
    "\n",
    "The `diff()` function shows:\n",
    "- Parameter differences\n",
    "- Metric differences\n",
    "- Tag differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = diff(baseline_id, best[\"run_id\"])\n",
    "\n",
    "print(\"Baseline vs Best Architecture\")\n",
    "print(\"=\" * 45)\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "### 8. Query Results\n",
    "\n",
    "Browse all runs and groups to see the full experiment history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for g in list_groups():\n",
    "    print(f\"\\n{g['group_name']}:\")\n",
    "    for run_info in list_runs_in_group(g[\"group_id\"]):\n",
    "        rec = load_run(run_info[\"run_id\"])\n",
    "        arch = rec.params.get(\"architecture\", \"?\")\n",
    "        layers = rec.params.get(\"n_layers\", \"?\")\n",
    "        acc = rec.metrics.get(\"best_test_acc\", 0)\n",
    "        print(f\"  {arch:15s} L={layers}: {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Feature | What we tracked |\n",
    "|---------|----------------|\n",
    "| **Architectures** | angle_encoding vs iqp_encoding |\n",
    "| **Epoch metrics** | loss, train_acc, test_acc |\n",
    "| **Sweep** | 4 configurations (2 arch × 2 depths) |\n",
    "| **Artifacts** | Trained parameters as JSON |\n",
    "| **Visualization** | Training curves, bar chart, decision boundary |\n",
    "\n",
    "**Key insight:** Different encodings capture different data patterns. The IQP encoding with ZZ interactions may better capture radial symmetry for circle classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(WORKSPACE)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
