#!/usr/bin/env python3
"""Phase 0 éªŒè¯å·¥å…· - ç›´æ¥æµ‹è¯•è„šæœ¬.

è¿™ä¸ªè„šæœ¬æ¨¡æ‹Ÿ MCP Context APIï¼Œç”¨äºéªŒè¯ Phase 0 å·¥å…·çš„æ ¸å¿ƒé€»è¾‘ã€‚
ç”±äºçœŸå®çš„ ctx.sample() å’Œ ctx.elicit() éœ€è¦åœ¨ Claude Code ä¸­è¿è¡Œï¼Œ
è¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿå¯¹è±¡è¿›è¡Œåˆæ­¥éªŒè¯ã€‚
"""

import asyncio
import json

# å¯¼å…¥è¦æµ‹è¯•çš„å‡½æ•°
import sys
from dataclasses import dataclass, field
from typing import Any

sys.path.insert(0, "src")

from skill_creator_mcp.utils.requirement_collection import (
    _generate_brainstorm_question,
    _generate_progressive_question,
)

# ============================================================================
# æ¨¡æ‹Ÿ Context API
# ============================================================================


@dataclass
class SamplingResult:
    """æ¨¡æ‹Ÿ LLM é‡‡æ ·ç»“æœ."""
    text: str | None = None
    history: list[dict[str, Any]] = field(default_factory=list)


@dataclass
class ElicitationResult:
    """æ¨¡æ‹Ÿç”¨æˆ·å¾è¯¢ç»“æœ."""
    accepted: bool = True
    data: Any = None
    action: str = "accept"


class MockContext:
    """æ¨¡æ‹Ÿ MCP Context å¯¹è±¡."""

    def __init__(self):
        self._state: dict[str, Any] = {}
        self.sample_history: list[dict] = []
        self.elicit_history: list[dict] = []

    async def sample(
        self,
        messages: str | list[dict],
        system_prompt: str = "",
        temperature: float = 0.7,
        **kwargs
    ) -> SamplingResult:
        """æ¨¡æ‹Ÿ LLM é‡‡æ ·."""
        self.sample_history.append({
            "messages": messages,
            "system_prompt": system_prompt,
            "temperature": temperature,
        })

        # æ¨¡æ‹Ÿ LLM å“åº”
        if isinstance(messages, str):
            prompt = messages
        else:
            prompt = messages[-1].get("content", "") if messages else ""

        # æ ¹æ®æç¤ºç”Ÿæˆæ¨¡æ‹Ÿå“åº”
        if "æ ¸å¿ƒä»·å€¼" in prompt or "ç—›ç‚¹" in prompt:
            response = "æ‚¨å¸Œæœ›è¿™ä¸ªæŠ€èƒ½è§£å†³ç”¨æˆ·ä»€ä¹ˆæ ·çš„æ ¸å¿ƒç—›ç‚¹ï¼Ÿ"
        elif "è§¦å‘" in prompt or "è‡ªåŠ¨åŒ–" in prompt:
            response = "è€ƒè™‘åˆ°è‡ªåŠ¨åŒ–ä»»åŠ¡ï¼Œæ‚¨å¸Œæœ›æ”¯æŒå“ªäº›è§¦å‘æ–¹å¼ï¼Ÿ"
        elif "æƒé™" in prompt:
            response = "æ‚¨æåˆ°çš„æƒé™æ§åˆ¶æ˜¯æŒ‡ä»€ä¹ˆçº§åˆ«çš„æƒé™ï¼Ÿ"
        elif "åˆ†æä»¥ä¸‹æŠ€èƒ½åˆ›å»ºéœ€æ±‚" in prompt:
            # å®Œæ•´æ€§æ£€æŸ¥è¿”å› JSON
            response = json.dumps({
                "is_complete": False,
                "missing_info": ["skill_name", "use_cases"],
                "suggestions": ["è¯·æä¾›æŠ€èƒ½åç§°", "è¯·æè¿°ä½¿ç”¨åœºæ™¯"]
            })
        else:
            response = "è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚è¯·é—®æ‚¨èƒ½è¯¦ç»†è¯´æ˜ä¸€ä¸‹å—ï¼Ÿ"

        return SamplingResult(
            text=response,
            history=[{"role": "assistant", "content": response}]
        )

    async def elicit(self, prompt: str, **kwargs) -> ElicitationResult:
        """æ¨¡æ‹Ÿç”¨æˆ·å¾è¯¢."""
        self.elicit_history.append({"prompt": prompt, "kwargs": kwargs})
        # æ¨¡æ‹Ÿç”¨æˆ·æ¥å—å¹¶è¾“å…¥æ•°æ®
        return ElicitationResult(
            accepted=True,
            data="test-skill-name"
        )

    async def get_state(self, key: str) -> Any:
        """è·å–çŠ¶æ€."""
        return self._state.get(key)

    async def set_state(self, key: str, value: Any) -> None:
        """è®¾ç½®çŠ¶æ€."""
        self._state[key] = value


# ============================================================================
# Phase 0 éªŒè¯æµ‹è¯•
# ============================================================================


async def test_llm_sampling():
    """éªŒè¯ç‚¹ 1: LLM Sampling èƒ½åŠ›."""
    print("\n" + "=" * 60)
    print("éªŒè¯ç‚¹ 1: LLM Sampling èƒ½åŠ›")
    print("=" * 60)

    ctx = MockContext()

    # è°ƒç”¨ sample
    result = await ctx.sample(
        messages="è¯·ç”Ÿæˆä¸€ä¸ªå…³äºæŠ€èƒ½åˆ›å»ºçš„é—®é¢˜",
        system_prompt="You are a helpful assistant for skill creation.",
        temperature=0.7,
    )

    # éªŒè¯ç»“æœ
    print(f"âœ… LLM å“åº”: {result.text}")
    print(f"âœ… åŒ…å«å†å²è®°å½•: {len(result.history) > 0}")
    print(f"âœ… é‡‡æ ·æ¬¡æ•°: {len(ctx.sample_history)}")

    assert result.text is not None, "LLM åº”è¯¥è¿”å›å“åº”æ–‡æœ¬"
    assert len(result.history) > 0, "åº”è¯¥åŒ…å«å†å²è®°å½•"
    assert len(ctx.sample_history) == 1, "åº”è¯¥è®°å½•ä¸€æ¬¡é‡‡æ ·"

    return True


async def test_user_elicitation():
    """éªŒè¯ç‚¹ 2: User Elicitation èƒ½åŠ›."""
    print("\n" + "=" * 60)
    print("éªŒè¯ç‚¹ 2: User Elicitation èƒ½åŠ›")
    print("=" * 60)

    ctx = MockContext()

    # è°ƒç”¨ elicit
    result = await ctx.elicit(
        prompt="è¯·æä¾›æŠ€èƒ½åç§°ï¼ˆå°å†™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦ï¼‰"
    )

    # éªŒè¯ç»“æœ
    print(f"âœ… ç”¨æˆ·æ¥å—: {result.accepted}")
    print(f"âœ… ç”¨æˆ·è¾“å…¥: {result.data}")
    print(f"âœ… å¾è¯¢æ¬¡æ•°: {len(ctx.elicit_history)}")

    assert result.accepted, "ç”¨æˆ·åº”è¯¥æ¥å—è¾“å…¥è¯·æ±‚"
    assert result.data is not None, "åº”è¯¥è¿”å›ç”¨æˆ·è¾“å…¥"
    assert len(ctx.elicit_history) == 1, "åº”è¯¥è®°å½•ä¸€æ¬¡å¾è¯¢"

    return True


async def test_conversation_loop():
    """éªŒè¯ç‚¹ 3: Session State + LLM ç»“åˆ."""
    print("\n" + "=" * 60)
    print("éªŒè¯ç‚¹ 3: Session State + LLM ç»“åˆ")
    print("=" * 60)

    ctx = MockContext()

    # ç¬¬ä¸€è½®å¯¹è¯
    user_input_1 = "æˆ‘æƒ³åˆ›å»ºä¸€ä¸ªæŠ€èƒ½"
    history_1 = await ctx.get_state("conversation_history")
    history_1 = list(history_1) if history_1 else []
    history_1.append({"role": "user", "content": user_input_1})

    result_1 = await ctx.sample(
        messages=history_1,
        system_prompt="You are a skill creation consultant.",
    )

    if result_1.text:
        history_1.append({"role": "assistant", "content": result_1.text})
    await ctx.set_state("conversation_history", history_1)

    print(f"ğŸ“ ç¬¬ä¸€è½® - ç”¨æˆ·: {user_input_1}")
    print(f"ğŸ“ ç¬¬ä¸€è½® - AI: {result_1.text}")
    print(f"ğŸ“ å¯¹è¯é•¿åº¦: {len(history_1)}")

    # ç¬¬äºŒè½®å¯¹è¯
    history_2 = await ctx.get_state("conversation_history")
    history_2 = list(history_2) if history_2 else []
    user_input_2 = "å¸®åŠ©ç”¨æˆ·å¿«é€Ÿæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"
    history_2.append({"role": "user", "content": user_input_2})

    result_2 = await ctx.sample(
        messages=history_2,
        system_prompt="You are a skill creation consultant.",
    )

    if result_2.text:
        history_2.append({"role": "assistant", "content": result_2.text})
    await ctx.set_state("conversation_history", history_2)

    print(f"ğŸ“ ç¬¬äºŒè½® - ç”¨æˆ·: {user_input_2}")
    print(f"ğŸ“ ç¬¬äºŒè½® - AI: {result_2.text}")
    print(f"ğŸ“ å¯¹è¯é•¿åº¦: {len(history_2)}")

    assert len(history_2) == 4, "åº”è¯¥æœ‰ 4 æ¡å¯¹è¯è®°å½•ï¼ˆ2 è½®ï¼‰"
    assert await ctx.get_state("conversation_history") == history_2, "çŠ¶æ€åº”è¯¥æ­£ç¡®ä¿å­˜"

    return True


async def test_requirement_completeness():
    """éªŒè¯ç‚¹ 4: éœ€æ±‚å®Œæ•´æ€§éªŒè¯."""
    print("\n" + "=" * 60)
    print("éªŒè¯ç‚¹ 4: éœ€æ±‚å®Œæ•´æ€§éªŒè¯")
    print("=" * 60)

    ctx = MockContext()

    requirement = "æˆ‘æƒ³åˆ›å»ºä¸€ä¸ªæŠ€èƒ½"

    result = await ctx.sample(
        messages=f"""åˆ†æä»¥ä¸‹æŠ€èƒ½åˆ›å»ºéœ€æ±‚ï¼Œåˆ¤æ–­æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯ï¼š

{requirement}

å¿…è¦ä¿¡æ¯åŒ…æ‹¬ï¼š
1. skill_name - æŠ€èƒ½åç§°
2. skill_function - ä¸»è¦åŠŸèƒ½
3. use_cases - ä½¿ç”¨åœºæ™¯
4. template_type - æ¨¡æ¿ç±»å‹

è¯·è¿”å› JSON æ ¼å¼ï¼ŒåŒ…å«ï¼š
- is_complete: boolï¼ˆæ˜¯å¦å®Œæ•´ï¼‰
- missing_info: list[str]ï¼ˆç¼ºå¤±çš„ä¿¡æ¯åˆ—è¡¨ï¼‰
- suggestions: list[str]ï¼ˆè¡¥å……å»ºè®®åˆ—è¡¨ï¼‰
""",
        system_prompt="You are a skill creation consultant. Analyze requirements for completeness.",
        temperature=0.3,
    )

    print(f"ğŸ“‹ LLM åˆ†æç»“æœ: {result.text}")

    # å°è¯•è§£æ JSON
    import re
    json_match = re.search(r"\{.*\}", result.text or "", re.DOTALL)
    if json_match:
        try:
            analysis = json.loads(json_match.group())
            print("âœ… JSON è§£ææˆåŠŸ")
            print(f"âœ… æ˜¯å¦å®Œæ•´: {analysis.get('is_complete')}")
            print(f"âœ… ç¼ºå¤±ä¿¡æ¯: {analysis.get('missing_info')}")
            print(f"âœ… è¡¥å……å»ºè®®: {analysis.get('suggestions')}")
            return True
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON è§£æå¤±è´¥: {e}")
            return False
    else:
        print("âš ï¸ æœªæ‰¾åˆ° JSON æ ¼å¼è¾“å‡º")
        return False


async def test_brainstorm_mode():
    """é¢å¤–æµ‹è¯•: Brainstorm æ¨¡å¼."""
    print("\n" + "=" * 60)
    print("é¢å¤–æµ‹è¯•: Brainstorm æ¨¡å¼ LLM é—®é¢˜ç”Ÿæˆ")
    print("=" * 60)

    ctx = MockContext()

    result = await _generate_brainstorm_question(
        ctx=ctx,
        answers={},
        conversation_history=None,
    )

    print(f"âœ… æˆåŠŸç”Ÿæˆé—®é¢˜: {result.get('success')}")
    print(f"âœ… é—®é¢˜æ¥æº: {result.get('source')}")
    print(f"âœ… æ˜¯å¦åŠ¨æ€: {result.get('is_dynamic')}")
    print(f"ğŸ“ ç”Ÿæˆçš„é—®é¢˜: {result.get('question')}")

    assert result["success"], "åº”è¯¥æˆåŠŸç”Ÿæˆé—®é¢˜"
    assert result["is_dynamic"], "åº”è¯¥æ˜¯åŠ¨æ€ç”Ÿæˆçš„é—®é¢˜"

    return True


async def test_progressive_mode():
    """é¢å¤–æµ‹è¯•: Progressive æ¨¡å¼."""
    print("\n" + "=" * 60)
    print("é¢å¤–æµ‹è¯•: Progressive æ¨¡å¼æ¸è¿›å¼é—®é¢˜")
    print("=" * 60)

    ctx = MockContext()

    result = await _generate_progressive_question(
        ctx=ctx,
        answers={},
    )

    print(f"âœ… æˆåŠŸç”Ÿæˆé—®é¢˜: {result.get('success')}")
    print(f"âœ… é—®é¢˜æ¥æº: {result.get('source')}")
    print(f"ğŸ“ ç”Ÿæˆçš„é—®é¢˜: {result.get('question')}")

    assert result["success"], "åº”è¯¥æˆåŠŸç”Ÿæˆé—®é¢˜"

    return True


# ============================================================================
# ä¸»æµ‹è¯•æµç¨‹
# ============================================================================


async def main():
    """è¿è¡Œæ‰€æœ‰ Phase 0 éªŒè¯æµ‹è¯•."""
    print("\n" + "=" * 60)
    print("Phase 0 æŠ€æœ¯éªŒè¯ - ç›´æ¥æµ‹è¯•")
    print("=" * 60)
    print("\nâš ï¸ æ³¨æ„: è¿™æ˜¯æ¨¡æ‹Ÿæµ‹è¯•ï¼ŒéªŒè¯æ ¸å¿ƒé€»è¾‘")
    print("âš ï¸ çœŸå®ç¯å¢ƒæµ‹è¯•éœ€è¦åœ¨ Claude Code ä¸­è¿è¡Œ MCP Server\n")

    tests = [
        ("LLM Sampling èƒ½åŠ›", test_llm_sampling),
        ("User Elicitation èƒ½åŠ›", test_user_elicitation),
        ("Session State + LLM ç»“åˆ", test_conversation_loop),
        ("éœ€æ±‚å®Œæ•´æ€§éªŒè¯", test_requirement_completeness),
        ("Brainstorm æ¨¡å¼", test_brainstorm_mode),
        ("Progressive æ¨¡å¼", test_progressive_mode),
    ]

    results = []

    for name, test_func in tests:
        try:
            result = await test_func()
            results.append((name, "âœ… é€šè¿‡" if result else "âš ï¸ éƒ¨åˆ†é€šè¿‡"))
        except Exception as e:
            results.append((name, f"âŒ å¤±è´¥: {e}"))

    # è¾“å‡ºæ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ€»ç»“")
    print("=" * 60)

    for name, result in results:
        print(f"{result} - {name}")

    passed = sum(1 for _, r in results if "âœ…" in r)
    total = len(results)

    print(f"\né€šè¿‡ç‡: {passed}/{total} ({passed/total*100:.1f}%)")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ ¸å¿ƒé€»è¾‘éªŒè¯æˆåŠŸã€‚")
        print("\nä¸‹ä¸€æ­¥: åœ¨ Claude Code ä¸­é‡å¯ä»¥åŠ è½½ MCP Serverï¼Œè¿›è¡ŒçœŸå®ç¯å¢ƒæµ‹è¯•ã€‚")
    else:
        print(f"\nâš ï¸ æœ‰ {total - passed} ä¸ªæµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼Œè¯·æ£€æŸ¥ã€‚")


if __name__ == "__main__":
    asyncio.run(main())
