"""HPC Sequential Pipeline for single-GPU setups.

Processes documents in phases, swapping models between each phase:
1. OCR Phase: Load DeepSeek-OCR -> extract text from all pages -> stop
2. Figure Phase: Load vision model -> describe figures -> stop
3. (Optional) Nougat Phase: Run Nougat for LaTeX equations

This avoids OOM issues when running multiple large models on a single GPU.
"""

import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from pathlib import Path

from PIL import Image

from smart_ocr.audit.heuristics import HeuristicsChecker
from smart_ocr.core.config import AgentConfig, EngineType
from smart_ocr.core.document import Document
from smart_ocr.core.result import FigureResult, OCRResult, PageResult, PageStatus
from smart_ocr.engines.deepseek_vllm import DeepSeekVLLMEngine
from smart_ocr.engines.gemini import GeminiEngine
from smart_ocr.engines.nougat import NougatEngine
from smart_ocr.engines.vllm import VLLMEngine
from smart_ocr.engines.vllm_manager import ServerConfig, VLLMServerManager
from smart_ocr.pipeline.processor import OCRPipeline
from smart_ocr.pipeline.reconciler import (
    EngineOutput,
    OutputReconciler,
    create_page_result_from_reconciliation,
)


class HPCSequentialPipeline(OCRPipeline):
    """HPC pipeline with sequential model loading for single-GPU setups.

    This pipeline swaps models between processing phases to fit within
    single-GPU memory constraints. Each phase:
    1. Starts vLLM with the required model
    2. Processes all items for that phase
    3. Stops vLLM and frees GPU memory

    Designed for HPC nodes with single high-memory GPUs (H100, A100).
    """

    def __init__(self, config: AgentConfig | None = None) -> None:
        """Initialize sequential HPC pipeline."""
        super().__init__(config)

        # Server manager for controlling vLLM lifecycle
        self.server_manager = VLLMServerManager(verbose=self.config.verbose)

        # Initialize reconciler
        self.reconciler = OutputReconciler(
            use_llm_reconciler=self.config.hpc.use_llm_reconciler,
            reconciler_model=self.config.hpc.reconciler_model,
            vllm_url=self.config.hpc.vllm_url,
        )

        # Initialize heuristics checker for quality audit
        self.heuristics = HeuristicsChecker(
            min_word_count=self.config.audit.min_word_count,
            max_garbage_ratio=0.15,
        )

        # Gemini engine for cloud fallback (lazy init)
        self._gemini_engine: GeminiEngine | None = None

        # Cache for page images (avoid re-rendering between phases)
        self._page_images: dict[int, Image.Image] = {}

    def process(self, pdf_path: Path | str, output_path: Path | str | None = None) -> OCRResult:
        """Process a document through sequential HPC pipeline.

        Sequential pipeline phases:
        1. OCR Phase: DeepSeek-vLLM extracts text
        2. Nougat Phase (optional): Nougat extracts LaTeX
        3. Figure Phase: Vision model describes figures
        4. Reconciliation: Merge outputs

        Args:
            pdf_path: Path to the PDF file to process
            output_path: Optional custom output path

        Returns:
            OCRResult with processed pages and figures
        """
        self._start_time = time.time()
        pdf_path = Path(pdf_path)
        self._custom_output_path = Path(output_path) if output_path else None

        # Print header
        self.console.print_header()
        self.console.console.print(
            "[info]HPC Sequential Mode[/info] - Single-GPU model swapping\n"
        )

        # Load document
        document = Document.from_pdf(pdf_path, render_dpi=self.config.render_dpi)
        document.classify()

        self.console.print_document_info(
            filename=document.filename,
            pages=document.num_pages,
            size_mb=document.size_mb,
            doc_type=document.doc_type.value,
            detected_features=document.detected_features,
        )

        # Initialize result
        result = OCRResult(document_path=str(pdf_path))
        default_output_file = self._default_output_file(pdf_path)
        result.metadata.update({
            "doc_type": document.doc_type.value,
            "detected_features": document.detected_features,
            "default_output_file": str(default_output_file),
            "hpc_mode": True,
            "hpc_sequential": True,
            "vllm_url": self.config.hpc.vllm_url,
        })

        # Cache page images for reuse across phases
        self._cache_page_images(document)

        try:
            # Phase 1: OCR with DeepSeek-vLLM
            ocr_outputs = self._run_ocr_phase(document)

            # Phase 2: Nougat for LaTeX (optional, runs locally without vLLM)
            nougat_outputs = {}
            if self.config.hpc.use_nougat:
                nougat_outputs = self._run_nougat_phase(document)

            # Phase 3: Reconciliation
            page_results = self._run_reconciliation_phase(
                ocr_outputs, nougat_outputs, document.num_pages
            )
            for r in page_results:
                result.add_page_result(r)

            # Phase 4: Figure processing with vision model
            if self.config.include_figures:
                self._run_figure_phase(document, result)

        finally:
            # Ensure server is stopped
            self.server_manager.stop()
            # Clear cached images
            self._page_images.clear()

        # Recalculate stats
        result.recalculate_stats()

        # Add engine attribution
        result.metadata["ocr_engines"] = list({r.engine for r in result.pages if r.engine})
        result.metadata["processed"] = datetime.utcnow().isoformat()

        # Print summary
        elapsed = time.time() - self._start_time
        result.stats.total_time = elapsed

        self.console.print_summary(
            pages_success=result.stats.pages_success,
            pages_total=result.stats.total_pages,
            figures_count=result.stats.figures_detected,
            time_seconds=elapsed,
            cost=result.stats.total_cost,
            engines_used=result.stats.engines_used,
            output_path=str(default_output_file),
        )

        return result

    def _cache_page_images(self, document: Document) -> None:
        """Cache page images to avoid re-rendering between phases."""
        self.console.console.print("[dim]Caching page images...[/dim]")
        for page in document.pages:
            self._page_images[page.page_num] = page.image

    def _run_ocr_phase(self, document: Document) -> dict[int, EngineOutput]:
        """Run OCR phase with DeepSeek-vLLM.

        Returns:
            Dict mapping page_num to EngineOutput
        """
        self.console.print_stage_header(1, "OCR PHASE", "DeepSeek-vLLM text extraction")

        # Start vLLM with OCR model
        if self.config.hpc.manage_server:
            self.console.console.print(
                f"[dim]Starting vLLM with {self.config.hpc.ocr_model}...[/dim]"
            )
            server_config = ServerConfig(
                model=self.config.hpc.ocr_model,
                port=self.config.hpc.vllm_port,
                gpu_memory_utilization=self.config.hpc.gpu_memory_utilization,
                max_model_len=self.config.hpc.max_model_len,
            )
            self.server_manager.start(
                server_config,
                timeout=self.config.hpc.server_startup_timeout,
            )
            base_url = self.server_manager.get_base_url()
        else:
            base_url = self.config.hpc.vllm_url

        # Configure and initialize engine
        self.config.deepseek_vllm.base_url = base_url
        self.config.deepseek_vllm.model = self.config.hpc.ocr_model
        engine = DeepSeekVLLMEngine(self.config.deepseek_vllm)

        if not engine.initialize():
            raise RuntimeError(f"Failed to initialize DeepSeek-vLLM at {base_url}")

        outputs: dict[int, EngineOutput] = {}
        workers = self.config.parallel_pages

        self.console.print_engine_active(
            "deepseek-vllm",
            f"processing {document.num_pages} pages ({workers} workers)",
        )

        with self.progress.stage_progress(
            stage_name="primary",
            engine="deepseek-vllm",
            total=document.num_pages,
            description="OCR extraction",
        ) as ctx:
            if workers <= 1:
                for page_num, image in self._page_images.items():
                    result = engine.process_image(image, page_num)
                    if result.status == PageStatus.SUCCESS:
                        outputs[page_num] = EngineOutput(
                            engine="deepseek-vllm",
                            text=result.text,
                            confidence=result.confidence or 0.85,
                            processing_time=result.processing_time,
                        )

                    status = "success" if result.status == PageStatus.SUCCESS else "error"
                    ctx.add_result(
                        item=page_num,
                        status=status,
                        message=result.error_message or "",
                        confidence=result.confidence,
                    )
                    ctx.advance()
            else:
                def process_page(page_num: int, image: Image.Image):
                    return page_num, engine.process_image(image, page_num)

                with ThreadPoolExecutor(max_workers=workers) as executor:
                    futures = {
                        executor.submit(process_page, pn, img): pn
                        for pn, img in self._page_images.items()
                    }
                    for future in as_completed(futures):
                        page_num, result = future.result()
                        if result.status == PageStatus.SUCCESS:
                            outputs[page_num] = EngineOutput(
                                engine="deepseek-vllm",
                                text=result.text,
                                confidence=result.confidence or 0.85,
                                processing_time=result.processing_time,
                            )

                        status = "success" if result.status == PageStatus.SUCCESS else "error"
                        ctx.add_result(
                            item=page_num,
                            status=status,
                            message=result.error_message or "",
                            confidence=result.confidence,
                        )
                        ctx.advance()

            ctx.print_results()

        # Stop server to free GPU memory
        if self.config.hpc.manage_server:
            self.console.console.print("[dim]Stopping OCR server...[/dim]")
            self.server_manager.stop()

        # Quality audit + Gemini fallback
        if self.config.hpc.audit_enabled:
            failed_pages = self._audit_ocr_results(outputs)

            if failed_pages and self.config.hpc.cloud_fallback:
                gemini_outputs = self._fallback_to_gemini(failed_pages)
                # Replace failed pages with Gemini output
                outputs.update(gemini_outputs)

        return outputs

    def _audit_ocr_results(
        self,
        ocr_outputs: dict[int, EngineOutput],
    ) -> list[int]:
        """Run heuristics on OCR outputs, return failed page numbers."""
        failed = []
        for page_num, output in ocr_outputs.items():
            result = self.heuristics.check(output.text)
            if not result.passed:
                failed.append(page_num)
                error_summary = ", ".join(result.errors[:2])  # First 2 errors
                self.console.console.print(
                    f"  [warning]![/warning] Page {page_num} failed audit: {error_summary}"
                )

        if failed:
            self.console.console.print(
                f"  [dim]{len(failed)}/{len(ocr_outputs)} pages failed quality check[/dim]"
            )
        else:
            self.console.console.print(
                f"  [success]+[/success] All {len(ocr_outputs)} pages passed quality check"
            )

        return failed

    def _fallback_to_gemini(
        self,
        failed_pages: list[int],
    ) -> dict[int, EngineOutput]:
        """Re-OCR failed pages with Gemini.

        Sends original page images to Gemini for fresh OCR, rather than
        trying to "fix" the failed DeepSeek output.
        """
        if not failed_pages:
            return {}

        self.console.console.print(
            f"\n  [info]Gemini fallback[/info] - Re-processing {len(failed_pages)} failed pages"
        )

        # Lazy-init Gemini engine
        if self._gemini_engine is None:
            self._gemini_engine = GeminiEngine(self.config.gemini)

        if not self._gemini_engine.is_available():
            self.console.console.print(
                "  [warning]![/warning] Gemini not available (check GEMINI_API_KEY)"
            )
            return {}

        outputs: dict[int, EngineOutput] = {}
        success_count = 0

        for page_num in failed_pages:
            image = self._page_images.get(page_num)
            if not image:
                continue

            result = self._gemini_engine.process_image(image, page_num)
            if result.status == PageStatus.SUCCESS:
                outputs[page_num] = EngineOutput(
                    engine="gemini",
                    text=result.text,
                    confidence=result.confidence or 0.9,
                    processing_time=result.processing_time,
                )
                success_count += 1
                self.console.console.print(
                    f"  [success]+[/success] Page {page_num} re-processed with Gemini"
                )
            else:
                err = result.error_message
                self.console.console.print(
                    f"  [error]x[/error] Page {page_num} Gemini fallback failed: {err}"
                )

        self.console.console.print(
            f"  [dim]Gemini fallback: {success_count}/{len(failed_pages)} pages recovered[/dim]"
        )

        return outputs

    def _run_nougat_phase(self, document: Document) -> dict[int, EngineOutput]:
        """Run Nougat phase for LaTeX extraction.

        Nougat runs locally (no vLLM), so this can run independently.

        Returns:
            Dict mapping page_num to EngineOutput
        """
        self.console.print_stage_header(2, "NOUGAT PHASE", "LaTeX equation extraction")

        engine = self.engines.get(EngineType.NOUGAT)
        if not engine or not engine.is_available():
            self.console.print_warning("Nougat not available, skipping LaTeX extraction")
            return {}

        outputs: dict[int, EngineOutput] = {}

        self.console.print_engine_active("nougat", f"processing {document.num_pages} pages")

        with self.progress.stage_progress(
            stage_name="primary",
            engine="nougat",
            total=document.num_pages,
            description="LaTeX extraction",
        ) as ctx:
            for page_num, image in self._page_images.items():
                result = engine.process_image(image, page_num)
                if result.status == PageStatus.SUCCESS:
                    outputs[page_num] = EngineOutput(
                        engine="nougat",
                        text=result.text,
                        confidence=result.confidence or 0.8,
                        processing_time=result.processing_time,
                    )

                status = "success" if result.status == PageStatus.SUCCESS else "error"
                ctx.add_result(
                    item=page_num,
                    status=status,
                    message=result.error_message or "",
                    confidence=result.confidence,
                )
                ctx.advance()

            ctx.print_results()

        return outputs

    def _run_reconciliation_phase(
        self,
        ocr_outputs: dict[int, EngineOutput],
        nougat_outputs: dict[int, EngineOutput],
        total_pages: int,
    ) -> list[PageResult]:
        """Reconcile outputs from OCR and Nougat phases."""
        self.console.print_stage_header(3, "RECONCILIATION", "Merge multi-engine outputs")

        results: list[PageResult] = []
        latex_merged = 0

        for page_num in range(1, total_pages + 1):
            outputs = []
            if page_num in ocr_outputs:
                outputs.append(ocr_outputs[page_num])
            if page_num in nougat_outputs:
                outputs.append(nougat_outputs[page_num])

            if not outputs:
                results.append(PageResult(
                    page_num=page_num,
                    status=PageStatus.ERROR,
                    error_message="No engine produced output",
                ))
                continue

            reconciliation = self.reconciler.reconcile(outputs, page_num)
            page_result = create_page_result_from_reconciliation(
                reconciliation,
                page_num,
                processing_time=sum(o.processing_time for o in outputs),
            )
            results.append(page_result)

            if reconciliation.latex_source:
                latex_merged += reconciliation.conflicts_resolved

        success_count = sum(1 for r in results if r.status == PageStatus.SUCCESS)
        self.console.console.print(
            f"  [success]+[/success] {success_count}/{total_pages} pages reconciled"
        )
        if latex_merged > 0:
            self.console.console.print(
                f"  [info]i[/info] {latex_merged} LaTeX blocks merged from Nougat"
            )

        return results

    def _run_figure_phase(self, document: Document, result: OCRResult) -> None:
        """Run figure description phase with vision model."""
        self.console.print_stage_header(4, "FIGURE PHASE", "Vision model figure description")

        # Extract figures first (no GPU needed)
        pending_figures = self._extract_figures(document, result)

        if not pending_figures:
            self.console.console.print("[dim]No figures detected[/dim]")
            return

        self.console.console.print(
            f"[dim]Extracted {len(pending_figures)} figures, starting vision model...[/dim]"
        )

        # Start vLLM with vision model
        if self.config.hpc.manage_server:
            server_config = ServerConfig(
                model=self.config.hpc.vision_model,
                port=self.config.hpc.vllm_port,
                gpu_memory_utilization=self.config.hpc.gpu_memory_utilization,
                max_model_len=self.config.hpc.max_model_len,
            )
            self.server_manager.start(
                server_config,
                timeout=self.config.hpc.server_startup_timeout,
            )
            base_url = self.server_manager.get_base_url()
        else:
            base_url = self.config.hpc.vllm_url

        # Configure vision engine
        self.config.vllm.base_url = base_url
        self.config.vllm.model = self.config.hpc.vision_model
        engine = VLLMEngine(self.config.vllm)

        if not engine.initialize():
            self.console.print_warning(
                f"Failed to initialize vision model at {base_url}"
            )
            if self.config.hpc.manage_server:
                self.server_manager.stop()
            return

        self.console.print_engine_active(
            "vllm",
            f"describing {len(pending_figures)} figures",
        )

        # Describe figures
        for fig_num, page_num, image, context, fig_path in pending_figures:
            fig_result = engine.describe_figure(image, context=context)
            fig_result.figure_num = fig_num
            fig_result.page_num = page_num
            if fig_path:
                fig_result.image_path = fig_path

            page_result = result.get_page(page_num)
            if page_result:
                page_result.figures.append(fig_result)

            self.console.print_figure_result(
                figure_num=fig_num,
                page=page_num,
                fig_type=fig_result.figure_type,
                description=fig_result.description,
            )

        # Stop server
        if self.config.hpc.manage_server:
            self.console.console.print("[dim]Stopping vision server...[/dim]")
            self.server_manager.stop()

    def _extract_figures(
        self,
        document: Document,
        result: OCRResult,
    ) -> list[tuple[int, int, Image.Image, str, str | None]]:
        """Extract figures from document without GPU.

        Uses multiple strategies:
        1. IMAGE blocks via page.get_text("dict") - catches most academic figures
        2. Embedded images via page.get_images() - catches raw image assets

        Returns:
            List of (fig_num, page_num, image, context, fig_path) tuples
        """
        try:
            import fitz
        except ImportError:
            self.console.print_warning("PyMuPDF not available for figure extraction")
            return []

        pending_figures: list[tuple[int, int, Image.Image, str, str | None]] = []
        figure_counter = 1
        max_dim = 1024
        min_area = 80 * 80
        render_dpi = 150
        # Vector figure detection parameters
        min_drawings_for_vector_figure = 5
        min_vector_figure_area_ratio = 0.05
        max_vector_figure_area_ratio = 0.85
        header_footer_margin = 0.1

        # Prepare figures directory
        figures_dir: Path | None = None
        if self.config.save_figures:
            if self._custom_output_path:
                figures_dir = self._custom_output_path.parent / "figures"
            else:
                doc_stem = Path(document.path).stem
                figures_dir = self.config.output_dir / doc_stem / "figures"
            figures_dir.mkdir(parents=True, exist_ok=True)

        self.console.console.print(f"[dim]Figure extraction: path={document.path}[/dim]")

        try:
            with fitz.open(document.path) as pdf:
                self.console.console.print(f"[dim]Scanning {len(pdf)} pages for figures...[/dim]")

                for page_index in range(len(pdf)):
                    if figure_counter > self.config.figures_max_total:
                        break

                    page = pdf[page_index]
                    page_num = page_index + 1
                    page_result = result.get_page(page_num)

                    context_text = ""
                    if page_result:
                        context_text = (page_result.text or "")[
                            : self.config.figures_context_max_chars
                        ]

                    per_page = 0
                    processed_regions: set[tuple[int, int, int, int]] = set()

                    # Detect page orientation
                    is_landscape = page.rect.width > page.rect.height
                    page_width = page.rect.width
                    page_height = page.rect.height
                    page_area = page_width * page_height
                    effective_min_area_ratio = min_vector_figure_area_ratio * 0.5 if is_landscape else min_vector_figure_area_ratio
                    effective_max_area_ratio = 0.98 if is_landscape else max_vector_figure_area_ratio
                    effective_min_drawings = 3 if is_landscape else min_drawings_for_vector_figure

                    # Strategy 0: Detect vector figures (most academic papers use this)
                    try:
                        drawings = page.get_drawings()
                        if len(drawings) >= effective_min_drawings:
                            figure_regions = self._cluster_drawings_into_figures(
                                drawings, page_width, page_height, cluster_gap=30,
                            )
                            if figure_regions:
                                self.console.console.print(
                                    f"[dim]  Page {page_num}: {len(figure_regions)} vector figures[/dim]"
                                )

                            for region_drawings, bbox in figure_regions:
                                if figure_counter > self.config.figures_max_total:
                                    break
                                if per_page >= self.config.figures_max_per_page:
                                    break

                                x0, y0, x1, y1 = bbox
                                width = x1 - x0
                                height = y1 - y0
                                area = width * height
                                area_ratio = area / page_area

                                if area < min_area or width < 50 or height < 50:
                                    continue
                                if area_ratio < effective_min_area_ratio or area_ratio > effective_max_area_ratio:
                                    continue
                                if len(region_drawings) < effective_min_drawings:
                                    continue

                                # Skip header/footer regions
                                if not is_landscape:
                                    center_y = (y0 + y1) / 2
                                    in_header = center_y < page_height * header_footer_margin
                                    in_footer = center_y > page_height * (1 - header_footer_margin)
                                    if (in_header or in_footer) and len(region_drawings) < 20:
                                        continue

                                region_key = (int(x0), int(y0), int(x1), int(y1))
                                if region_key in processed_regions:
                                    continue
                                processed_regions.add(region_key)

                                # Render figure region
                                padding = 10
                                clip = fitz.Rect(
                                    max(0, x0 - padding), max(0, y0 - padding),
                                    min(page_width, x1 + padding), min(page_height, y1 + padding)
                                )
                                mat = fitz.Matrix(render_dpi / 72, render_dpi / 72)
                                try:
                                    pix = page.get_pixmap(matrix=mat, clip=clip)
                                    pil_img = Image.frombytes(
                                        "RGB", (pix.width, pix.height), pix.samples
                                    )
                                    if max(pil_img.size) > max_dim:
                                        pil_img.thumbnail((max_dim, max_dim))

                                    fig_path: str | None = None
                                    if figures_dir:
                                        fig_filename = f"figure_{figure_counter}_page{page_num}.png"
                                        fig_path = str(figures_dir / fig_filename)
                                        pil_img.save(fig_path)

                                    pending_figures.append(
                                        (figure_counter, page_num, pil_img, context_text, fig_path)
                                    )
                                    figure_counter += 1
                                    per_page += 1
                                except Exception:
                                    pass
                    except Exception:
                        pass

                    # Strategy 1: Extract IMAGE blocks (finds most academic figures)
                    try:
                        text_dict = page.get_text("dict")
                        blocks = text_dict.get("blocks", [])
                        image_blocks = [b for b in blocks if b.get("type") == 1]
                        if image_blocks:
                            self.console.console.print(
                                f"[dim]  Page {page_num}: {len(image_blocks)} image blocks[/dim]"
                            )
                        for block in blocks:
                            if (
                                figure_counter > self.config.figures_max_total
                                or per_page >= self.config.figures_max_per_page
                            ):
                                break
                            if block.get("type") != 1:  # type 1 = image block
                                continue

                            bbox = block.get("bbox")
                            if not bbox:
                                continue

                            x0, y0, x1, y1 = bbox
                            width, height = x1 - x0, y1 - y0
                            area = width * height
                            aspect = width / max(height, 1)

                            if area < min_area or aspect > 8 or aspect < 0.125:
                                continue

                            region_key = (int(x0), int(y0), int(x1), int(y1))
                            if region_key in processed_regions:
                                continue
                            processed_regions.add(region_key)

                            clip = fitz.Rect(bbox)
                            mat = fitz.Matrix(render_dpi / 72, render_dpi / 72)
                            try:
                                pix = page.get_pixmap(matrix=mat, clip=clip)
                                pil_img = Image.frombytes(
                                    "RGB", (pix.width, pix.height), pix.samples
                                )
                            except Exception:
                                continue

                            if max(pil_img.size) > max_dim:
                                pil_img.thumbnail((max_dim, max_dim))

                            fig_path: str | None = None
                            if figures_dir:
                                fig_filename = f"figure_{figure_counter}_page{page_num}.png"
                                fig_path = str(figures_dir / fig_filename)
                                pil_img.save(fig_path)

                            pending_figures.append(
                                (figure_counter, page_num, pil_img, context_text, fig_path)
                            )
                            figure_counter += 1
                            per_page += 1
                    except Exception:
                        pass

                    # Strategy 2: Extract raw embedded images
                    images = page.get_images(full=True)
                    if images:
                        self.console.console.print(
                            f"[dim]  Page {page_num}: {len(images)} embedded images[/dim]"
                        )
                    for img in images:
                        if (
                            figure_counter > self.config.figures_max_total
                            or per_page >= self.config.figures_max_per_page
                        ):
                            break

                        xref = img[0]
                        width, height = img[2], img[3]
                        area = width * height
                        aspect = width / max(height, 1)

                        if area < min_area or aspect > 8 or aspect < 0.125:
                            continue

                        # Skip small images (likely icons/bullets)
                        try:
                            raw_image = pdf.extract_image(xref)
                            if len(raw_image.get("image", b"")) < 5000:
                                continue
                        except Exception:
                            pass

                        pix = None
                        rgb = None
                        try:
                            pix = fitz.Pixmap(pdf, xref)
                            if pix.colorspace is None:
                                continue

                            if pix.colorspace != fitz.csRGB or pix.alpha or pix.n != 3:
                                rgb = fitz.Pixmap(fitz.csRGB, pix)
                                pix = rgb

                            pil_img = Image.frombytes(
                                "RGB", (pix.width, pix.height), pix.samples
                            )
                        except Exception:
                            continue
                        finally:
                            del rgb
                            del pix

                        if max(pil_img.size) > max_dim:
                            pil_img.thumbnail((max_dim, max_dim))

                        fig_path: str | None = None
                        if figures_dir:
                            fig_filename = f"figure_{figure_counter}_page{page_num}.png"
                            fig_path = str(figures_dir / fig_filename)
                            pil_img.save(fig_path)

                        pending_figures.append(
                            (figure_counter, page_num, pil_img, context_text, fig_path)
                        )
                        figure_counter += 1
                        per_page += 1

        except Exception as e:
            self.console.print_warning(f"Figure extraction error: {e}")

        return pending_figures

    def _cluster_drawings_into_figures(
        self,
        drawings: list[dict],
        page_width: float,
        page_height: float,
        cluster_gap: float = 30,
    ) -> list[tuple[list[dict], tuple[float, float, float, float]]]:
        """Cluster drawings into figure regions using spatial proximity.

        Uses a simple union-find approach: drawings whose bounding boxes are within
        `cluster_gap` pixels of each other belong to the same figure.

        Returns:
            List of (drawings_in_cluster, bounding_box) tuples.
        """
        if not drawings:
            return []

        # Extract bounding boxes
        boxes = []
        for d in drawings:
            rect = d.get("rect")
            if rect:
                boxes.append((rect.x0, rect.y0, rect.x1, rect.y1))
            else:
                boxes.append(None)

        # Filter out drawings without valid boxes
        valid = [(i, boxes[i]) for i in range(len(boxes)) if boxes[i] is not None]
        if not valid:
            return []

        # Union-Find structure
        parent = {i: i for i, _ in valid}

        def find(x: int) -> int:
            if parent[x] != x:
                parent[x] = find(parent[x])
            return parent[x]

        def union(x: int, y: int) -> None:
            px, py = find(x), find(y)
            if px != py:
                parent[px] = py

        # Check proximity between all pairs
        for i, (idx_i, box_i) in enumerate(valid):
            for j, (idx_j, box_j) in enumerate(valid):
                if i >= j:
                    continue
                x0_i, y0_i, x1_i, y1_i = box_i
                x0_j, y0_j, x1_j, y1_j = box_j

                # Horizontal gap
                if x1_i < x0_j:
                    h_gap = x0_j - x1_i
                elif x1_j < x0_i:
                    h_gap = x0_i - x1_j
                else:
                    h_gap = 0

                # Vertical gap
                if y1_i < y0_j:
                    v_gap = y0_j - y1_i
                elif y1_j < y0_i:
                    v_gap = y0_i - y1_j
                else:
                    v_gap = 0

                if h_gap <= cluster_gap and v_gap <= cluster_gap:
                    union(idx_i, idx_j)

        # Group drawings by cluster
        clusters: dict[int, list[int]] = {}
        for idx, _ in valid:
            root = find(idx)
            if root not in clusters:
                clusters[root] = []
            clusters[root].append(idx)

        # Compute bounding box for each cluster
        results = []
        for indices in clusters.values():
            cluster_drawings = [drawings[i] for i in indices]
            cluster_boxes = [boxes[i] for i in indices if boxes[i] is not None]

            if not cluster_boxes:
                continue

            x0 = min(b[0] for b in cluster_boxes)
            y0 = min(b[1] for b in cluster_boxes)
            x1 = max(b[2] for b in cluster_boxes)
            y1 = max(b[3] for b in cluster_boxes)

            results.append((cluster_drawings, (x0, y0, x1, y1)))

        # Sort by position (top-to-bottom, left-to-right)
        results.sort(key=lambda r: (r[1][1], r[1][0]))

        return results

    def save_output(self, result: OCRResult, output_path: Path | None = None) -> Path:
        """Save OCR result with HPC sequential metadata."""
        saved_path = super().save_output(result, output_path)

        # Add YAML frontmatter for markdown
        if self.config.output_format == "markdown":
            content = saved_path.read_text()

            frontmatter_lines = [
                "---",
                f"source: {Path(result.document_path).name}",
            ]

            engines = result.metadata.get("ocr_engines", [])
            if engines:
                frontmatter_lines.append(f"ocr_engines: [{', '.join(engines)}]")

            processed = result.metadata.get("processed", "")
            if processed:
                frontmatter_lines.append(f"processed: {processed}")

            frontmatter_lines.append("hpc_mode: sequential")
            frontmatter_lines.append("---")
            frontmatter_lines.append("")

            new_content = "\n".join(frontmatter_lines) + content
            saved_path.write_text(new_content)

        return saved_path
