import asyncio
import re
from contextlib import asynccontextmanager
from pathlib import Path
from sqlite3 import LEGACY_TRANSACTION_CONTROL
from typing import Any, Callable, Coroutine, cast

from alembic import command
from alembic.config import Config as AlembicConfig
from pydantic import ConfigDict
from sqlalchemy import (
    Connection,
    MetaData,
    event,
    insert,
    make_url,
    text,
)
from sqlalchemy.dialects.postgresql import insert as pg_insert
from sqlalchemy.dialects.sqlite import insert as sqlite_insert
from sqlalchemy.engine.url import URL
from sqlalchemy.exc import DBAPIError
from sqlalchemy.ext.asyncio import AsyncEngine, create_async_engine
from sqlalchemy.ext.compiler import compiles
from sqlalchemy.orm import declared_attr
from sqlalchemy.sql.expression import ClauseElement, Executable
from sqlmodel import SQLModel
from sqlmodel.ext.asyncio.session import AsyncSession

import planar
from planar.logging import get_logger
from planar.modeling.orm.planar_base_entity import (
    PLANAR_APPLICATION_METADATA,
    PLANAR_ENTITY_SCHEMA,
)
from planar.utils import P, R, T, U, exponential_backoff_with_jitter


def camel_to_snake(name):
    name = re.sub("(.)([A-Z][a-z]+)", r"\1_\2", name)
    return re.sub("([a-z0-9])([A-Z])", r"\1_\2", name).lower()


PLANAR_SCHEMA = "planar"
PLANAR_FRAMEWORK_METADATA = MetaData(schema=PLANAR_SCHEMA)
logger = get_logger(__name__)


class explain(Executable, ClauseElement):
    inherit_cache = False

    def __init__(self, stmt):
        self.statement = stmt
        self._inline = False


@compiles(explain, "postgresql")
def pg_explain(element, compiler, **kw):
    text = "EXPLAIN ANALYZE "
    text += compiler.process(element.statement, **kw)
    return text


class PlanarInternalBase(SQLModel, table=False):
    """
    Base model with common fields for all database tables.
    Not a table itself - meant to be inherited by concrete model classes.

    Usage conventions:
    - Primary keys should be "id" and be UUID with default_factory=uuid4 when possible
    - Use TimeStampMixin for auto-timestamp fields
    - Field names should use snake_case consistently
    - Table schema is set to 'planar' automatically
    - Foreign keys should specify the full schema.table_name
    """

    @declared_attr.directive
    def __tablename__(cls) -> str:  # type: ignore
        return camel_to_snake(cls.__name__)

    __abstract__ = True
    # __table_args__ = {"schema": PLANAR_SCHEMA}
    metadata = PLANAR_FRAMEWORK_METADATA
    model_config = ConfigDict(validate_assignment=True)  # type: ignore


class PlanarSession(AsyncSession):
    def __init__(self, engine: AsyncEngine | None = None):
        assert engine
        self.engine = engine
        self.dialect = engine.dialect
        self.max_conflict_retries: int = 10
        # dynamic import since planar.session depends on this
        from planar.session import config_var

        config = config_var.get(None)
        if config is not None and config.app.max_db_conflict_retries:
            self.max_conflict_retries = config.app.max_db_conflict_retries
        super().__init__(engine, expire_on_commit=False)

    async def set_serializable_isolation(self):
        if self.dialect.name == "postgresql":
            await self.exec(text("SET TRANSACTION ISOLATION LEVEL SERIALIZABLE"))  # type: ignore[arg-type]

    @asynccontextmanager
    async def begin_read(self):
        """Context manager for read-only transactions.

        This is useful when reading from the database since it ensures that if
        a transaction has not started before the context, it will ensure no
        transactions are open after the context.
        """
        in_transaction = self.in_transaction()
        try:
            yield
            if not in_transaction:
                await self.commit()
        except Exception:
            if not in_transaction:
                await self.rollback()
            raise

    async def run_transaction(
        self,
        fn: Callable[P, Coroutine[T, U, R]],
        *args: P.args,
        **kwargs: P.kwargs,
    ) -> R:
        max_conflict_retries = self.max_conflict_retries

        if self.in_transaction():
            await self.commit()

        remaining_retries = max_conflict_retries

        while True:
            try:
                async with self.begin():
                    await self.set_serializable_isolation()
                    return await fn(*args, **kwargs)
            except Exception as e:
                if remaining_retries == 0:
                    logger.exception("transaction failed after maximum retries")
                    raise

                if isinstance(e, DBAPIError) and "could not serialize access" in str(e):
                    delay = exponential_backoff_with_jitter(
                        max_conflict_retries - remaining_retries
                    )
                    await asyncio.sleep(delay)
                    remaining_retries -= 1
                    continue
                logger.exception(
                    "transaction failed due to unrecoverable error",
                    remaining_retries=remaining_retries,
                )
                raise

    async def explain(self, query: Executable, log_identifier: str) -> str:
        if self.dialect.name != "postgresql" or not logger.isDebugEnabled():
            return ""
        # Reusing the current session will mess things up
        # (implicit transaction starting, for example), so use
        # a separate session to run the explain command
        async with PlanarSession(self.engine) as session:
            result = await session.exec(cast(Any, explain(query)))
            query_plan = "\n".join([str(row[0]) for row in result])
            compiled_sql = str(query)
            logger.debug(
                f"query_plan:{log_identifier}",
                query_plan=query_plan,
                compiled_sql=compiled_sql,
            )
            return query_plan

    def insert_or_ignore[T: SQLModel](
        self,
        model: type[T],
        values: list[T],
        conflict_columns: list[str] | None = None,
    ):
        """Insert records, ignoring conflicts.

        Creates a database-specific insert statement that ignores conflicts
        based on the database backend.

        Args:
            model: The SQLModel class representing the table to insert into.
            values: List of model instances to insert. Must not be empty.
            conflict_columns: Optional list of column names to check for conflicts.
                For PostgreSQL, specifies which columns trigger conflict detection.
                For SQLite, this is used to construct the OR IGNORE behavior.
                If None (PostgreSQL only), all conflicts are ignored.

        Returns:
            A SQLAlchemy insert statement with appropriate conflict handling
            based on the database dialect.

        Raises:
            ValueError: If the values list is empty.

        Example:
            ```python
            # Insert or ignore on conflict
            users = [User(name="Alice"), User(name="Bob")]
            stmt = session.insert_or_ignore(User, users, conflict_columns=["email"])
            await session.exec(stmt)
            ```
        """
        if not values:
            raise ValueError("values list cannot be empty")

        values_dicts = [
            value.model_dump(mode="python", exclude_unset=True) for value in values
        ]

        if self.dialect.name == "postgresql":
            stmt = pg_insert(model).values(values_dicts)
            if conflict_columns:
                stmt = stmt.on_conflict_do_nothing(index_elements=conflict_columns)
            else:
                stmt = stmt.on_conflict_do_nothing()
        else:
            stmt = insert(model).values(values_dicts).prefix_with("OR IGNORE")

        return stmt

    def upsert[T: SQLModel](
        self,
        model: type[T],
        values: list[T],
        *,
        conflict_columns: list[str],
        update_columns: list[str],
    ):
        """Insert records and update on conflict.

        Creates a database-specific upsert statement that inserts records and
        updates existing records on conflict with the specified column mappings.

        Args:
            model: The SQLModel class representing the table to insert into.
            values: List of model instances to insert. Must not be empty.
            conflict_columns: List of column names to check for conflicts.
                For PostgreSQL, specifies which columns trigger conflict detection.
                For SQLite, specifies the conflict index.
            update_columns: List of column names to update on conflict.
                These columns will be updated with values from the INSERT statement
                (i.e., SET column = EXCLUDED.column for each column in the list).

        Returns:
            A SQLAlchemy insert statement with appropriate conflict handling
            based on the database dialect.

        Raises:
            ValueError: If the values list is empty.

        Example:
            ```python
            # Insert or update on conflict
            users = [User(name="Alice"), User(name="Bob")]
            stmt = session.insert_and_update(
                User, users,
                conflict_columns=["email"],
                update_columns=["name", "updated_at"]
            )
            await session.exec(stmt)
            ```
        """
        if not values:
            raise ValueError("values list cannot be empty")

        values_dicts = [
            value.model_dump(mode="python", exclude_unset=True) for value in values
        ]

        if self.dialect.name == "postgresql":
            stmt = pg_insert(model).values(values_dicts)
        else:
            stmt = sqlite_insert(model).values(values_dicts)

        update_dict = {col: stmt.excluded[col] for col in update_columns}
        return stmt.on_conflict_do_update(
            index_elements=conflict_columns, set_=update_dict
        )


def new_session(engine: AsyncEngine) -> PlanarSession:
    return PlanarSession(engine)


class DatabaseManager:
    def __init__(
        self,
        db_url: str | URL,
        *,
        entity_schema: str = PLANAR_ENTITY_SCHEMA,
    ):
        self.db_url = make_url(db_url) if isinstance(db_url, str) else db_url
        self.engine: AsyncEngine | None = None
        self.entity_schema = entity_schema

    def _create_sqlite_engine(self, url: URL) -> AsyncEngine:
        # in practice this high timeout is only use
        timeout = int(str(url.query.get("timeout", 60)))
        logger.info("Setting up SQLite engine with timeout", timeout=timeout)

        engine = create_async_engine(
            url,
            connect_args=dict(
                timeout=timeout,
                isolation_level=None,
                # If autocommit is not LEGACY_TRANSACTION_CONTROL, isolation_level
                # is ignored, so we set here explicitly to make the intention clear,
                # even though it is the default value.
                autocommit=LEGACY_TRANSACTION_CONTROL,
            ),
            # SQLite doesn't support schemas, so we need to translate the planar and user
            # schema names to None.
            execution_options={
                "schema_translate_map": {
                    "planar": None,
                    PLANAR_ENTITY_SCHEMA: None,
                }
            },
        )

        def do_begin(conn: Connection):
            conn.exec_driver_sql("BEGIN IMMEDIATE")

        event.listen(engine.sync_engine, "begin", do_begin)

        return engine

    def _create_postgresql_engine(self, url: URL) -> AsyncEngine:
        # Map default (PLANAR_ENTITY_SCHEMA) schema to the configured entity schema for user tables.
        # Leave the system table schema ('planar') unmapped so system tables are not overridden.
        schema_map = {PLANAR_ENTITY_SCHEMA: self.entity_schema}
        engine = create_async_engine(
            url, execution_options={"schema_translate_map": schema_map}
        )

        return engine

    def connect(self):
        """Creates and initializes the database engine."""
        if self.engine:
            logger.warning("database engine already initialized")
            return

        db_backend = self.db_url.get_backend_name()

        if self.entity_schema == PLANAR_SCHEMA:
            logger.warning(
                "entity_schema is set to 'planar'; mixing user and system tables in the same schema is discouraged",
                entity_schema=self.entity_schema,
            )

        match db_backend:
            case "sqlite":
                logger.info(
                    "connecting to database", db_backend=db_backend, db_url=self.db_url
                )
                self.engine = self._create_sqlite_engine(self.db_url)
            case "postgresql":
                logger.info("connecting to database", db_backend=db_backend)
                self.engine = self._create_postgresql_engine(self.db_url)
            case _:
                raise NotImplementedError(
                    f'Unsupported database backend "{db_backend}"'
                )

    async def disconnect(self):
        """Disposes of the database engine."""
        if self.engine:
            logger.info("disconnecting database engine")
            await self.engine.dispose()
            self.engine = None
        else:
            logger.warning("attempted to disconnect an uninitialized engine")

    def get_engine(self) -> AsyncEngine:
        """Returns the initialized AsyncEngine."""
        if not self.engine:
            raise RuntimeError("Database engine not initialized. Call connect() first.")
        return self.engine

    def get_session(self) -> PlanarSession:
        """Returns a new PlanarSession."""
        if not self.engine:
            raise RuntimeError("Database engine not initialized. Call connect() first.")
        return PlanarSession(self.engine)

    async def _run_system_migrations(self):
        logger.info("running planar system migrations")

        module_path = Path(planar.__file__).parent
        script_location = str(module_path / "db" / "alembic")

        alembic_cfg = AlembicConfig()
        alembic_cfg.set_main_option("script_location", script_location)

        if not self.engine:
            raise RuntimeError("Database engine not initialized. Call connect() first.")
        try:
            async with self.engine.begin() as conn:
                # Pass the *synchronous* connection produced by `run_sync` to Alembic.

                def _upgrade(sync_conn):
                    """Run Alembic upgrade using the given synchronous connection."""

                    # Inject the sync SQLAlchemy Connection so that planar/db/alembic/env.py
                    # recognises we're running in programmatic (runtime) mode instead of
                    # development mode. This prevents it from trying to create a new engine
                    # via `engine_from_config`, which expects a URL in the Alembic config.
                    alembic_cfg.attributes["connection"] = sync_conn

                    # Execute migrations up to the latest revision.
                    command.upgrade(alembic_cfg, "head")

                # Execute the upgrade inside the green-thread aware sync context.
                await conn.run_sync(_upgrade)
            logger.info("planar system migrations completed successfully")
        except Exception:
            logger.exception("planar system migration failed")
            raise

    async def _setup_database(self):
        if not self.engine:
            raise RuntimeError("Database engine not initialized. Call connect() first.")

        async with self.engine.begin() as conn:
            if "sqlite" in self.db_url.drivername:
                await conn.execute(text("PRAGMA foreign_keys=ON"))
            else:
                # Ensure planar schema exists
                await conn.execute(text(f"CREATE SCHEMA IF NOT EXISTS {PLANAR_SCHEMA}"))
                # Ensure the configured entity schema exists
                if self.entity_schema != PLANAR_SCHEMA:
                    await conn.execute(
                        text(f"CREATE SCHEMA IF NOT EXISTS {self.entity_schema}")
                    )

    async def migrate(self):
        """
        Runs database migrations.
        By default, uses SQLModel.metadata.create_all.
        """
        if not self.engine:
            raise RuntimeError("Database engine not initialized. Call connect() first.")

        logger.info("starting database migration with alembic")
        await self._setup_database()
        await self._run_system_migrations()
        # For now user migrations are not supported, so we fall back to SQLModel.metadata.create_all
        async with self.engine.begin() as conn:
            await conn.run_sync(PLANAR_APPLICATION_METADATA.create_all)
