Metadata-Version: 2.4
Name: grkmemory
Version: 1.2.1
Summary: GRKMemory (Graph Retrieve Knowledge Memory) - A semantic graph-based memory system for AI agents developed by MonkAI team
Author-email: Arthur Vaz <contato@monkai.com.br>
Maintainer-email: Arthur Vaz <contato@monkai.com.br>
License: MIT
Project-URL: Homepage, https://github.com/BeMonkAI/GRKMemory
Project-URL: Documentation, https://github.com/BeMonkAI/GRKMemory#readme
Project-URL: Repository, https://github.com/BeMonkAI/GRKMemory
Project-URL: Issues, https://github.com/BeMonkAI/GRKMemory/issues
Keywords: grkmemory,monkai,ai,agents,memory,semantic-graph,knowledge-retrieval,openai,llm,chatgpt,conversational-ai,machine-learning,toon,token-optimization,serialization
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: openai>=1.0.0
Requires-Dist: openai-agents>=0.6.0
Requires-Dist: pydantic>=2.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: isort>=5.12.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Provides-Extra: embeddings
Requires-Dist: tiktoken>=0.5.0; extra == "embeddings"
Provides-Extra: toon
Requires-Dist: toon_format>=0.9.0; extra == "toon"
Provides-Extra: all
Requires-Dist: grkmemory[dev,embeddings,toon]; extra == "all"
Dynamic: license-file

# ğŸ§  GRKMemory - Graph Retrieve Knowledge Memory

> **GRKMemory** = **G**raph **R**etrieve **K**nowledge **Memory**

[![PyPI version](https://badge.fury.io/py/grkmemory.svg)](https://badge.fury.io/py/grkmemory)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**GRKMemory** Ã© um sistema de memÃ³ria semÃ¢ntica baseado em grafos para agentes de IA, desenvolvido pelo time **MonkAI**. RecuperaÃ§Ã£o inteligente de conhecimento com economia de 95% em tokens.

## ğŸš€ ComeÃ§ando

### 1ï¸âƒ£ InstalaÃ§Ã£o

```bash
pip install grkmemory
```

### 2ï¸âƒ£ Obter Token de Acesso

Para utilizar o GRKMemory, vocÃª precisa de um token fornecido pelo time **MonkAI**:

ğŸ“§ **Contato:** contato@monkai.com.br  
ğŸŒ **Site:** [www.monkai.com.br](https://www.monkai.com.br)

### 3ï¸âƒ£ Configurar Token

```bash
# Configurar como variÃ¡vel de ambiente
export GRKMEMORY_API_KEY="grk_seu_token_aqui"

# OpenAI (padrÃ£o)
export OPENAI_API_KEY="sua_openai_key"

# OU Azure OpenAI
export USE_AZURE_OPENAI="true"
export AZURE_OPENAI_API_KEY="sua_azure_key"
export AZURE_OPENAI_ENDPOINT="https://seu-recurso.openai.azure.com"
export AZURE_OPENAI_DEPLOYMENT="gpt-4o"
export AZURE_OPENAI_EMBEDDING_DEPLOYMENT="text-embedding-3-small"
```

### 4ï¸âƒ£ Autenticar e Usar

```python
from grkmemory import GRKMemory, GRKAuth, AuthenticatedGRK

# Autenticar com token MonkAI
auth = GRKAuth.from_env()  # Usa GRKMEMORY_API_KEY
print("âœ… Autenticado!")

# Inicializar GRKMemory protegido
grk = GRKMemory()
secure = AuthenticatedGRK(grk, auth.get_current_token())

# Usar!
secure.save_conversation([
    {"role": "user", "content": "OlÃ¡!"},
    {"role": "assistant", "content": "Oi! Como posso ajudar?"}
])

results = secure.search("OlÃ¡")
```

## ğŸ¯ Quick Start (Completo)

```python
from grkmemory import GRKMemory, GRKAuth, AuthenticatedGRK
import os

# 1. Autenticar
api_key = os.getenv("GRKMEMORY_API_KEY")
auth = GRKAuth()
auth.authenticate(api_key)

# 2. Criar GRKMemory autenticado
grk = GRKMemory()
secure = AuthenticatedGRK(grk, api_key)

# 3. Salvar conversa
secure.save_conversation([
    {"role": "user", "content": "Vamos falar sobre Python"},
    {"role": "assistant", "content": "Claro! O que vocÃª quer saber?"}
])

# 4. Buscar memÃ³rias relevantes
results = secure.search("O que discutimos sobre Python?")

# 5. Chat com contexto de memÃ³ria automÃ¡tico
response = secure.chat("Me conte sobre nossas discussÃµes anteriores")
```

## ğŸ” AutenticaÃ§Ã£o

### Token MonkAI

A autenticaÃ§Ã£o Ã© uma camada de proteÃ§Ã£o fornecida pelo time **MonkAI**. Todos os recursos requerem um token vÃ¡lido.

| PermissÃ£o | DescriÃ§Ã£o |
|-----------|-----------|
| `read` | Buscar e consultar memÃ³rias |
| `write` | Salvar novas memÃ³rias |
| `admin` | Gerenciamento completo |

### MÃ©todos de AutenticaÃ§Ã£o

```python
from grkmemory import GRKAuth

# MÃ©todo 1: Via variÃ¡vel de ambiente (recomendado)
auth = GRKAuth.from_env()  # Usa GRKMEMORY_API_KEY

# MÃ©todo 2: Diretamente
auth = GRKAuth()
auth.authenticate("grk_seu_token")

# Verificar permissÃµes
print(f"Pode ler: {auth.check_permission('read')}")
print(f"Pode escrever: {auth.check_permission('write')}")
```

> âš ï¸ **Importante:** Tokens sÃ£o fornecidos exclusivamente pelo time MonkAI.

## âš™ï¸ ConfiguraÃ§Ã£o

```python
from grkmemory import GRKMemory, MemoryConfig

config = MemoryConfig(
    model="gpt-4o",
    memory_file="minhas_memorias.json",
    enable_embeddings=True,
    background_memory_method="graph",  # 'graph', 'embedding', 'tags', 'entities'
    background_memory_limit=5,
    background_memory_threshold=0.3,
    storage_format="json",   # 'json' (padrÃ£o) ou 'toon'
    output_format="json"     # 'json', 'toon' ou 'text'
)

grk = GRKMemory(config=config)
```

## â˜ï¸ Azure OpenAI

GRKMemory suporta Azure OpenAI nativamente. Configure via variÃ¡veis de ambiente ou cÃ³digo:

### Via VariÃ¡veis de Ambiente

```bash
export USE_AZURE_OPENAI="true"
export AZURE_OPENAI_API_KEY="sua-api-key"
export AZURE_OPENAI_ENDPOINT="https://seu-recurso.openai.azure.com"
export AZURE_OPENAI_DEPLOYMENT="gpt-4o"
export AZURE_OPENAI_EMBEDDING_DEPLOYMENT="text-embedding-3-small"
export AZURE_OPENAI_API_VERSION="2024-02-01"  # opcional
```

### Via CÃ³digo

```python
from grkmemory import GRKMemory, MemoryConfig

# ConfiguraÃ§Ã£o Azure OpenAI
config = MemoryConfig(
    use_azure=True,
    api_key="sua-azure-api-key",
    azure_endpoint="https://seu-recurso.openai.azure.com",
    azure_deployment="gpt-4o",
    azure_embedding_deployment="text-embedding-3-small",
    azure_api_version="2024-02-01"
)

grk = GRKMemory(config=config)
```

### Tabela de ConfiguraÃ§Ãµes Azure

| VariÃ¡vel | Config | DescriÃ§Ã£o |
|----------|--------|-----------|
| `USE_AZURE_OPENAI` | `use_azure` | Ativar Azure (true/false) |
| `AZURE_OPENAI_API_KEY` | `api_key` | Chave da API Azure |
| `AZURE_OPENAI_ENDPOINT` | `azure_endpoint` | URL do recurso Azure |
| `AZURE_OPENAI_DEPLOYMENT` | `azure_deployment` | Nome do deployment (chat) |
| `AZURE_OPENAI_EMBEDDING_DEPLOYMENT` | `azure_embedding_deployment` | Nome do deployment (embeddings) |
| `AZURE_OPENAI_API_VERSION` | `azure_api_version` | VersÃ£o da API (default: 2024-02-01) |

## ğŸ“¦ Formatos de Armazenamento (JSON vs TOON)

GRKMemory suporta dois formatos de serializaÃ§Ã£o:

| Formato | Vantagem | Uso Recomendado |
|---------|----------|-----------------|
| **JSON** | Parsing 27x mais rÃ¡pido | Armazenamento (padrÃ£o) |
| **TOON** | 25% menos tokens | Contexto para LLM |

### Instalando TOON (opcional)

```bash
pip install toon_format
```

### EstratÃ©gia HÃ­brida (Recomendada)

```python
from grkmemory import MemoryRepository

# JSON para armazenamento (rÃ¡pido) + TOON para LLM (economia de tokens)
repo = MemoryRepository(
    memory_file="memorias.json",
    storage_format="json",      # Parsing rÃ¡pido
    output_format="toon"        # 25% menos tokens para LLM
)

# Buscar e formatar para LLM
results = repo.search("Python")
context = repo.format_for_llm(results)  # Retorna em TOON (~25% menos tokens)
```

### Comparando Formatos

```python
# Estimar economia de tokens
estimates = repo.get_token_estimate(results)
print(estimates)
# {'json': 689, 'toon': 512, 'savings_toon_vs_json': '25.7%'}
```

### Convertendo entre Formatos

```python
# Exportar para TOON
repo.export("backup.toon", format="toon")

# Converter armazenamento para TOON
repo.convert_storage_format("toon")
```

## ğŸ”“ Modo Offline (Sem Token)

VocÃª pode usar o `MemoryRepository` **sem token/API key** quando embeddings estÃ£o desabilitados:

```python
from grkmemory import MemoryRepository

# Modo offline - nÃ£o precisa de API key
repo = MemoryRepository(
    memory_file="memories.json",
    enable_embeddings=False  # â† Chave: desabilitar embeddings
)

# Funcionalidades disponÃ­veis sem token:
# âœ… Salvar memÃ³rias
repo.save({
    "summary": "Conversa sobre Python",
    "tags": ["python", "programaÃ§Ã£o"],
    "entities": ["Python"],
    "key_points": ["Linguagem interpretada"]
})

# âœ… Buscar por tags
results = repo.search("python", method="tags")

# âœ… Buscar por entities
results = repo.search("Python", method="entities")

# âœ… Buscar por grafo (sem embeddings)
results = repo.search("programaÃ§Ã£o", method="graph")

# âŒ Busca por embedding requer API key
# results = repo.search("query", method="embedding")  # Retorna vazio sem API key
```

> **Nota:** `GRKMemory` e `MemoryConfig` **requerem** API key. Apenas `MemoryRepository` com `enable_embeddings=False` funciona sem token.

## ğŸ’¾ Salvando Conversas em JSON

O GRKMemory salva automaticamente as conversas em um arquivo JSON estruturado:

### Estrutura do JSON

```json
{
  "sessoes": [
    {
      "id": "sess_abc123",
      "timestamp": "2025-01-09T12:00:00",
      "summary": "DiscussÃ£o sobre Python e IA",
      "tags": ["python", "ia", "programaÃ§Ã£o"],
      "entities": ["Python", "OpenAI", "GPT"],
      "concepts": ["machine learning", "api"],
      "messages": [
        {"role": "user", "content": "..."},
        {"role": "assistant", "content": "..."}
      ]
    }
  ]
}
```

### Usando o MemoryRepository diretamente

```python
from grkmemory import MemoryRepository

# Inicializar repositÃ³rio
repo = MemoryRepository(memory_file="minhas_memorias.json")

# Salvar memÃ³ria estruturada
memoria = {
    "summary": "Conversa sobre Python",
    "tags": ["python", "programaÃ§Ã£o"],
    "entities": ["Python", "VS Code"],
    "concepts": ["sintaxe", "bibliotecas"],
    "messages": [
        {"role": "user", "content": "Como instalar Python?"},
        {"role": "assistant", "content": "Baixe em python.org..."}
    ]
}
repo.save(memoria)

# Buscar memÃ³rias
resultados = repo.search("Python", method="tags")
```

## ğŸ“Š MÃ©todos de Busca

| MÃ©todo | DescriÃ§Ã£o |
|--------|-----------|
| `graph` | Grafo semÃ¢ntico (recomendado) |
| `embedding` | Similaridade vetorial |
| `tags` | Busca por tags |
| `entities` | Busca por entidades |

```python
# Busca por grafo semÃ¢ntico
results = secure.search("IA", method="graph")

# Busca por embedding
results = secure.search("machine learning", method="embedding")
```

## ğŸ“ˆ EstatÃ­sticas

```python
# EstatÃ­sticas gerais
stats = secure.get_stats()
print(f"Total de memÃ³rias: {stats['total_memories']}")

# EstatÃ­sticas do grafo
graph_stats = secure.get_graph_stats()
print(f"NÃ³s: {graph_stats['total_nodes']}")
print(f"Arestas: {graph_stats['total_edges']}")
```

## ğŸ“ Estrutura do Projeto

```
GRKMemory/
â”œâ”€â”€ grkmemory/              # ğŸ“¦ Pacote principal
â”‚   â”œâ”€â”€ core/               # Classes principais
â”‚   â”œâ”€â”€ memory/             # RepositÃ³rio de memÃ³ria
â”‚   â”œâ”€â”€ graph/              # Grafo semÃ¢ntico
â”‚   â”œâ”€â”€ auth/               # AutenticaÃ§Ã£o
â”‚   â””â”€â”€ utils/              # UtilitÃ¡rios
â”œâ”€â”€ examples/               # ğŸ’¡ Exemplos de uso
â”œâ”€â”€ papers/                 # ğŸ“„ DocumentaÃ§Ã£o tÃ©cnica
â””â”€â”€ README.md
```

## ğŸ“š Exemplos

Veja a pasta `examples/` para exemplos completos:

| Exemplo | DescriÃ§Ã£o |
|---------|-----------|
| `01_basic_usage.py` | Uso bÃ¡sico |
| `02_custom_config.py` | ConfiguraÃ§Ã£o personalizada |
| `03_chatbot_with_memory.py` | Chatbot com memÃ³ria |
| `04_graph_analysis.py` | AnÃ¡lise do grafo |
| `05_batch_processing.py` | Processamento em lote |
| `06_authentication.py` | Uso com autenticaÃ§Ã£o |
| `07_storage_formats.py` | Formatos de armazenamento (JSON/TOON) |
| `08_azure_openai.py` | **IntegraÃ§Ã£o com Azure OpenAI** |

## ğŸ”¬ Performance

| MÃ©trica | Context Window | GRKMemory |
|---------|----------------|-----------|
| Tokens/query | ~50.000 | ~2.500 |
| Economia | - | **95%** |
| PrecisÃ£o | VariÃ¡vel | **95%** |
| Velocidade | Lenta | **10x mais rÃ¡pido** |

## ğŸ“ Contato

Para obter seu token de acesso ou suporte:

ğŸ“§ **Email:** contato@monkai.com.br  
ğŸŒ **Site:** [www.monkai.com.br](https://www.monkai.com.br)

## ğŸ“„ LicenÃ§a

MIT License - veja [LICENSE](LICENSE)

## ğŸ‘¨â€ğŸ’» Autor

**Arthur Vaz** - [MonkAI](https://www.monkai.com.br)
