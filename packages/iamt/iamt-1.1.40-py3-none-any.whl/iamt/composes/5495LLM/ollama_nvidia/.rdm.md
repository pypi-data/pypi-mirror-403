
https://www.ollama.com/search
https://github.com/ollama/ollama/blob/main/docs/docker.md


https://hub.docker.com/r/ollama/ollama/tags



docker run -d --gpus=all -v ./ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama:0.5.13 
# nvidia gpu 一句话运行容器 
docker exec -it ollama ollama run qwen2.5:0.5b
# 直接下载并运行一个400MB模型 看了一下 确实100%GPU 可以说很棒了  


docker exec -it ollama ollama run qwen3:32b
# 测试圆满成功 就是这玩意 需要一个系统来保护一下要不然容易被被人白嫖 


# 我今天发现只需要把 模型下载下来就行好像完全不用运行 
# 然后调用的时候会自动运行 相关的模型 然后就是 调用完成之后 过一段时间 会自当卸载模型  