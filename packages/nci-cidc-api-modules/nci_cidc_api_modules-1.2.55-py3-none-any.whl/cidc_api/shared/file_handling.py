from pathlib import Path

from pandas import Series, DataFrame
from sqlalchemy.orm.session import Session
from werkzeug.datastructures import FileStorage
from werkzeug.exceptions import BadRequest, InternalServerError

from ..config.logging import get_logger
from ..config.settings import GOOGLE_CLINICAL_DATA_BUCKET
from ..models import PreprocessedFiles, TRIAL_APPENDIX_A_CELL_THAT_ENDS_THE_HEADER
from ..shared.auth import get_current_user
from ..shared.gcloud_client import upload_file_to_gcs, move_gcs_file
from ..telemetry import trace_

logger = get_logger(__name__)

MASTER_APPENDIX_A_VERSION_PREFIX = "Master Appendix A Version:"


@trace_()
def set_current_file(
    file: FileStorage,
    file_category: str,
    gcs_folder: str,
    session: Session,
    uploader_email: str,
    job_id: int = None,
    append_timestamp: bool = None,
) -> PreprocessedFiles:
    """
    Archives any existing 'current' files for the given category and job,
    then uploads the new file as the latest 'current' version.
    """
    latest_version = PreprocessedFiles.archive_current_files(file_category, job_id=job_id, session=session)
    latest_file = create_file(
        file, gcs_folder, file_category, session, uploader_email, job_id, latest_version + 1, append_timestamp
    )
    return latest_file


@trace_()
def create_file(
    file: FileStorage,
    gcs_folder: str,
    file_category: str,
    session: Session,
    uploader_email: str,
    job_id: int = None,
    version: int = None,
    append_timestamp: bool = None,
) -> PreprocessedFiles:
    """Upload file to GCS and create corresponding metadata record in the database."""
    status = "pending" if gcs_folder.endswith("pending/") else "current"
    # only need timestamp for current/versioned files, if not specified otherwise
    append_timestamp = append_timestamp if append_timestamp is not None else (status == "current")
    # create file in GCS
    gcs_file_path = upload_file_to_gcs(file, GOOGLE_CLINICAL_DATA_BUCKET, gcs_folder, append_timestamp=append_timestamp)
    # create corresponding record in db
    file = PreprocessedFiles.create(
        file_name=file.filename,
        object_url=gcs_file_path,
        file_category=file_category,
        uploader_email=uploader_email,
        status=status,
        job_id=job_id,
        version=version,
        session=session,
    )
    return file


def validate_file_extension(filename: str, allowed_extensions: list[str]):
    if not filename or not any(filename.lower().endswith(ext) for ext in allowed_extensions):
        raise BadRequest(f"Invalid file type. Must be one of: {allowed_extensions}")


def format_common_preprocessed_file_response(file: PreprocessedFiles):
    """Format a common response for a single PreprocessedFiles record."""
    return {
        "file_name": file.file_name,
        "gcs_uri": f"gs://{GOOGLE_CLINICAL_DATA_BUCKET}/{file.object_url}",
        "status": file.status,
        "file_category": file.file_category,
        "uploader_email": file.uploader_email,
        "date": file._created.isoformat(),
    }


def version_pending_file(pending_file: PreprocessedFiles):
    """Transitions an existing pending file to be a current versioned file."""
    original_filename = pending_file.file_name
    pending_gcs_path = pending_file.object_url
    try:
        versioned_gcs_folder = strip_filename_and_pending_folder(pending_gcs_path)
        new_gcs_path = move_gcs_file(GOOGLE_CLINICAL_DATA_BUCKET, pending_gcs_path, versioned_gcs_folder)
    except Exception as e:
        logger.error(str(e))
        raise InternalServerError(str(e))
    # Move any 'current' file(s) to 'archived' status
    latest_version = PreprocessedFiles.archive_current_files(pending_file.file_category, pending_file.job_id)
    # Insert new current/versioned DB record
    PreprocessedFiles.create(
        file_name=original_filename,
        object_url=new_gcs_path,
        file_category=pending_file.file_category,
        uploader_email=get_current_user().email,
        status="current",
        job_id=pending_file.job_id,
        version=latest_version + 1,
    )
    # Delete pending record
    pending_file.delete()
    return new_gcs_path


def strip_filename_and_pending_folder(path_str):
    """Returns the file path above the 'pending' folder to be used for versioned files."""
    path = Path(path_str)
    if path.parent.name != "pending":
        raise ValueError("Expected 'pending' folder above file")
    return str(path.parent.parent)


def get_row_at_condition(df: DataFrame, condition):
    condition_met_index = df[condition].index[0]
    row_at_condition_series = df.iloc[condition_met_index]

    return row_at_condition_series


def get_column(header_row_series: Series, header_name: str, use_raw_header_val: bool = False):
    for idx, raw_header in enumerate(header_row_series):
        if str(raw_header).lower() == header_name.lower():
            return raw_header if use_raw_header_val else header_row_series.index[idx]
    return None


def get_column_from_appendix_a(appendix_a_df: DataFrame, header_name: str):
    category_column = appendix_a_df.columns[0]
    aa_header_condition = appendix_a_df[category_column] == TRIAL_APPENDIX_A_CELL_THAT_ENDS_THE_HEADER
    header_row_series = get_row_at_condition(appendix_a_df, aa_header_condition)
    return get_column(header_row_series, header_name)


def get_column_from_first_row(df: DataFrame, header_name: str):
    use_raw_header_val = False
    if df.columns.inferred_type == "integer":
        # If columns are integers (i.e. file was read without headers), treat the first row as header values.
        header_row_series = df.iloc[0]
    else:
        # Otherwise columns already are headers
        header_row_series = Series(df.columns)
        use_raw_header_val = True

    return get_column(header_row_series, header_name, use_raw_header_val=use_raw_header_val)
