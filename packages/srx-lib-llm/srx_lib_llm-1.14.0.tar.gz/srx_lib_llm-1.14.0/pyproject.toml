[build-system]
requires = ["hatchling==1.18.0"]
build-backend = "hatchling.build"

[project]
name = "srx-lib-llm"
version = "1.14.0"
description = "LLM helpers for SRX services: ChatOpenAI wrapper, tool base, Tavily tool, OpenAI Batch API, and infrastructure-agnostic batch state management"
readme = "README.md"
requires-python = ">=3.12"
authors = [{ name = "SRX", email = "dev@srx.id" }]
dependencies = [
  "openai>=2.6.1,<3",
  "langchain>=1.0.7",
  "langchain-core>=1.0.5",
  "langchain-community>=0.4.1",
  "langchain-openai>=1.0.3",
  "langgraph>=1.0.3",
  "langfuse>=3.8.0,<4",
  "tavily-python>=0.7.13,<0.8",
  "httpx>=0.27.0,<1",
]

[project.optional-dependencies]
dev = [
  "pytest>=8.0.0,<9",
  "pytest-asyncio>=0.23.0,<1",
]

[tool.hatch.build.targets.wheel]
packages = ["src/srx_lib_llm"]

[tool.hatch.build.targets.sdist]
exclude = [
  ".venv",
  "venv",
]

[tool.ruff]
line-length = 100
target-version = "py312"
