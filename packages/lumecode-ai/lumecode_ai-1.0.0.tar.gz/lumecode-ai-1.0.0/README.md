<div align="center">

# ðŸ”® Lumecode

**AI-powered coding agent with multi-model LLM support**

[![PyPI version](https://badge.fury.io/py/lumecode.svg)](https://badge.fury.io/py/lumecode)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

</div>

---

## Installation

```bash
pip install lumecode
```

## Usage

```bash
# Start interactive TUI
lumecode

# Show help
lumecode --help
```

## Configuration

Set your LLM provider API key:

```bash
# OpenAI
export LUMECODE_PROVIDER=openai
export LUMECODE_API_KEY=sk-...

# Anthropic
export LUMECODE_PROVIDER=anthropic
export LUMECODE_API_KEY=sk-ant-...

# Ollama (local)
export LUMECODE_PROVIDER=ollama
```

## Features

- ðŸ¤– 7 specialized AI agents
- ðŸ”— 6 LLM providers (OpenAI, Anthropic, Gemini, Groq, Ollama, DeepSeek)
- ðŸŽ¯ Interactive TUI with parallel execution
- ðŸ“Š Smart code analysis

## Links

- [GitHub Repository](https://github.com/anonymus-netizien/lumecode)
- [Documentation](https://github.com/anonymus-netizien/lumecode#readme)
- [Releases](https://github.com/anonymus-netizien/lumecode/releases)

## License

MIT License - see [LICENSE](https://github.com/anonymus-netizien/lumecode/blob/main/LICENSE)
