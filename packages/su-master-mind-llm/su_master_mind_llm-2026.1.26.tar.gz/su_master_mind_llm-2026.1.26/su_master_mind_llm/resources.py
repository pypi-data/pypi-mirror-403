"""Auto-generated downloadable resources configuration.

WARNING: This file is automatically generated by scripts/generate_plugin.py
Do not edit manually - your changes will be overwritten!
"""

from typing import Dict, List

from master_mind.plugin import (
    DownloadableResource,
    make_pyterrier_dataset_resource,
)
from master_mind.teaching.hf import (
    make_hf_dataset_resource,
    make_hf_model_resource,
    make_hf_processor_resource,
    make_hf_tokenizer_resource,
)


def get_downloadable_resources() -> Dict[str, List[DownloadableResource]]:
    """Get downloadable resources for all practicals.

    Returns:
        Dictionary mapping practical IDs to lists of downloadable resources.
    """
    return {
        "practical1": [
            make_hf_model_resource(
                "distilbert-base-uncased",
                model_class="AutoModel",
            ),
            make_hf_tokenizer_resource(
                "distilbert-base-uncased",
                tokenizer_class="AutoTokenizer",
            ),
        ],
        "practical2": [
            make_hf_model_resource(
                "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                model_class="AutoModelForCausalLM",
            ),
            make_hf_tokenizer_resource(
                "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                tokenizer_class="AutoTokenizer",
            ),
            make_hf_dataset_resource(
                "imdb",
                "train",
            ),
        ],
        "practical3": [
            make_hf_model_resource(
                "distilbert-base-uncased-finetuned-sst-2-english",
                model_class="AutoModelForSequenceClassification",
            ),
            make_hf_tokenizer_resource(
                "distilbert-base-uncased-finetuned-sst-2-english",
                tokenizer_class="AutoTokenizer",
            ),
            make_hf_dataset_resource(
                "imdb",
                "train",
            ),
        ],
        "practical4": [
            make_hf_model_resource(
                "HuggingFaceTB/SmolLM2-1.7B-Instruct",
                model_class="AutoModelForCausalLM",
            ),
            make_hf_tokenizer_resource(
                "HuggingFaceTB/SmolLM2-1.7B-Instruct",
                tokenizer_class="AutoTokenizer",
            ),
            make_hf_tokenizer_resource(
                "Qwen/Qwen3-0.6B",
                tokenizer_class="AutoTokenizer",
            ),
            make_pyterrier_dataset_resource(
                "irds:lotte/technology/dev/search",
                "lotte technology dev search dataset",
            ),
        ],
        "practical5": [
            make_hf_model_resource(
                "HuggingFaceTB/SmolLM2-1.7B-Instruct",
                model_class="AutoModelForCausalLM",
            ),
            make_hf_tokenizer_resource(
                "HuggingFaceTB/SmolLM2-1.7B-Instruct",
                tokenizer_class="AutoTokenizer",
            ),
            make_pyterrier_dataset_resource(
                "irds:lotte/technology/dev/search",
                "lotte technology dev search dataset",
            ),
        ],
        "practical6": [
            make_hf_model_resource(
                "openai/clip-vit-base-patch32",
                model_class="CLIPModel",
            ),
            make_hf_model_resource(
                "Qwen/Qwen2.5-3B-Instruct",
                model_class="AutoModelForCausalLM",
            ),
            make_hf_model_resource(
                "Qwen/Qwen2.5-0.5B-Instruct",
                model_class="AutoModelForCausalLM",
            ),
            make_hf_tokenizer_resource(
                "Qwen/Qwen2.5-3B-Instruct",
                tokenizer_class="AutoTokenizer",
            ),
            make_hf_processor_resource(
                "openai/clip-vit-base-patch32",
                processor_class="CLIPProcessor",
            ),
            make_hf_dataset_resource(
                "jxie/flickr8k",
                "train",
            ),
        ],
        "practical7": [
            make_hf_model_resource(
                "HuggingFaceTB/SmolLM2-1.7B-Instruct",
                model_class="AutoModelForCausalLM",
            ),
            make_hf_tokenizer_resource(
                "HuggingFaceTB/SmolLM2-1.7B-Instruct",
                tokenizer_class="AutoTokenizer",
            ),
            make_hf_model_resource(
                "gpt2",
                model_class="GPT2LMHeadModel",
            ),
            make_hf_tokenizer_resource(
                "gpt2",
                tokenizer_class="GPT2Tokenizer",
            ),
            make_hf_model_resource(
                "distilgpt2",
                model_class="GPT2LMHeadModel",
            ),
            make_hf_model_resource(
                "gpt2-medium",
                model_class="GPT2LMHeadModel",
            ),
            make_hf_tokenizer_resource(
                "distilgpt2",
                tokenizer_class="GPT2Tokenizer",
            ),
            make_hf_tokenizer_resource(
                "gpt2-medium",
                tokenizer_class="GPT2Tokenizer",
            ),
        ],
    }