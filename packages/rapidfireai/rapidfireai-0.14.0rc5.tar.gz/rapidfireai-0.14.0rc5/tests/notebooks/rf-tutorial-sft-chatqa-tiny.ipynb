{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<a href=\"https://rapidfire.ai/\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/RapidFire - Blue bug -white text.svg\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/6vSTtncKNN\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/discord-button.svg\" width=\"145\"></a>\n",
    "<a href=\"https://oss-docs.rapidfire.ai/\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/documentation-button.svg\" width=\"125\"></a>\n",
    "<br/>\n",
    "Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/RapidFireAI/rapidfireai\">GitHub</a></i> ⭐\n",
    "<br/>\n",
    "To install RapidFire AI on your own machine, see the <a href=\"https://oss-docs.rapidfire.ai/en/latest/walkthrough.html\">Install and Get Started</a> guide in our docs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable all metric loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RF_MLFLOW_ENABLED\"] = \"true\"\n",
    "os.environ[\"RF_TENSORBOARD_ENABLED\"] = \"true\"\n",
    "os.environ[\"RF_TRACKIO_ENABLED\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RapidFire AI Tutorial Use Case: SFT for Customer Support Q&A Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfireai import Experiment\n",
    "from rapidfireai.automl import (\n",
    "    List,\n",
    "    RFGridSearch,\n",
    "    RFModelConfig,\n",
    "    RFLoraConfig,\n",
    "    RFSFTConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Specify Train and Eval Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bitext/Bitext-customer-support-llm-chatbot-training-dataset\")\n",
    "\n",
    "# Select a subset of the dataset for demo purposes\n",
    "train_dataset = dataset[\"train\"].select(range(4))\n",
    "eval_dataset = dataset[\"train\"].select(range(10, 11))\n",
    "train_dataset = train_dataset.shuffle(seed=42)\n",
    "eval_dataset = eval_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_formatting_function(example):\n",
    "    \"\"\"Format the dataset for GPT-2 while preserving original fields\"\"\"\n",
    "    return {\n",
    "        \"text\": f\"Question: {example['instruction']}\\nAnswer: {example['response']}\",\n",
    "        \"instruction\": example[\"instruction\"],  # Keep original\n",
    "        \"response\": example[\"response\"],  # Keep original\n",
    "    }\n",
    "\n",
    "\n",
    "# Apply formatting to datasets\n",
    "eval_dataset = eval_dataset.map(sample_formatting_function)\n",
    "train_dataset = train_dataset.map(sample_formatting_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every experiment instance must be uniquely named\n",
    "experiment = Experiment(experiment_name=\"exp1-chatqa-tiny\", mode=\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Eval Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_compute_metrics(eval_preds):\n",
    "    \"\"\"Optional function to compute eval metrics based on predictions and labels\"\"\"\n",
    "    predictions, labels = eval_preds\n",
    "\n",
    "    # Standard text-based eval metrics: Rouge and BLEU\n",
    "    import evaluate\n",
    "\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "    rouge_output = rouge.compute(\n",
    "        predictions=predictions, references=labels, use_stemmer=True\n",
    "    )\n",
    "    rouge_l = rouge_output[\"rougeL\"]\n",
    "    bleu_output = bleu.compute(predictions=predictions, references=labels)\n",
    "    bleu_score = bleu_output[\"bleu\"]\n",
    "\n",
    "    return {\n",
    "        \"rougeL\": round(rouge_l, 4),\n",
    "        \"bleu\": round(bleu_score, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Multi-Config Knobs for Model, LoRA, and SFT Trainer using RapidFire AI Wrapper APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 specific LoRA configs - different module names!\n",
    "peft_configs_tiny = List(\n",
    "    [\n",
    "        RFLoraConfig(\n",
    "            r=8,\n",
    "            lora_alpha=16,\n",
    "            lora_dropout=0.1,\n",
    "            target_modules=[\"c_attn\"],  # GPT-2 combines Q,K,V in c_attn\n",
    "            bias=\"none\",\n",
    "        ),\n",
    "        RFLoraConfig(\n",
    "            r=8,\n",
    "            lora_alpha=32,\n",
    "            lora_dropout=0.1,\n",
    "            target_modules=[\"c_attn\", \"c_proj\"],  # c_attn (QKV) + c_proj (output)\n",
    "            bias=\"none\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 2 configs with GPT-2\n",
    "config_set_tiny = List(\n",
    "    [\n",
    "        RFModelConfig(\n",
    "            model_name=\"gpt2\",  # Only 124M params\n",
    "            peft_config=peft_configs_tiny,\n",
    "            training_args=RFSFTConfig(\n",
    "                learning_rate=5e-4,  # Low lr for more stability\n",
    "                lr_scheduler_type=\"linear\",\n",
    "                per_device_train_batch_size=1,  # Effective bs = 4\n",
    "                max_steps=8,  # Raise this to see more learning\n",
    "                logging_steps=2,\n",
    "                eval_strategy=\"steps\",\n",
    "                eval_steps=4,\n",
    "                per_device_eval_batch_size=1,\n",
    "                fp16=True,\n",
    "                report_to=\"none\",  # Disables wandb\n",
    "            ),\n",
    "            model_type=\"causal_lm\",\n",
    "            model_kwargs={\n",
    "                \"device_map\": \"auto\",\n",
    "                \"torch_dtype\": \"float16\",  # Explicit fp16\n",
    "                \"use_cache\": False,\n",
    "            },\n",
    "            formatting_func=sample_formatting_function,\n",
    "            compute_metrics=sample_compute_metrics,\n",
    "            generation_config={\n",
    "                \"max_new_tokens\": 128,  # Reduced from 256\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.9,\n",
    "                \"top_k\": 40,\n",
    "                \"repetition_penalty\": 1.1,\n",
    "                \"pad_token_id\": 50256,  # GPT-2's EOS token\n",
    "            },\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model Creation Function for All Model Types Across Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_create_model(model_config):\n",
    "    \"\"\"Function to create model object with GPT-2 adjustments\"\"\"\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "    model_name = model_config[\"model_name\"]\n",
    "    model_type = model_config[\"model_type\"]\n",
    "    model_kwargs = model_config[\"model_kwargs\"]\n",
    "\n",
    "    if model_type == \"causal_lm\":\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, **model_kwargs)\n",
    "    else:\n",
    "        # Default to causal LM\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, **model_kwargs)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # GPT-2 specific: Set pad token (GPT-2 doesn't have one by default)\n",
    "    if \"gpt2\" in model_name.lower():\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.padding_side = \"left\"  # GPT-2 works better with left padding\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "    return (model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Config Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple grid search across all sets of config knob values = 4 combinations in total\n",
    "config_group = RFGridSearch(configs=config_set_tiny, trainer_type=\"SFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "from rapidfireai.utils.metric_rfmetric_manager import RFMetricLogger\n",
    "metric_loggers = RFMetricLogger.get_default_metric_loggers(experiment_name=experiment.experiment_name)\n",
    "tensorboard_log_dir = metric_loggers.get(\"rf_tensorboard\", {}).get(\"config\", {}).get(\"log_dir\", \".\")\n",
    "\n",
    "print(f\"TensorBoard logs will be saved to: {tensorboard_log_dir}\")\n",
    "%tensorboard --logdir {tensorboard_log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Multi-Config Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch training of all configs in the config_group with swap granularity of 4 chunks\n",
    "experiment.run_fit(\n",
    "    config_group,\n",
    "    sample_create_model,\n",
    "    train_dataset,\n",
    "    eval_dataset,\n",
    "    num_chunks=2,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Current Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<a href=\"https://rapidfire.ai/\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/RapidFire - Blue bug -white text.svg\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/6vSTtncKNN\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/discord-button.svg\" width=\"145\"></a>\n",
    "<a href=\"https://oss-docs.rapidfire.ai/\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/documentation-button.svg\" width=\"125\"></a>\n",
    "<br/>\n",
    "Thanks for trying RapidFire AI! ⭐ <i>Star us on <a href=\"https://github.com/RapidFireAI/rapidfireai\">GitHub</a></i> ⭐\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
