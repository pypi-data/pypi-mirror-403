{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<a href=\"https://rapidfire.ai/\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/RapidFire - Blue bug -white text.svg\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/6vSTtncKNN\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/discord-button.svg\" width=\"145\"></a>\n",
    "<a href=\"https://oss-docs.rapidfire.ai/\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/documentation-button.svg\" width=\"125\"></a>\n",
    "<br/>\n",
    "Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/RapidFireAI/rapidfireai\">GitHub</a></i> ⭐\n",
    "<br/>\n",
    "To install RapidFire AI on your own machine, see the <a href=\"https://oss-docs.rapidfire.ai/en/latest/walkthrough.html\">Install and Get Started</a> guide in our docs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RapidFire AI Tutorial: SFT with Trackio Experiment Tracking\n",
    "\n",
    "This tutorial demonstrates how to use **[Trackio](https://github.com/gradio-app/trackio)** as the experiment tracking backend for RapidFire AI. Trackio is a lightweight, local-first experiment tracking library that provides:\n",
    "\n",
    "- **No server required**: Runs entirely locally with no external dependencies\n",
    "- **Simple API**: Just `trackio.init()`, `trackio.log()`, and `trackio.finish()`\n",
    "- **Beautiful dashboard**: View metrics with `trackio show` command\n",
    "- **Gradio integration**: Built by the Gradio team for seamless ML workflow integration\n",
    "\n",
    "We'll fine-tune a model on customer support data using Supervised Fine-Tuning (SFT) while tracking all metrics with Trackio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Trackio as the Tracking Backend\n",
    "\n",
    "RapidFire AI supports multiple tracking backends: MLflow, TensorBoard, and Trackio. Here we configure Trackio as the **standalone** tracking backend by setting environment variables **before** importing RapidFire components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Enable Trackio as the tracking backend\n",
    "os.environ[\"RF_TRACKIO_ENABLED\"] = \"true\"\n",
    "\n",
    "# Disable other tracking backends for standalone Trackio usage\n",
    "os.environ[\"RF_MLFLOW_ENABLED\"] = \"false\"\n",
    "os.environ[\"RF_TENSORBOARD_ENABLED\"] = \"false\"\n",
    "\n",
    "print(\"✅ Trackio configured as standalone tracking backend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import RapidFire Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfireai import Experiment\n",
    "from rapidfireai.automl import List, RFGridSearch, RFModelConfig, RFLoraConfig, RFSFTConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Trackio: What Gets Tracked\n",
    "\n",
    "[Trackio](https://github.com/gradio-app/trackio) is a free, open-source experiment tracking library from Hugging Face. When enabled in RapidFire AI, it automatically captures:\n",
    "\n",
    "**Training Metrics (logged every `logging_steps`):**\n",
    "- `loss` - Training loss at each logging step\n",
    "- `learning_rate` - Current learning rate (useful for seeing scheduler effects)\n",
    "- `epoch` and `step` - Progress indicators\n",
    "\n",
    "**Evaluation Metrics (logged every `eval_steps`):**\n",
    "- `eval_loss` - Validation loss\n",
    "- Custom metrics from your `compute_metrics` function (e.g., `rougeL`, `bleu`)\n",
    "\n",
    "**Run Configuration:**\n",
    "- All hyperparameters (learning rate, batch size, LoRA settings, etc.)\n",
    "- Model name and training arguments\n",
    "\n",
    "**How RapidFire AI integrates with Trackio:**\n",
    "\n",
    "Under the hood, RapidFire AI wraps Trackio's simple API:\n",
    "```python\n",
    "# What RapidFire does automatically:\n",
    "trackio.init(project=\"experiment-name\", name=\"run-name\", config={...})\n",
    "trackio.log({\"loss\": 0.5, \"step\": 100})  # Called during training\n",
    "trackio.finish()  # Called when run completes\n",
    "```\n",
    "\n",
    "You don't need to call these directly—RapidFire handles it. Just enable Trackio and run your experiments!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Specify Train and Eval Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset=load_dataset(\"bitext/Bitext-customer-support-llm-chatbot-training-dataset\")\n",
    "\n",
    "# Select a subset of the dataset for demo purposes\n",
    "train_dataset=dataset[\"train\"].select(range(128))\n",
    "eval_dataset=dataset[\"train\"].select(range(100,124))\n",
    "train_dataset=train_dataset.shuffle(seed=42)\n",
    "eval_dataset=eval_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_formatting_function(row):\n",
    "    \"\"\"Function to preprocess each example from dataset\"\"\"\n",
    "    # Special tokens for formatting\n",
    "    SYSTEM_PROMPT = \"You are a helpful and friendly customer support assistant. Please answer the user's query to the best of your ability.\"\n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": row[\"instruction\"]},\n",
    "            \n",
    "        ],\n",
    "        \"completion\": [\n",
    "            {\"role\": \"assistant\", \"content\": row[\"response\"]}\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Experiment\n",
    "\n",
    "When Trackio is enabled, RapidFire AI will automatically initialize Trackio with the experiment name and log all training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every experiment instance must be uniquely named\n",
    "experiment = Experiment(experiment_name=\"exp1-sft-trackio-demo\", mode=\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Eval Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_compute_metrics(eval_preds):  \n",
    "    \"\"\"Optional function to compute eval metrics based on predictions and labels\"\"\"\n",
    "    predictions, labels = eval_preds\n",
    "\n",
    "    # Standard text-based eval metrics: Rouge and BLEU\n",
    "    import evaluate\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=predictions, references=labels, use_stemmer=True)\n",
    "    rouge_l = rouge_output[\"rougeL\"]\n",
    "    bleu_output = bleu.compute(predictions=predictions, references=labels)\n",
    "    bleu_score = bleu_output[\"bleu\"]\n",
    "\n",
    "    return {\n",
    "        \"rougeL\": round(rouge_l, 4),\n",
    "        \"bleu\": round(bleu_score, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Multi-Config Knobs for Model, LoRA, and SFT Trainer using RapidFire AI Wrapper APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 LoRA PEFT configs lite with different adapter capacities\n",
    "peft_configs_lite = List([\n",
    "    RFLoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],  # Standard transformer naming\n",
    "        bias=\"none\"\n",
    "    ),\n",
    "    RFLoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=64,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # Standard naming\n",
    "        bias=\"none\"\n",
    "    )\n",
    "])\n",
    "\n",
    "# 2 base models x 2 peft configs = 4 combinations in total\n",
    "config_set_lite = List([\n",
    "    RFModelConfig(\n",
    "        model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",  # 1.1B model\n",
    "        peft_config=peft_configs_lite,\n",
    "        training_args=RFSFTConfig(\n",
    "            learning_rate=1e-3,  # Higher LR for very small model\n",
    "            lr_scheduler_type=\"linear\",\n",
    "            per_device_train_batch_size=4,\n",
    "            per_device_eval_batch_size=4,\n",
    "            max_steps=128,\n",
    "            gradient_accumulation_steps=1,   # No accumulation needed\n",
    "            logging_steps=2,\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=4,\n",
    "            fp16=True,\n",
    "        ),\n",
    "        model_type=\"causal_lm\",\n",
    "        model_kwargs={\"device_map\": \"auto\", \"torch_dtype\": \"auto\", \"use_cache\": False},\n",
    "        formatting_func=sample_formatting_function,\n",
    "        compute_metrics=sample_compute_metrics,\n",
    "        generation_config={\n",
    "            \"max_new_tokens\": 256,\n",
    "            \"temperature\": 0.8,  # Higher temp for tiny model\n",
    "            \"top_p\": 0.9,\n",
    "            \"top_k\": 30,         # Reduced top_k\n",
    "            \"repetition_penalty\": 1.05,\n",
    "        }\n",
    "    ),\n",
    "    RFModelConfig(\n",
    "        model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",  # 1.1B model\n",
    "        peft_config=peft_configs_lite,\n",
    "        training_args=RFSFTConfig(\n",
    "            learning_rate=1e-4,  # Higher LR for very small model\n",
    "            lr_scheduler_type=\"linear\",\n",
    "            per_device_train_batch_size=4,  # Even larger batch size\n",
    "            per_device_eval_batch_size=4,\n",
    "            max_steps=128,\n",
    "            gradient_accumulation_steps=1,   # No accumulation needed\n",
    "            logging_steps=2,\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=4,\n",
    "            fp16=True,\n",
    "        ),\n",
    "        model_type=\"causal_lm\",\n",
    "        model_kwargs={\"device_map\": \"auto\", \"torch_dtype\": \"auto\", \"use_cache\": False},\n",
    "        formatting_func=sample_formatting_function,\n",
    "        compute_metrics=sample_compute_metrics,\n",
    "        generation_config={\n",
    "            \"max_new_tokens\": 256,\n",
    "            \"temperature\": 0.8,  # Higher temp for tiny model\n",
    "            \"top_p\": 0.9,\n",
    "            \"top_k\": 30,         # Reduced top_k\n",
    "            \"repetition_penalty\": 1.05,\n",
    "        }\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model Creation Function for All Model Types Across Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_create_model(model_config): \n",
    "     \"\"\"Function to create model object for any given config; must return tuple of (model, tokenizer)\"\"\"\n",
    "     from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM\n",
    "\n",
    "     model_name = model_config[\"model_name\"]\n",
    "     model_type = model_config[\"model_type\"]\n",
    "     model_kwargs = model_config[\"model_kwargs\"]\n",
    " \n",
    "     if model_type == \"causal_lm\":\n",
    "          model = AutoModelForCausalLM.from_pretrained(model_name, **model_kwargs)\n",
    "     elif model_type == \"seq2seq_lm\":\n",
    "          model = AutoModelForSeq2SeqLM.from_pretrained(model_name, **model_kwargs)\n",
    "     elif model_type == \"masked_lm\":\n",
    "          model = AutoModelForMaskedLM.from_pretrained(model_name, **model_kwargs)\n",
    "     elif model_type == \"custom\":\n",
    "          # Handle custom model loading logic, e.g., loading your own checkpoints\n",
    "          # model = ... \n",
    "          pass\n",
    "     else:\n",
    "          # Default to causal LM\n",
    "          model = AutoModelForCausalLM.from_pretrained(model_name, **model_kwargs)\n",
    "      \n",
    "     tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "      \n",
    "     return (model,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Config Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple grid search across all sets of config knob values = 4 combinations in total\n",
    "config_group = RFGridSearch(\n",
    "    configs=config_set_lite,\n",
    "    trainer_type=\"SFT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Multi-Config Training\n",
    "\n",
    "All training metrics will be automatically logged to Trackio. You can view them in real-time using the Trackio dashboard (see next section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch training of all configs in the config_group with swap granularity of 4 chunks\n",
    "experiment.run_fit(config_group, sample_create_model, train_dataset, eval_dataset, num_chunks=4, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Metrics with Trackio Dashboard\n",
    "\n",
    "Trackio provides a beautiful Gradio-powered dashboard to visualize your experiment metrics. You can launch it in two ways:\n",
    "\n",
    "**Option 1: From a terminal** (recommended for real-time viewing during training)\n",
    "```bash\n",
    "trackio show\n",
    "```\n",
    "\n",
    "**Option 2: From Python** (opens the dashboard in your browser)\n",
    "```python\n",
    "import trackio\n",
    "trackio.show()\n",
    "```\n",
    "\n",
    "You can also load a specific project directly:\n",
    "```bash\n",
    "trackio show --project \"exp1-sft-trackio-demo\"\n",
    "```\n",
    "\n",
    "**What You'll See in the Dashboard:**\n",
    "\n",
    "- **Loss Curves**: Each of your 4 parallel runs will show training loss over steps\n",
    "- **Evaluation Metrics**: ROUGE-L and BLEU scores from your `compute_metrics` function\n",
    "- **Run Comparison**: Select/deselect runs, zoom into step ranges, apply smoothing\n",
    "- **Hyperparameters**: View all logged configuration for each run\n",
    "\n",
    "**Pro Tips:**\n",
    "- Open the dashboard in a separate browser tab while training runs\n",
    "- Metrics update in real-time as training progresses\n",
    "- Use the project filter if you have multiple experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines to launch the Trackio dashboard\n",
    "# import trackio\n",
    "# trackio.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Trackio Insights with RapidFire's Interactive Control (IC Ops)\n",
    "\n",
    "One of RapidFire AI's unique features is **Interactive Control Operations (IC Ops)**, which lets you control experiments in real-time. Combined with Trackio's observability, you get a powerful workflow:\n",
    "\n",
    "**The Workflow:**\n",
    "\n",
    "1. **Monitor in Trackio**: Watch your parallel runs in the Trackio dashboard as they train\n",
    "2. **Identify patterns**: Spot runs with poor loss curves, diverging metrics, or slow convergence\n",
    "3. **Take action with IC Ops**: \n",
    "   - **Stop** underperforming runs to free up GPU resources\n",
    "   - **Clone** promising configurations and modify parameters\n",
    "   - **Resume** stopped runs if you want to continue training\n",
    "\n",
    "**Example Scenario:**\n",
    "\n",
    "You're running 4 configurations in parallel. In Trackio, you notice:\n",
    "- Run 1 (lr=1e-3, r=8): Loss dropping quickly, good convergence\n",
    "- Run 2 (lr=1e-3, r=32): Similar to Run 1, slightly better eval metrics\n",
    "- Run 3 (lr=1e-4, r=8): Loss dropping slowly, may need more steps\n",
    "- Run 4 (lr=1e-4, r=32): Loss barely moving, likely too low learning rate\n",
    "\n",
    "**Actions you might take:**\n",
    "- Stop Run 4 (not converging) to free GPU memory\n",
    "- Clone Run 2 with a different scheduler to see if you can improve further\n",
    "- Let Runs 1-3 continue to completion\n",
    "\n",
    "This turns experiment tracking from passive observation into **active experiment management**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Current Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this tutorial, you learned how to:\n",
    "\n",
    "1. **Configure Trackio** as the standalone tracking backend for RapidFire AI\n",
    "2. **Understand what gets tracked** - training metrics, eval metrics, and hyperparameters\n",
    "3. **Run multi-config training** with automatic metric logging to Trackio\n",
    "4. **View and compare experiments** using the Trackio dashboard\n",
    "5. **Combine Trackio insights with IC Ops** for active experiment management\n",
    "\n",
    "**Why Trackio + RapidFire AI?**\n",
    "- **Free and open source**: No usage limits, no vendor lock-in\n",
    "- **Local-first**: No server setup, metrics stored locally and persist between sessions\n",
    "- **Real-time visibility**: Compare parallel runs as they train\n",
    "- **Actionable insights**: Use Trackio data to guide IC Ops decisions\n",
    "\n",
    "**Learn More:**\n",
    "- [Trackio GitHub Repository](https://github.com/gradio-app/trackio) - Full documentation and examples\n",
    "- [Trackio Documentation](https://huggingface.co/docs/trackio/index) - API reference\n",
    "- [RapidFire AI Documentation](https://oss-docs.rapidfire.ai/) - Getting started guide\n",
    "- [RapidFire AI + Trackio Announcement](https://github.com/RapidFireAI/rapidfireai/blob/main/tutorial_notebooks/fine-tuning/Co-Announcement%20Blog%20Trackio%20and%20RapidFire%20AI.md) - Co-authored blog post with Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<a href=\"https://rapidfire.ai/\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/RapidFire - Blue bug -white text.svg\" width=\"115\"></a>\n",
    "<a href=\"https://discord.gg/6vSTtncKNN\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/discord-button.svg\" width=\"145\"></a>\n",
    "<a href=\"https://oss-docs.rapidfire.ai/\"><img src=\"https://raw.githubusercontent.com/RapidFireAI/rapidfireai/main/docs/images/documentation-button.svg\" width=\"125\"></a>\n",
    "<br/>\n",
    "Thanks for trying RapidFire AI! ⭐ <i>Star us on <a href=\"https://github.com/RapidFireAI/rapidfireai\">GitHub</a></i> ⭐\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
