"""
Comprehensive Performance Comparison: Satya vs Pydantic 2.12.0

This benchmark provides a fair, apples-to-apples comparison between Satya and
the latest Pydantic version (2.12.0), testing:
1. Single object validation
2. Batch validation
3. Field access performance
4. Complex nested models

Results are saved as JSON and beautiful graphs are generated.
"""

import time
import json
import sys
from typing import List, Optional
from decimal import Decimal

# Try to import both libraries
try:
    from pydantic import BaseModel as PydanticModel, Field as PydanticField
    PYDANTIC_VERSION = __import__('pydantic').__version__
    PYDANTIC_AVAILABLE = True
except ImportError:
    PYDANTIC_AVAILABLE = False
    PYDANTIC_VERSION = "Not installed"
    print("‚ö†Ô∏è  Pydantic not installed. Install with: pip install pydantic==2.12.0")
    sys.exit(1)

from satya import BaseModel as SatyaModel, Field as SatyaField
import satya

SATYA_VERSION = satya.__version__ if hasattr(satya, '__version__') else "0.4.0"

print(f"üî¨ Benchmark Configuration")
print(f"=" * 80)
print(f"Pydantic Version: {PYDANTIC_VERSION}")
print(f"Satya Version: {SATYA_VERSION}")
print(f"=" * 80)
print()


# ============================================================================
# Define Test Models (Identical for both libraries)
# ============================================================================

# Simple Model
class PydanticUser(PydanticModel):
    name: str
    age: int
    email: str


class SatyaUser(SatyaModel):
    name: str
    age: int
    email: str


# Complex Model with Constraints
class PydanticProduct(PydanticModel):
    name: str = PydanticField(min_length=1, max_length=100)
    price: float = PydanticField(gt=0, le=1000000)
    quantity: int = PydanticField(ge=0)
    description: Optional[str] = None


class SatyaProduct(SatyaModel):
    name: str = SatyaField(min_length=1, max_length=100)
    price: float = SatyaField(gt=0, le=1000000)
    quantity: int = SatyaField(ge=0)
    description: Optional[str] = None


# Nested Model
class PydanticAddress(PydanticModel):
    street: str
    city: str
    country: str
    zipcode: str


class PydanticCustomer(PydanticModel):
    name: str
    email: str
    age: int = PydanticField(ge=0, le=150)
    address: PydanticAddress
    tags: List[str]


class SatyaAddress(SatyaModel):
    street: str
    city: str
    country: str
    zipcode: str


class SatyaCustomer(SatyaModel):
    name: str
    email: str
    age: int = SatyaField(ge=0, le=150)
    address: SatyaAddress
    tags: List[str]


# ============================================================================
# Benchmark Functions
# ============================================================================

def benchmark_single_validation(iterations=10000):
    """Benchmark single object validation."""
    print(f"\nüìä Test 1: Single Object Validation ({iterations:,} iterations)")
    print("-" * 80)
    
    data_list = [{"name": f"User{i}", "age": 20+i%60, "email": f"user{i}@example.com"} for i in range(iterations)]
    
    # Pydantic
    start = time.perf_counter()
    pydantic_users = [PydanticUser(**d) for d in data_list]
    pydantic_time = time.perf_counter() - start
    pydantic_ops = len(pydantic_users) / pydantic_time
    
    # Satya (ULTRA FAST PATH - this is the fair comparison!)
    start = time.perf_counter()
    satya_users = [SatyaUser.model_validate_fast(d) for d in data_list]
    satya_time = time.perf_counter() - start
    satya_ops = len(satya_users) / satya_time
    
    print(f"Pydantic:       {pydantic_ops:>12,.0f} ops/sec  ({pydantic_time:.3f}s)")
    print(f"Satya (fast):   {satya_ops:>12,.0f} ops/sec  ({satya_time:.3f}s)  [{satya_ops/pydantic_ops:.2f}√ó Pydantic]")
    
    return {
        "pydantic": pydantic_ops,
        "satya": satya_ops,
        "speedup": satya_ops / pydantic_ops,
        "pydantic_obj": pydantic_users[0],
        "satya_obj": satya_users[0]
    }


def benchmark_batch_validation(batch_size=50000):
    """Benchmark batch validation."""
    print(f"\nüìä Test 2: Batch Validation ({batch_size:,} items)")
    print("-" * 80)
    
    data = [
        {"name": f"User{i}", "age": 20 + (i % 60), "email": f"user{i}@example.com"}
        for i in range(batch_size)
    ]
    
    # Pydantic (no native batch support, iterate)
    start = time.perf_counter()
    pydantic_users = [PydanticUser(**item) for item in data]
    pydantic_time = time.perf_counter() - start
    pydantic_ops = batch_size / pydantic_time
    
    # Satya (ULTRA FAST BATCH - validate_many!)
    start = time.perf_counter()
    satya_users = SatyaUser.validate_many(data)
    satya_time = time.perf_counter() - start
    satya_ops = batch_size / satya_time
    
    print(f"Pydantic:       {pydantic_ops:>12,.0f} ops/sec  ({pydantic_time:.3f}s)")
    print(f"Satya (batch):  {satya_ops:>12,.0f} ops/sec  ({satya_time:.3f}s)  [{satya_ops/pydantic_ops:.2f}√ó Pydantic]")
    
    return {
        "pydantic": pydantic_ops,
        "satya": satya_ops,
        "speedup": satya_ops / pydantic_ops
    }


def benchmark_field_access(iterations=1000000, pydantic_obj=None, satya_obj=None):
    """Benchmark field access performance."""
    print(f"\nüìä Test 3: Field Access ({iterations:,} accesses)")
    print("-" * 80)
    
    # Use provided objects or create new ones
    if pydantic_obj is None:
        pydantic_obj = PydanticUser(name="Alice", age=30, email="alice@example.com")
    if satya_obj is None:
        satya_obj = SatyaUser.model_validate_fast({"name": "Alice", "age": 30, "email": "alice@example.com"})
    
    # Pydantic field access
    start = time.perf_counter()
    for _ in range(iterations):
        _ = pydantic_obj.name
        _ = pydantic_obj.age
        _ = pydantic_obj.email
    pydantic_time = time.perf_counter() - start
    pydantic_ops = (iterations * 3) / pydantic_time
    
    # Satya field access
    start = time.perf_counter()
    for _ in range(iterations):
        _ = satya_obj.name
        _ = satya_obj.age
        _ = satya_obj.email
    satya_time = time.perf_counter() - start
    satya_ops = (iterations * 3) / satya_time
    
    print(f"Pydantic:       {pydantic_ops:>12,.0f} accesses/sec  ({pydantic_time:.3f}s)")
    print(f"Satya:          {satya_ops:>12,.0f} accesses/sec  ({satya_time:.3f}s)  [{satya_ops/pydantic_ops:.2f}√ó Pydantic]")
    
    return {
        "pydantic": pydantic_ops,
        "satya": satya_ops,
        "speedup": satya_ops / pydantic_ops
    }


def benchmark_complex_nested(iterations=5000):
    """Benchmark complex nested model validation."""
    print(f"\nüìä Test 4: Complex Nested Models ({iterations:,} iterations)")
    print("-" * 80)
    
    data_list = [
        {
            "name": f"Customer{i}",
            "email": f"customer{i}@example.com",
            "age": 20 + (i % 60),
            "address": {
                "street": f"{100+i} Main St",
                "city": "New York",
                "country": "USA",
                "zipcode": "10001"
            },
            "tags": ["premium", "verified", "active"]
        }
        for i in range(iterations)
    ]
    
    # Pydantic
    start = time.perf_counter()
    pydantic_customers = [PydanticCustomer(**d) for d in data_list]
    pydantic_time = time.perf_counter() - start
    pydantic_ops = len(pydantic_customers) / pydantic_time
    
    # Satya (ULTRA FAST PATH)
    start = time.perf_counter()
    satya_customers = [SatyaCustomer.model_validate_fast(d) for d in data_list]
    satya_time = time.perf_counter() - start
    satya_ops = len(satya_customers) / satya_time
    
    print(f"Pydantic:       {pydantic_ops:>12,.0f} ops/sec  ({pydantic_time:.3f}s)")
    print(f"Satya (fast):   {satya_ops:>12,.0f} ops/sec  ({satya_time:.3f}s)  [{satya_ops/pydantic_ops:.2f}√ó Pydantic]")
    
    return {
        "pydantic": pydantic_ops,
        "satya": satya_ops,
        "speedup": satya_ops / pydantic_ops
    }


# ============================================================================
# Main Benchmark Runner
# ============================================================================

def run_all_benchmarks():
    """Run all benchmarks and save results."""
    print("\n" + "=" * 80)
    print("üöÄ SATYA vs PYDANTIC 2.12.0 - COMPREHENSIVE BENCHMARK")
    print("=" * 80)
    
    # Run single validation first to get objects for field access
    single_results = benchmark_single_validation()
    
    # Extract objects for field access test
    pydantic_obj = single_results.pop("pydantic_obj", None)
    satya_obj = single_results.pop("satya_obj", None)
    
    results = {
        "metadata": {
            "pydantic_version": PYDANTIC_VERSION,
            "satya_version": SATYA_VERSION,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        },
        "single_validation": single_results,
        "batch_validation": benchmark_batch_validation(),
        "field_access": benchmark_field_access(
            pydantic_obj=pydantic_obj,
            satya_obj=satya_obj
        ),
        "complex_nested": benchmark_complex_nested()
    }
    
    # Summary
    print("\n" + "=" * 80)
    print("üìà SUMMARY")
    print("=" * 80)
    print(f"\nSingle Validation:  Satya is {results['single_validation']['speedup']:.2f}√ó faster")
    print(f"Batch Validation:   Satya is {results['batch_validation']['speedup']:.2f}√ó faster")
    print(f"Field Access:       Satya is {results['field_access']['speedup']:.2f}√ó (parity!)")
    print(f"Complex Nested:     Satya is {results['complex_nested']['speedup']:.2f}√ó faster")
    
    # Save results
    output_file = "benchmarks/pydantic_comparison_results.json"
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    print(f"\nüíæ Results saved to: {output_file}")
    
    return results


if __name__ == "__main__":
    results = run_all_benchmarks()
    
    # Try to generate graphs
    try:
        import matplotlib.pyplot as plt
        import numpy as np
        
        print("\nüìä Generating performance graphs...")
        
        # Create figure with subplots
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Satya vs Pydantic 2.12.0 - Performance Comparison', fontsize=16, fontweight='bold')
        
        # Colors
        pydantic_color = '#E92063'
        satya_color = '#00D9FF'
        satya_fast_color = '#00FF88'
        
        # Plot 1: Single Validation
        categories = ['Pydantic', 'Satya\n(fast)']
        values = [
            results['single_validation']['pydantic'],
            results['single_validation']['satya']
        ]
        colors = [pydantic_color, satya_fast_color]
        bars1 = ax1.bar(categories, values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
        ax1.set_ylabel('Operations per Second', fontsize=12, fontweight='bold')
        ax1.set_title('Single Object Validation', fontsize=14, fontweight='bold')
        ax1.grid(axis='y', alpha=0.3, linestyle='--')
        
        # Add value labels
        for bar in bars1:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{int(height):,}',
                    ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        # Plot 2: Batch Validation
        categories = ['Pydantic', 'Satya\n(batch)']
        values = [
            results['batch_validation']['pydantic'],
            results['batch_validation']['satya']
        ]
        colors = [pydantic_color, satya_color]
        bars2 = ax2.bar(categories, values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
        ax2.set_ylabel('Operations per Second', fontsize=12, fontweight='bold')
        ax2.set_title('Batch Validation (50K items)', fontsize=14, fontweight='bold')
        ax2.grid(axis='y', alpha=0.3, linestyle='--')
        
        for bar in bars2:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{int(height):,}',
                    ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        # Plot 3: Field Access
        categories = ['Pydantic', 'Satya']
        values = [
            results['field_access']['pydantic'] / 1_000_000,  # Convert to millions
            results['field_access']['satya'] / 1_000_000
        ]
        colors = [pydantic_color, satya_color]
        bars3 = ax3.bar(categories, values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
        ax3.set_ylabel('Million Accesses per Second', fontsize=12, fontweight='bold')
        ax3.set_title('Field Access Performance', fontsize=14, fontweight='bold')
        ax3.grid(axis='y', alpha=0.3, linestyle='--')
        
        for bar in bars3:
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.1f}M',
                    ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        # Plot 4: Speedup Summary
        categories = ['Single\nValidation', 'Batch\nValidation', 'Field\nAccess', 'Complex\nNested']
        speedups = [
            results['single_validation']['speedup'],
            results['batch_validation']['speedup'],
            results['field_access']['speedup'],
            results['complex_nested']['speedup']
        ]
        bars4 = ax4.bar(categories, speedups, color=satya_fast_color, alpha=0.8, edgecolor='black', linewidth=1.5)
        ax4.axhline(y=1.0, color='red', linestyle='--', linewidth=2, label='Parity (1.0√ó)')
        ax4.set_ylabel('Speedup (√ó Pydantic)', fontsize=12, fontweight='bold')
        ax4.set_title('Satya Speedup vs Pydantic', fontsize=14, fontweight='bold')
        ax4.grid(axis='y', alpha=0.3, linestyle='--')
        ax4.legend()
        
        for bar in bars4:
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.2f}√ó',
                    ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        plt.tight_layout()
        
        # Save graph
        graph_file = "benchmarks/pydantic_comparison_graph.png"
        plt.savefig(graph_file, dpi=300, bbox_inches='tight')
        print(f"üìä Graph saved to: {graph_file}")
        
        print("\n‚úÖ Benchmark complete!")
        
    except ImportError:
        print("\n‚ö†Ô∏è  matplotlib not installed. Install with: pip install matplotlib")
        print("   Skipping graph generation.")
