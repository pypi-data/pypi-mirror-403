"""
Recursive Function Analyzer for LEVEL_4 GPU Acceleration

Solves the problem where outer wrapper functions are rejected by pattern detection
due to external function calls, but their inner functions contain GPU-acceleratable
patterns (stencil, map, reduce).

Key Components:
- FunctionCallExtractor: Extracts function calls from loop bodies
- RecursivePatternAnalyzer: Recursively analyzes extracted functions for GPU patterns
- InnerFunctionGPUWrapper: Creates GPU-accelerated wrappers via closure substitution
- create_gpu_accelerated_version: Main API for creating accelerated outer functions

Example:
    def run_spatial_iterations(F, iterations=10):
        for _ in range(iterations):
            F = spatial_feature_step(F, gamma, beta, alpha)  # Stencil pattern
        return F

    # Without recursive analysis: rejected due to external function call
    # With recursive analysis: spatial_feature_step compiled to GPU, 178x speedup

Author: Epochly Development Team
Date: January 2025
"""

from __future__ import annotations

import ast
import copy
import functools
import inspect
import logging
import threading
import types
import weakref
from dataclasses import dataclass, field
from typing import Any, Callable, Dict, List, Optional, Set, Tuple, Union

logger = logging.getLogger(__name__)


# Safe built-in functions that don't need recursive analysis
SAFE_BUILTINS = frozenset({
    'range', 'len', 'abs', 'min', 'max', 'sum', 'enumerate', 'zip', 'map',
    'filter', 'sorted', 'reversed', 'list', 'tuple', 'dict', 'set', 'frozenset',
    'int', 'float', 'str', 'bool', 'bytes', 'type', 'isinstance', 'issubclass',
    'hasattr', 'getattr', 'setattr', 'delattr', 'callable', 'print', 'repr',
    'id', 'hash', 'iter', 'next', 'all', 'any', 'round', 'pow', 'divmod',
    'ord', 'chr', 'format', 'open', 'input', 'super', 'slice', 'staticmethod',
    'classmethod', 'property', 'object', 'memoryview', 'bytearray', 'complex',
    'bin', 'oct', 'hex', 'ascii', 'eval', 'exec', 'compile', 'globals', 'locals',
    'vars', 'dir', 'help', 'breakpoint', '__import__',
})

# NumPy functions that are already optimized (no need for recursive analysis)
SAFE_NUMPY = frozenset({
    'zeros', 'ones', 'empty', 'zeros_like', 'ones_like', 'empty_like', 'full',
    'array', 'asarray', 'arange', 'linspace', 'logspace', 'eye', 'identity',
    'copy', 'reshape', 'ravel', 'flatten', 'squeeze', 'expand_dims', 'transpose',
    'dot', 'matmul', 'sum', 'prod', 'mean', 'std', 'var', 'min', 'max',
    'argmin', 'argmax', 'cumsum', 'cumprod', 'sort', 'argsort', 'clip',
    'concatenate', 'stack', 'vstack', 'hstack', 'dstack', 'split', 'where',
})


# Default stencil parameters for GPU kernel execution
# These values are used as fallbacks when the calling code doesn't provide explicit values.
# The defaults are mathematically safe for iterative stencil operations.
#
# GAMMA: Primary decay/diffusion coefficient (0.95 = 5% decay per iteration)
#        Used in spatial smoothing, diffusion, and iterative solvers
#        Range: typically 0.8-1.0 for stable convergence
STENCIL_DEFAULT_GAMMA = 0.95
#
# BETA: Secondary coefficient for neighbor influence (0.05 = 5% influence)
#       Controls contribution from neighboring cells in stencil operations
#       Range: typically 0.01-0.1, should satisfy gamma + 4*beta â‰¤ 1 for stability
STENCIL_DEFAULT_BETA = 0.05
#
# ALPHA: Tertiary coefficient for diagonal/corner influence (0.3 = 30% weight)
#        Used for non-orthogonal neighbor contributions
#        Range: application-dependent, commonly 0.1-0.5
STENCIL_DEFAULT_ALPHA = 0.3


@dataclass
class ExtractedCall:
    """Information about a function call extracted from loop body."""
    name: str
    lineno: int
    col_offset: int
    args: List[ast.expr] = field(default_factory=list)
    keywords: List[ast.keyword] = field(default_factory=list)
    resolved_function: Optional[Callable] = None
    is_method: bool = False
    is_nested_def: bool = False
    source_context: Optional[str] = None


@dataclass
class GPUCandidate:
    """A function that is a candidate for GPU acceleration."""
    function_name: str
    function_obj: Optional[Callable]
    pattern_type: str  # 'stencil', 'map', 'reduce', 'scan', 'matmul'
    confidence: float
    dimensions: int = 2
    estimated_speedup: float = 1.0
    analysis_info: Optional[Any] = None


@dataclass
class RecursiveAnalysisResult:
    """Result of recursive function analysis."""
    outer_function_name: str
    outer_rejection_reason: Optional[str] = None
    has_gpu_candidates: bool = False
    gpu_candidates: List[GPUCandidate] = field(default_factory=list)
    recursion_depth: int = 0
    has_closure_warnings: bool = False
    closure_warnings: List[str] = field(default_factory=list)
    analysis_time_ms: float = 0.0


class FunctionCallExtractor:
    """
    Extracts function calls from loop bodies in a Python function.

    Uses AST analysis to find all function calls within for/while loops,
    filtering out safe built-ins and NumPy functions that don't need
    recursive analysis.
    """

    def __init__(self):
        self._safe_names = SAFE_BUILTINS | SAFE_NUMPY
        self._cache: Dict[int, List[ExtractedCall]] = {}
        self._cache_lock = threading.Lock()

    def extract_from_function(self, func: Callable) -> List[ExtractedCall]:
        """
        Extract function calls from loop bodies in a function.

        Args:
            func: Function to analyze

        Returns:
            List of extracted function calls
        """
        func_id = id(func)

        with self._cache_lock:
            if func_id in self._cache:
                return self._cache[func_id]

        try:
            source = inspect.getsource(func)
            tree = ast.parse(source)
        except (OSError, TypeError, SyntaxError) as e:
            logger.debug(f"Could not get source for {getattr(func, '__name__', 'unknown')}: {e}")
            return []

        # Get function globals for resolution
        func_globals = getattr(func, '__globals__', {})
        func_closure = getattr(func, '__closure__', None)
        func_code = getattr(func, '__code__', None)

        # Find nested function definitions
        nested_defs = self._find_nested_definitions(tree)

        # Extract calls from loops
        calls = []
        visitor = _LoopCallExtractor(
            safe_names=self._safe_names,
            func_globals=func_globals,
            nested_defs=nested_defs,
            func_closure=func_closure,
            func_code=func_code,
        )
        visitor.visit(tree)
        calls = visitor.calls

        with self._cache_lock:
            self._cache[func_id] = calls

        return calls

    def _find_nested_definitions(self, tree: ast.AST) -> Dict[str, ast.FunctionDef]:
        """Find all nested function definitions in the AST."""
        nested = {}

        class NestedDefFinder(ast.NodeVisitor):
            def visit_FunctionDef(self, node):
                nested[node.name] = node
                self.generic_visit(node)

            def visit_AsyncFunctionDef(self, node):
                nested[node.name] = node
                self.generic_visit(node)

        NestedDefFinder().visit(tree)
        return nested

    def clear_cache(self) -> None:
        """Clear the extraction cache."""
        with self._cache_lock:
            self._cache.clear()


class _LoopCallExtractor(ast.NodeVisitor):
    """AST visitor that extracts function calls from loop bodies."""

    def __init__(
        self,
        safe_names: frozenset,
        func_globals: Dict[str, Any],
        nested_defs: Dict[str, ast.FunctionDef],
        func_closure: Optional[tuple],
        func_code: Optional[types.CodeType],
    ):
        self.safe_names = safe_names
        self.func_globals = func_globals
        self.nested_defs = nested_defs
        self.func_closure = func_closure
        self.func_code = func_code
        self.calls: List[ExtractedCall] = []
        self._in_loop_depth = 0

    def visit_For(self, node):
        self._in_loop_depth += 1
        self.generic_visit(node)
        self._in_loop_depth -= 1

    def visit_While(self, node):
        self._in_loop_depth += 1
        self.generic_visit(node)
        self._in_loop_depth -= 1

    def visit_Call(self, node):
        if self._in_loop_depth > 0:
            call_info = self._extract_call_info(node)
            if call_info is not None:
                self.calls.append(call_info)
        self.generic_visit(node)

    def _extract_call_info(self, node: ast.Call) -> Optional[ExtractedCall]:
        """Extract information about a function call."""
        # Get call name
        if isinstance(node.func, ast.Name):
            name = node.func.id

            # Skip safe builtins
            if name in self.safe_names:
                return None

            # Check if it's a method call disguised as Name
            is_method = False
            resolved = None

            # Try to resolve from nested definitions
            if name in self.nested_defs:
                return ExtractedCall(
                    name=name,
                    lineno=node.lineno,
                    col_offset=node.col_offset,
                    args=node.args,
                    keywords=node.keywords,
                    resolved_function=None,  # Will be resolved later
                    is_method=False,
                    is_nested_def=True,
                )

            # Try to resolve from globals
            if name in self.func_globals:
                resolved = self.func_globals[name]
                if callable(resolved):
                    return ExtractedCall(
                        name=name,
                        lineno=node.lineno,
                        col_offset=node.col_offset,
                        args=node.args,
                        keywords=node.keywords,
                        resolved_function=resolved,
                        is_method=False,
                        is_nested_def=False,
                    )

            # Try to resolve from closure
            if self.func_closure and self.func_code:
                freevars = self.func_code.co_freevars
                if name in freevars:
                    idx = freevars.index(name)
                    if idx < len(self.func_closure):
                        resolved = self.func_closure[idx].cell_contents
                        if callable(resolved):
                            return ExtractedCall(
                                name=name,
                                lineno=node.lineno,
                                col_offset=node.col_offset,
                                args=node.args,
                                keywords=node.keywords,
                                resolved_function=resolved,
                                is_method=False,
                                is_nested_def=False,
                            )

            # Unknown function - still extract for analysis
            return ExtractedCall(
                name=name,
                lineno=node.lineno,
                col_offset=node.col_offset,
                args=node.args,
                keywords=node.keywords,
                resolved_function=None,
                is_method=False,
                is_nested_def=False,
            )

        elif isinstance(node.func, ast.Attribute):
            # Method call (obj.method) - skip for now
            # These can't be GPU-accelerated directly
            return None

        return None


class RecursivePatternAnalyzer:
    """
    Recursively analyzes functions for GPU-acceleratable patterns.

    When an outer function is rejected due to external function calls,
    this analyzer extracts those calls and analyzes each for GPU patterns
    (stencil, map, reduce, etc.).
    """

    def __init__(self, max_depth: int = 3):
        self.max_depth = max_depth
        self._cache: Dict[int, RecursiveAnalysisResult] = {}
        self._cache_lock = threading.Lock()
        self._extractor = FunctionCallExtractor()

    def analyze_recursively(
        self,
        func: Callable,
        depth: int = 0,
    ) -> RecursiveAnalysisResult:
        """
        Recursively analyze a function for GPU-acceleratable inner functions.

        Args:
            func: Function to analyze
            depth: Current recursion depth

        Returns:
            RecursiveAnalysisResult with GPU candidates
        """
        import time
        start_time = time.perf_counter()

        func_id = id(func)
        func_name = getattr(func, '__name__', 'unknown')

        # Check cache
        with self._cache_lock:
            if func_id in self._cache:
                return self._cache[func_id]

        result = RecursiveAnalysisResult(
            outer_function_name=func_name,
            recursion_depth=depth,
        )

        # Check recursion limit
        if depth > self.max_depth:
            logger.debug(f"Max recursion depth {self.max_depth} reached for {func_name}")
            return result

        try:
            # First, try direct pattern detection on this function
            from epochly.jit.cuda_pattern_detector import CUDAPatternDetector
            detector = CUDAPatternDetector()
            analysis = detector.analyze(func)

            if analysis.parallelizable and analysis.confidence >= 0.7:
                # This function itself is GPU-acceleratable
                candidate = GPUCandidate(
                    function_name=func_name,
                    function_obj=func,
                    pattern_type=analysis.pattern_type,
                    confidence=analysis.confidence,
                    dimensions=analysis.dimensions if hasattr(analysis, 'dimensions') else 2,
                    estimated_speedup=self._estimate_speedup(analysis.pattern_type),
                    analysis_info=analysis,
                )
                result.has_gpu_candidates = True
                result.gpu_candidates.append(candidate)

            else:
                # Function is rejected - try recursive analysis
                result.outer_rejection_reason = analysis.rejection_reason

                # Extract function calls from loops
                calls = self._extractor.extract_from_function(func)

                for call in calls:
                    # Skip if we can't resolve the function
                    if call.is_nested_def:
                        # Try to get the nested function from source
                        nested_func = self._resolve_nested_function(func, call.name)
                        if nested_func:
                            call.resolved_function = nested_func
                        else:
                            logger.debug(f"Could not resolve nested function {call.name}")
                            continue

                    if call.resolved_function is None:
                        continue

                    # Recursively analyze the called function
                    inner_result = self.analyze_recursively(
                        call.resolved_function,
                        depth=depth + 1
                    )

                    # Merge results
                    if inner_result.has_gpu_candidates:
                        result.has_gpu_candidates = True
                        result.gpu_candidates.extend(inner_result.gpu_candidates)

                    if inner_result.has_closure_warnings:
                        result.has_closure_warnings = True
                        result.closure_warnings.extend(inner_result.closure_warnings)

        except Exception as e:
            logger.debug(f"Recursive analysis failed for {func_name}: {e}")

        result.analysis_time_ms = (time.perf_counter() - start_time) * 1000

        # Cache result
        with self._cache_lock:
            self._cache[func_id] = result

        return result

    def _resolve_nested_function(
        self,
        outer_func: Callable,
        nested_name: str
    ) -> Optional[Callable]:
        """Attempt to resolve a nested function definition."""
        try:
            source = inspect.getsource(outer_func)
            tree = ast.parse(source)

            # Find the nested function definition
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef) and node.name == nested_name:
                    # Compile the nested function
                    nested_code = compile(
                        ast.Module(body=[node], type_ignores=[]),
                        '<nested>',
                        'exec'
                    )
                    # Create a namespace with the outer function's globals
                    namespace = dict(outer_func.__globals__)
                    exec(nested_code, namespace)
                    return namespace.get(nested_name)

        except Exception as e:
            logger.debug(f"Could not resolve nested function {nested_name}: {e}")

        return None

    def _estimate_speedup(self, pattern_type: str) -> float:
        """Estimate GPU speedup based on pattern type."""
        speedup_estimates = {
            'stencil': 100.0,  # Stencils have high arithmetic intensity
            'map': 10.0,       # Element-wise operations
            'reduce': 5.0,     # Reductions need synchronization
            'scan': 5.0,       # Scans have dependencies
            'matmul': 50.0,    # Matrix multiply is well-optimized
            'transpose': 2.0,  # Memory-bound
        }
        return speedup_estimates.get(pattern_type, 1.0)

    def clear_cache(self) -> None:
        """Clear the analysis cache."""
        with self._cache_lock:
            self._cache.clear()
        self._extractor.clear_cache()


class InnerFunctionGPUWrapper:
    """
    Creates GPU-accelerated wrappers for inner functions.

    Takes a function and its compiled GPU kernel, returns a wrapper
    that maintains the original function signature but executes on GPU.
    """

    def __init__(self):
        self._wrapper_cache: Dict[int, Callable] = {}
        self._cache_lock = threading.Lock()

    def create_wrapper(
        self,
        original_function: Callable,
        compiled_kernel: Any,
        pattern_type: str,
    ) -> Callable:
        """
        Create a GPU-accelerated wrapper for a function.

        Args:
            original_function: Original Python function
            compiled_kernel: Compiled GPU kernel
            pattern_type: Type of pattern ('stencil', 'map', 'reduce')

        Returns:
            Wrapper function that executes on GPU
        """
        func_id = id(original_function)

        with self._cache_lock:
            if func_id in self._wrapper_cache:
                return self._wrapper_cache[func_id]

        # Get original signature
        try:
            sig = inspect.signature(original_function)
            params = list(sig.parameters.keys())
        except (ValueError, TypeError):
            params = []

        func_name = getattr(original_function, '__name__', 'unknown')

        # Create appropriate wrapper based on pattern type
        if pattern_type == 'stencil':
            wrapper = self._create_stencil_wrapper(
                compiled_kernel, func_name, params
            )
        elif pattern_type == 'map':
            wrapper = self._create_map_wrapper(
                compiled_kernel, func_name, params
            )
        elif pattern_type == 'reduce':
            wrapper = self._create_reduce_wrapper(
                compiled_kernel, func_name, params
            )
        else:
            wrapper = self._create_generic_wrapper(
                compiled_kernel, func_name, params
            )

        # Mark as GPU-accelerated
        wrapper._gpu_accelerated = True
        wrapper._original_function = original_function
        wrapper._compiled_kernel = compiled_kernel
        wrapper._pattern_type = pattern_type

        # CRITICAL FIX (Jan 2025): Register dynamic wrapper's code_id with profiler
        # Without this, the profiler's _trace_callback sees calls to these wrappers
        # and tries to profile/optimize them. After Run 1's cumulative time builds up,
        # Run 2 triggers expensive optimization attempts, causing Run 2 > Run 1 variance.
        # By registering the code_id, the profiler's fast-path skips these wrappers.
        self._register_wrapper_code_id(wrapper)

        with self._cache_lock:
            self._wrapper_cache[func_id] = wrapper

        return wrapper

    def _register_wrapper_code_id(self, wrapper: Callable) -> None:
        """
        Register wrapper's __call__ code_id with profiler to enable fast-path skipping.

        CRITICAL FIX (Jan 2025): Dynamic wrappers created by InnerFunctionGPUWrapper
        have new code_ids that aren't registered with the profiler. Without registration,
        the profiler tries to profile these wrappers on every call, causing:
        - Run 1: Cumulative time builds up
        - Run 2: Exceeds threshold, triggers expensive optimization attempt
        - Run 3: Already marked as not-optimizable, skipped (fast)

        This causes the "Run 2 > Run 1" variance bug in LEVEL_4 GPU acceleration.

        Args:
            wrapper: The dynamically created wrapper function
        """
        try:
            # Import the profiler's registration function
            from epochly.profiling.auto_profiler import (
                _wrapper_call_code_ids,
                _wrapper_registry_lock,
            )

            # Get the wrapper's code object
            if hasattr(wrapper, '__code__'):
                code_id = id(wrapper.__code__)
                registered = False
                with _wrapper_registry_lock:
                    if code_id not in _wrapper_call_code_ids:
                        _wrapper_call_code_ids.add(code_id)
                        registered = True

                if registered:
                    logger.debug(
                        f"Registered dynamic GPU wrapper code_id {code_id} "
                        f"for {getattr(wrapper, '__name__', 'unknown')}"
                    )

        except ImportError:
            # Profiler not available - registration not needed
            pass
        except Exception as e:
            # Don't fail wrapper creation on registration error
            logger.debug(f"Failed to register wrapper code_id: {e}")

    def _create_stencil_wrapper(
        self,
        kernel: Any,
        func_name: str,
        params: List[str],
    ) -> Callable:
        """Create wrapper for stencil pattern."""
        try:
            import cupy as cp
            import numpy as np

            @functools.wraps(lambda: None)
            def stencil_wrapper(F, *args, **kwargs):
                """GPU-accelerated stencil wrapper."""
                # Convert to CuPy array if needed
                if hasattr(F, 'get'):  # Already CuPy
                    F_gpu = F
                else:
                    F_gpu = cp.asarray(F)

                # Allocate output
                F_out_gpu = cp.empty_like(F_gpu)

                # Get dimensions
                n_rows, n_cols = F.shape

                # Extract scalar parameters
                gamma = args[0] if len(args) > 0 else kwargs.get('gamma', STENCIL_DEFAULT_GAMMA)
                beta = args[1] if len(args) > 1 else kwargs.get('beta', STENCIL_DEFAULT_BETA)
                alpha = args[2] if len(args) > 2 else kwargs.get('alpha', STENCIL_DEFAULT_ALPHA)

                # Execute kernel
                if hasattr(kernel, 'kernel'):
                    # CompiledStencilKernel from stencil_kernel_compiler
                    block_size = getattr(kernel.config, 'block_size', (16, 16))
                    block_x, block_y = block_size
                    grid_x = (n_cols + block_x - 1) // block_x
                    grid_y = (n_rows + block_y - 1) // block_y

                    kernel.kernel(
                        (grid_x, grid_y),
                        (block_x, block_y),
                        (F_gpu, F_out_gpu,
                         np.int32(n_rows), np.int32(n_cols),
                         np.float64(gamma), np.float64(beta), np.float64(alpha))
                    )
                elif hasattr(kernel, 'execute'):
                    # Generic kernel interface
                    F_out_gpu = kernel.execute(F_gpu, gamma, beta, alpha)

                # Convert back to numpy
                return cp.asnumpy(F_out_gpu)

            stencil_wrapper.__name__ = f'gpu_stencil_{func_name}'
            return stencil_wrapper

        except ImportError:
            # No CuPy - return identity wrapper
            def fallback_wrapper(*args, **kwargs):
                logger.warning("CuPy not available, using CPU fallback")
                return kernel.execute(*args, **kwargs) if hasattr(kernel, 'execute') else args[0]
            return fallback_wrapper

    def _create_map_wrapper(
        self,
        kernel: Any,
        func_name: str,
        params: List[str],
    ) -> Callable:
        """Create wrapper for map pattern."""
        try:
            import cupy as cp

            @functools.wraps(lambda: None)
            def map_wrapper(arr, *args, **kwargs):
                """GPU-accelerated map wrapper."""
                arr_gpu = cp.asarray(arr) if not hasattr(arr, 'get') else arr
                result_gpu = kernel.execute(arr_gpu)
                return cp.asnumpy(result_gpu)

            map_wrapper.__name__ = f'gpu_map_{func_name}'
            return map_wrapper

        except ImportError:
            def fallback_wrapper(arr, *args, **kwargs):
                return kernel.execute(arr) if hasattr(kernel, 'execute') else arr
            return fallback_wrapper

    def _create_reduce_wrapper(
        self,
        kernel: Any,
        func_name: str,
        params: List[str],
    ) -> Callable:
        """Create wrapper for reduce pattern."""
        try:
            import cupy as cp

            @functools.wraps(lambda: None)
            def reduce_wrapper(arr, *args, **kwargs):
                """GPU-accelerated reduce wrapper."""
                arr_gpu = cp.asarray(arr) if not hasattr(arr, 'get') else arr
                result = kernel.execute(arr_gpu)
                return float(result) if hasattr(result, 'get') else result

            reduce_wrapper.__name__ = f'gpu_reduce_{func_name}'
            return reduce_wrapper

        except ImportError:
            def fallback_wrapper(arr, *args, **kwargs):
                return kernel.execute(arr) if hasattr(kernel, 'execute') else 0.0
            return fallback_wrapper

    def _create_generic_wrapper(
        self,
        kernel: Any,
        func_name: str,
        params: List[str],
    ) -> Callable:
        """Create generic wrapper for unknown patterns."""
        try:
            import cupy as cp

            @functools.wraps(lambda: None)
            def generic_wrapper(*args, **kwargs):
                """GPU-accelerated generic wrapper."""
                gpu_args = []
                for arg in args:
                    if hasattr(arg, 'dtype') and hasattr(arg, 'shape'):
                        gpu_args.append(cp.asarray(arg))
                    else:
                        gpu_args.append(arg)

                result = kernel.execute(*gpu_args, **kwargs)

                if hasattr(result, 'get'):
                    return cp.asnumpy(result)
                return result

            generic_wrapper.__name__ = f'gpu_{func_name}'
            return generic_wrapper

        except ImportError:
            def fallback_wrapper(*args, **kwargs):
                return kernel.execute(*args, **kwargs) if hasattr(kernel, 'execute') else args[0]
            return fallback_wrapper


def create_gpu_accelerated_version(
    outer_function: Callable,
    gpu_candidates: List[GPUCandidate],
) -> Callable:
    """
    Create a GPU-accelerated version of an outer function.

    Uses closure-based substitution to replace inner function calls
    with GPU-accelerated wrappers.

    Args:
        outer_function: Original outer function
        gpu_candidates: List of GPU-acceleratable inner functions

    Returns:
        Accelerated version of the outer function
    """
    if not gpu_candidates:
        return outer_function

    func_name = getattr(outer_function, '__name__', 'unknown')

    # Build mapping of function names to GPU wrappers
    # CRITICAL FIX (Jan 2025): Use singleton wrapper factory to persist cache
    # across recursive JIT calls. This ensures the same wrapper functions (with
    # registered code_ids) are reused, eliminating Run 2 > Run 1 variance.
    wrapper_factory = get_inner_wrapper_factory()
    gpu_substitutions: Dict[str, Callable] = {}

    for candidate in gpu_candidates:
        if candidate.function_obj is None:
            continue

        # Compile the inner function to GPU kernel
        try:
            compiled_kernel = _compile_to_gpu_kernel(candidate)
            if compiled_kernel is not None:
                wrapper = wrapper_factory.create_wrapper(
                    original_function=candidate.function_obj,
                    compiled_kernel=compiled_kernel,
                    pattern_type=candidate.pattern_type,
                )
                gpu_substitutions[candidate.function_name] = wrapper

        except Exception as e:
            logger.debug(f"Could not compile {candidate.function_name} to GPU: {e}")

    if not gpu_substitutions:
        logger.debug(f"No GPU substitutions created for {func_name}")
        return outer_function

    # Create accelerated version using closure substitution
    accelerated = _create_closure_substituted_function(
        outer_function,
        gpu_substitutions,
    )

    # Mark as recursively accelerated
    accelerated._level4_recursive = True
    accelerated._gpu_substitutions = gpu_substitutions
    accelerated.__name__ = f'{func_name}_gpu'

    return accelerated


def _compile_to_gpu_kernel(candidate: GPUCandidate) -> Optional[Any]:
    """Compile a GPU candidate to a GPU kernel."""
    from epochly.jit.stencil_kernel_compiler import get_stencil_compiler, StencilCompilationError
    from epochly.jit.pattern_kernel_compiler import PatternKernelCompiler, UnsupportedOperationError
    import numpy as np

    func = candidate.function_obj
    pattern_type = candidate.pattern_type

    try:
        if pattern_type == 'stencil':
            compiler = get_stencil_compiler()
            # Default to spatial feature stencil
            kernel = compiler.compile_spatial_feature_kernel(
                dtype=np.float64,
                block_size=(16, 16)
            )
            return kernel

        elif pattern_type == 'map':
            compiler = PatternKernelCompiler()
            kernel = compiler.compile_map_pattern(
                operation='square',  # Default operation
                input_dtype=np.float64,
                output_dtype=np.float64
            )
            return kernel

        elif pattern_type == 'reduce':
            compiler = PatternKernelCompiler()
            kernel = compiler.compile_reduce_pattern(
                operation='sum',
                input_dtype=np.float64,
                output_dtype=np.float64
            )
            return kernel

    except (StencilCompilationError, UnsupportedOperationError) as e:
        logger.debug(f"Kernel compilation failed: {e}")
    except ImportError as e:
        logger.debug(f"Required compiler not available: {e}")
    except Exception as e:
        logger.debug(f"Unexpected compilation error: {e}")

    return None


def _create_closure_substituted_function(
    original: Callable,
    substitutions: Dict[str, Callable],
) -> Callable:
    """
    Create a new function with inner calls substituted via closure.

    This approach modifies the function's globals dict to inject
    the GPU-accelerated versions of inner functions.
    """
    # Get original function attributes
    original_globals = original.__globals__.copy()

    # Inject substitutions into the globals
    modified_globals = dict(original_globals)
    modified_globals.update(substitutions)

    # Get the code object and create a new function with modified globals
    code = original.__code__

    # Create new function with modified globals
    new_func = types.FunctionType(
        code,
        modified_globals,
        name=f"{original.__name__}_gpu",
        argdefs=original.__defaults__,
        closure=original.__closure__,
    )

    # Copy over other attributes
    if original.__kwdefaults__:
        new_func.__kwdefaults__ = original.__kwdefaults__.copy()
    if original.__annotations__:
        new_func.__annotations__ = original.__annotations__.copy()
    if original.__doc__:
        new_func.__doc__ = original.__doc__

    return new_func


# Thread-safe singleton for analyzer
_recursive_analyzer: Optional[RecursivePatternAnalyzer] = None
_analyzer_lock = threading.Lock()


def get_recursive_analyzer(max_depth: int = 3) -> RecursivePatternAnalyzer:
    """Get or create the global recursive pattern analyzer."""
    global _recursive_analyzer
    with _analyzer_lock:
        if _recursive_analyzer is None:
            _recursive_analyzer = RecursivePatternAnalyzer(max_depth=max_depth)
        return _recursive_analyzer


# Thread-safe singleton for wrapper factory
# CRITICAL FIX (Jan 2025): InnerFunctionGPUWrapper was being created fresh on every
# create_gpu_accelerated_version call, causing its wrapper cache to be empty each time.
# This resulted in new wrapper functions (with new code_ids) being created on every
# recursive JIT call, contributing to the "Run 2 > Run 1" variance bug.
# By using a singleton, the wrapper cache persists and the same wrapper functions
# (with registered code_ids) are reused across calls.
_inner_wrapper_factory: Optional[InnerFunctionGPUWrapper] = None
_wrapper_factory_lock = threading.Lock()


def get_inner_wrapper_factory() -> InnerFunctionGPUWrapper:
    """Get or create the global inner function GPU wrapper factory."""
    global _inner_wrapper_factory
    with _wrapper_factory_lock:
        if _inner_wrapper_factory is None:
            _inner_wrapper_factory = InnerFunctionGPUWrapper()
        return _inner_wrapper_factory
