<div align="center">


<img src="https://raw.githubusercontent.com/gm24med/MHC/main/docs/images/logo.png" alt="mHC Logo" width="200"/>

# mhc: Manifold-Constrained Hyper-Connections

**Honey Badger Stability for Deeper, More Stable Neural Networks.**

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/pytorch-2.0+-ee4c2c.svg?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/get-started/locally/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)
[![CI](https://github.com/gm24med/MHC/actions/workflows/ci.yml/badge.svg?style=for-the-badge)](https://github.com/gm24med/MHC/actions/workflows/ci.yml)

[Documentation](https://gm24med.github.io/MHC/) â€¢ [Examples](https://github.com/gm24med/MHC/tree/main/examples) â€¢ [Paper](#citation) â€¢ [Contributing](#contributing)

</div>

---

## ğŸ¯ What is mHC?

`mhc` is a next-generation PyTorch library that reimagines residual connections. Instead of simple one-to-one skips, mHC learns to dynamically mix multiple historical network states through geometrically constrained manifolds, bringing **Honey Badger toughness** to your gradients.

<div align="center">

| ğŸš€ **High Performance** | ğŸ§  **Smart Memory** | ğŸ› ï¸ **Drop-in Ease** |
|:---:|:---:|:---:|
| Reach deeper than ever before with optimized gradient flow. | Dynamically mix past states for richer feature representation. | Transform any model to mHC with a single line of code. |

</div>

<br/>

<div align="center">
<img src="https://raw.githubusercontent.com/gm24med/MHC/main/docs/images/architecture.png" alt="mHC Architecture" width="800"/>
</div>

---

### Installation

â€œWe recommend `uv` for faster and reproducible installs, but standard `pip` is fully supported.â€

```bash
# Using pip (standard)
pip install mhc
```

```bash
# Using uv (faster, recommended)
uv pip install mhc
```

### Optional Extras

```bash
# Visualization utilities
pip install "mhc[viz]"
uv pip install "mhc[viz]"

# TensorFlow support
pip install "mhc[tf]"
uv pip install "mhc[tf]"
```

### 30-Second Example

```python
import torch
from mhc import MHCSequential

# Create a model with mHC skip connections
model = MHCSequential([
    nn.Linear(64, 64),
    nn.ReLU(),
    nn.Linear(64, 64),
    nn.ReLU(),
    nn.Linear(64, 32)
], max_history=4, mode="mhc", constraint="simplex")

# Use it like any PyTorch model
x = torch.randn(8, 64)
output = model(x)
```

### Inject into Existing Models

Transform any model to use mHC with one line:

```python
from mhc import inject_mhc
import torchvision.models as models

model = models.resnet50(pretrained=True)
inject_mhc(model, target_types=nn.Conv2d, max_history=4)
```

---

## ğŸ¤” Why mHC?

### The Gradient Bottleneck
Standard residual connections only look one step back: $x_{l+1} = x_l + f(x_l)$. While revolutionary, this narrow window limits the network's ability to leverage long-range dependencies and can lead to diminishing returns in extremely deep architectures.

### The mHC Breakthrough
mHC implements a **history-aware manifold** that mixes a sliding window of $H$ past representations:

$$
x_{l+1} = f(x_l) + \sum_{k=l-H+1}^{l} \alpha_{l,k}\, x_k
$$

Where:
- **$\alpha_{l,k}$**: Learned mixing weights optimized for feature relevance.
- **Constraints**: Weights are projected onto stable manifolds (Simplex, Identity-preserving, or Doubly Stochastic) to ensure mathematical convergence.

### Key Advantages

| Benefit | Description |
|:---|:---|
| **Deep Stability** | Geometric constraints prevent gradient explosion even at 200+ layers. |
| **Feature Fusion** | Multi-history mixing allows layers to recover lost spatial or semantic info. |
| **Adaptive Flow** | The network learns *which* historical states are most important for the current layer. |

---

## ğŸ“Š Performance Highlights

Experiments with 50-layer networks show:

- âœ… **2x Faster Convergence** compared to standard ResNet on deep MLPs.
- âœ… **Superior Gradient Stability** through geometric manifold constraints.
- âœ… **Minimal Overhead** (~10% additional compute for 4x history).

> [!TIP]
> Run the benchmark yourself: `uv run python experiments/benchmark_stability.py`

---

## ğŸ“Š Visualizing Results

<div align="center">

| **Training Dashboard** | **History Evolution** |
|:---:|:---:|
| ![Training Dashboard](https://raw.githubusercontent.com/gm24med/MHC/main/docs/images/training_dashboard.png) | ![Mixing Weights](https://raw.githubusercontent.com/gm24med/MHC/main/docs/images/mixing_weights.png) |
| *Loss curves & weight dynamics* | *Learned coefficients over time* |

<br/>

| **Gradient Flow** | **Feature Contribution** |
|:---:|:---:|
| ![Gradient Flow](https://raw.githubusercontent.com/gm24med/MHC/main/docs/images/gradient_flow.png) | ![History Contribution](https://raw.githubusercontent.com/gm24med/MHC/main/docs/images/history_contribution.png) |
| *Improved backpropagation signal* | *Single layer state importance* |

</div>

---

## ğŸŒ³ Repository Structure

```text
MHC/
â”œâ”€â”€ mhc/                     # Core package
â”‚   â”œâ”€â”€ constraints/         # Mathematical projections
â”‚   â”œâ”€â”€ layers/              # mHC Skip implementations
â”‚   â”œâ”€â”€ tf/                  # TensorFlow compatibility
â”‚   â””â”€â”€ utils/               # Injection & logging tools
â”œâ”€â”€ tests/                   # Robust PyTest suite
â”œâ”€â”€ docs/                    # Documentation sources
â””â”€â”€ examples/                # Quick-start notebooks
```

---

## ğŸ› ï¸ Development Installation

For contributors cloning the repository:

```bash
git clone https://github.com/gm24med/MHC.git
cd MHC

# Using uv (recommended for dev)
uv pip install -e ".[dev]"

# Or standard pip
pip install -e ".[dev]"
```

---

<div align="center">

### **â­ Star us on GitHub!**

[Report Bug](https://github.com/gm24med/MHC/issues) â€¢ [Request Feature](https://github.com/gm24med/MHC/issues) â€¢ [Discussions](https://github.com/gm24med/MHC/discussions)

</div>
