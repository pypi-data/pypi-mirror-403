# coding: utf-8

"""
 Shaped API

 Welcome to Shaped's API reference docs. These provide a  detailed view of the endpoints and CLI commands that Shaped provides and brief  explanations of how they should be used.  The Shaped API has four main endpoints:  **Tables** - Provision and manage batch and real-time data connectors.   **Views** - Configure SQL transformations and AI enrichment on your input data. Use SQL to combine multiple data sources or use an LLM to add new categories, extract specific attributes from descriptions, etc.  **Engines** - Deploy and manage your relevance engines. The Engine API exposes configuration for indexing logic, input datasets, externam embeddings, and more.  **Query** - Execute queries against your engines, to return data based on an input query or rerank an existing list. The Query API exposes the retrieve, filter, score, and ranking steps of the 4-stage ranking architecture.  The base URL for each endpoint is: `https://api.shaped.ai/v2`

 Generated by OpenAPI Generator (https://openapi-generator.tech)

 Do not edit the class manually.
""" # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictFloat, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional, Union
from shaped.autogen.models.attn_dropout_prob import AttnDropoutProb
from shaped.autogen.models.batch_size import BatchSize
from shaped.autogen.models.hidden_dropout_prob import HiddenDropoutProb
from shaped.autogen.models.hidden_size1 import HiddenSize1
from shaped.autogen.models.inner_size1 import InnerSize1
from shaped.autogen.models.learning_rate2 import LearningRate2
from shaped.autogen.models.loss_types import LossTypes
from shaped.autogen.models.max_seq_length2 import MaxSeqLength2
from shaped.autogen.models.n_heads import NHeads
from shaped.autogen.models.n_layers import NLayers
from shaped.autogen.models.sampling_strategy import SamplingStrategy
from typing import Optional, Set
from typing_extensions import Self

class ShapedInternalRecsysPoliciesSasrecModelPolicySasrecModelPolicySASRecModelPolicyConfig(BaseModel):
    """
    ShapedInternalRecsysPoliciesSasrecModelPolicySasrecModelPolicySASRecModelPolicyConfig
    """ # noqa: E501
    policy_type: Optional[StrictStr] = 'sasrec'
    name: Optional[StrictStr] = None
    event_values: Optional[List[StrictStr]] = None
    batch_size: Optional[BatchSize] = None
    eval_batch_size: Optional[StrictInt] = Field(default=1000, description="Batch size used during model evaluation.")
    n_epochs: Optional[StrictInt] = Field(default=1, description="Number of complete passes through the training dataset.")
    negative_samples_count: Optional[StrictInt] = Field(default=2, description="Number of negative samples per positive sample for contrastive learning.")
    device: Optional[StrictStr] = None
    hidden_size: Optional[HiddenSize1] = None
    inner_size: Optional[InnerSize1] = None
    learning_rate: Optional[LearningRate2] = None
    attn_dropout_prob: Optional[AttnDropoutProb] = None
    hidden_act: Optional[StrictStr] = 'gelu'
    hidden_dropout_prob: Optional[HiddenDropoutProb] = None
    n_heads: Optional[NHeads] = None
    n_layers: Optional[NLayers] = None
    layer_norm_eps: Optional[Union[StrictFloat, StrictInt]] = 1.0E-12
    initializer_range: Optional[Union[StrictFloat, StrictInt]] = 0.02
    mask_rate: Optional[Union[StrictFloat, StrictInt]] = Field(default=0.2, description="Fraction of tokens to mask during training.")
    loss_type: Optional[LossTypes] = None
    max_seq_length: Optional[MaxSeqLength2] = None
    sample_strategy: Optional[SamplingStrategy] = None
    append_item_features: Optional[StrictBool] = False
    append_item_embeddings: Optional[StrictBool] = False
    use_candidate_embeddings: Optional[StrictBool] = False
    sample_seed: Optional[StrictInt] = 42
    sample_ratio: Optional[Union[StrictFloat, StrictInt]] = 0.8
    eval_step: Optional[StrictInt] = 1
    early_stopping_step: Optional[StrictInt] = 5
    normalize_numerical_features: Optional[StrictBool] = Field(default=True, description="Enable NormalizeNumerical transform for entity features.")
    use_derived_timestamp_features: Optional[StrictBool] = Field(default=True, description="Enable TimestampSinCosEncoder and TimestampCountEncoder for entity features.")
    balance_labels: Optional[StrictBool] = Field(default=True, description="Enable BalanceLabel transform for interactions.")
    additional_properties: Dict[str, Any] = {}
    __properties: ClassVar[List[str]] = ["policy_type", "name", "event_values", "batch_size", "eval_batch_size", "n_epochs", "negative_samples_count", "device", "hidden_size", "inner_size", "learning_rate", "attn_dropout_prob", "hidden_act", "hidden_dropout_prob", "n_heads", "n_layers", "layer_norm_eps", "initializer_range", "mask_rate", "loss_type", "max_seq_length", "sample_strategy", "append_item_features", "append_item_embeddings", "use_candidate_embeddings", "sample_seed", "sample_ratio", "eval_step", "early_stopping_step", "normalize_numerical_features", "use_derived_timestamp_features", "balance_labels"]

    @field_validator('policy_type')
    def policy_type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['sasrec']):
            raise ValueError("must be one of enum values ('sasrec')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of ShapedInternalRecsysPoliciesSasrecModelPolicySasrecModelPolicySASRecModelPolicyConfig from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * Fields in `self.additional_properties` are added to the output dict.
        """
        excluded_fields: Set[str] = set([
            "additional_properties",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of batch_size
        if self.batch_size:
            _dict['batch_size'] = self.batch_size.to_dict()
        # override the default output from pydantic by calling `to_dict()` of hidden_size
        if self.hidden_size:
            _dict['hidden_size'] = self.hidden_size.to_dict()
        # override the default output from pydantic by calling `to_dict()` of inner_size
        if self.inner_size:
            _dict['inner_size'] = self.inner_size.to_dict()
        # override the default output from pydantic by calling `to_dict()` of learning_rate
        if self.learning_rate:
            _dict['learning_rate'] = self.learning_rate.to_dict()
        # override the default output from pydantic by calling `to_dict()` of attn_dropout_prob
        if self.attn_dropout_prob:
            _dict['attn_dropout_prob'] = self.attn_dropout_prob.to_dict()
        # override the default output from pydantic by calling `to_dict()` of hidden_dropout_prob
        if self.hidden_dropout_prob:
            _dict['hidden_dropout_prob'] = self.hidden_dropout_prob.to_dict()
        # override the default output from pydantic by calling `to_dict()` of n_heads
        if self.n_heads:
            _dict['n_heads'] = self.n_heads.to_dict()
        # override the default output from pydantic by calling `to_dict()` of n_layers
        if self.n_layers:
            _dict['n_layers'] = self.n_layers.to_dict()
        # override the default output from pydantic by calling `to_dict()` of max_seq_length
        if self.max_seq_length:
            _dict['max_seq_length'] = self.max_seq_length.to_dict()
        # puts key-value pairs in additional_properties in the top level
        if self.additional_properties is not None:
            for _key, _value in self.additional_properties.items():
                _dict[_key] = _value

        # set to None if name (nullable) is None
        # and model_fields_set contains the field
        if self.name is None and "name" in self.model_fields_set:
            _dict['name'] = None

        # set to None if event_values (nullable) is None
        # and model_fields_set contains the field
        if self.event_values is None and "event_values" in self.model_fields_set:
            _dict['event_values'] = None

        # set to None if device (nullable) is None
        # and model_fields_set contains the field
        if self.device is None and "device" in self.model_fields_set:
            _dict['device'] = None

        # set to None if sample_strategy (nullable) is None
        # and model_fields_set contains the field
        if self.sample_strategy is None and "sample_strategy" in self.model_fields_set:
            _dict['sample_strategy'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of ShapedInternalRecsysPoliciesSasrecModelPolicySasrecModelPolicySASRecModelPolicyConfig from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "policy_type": obj.get("policy_type") if obj.get("policy_type") is not None else 'sasrec',
            "name": obj.get("name"),
            "event_values": obj.get("event_values"),
            "batch_size": BatchSize.from_dict(obj["batch_size"]) if obj.get("batch_size") is not None else None,
            "eval_batch_size": obj.get("eval_batch_size") if obj.get("eval_batch_size") is not None else 1000,
            "n_epochs": obj.get("n_epochs") if obj.get("n_epochs") is not None else 1,
            "negative_samples_count": obj.get("negative_samples_count") if obj.get("negative_samples_count") is not None else 2,
            "device": obj.get("device"),
            "hidden_size": HiddenSize1.from_dict(obj["hidden_size"]) if obj.get("hidden_size") is not None else None,
            "inner_size": InnerSize1.from_dict(obj["inner_size"]) if obj.get("inner_size") is not None else None,
            "learning_rate": LearningRate2.from_dict(obj["learning_rate"]) if obj.get("learning_rate") is not None else None,
            "attn_dropout_prob": AttnDropoutProb.from_dict(obj["attn_dropout_prob"]) if obj.get("attn_dropout_prob") is not None else None,
            "hidden_act": obj.get("hidden_act") if obj.get("hidden_act") is not None else 'gelu',
            "hidden_dropout_prob": HiddenDropoutProb.from_dict(obj["hidden_dropout_prob"]) if obj.get("hidden_dropout_prob") is not None else None,
            "n_heads": NHeads.from_dict(obj["n_heads"]) if obj.get("n_heads") is not None else None,
            "n_layers": NLayers.from_dict(obj["n_layers"]) if obj.get("n_layers") is not None else None,
            "layer_norm_eps": obj.get("layer_norm_eps") if obj.get("layer_norm_eps") is not None else 1.0E-12,
            "initializer_range": obj.get("initializer_range") if obj.get("initializer_range") is not None else 0.02,
            "mask_rate": obj.get("mask_rate") if obj.get("mask_rate") is not None else 0.2,
            "loss_type": obj.get("loss_type"),
            "max_seq_length": MaxSeqLength2.from_dict(obj["max_seq_length"]) if obj.get("max_seq_length") is not None else None,
            "sample_strategy": obj.get("sample_strategy"),
            "append_item_features": obj.get("append_item_features") if obj.get("append_item_features") is not None else False,
            "append_item_embeddings": obj.get("append_item_embeddings") if obj.get("append_item_embeddings") is not None else False,
            "use_candidate_embeddings": obj.get("use_candidate_embeddings") if obj.get("use_candidate_embeddings") is not None else False,
            "sample_seed": obj.get("sample_seed") if obj.get("sample_seed") is not None else 42,
            "sample_ratio": obj.get("sample_ratio") if obj.get("sample_ratio") is not None else 0.8,
            "eval_step": obj.get("eval_step") if obj.get("eval_step") is not None else 1,
            "early_stopping_step": obj.get("early_stopping_step") if obj.get("early_stopping_step") is not None else 5,
            "normalize_numerical_features": obj.get("normalize_numerical_features") if obj.get("normalize_numerical_features") is not None else True,
            "use_derived_timestamp_features": obj.get("use_derived_timestamp_features") if obj.get("use_derived_timestamp_features") is not None else True,
            "balance_labels": obj.get("balance_labels") if obj.get("balance_labels") is not None else True
        })
        # store additional fields in additional_properties
        for _key in obj.keys():
            if _key not in cls.__properties:
                _obj.additional_properties[_key] = obj.get(_key)

        return _obj


