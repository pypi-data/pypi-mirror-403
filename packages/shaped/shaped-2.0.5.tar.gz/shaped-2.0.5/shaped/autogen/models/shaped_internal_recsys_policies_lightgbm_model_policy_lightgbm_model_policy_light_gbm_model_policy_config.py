# coding: utf-8

"""
 Shaped API

 Welcome to Shaped's API reference docs. These provide a  detailed view of the endpoints and CLI commands that Shaped provides and brief  explanations of how they should be used.  The Shaped API has four main endpoints:  **Tables** - Provision and manage batch and real-time data connectors.   **Views** - Configure SQL transformations and AI enrichment on your input data. Use SQL to combine multiple data sources or use an LLM to add new categories, extract specific attributes from descriptions, etc.  **Engines** - Deploy and manage your relevance engines. The Engine API exposes configuration for indexing logic, input datasets, externam embeddings, and more.  **Query** - Execute queries against your engines, to return data based on an input query or rerank an existing list. The Query API exposes the retrieve, filter, score, and ranking steps of the 4-stage ranking architecture.  The base URL for each endpoint is: `https://api.shaped.ai/v2`

 Generated by OpenAPI Generator (https://openapi-generator.tech)

 Do not edit the class manually.
""" # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictFloat, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional, Union
from shaped.autogen.models.learning_rate1 import LearningRate1
from shaped.autogen.models.max_depth import MaxDepth
from shaped.autogen.models.num_leaves import NumLeaves
from shaped.autogen.models.objective1 import Objective1
from typing import Optional, Set
from typing_extensions import Self

class ShapedInternalRecsysPoliciesLightgbmModelPolicyLightgbmModelPolicyLightGBMModelPolicyConfig(BaseModel):
    """
    ShapedInternalRecsysPoliciesLightgbmModelPolicyLightgbmModelPolicyLightGBMModelPolicyConfig
    """ # noqa: E501
    policy_type: Optional[StrictStr] = 'lightgbm'
    name: Optional[StrictStr] = None
    event_values: Optional[List[StrictStr]] = None
    objective: Optional[Objective1] = None
    n_estimators: Optional[StrictInt] = Field(default=100, description="Number of boosting iterations.")
    max_depth: Optional[MaxDepth] = None
    num_leaves: Optional[NumLeaves] = None
    min_child_weight: Optional[Union[StrictFloat, StrictInt]] = Field(default=1, description="Minimum sum Hessian in one leaf.")
    learning_rate: Optional[LearningRate1] = None
    colsample_bytree: Optional[Union[StrictFloat, StrictInt]] = Field(default=0.9, description="Subsample columns on each iteration.")
    subsample: Optional[Union[StrictFloat, StrictInt]] = Field(default=0.8, description="Subsample training data on each iteration.")
    subsample_freq: Optional[StrictInt] = Field(default=5, description="Bagging frequency.")
    zero_as_missing: Optional[StrictBool] = Field(default=True, description="Treat zero values as missing.")
    bin_construct_sample_cnt: Optional[StrictInt] = Field(default=200000, description="Number of samples used to construct bins.")
    verbose: Optional[StrictInt] = 1
    verbose_eval: Optional[StrictInt] = 1
    num_threads: Optional[StrictInt] = None
    enable_resume: Optional[StrictBool] = True
    lambdarank_truncation_level: Optional[StrictInt] = Field(default=53, description="Number of pairs used in pairwise loss. Should be set to slightly higher than the k value used for NDCG@k.")
    calibrate: Optional[StrictBool] = False
    event_value_user_affinity_features: Optional[StrictBool] = False
    event_value_affinity_features_value_filter: Optional[List[StrictStr]] = None
    rolling_window_hours: Optional[StrictInt] = None
    negative_affinity_features: Optional[StrictBool] = False
    content_affinity_features: Optional[StrictBool] = False
    content_affinity_features_batch_size: Optional[StrictInt] = 1024
    content_affinity_max_num_latest_items: Optional[StrictInt] = None
    content_affinity_embedding_ref: Optional[StrictStr] = None
    container_categorical_to_multi_hot: Optional[StrictBool] = False
    container_to_container_affinities: Optional[StrictBool] = True
    point_in_time_item_feature: Optional[StrictBool] = False
    drop_user_id: Optional[StrictBool] = True
    drop_item_id: Optional[StrictBool] = False
    early_stopping_rounds: Optional[StrictInt] = None
    include_attributes: Optional[List[StrictStr]] = None
    normalize_numerical_features: Optional[StrictBool] = Field(default=True, description="Enable NormalizeNumerical transform for entity features.")
    use_derived_timestamp_features: Optional[StrictBool] = Field(default=True, description="Enable TimestampSinCosEncoder and TimestampCountEncoder for entity features.")
    balance_labels: Optional[StrictBool] = Field(default=True, description="Enable BalanceLabel transform for interactions.")
    additional_properties: Dict[str, Any] = {}
    __properties: ClassVar[List[str]] = ["policy_type", "name", "event_values", "objective", "n_estimators", "max_depth", "num_leaves", "min_child_weight", "learning_rate", "colsample_bytree", "subsample", "subsample_freq", "zero_as_missing", "bin_construct_sample_cnt", "verbose", "verbose_eval", "num_threads", "enable_resume", "lambdarank_truncation_level", "calibrate", "event_value_user_affinity_features", "event_value_affinity_features_value_filter", "rolling_window_hours", "negative_affinity_features", "content_affinity_features", "content_affinity_features_batch_size", "content_affinity_max_num_latest_items", "content_affinity_embedding_ref", "container_categorical_to_multi_hot", "container_to_container_affinities", "point_in_time_item_feature", "drop_user_id", "drop_item_id", "early_stopping_rounds", "include_attributes", "normalize_numerical_features", "use_derived_timestamp_features", "balance_labels"]

    @field_validator('policy_type')
    def policy_type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['lightgbm']):
            raise ValueError("must be one of enum values ('lightgbm')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of ShapedInternalRecsysPoliciesLightgbmModelPolicyLightgbmModelPolicyLightGBMModelPolicyConfig from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * Fields in `self.additional_properties` are added to the output dict.
        """
        excluded_fields: Set[str] = set([
            "additional_properties",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of objective
        if self.objective:
            _dict['objective'] = self.objective.to_dict()
        # override the default output from pydantic by calling `to_dict()` of max_depth
        if self.max_depth:
            _dict['max_depth'] = self.max_depth.to_dict()
        # override the default output from pydantic by calling `to_dict()` of num_leaves
        if self.num_leaves:
            _dict['num_leaves'] = self.num_leaves.to_dict()
        # override the default output from pydantic by calling `to_dict()` of learning_rate
        if self.learning_rate:
            _dict['learning_rate'] = self.learning_rate.to_dict()
        # puts key-value pairs in additional_properties in the top level
        if self.additional_properties is not None:
            for _key, _value in self.additional_properties.items():
                _dict[_key] = _value

        # set to None if name (nullable) is None
        # and model_fields_set contains the field
        if self.name is None and "name" in self.model_fields_set:
            _dict['name'] = None

        # set to None if event_values (nullable) is None
        # and model_fields_set contains the field
        if self.event_values is None and "event_values" in self.model_fields_set:
            _dict['event_values'] = None

        # set to None if num_threads (nullable) is None
        # and model_fields_set contains the field
        if self.num_threads is None and "num_threads" in self.model_fields_set:
            _dict['num_threads'] = None

        # set to None if event_value_affinity_features_value_filter (nullable) is None
        # and model_fields_set contains the field
        if self.event_value_affinity_features_value_filter is None and "event_value_affinity_features_value_filter" in self.model_fields_set:
            _dict['event_value_affinity_features_value_filter'] = None

        # set to None if rolling_window_hours (nullable) is None
        # and model_fields_set contains the field
        if self.rolling_window_hours is None and "rolling_window_hours" in self.model_fields_set:
            _dict['rolling_window_hours'] = None

        # set to None if content_affinity_max_num_latest_items (nullable) is None
        # and model_fields_set contains the field
        if self.content_affinity_max_num_latest_items is None and "content_affinity_max_num_latest_items" in self.model_fields_set:
            _dict['content_affinity_max_num_latest_items'] = None

        # set to None if content_affinity_embedding_ref (nullable) is None
        # and model_fields_set contains the field
        if self.content_affinity_embedding_ref is None and "content_affinity_embedding_ref" in self.model_fields_set:
            _dict['content_affinity_embedding_ref'] = None

        # set to None if early_stopping_rounds (nullable) is None
        # and model_fields_set contains the field
        if self.early_stopping_rounds is None and "early_stopping_rounds" in self.model_fields_set:
            _dict['early_stopping_rounds'] = None

        # set to None if include_attributes (nullable) is None
        # and model_fields_set contains the field
        if self.include_attributes is None and "include_attributes" in self.model_fields_set:
            _dict['include_attributes'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of ShapedInternalRecsysPoliciesLightgbmModelPolicyLightgbmModelPolicyLightGBMModelPolicyConfig from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "policy_type": obj.get("policy_type") if obj.get("policy_type") is not None else 'lightgbm',
            "name": obj.get("name"),
            "event_values": obj.get("event_values"),
            "objective": Objective1.from_dict(obj["objective"]) if obj.get("objective") is not None else None,
            "n_estimators": obj.get("n_estimators") if obj.get("n_estimators") is not None else 100,
            "max_depth": MaxDepth.from_dict(obj["max_depth"]) if obj.get("max_depth") is not None else None,
            "num_leaves": NumLeaves.from_dict(obj["num_leaves"]) if obj.get("num_leaves") is not None else None,
            "min_child_weight": obj.get("min_child_weight") if obj.get("min_child_weight") is not None else 1,
            "learning_rate": LearningRate1.from_dict(obj["learning_rate"]) if obj.get("learning_rate") is not None else None,
            "colsample_bytree": obj.get("colsample_bytree") if obj.get("colsample_bytree") is not None else 0.9,
            "subsample": obj.get("subsample") if obj.get("subsample") is not None else 0.8,
            "subsample_freq": obj.get("subsample_freq") if obj.get("subsample_freq") is not None else 5,
            "zero_as_missing": obj.get("zero_as_missing") if obj.get("zero_as_missing") is not None else True,
            "bin_construct_sample_cnt": obj.get("bin_construct_sample_cnt") if obj.get("bin_construct_sample_cnt") is not None else 200000,
            "verbose": obj.get("verbose") if obj.get("verbose") is not None else 1,
            "verbose_eval": obj.get("verbose_eval") if obj.get("verbose_eval") is not None else 1,
            "num_threads": obj.get("num_threads"),
            "enable_resume": obj.get("enable_resume") if obj.get("enable_resume") is not None else True,
            "lambdarank_truncation_level": obj.get("lambdarank_truncation_level") if obj.get("lambdarank_truncation_level") is not None else 53,
            "calibrate": obj.get("calibrate") if obj.get("calibrate") is not None else False,
            "event_value_user_affinity_features": obj.get("event_value_user_affinity_features") if obj.get("event_value_user_affinity_features") is not None else False,
            "event_value_affinity_features_value_filter": obj.get("event_value_affinity_features_value_filter"),
            "rolling_window_hours": obj.get("rolling_window_hours"),
            "negative_affinity_features": obj.get("negative_affinity_features") if obj.get("negative_affinity_features") is not None else False,
            "content_affinity_features": obj.get("content_affinity_features") if obj.get("content_affinity_features") is not None else False,
            "content_affinity_features_batch_size": obj.get("content_affinity_features_batch_size") if obj.get("content_affinity_features_batch_size") is not None else 1024,
            "content_affinity_max_num_latest_items": obj.get("content_affinity_max_num_latest_items"),
            "content_affinity_embedding_ref": obj.get("content_affinity_embedding_ref"),
            "container_categorical_to_multi_hot": obj.get("container_categorical_to_multi_hot") if obj.get("container_categorical_to_multi_hot") is not None else False,
            "container_to_container_affinities": obj.get("container_to_container_affinities") if obj.get("container_to_container_affinities") is not None else True,
            "point_in_time_item_feature": obj.get("point_in_time_item_feature") if obj.get("point_in_time_item_feature") is not None else False,
            "drop_user_id": obj.get("drop_user_id") if obj.get("drop_user_id") is not None else True,
            "drop_item_id": obj.get("drop_item_id") if obj.get("drop_item_id") is not None else False,
            "early_stopping_rounds": obj.get("early_stopping_rounds"),
            "include_attributes": obj.get("include_attributes"),
            "normalize_numerical_features": obj.get("normalize_numerical_features") if obj.get("normalize_numerical_features") is not None else True,
            "use_derived_timestamp_features": obj.get("use_derived_timestamp_features") if obj.get("use_derived_timestamp_features") is not None else True,
            "balance_labels": obj.get("balance_labels") if obj.get("balance_labels") is not None else True
        })
        # store additional fields in additional_properties
        for _key in obj.keys():
            if _key not in cls.__properties:
                _obj.additional_properties[_key] = obj.get(_key)

        return _obj


