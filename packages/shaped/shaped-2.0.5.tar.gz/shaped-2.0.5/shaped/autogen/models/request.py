# coding: utf-8

"""
 Shaped API

 Welcome to Shaped's API reference docs. These provide a  detailed view of the endpoints and CLI commands that Shaped provides and brief  explanations of how they should be used.  The Shaped API has four main endpoints:  **Tables** - Provision and manage batch and real-time data connectors.   **Views** - Configure SQL transformations and AI enrichment on your input data. Use SQL to combine multiple data sources or use an LLM to add new categories, extract specific attributes from descriptions, etc.  **Engines** - Deploy and manage your relevance engines. The Engine API exposes configuration for indexing logic, input datasets, externam embeddings, and more.  **Query** - Execute queries against your engines, to return data based on an input query or rerank an existing list. The Query API exposes the retrieve, filter, score, and ranking steps of the 4-stage ranking architecture.  The base URL for each endpoint is: `https://api.shaped.ai/v2`

 Generated by OpenAPI Generator (https://openapi-generator.tech)

 Do not edit the class manually.
""" # noqa: E501


from __future__ import annotations
import json
import pprint
from pydantic import BaseModel, ConfigDict, Field, StrictStr, ValidationError, field_validator
from typing import Any, List, Optional
from shaped.autogen.models.amplitude_table_config import AmplitudeTableConfig
from shaped.autogen.models.aws_pinpoint_table_config import AWSPinpointTableConfig
from shaped.autogen.models.big_query_table_config import BigQueryTableConfig
from shaped.autogen.models.clickhouse_table_config import ClickhouseTableConfig
from shaped.autogen.models.custom_table_config import CustomTableConfig
from shaped.autogen.models.dynamo_db_table_config import DynamoDBTableConfig
from shaped.autogen.models.iceberg_table_config import IcebergTableConfig
from shaped.autogen.models.kafka_table_config import KafkaTableConfig
from shaped.autogen.models.kinesis_table_config import KinesisTableConfig
from shaped.autogen.models.mongo_db_table_config import MongoDBTableConfig
from shaped.autogen.models.mssql_table_config import MSSQLTableConfig
from shaped.autogen.models.my_sql_table_config import MySQLTableConfig
from shaped.autogen.models.postgres_table_config import PostgresTableConfig
from shaped.autogen.models.posthog_table_config import PosthogTableConfig
from shaped.autogen.models.redshift_table_config import RedshiftTableConfig
from shaped.autogen.models.rudderstack_table_config import RudderstackTableConfig
from shaped.autogen.models.segment_table_config import SegmentTableConfig
from shaped.autogen.models.shopify_table_config import ShopifyTableConfig
from shaped.autogen.models.snowflake_table_config import SnowflakeTableConfig
from pydantic import StrictStr, Field
from typing import Union, List, Set, Optional, Dict
from typing_extensions import Literal, Self

REQUEST_ONE_OF_SCHEMAS = ["AWSPinpointTableConfig", "AmplitudeTableConfig", "BigQueryTableConfig", "ClickhouseTableConfig", "CustomTableConfig", "DynamoDBTableConfig", "IcebergTableConfig", "KafkaTableConfig", "KinesisTableConfig", "MSSQLTableConfig", "MongoDBTableConfig", "MySQLTableConfig", "PostgresTableConfig", "PosthogTableConfig", "RedshiftTableConfig", "RudderstackTableConfig", "SegmentTableConfig", "ShopifyTableConfig", "SnowflakeTableConfig"]

class Request(BaseModel):
    """
    Request
    """
    # data type: BigQueryTableConfig
    oneof_schema_1_validator: Optional[BigQueryTableConfig] = None
    # data type: MongoDBTableConfig
    oneof_schema_2_validator: Optional[MongoDBTableConfig] = None
    # data type: SnowflakeTableConfig
    oneof_schema_3_validator: Optional[SnowflakeTableConfig] = None
    # data type: AWSPinpointTableConfig
    oneof_schema_4_validator: Optional[AWSPinpointTableConfig] = None
    # data type: CustomTableConfig
    oneof_schema_5_validator: Optional[CustomTableConfig] = None
    # data type: RedshiftTableConfig
    oneof_schema_6_validator: Optional[RedshiftTableConfig] = None
    # data type: PostgresTableConfig
    oneof_schema_7_validator: Optional[PostgresTableConfig] = None
    # data type: MySQLTableConfig
    oneof_schema_8_validator: Optional[MySQLTableConfig] = None
    # data type: MSSQLTableConfig
    oneof_schema_9_validator: Optional[MSSQLTableConfig] = None
    # data type: AmplitudeTableConfig
    oneof_schema_10_validator: Optional[AmplitudeTableConfig] = None
    # data type: SegmentTableConfig
    oneof_schema_11_validator: Optional[SegmentTableConfig] = None
    # data type: RudderstackTableConfig
    oneof_schema_12_validator: Optional[RudderstackTableConfig] = None
    # data type: IcebergTableConfig
    oneof_schema_13_validator: Optional[IcebergTableConfig] = None
    # data type: DynamoDBTableConfig
    oneof_schema_14_validator: Optional[DynamoDBTableConfig] = None
    # data type: ShopifyTableConfig
    oneof_schema_15_validator: Optional[ShopifyTableConfig] = None
    # data type: KinesisTableConfig
    oneof_schema_16_validator: Optional[KinesisTableConfig] = None
    # data type: PosthogTableConfig
    oneof_schema_17_validator: Optional[PosthogTableConfig] = None
    # data type: ClickhouseTableConfig
    oneof_schema_18_validator: Optional[ClickhouseTableConfig] = None
    # data type: KafkaTableConfig
    oneof_schema_19_validator: Optional[KafkaTableConfig] = None
    actual_instance: Optional[Union[AWSPinpointTableConfig, AmplitudeTableConfig, BigQueryTableConfig, ClickhouseTableConfig, CustomTableConfig, DynamoDBTableConfig, IcebergTableConfig, KafkaTableConfig, KinesisTableConfig, MSSQLTableConfig, MongoDBTableConfig, MySQLTableConfig, PostgresTableConfig, PosthogTableConfig, RedshiftTableConfig, RudderstackTableConfig, SegmentTableConfig, ShopifyTableConfig, SnowflakeTableConfig]] = None
    one_of_schemas: Set[str] = { "AWSPinpointTableConfig", "AmplitudeTableConfig", "BigQueryTableConfig", "ClickhouseTableConfig", "CustomTableConfig", "DynamoDBTableConfig", "IcebergTableConfig", "KafkaTableConfig", "KinesisTableConfig", "MSSQLTableConfig", "MongoDBTableConfig", "MySQLTableConfig", "PostgresTableConfig", "PosthogTableConfig", "RedshiftTableConfig", "RudderstackTableConfig", "SegmentTableConfig", "ShopifyTableConfig", "SnowflakeTableConfig" }

    model_config = ConfigDict(
        validate_assignment=True,
        protected_namespaces=(),
    )


    discriminator_value_class_map: Dict[str, str] = {
    }

    def __init__(self, *args, **kwargs) -> None:
        if args:
            if len(args) > 1:
                raise ValueError("If a position argument is used, only 1 is allowed to set `actual_instance`")
            if kwargs:
                raise ValueError("If a position argument is used, keyword arguments cannot be used.")
            super().__init__(actual_instance=args[0])
        else:
            super().__init__(**kwargs)

    @field_validator('actual_instance')
    def actual_instance_must_validate_oneof(cls, v):
        instance = Request.model_construct()
        error_messages = []
        match = 0
        # validate data type: BigQueryTableConfig
        if not isinstance(v, BigQueryTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `BigQueryTableConfig`")
        else:
            match += 1
        # validate data type: MongoDBTableConfig
        if not isinstance(v, MongoDBTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MongoDBTableConfig`")
        else:
            match += 1
        # validate data type: SnowflakeTableConfig
        if not isinstance(v, SnowflakeTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `SnowflakeTableConfig`")
        else:
            match += 1
        # validate data type: AWSPinpointTableConfig
        if not isinstance(v, AWSPinpointTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `AWSPinpointTableConfig`")
        else:
            match += 1
        # validate data type: CustomTableConfig
        if not isinstance(v, CustomTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `CustomTableConfig`")
        else:
            match += 1
        # validate data type: RedshiftTableConfig
        if not isinstance(v, RedshiftTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `RedshiftTableConfig`")
        else:
            match += 1
        # validate data type: PostgresTableConfig
        if not isinstance(v, PostgresTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `PostgresTableConfig`")
        else:
            match += 1
        # validate data type: MySQLTableConfig
        if not isinstance(v, MySQLTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MySQLTableConfig`")
        else:
            match += 1
        # validate data type: MSSQLTableConfig
        if not isinstance(v, MSSQLTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `MSSQLTableConfig`")
        else:
            match += 1
        # validate data type: AmplitudeTableConfig
        if not isinstance(v, AmplitudeTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `AmplitudeTableConfig`")
        else:
            match += 1
        # validate data type: SegmentTableConfig
        if not isinstance(v, SegmentTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `SegmentTableConfig`")
        else:
            match += 1
        # validate data type: RudderstackTableConfig
        if not isinstance(v, RudderstackTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `RudderstackTableConfig`")
        else:
            match += 1
        # validate data type: IcebergTableConfig
        if not isinstance(v, IcebergTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `IcebergTableConfig`")
        else:
            match += 1
        # validate data type: DynamoDBTableConfig
        if not isinstance(v, DynamoDBTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DynamoDBTableConfig`")
        else:
            match += 1
        # validate data type: ShopifyTableConfig
        if not isinstance(v, ShopifyTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `ShopifyTableConfig`")
        else:
            match += 1
        # validate data type: KinesisTableConfig
        if not isinstance(v, KinesisTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `KinesisTableConfig`")
        else:
            match += 1
        # validate data type: PosthogTableConfig
        if not isinstance(v, PosthogTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `PosthogTableConfig`")
        else:
            match += 1
        # validate data type: ClickhouseTableConfig
        if not isinstance(v, ClickhouseTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `ClickhouseTableConfig`")
        else:
            match += 1
        # validate data type: KafkaTableConfig
        if not isinstance(v, KafkaTableConfig):
            error_messages.append(f"Error! Input type `{type(v)}` is not `KafkaTableConfig`")
        else:
            match += 1
        if match > 1:
            # more than 1 match
            raise ValueError("Multiple matches found when setting `actual_instance` in Request with oneOf schemas: AWSPinpointTableConfig, AmplitudeTableConfig, BigQueryTableConfig, ClickhouseTableConfig, CustomTableConfig, DynamoDBTableConfig, IcebergTableConfig, KafkaTableConfig, KinesisTableConfig, MSSQLTableConfig, MongoDBTableConfig, MySQLTableConfig, PostgresTableConfig, PosthogTableConfig, RedshiftTableConfig, RudderstackTableConfig, SegmentTableConfig, ShopifyTableConfig, SnowflakeTableConfig. Details: " + ", ".join(error_messages))
        elif match == 0:
            # no match
            raise ValueError("No match found when setting `actual_instance` in Request with oneOf schemas: AWSPinpointTableConfig, AmplitudeTableConfig, BigQueryTableConfig, ClickhouseTableConfig, CustomTableConfig, DynamoDBTableConfig, IcebergTableConfig, KafkaTableConfig, KinesisTableConfig, MSSQLTableConfig, MongoDBTableConfig, MySQLTableConfig, PostgresTableConfig, PosthogTableConfig, RedshiftTableConfig, RudderstackTableConfig, SegmentTableConfig, ShopifyTableConfig, SnowflakeTableConfig. Details: " + ", ".join(error_messages))
        else:
            return v

    @classmethod
    def from_dict(cls, obj: Union[str, Dict[str, Any]]) -> Self:
        return cls.from_json(json.dumps(obj))

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Returns the object represented by the json string"""
        instance = cls.model_construct()
        error_messages = []
        match = 0

        # deserialize data into BigQueryTableConfig
        try:
            instance.actual_instance = BigQueryTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MongoDBTableConfig
        try:
            instance.actual_instance = MongoDBTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into SnowflakeTableConfig
        try:
            instance.actual_instance = SnowflakeTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into AWSPinpointTableConfig
        try:
            instance.actual_instance = AWSPinpointTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into CustomTableConfig
        try:
            instance.actual_instance = CustomTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into RedshiftTableConfig
        try:
            instance.actual_instance = RedshiftTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into PostgresTableConfig
        try:
            instance.actual_instance = PostgresTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MySQLTableConfig
        try:
            instance.actual_instance = MySQLTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into MSSQLTableConfig
        try:
            instance.actual_instance = MSSQLTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into AmplitudeTableConfig
        try:
            instance.actual_instance = AmplitudeTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into SegmentTableConfig
        try:
            instance.actual_instance = SegmentTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into RudderstackTableConfig
        try:
            instance.actual_instance = RudderstackTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into IcebergTableConfig
        try:
            instance.actual_instance = IcebergTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DynamoDBTableConfig
        try:
            instance.actual_instance = DynamoDBTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into ShopifyTableConfig
        try:
            instance.actual_instance = ShopifyTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into KinesisTableConfig
        try:
            instance.actual_instance = KinesisTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into PosthogTableConfig
        try:
            instance.actual_instance = PosthogTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into ClickhouseTableConfig
        try:
            instance.actual_instance = ClickhouseTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into KafkaTableConfig
        try:
            instance.actual_instance = KafkaTableConfig.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))

        if match > 1:
            # more than 1 match
            raise ValueError("Multiple matches found when deserializing the JSON string into Request with oneOf schemas: AWSPinpointTableConfig, AmplitudeTableConfig, BigQueryTableConfig, ClickhouseTableConfig, CustomTableConfig, DynamoDBTableConfig, IcebergTableConfig, KafkaTableConfig, KinesisTableConfig, MSSQLTableConfig, MongoDBTableConfig, MySQLTableConfig, PostgresTableConfig, PosthogTableConfig, RedshiftTableConfig, RudderstackTableConfig, SegmentTableConfig, ShopifyTableConfig, SnowflakeTableConfig. Details: " + ", ".join(error_messages))
        elif match == 0:
            # no match
            raise ValueError("No match found when deserializing the JSON string into Request with oneOf schemas: AWSPinpointTableConfig, AmplitudeTableConfig, BigQueryTableConfig, ClickhouseTableConfig, CustomTableConfig, DynamoDBTableConfig, IcebergTableConfig, KafkaTableConfig, KinesisTableConfig, MSSQLTableConfig, MongoDBTableConfig, MySQLTableConfig, PostgresTableConfig, PosthogTableConfig, RedshiftTableConfig, RudderstackTableConfig, SegmentTableConfig, ShopifyTableConfig, SnowflakeTableConfig. Details: " + ", ".join(error_messages))
        else:
            return instance

    def to_json(self) -> str:
        """Returns the JSON representation of the actual instance"""
        if self.actual_instance is None:
            return "null"

        if hasattr(self.actual_instance, "to_json") and callable(self.actual_instance.to_json):
            return self.actual_instance.to_json()
        else:
            return json.dumps(self.actual_instance)

    def to_dict(self) -> Optional[Union[Dict[str, Any], AWSPinpointTableConfig, AmplitudeTableConfig, BigQueryTableConfig, ClickhouseTableConfig, CustomTableConfig, DynamoDBTableConfig, IcebergTableConfig, KafkaTableConfig, KinesisTableConfig, MSSQLTableConfig, MongoDBTableConfig, MySQLTableConfig, PostgresTableConfig, PosthogTableConfig, RedshiftTableConfig, RudderstackTableConfig, SegmentTableConfig, ShopifyTableConfig, SnowflakeTableConfig]]:
        """Returns the dict representation of the actual instance"""
        if self.actual_instance is None:
            return None

        if hasattr(self.actual_instance, "to_dict") and callable(self.actual_instance.to_dict):
            return self.actual_instance.to_dict()
        else:
            # primitive type
            return self.actual_instance

    def to_str(self) -> str:
        """Returns the string representation of the actual instance"""
        return pprint.pformat(self.model_dump())


