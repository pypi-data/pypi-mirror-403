import pytest
from urdu_g2p import UrduG2P

def test_nonsense_and_symbols():
    g2p = UrduG2P()
    
    # Test 1: Emojis mixed with Urdu
    text_emoji = "Ù¾Ø§Ú©Ø³ØªØ§Ù† ðŸ‡µðŸ‡° Ø²Ù†Ø¯Û Ø¨Ø§Ø¯ â¤ï¸"
    # Expectation: Emojis should be ignored or treated as punctuation/space, not crash
    phonemes = g2p(text_emoji)
    print(f"Input: {text_emoji}")
    print(f"Output: {phonemes}")
    # Ideally, ðŸ‡µðŸ‡° and â¤ï¸ should be stripped or ignored if they are not in the map
    # The current regex for punctuation might not catch emojis, so they might be passed through or treated as OOV
    
    # Test 2: Random symbols
    text_symbols = "@@##!! Ø§Ø±Ø¯Ùˆ $$%%"
    phonemes_symbols = g2p(text_symbols)
    print(f"Input: {text_symbols}")
    print(f"Output: {phonemes_symbols}")
    
    # Test 3: Dirty text
    text_dirty = "F&%^$k this s#*t... Ù…Ø¬Ú¾Û’ Ù¹ÛŒØ³Ù¹ Ú©Ø±Ùˆ"
    phonemes_dirty = g2p(text_dirty)
    print(f"Input: {text_dirty}")
    print(f"Output: {phonemes_dirty}")

    # Test 4: Dot removal check
    # Manually check _normalize_ipa since it's hard to force espeak to produce a dot deterministically without specific context
    normalized = g2p._normalize_ipa("ÊˆeË.stÌª")
    assert "." not in normalized
    assert normalized == "ÊˆeËstÌª"
    print(f"Dot removal test: ÊˆeË.stÌª -> {normalized}")

    # Test 5: Stress removal (init param)
    g2p_stress = UrduG2P(ignore_stress=True)
    text_stress = "Ù…Ø¬Ú¾Û’"
    # mÊŠËˆdÍ¡Ê’eË -> mÊŠdÍ¡Ê’eË
    phoneme_stress = g2p_stress(text_stress)[0]
    print(f"Stress removal test: {text_stress} -> {phoneme_stress}")
    assert "Ëˆ" not in phoneme_stress
    
    # Assertions - basically ensuring it doesn't crash and output helps diagnosis
    assert isinstance(phonemes, list)
    assert isinstance(phonemes_symbols, list)
    assert isinstance(phonemes_dirty, list)
