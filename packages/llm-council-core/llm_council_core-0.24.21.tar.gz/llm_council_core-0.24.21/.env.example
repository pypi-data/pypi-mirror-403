# LLM Council Environment Configuration
# Copy this file to .env and fill in your values
# NEVER commit .env to version control!

# =============================================================================
# REQUIRED: API Keys (at least one gateway key required)
# =============================================================================

# OpenRouter API Key (default gateway)
# Get yours at: https://openrouter.ai/
OPENROUTER_API_KEY=your-openrouter-api-key-here

# =============================================================================
# OPTIONAL: Alternative Gateways
# =============================================================================

# Requesty Gateway (for BYOK mode and analytics)
# REQUESTY_API_KEY=your-requesty-api-key

# Direct Provider APIs (for DirectGateway)
# ANTHROPIC_API_KEY=sk-ant-...
# OPENAI_API_KEY=sk-...
# GOOGLE_API_KEY=...

# Not Diamond API (for advanced routing)
# NOT_DIAMOND_API_KEY=your-not-diamond-key

# =============================================================================
# OPTIONAL: Council Configuration
# =============================================================================

# Council models (comma-separated)
# LLM_COUNCIL_MODELS=openai/gpt-4o,anthropic/claude-3-5-sonnet,google/gemini-pro

# Chairman model (synthesizes final response)
# LLM_COUNCIL_CHAIRMAN=google/gemini-3-pro-preview

# Synthesis mode: consensus (default) or debate
# LLM_COUNCIL_MODE=consensus

# Default gateway: openrouter (default), requesty, direct
# LLM_COUNCIL_DEFAULT_GATEWAY=openrouter

# =============================================================================
# OPTIONAL: Feature Flags
# =============================================================================

# Enable gateway layer with circuit breaker
# LLM_COUNCIL_USE_GATEWAY=false

# Enable wildcard specialist selection (ADR-020)
# LLM_COUNCIL_WILDCARD_ENABLED=false

# Enable per-model prompt optimization (ADR-020)
# LLM_COUNCIL_PROMPT_OPTIMIZATION_ENABLED=false

# Enable rubric scoring (ADR-016)
# LLM_COUNCIL_RUBRIC_SCORING=false

# Enable bias auditing (ADR-015)
# LLM_COUNCIL_BIAS_AUDIT=false

# Enable cross-session bias persistence (ADR-018)
# LLM_COUNCIL_BIAS_PERSISTENCE=false

# Enable offline mode (no external metadata calls)
# LLM_COUNCIL_OFFLINE=false

# =============================================================================
# OPTIONAL: Ollama Configuration (for local models)
# =============================================================================

# Ollama API endpoint
# LLM_COUNCIL_OLLAMA_BASE_URL=http://localhost:11434

# Ollama timeout (seconds)
# LLM_COUNCIL_OLLAMA_TIMEOUT=120.0

# =============================================================================
# OPTIONAL: Webhook Configuration
# =============================================================================

# Webhook timeout (seconds)
# LLM_COUNCIL_WEBHOOK_TIMEOUT=5.0

# Max retry attempts
# LLM_COUNCIL_WEBHOOK_RETRIES=3

# Require HTTPS for webhooks (except localhost)
# LLM_COUNCIL_WEBHOOK_HTTPS_ONLY=true
