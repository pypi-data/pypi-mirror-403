# This file was auto-generated by Fern from our API Definition.

import typing

from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from ..types.scrape_post_response import ScrapePostResponse
from ..types.scrape_user_response import ScrapeUserResponse
from .raw_client import AsyncRawScrapingClient, RawScrapingClient
from .types.scrape_user_params_query_type import ScrapeUserParamsQueryType
from .types.scrape_user_params_replies_filter import ScrapeUserParamsRepliesFilter

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class ScrapingClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawScrapingClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawScrapingClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawScrapingClient
        """
        return self._raw_client

    def scrape_tweets_from_a_twitter_user(
        self,
        *,
        user_name: str,
        max_tweets: typing.Optional[int] = OMIT,
        time_window: typing.Optional[str] = OMIT,
        query_type: typing.Optional[ScrapeUserParamsQueryType] = OMIT,
        replies_filter: typing.Optional[ScrapeUserParamsRepliesFilter] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ScrapeUserResponse:
        """
        Fetches tweets from a specific Twitter user with filtering options. Supports time windows, reply filters, and sorting by latest or top engagement.

        Parameters
        ----------
        user_name : str
            Twitter username (without @ symbol)

        max_tweets : typing.Optional[int]
            Maximum number of tweets to scrape (1-1000)

        time_window : typing.Optional[str]
            Time window for tweets (e.g., "7d", "24h", "30d")

        query_type : typing.Optional[ScrapeUserParamsQueryType]
            Sort order: Latest (chronological) or Top (by engagement)

        replies_filter : typing.Optional[ScrapeUserParamsRepliesFilter]
            Filter for replies: all (include), only (replies only), exclude (no replies)

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ScrapeUserResponse
            Successfully scraped tweets

        Examples
        --------
        from alavida_x_scraper import XScraperClient

        client = XScraperClient(
            token="YOUR_TOKEN",
        )
        client.scraping.scrape_tweets_from_a_twitter_user(
            user_name="elonmusk",
        )
        """
        _response = self._raw_client.scrape_tweets_from_a_twitter_user(
            user_name=user_name,
            max_tweets=max_tweets,
            time_window=time_window,
            query_type=query_type,
            replies_filter=replies_filter,
            request_options=request_options,
        )
        return _response.data

    def scrape_a_single_tweet_by_url(
        self, *, url: str, request_options: typing.Optional[RequestOptions] = None
    ) -> ScrapePostResponse:
        """
        Fetches detailed information about a specific tweet given its URL.

        Parameters
        ----------
        url : str
            Twitter/X post URL

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ScrapePostResponse
            Successfully scraped tweet

        Examples
        --------
        from alavida_x_scraper import XScraperClient

        client = XScraperClient(
            token="YOUR_TOKEN",
        )
        client.scraping.scrape_a_single_tweet_by_url(
            url="https://x.com/elonmusk/status/1234567890",
        )
        """
        _response = self._raw_client.scrape_a_single_tweet_by_url(url=url, request_options=request_options)
        return _response.data


class AsyncScrapingClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawScrapingClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawScrapingClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawScrapingClient
        """
        return self._raw_client

    async def scrape_tweets_from_a_twitter_user(
        self,
        *,
        user_name: str,
        max_tweets: typing.Optional[int] = OMIT,
        time_window: typing.Optional[str] = OMIT,
        query_type: typing.Optional[ScrapeUserParamsQueryType] = OMIT,
        replies_filter: typing.Optional[ScrapeUserParamsRepliesFilter] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> ScrapeUserResponse:
        """
        Fetches tweets from a specific Twitter user with filtering options. Supports time windows, reply filters, and sorting by latest or top engagement.

        Parameters
        ----------
        user_name : str
            Twitter username (without @ symbol)

        max_tweets : typing.Optional[int]
            Maximum number of tweets to scrape (1-1000)

        time_window : typing.Optional[str]
            Time window for tweets (e.g., "7d", "24h", "30d")

        query_type : typing.Optional[ScrapeUserParamsQueryType]
            Sort order: Latest (chronological) or Top (by engagement)

        replies_filter : typing.Optional[ScrapeUserParamsRepliesFilter]
            Filter for replies: all (include), only (replies only), exclude (no replies)

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ScrapeUserResponse
            Successfully scraped tweets

        Examples
        --------
        import asyncio

        from alavida_x_scraper import AsyncXScraperClient

        client = AsyncXScraperClient(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.scraping.scrape_tweets_from_a_twitter_user(
                user_name="elonmusk",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.scrape_tweets_from_a_twitter_user(
            user_name=user_name,
            max_tweets=max_tweets,
            time_window=time_window,
            query_type=query_type,
            replies_filter=replies_filter,
            request_options=request_options,
        )
        return _response.data

    async def scrape_a_single_tweet_by_url(
        self, *, url: str, request_options: typing.Optional[RequestOptions] = None
    ) -> ScrapePostResponse:
        """
        Fetches detailed information about a specific tweet given its URL.

        Parameters
        ----------
        url : str
            Twitter/X post URL

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ScrapePostResponse
            Successfully scraped tweet

        Examples
        --------
        import asyncio

        from alavida_x_scraper import AsyncXScraperClient

        client = AsyncXScraperClient(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.scraping.scrape_a_single_tweet_by_url(
                url="https://x.com/elonmusk/status/1234567890",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.scrape_a_single_tweet_by_url(url=url, request_options=request_options)
        return _response.data
