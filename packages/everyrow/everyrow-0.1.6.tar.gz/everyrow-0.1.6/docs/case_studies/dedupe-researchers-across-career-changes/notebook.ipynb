{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Researcher Deduplication\n",
    "\n",
    "This notebook demonstrates using everyrow's `dedupe()` utility to clean a researcher/candidate database where the same person appears multiple times due to career changes, name variations, and data quality issues.\n",
    "\n",
    "**Use Case:** Your candidate database has the same researchers listed multiple timesâ€”once from a conference 3 years ago (when they were at Stanford), again from a recent paper (now at OpenAI), and maybe a third time with just initials. You need to deduplicate without losing the career history.\n",
    "\n",
    "**Why everyrow?** The `dedupe()` function understands that \"Dr. A. Butoi\" at Stanford in 2021 and \"Alexandra Butoi\" at Google in 2024 might be the same person who changed jobs. Traditional fuzzy matching can't handle these career transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import pandas as pd\n",
    "from everyrow import create_session\n",
    "from everyrow.ops import dedupe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Researcher Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "researchers_df = pd.read_csv(\"../data/researchers.csv\")\n\n# Fill NaN values with empty strings to avoid JSON serialization issues\nresearchers_df = researchers_df.fillna(\"\")\n\nprint(f\"Researcher records: {len(researchers_df)}\")\nprint(f\"Expected unique people: ~12\")\nresearchers_df"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Deduplication Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEDUPE_RULE = \"\"\"\n",
    "Two rows represent the SAME PERSON if they are the same researcher/individual.\n",
    "\n",
    "Consider as the same person:\n",
    "- Name variations: initials (A. Butoi = Alexandra Butoi), nicknames (Bob = Robert, Mike = Michael)\n",
    "- Typos in names (Sara = Sarah)\n",
    "- Same person at different institutions over time (career transitions are common in academia/tech)\n",
    "- Same GitHub handle is a strong signal of same person\n",
    "- Same email domain root can indicate same person (even if subdomain differs)\n",
    "\n",
    "Do NOT consider as same person:\n",
    "- Same common name but clearly different fields/institutions with no linking signals\n",
    "- Same first name only with different last names\n",
    "- Different GitHub handles usually means different people (unless one is missing)\n",
    "\n",
    "When GitHub handles match, that's strong evidence of same person even with institution changes.\n",
    "When a common name appears with no linking signals (different github, different field), keep separate.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_dedupe():\n",
    "    async with create_session(name=\"Researcher Deduplication\") as session:\n",
    "        print(f\"Session URL: {session.get_url()}\")\n",
    "        print(\"\\nDeduplicating researcher records...\\n\")\n",
    "        \n",
    "        result = await dedupe(\n",
    "            session=session,\n",
    "            input=researchers_df,\n",
    "            equivalence_relation=DEDUPE_RULE,\n",
    "        )\n",
    "        \n",
    "        return result.data\n",
    "\n",
    "results_df = await run_dedupe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DEDUPLICATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Original records:      {len(researchers_df)}\")\n",
    "print(f\"  Unique researchers:    {results_df['cluster_id'].nunique()}\")\n",
    "print(f\"  Duplicate records:     {len(researchers_df) - results_df['cluster_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show duplicate clusters (people with multiple records)\n",
    "print(\"\\nRESEARCHERS WITH MULTIPLE RECORDS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "cluster_counts = results_df['cluster_id'].value_counts()\n",
    "duplicate_clusters = cluster_counts[cluster_counts > 1].index\n",
    "\n",
    "for cluster_id in duplicate_clusters:\n",
    "    cluster = results_df[results_df['cluster_id'] == cluster_id].sort_values('year')\n",
    "    \n",
    "    print(f\"\\n--- Person (Cluster {cluster_id}) ---\")\n",
    "    print(\"Career timeline:\")\n",
    "    for _, row in cluster.iterrows():\n",
    "        github = f\"@{row['github']}\" if pd.notna(row['github']) else \"(no github)\"\n",
    "        email = row['email'] if pd.notna(row['email']) else \"(no email)\"\n",
    "        print(f\"  {row['year']}: {row['name']:20} | {row['institution']:25} | {github}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the \"distractor\" Michael Chen was correctly kept separate\n",
    "michael_chens = results_df[results_df['name'].str.contains('Michael Chen|Mike Chen|M. Chen', case=False, na=False)]\n",
    "\n",
    "print(\"\\nMICHAEL CHEN DISAMBIGUATION CHECK:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Records with 'Michael/Mike Chen': {len(michael_chens)}\")\n",
    "print(f\"Unique clusters: {michael_chens['cluster_id'].nunique()}\")\n",
    "print(\"\\nDetails:\")\n",
    "for _, row in michael_chens.iterrows():\n",
    "    print(f\"  Cluster {row['cluster_id']}: {row['name']:15} | {row['institution']:20} | {row.get('github', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show unique researchers (no duplicates found)\n",
    "singleton_clusters = cluster_counts[cluster_counts == 1].index\n",
    "singletons = results_df[results_df['cluster_id'].isin(singleton_clusters)]\n",
    "\n",
    "print(f\"\\nUNIQUE RESEARCHERS ({len(singletons)} with single record):\")\n",
    "print(\"-\" * 60)\n",
    "for _, row in singletons.iterrows():\n",
    "    print(f\"  {row['name']:25} | {row['institution']:25} | {row['year']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create consolidated view (most recent record per person)\n",
    "consolidated = results_df.sort_values('year', ascending=False).groupby('cluster_id').first().reset_index()\n",
    "\n",
    "print(f\"\\nCONSOLIDATED RESEARCHER LIST ({len(consolidated)} unique people):\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Name':<25} | {'Current Institution':<30} | {'Year'}\")\n",
    "print(\"-\" * 70)\n",
    "for _, row in consolidated.sort_values('name').iterrows():\n",
    "    print(f\"{row['name']:<25} | {row['institution']:<30} | {row['year']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export deduplicated list\n",
    "consolidated.to_csv(\"researchers_deduplicated.csv\", index=False)\n",
    "print(f\"\\nExported {len(consolidated)} unique researchers to researchers_deduplicated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full results with cluster assignments\n",
    "results_df.sort_values(['cluster_id', 'year'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}