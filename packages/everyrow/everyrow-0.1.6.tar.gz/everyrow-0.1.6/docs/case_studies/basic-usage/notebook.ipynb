{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# everyrow SDK Basic Usage\n",
    "\n",
    "This notebook demonstrates all the core operations in the everyrow SDK:\n",
    "\n",
    "1. **Screen** - Filter rows based on criteria that need judgment\n",
    "2. **Rank** - Score rows by qualitative factors\n",
    "3. **Dedupe** - Deduplicate when fuzzy matching fails\n",
    "4. **Merge** - Join tables when keys don't match exactly\n",
    "5. **Derive** - Add computed columns (no AI needed)\n",
    "6. **Single Agent** - Web research on a single input\n",
    "7. **Agent Map** - Web research on every row of a dataframe\n",
    "\n",
    "Get an API key at [everyrow.io/api-key](https://everyrow.io/api-key) to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from textwrap import dedent\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pandas import DataFrame\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Screen\n",
    "\n",
    "Filter rows based on criteria you can't put in a WHERE clause. This example performs vendor risk assessment - evaluating security track records and financial stability requires judgment, not pattern matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vendors:\n",
      "      company             category         website\n",
      "0        Okta  Identity Management        okta.com\n",
      "1    LastPass  Password Management    lastpass.com\n",
      "2   Snowflake       Data Warehouse   snowflake.com\n",
      "3  Cloudflare       CDN & Security  cloudflare.com\n",
      "4     MongoDB             Database     mongodb.com\n"
     ]
    }
   ],
   "source": [
    "from everyrow.ops import screen\n",
    "\n",
    "\n",
    "class VendorRiskAssessment(BaseModel):\n",
    "    approved: bool\n",
    "    risk_level: str  # \"low\", \"medium\", \"high\"\n",
    "    security_concerns: str\n",
    "    financial_stability_notes: str\n",
    "    recommendation: str\n",
    "\n",
    "\n",
    "vendors = DataFrame(\n",
    "    [\n",
    "        {\"company\": \"Okta\", \"category\": \"Identity Management\", \"website\": \"okta.com\"},\n",
    "        {\"company\": \"LastPass\", \"category\": \"Password Management\", \"website\": \"lastpass.com\"},\n",
    "        {\"company\": \"Snowflake\", \"category\": \"Data Warehouse\", \"website\": \"snowflake.com\"},\n",
    "        {\"company\": \"Cloudflare\", \"category\": \"CDN & Security\", \"website\": \"cloudflare.com\"},\n",
    "        {\"company\": \"MongoDB\", \"category\": \"Database\", \"website\": \"mongodb.com\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Input vendors:\")\n",
    "print(vendors.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "screen_result = await screen(\n    task=dedent(\"\"\"\n        Perform vendor risk assessment for each company. Research and evaluate:\n\n        1. Security track record: Have they had any significant data breaches or security\n        incidents in the past 3 years? How did they respond?\n\n        2. Financial stability: Are there signs of financial distress (major layoffs,\n        funding difficulties, declining revenue)?\n\n        3. Overall recommendation: Based on your research, should we proceed with\n        this vendor for enterprise use?\n\n        Only approve vendors with low or medium risk and no unresolved critical security incidents.\n    \"\"\"),\n    input=vendors,\n    response_model=VendorRiskAssessment,\n)\n\nprint(\"Vendor Risk Assessment Results:\")\nprint(screen_result.data.to_string())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rank\n",
    "\n",
    "Score rows by things you can't put in a database field. This example ranks AI research organizations by leadership citation counts - information that requires researching each org's leaders and their publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Research Organizations:\n",
      "         organization           type  founded\n",
      "0              OpenAI    Private lab     2015\n",
      "1     Google DeepMind  Corporate lab     2010\n",
      "2           Anthropic    Private lab     2021\n",
      "3           Meta FAIR  Corporate lab     2013\n",
      "4  Microsoft Research  Corporate lab     1991\n",
      "5        Stanford HAI       Academic     2019\n"
     ]
    }
   ],
   "source": [
    "from everyrow.ops import rank\n",
    "\n",
    "\n",
    "class ContributionRanking(BaseModel):\n",
    "    contribution_score: int = Field(description=\"Total citation count\")\n",
    "    most_significant_contribution: str = Field(\n",
    "        description=\"Single most important paper authored by a firm leader\"\n",
    "    )\n",
    "\n",
    "\n",
    "ai_research_orgs = DataFrame(\n",
    "    [\n",
    "        {\"organization\": \"OpenAI\", \"type\": \"Private lab\", \"founded\": 2015},\n",
    "        {\"organization\": \"Google DeepMind\", \"type\": \"Corporate lab\", \"founded\": 2010},\n",
    "        {\"organization\": \"Anthropic\", \"type\": \"Private lab\", \"founded\": 2021},\n",
    "        {\"organization\": \"Meta FAIR\", \"type\": \"Corporate lab\", \"founded\": 2013},\n",
    "        {\"organization\": \"Microsoft Research\", \"type\": \"Corporate lab\", \"founded\": 1991},\n",
    "        {\"organization\": \"Stanford HAI\", \"type\": \"Academic\", \"founded\": 2019},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"AI Research Organizations:\")\n",
    "print(ai_research_orgs.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Research Organization Rankings:\n",
      "         organization           type  founded                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            research  contribution_score\n",
      "0           Anthropic    Private lab     2021                                                                                                                                                                                                                                                                                                                                                                                                                                                              {'contribution_score': 'Citations for the seven co-founders and key C-suite members were aggregated from verified Google Scholar profiles: Dario Amodei (146,768), Jared Kaplan (125,951), Tom Brown (113,794), Sam McCandlish (107,871), Chris Olah (104,560), Jack Clark (63,145), and Daniela Amodei (approx. 43,000). Mike Krieger (est. <1,000) and Krishna Rao (negligible) were also considered. The total citation count is approximately 705,089. Data as of Jan 2026. Sources include Google Scholar profiles for the Amodeis, Kaplan, Brown, McCandlish, Olah, and Clark.'}              705089\n",
      "1  Microsoft Research  Corporate lab     1991                                                                                                                              {'contribution_score': 'Citation counts were sourced from Google Scholar profiles where available, and supplemented with ResearchGate or academic news snippets for leaders without a public Scholar profile. Specifically: Eric Horvitz (117,210 citations), Johannes Gehrke (69,301), Jaime Teevan (23,951), Ece Kamar (21,470), Peter Lee (est. 15,000+ based on h-index 35 in 2013 and recent high-impact works like GPT-4 in Medicine with 1,800+ citations), Rick Rashid (est. 12,000+ based on ResearchGate and long-term research leadership), Nathan Myhrvold (est. 25,000+ based on academic databases for his work in planetary science and computer science), and Ashley Llorens (750). The aggregate is approximately 411,311. Assumed Peter Lee and Nathan Myhrvold's counts from reliable snippets and ResearchGate profiles as they lack a single verified Google Scholar page. Data as of Jan 2026.'}              411311\n",
      "2     Google DeepMind  Corporate lab     2010                                                                                                                                                                                                                                                                                                                                                                                                                                                                               {'contribution_score': 'Google DeepMind leaders identified as Demis Hassabis (CEO/Co-founder), Shane Legg (Chief AGI Scientist/Co-founder), Mustafa Suleyman (Co-founder), Lila Ibrahim (COO), Koray Kavukcuoglu (VP Research/CTO), Zoubin Ghahramani (VP Research), and Pushmeet Kohli (VP Research). Citation data sourced from Google Scholar profiles and academic databases as of January 2026. Top publications for individuals like Hassabis and Kavukcuoglu include AlphaFold and AlphaGo papers with tens of thousands of citations. [1, 3, 4, 11, 22, 23]'}                   5\n",
      "3           Meta FAIR  Corporate lab     2013                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          {'contribution_score': 'Meta FAIR leaders identified as Yann LeCun (Chief AI Scientist/Founding Director), Joelle Pineau (former VP AI Research/Co-Managing Director), and Shengjia Zhao (newly appointed Chief Scientist of Superintelligence/FAIR in 2025). Mark Zuckerberg and Andrew Bosworth are included as C-suite. Citation data reflects significant impact of 'Godfathers of AI' papers and recent foundation model (Llama) contributions. Yann LeCun's total citations exceed 440,000. [5, 6, 12, 14, 21, 26]'}                   5\n",
      "4              OpenAI    Private lab     2015  {'contribution_score': 'Citation counts were obtained primarily from Google Scholar profiles where available, which aggregate citations across all major publications. For founders without a public Google Scholar profile, alternative academic databases like Semantic Scholar, ResearchGate, or SciSpace were used. Sam Altman and Sarah Friar do not have public research profiles, reflecting their roles as business executives rather than primary researchers, though Altman is a co-author on the highly cited GPT-4 technical report. Elon Musk's count is from a verified Google Scholar profile. Citations for Trevor Blackwell, Vicki Cheung, and Pamela Vagata were sourced from academic repositories linking them to OpenAI's early research outputs like OpenAI Gym. Jakub Pachocki's count is from Semantic Scholar. Kevin Weil's count is from his verified LinkedIn announcement regarding his Google Scholar metrics. Ilya Sutskever, John Schulman, and Diederik Kingma are among the most cited AI researchers globally.'}                   4\n",
      "5        Stanford HAI       Academic     2019                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {'contribution_score': 'Fei-Fei Li and James Landay have verified Google Scholar profiles which were used for their total citation counts. John Etchemendy's citation count was sourced from ScholarGPS and ResearchGate, reflecting his long career in logic and philosophy. Russell Wald's citations are primarily associated with his leadership and co-authorship of the annual Stanford AI Index reports, which are widely cited in policy and research literature; the count provided reflects citations to these key institutional outputs.'}                   4\n"
     ]
    }
   ],
   "source": [
    "rank_task = dedent(\"\"\"\n",
    "    Research the total citation count of all leaders of the given AI research organization.\n",
    "\n",
    "    A leader is defined as a C-Suite or founder of the company.\n",
    "    Citation count should count all major publications. Top ten by each person is sufficient.\n",
    "\"\"\")\n",
    "\n",
    "# Basic ranking with a single score field\n",
    "rank_result = await rank(\n",
    "    task=rank_task,\n",
    "    input=ai_research_orgs,\n",
    "    field_name=\"contribution_score\",\n",
    "    ascending_order=False,\n",
    ")\n",
    "\n",
    "print(\"AI Research Organization Rankings:\")\n",
    "print(rank_result.data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Rankings with Context:\n",
      "         organization           type  founded  contribution_score                                                                                                                                                   most_significant_contribution                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   research\n",
      "0     Google DeepMind  Corporate lab     2010             1052670                                                                     AlphaFold (Nobel Prize in Chemistry 2024) and the development of Deep Reinforcement Learning (DQN/AlphaGo).  {'most_significant_contribution': 'The organization's most significant contribution is the creation of AlphaFold, which solved the 50-year-old protein folding problem, earning Demis Hassabis and John Jumper the 2024 Nobel Prize in Chemistry. Other major contributions include AlphaGo (beating Lee Sedol) and the foundations of deep reinforcement learning (DQN). Sources: [Wikipedia: Demis Hassabis], [Nature: AlphaFold Nobel].', 'contribution_score': 'The total citation count for Google DeepMind's leadership is approximately 1,052,670. This includes Demis Hassabis (CEO/Co-founder) with ~204,149 citations (SciSpace, Jan 2026), Shane Legg (Chief AGI Scientist/Co-founder) with ~13,000 citations (based on specific high-impact papers like Definitions of Intelligence), Mustafa Suleyman (Co-founder) with ~17,758 citations (ResearchGate), Koray Kavukcuoglu (VP Research/C-Suite) with ~292,000 citations (Google Scholar profile), Jeff Dean (Chief Scientist) with ~376,412 citations (Google Scholar, Jan 2026), and John Jumper (Director/Leader) with ~149,351 citations (estimated from Nobel Prize impacts and Google Scholar). Sources: [Demis Hassabis SciSpace], [Koray Kavukcuoglu Analysis], [Jeff Dean Analysis], [John Jumper Nobel Impact].'}\n",
      "1              OpenAI    Private lab     2015             1017389                                                                        AlexNet (modern deep learning foundation) and the development of the GPT series (Large Language Models).                   {'contribution_score': 'The total citation count for OpenAI's leadership (founders and current/recent C-suite) is approximately 1,017,389. This includes Ilya Sutskever (Co-founder/Former Chief Scientist) with ~741,302 citations (Google Scholar 2026), Sam Altman (CEO/Co-founder) with ~180,000 citations (Observer 2025), Wojciech Zaremba (Co-founder) with ~50,233 citations (Research.com), Mira Murati (Former CTO) with ~43,000 citations (CoinDesk 2025/Google Scholar), Jakub Pachocki (Chief Scientist) with ~3,854 citations (ResearchGate), and Greg Brockman (President/Co-founder) with ~20,000 citations (Observer/various reports). Business leaders Brad Lightcap and Sarah Friar have negligible academic citation counts. Sources: [Ilya Sutskever Google Scholar], [Sam Altman Observer Profile], [Mira Murati CoinDesk], [Jakub Pachocki ResearchGate].', 'most_significant_contribution': 'The primary scientific contribution is AlexNet (co-authored by Ilya Sutskever), which triggered the current AI revolution. The primary organizational contribution is the development and scaling of the GPT (Generative Pre-trained Transformer) series, leading to ChatGPT and GPT-4. Sources: [Wikipedia: Ilya Sutskever], [OpenAI structure].'}\n",
      "2           Anthropic    Private lab     2021              788000                                        Development of Scaling Laws for Neural Language Models, which formalized the relationship between model performance, scale, and compute.                                                                                                                                                                                                                                                                                                            {'most_significant_contribution': 'Dario Amodei, Jared Kaplan, and Sam McCandlish are credited with pioneering the concept of AI Scaling Laws at OpenAI before founding Anthropic [16, 17, 26]. This research remains the foundational principle for Anthropic's development of the Claude series [19, 25].', 'contribution_score': 'Aggregated citation counts for the primary founders of Anthropic. Dario Amodei: ~146,768 [Google Scholar 1]. Jared Kaplan: ~125,951 [Google Scholar 6]. Tom Brown: ~113,794 [Google Scholar 5]. Sam McCandlish: ~107,871 [Google Scholar 4]. Benjamin Mann: ~90,043 [Google Scholar 11]. Jack Clark: ~66,298 [Google Scholar 3]. Daniela Amodei: ~137,000 (aggregated from co-authored works like GPT-3 and scaling laws, often sharing citations with her brother) [Google Scholar 1, 10, 20]. Mike Krieger (CPO) has negligible academic citations but is noted for co-founding Instagram [21, 23]. Total rounded to nearest thousand.'}\n",
      "3        Stanford HAI       Academic     2019              711197                                      Development of ImageNet, a foundational large-scale dataset that catalyzed the deep learning revolution in computer vision [4, 5, 23, 24].                                                                                                                                                                                                      {'contribution_score': 'The total citation count is the sum of the Google Scholar total citations for the primary leaders (C-Suite/Founders) identified: Fei-Fei Li (334,648 [4]), Christopher Manning (307,732 [14]), James Landay (34,817 [15]), and John Etchemendy (~34,000 [3, 6, 22]). Fei-Fei Li, John Etchemendy, and James Landay are founding co-directors [1, 5, 22], and Christopher Manning is the Director of the Stanford AI Lab (SAIL) and a lead faculty at HAI [14, 16, 20]. Citations are based on Google Scholar profiles as of early 2026. Data for John Etchemendy was estimated from multiple scholarly databases as he lacks a consolidated public Google Scholar profile [3, 6, 17, 18, 22].', 'most_significant_contribution': 'Fei-Fei Li is the most cited founder and her work on ImageNet is universally cited as the most transformative contribution to the field of AI from the HAI leadership team [4, 5, 23, 24]. Manning's GloVe and Landay's HCI work are also significant but secondary to the industry-wide impact of ImageNet [14, 15, 16].'}\n",
      "4           Meta FAIR  Corporate lab     2013              663372                            Pioneering the development of Convolutional Neural Networks (CNNs), which form the architecture for most modern computer vision systems [3, 10, 21].                                                                                                                                                                                                                                                                        {'most_significant_contribution': 'Yann LeCun is the founder and his development of CNNs is the single most significant contribution credited to FAIR's leadership, having revolutionized the field of deep learning [3, 10, 21]. Van der Maaten's t-SNE is also highly significant (64k+ citations) but is considered a tool within the broader neural network framework pioneered by LeCun [12].', 'contribution_score': 'The total citation count is the sum of citations for the primary leaders/founders of FAIR: Yann LeCun (Founder/Chief Scientist: 447,247 [3]), Joelle Pineau (VP Research: 40,593 [7]), Laurens van der Maaten (Senior Research Director: 175,532 [12, 13]). Other FAIR leads like Antoine Bordes (estimated ~50,000 [11, 26]) also contribute, but the core leadership citations already exceed 660,000. Data reflects values from Google Scholar and personal academic pages as of early 2026 [3, 7, 10, 12, 13, 25]. Joelle Pineau left for Cohere in late 2025/early 2026 [2, 13].'}\n",
      "5  Microsoft Research  Corporate lab     1991              450000  Foundational work in Bayesian modeling and decision-making under uncertainty, and the authorship of the industry-standard textbook 'Pattern Recognition and Machine Learning'.                                                                                                                                                                                                                                                                                              {'most_significant_contribution': 'Christopher Bishop's textbook 'Pattern Recognition and Machine Learning' is one of the most cited works in AI history [13, 28]. Eric Horvitz is cited as a pioneer in decision science and Bayesian reasoning for AI [9, 18, 27]. Johannes Gehrke is best known for the BIRCH algorithm and data mining privacy [10, 19]. Jaime Teevan invented the first personalized search algorithm for Bing [14, 22, 29].', 'contribution_score': 'Aggregated citation counts for Microsoft Research leadership. Christopher Bishop: ~164,388 [Google Scholar 13]. Eric Horvitz: ~117,210 [Google Scholar 9]. Johannes Gehrke: ~69,301 [Google Scholar 10]. Jaime Teevan: ~23,620 [Google Scholar 14, 22]. Peter Lee: ~66,000 (aggregated across diverse contributions including his time as CMU professor and MSR leader; distinct from UK-based Peter Lee) [Google Scholar 8, 25, 27]. Ashley Llorens: ~750 [Google Scholar 15]. Total rounded for major leaders.'}\n"
     ]
    }
   ],
   "source": [
    "# Ranking with a custom response model for additional context\n",
    "detailed_rank_result = await rank(\n",
    "    task=rank_task + \"\\n\\nAlso include their single most significant contribution.\",\n",
    "    input=ai_research_orgs,\n",
    "    field_name=\"contribution_score\",\n",
    "    response_model=ContributionRanking,\n",
    "    ascending_order=False,\n",
    ")\n",
    "\n",
    "print(\"Detailed Rankings with Context:\")\n",
    "print(detailed_rank_result.data.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dedupe\n",
    "\n",
    "Deduplicate when fuzzy matching falls short. This example deduplicates academic papers where the same paper may appear with different identifiers (arXiv ID vs DOI), different title formats, or as preprint vs published versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input papers (8 rows):\n",
      "                                                                              title                          authors         venue               identifier\n",
      "0                                                         Attention Is All You Need                   Vaswani et al.  NeurIPS 2017  10.5555/3295222.3295349\n",
      "1                                                         Attention Is All You Need  Vaswani, Shazeer, Parmar et al.         arXiv               1706.03762\n",
      "2  BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding                    Devlin et al.    NAACL 2019     10.18653/v1/N19-1423\n",
      "3                             BERT: Pre-training of Deep Bidirectional Transformers    Devlin, Chang, Lee, Toutanova         arXiv               1810.04805\n",
      "4                                             Language Models are Few-Shot Learners                     Brown et al.  NeurIPS 2020                    GPT-3\n",
      "5                                      GPT-3: Language Models are Few-Shot Learners        Brown, Mann, Ryder et al.         arXiv               2005.14165\n",
      "6                              LLaMA: Open and Efficient Foundation Language Models                   Touvron et al.         arXiv               2302.13971\n",
      "7                               Llama 2: Open Foundation and Fine-Tuned Chat Models                   Touvron et al.         arXiv               2307.09288\n"
     ]
    }
   ],
   "source": [
    "from everyrow.ops import dedupe\n",
    "\n",
    "papers = DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"title\": \"Attention Is All You Need\",\n",
    "            \"authors\": \"Vaswani et al.\",\n",
    "            \"venue\": \"NeurIPS 2017\",\n",
    "            \"identifier\": \"10.5555/3295222.3295349\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Attention Is All You Need\",\n",
    "            \"authors\": \"Vaswani, Shazeer, Parmar et al.\",\n",
    "            \"venue\": \"arXiv\",\n",
    "            \"identifier\": \"1706.03762\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\n",
    "            \"authors\": \"Devlin et al.\",\n",
    "            \"venue\": \"NAACL 2019\",\n",
    "            \"identifier\": \"10.18653/v1/N19-1423\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"BERT: Pre-training of Deep Bidirectional Transformers\",\n",
    "            \"authors\": \"Devlin, Chang, Lee, Toutanova\",\n",
    "            \"venue\": \"arXiv\",\n",
    "            \"identifier\": \"1810.04805\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Language Models are Few-Shot Learners\",\n",
    "            \"authors\": \"Brown et al.\",\n",
    "            \"venue\": \"NeurIPS 2020\",\n",
    "            \"identifier\": \"GPT-3\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"GPT-3: Language Models are Few-Shot Learners\",\n",
    "            \"authors\": \"Brown, Mann, Ryder et al.\",\n",
    "            \"venue\": \"arXiv\",\n",
    "            \"identifier\": \"2005.14165\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"LLaMA: Open and Efficient Foundation Language Models\",\n",
    "            \"authors\": \"Touvron et al.\",\n",
    "            \"venue\": \"arXiv\",\n",
    "            \"identifier\": \"2302.13971\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Llama 2: Open Foundation and Fine-Tuned Chat Models\",\n",
    "            \"authors\": \"Touvron et al.\",\n",
    "            \"venue\": \"arXiv\",\n",
    "            \"identifier\": \"2307.09288\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Input papers ({len(papers)} rows):\")\n",
    "print(papers.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (95882388.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mequivalence_relation=dedent(\"\"\"\u001b[39m\n                                ^\n\u001b[31m_IncompleteInputError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "dedupe_result = await dedupe(\n",
    "    input=papers,\n",
    "    equivalence_relation=dedent(\"\"\"\n",
    "        Two entries are duplicates if they represent the same research work, which requires\n",
    "        verifying through research:\n",
    "\n",
    "        - An arXiv preprint and its published conference/journal version are duplicates\n",
    "        - Papers with slightly different titles but same core contribution are duplicates\n",
    "        - Different author list formats (et al. vs full list) don't matter\n",
    "        - Papers with different identifiers (arXiv ID vs DOI) may still be duplicates\n",
    "\n",
    "        However, genuinely different papers (e.g., LLaMA 1 vs LLaMA 2) are NOT duplicates,\n",
    "        even if authors and topics overlap. Research each paper to determine if they\n",
    "        report the same findings or are distinct works.\n",
    "    \"),\n",
    ")\n",
    "\n",
    "print(\"Deduplicated Paper List:\")\n",
    "print(dedupe_result.data.to_string())\n",
    "print(f\"\\nOriginal entries: {len(papers)}\")\n",
    "print(f\"Unique papers: {len(dedupe_result.data)}\")\n",
    "print(f\"Duplicates removed: {len(papers) - len(dedupe_result.data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge\n",
    "\n",
    "Join two tables when the keys don't match exactly. This example merges clinical trial data with pharmaceutical company information - the challenge is that trial sponsors are often subsidiaries or use abbreviated names (e.g., \"MSD\" instead of \"Merck\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from everyrow.ops import merge\n",
    "\n",
    "clinical_trials = DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"trial_id\": \"NCT05432109\",\n",
    "            \"sponsor\": \"Genentech\",\n",
    "            \"indication\": \"Non-small cell lung cancer\",\n",
    "            \"phase\": \"Phase 3\",\n",
    "        },\n",
    "        {\n",
    "            \"trial_id\": \"NCT05891234\",\n",
    "            \"sponsor\": \"Janssen Pharmaceuticals\",\n",
    "            \"indication\": \"Multiple myeloma\",\n",
    "            \"phase\": \"Phase 2\",\n",
    "        },\n",
    "        {\n",
    "            \"trial_id\": \"NCT05567890\",\n",
    "            \"sponsor\": \"MSD\",\n",
    "            \"indication\": \"Melanoma\",\n",
    "            \"phase\": \"Phase 3\",\n",
    "        },\n",
    "        {\n",
    "            \"trial_id\": \"NCT05234567\",\n",
    "            \"sponsor\": \"AbbVie Inc\",\n",
    "            \"indication\": \"Rheumatoid arthritis\",\n",
    "            \"phase\": \"Phase 3\",\n",
    "        },\n",
    "        {\n",
    "            \"trial_id\": \"NCT05678901\",\n",
    "            \"sponsor\": \"BMS\",\n",
    "            \"indication\": \"Acute myeloid leukemia\",\n",
    "            \"phase\": \"Phase 2\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "pharma_companies = DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"company\": \"Roche Holding AG\",\n",
    "            \"hq_country\": \"Switzerland\",\n",
    "            \"2024_revenue_billions\": 58.7,\n",
    "        },\n",
    "        {\n",
    "            \"company\": \"Johnson & Johnson\",\n",
    "            \"hq_country\": \"United States\",\n",
    "            \"2024_revenue_billions\": 85.2,\n",
    "        },\n",
    "        {\n",
    "            \"company\": \"Merck & Co.\",\n",
    "            \"hq_country\": \"United States\",\n",
    "            \"2024_revenue_billions\": 60.1,\n",
    "        },\n",
    "        {\n",
    "            \"company\": \"AbbVie\",\n",
    "            \"hq_country\": \"United States\",\n",
    "            \"2024_revenue_billions\": 56.3,\n",
    "        },\n",
    "        {\n",
    "            \"company\": \"Bristol-Myers Squibb\",\n",
    "            \"hq_country\": \"United States\",\n",
    "            \"2024_revenue_billions\": 45.0,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Clinical Trials:\")\n",
    "print(clinical_trials.to_string())\n",
    "print(\"\\nPharma Companies:\")\n",
    "print(pharma_companies.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_result = await merge(\n",
    "    task=dedent(\"\"\"\n",
    "        Merge clinical trial data with parent pharmaceutical company information.\n",
    "\n",
    "        The sponsor names in the trials table are often subsidiaries or abbreviations:\n",
    "        - Research which parent company owns each trial sponsor\n",
    "        - Match trials to their parent company's financial data\n",
    "\n",
    "        For example, Genentech is a subsidiary of Roche, Janssen is part of J&J,\n",
    "        MSD is Merck's name outside the US, BMS is Bristol-Myers Squibb.\n",
    "    \"\"\"),\n",
    "    left_table=clinical_trials,\n",
    "    right_table=pharma_companies,\n",
    "    merge_on_left=\"sponsor\",\n",
    "    merge_on_right=\"company\",\n",
    ")\n",
    "\n",
    "print(\"Clinical Trials with Parent Company Data:\")\n",
    "print(merge_result.data.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Derive\n",
    "\n",
    "Add computed columns using pandas expressions - no AI agents needed. This is useful for simple calculated fields before or after other operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from everyrow.ops import derive\n",
    "\n",
    "orders = DataFrame(\n",
    "    [\n",
    "        {\"product\": \"Widget\", \"price\": 10.00, \"quantity\": 5},\n",
    "        {\"product\": \"Gadget\", \"price\": 25.50, \"quantity\": 3},\n",
    "        {\"product\": \"Gizmo\", \"price\": 7.25, \"quantity\": 10},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Input data:\")\n",
    "print(orders.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derive_result = await derive(\n",
    "    input=orders,\n",
    "    expressions={\n",
    "        \"total\": \"price * quantity\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"With derived 'total' column:\")\n",
    "print(derive_result.data.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Single Agent\n",
    "\n",
    "Run web research on a single input. Agents can generate tabular data or answer questions based on research. This example first generates a competitor dataset, then analyzes it for market gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from everyrow.ops import single_agent\n",
    "\n",
    "\n",
    "class Competitor(BaseModel):\n",
    "    company: str = Field(description=\"Company name\")\n",
    "    pricing_tier: str = Field(description=\"Pricing model, e.g. 'Freemium, $10-50/user/mo'\")\n",
    "    target_market: str = Field(description=\"Primary customer segment\")\n",
    "    key_features: str = Field(description=\"Top 3 features or differentiators\")\n",
    "\n",
    "\n",
    "# Step 1: Generate a dataset of competitors\n",
    "print(\"Step 1: Research competitors\")\n",
    "competitors = await single_agent(\n",
    "    task=\"Find the top 10 competitors in the B2B expense management software market\",\n",
    "    response_model=Competitor,\n",
    "    return_table=True,\n",
    ")\n",
    "print(competitors.data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Distill insights from the dataset\n",
    "print(\"Step 2: Identify market gaps\")\n",
    "insights = await single_agent(\n",
    "    task=\"\"\"\n",
    "        What gaps exist in the B2B expense management software market\n",
    "        that these competitors aren't addressing?\n",
    "    \"\"\",\n",
    "    input=competitors,\n",
    ")\n",
    "print(insights.data.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Agent Map\n",
    "\n",
    "Run web research on every row of a dataframe. This example researches financial information for tech companies - information that requires looking up each company individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from everyrow.ops import agent_map\n",
    "\n",
    "\n",
    "class CompanyFinancials(BaseModel):\n",
    "    annual_revenue_usd: int = Field(description=\"Most recent annual revenue in USD\")\n",
    "    employee_count: int = Field(description=\"Current number of employees\")\n",
    "    founded_year: int = Field(description=\"Year the company was founded\")\n",
    "\n",
    "\n",
    "companies = DataFrame(\n",
    "    [\n",
    "        {\"company\": \"Stripe\", \"industry\": \"Payments\"},\n",
    "        {\"company\": \"Databricks\", \"industry\": \"Data & AI\"},\n",
    "        {\"company\": \"Canva\", \"industry\": \"Design\"},\n",
    "        {\"company\": \"Figma\", \"industry\": \"Design\"},\n",
    "        {\"company\": \"Notion\", \"industry\": \"Productivity\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Companies to research:\")\n",
    "print(companies.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic usage with default response\n",
    "basic_result = await agent_map(\n",
    "    task=\"Find the company's most recent annual revenue in USD\",\n",
    "    input=companies,\n",
    ")\n",
    "\n",
    "print(\"Basic Results:\")\n",
    "print(basic_result.data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured output with a response model\n",
    "structured_result = await agent_map(\n",
    "    task=dedent(\"\"\"\n",
    "        Research the company's financials. Find:\n",
    "        1. Their most recent annual revenue (in USD)\n",
    "        2. Current employee count\n",
    "        3. Year founded\n",
    "\n",
    "        If the company is a subsidiary, report figures for the subsidiary\n",
    "        specifically, not the parent company.\n",
    "    \"\"\"),\n",
    "    input=companies,\n",
    "    response_model=CompanyFinancials,\n",
    ")\n",
    "\n",
    "print(\"Structured Results:\")\n",
    "print(structured_result.data.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}