{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# everyrow.io/merge Tutorial\n",
    "\n",
    "This notebook demonstrates the [everyrow.io SDK](https://github.com/futuresearch/everyrow-sdk) merge capabilities:\n",
    "\n",
    "1. **Fuzzy String Matching** - Handling typos and corrupted data\n",
    "2. **LLM Merge** - Matching without common columns (company ↔ ticker)\n",
    "3. **Web Merge** - Dynamic data requiring real-time verification (CEO matching)\n",
    "\n",
    "The SDK implements a cascade: **Exact → Fuzzy → LLM → Web**, using the simplest method that works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the SDK and set your API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install everyrow\n",
    "%env EVERYROW_API_KEY=your_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T05:25:18.713644Z",
     "start_time": "2026-01-17T05:25:18.362936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 438 companies, 7 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "      <th>fair_value</th>\n",
       "      <th>price</th>\n",
       "      <th>mkt_cap</th>\n",
       "      <th>shares</th>\n",
       "      <th>CEO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3M</td>\n",
       "      <td>MMM</td>\n",
       "      <td>39.18</td>\n",
       "      <td>101.74</td>\n",
       "      <td>61.70678828</td>\n",
       "      <td>606514530</td>\n",
       "      <td>William M. Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>AOS</td>\n",
       "      <td>6.59</td>\n",
       "      <td>32.38</td>\n",
       "      <td>4.904416495</td>\n",
       "      <td>151464376</td>\n",
       "      <td>Stephen Shafer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>ABT</td>\n",
       "      <td>119.19</td>\n",
       "      <td>34.87</td>\n",
       "      <td>51.22933139</td>\n",
       "      <td>1469152033</td>\n",
       "      <td>Robert B. Ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AbbVie</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>180.95</td>\n",
       "      <td>38.06</td>\n",
       "      <td>61.55666858</td>\n",
       "      <td>1617358607</td>\n",
       "      <td>Robert A. Michael</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>ACN</td>\n",
       "      <td>107.79</td>\n",
       "      <td>97.84</td>\n",
       "      <td>79.53540176</td>\n",
       "      <td>812912937</td>\n",
       "      <td>Julie Sweet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               company ticker  fair_value   price      mkt_cap      shares  \\\n",
       "0                   3M    MMM       39.18  101.74  61.70678828   606514530   \n",
       "1          A. O. Smith    AOS        6.59   32.38  4.904416495   151464376   \n",
       "2  Abbott Laboratories    ABT      119.19   34.87  51.22933139  1469152033   \n",
       "3               AbbVie   ABBV      180.95   38.06  61.55666858  1617358607   \n",
       "4            Accenture    ACN      107.79   97.84  79.53540176   812912937   \n",
       "\n",
       "                 CEO  \n",
       "0   William M. Brown  \n",
       "1     Stephen Shafer  \n",
       "2     Robert B. Ford  \n",
       "3  Robert A. Michael  \n",
       "4        Julie Sweet  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "from everyrow import create_session\n",
    "from everyrow.ops import merge\n",
    "from everyrow.generated.models import LLMEnum\n",
    "\n",
    "# Load dataset: 438 S&P 500 companies\n",
    "data = pd.read_csv(\"../data/companies.csv\")\n",
    "print(f\"Dataset: {data.shape[0]} companies, {data.shape[1]} columns\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Fuzzy String Matching Under Noise\n",
    "\n",
    "We corrupt company names with increasing noise levels to test the merge cascade.\n",
    "\n",
    "**Setup:**\n",
    "- Left table: all columns except `fair_value`\n",
    "- Right table: `company` (corrupted) + `fair_value`\n",
    "- Merge on company name columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a function that adds noise to a string column of a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T05:25:27.420514Z",
     "start_time": "2026-01-17T05:25:27.417704Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def randomize_string_column(df: DataFrame, column_name: str, p: float = 0.1) -> DataFrame:\n",
    "    def randomize_string(text):\n",
    "        if pd.isna(text) or not isinstance(text, str):\n",
    "            return text\n",
    "        return ''.join([random.choice(string.ascii_letters + '') if random.random() < p else char for char in text])\n",
    "    df_copy: DataFrame = df.copy()\n",
    "    df_copy[column_name] = df_copy[column_name].apply(randomize_string)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1a: 0% Noise (Baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we pick the right columns from the groun truth, apply the noise, and call the everyrow.io SDK to perform the merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tables\n",
    "left_table = data.drop(columns=[\"fair_value\"])\n",
    "right_table = data[[\"company\", \"fair_value\"]].copy()  # No noise\n",
    "\n",
    "async with create_session(name=\"Fuzzy Match p=0\") as session:\n",
    "    print(f\"Session: {session.get_url()}\")\n",
    "    result = await merge(\n",
    "        session=session,\n",
    "        task=\"Merge the tables on company name\",\n",
    "        left_table=left_table,\n",
    "        right_table=right_table,\n",
    "        merge_on_left=\"company\",\n",
    "        merge_on_right=\"company\",\n",
    "    )\n",
    "result.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results (0% Noise):**\n",
    "\n",
    "| Matched | Exact | Fuzzy | LLM | Web | Accuracy | False Pos | Price |\n",
    "|---------|-------|-------|-----|-----|----------|-----------|-------|\n",
    "| 100%    | 100%  | 0%    | 0%  | 0%  | 100%     | 0%        | $0.13 |\n",
    "\n",
    "[View session](https://everyrow.io/sessions/b2ae2e9b-c2d6-476d-a970-975163c79309/public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1b: 5% Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_table = data.drop(columns=[\"fair_value\"])\n",
    "right_table = randomize_string_column(data[[\"company\", \"fair_value\"]].copy(), \"company\", p=0.05)\n",
    "\n",
    "async with create_session(name=\"Fuzzy Match p=0.05\") as session:\n",
    "    print(f\"Session: {session.get_url()}\")\n",
    "    result = await merge(\n",
    "        session=session,\n",
    "        task=\"Merge the tables on company name\",\n",
    "        left_table=left_table,\n",
    "        right_table=right_table,\n",
    "        merge_on_left=\"company\",\n",
    "        merge_on_right=\"company\",\n",
    "    )\n",
    "result.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results (5% Noise):**\n",
    "\n",
    "| Matched | Exact | Fuzzy | LLM   | Web | Accuracy | False Pos | Price |\n",
    "|---------|-------|-------|-------|-----|----------|-----------|-------|\n",
    "| 100%    | 49.8% | 30.6% | 19.6% | 0%  | 100%     | 0%        | $0.32 |\n",
    "\n",
    "[View session](https://everyrow.io/sessions/fcbde005-9505-4310-b523-4aa88d9bd7b7/public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1c: 10% Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_table = data.drop(columns=[\"fair_value\"])\n",
    "right_table = randomize_string_column(data[[\"company\", \"fair_value\"]].copy(), \"company\", p=0.1)\n",
    "\n",
    "async with create_session(name=\"Fuzzy Match p=0.1\") as session:\n",
    "    print(f\"Session: {session.get_url()}\")\n",
    "    result = await merge(\n",
    "        session=session,\n",
    "        task=\"Merge the tables on company name\",\n",
    "        left_table=left_table,\n",
    "        right_table=right_table,\n",
    "        merge_on_left=\"company\",\n",
    "        merge_on_right=\"company\",\n",
    "    )\n",
    "result.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results (10% Noise):**\n",
    "\n",
    "| Matched | Exact | Fuzzy | LLM   | Web | Accuracy | False Pos | Price |\n",
    "|---------|-------|-------|-------|-----|----------|-----------|-------|\n",
    "| 100%    | 26.5% | 30.8% | 42.7% | 0%  | 100%     | 0%        | $0.44 |\n",
    "\n",
    "At 10% corruption, exact matching handles only 27% of rows. The cascade escalates to LLM matching for 43%.\n",
    "\n",
    "[View session](https://everyrow.io/sessions/65df5d45-7816-42c9-b737-f973dab51ca2/public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: LLM Merge for Semantic Relationships\n",
    "\n",
    "Matching tables with **no common columns** — the LLM must use world knowledge to match company names to tickers.\n",
    "\n",
    "**Setup:**\n",
    "- Left table: company info (no ticker)\n",
    "- Right table: ticker + fair_value only\n",
    "- No merge columns specified → skips string matching, goes straight to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_table = data.drop(columns=[\"ticker\", \"fair_value\"])\n",
    "right_table = data[[\"ticker\", \"fair_value\"]]\n",
    "\n",
    "async with create_session(name=\"LLM Match (company to ticker)\") as session:\n",
    "    print(f\"Session: {session.get_url()}\")\n",
    "    result = await merge(\n",
    "        session=session,\n",
    "        task=\"Merge the tables based on company name and ticker\",\n",
    "        left_table=left_table,\n",
    "        right_table=right_table,\n",
    "        # No merge columns → LLM matching\n",
    "    )\n",
    "result.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "\n",
    "| Matched | Exact | Fuzzy | LLM   | Web  | Accuracy | False Pos | Price |\n",
    "|---------|-------|-------|-------|------|----------|-----------|-------|\n",
    "| 100%    | 0%    | 0%    | 99.8% | 0.2% | 100%     | 0%        | $1.00 |\n",
    "\n",
    "437/438 rows matched via pure LLM reasoning. Company-ticker mappings are stable and well-learned.\n",
    "\n",
    "[View session](https://everyrow.io/sessions/ada2895f-fc6d-47fc-b3c4-6a826f3a676f/public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Web Merge for Dynamic Data\n",
    "\n",
    "CEO information changes frequently — LLM training data becomes stale. Web verification is needed.\n",
    "\n",
    "**Setup:**\n",
    "- Left table: company info (no CEO)\n",
    "- Right table: CEO names only\n",
    "- Task instructs to use web search if unsure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_table = data.drop(columns=[\"CEO\"])\n",
    "right_table = data[[\"CEO\"]]\n",
    "\n",
    "async with create_session(name=\"Web Match (CEO)\") as session:\n",
    "    print(f\"Session: {session.get_url()}\")\n",
    "    result = await merge(\n",
    "        session=session,\n",
    "        task=\"Merge the CEO to the company information, use web search if unsure\",\n",
    "        left_table=left_table,\n",
    "        right_table=right_table,\n",
    "    )\n",
    "result.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "\n",
    "| Matched | LLM   | Web   | Accuracy | False Pos | Cost  |\n",
    "|---------|-------|-------|----------|-----------|-------|\n",
    "| 95.7%   | 59.8% | 35.8% | 96.7%    | 3.2%      | $3.69 |\n",
    "\n",
    "CEO matching requires web verification since leadership changes frequently.\n",
    "\n",
    "[View session](https://cohort.futuresearch.ai/sessions/16ecedfc-8187-4eb5-aa67-fc2bab48e876/public)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
