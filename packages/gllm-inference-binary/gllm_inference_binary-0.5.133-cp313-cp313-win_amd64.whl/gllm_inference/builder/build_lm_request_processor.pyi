from _typeshed import Incomplete
from gllm_inference.builder.build_lm_invoker import build_lm_invoker as build_lm_invoker
from gllm_inference.builder.build_output_parser import build_output_parser as build_output_parser
from gllm_inference.prompt_builder import PromptBuilder as PromptBuilder
from gllm_inference.request_processor.lm_request_processor import LMRequestProcessor as LMRequestProcessor
from gllm_inference.schema.model_id import ModelId as ModelId
from typing import Any

logger: Incomplete

def build_lm_request_processor(model_id: str | ModelId, credentials: str | dict[str, Any] | None = None, config: dict[str, Any] | None = None, system_template: str = '', user_template: str = '', key_defaults: dict[str, Any] | None = None, prompt_builder_kwargs: dict[str, Any] | None = None, output_parser_type: str = 'none') -> LMRequestProcessor:
    '''Build a language model invoker based on the provided configurations.

    Args:
        model_id (str | ModelId): The model id, can either be a ModelId instance or a string in a format defined
            in the following page: https://gdplabs.gitbook.io/sdk/resources/supported-models#language-models-lms
        credentials (str | dict[str, Any] | None, optional): The credentials for the language model. Can either be:
            1. An API key.
            2. A path to a credentials JSON file, currently only supported for Google Vertex AI.
            3. A dictionary of credentials, currently supported for Bedrock and LangChain.
            Defaults to None, in which case the credentials will be loaded from the appropriate environment variables.
        config (dict[str, Any] | None, optional): Additional configuration for the language model. Defaults to None.
        system_template (str): The system prompt template. May contain placeholders enclosed in curly braces `{}`.
            Defaults to an empty string.
        user_template (str): The user prompt template. May contain placeholders enclosed in curly braces `{}`.
            Defaults to an empty string.
        key_defaults (dict[str, Any] | None, optional): Default values for the keys in the prompt templates.
            Applied when the corresponding keys are not provided in the runtime input.
            Defaults to None.
        prompt_builder_kwargs (dict[str, Any] | None, optional): Additional keyword arguments for PromptBuilder.
            Defaults to None.
        output_parser_type (str, optional): The type of output parser to use. Supports "json" and "none".
            Defaults to "none".


    Returns:
        LMRequestProcessor: The initialized language model request processor.

    Raises:
        ValueError: If the provided configuration is invalid.

    Usage examples:
        ```python
        # Basic usage
        lm_request_processor = build_lm_request_processor(
            model_id="openai/gpt-4o-mini",
            credentials="sk-...",
            user_template="{query}",
        )
        ```

        # With custom LM invoker configuration
        ```python
        config = {
            "default_hyperparameters": {"temperature": 0.5},
            "tools": [tool_1, tool_2],
        }

        lm_request_processor = build_lm_request_processor(
            model_id="openai/gpt-4o-mini",
            credentials="sk-...",
            config=config,
            user_template="{query}",
        )
        ```

        # With custom prompt builder configuration
        ```python
        lm_request_processor = build_lm_request_processor(
            model_id="openai/gpt-4o-mini",
            credentials="sk-...",
            system_template="Talk like a {role}.",
            user_template="{query}",
            prompt_builder_kwargs={
                "key_defaults": {"role": "pirate"},
                "use_jinja": True,
                "jinja_env": "restricted",
            },
        )
        ```

        # With output parser
        ```python
        lm_request_processor = build_lm_request_processor(
            model_id="openai/gpt-4o-mini",
            credentials="sk-...",
            user_template="{query}",
            output_parser_type="json",
        )
        ```

    Security warning:
        Please provide the LM invoker credentials ONLY to the `credentials` parameter. Do not put any kind of
        credentials in the `config` parameter as the content of the `config` parameter will be logged.
    '''
