{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModSSC | Views\n",
    "\n",
    "Build and inspect multi view representations used by some SSL methods.\n",
    "\n",
    "## Objective\n",
    "- Show the minimal steps to run this component in a notebook setting.\n",
    "- Provide the exact objects to look at (outputs, shapes, metrics) to confirm it worked.\n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.11+.\n",
    "- `pip install modssc`.\n",
    "- Optional dependencies depend on datasets and backends. If an import fails, install the matching extra and rerun.\n",
    "\n",
    "## Outline\n",
    "1) Imports and configuration\n",
    "2) Core run (the part that does the work)\n",
    "3) Sanity checks and outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook notes\n",
    "\n",
    "This notebook demonstrates **feature view generation** with `modssc.views`.\n",
    "\n",
    "A *view* is a 2D feature matrix derived from the same dataset, typically used by classic multi-view SSL methods such as **Co-Training**.\n",
    "\n",
    "> Augmentation-based multi-view training (weak/strong augmentation) belongs to `modssc.data_augmentation`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configuration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7711f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modssc.data_loader import load_dataset\n",
    "from modssc.preprocess.plan import PreprocessPlan, StepConfig\n",
    "from modssc.views import generate_views, two_view_random_feature_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00003a4a",
   "metadata": {},
   "source": [
    "## 1) Load a dataset\n",
    "\n",
    "We'll use the built-in deterministic **toy** dataset so the notebook runs fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfbbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"toy\")\n",
    "print(ds.train.X.shape, ds.test.X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f10682a",
   "metadata": {},
   "source": [
    "## 2) Define a preprocessing plan (optional)\n",
    "\n",
    "We ensure features are 2D and cast to float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cdc60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = PreprocessPlan(\n",
    "    steps=(\n",
    "        StepConfig(step_id=\"core.ensure_2d\"),\n",
    "        StepConfig(step_id=\"core.cast_dtype\", params={\"dtype\": \"float32\"}),\n",
    "    ),\n",
    "    output_key=\"features.X\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ed99f",
   "metadata": {},
   "source": [
    "## 3) Build a 2-view random feature split plan\n",
    "\n",
    "- View A selects a random subset of columns.\n",
    "- View B is the complement of View A.\n",
    "\n",
    "This is a common setup for classic Co-Training when no natural multi-view feature sets exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = two_view_random_feature_split(preprocess=pre, fraction=0.5)\n",
    "plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d047d",
   "metadata": {},
   "source": [
    "## 4) Generate the views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad45a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = generate_views(ds, plan=plan, seed=0, cache=True)\n",
    "res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9097819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_a = res.views[\"view_a\"]\n",
    "ds_b = res.views[\"view_b\"]\n",
    "\n",
    "print(\"A train:\", ds_a.train.X.shape, \"test:\", ds_a.test.X.shape)\n",
    "print(\"B train:\", ds_b.train.X.shape, \"test:\", ds_b.test.X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c02abad",
   "metadata": {},
   "source": [
    "## 5) Integration idea (Co-Training)\n",
    "\n",
    "A Co-Training implementation can consume the two view datasets:\n",
    "\n",
    "- `ds_a.train.X`, `ds_a.train.y`\n",
    "- `ds_b.train.X`, `ds_b.train.y`\n",
    "\n",
    "The algorithm can train two classifiers (one per view), and exchange pseudo-labeled samples between them.\n",
    "\n",
    "> The exact Co-Training loop depends on the paper/variant, so the view brick intentionally stays independent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "\n",
    "- The last cells should print key shapes and a minimal metric or artifact summary.\n",
    "- If something fails early, the error should point to a missing optional dependency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Explore the adjacent notebooks in this folder for the other pipeline components.\n",
    "- If you hit an optional dependency error, install the suggested extra and rerun.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
