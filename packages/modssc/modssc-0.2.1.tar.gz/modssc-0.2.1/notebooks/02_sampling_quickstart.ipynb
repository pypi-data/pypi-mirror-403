{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModSSC | Sampling\n",
    "\n",
    "Create and validate semi supervised splits (labeled, unlabeled, val, test).\n",
    "\n",
    "## Objective\n",
    "- Show the minimal steps to run this component in a notebook setting.\n",
    "- Provide the exact objects to look at (outputs, shapes, metrics) to confirm it worked.\n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.11+.\n",
    "- `pip install modssc`.\n",
    "- Optional dependencies depend on datasets and backends. If an import fails, install the matching extra and rerun.\n",
    "\n",
    "## Outline\n",
    "1) Imports and configuration\n",
    "2) Core run (the part that does the work)\n",
    "3) Sanity checks and outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook notes\n",
    "\n",
    "This notebook demonstrates how to use ModSSC's sampling capabilities to create reproducible data splits (train/val/test) and label sets.\n",
    "\n",
    "## Installation\n",
    "\n",
    "Base install:\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "## Load dataset\n",
    "\n",
    "First, we load a dataset. We need its fingerprint to ensure reproducibility of the sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configuration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modssc.data_loader import load_dataset\n",
    "\n",
    "ds = load_dataset(\"toy\", download=True)\n",
    "ds_fp = ds.meta.get(\"dataset_fingerprint\")\n",
    "ds_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## Holdout + labeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modssc.sampling import HoldoutSplitSpec, LabelingSpec, SamplingPlan, sample\n",
    "\n",
    "# Define a Sampling Plan\n",
    "# 1. Split: How to divide the data (Holdout, K-Fold, etc.)\n",
    "# 2. Labeling: How many labels to reveal (Active Learning / Semi-Supervised setting)\n",
    "plan = SamplingPlan(\n",
    "    split=HoldoutSplitSpec(test_fraction=0.3, val_fraction=0.1, stratify=True),\n",
    "    labeling=LabelingSpec(mode=\"fraction\", value=0.1, per_class=True, min_per_class=1),\n",
    ")\n",
    "\n",
    "# Run the sampling\n",
    "# - dataset_fingerprint: Ensures we are sampling the exact same data version\n",
    "# - save=True: Saves the result to disk for later use\n",
    "# - overwrite=True: Re-runs sampling even if the file exists (useful for notebooks)\n",
    "result, path = sample(ds, plan=plan, seed=0, dataset_fingerprint=ds_fp, save=True, overwrite=True)\n",
    "\n",
    "print(\"Split Fingerprint:\", result.split_fingerprint)\n",
    "print(\"Saved to:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787e9837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_class_dist(y, idx, name=\"subset\"):\n",
    "    \"\"\"Helper to print class distribution of a subset.\"\"\"\n",
    "    if idx is None or len(idx) == 0:\n",
    "        print(f\"{name}: empty\")\n",
    "        return\n",
    "    classes, counts = np.unique(y[idx], return_counts=True)\n",
    "    dist = dict(zip(classes, counts, strict=True))\n",
    "    print(f\"{name} distribution: {dist} (total={len(idx)})\")\n",
    "\n",
    "\n",
    "# Inspect the resulting indices\n",
    "# The result object provides .train_idx, .val_idx, .test_idx, .labeled_idx\n",
    "print_class_dist(ds.train.y, result.train_idx, \"Train\")\n",
    "print_class_dist(ds.train.y, result.val_idx, \"Val\")\n",
    "print_class_dist(ds.train.y, result.test_idx, \"Test\")\n",
    "print_class_dist(ds.train.y, result.labeled_idx, \"Labeled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d57a14",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation\n",
    "\n",
    "We can also use K-Fold splitting. Note that `val_fraction` can still be used within each fold's training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d63b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modssc.sampling import KFoldSplitSpec\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "# We specify k=5 and fold=0 (the first fold)\n",
    "# Note: val_fraction is applied *within* the training portion of the fold\n",
    "k_plan = SamplingPlan(\n",
    "    split=KFoldSplitSpec(k=5, fold=0, stratify=True, val_fraction=0.1),\n",
    "    labeling=LabelingSpec(mode=\"fraction\", value=1.0),  # Use all train data as labeled\n",
    ")\n",
    "\n",
    "k_res, _ = sample(ds, plan=k_plan, seed=0, dataset_fingerprint=ds_fp)\n",
    "print(\"Fold 0 stats:\", k_res.stats)\n",
    "print_class_dist(ds.train.y, k_res.test_idx, \"Fold 0 Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2434e0b",
   "metadata": {},
   "source": [
    "## Imbalance Simulation\n",
    "\n",
    "We can simulate class imbalance (e.g. Long Tail) or subsample classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5649eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modssc.sampling import ImbalanceSpec\n",
    "\n",
    "# Imbalance Simulation\n",
    "# We can simulate a \"long_tail\" distribution on the training set.\n",
    "imb_plan = SamplingPlan(\n",
    "    split=HoldoutSplitSpec(test_fraction=0.2),\n",
    "    labeling=LabelingSpec(mode=\"fraction\", value=1.0),\n",
    "    imbalance=ImbalanceSpec(kind=\"long_tail\", alpha=0.5, min_per_class=1, apply_to=\"train\"),\n",
    ")\n",
    "\n",
    "imb_res, _ = sample(ds, plan=imb_plan, seed=0, dataset_fingerprint=ds_fp)\n",
    "print(\"Imbalance stats:\", imb_res.stats)\n",
    "print_class_dist(ds.train.y, imb_res.train_idx, \"Imbalanced Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "source": [
    "## Load split from disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modssc.sampling import load_split\n",
    "\n",
    "loaded = load_split(path)\n",
    "loaded.split_fingerprint == result.split_fingerprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fbc9d89aee49ed8cba700edbd1c200",
   "metadata": {},
   "source": [
    "## CLI\n",
    "\n",
    "This mirrors the Python API above using the `modssc sampling` subcommand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9524472154127bcd456690ad6b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "def run_cli(*args):\n",
    "    cmd = [sys.executable, \"-m\", \"modssc\", *args]\n",
    "    res = subprocess.run(cmd, text=True, capture_output=True)\n",
    "    return res.returncode, res.stdout.strip(), res.stderr.strip()\n",
    "\n",
    "\n",
    "print(run_cli(\"sampling\", \"show\", str(path)))\n",
    "print(run_cli(\"sampling\", \"validate\", str(path), \"--dataset\", \"toy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "source": [
    "## Graph example (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modssc.data_loader.errors import OptionalDependencyError\n",
    "from modssc.sampling.plan import HoldoutSplitSpec, LabelingSpec, SamplingPlan\n",
    "\n",
    "# Graph Sampling Example\n",
    "# For graphs, we often use transductive splitting (masks on nodes) rather than inductive splitting (indices).\n",
    "# ModSSC handles this unifiedly.\n",
    "\n",
    "try:\n",
    "    gds = load_dataset(\"cora\", download=True)\n",
    "    gfp = gds.meta.get(\"dataset_fingerprint\")\n",
    "\n",
    "    gplan = SamplingPlan(\n",
    "        split=HoldoutSplitSpec(test_fraction=0.0, val_fraction=0.0, stratify=False),\n",
    "        labeling=LabelingSpec(mode=\"per_class\", value=20, min_per_class=1),\n",
    "    )\n",
    "\n",
    "    # overwrite=True allows re-running\n",
    "    gres, gpath = sample(\n",
    "        gds, plan=gplan, seed=0, dataset_fingerprint=gfp, save=True, overwrite=True\n",
    "    )\n",
    "    print(\"graph split:\", gres.stats)\n",
    "\n",
    "except OptionalDependencyError as e:\n",
    "    print(\"SKIP graph, missing extra:\", e.extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "\n",
    "- The last cells should print key shapes and a minimal metric or artifact summary.\n",
    "- If something fails early, the error should point to a missing optional dependency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Explore the adjacent notebooks in this folder for the other pipeline components.\n",
    "- If you hit an optional dependency error, install the suggested extra and rerun.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
