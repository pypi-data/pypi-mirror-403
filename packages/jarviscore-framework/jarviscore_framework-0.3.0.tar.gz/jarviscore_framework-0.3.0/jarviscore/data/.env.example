# =============================================================================
# JARVISCORE FRAMEWORK CONFIGURATION
# =============================================================================
# Copy this file to .env and fill in your values
# All settings are optional - framework provides sensible defaults
# Standard environment variable names (no JARVISCORE_ prefix)

# =============================================================================
# LLM CONFIGURATION (Zero-Config with Automatic Fallback)
# =============================================================================
# Framework tries providers in order: Claude → vLLM → Azure → Gemini
# At least ONE provider must be configured for AutoAgent to work

# --- Anthropic Claude ---
# Standard: CLAUDE_API_KEY or ANTHROPIC_API_KEY
# CLAUDE_API_KEY=your-anthropic-api-key
# CLAUDE_ENDPOINT=https://api.anthropic.com  # Optional: custom endpoint
# CLAUDE_MODEL=claude-sonnet-4

# --- vLLM (Local/Self-Hosted) ---
# Recommended for development and cost-effective production
# LLM_ENDPOINT=http://localhost:8000
# LLM_MODEL=Qwen/Qwen2.5-Coder-32B-Instruct

# --- Azure OpenAI ---
# Standard: AZURE_API_KEY or AZURE_OPENAI_KEY
# AZURE_API_KEY=your-azure-openai-key
# AZURE_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_DEPLOYMENT=gpt-4o
# AZURE_API_VERSION=2024-02-15-preview

# --- Google Gemini ---
# GEMINI_API_KEY=your-gemini-api-key
# GEMINI_MODEL=gemini-1.5-flash
# GEMINI_TEMPERATURE=0.1
# GEMINI_TIMEOUT=30.0

# Common LLM Settings
# LLM_TIMEOUT=120.0
# LLM_TEMPERATURE=0.7

# =============================================================================
# EXECUTION SETTINGS
# =============================================================================
# Sandbox execution and code generation limits

# Maximum execution time for generated code (seconds)
EXECUTION_TIMEOUT=300

# Maximum number of autonomous repair attempts
MAX_REPAIR_ATTEMPTS=3

# Maximum retries for failed operations
MAX_RETRIES=3

# =============================================================================
# SANDBOX CONFIGURATION (Phase 2)
# =============================================================================
# Sandbox execution mode: "local" (in-process) or "remote" (service)
# Default: local (for development)
# Production: remote (uses JarvisCore's Azure Container Apps sandbox)
SANDBOX_MODE=local

# Remote sandbox service URL (provided by JarvisCore)
# Azure Container Apps sandbox service - no setup required!
# Uncomment and set SANDBOX_MODE=remote to use it
# SANDBOX_SERVICE_URL=https://browser-task-executor.bravesea-3f5f7e75.eastus.azurecontainerapps.io

# =============================================================================
# STORAGE CONFIGURATION (Phase 1)
# =============================================================================
# Directory for result storage and code registry
LOG_DIRECTORY=./logs

# =============================================================================
# P2P CONFIGURATION (For Distributed Mode)
# =============================================================================
# Required only if using mesh in distributed mode
# Autonomous mode works without P2P

# Enable P2P mesh networking
P2P_ENABLED=true

# Node identification
NODE_NAME=jarviscore-node-1

# Bind address and port for P2P communication
BIND_HOST=127.0.0.1
BIND_PORT=7946

# Seed nodes to join existing mesh (comma-separated)
# Example: 192.168.1.100:7946,192.168.1.101:7946
# SEED_NODES=

# ZeroMQ port offset (P2P messaging)
ZMQ_PORT_OFFSET=1000

# Transport type: udp, tcp, or hybrid
TRANSPORT_TYPE=hybrid

# =============================================================================
# KEEPALIVE SETTINGS (P2P Health Monitoring)
# =============================================================================

# Enable smart keepalive (suppresses when active)
KEEPALIVE_ENABLED=true

# Keepalive interval (seconds)
KEEPALIVE_INTERVAL=90

# Keepalive timeout (seconds)
KEEPALIVE_TIMEOUT=10

# Activity suppression window (seconds)
# If agent is actively working, suppress keepalive for this duration
ACTIVITY_SUPPRESS_WINDOW=60

# =============================================================================
# LOGGING
# =============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# =============================================================================
# EXAMPLES
# =============================================================================

# Example 1: Local development with vLLM
# LLM_ENDPOINT=http://localhost:8000
# LLM_MODEL=Qwen/Qwen2.5-Coder-32B-Instruct
# P2P_ENABLED=false

# Example 2: Production with Azure OpenAI + P2P mesh
# AZURE_API_KEY=sk-...
# AZURE_ENDPOINT=https://my-resource.openai.azure.com
# AZURE_DEPLOYMENT=gpt-4o
# P2P_ENABLED=true
# BIND_HOST=0.0.0.0
# BIND_PORT=7946
# SEED_NODES=192.168.1.100:7946

# Example 3: Zero-config (use defaults)
# Just don't set any variables and framework will:
# - Try to detect available LLM providers
# - Use sensible defaults for all settings
# - Work in autonomous mode (no P2P)
