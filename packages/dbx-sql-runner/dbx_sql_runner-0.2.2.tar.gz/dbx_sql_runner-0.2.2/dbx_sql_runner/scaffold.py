import os
import logging

logger = logging.getLogger(__name__)

PROFILES_YML_TEMPLATE = """
target: dev

outputs:
  dev:
    server_hostname: "dbc-xxxxxxxx-xxxx.cloud.databricks.com"
    http_path: "/sql/1.0/warehouses/xxxxxxxxxxxxxxxx"
    access_token: "${DBX_TOKEN_DEV}"
    catalog: "my_catalog_dev"
    schema: "my_schema_dev"
    sources:
      my_source: "prod_catalog.schema.table"
    # alert_webhook_url: "https://your.webhook.url"

  prod:
    server_hostname: "dbc-xxxxxxxx-xxxx.cloud.databricks.com"
    http_path: "/sql/1.0/warehouses/xxxxxxxxxxxxxxxx"
    access_token: "${DBX_TOKEN_PROD}"
    catalog: "my_catalog_prod"
    schema: "my_schema_prod"
    # alert_webhook_url: "https://your.webhook.url"
""".strip()

EXAMPLE_SQL_TEMPLATE = """
-- name: my_first_model
-- materialized: table
-- partition_by: date

/*
    Welcome to your first dbx-sql-runner model!
    
    This is where you define your SQL logic.
    You can refer to other models like this: {upstream_model_name}
    Or refer to sources defined in profiles.yml like this: {my_source}
*/

SELECT 
    1 as id, 
    current_date() as date, 
    'Hello World' as message
""".strip()

GITIGNORE_TEMPLATE = """
# python
__pycache__/
*.py[cod]
*$py.class
venv/
.venv/

# dbx-sql-runner
profiles.yml
""".strip()

README_TEMPLATE = """
# {project_name}

This project was generated by `dbx-sql-runner init`.

## Getting Started

1.  **Configure Credentials**:
    Edit `profiles.yml` with your Databricks credentials.

2.  **Run Models**:
    ```bash
    dbx-sql-runner run
    ```
""".strip()

LINTER_CONFIG_TEMPLATE = """
# Configuration for dbx-sql-runner linter
# You can customize the regex patterns and error messages here.
rules:
  model_name:
    pattern: "^[a-z0-9_]+$"
    message: "Model names must be snake_case (lowercase, numbers, underscores)"
  source_name:
    pattern: "^[a-z0-9_]+$"
    message: "Source names must be snake_case (lowercase, numbers, underscores)"
  column_name:
    pattern: "^[a-z0-9_]+$"
    message: "Column names must be snake_case (lowercase, numbers, underscores)"
""".strip()

def create_file(path, content):
    with open(path, "w") as f:
        f.write(content)
    logger.info(f"Created {path}")

def init_project(project_name="."):
    """
    Initializes a new dbx-sql-runner project.
    
    Args:
        project_name (str): The name of the directory to create. 
                            If ".", initializes in current directory.
    """
    base_dir = os.path.abspath(project_name)
    
    if project_name != "." and not os.path.exists(base_dir):
        os.makedirs(base_dir)
        logger.info(f"Created directory {base_dir}")
    
    models_dir = os.path.join(base_dir, "models")
    if not os.path.exists(models_dir):
        os.makedirs(models_dir)
        logger.info(f"Created directory {models_dir}")

    # Create files
    create_file(os.path.join(base_dir, "profiles.yml"), PROFILES_YML_TEMPLATE)
    create_file(os.path.join(base_dir, ".gitignore"), GITIGNORE_TEMPLATE)
    create_file(os.path.join(base_dir, "lint.yml"), LINTER_CONFIG_TEMPLATE)
    create_file(os.path.join(models_dir, "example.sql"), EXAMPLE_SQL_TEMPLATE)
    
    # Only create README if we are creating a new folder, or if it doesn't exist
    readme_path = os.path.join(base_dir, "README.md")
    if not os.path.exists(readme_path):
        name = os.path.basename(base_dir)
        if name == "." or not name:
            name = "My Project"
        create_file(readme_path, README_TEMPLATE.format(project_name=name))

    logger.info(f"\nProject initialized successfully in {base_dir}!")
    logger.info("Next steps:")
    logger.info("1. Edit 'profiles.yml' with your Databricks credentials.")
    logger.info("2. Run 'dbx-sql-runner run' to execute your models.")
