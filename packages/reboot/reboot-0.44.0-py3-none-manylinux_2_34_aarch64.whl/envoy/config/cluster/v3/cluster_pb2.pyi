"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""

import builtins
import collections.abc
import envoy.config.cluster.v3.circuit_breaker_pb2
import envoy.config.cluster.v3.filter_pb2
import envoy.config.cluster.v3.outlier_detection_pb2
import envoy.config.core.v3.address_pb2
import envoy.config.core.v3.base_pb2
import envoy.config.core.v3.config_source_pb2
import envoy.config.core.v3.extension_pb2
import envoy.config.core.v3.health_check_pb2
import envoy.config.core.v3.protocol_pb2
import envoy.config.core.v3.resolver_pb2
import envoy.config.endpoint.v3.endpoint_pb2
import envoy.type.v3.percent_pb2
import google.protobuf.any_pb2
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.struct_pb2
import google.protobuf.wrappers_pb2
import sys
import typing
import xds.core.v3.collection_entry_pb2

if sys.version_info >= (3, 10):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

@typing.final
class ClusterCollection(google.protobuf.message.Message):
    """[#protodoc-title: Cluster configuration]

    Cluster list collections. Entries are ``Cluster`` resources or references.
    [#not-implemented-hide:]
    """

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    ENTRIES_FIELD_NUMBER: builtins.int
    @property
    def entries(self) -> xds.core.v3.collection_entry_pb2.CollectionEntry: ...
    def __init__(
        self,
        *,
        entries: xds.core.v3.collection_entry_pb2.CollectionEntry | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["entries", b"entries"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["entries", b"entries"]) -> None: ...

global___ClusterCollection = ClusterCollection

@typing.final
class Cluster(google.protobuf.message.Message):
    """Configuration for a single upstream cluster.
    [#next-free-field: 57]
    """

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    class _DiscoveryType:
        ValueType = typing.NewType("ValueType", builtins.int)
        V: typing_extensions.TypeAlias = ValueType

    class _DiscoveryTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[Cluster._DiscoveryType.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
        STATIC: Cluster._DiscoveryType.ValueType  # 0
        """Refer to the :ref:`static discovery type<arch_overview_service_discovery_types_static>`
        for an explanation.
        """
        STRICT_DNS: Cluster._DiscoveryType.ValueType  # 1
        """Refer to the :ref:`strict DNS discovery
        type<arch_overview_service_discovery_types_strict_dns>`
        for an explanation.
        """
        LOGICAL_DNS: Cluster._DiscoveryType.ValueType  # 2
        """Refer to the :ref:`logical DNS discovery
        type<arch_overview_service_discovery_types_logical_dns>`
        for an explanation.
        """
        EDS: Cluster._DiscoveryType.ValueType  # 3
        """Refer to the :ref:`service discovery type<arch_overview_service_discovery_types_eds>`
        for an explanation.
        """
        ORIGINAL_DST: Cluster._DiscoveryType.ValueType  # 4
        """Refer to the :ref:`original destination discovery
        type<arch_overview_service_discovery_types_original_destination>`
        for an explanation.
        """

    class DiscoveryType(_DiscoveryType, metaclass=_DiscoveryTypeEnumTypeWrapper):
        """Refer to :ref:`service discovery type <arch_overview_service_discovery_types>`
        for an explanation on each type.
        """

    STATIC: Cluster.DiscoveryType.ValueType  # 0
    """Refer to the :ref:`static discovery type<arch_overview_service_discovery_types_static>`
    for an explanation.
    """
    STRICT_DNS: Cluster.DiscoveryType.ValueType  # 1
    """Refer to the :ref:`strict DNS discovery
    type<arch_overview_service_discovery_types_strict_dns>`
    for an explanation.
    """
    LOGICAL_DNS: Cluster.DiscoveryType.ValueType  # 2
    """Refer to the :ref:`logical DNS discovery
    type<arch_overview_service_discovery_types_logical_dns>`
    for an explanation.
    """
    EDS: Cluster.DiscoveryType.ValueType  # 3
    """Refer to the :ref:`service discovery type<arch_overview_service_discovery_types_eds>`
    for an explanation.
    """
    ORIGINAL_DST: Cluster.DiscoveryType.ValueType  # 4
    """Refer to the :ref:`original destination discovery
    type<arch_overview_service_discovery_types_original_destination>`
    for an explanation.
    """

    class _LbPolicy:
        ValueType = typing.NewType("ValueType", builtins.int)
        V: typing_extensions.TypeAlias = ValueType

    class _LbPolicyEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[Cluster._LbPolicy.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
        ROUND_ROBIN: Cluster._LbPolicy.ValueType  # 0
        """Refer to the :ref:`round robin load balancing
        policy<arch_overview_load_balancing_types_round_robin>`
        for an explanation.
        """
        LEAST_REQUEST: Cluster._LbPolicy.ValueType  # 1
        """Refer to the :ref:`least request load balancing
        policy<arch_overview_load_balancing_types_least_request>`
        for an explanation.
        """
        RING_HASH: Cluster._LbPolicy.ValueType  # 2
        """Refer to the :ref:`ring hash load balancing
        policy<arch_overview_load_balancing_types_ring_hash>`
        for an explanation.
        """
        RANDOM: Cluster._LbPolicy.ValueType  # 3
        """Refer to the :ref:`random load balancing
        policy<arch_overview_load_balancing_types_random>`
        for an explanation.
        """
        MAGLEV: Cluster._LbPolicy.ValueType  # 5
        """Refer to the :ref:`Maglev load balancing policy<arch_overview_load_balancing_types_maglev>`
        for an explanation.
        """
        CLUSTER_PROVIDED: Cluster._LbPolicy.ValueType  # 6
        """This load balancer type must be specified if the configured cluster provides a cluster
        specific load balancer. Consult the configured cluster's documentation for whether to set
        this option or not.
        """
        LOAD_BALANCING_POLICY_CONFIG: Cluster._LbPolicy.ValueType  # 7
        """Use the new :ref:`load_balancing_policy
        <envoy_v3_api_field_config.cluster.v3.Cluster.load_balancing_policy>` field to determine the LB policy.
        This has been deprecated in favor of using the :ref:`load_balancing_policy
        <envoy_v3_api_field_config.cluster.v3.Cluster.load_balancing_policy>` field without
        setting any value in :ref:`lb_policy<envoy_v3_api_field_config.cluster.v3.Cluster.lb_policy>`.
        """

    class LbPolicy(_LbPolicy, metaclass=_LbPolicyEnumTypeWrapper):
        """Refer to :ref:`load balancer type <arch_overview_load_balancing_types>` architecture
        overview section for information on each type.
        """

    ROUND_ROBIN: Cluster.LbPolicy.ValueType  # 0
    """Refer to the :ref:`round robin load balancing
    policy<arch_overview_load_balancing_types_round_robin>`
    for an explanation.
    """
    LEAST_REQUEST: Cluster.LbPolicy.ValueType  # 1
    """Refer to the :ref:`least request load balancing
    policy<arch_overview_load_balancing_types_least_request>`
    for an explanation.
    """
    RING_HASH: Cluster.LbPolicy.ValueType  # 2
    """Refer to the :ref:`ring hash load balancing
    policy<arch_overview_load_balancing_types_ring_hash>`
    for an explanation.
    """
    RANDOM: Cluster.LbPolicy.ValueType  # 3
    """Refer to the :ref:`random load balancing
    policy<arch_overview_load_balancing_types_random>`
    for an explanation.
    """
    MAGLEV: Cluster.LbPolicy.ValueType  # 5
    """Refer to the :ref:`Maglev load balancing policy<arch_overview_load_balancing_types_maglev>`
    for an explanation.
    """
    CLUSTER_PROVIDED: Cluster.LbPolicy.ValueType  # 6
    """This load balancer type must be specified if the configured cluster provides a cluster
    specific load balancer. Consult the configured cluster's documentation for whether to set
    this option or not.
    """
    LOAD_BALANCING_POLICY_CONFIG: Cluster.LbPolicy.ValueType  # 7
    """Use the new :ref:`load_balancing_policy
    <envoy_v3_api_field_config.cluster.v3.Cluster.load_balancing_policy>` field to determine the LB policy.
    This has been deprecated in favor of using the :ref:`load_balancing_policy
    <envoy_v3_api_field_config.cluster.v3.Cluster.load_balancing_policy>` field without
    setting any value in :ref:`lb_policy<envoy_v3_api_field_config.cluster.v3.Cluster.lb_policy>`.
    """

    class _DnsLookupFamily:
        ValueType = typing.NewType("ValueType", builtins.int)
        V: typing_extensions.TypeAlias = ValueType

    class _DnsLookupFamilyEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[Cluster._DnsLookupFamily.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
        AUTO: Cluster._DnsLookupFamily.ValueType  # 0
        V4_ONLY: Cluster._DnsLookupFamily.ValueType  # 1
        V6_ONLY: Cluster._DnsLookupFamily.ValueType  # 2
        V4_PREFERRED: Cluster._DnsLookupFamily.ValueType  # 3
        ALL: Cluster._DnsLookupFamily.ValueType  # 4

    class DnsLookupFamily(_DnsLookupFamily, metaclass=_DnsLookupFamilyEnumTypeWrapper):
        """When V4_ONLY is selected, the DNS resolver will only perform a lookup for
        addresses in the IPv4 family. If V6_ONLY is selected, the DNS resolver will
        only perform a lookup for addresses in the IPv6 family. If AUTO is
        specified, the DNS resolver will first perform a lookup for addresses in
        the IPv6 family and fallback to a lookup for addresses in the IPv4 family.
        This is semantically equivalent to a non-existent V6_PREFERRED option.
        AUTO is a legacy name that is more opaque than
        necessary and will be deprecated in favor of V6_PREFERRED in a future major version of the API.
        If V4_PREFERRED is specified, the DNS resolver will first perform a lookup for addresses in the
        IPv4 family and fallback to a lookup for addresses in the IPv6 family. i.e., the callback
        target will only get v6 addresses if there were NO v4 addresses to return.
        If ALL is specified, the DNS resolver will perform a lookup for both IPv4 and IPv6 families,
        and return all resolved addresses. When this is used, Happy Eyeballs will be enabled for
        upstream connections. Refer to :ref:`Happy Eyeballs Support <arch_overview_happy_eyeballs>`
        for more information.
        For cluster types other than
        :ref:`STRICT_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.STRICT_DNS>` and
        :ref:`LOGICAL_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.LOGICAL_DNS>`,
        this setting is
        ignored.
        [#next-major-version: deprecate AUTO in favor of a V6_PREFERRED option.]
        """

    AUTO: Cluster.DnsLookupFamily.ValueType  # 0
    V4_ONLY: Cluster.DnsLookupFamily.ValueType  # 1
    V6_ONLY: Cluster.DnsLookupFamily.ValueType  # 2
    V4_PREFERRED: Cluster.DnsLookupFamily.ValueType  # 3
    ALL: Cluster.DnsLookupFamily.ValueType  # 4

    class _ClusterProtocolSelection:
        ValueType = typing.NewType("ValueType", builtins.int)
        V: typing_extensions.TypeAlias = ValueType

    class _ClusterProtocolSelectionEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[Cluster._ClusterProtocolSelection.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
        USE_CONFIGURED_PROTOCOL: Cluster._ClusterProtocolSelection.ValueType  # 0
        """Cluster can only operate on one of the possible upstream protocols (HTTP1.1, HTTP2).
        If :ref:`http2_protocol_options <envoy_v3_api_field_config.cluster.v3.Cluster.http2_protocol_options>` are
        present, HTTP2 will be used, otherwise HTTP1.1 will be used.
        """
        USE_DOWNSTREAM_PROTOCOL: Cluster._ClusterProtocolSelection.ValueType  # 1
        """Use HTTP1.1 or HTTP2, depending on which one is used on the downstream connection."""

    class ClusterProtocolSelection(_ClusterProtocolSelection, metaclass=_ClusterProtocolSelectionEnumTypeWrapper): ...
    USE_CONFIGURED_PROTOCOL: Cluster.ClusterProtocolSelection.ValueType  # 0
    """Cluster can only operate on one of the possible upstream protocols (HTTP1.1, HTTP2).
    If :ref:`http2_protocol_options <envoy_v3_api_field_config.cluster.v3.Cluster.http2_protocol_options>` are
    present, HTTP2 will be used, otherwise HTTP1.1 will be used.
    """
    USE_DOWNSTREAM_PROTOCOL: Cluster.ClusterProtocolSelection.ValueType  # 1
    """Use HTTP1.1 or HTTP2, depending on which one is used on the downstream connection."""

    @typing.final
    class TransportSocketMatch(google.protobuf.message.Message):
        """TransportSocketMatch specifies what transport socket config will be used
        when the match conditions are satisfied.
        """

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        NAME_FIELD_NUMBER: builtins.int
        MATCH_FIELD_NUMBER: builtins.int
        TRANSPORT_SOCKET_FIELD_NUMBER: builtins.int
        name: builtins.str
        """The name of the match, used in stats generation."""
        @property
        def match(self) -> google.protobuf.struct_pb2.Struct:
            """Optional endpoint metadata match criteria.
            The connection to the endpoint with metadata matching what is set in this field
            will use the transport socket configuration specified here.
            The endpoint's metadata entry in ``envoy.transport_socket_match`` is used to match
            against the values specified in this field.
            """

        @property
        def transport_socket(self) -> envoy.config.core.v3.base_pb2.TransportSocket:
            """The configuration of the transport socket.
            [#extension-category: envoy.transport_sockets.upstream]
            """

        def __init__(
            self,
            *,
            name: builtins.str = ...,
            match: google.protobuf.struct_pb2.Struct | None = ...,
            transport_socket: envoy.config.core.v3.base_pb2.TransportSocket | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["match", b"match", "transport_socket", b"transport_socket"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["match", b"match", "name", b"name", "transport_socket", b"transport_socket"]) -> None: ...

    @typing.final
    class CustomClusterType(google.protobuf.message.Message):
        """Extended cluster type."""

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        NAME_FIELD_NUMBER: builtins.int
        TYPED_CONFIG_FIELD_NUMBER: builtins.int
        name: builtins.str
        """The type of the cluster to instantiate. The name must match a supported cluster type."""
        @property
        def typed_config(self) -> google.protobuf.any_pb2.Any:
            """Cluster specific configuration which depends on the cluster being instantiated.
            See the supported cluster for further documentation.
            [#extension-category: envoy.clusters]
            """

        def __init__(
            self,
            *,
            name: builtins.str = ...,
            typed_config: google.protobuf.any_pb2.Any | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["typed_config", b"typed_config"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["name", b"name", "typed_config", b"typed_config"]) -> None: ...

    @typing.final
    class EdsClusterConfig(google.protobuf.message.Message):
        """Only valid when discovery type is EDS."""

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        EDS_CONFIG_FIELD_NUMBER: builtins.int
        SERVICE_NAME_FIELD_NUMBER: builtins.int
        service_name: builtins.str
        """Optional alternative to cluster name to present to EDS. This does not
        have the same restrictions as cluster name, i.e. it may be arbitrary
        length. This may be a xdstp:// URL.
        """
        @property
        def eds_config(self) -> envoy.config.core.v3.config_source_pb2.ConfigSource:
            """Configuration for the source of EDS updates for this Cluster."""

        def __init__(
            self,
            *,
            eds_config: envoy.config.core.v3.config_source_pb2.ConfigSource | None = ...,
            service_name: builtins.str = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["eds_config", b"eds_config"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["eds_config", b"eds_config", "service_name", b"service_name"]) -> None: ...

    @typing.final
    class LbSubsetConfig(google.protobuf.message.Message):
        """Optionally divide the endpoints in this cluster into subsets defined by
        endpoint metadata and selected by route and weighted cluster metadata.
        [#next-free-field: 9]
        """

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        class _LbSubsetFallbackPolicy:
            ValueType = typing.NewType("ValueType", builtins.int)
            V: typing_extensions.TypeAlias = ValueType

        class _LbSubsetFallbackPolicyEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[Cluster.LbSubsetConfig._LbSubsetFallbackPolicy.ValueType], builtins.type):
            DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
            NO_FALLBACK: Cluster.LbSubsetConfig._LbSubsetFallbackPolicy.ValueType  # 0
            ANY_ENDPOINT: Cluster.LbSubsetConfig._LbSubsetFallbackPolicy.ValueType  # 1
            DEFAULT_SUBSET: Cluster.LbSubsetConfig._LbSubsetFallbackPolicy.ValueType  # 2

        class LbSubsetFallbackPolicy(_LbSubsetFallbackPolicy, metaclass=_LbSubsetFallbackPolicyEnumTypeWrapper):
            """If NO_FALLBACK is selected, a result
            equivalent to no healthy hosts is reported. If ANY_ENDPOINT is selected,
            any cluster endpoint may be returned (subject to policy, health checks,
            etc). If DEFAULT_SUBSET is selected, load balancing is performed over the
            endpoints matching the values from the default_subset field.
            """

        NO_FALLBACK: Cluster.LbSubsetConfig.LbSubsetFallbackPolicy.ValueType  # 0
        ANY_ENDPOINT: Cluster.LbSubsetConfig.LbSubsetFallbackPolicy.ValueType  # 1
        DEFAULT_SUBSET: Cluster.LbSubsetConfig.LbSubsetFallbackPolicy.ValueType  # 2

        class _LbSubsetMetadataFallbackPolicy:
            ValueType = typing.NewType("ValueType", builtins.int)
            V: typing_extensions.TypeAlias = ValueType

        class _LbSubsetMetadataFallbackPolicyEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[Cluster.LbSubsetConfig._LbSubsetMetadataFallbackPolicy.ValueType], builtins.type):
            DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
            METADATA_NO_FALLBACK: Cluster.LbSubsetConfig._LbSubsetMetadataFallbackPolicy.ValueType  # 0
            """No fallback. Route metadata will be used as-is."""
            FALLBACK_LIST: Cluster.LbSubsetConfig._LbSubsetMetadataFallbackPolicy.ValueType  # 1
            """A special metadata key ``fallback_list`` will be used to provide variants of metadata to try.
            Value of ``fallback_list`` key has to be a list. Every list element has to be a struct - it will
            be merged with route metadata, overriding keys that appear in both places.
            ``fallback_list`` entries will be used in order until a host is found.

            ``fallback_list`` key itself is removed from metadata before subset load balancing is performed.

            Example:

            for metadata:

            .. code-block:: yaml

              version: 1.0
              fallback_list:
                - version: 2.0
                  hardware: c64
                - hardware: c32
                - version: 3.0

            at first, metadata:

            .. code-block:: json

              {"version": "2.0", "hardware": "c64"}

            will be used for load balancing. If no host is found, metadata:

            .. code-block:: json

              {"version": "1.0", "hardware": "c32"}

            is next to try. If it still results in no host, finally metadata:

            .. code-block:: json

              {"version": "3.0"}

            is used.
            """

        class LbSubsetMetadataFallbackPolicy(_LbSubsetMetadataFallbackPolicy, metaclass=_LbSubsetMetadataFallbackPolicyEnumTypeWrapper): ...
        METADATA_NO_FALLBACK: Cluster.LbSubsetConfig.LbSubsetMetadataFallbackPolicy.ValueType  # 0
        """No fallback. Route metadata will be used as-is."""
        FALLBACK_LIST: Cluster.LbSubsetConfig.LbSubsetMetadataFallbackPolicy.ValueType  # 1
        """A special metadata key ``fallback_list`` will be used to provide variants of metadata to try.
        Value of ``fallback_list`` key has to be a list. Every list element has to be a struct - it will
        be merged with route metadata, overriding keys that appear in both places.
        ``fallback_list`` entries will be used in order until a host is found.

        ``fallback_list`` key itself is removed from metadata before subset load balancing is performed.

        Example:

        for metadata:

        .. code-block:: yaml

          version: 1.0
          fallback_list:
            - version: 2.0
              hardware: c64
            - hardware: c32
            - version: 3.0

        at first, metadata:

        .. code-block:: json

          {"version": "2.0", "hardware": "c64"}

        will be used for load balancing. If no host is found, metadata:

        .. code-block:: json

          {"version": "1.0", "hardware": "c32"}

        is next to try. If it still results in no host, finally metadata:

        .. code-block:: json

          {"version": "3.0"}

        is used.
        """

        @typing.final
        class LbSubsetSelector(google.protobuf.message.Message):
            """Specifications for subsets."""

            DESCRIPTOR: google.protobuf.descriptor.Descriptor

            class _LbSubsetSelectorFallbackPolicy:
                ValueType = typing.NewType("ValueType", builtins.int)
                V: typing_extensions.TypeAlias = ValueType

            class _LbSubsetSelectorFallbackPolicyEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[Cluster.LbSubsetConfig.LbSubsetSelector._LbSubsetSelectorFallbackPolicy.ValueType], builtins.type):
                DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
                NOT_DEFINED: Cluster.LbSubsetConfig.LbSubsetSelector._LbSubsetSelectorFallbackPolicy.ValueType  # 0
                """If NOT_DEFINED top level config fallback policy is used instead."""
                NO_FALLBACK: Cluster.LbSubsetConfig.LbSubsetSelector._LbSubsetSelectorFallbackPolicy.ValueType  # 1
                """If NO_FALLBACK is selected, a result equivalent to no healthy hosts is reported."""
                ANY_ENDPOINT: Cluster.LbSubsetConfig.LbSubsetSelector._LbSubsetSelectorFallbackPolicy.ValueType  # 2
                """If ANY_ENDPOINT is selected, any cluster endpoint may be returned
                (subject to policy, health checks, etc).
                """
                DEFAULT_SUBSET: Cluster.LbSubsetConfig.LbSubsetSelector._LbSubsetSelectorFallbackPolicy.ValueType  # 3
                """If DEFAULT_SUBSET is selected, load balancing is performed over the
                endpoints matching the values from the default_subset field.
                """
                KEYS_SUBSET: Cluster.LbSubsetConfig.LbSubsetSelector._LbSubsetSelectorFallbackPolicy.ValueType  # 4
                """If KEYS_SUBSET is selected, subset selector matching is performed again with metadata
                keys reduced to
                :ref:`fallback_keys_subset<envoy_v3_api_field_config.cluster.v3.Cluster.LbSubsetConfig.LbSubsetSelector.fallback_keys_subset>`.
                It allows for a fallback to a different, less specific selector if some of the keys of
                the selector are considered optional.
                """

            class LbSubsetSelectorFallbackPolicy(_LbSubsetSelectorFallbackPolicy, metaclass=_LbSubsetSelectorFallbackPolicyEnumTypeWrapper):
                """Allows to override top level fallback policy per selector."""

            NOT_DEFINED: Cluster.LbSubsetConfig.LbSubsetSelector.LbSubsetSelectorFallbackPolicy.ValueType  # 0
            """If NOT_DEFINED top level config fallback policy is used instead."""
            NO_FALLBACK: Cluster.LbSubsetConfig.LbSubsetSelector.LbSubsetSelectorFallbackPolicy.ValueType  # 1
            """If NO_FALLBACK is selected, a result equivalent to no healthy hosts is reported."""
            ANY_ENDPOINT: Cluster.LbSubsetConfig.LbSubsetSelector.LbSubsetSelectorFallbackPolicy.ValueType  # 2
            """If ANY_ENDPOINT is selected, any cluster endpoint may be returned
            (subject to policy, health checks, etc).
            """
            DEFAULT_SUBSET: Cluster.LbSubsetConfig.LbSubsetSelector.LbSubsetSelectorFallbackPolicy.ValueType  # 3
            """If DEFAULT_SUBSET is selected, load balancing is performed over the
            endpoints matching the values from the default_subset field.
            """
            KEYS_SUBSET: Cluster.LbSubsetConfig.LbSubsetSelector.LbSubsetSelectorFallbackPolicy.ValueType  # 4
            """If KEYS_SUBSET is selected, subset selector matching is performed again with metadata
            keys reduced to
            :ref:`fallback_keys_subset<envoy_v3_api_field_config.cluster.v3.Cluster.LbSubsetConfig.LbSubsetSelector.fallback_keys_subset>`.
            It allows for a fallback to a different, less specific selector if some of the keys of
            the selector are considered optional.
            """

            KEYS_FIELD_NUMBER: builtins.int
            SINGLE_HOST_PER_SUBSET_FIELD_NUMBER: builtins.int
            FALLBACK_POLICY_FIELD_NUMBER: builtins.int
            FALLBACK_KEYS_SUBSET_FIELD_NUMBER: builtins.int
            single_host_per_subset: builtins.bool
            """Selects a mode of operation in which each subset has only one host. This mode uses the same rules for
            choosing a host, but updating hosts is faster, especially for large numbers of hosts.

            If a match is found to a host, that host will be used regardless of priority levels.

            When this mode is enabled, configurations that contain more than one host with the same metadata value for the single key in ``keys``
            will use only one of the hosts with the given key; no requests will be routed to the others. The cluster gauge
            :ref:`lb_subsets_single_host_per_subset_duplicate<config_cluster_manager_cluster_stats_subset_lb>` indicates how many duplicates are
            present in the current configuration.
            """
            fallback_policy: global___Cluster.LbSubsetConfig.LbSubsetSelector.LbSubsetSelectorFallbackPolicy.ValueType
            """The behavior used when no endpoint subset matches the selected route's
            metadata.
            """
            @property
            def keys(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
                """List of keys to match with the weighted cluster metadata."""

            @property
            def fallback_keys_subset(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
                """Subset of
                :ref:`keys<envoy_v3_api_field_config.cluster.v3.Cluster.LbSubsetConfig.LbSubsetSelector.keys>` used by
                :ref:`KEYS_SUBSET<envoy_v3_api_enum_value_config.cluster.v3.Cluster.LbSubsetConfig.LbSubsetSelector.LbSubsetSelectorFallbackPolicy.KEYS_SUBSET>`
                fallback policy.
                It has to be a non empty list if KEYS_SUBSET fallback policy is selected.
                For any other fallback policy the parameter is not used and should not be set.
                Only values also present in
                :ref:`keys<envoy_v3_api_field_config.cluster.v3.Cluster.LbSubsetConfig.LbSubsetSelector.keys>` are allowed, but
                ``fallback_keys_subset`` cannot be equal to ``keys``.
                """

            def __init__(
                self,
                *,
                keys: collections.abc.Iterable[builtins.str] | None = ...,
                single_host_per_subset: builtins.bool = ...,
                fallback_policy: global___Cluster.LbSubsetConfig.LbSubsetSelector.LbSubsetSelectorFallbackPolicy.ValueType = ...,
                fallback_keys_subset: collections.abc.Iterable[builtins.str] | None = ...,
            ) -> None: ...
            def ClearField(self, field_name: typing.Literal["fallback_keys_subset", b"fallback_keys_subset", "fallback_policy", b"fallback_policy", "keys", b"keys", "single_host_per_subset", b"single_host_per_subset"]) -> None: ...

        FALLBACK_POLICY_FIELD_NUMBER: builtins.int
        DEFAULT_SUBSET_FIELD_NUMBER: builtins.int
        SUBSET_SELECTORS_FIELD_NUMBER: builtins.int
        LOCALITY_WEIGHT_AWARE_FIELD_NUMBER: builtins.int
        SCALE_LOCALITY_WEIGHT_FIELD_NUMBER: builtins.int
        PANIC_MODE_ANY_FIELD_NUMBER: builtins.int
        LIST_AS_ANY_FIELD_NUMBER: builtins.int
        METADATA_FALLBACK_POLICY_FIELD_NUMBER: builtins.int
        fallback_policy: global___Cluster.LbSubsetConfig.LbSubsetFallbackPolicy.ValueType
        """The behavior used when no endpoint subset matches the selected route's
        metadata. The value defaults to
        :ref:`NO_FALLBACK<envoy_v3_api_enum_value_config.cluster.v3.Cluster.LbSubsetConfig.LbSubsetFallbackPolicy.NO_FALLBACK>`.
        """
        locality_weight_aware: builtins.bool
        """If true, routing to subsets will take into account the localities and locality weights of the
        endpoints when making the routing decision.

        There are some potential pitfalls associated with enabling this feature, as the resulting
        traffic split after applying both a subset match and locality weights might be undesirable.

        Consider for example a situation in which you have 50/50 split across two localities X/Y
        which have 100 hosts each without subsetting. If the subset LB results in X having only 1
        host selected but Y having 100, then a lot more load is being dumped on the single host in X
        than originally anticipated in the load balancing assignment delivered via EDS.
        """
        scale_locality_weight: builtins.bool
        """When used with locality_weight_aware, scales the weight of each locality by the ratio
        of hosts in the subset vs hosts in the original subset. This aims to even out the load
        going to an individual locality if said locality is disproportionately affected by the
        subset predicate.
        """
        panic_mode_any: builtins.bool
        """If true, when a fallback policy is configured and its corresponding subset fails to find
        a host this will cause any host to be selected instead.

        This is useful when using the default subset as the fallback policy, given the default
        subset might become empty. With this option enabled, if that happens the LB will attempt
        to select a host from the entire cluster.
        """
        list_as_any: builtins.bool
        """If true, metadata specified for a metadata key will be matched against the corresponding
        endpoint metadata if the endpoint metadata matches the value exactly OR it is a list value
        and any of the elements in the list matches the criteria.
        """
        metadata_fallback_policy: global___Cluster.LbSubsetConfig.LbSubsetMetadataFallbackPolicy.ValueType
        """Fallback mechanism that allows to try different route metadata until a host is found.
        If load balancing process, including all its mechanisms (like
        :ref:`fallback_policy<envoy_v3_api_field_config.cluster.v3.Cluster.LbSubsetConfig.fallback_policy>`)
        fails to select a host, this policy decides if and how the process is repeated using another metadata.

        The value defaults to
        :ref:`METADATA_NO_FALLBACK<envoy_v3_api_enum_value_config.cluster.v3.Cluster.LbSubsetConfig.LbSubsetMetadataFallbackPolicy.METADATA_NO_FALLBACK>`.
        """
        @property
        def default_subset(self) -> google.protobuf.struct_pb2.Struct:
            """Specifies the default subset of endpoints used during fallback if
            fallback_policy is
            :ref:`DEFAULT_SUBSET<envoy_v3_api_enum_value_config.cluster.v3.Cluster.LbSubsetConfig.LbSubsetFallbackPolicy.DEFAULT_SUBSET>`.
            Each field in default_subset is
            compared to the matching LbEndpoint.Metadata under the ``envoy.lb``
            namespace. It is valid for no hosts to match, in which case the behavior
            is the same as a fallback_policy of
            :ref:`NO_FALLBACK<envoy_v3_api_enum_value_config.cluster.v3.Cluster.LbSubsetConfig.LbSubsetFallbackPolicy.NO_FALLBACK>`.
            """

        @property
        def subset_selectors(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Cluster.LbSubsetConfig.LbSubsetSelector]:
            """For each entry, LbEndpoint.Metadata's
            ``envoy.lb`` namespace is traversed and a subset is created for each unique
            combination of key and value. For example:

            .. code-block:: json

              { "subset_selectors": [
                  { "keys": [ "version" ] },
                  { "keys": [ "stage", "hardware_type" ] }
              ]}

            A subset is matched when the metadata from the selected route and
            weighted cluster contains the same keys and values as the subset's
            metadata. The same host may appear in multiple subsets.
            """

        def __init__(
            self,
            *,
            fallback_policy: global___Cluster.LbSubsetConfig.LbSubsetFallbackPolicy.ValueType = ...,
            default_subset: google.protobuf.struct_pb2.Struct | None = ...,
            subset_selectors: collections.abc.Iterable[global___Cluster.LbSubsetConfig.LbSubsetSelector] | None = ...,
            locality_weight_aware: builtins.bool = ...,
            scale_locality_weight: builtins.bool = ...,
            panic_mode_any: builtins.bool = ...,
            list_as_any: builtins.bool = ...,
            metadata_fallback_policy: global___Cluster.LbSubsetConfig.LbSubsetMetadataFallbackPolicy.ValueType = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["default_subset", b"default_subset"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["default_subset", b"default_subset", "fallback_policy", b"fallback_policy", "list_as_any", b"list_as_any", "locality_weight_aware", b"locality_weight_aware", "metadata_fallback_policy", b"metadata_fallback_policy", "panic_mode_any", b"panic_mode_any", "scale_locality_weight", b"scale_locality_weight", "subset_selectors", b"subset_selectors"]) -> None: ...

    @typing.final
    class SlowStartConfig(google.protobuf.message.Message):
        """Configuration for :ref:`slow start mode <arch_overview_load_balancing_slow_start>`."""

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        SLOW_START_WINDOW_FIELD_NUMBER: builtins.int
        AGGRESSION_FIELD_NUMBER: builtins.int
        MIN_WEIGHT_PERCENT_FIELD_NUMBER: builtins.int
        @property
        def slow_start_window(self) -> google.protobuf.duration_pb2.Duration:
            """Represents the size of slow start window.
            If set, the newly created host remains in slow start mode starting from its creation time
            for the duration of slow start window.
            """

        @property
        def aggression(self) -> envoy.config.core.v3.base_pb2.RuntimeDouble:
            """This parameter controls the speed of traffic increase over the slow start window. Defaults to 1.0,
            so that endpoint would get linearly increasing amount of traffic.
            When increasing the value for this parameter, the speed of traffic ramp-up increases non-linearly.
            The value of aggression parameter should be greater than 0.0.
            By tuning the parameter, is possible to achieve polynomial or exponential shape of ramp-up curve.

            During slow start window, effective weight of an endpoint would be scaled with time factor and aggression:
            ``new_weight = weight * max(min_weight_percent, time_factor ^ (1 / aggression))``,
            where ``time_factor=(time_since_start_seconds / slow_start_time_seconds)``.

            As time progresses, more and more traffic would be sent to endpoint, which is in slow start window.
            Once host exits slow start, time_factor and aggression no longer affect its weight.
            """

        @property
        def min_weight_percent(self) -> envoy.type.v3.percent_pb2.Percent:
            """Configures the minimum percentage of origin weight that avoids too small new weight,
            which may cause endpoints in slow start mode receive no traffic in slow start window.
            If not specified, the default is 10%.
            """

        def __init__(
            self,
            *,
            slow_start_window: google.protobuf.duration_pb2.Duration | None = ...,
            aggression: envoy.config.core.v3.base_pb2.RuntimeDouble | None = ...,
            min_weight_percent: envoy.type.v3.percent_pb2.Percent | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["aggression", b"aggression", "min_weight_percent", b"min_weight_percent", "slow_start_window", b"slow_start_window"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["aggression", b"aggression", "min_weight_percent", b"min_weight_percent", "slow_start_window", b"slow_start_window"]) -> None: ...

    @typing.final
    class RoundRobinLbConfig(google.protobuf.message.Message):
        """Specific configuration for the RoundRobin load balancing policy."""

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        SLOW_START_CONFIG_FIELD_NUMBER: builtins.int
        @property
        def slow_start_config(self) -> global___Cluster.SlowStartConfig:
            """Configuration for slow start mode.
            If this configuration is not set, slow start will not be not enabled.
            """

        def __init__(
            self,
            *,
            slow_start_config: global___Cluster.SlowStartConfig | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["slow_start_config", b"slow_start_config"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["slow_start_config", b"slow_start_config"]) -> None: ...

    @typing.final
    class LeastRequestLbConfig(google.protobuf.message.Message):
        """Specific configuration for the LeastRequest load balancing policy."""

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        CHOICE_COUNT_FIELD_NUMBER: builtins.int
        ACTIVE_REQUEST_BIAS_FIELD_NUMBER: builtins.int
        SLOW_START_CONFIG_FIELD_NUMBER: builtins.int
        @property
        def choice_count(self) -> google.protobuf.wrappers_pb2.UInt32Value:
            """The number of random healthy hosts from which the host with the fewest active requests will
            be chosen. Defaults to 2 so that we perform two-choice selection if the field is not set.
            """

        @property
        def active_request_bias(self) -> envoy.config.core.v3.base_pb2.RuntimeDouble:
            """The following formula is used to calculate the dynamic weights when hosts have different load
            balancing weights:

            ``weight = load_balancing_weight / (active_requests + 1)^active_request_bias``

            The larger the active request bias is, the more aggressively active requests will lower the
            effective weight when all host weights are not equal.

            ``active_request_bias`` must be greater than or equal to 0.0.

            When ``active_request_bias == 0.0`` the Least Request Load Balancer doesn't consider the number
            of active requests at the time it picks a host and behaves like the Round Robin Load
            Balancer.

            When ``active_request_bias > 0.0`` the Least Request Load Balancer scales the load balancing
            weight by the number of active requests at the time it does a pick.

            The value is cached for performance reasons and refreshed whenever one of the Load Balancer's
            host sets changes, e.g., whenever there is a host membership update or a host load balancing
            weight change.

            .. note::
              This setting only takes effect if all host weights are not equal.
            """

        @property
        def slow_start_config(self) -> global___Cluster.SlowStartConfig:
            """Configuration for slow start mode.
            If this configuration is not set, slow start will not be not enabled.
            """

        def __init__(
            self,
            *,
            choice_count: google.protobuf.wrappers_pb2.UInt32Value | None = ...,
            active_request_bias: envoy.config.core.v3.base_pb2.RuntimeDouble | None = ...,
            slow_start_config: global___Cluster.SlowStartConfig | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["active_request_bias", b"active_request_bias", "choice_count", b"choice_count", "slow_start_config", b"slow_start_config"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["active_request_bias", b"active_request_bias", "choice_count", b"choice_count", "slow_start_config", b"slow_start_config"]) -> None: ...

    @typing.final
    class RingHashLbConfig(google.protobuf.message.Message):
        """Specific configuration for the :ref:`RingHash<arch_overview_load_balancing_types_ring_hash>`
        load balancing policy.
        """

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        class _HashFunction:
            ValueType = typing.NewType("ValueType", builtins.int)
            V: typing_extensions.TypeAlias = ValueType

        class _HashFunctionEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[Cluster.RingHashLbConfig._HashFunction.ValueType], builtins.type):
            DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
            XX_HASH: Cluster.RingHashLbConfig._HashFunction.ValueType  # 0
            """Use `xxHash <https://github.com/Cyan4973/xxHash>`_, this is the default hash function."""
            MURMUR_HASH_2: Cluster.RingHashLbConfig._HashFunction.ValueType  # 1
            """Use `MurmurHash2 <https://sites.google.com/site/murmurhash/>`_, this is compatible with
            std:hash<string> in GNU libstdc++ 3.4.20 or above. This is typically the case when compiled
            on Linux and not macOS.
            """

        class HashFunction(_HashFunction, metaclass=_HashFunctionEnumTypeWrapper):
            """The hash function used to hash hosts onto the ketama ring."""

        XX_HASH: Cluster.RingHashLbConfig.HashFunction.ValueType  # 0
        """Use `xxHash <https://github.com/Cyan4973/xxHash>`_, this is the default hash function."""
        MURMUR_HASH_2: Cluster.RingHashLbConfig.HashFunction.ValueType  # 1
        """Use `MurmurHash2 <https://sites.google.com/site/murmurhash/>`_, this is compatible with
        std:hash<string> in GNU libstdc++ 3.4.20 or above. This is typically the case when compiled
        on Linux and not macOS.
        """

        MINIMUM_RING_SIZE_FIELD_NUMBER: builtins.int
        HASH_FUNCTION_FIELD_NUMBER: builtins.int
        MAXIMUM_RING_SIZE_FIELD_NUMBER: builtins.int
        hash_function: global___Cluster.RingHashLbConfig.HashFunction.ValueType
        """The hash function used to hash hosts onto the ketama ring. The value defaults to
        :ref:`XX_HASH<envoy_v3_api_enum_value_config.cluster.v3.Cluster.RingHashLbConfig.HashFunction.XX_HASH>`.
        """
        @property
        def minimum_ring_size(self) -> google.protobuf.wrappers_pb2.UInt64Value:
            """Minimum hash ring size. The larger the ring is (that is, the more hashes there are for each
            provided host) the better the request distribution will reflect the desired weights. Defaults
            to 1024 entries, and limited to 8M entries. See also
            :ref:`maximum_ring_size<envoy_v3_api_field_config.cluster.v3.Cluster.RingHashLbConfig.maximum_ring_size>`.
            """

        @property
        def maximum_ring_size(self) -> google.protobuf.wrappers_pb2.UInt64Value:
            """Maximum hash ring size. Defaults to 8M entries, and limited to 8M entries, but can be lowered
            to further constrain resource use. See also
            :ref:`minimum_ring_size<envoy_v3_api_field_config.cluster.v3.Cluster.RingHashLbConfig.minimum_ring_size>`.
            """

        def __init__(
            self,
            *,
            minimum_ring_size: google.protobuf.wrappers_pb2.UInt64Value | None = ...,
            hash_function: global___Cluster.RingHashLbConfig.HashFunction.ValueType = ...,
            maximum_ring_size: google.protobuf.wrappers_pb2.UInt64Value | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["maximum_ring_size", b"maximum_ring_size", "minimum_ring_size", b"minimum_ring_size"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["hash_function", b"hash_function", "maximum_ring_size", b"maximum_ring_size", "minimum_ring_size", b"minimum_ring_size"]) -> None: ...

    @typing.final
    class MaglevLbConfig(google.protobuf.message.Message):
        """Specific configuration for the :ref:`Maglev<arch_overview_load_balancing_types_maglev>`
        load balancing policy.
        """

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        TABLE_SIZE_FIELD_NUMBER: builtins.int
        @property
        def table_size(self) -> google.protobuf.wrappers_pb2.UInt64Value:
            """The table size for Maglev hashing. Maglev aims for "minimal disruption" rather than an absolute guarantee.
            Minimal disruption means that when the set of upstream hosts change, a connection will likely be sent to the same
            upstream as it was before. Increasing the table size reduces the amount of disruption.
            The table size must be prime number limited to 5000011. If it is not specified, the default is 65537.
            """

        def __init__(
            self,
            *,
            table_size: google.protobuf.wrappers_pb2.UInt64Value | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["table_size", b"table_size"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["table_size", b"table_size"]) -> None: ...

    @typing.final
    class OriginalDstLbConfig(google.protobuf.message.Message):
        """Specific configuration for the
        :ref:`Original Destination <arch_overview_load_balancing_types_original_destination>`
        load balancing policy.
        [#extension: envoy.clusters.original_dst]
        """

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        USE_HTTP_HEADER_FIELD_NUMBER: builtins.int
        HTTP_HEADER_NAME_FIELD_NUMBER: builtins.int
        UPSTREAM_PORT_OVERRIDE_FIELD_NUMBER: builtins.int
        use_http_header: builtins.bool
        """When true, a HTTP header can be used to override the original dst address. The default header is
        :ref:`x-envoy-original-dst-host <config_http_conn_man_headers_x-envoy-original-dst-host>`.

        .. attention::

          This header isn't sanitized by default, so enabling this feature allows HTTP clients to
          route traffic to arbitrary hosts and/or ports, which may have serious security
          consequences.

        .. note::

          If the header appears multiple times only the first value is used.
        """
        http_header_name: builtins.str
        """The http header to override destination address if :ref:`use_http_header <envoy_v3_api_field_config.cluster.v3.Cluster.OriginalDstLbConfig.use_http_header>`.
        is set to true. If the value is empty, :ref:`x-envoy-original-dst-host <config_http_conn_man_headers_x-envoy-original-dst-host>` will be used.
        """
        @property
        def upstream_port_override(self) -> google.protobuf.wrappers_pb2.UInt32Value:
            """The port to override for the original dst address. This port
            will take precedence over filter state and header override ports
            """

        def __init__(
            self,
            *,
            use_http_header: builtins.bool = ...,
            http_header_name: builtins.str = ...,
            upstream_port_override: google.protobuf.wrappers_pb2.UInt32Value | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["upstream_port_override", b"upstream_port_override"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["http_header_name", b"http_header_name", "upstream_port_override", b"upstream_port_override", "use_http_header", b"use_http_header"]) -> None: ...

    @typing.final
    class CommonLbConfig(google.protobuf.message.Message):
        """Common configuration for all load balancer implementations.
        [#next-free-field: 9]
        """

        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        @typing.final
        class ZoneAwareLbConfig(google.protobuf.message.Message):
            """Configuration for :ref:`zone aware routing
            <arch_overview_load_balancing_zone_aware_routing>`.
            """

            DESCRIPTOR: google.protobuf.descriptor.Descriptor

            ROUTING_ENABLED_FIELD_NUMBER: builtins.int
            MIN_CLUSTER_SIZE_FIELD_NUMBER: builtins.int
            FAIL_TRAFFIC_ON_PANIC_FIELD_NUMBER: builtins.int
            fail_traffic_on_panic: builtins.bool
            """If set to true, Envoy will not consider any hosts when the cluster is in :ref:`panic
            mode<arch_overview_load_balancing_panic_threshold>`. Instead, the cluster will fail all
            requests as if all hosts are unhealthy. This can help avoid potentially overwhelming a
            failing service.
            """
            @property
            def routing_enabled(self) -> envoy.type.v3.percent_pb2.Percent:
                """Configures percentage of requests that will be considered for zone aware routing
                if zone aware routing is configured. If not specified, the default is 100%.
                * :ref:`runtime values <config_cluster_manager_cluster_runtime_zone_routing>`.
                * :ref:`Zone aware routing support <arch_overview_load_balancing_zone_aware_routing>`.
                """

            @property
            def min_cluster_size(self) -> google.protobuf.wrappers_pb2.UInt64Value:
                """Configures minimum upstream cluster size required for zone aware routing
                If upstream cluster size is less than specified, zone aware routing is not performed
                even if zone aware routing is configured. If not specified, the default is 6.
                * :ref:`runtime values <config_cluster_manager_cluster_runtime_zone_routing>`.
                * :ref:`Zone aware routing support <arch_overview_load_balancing_zone_aware_routing>`.
                """

            def __init__(
                self,
                *,
                routing_enabled: envoy.type.v3.percent_pb2.Percent | None = ...,
                min_cluster_size: google.protobuf.wrappers_pb2.UInt64Value | None = ...,
                fail_traffic_on_panic: builtins.bool = ...,
            ) -> None: ...
            def HasField(self, field_name: typing.Literal["min_cluster_size", b"min_cluster_size", "routing_enabled", b"routing_enabled"]) -> builtins.bool: ...
            def ClearField(self, field_name: typing.Literal["fail_traffic_on_panic", b"fail_traffic_on_panic", "min_cluster_size", b"min_cluster_size", "routing_enabled", b"routing_enabled"]) -> None: ...

        @typing.final
        class LocalityWeightedLbConfig(google.protobuf.message.Message):
            """Configuration for :ref:`locality weighted load balancing
            <arch_overview_load_balancing_locality_weighted_lb>`
            """

            DESCRIPTOR: google.protobuf.descriptor.Descriptor

            def __init__(
                self,
            ) -> None: ...

        @typing.final
        class ConsistentHashingLbConfig(google.protobuf.message.Message):
            """Common Configuration for all consistent hashing load balancers (MaglevLb, RingHashLb, etc.)"""

            DESCRIPTOR: google.protobuf.descriptor.Descriptor

            USE_HOSTNAME_FOR_HASHING_FIELD_NUMBER: builtins.int
            HASH_BALANCE_FACTOR_FIELD_NUMBER: builtins.int
            use_hostname_for_hashing: builtins.bool
            """If set to ``true``, the cluster will use hostname instead of the resolved
            address as the key to consistently hash to an upstream host. Only valid for StrictDNS clusters with hostnames which resolve to a single IP address.
            """
            @property
            def hash_balance_factor(self) -> google.protobuf.wrappers_pb2.UInt32Value:
                """Configures percentage of average cluster load to bound per upstream host. For example, with a value of 150
                no upstream host will get a load more than 1.5 times the average load of all the hosts in the cluster.
                If not specified, the load is not bounded for any upstream host. Typical value for this parameter is between 120 and 200.
                Minimum is 100.

                Applies to both Ring Hash and Maglev load balancers.

                This is implemented based on the method described in the paper https://arxiv.org/abs/1608.01350. For the specified
                ``hash_balance_factor``, requests to any upstream host are capped at ``hash_balance_factor/100`` times the average number of requests
                across the cluster. When a request arrives for an upstream host that is currently serving at its max capacity, linear probing
                is used to identify an eligible host. Further, the linear probe is implemented using a random jump in hosts ring/table to identify
                the eligible host (this technique is as described in the paper https://arxiv.org/abs/1908.08762 - the random jump avoids the
                cascading overflow effect when choosing the next host in the ring/table).

                If weights are specified on the hosts, they are respected.

                This is an O(N) algorithm, unlike other load balancers. Using a lower ``hash_balance_factor`` results in more hosts
                being probed, so use a higher value if you require better performance.
                """

            def __init__(
                self,
                *,
                use_hostname_for_hashing: builtins.bool = ...,
                hash_balance_factor: google.protobuf.wrappers_pb2.UInt32Value | None = ...,
            ) -> None: ...
            def HasField(self, field_name: typing.Literal["hash_balance_factor", b"hash_balance_factor"]) -> builtins.bool: ...
            def ClearField(self, field_name: typing.Literal["hash_balance_factor", b"hash_balance_factor", "use_hostname_for_hashing", b"use_hostname_for_hashing"]) -> None: ...

        HEALTHY_PANIC_THRESHOLD_FIELD_NUMBER: builtins.int
        ZONE_AWARE_LB_CONFIG_FIELD_NUMBER: builtins.int
        LOCALITY_WEIGHTED_LB_CONFIG_FIELD_NUMBER: builtins.int
        UPDATE_MERGE_WINDOW_FIELD_NUMBER: builtins.int
        IGNORE_NEW_HOSTS_UNTIL_FIRST_HC_FIELD_NUMBER: builtins.int
        CLOSE_CONNECTIONS_ON_HOST_SET_CHANGE_FIELD_NUMBER: builtins.int
        CONSISTENT_HASHING_LB_CONFIG_FIELD_NUMBER: builtins.int
        OVERRIDE_HOST_STATUS_FIELD_NUMBER: builtins.int
        ignore_new_hosts_until_first_hc: builtins.bool
        """If set to true, Envoy will :ref:`exclude <arch_overview_load_balancing_excluded>` new hosts
        when computing load balancing weights until they have been health checked for the first time.
        This will have no effect unless active health checking is also configured.
        """
        close_connections_on_host_set_change: builtins.bool
        """If set to ``true``, the cluster manager will drain all existing
        connections to upstream hosts whenever hosts are added or removed from the cluster.
        """
        @property
        def healthy_panic_threshold(self) -> envoy.type.v3.percent_pb2.Percent:
            """Configures the :ref:`healthy panic threshold <arch_overview_load_balancing_panic_threshold>`.
            If not specified, the default is 50%.
            To disable panic mode, set to 0%.

            .. note::
              The specified percent will be truncated to the nearest 1%.
            """

        @property
        def zone_aware_lb_config(self) -> global___Cluster.CommonLbConfig.ZoneAwareLbConfig: ...
        @property
        def locality_weighted_lb_config(self) -> global___Cluster.CommonLbConfig.LocalityWeightedLbConfig: ...
        @property
        def update_merge_window(self) -> google.protobuf.duration_pb2.Duration:
            """If set, all health check/weight/metadata updates that happen within this duration will be
            merged and delivered in one shot when the duration expires. The start of the duration is when
            the first update happens. This is useful for big clusters, with potentially noisy deploys
            that might trigger excessive CPU usage due to a constant stream of healthcheck state changes
            or metadata updates. The first set of updates to be seen apply immediately (e.g.: a new
            cluster). Please always keep in mind that the use of sandbox technologies may change this
            behavior.

            If this is not set, we default to a merge window of 1000ms. To disable it, set the merge
            window to 0.

            Note: merging does not apply to cluster membership changes (e.g.: adds/removes); this is
            because merging those updates isn't currently safe. See
            https://github.com/envoyproxy/envoy/pull/3941.
            """

        @property
        def consistent_hashing_lb_config(self) -> global___Cluster.CommonLbConfig.ConsistentHashingLbConfig:
            """Common Configuration for all consistent hashing load balancers (MaglevLb, RingHashLb, etc.)"""

        @property
        def override_host_status(self) -> envoy.config.core.v3.health_check_pb2.HealthStatusSet:
            """This controls what hosts are considered valid when using
            :ref:`host overrides <arch_overview_load_balancing_override_host>`, which is used by some
            filters to modify the load balancing decision.

            If this is unset then [UNKNOWN, HEALTHY, DEGRADED] will be applied by default. If this is
            set with an empty set of statuses then host overrides will be ignored by the load balancing.
            """

        def __init__(
            self,
            *,
            healthy_panic_threshold: envoy.type.v3.percent_pb2.Percent | None = ...,
            zone_aware_lb_config: global___Cluster.CommonLbConfig.ZoneAwareLbConfig | None = ...,
            locality_weighted_lb_config: global___Cluster.CommonLbConfig.LocalityWeightedLbConfig | None = ...,
            update_merge_window: google.protobuf.duration_pb2.Duration | None = ...,
            ignore_new_hosts_until_first_hc: builtins.bool = ...,
            close_connections_on_host_set_change: builtins.bool = ...,
            consistent_hashing_lb_config: global___Cluster.CommonLbConfig.ConsistentHashingLbConfig | None = ...,
            override_host_status: envoy.config.core.v3.health_check_pb2.HealthStatusSet | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["consistent_hashing_lb_config", b"consistent_hashing_lb_config", "healthy_panic_threshold", b"healthy_panic_threshold", "locality_config_specifier", b"locality_config_specifier", "locality_weighted_lb_config", b"locality_weighted_lb_config", "override_host_status", b"override_host_status", "update_merge_window", b"update_merge_window", "zone_aware_lb_config", b"zone_aware_lb_config"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["close_connections_on_host_set_change", b"close_connections_on_host_set_change", "consistent_hashing_lb_config", b"consistent_hashing_lb_config", "healthy_panic_threshold", b"healthy_panic_threshold", "ignore_new_hosts_until_first_hc", b"ignore_new_hosts_until_first_hc", "locality_config_specifier", b"locality_config_specifier", "locality_weighted_lb_config", b"locality_weighted_lb_config", "override_host_status", b"override_host_status", "update_merge_window", b"update_merge_window", "zone_aware_lb_config", b"zone_aware_lb_config"]) -> None: ...
        def WhichOneof(self, oneof_group: typing.Literal["locality_config_specifier", b"locality_config_specifier"]) -> typing.Literal["zone_aware_lb_config", "locality_weighted_lb_config"] | None: ...

    @typing.final
    class RefreshRate(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        BASE_INTERVAL_FIELD_NUMBER: builtins.int
        MAX_INTERVAL_FIELD_NUMBER: builtins.int
        @property
        def base_interval(self) -> google.protobuf.duration_pb2.Duration:
            """Specifies the base interval between refreshes. This parameter is required and must be greater
            than zero and less than
            :ref:`max_interval <envoy_v3_api_field_config.cluster.v3.Cluster.RefreshRate.max_interval>`.
            """

        @property
        def max_interval(self) -> google.protobuf.duration_pb2.Duration:
            """Specifies the maximum interval between refreshes. This parameter is optional, but must be
            greater than or equal to the
            :ref:`base_interval <envoy_v3_api_field_config.cluster.v3.Cluster.RefreshRate.base_interval>`  if set. The default
            is 10 times the :ref:`base_interval <envoy_v3_api_field_config.cluster.v3.Cluster.RefreshRate.base_interval>`.
            """

        def __init__(
            self,
            *,
            base_interval: google.protobuf.duration_pb2.Duration | None = ...,
            max_interval: google.protobuf.duration_pb2.Duration | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["base_interval", b"base_interval", "max_interval", b"max_interval"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["base_interval", b"base_interval", "max_interval", b"max_interval"]) -> None: ...

    @typing.final
    class PreconnectPolicy(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        PER_UPSTREAM_PRECONNECT_RATIO_FIELD_NUMBER: builtins.int
        PREDICTIVE_PRECONNECT_RATIO_FIELD_NUMBER: builtins.int
        @property
        def per_upstream_preconnect_ratio(self) -> google.protobuf.wrappers_pb2.DoubleValue:
            """Indicates how many streams (rounded up) can be anticipated per-upstream for each
            incoming stream. This is useful for high-QPS or latency-sensitive services. Preconnecting
            will only be done if the upstream is healthy and the cluster has traffic.

            For example if this is 2, for an incoming HTTP/1.1 stream, 2 connections will be
            established, one for the new incoming stream, and one for a presumed follow-up stream. For
            HTTP/2, only one connection would be established by default as one connection can
            serve both the original and presumed follow-up stream.

            In steady state for non-multiplexed connections a value of 1.5 would mean if there were 100
            active streams, there would be 100 connections in use, and 50 connections preconnected.
            This might be a useful value for something like short lived single-use connections,
            for example proxying HTTP/1.1 if keep-alive were false and each stream resulted in connection
            termination. It would likely be overkill for long lived connections, such as TCP proxying SMTP
            or regular HTTP/1.1 with keep-alive. For long lived traffic, a value of 1.05 would be more
            reasonable, where for every 100 connections, 5 preconnected connections would be in the queue
            in case of unexpected disconnects where the connection could not be reused.

            If this value is not set, or set explicitly to one, Envoy will fetch as many connections
            as needed to serve streams in flight. This means in steady state if a connection is torn down,
            a subsequent streams will pay an upstream-rtt latency penalty waiting for a new connection.

            This is limited somewhat arbitrarily to 3 because preconnecting too aggressively can
            harm latency more than the preconnecting helps.
            """

        @property
        def predictive_preconnect_ratio(self) -> google.protobuf.wrappers_pb2.DoubleValue:
            """Indicates how many many streams (rounded up) can be anticipated across a cluster for each
            stream, useful for low QPS services. This is currently supported for a subset of
            deterministic non-hash-based load-balancing algorithms (weighted round robin, random).
            Unlike ``per_upstream_preconnect_ratio`` this preconnects across the upstream instances in a
            cluster, doing best effort predictions of what upstream would be picked next and
            pre-establishing a connection.

            Preconnecting will be limited to one preconnect per configured upstream in the cluster and will
            only be done if there are healthy upstreams and the cluster has traffic.

            For example if preconnecting is set to 2 for a round robin HTTP/2 cluster, on the first
            incoming stream, 2 connections will be preconnected - one to the first upstream for this
            cluster, one to the second on the assumption there will be a follow-up stream.

            If this value is not set, or set explicitly to one, Envoy will fetch as many connections
            as needed to serve streams in flight, so during warm up and in steady state if a connection
            is closed (and per_upstream_preconnect_ratio is not set), there will be a latency hit for
            connection establishment.

            If both this and preconnect_ratio are set, Envoy will make sure both predicted needs are met,
            basically preconnecting max(predictive-preconnect, per-upstream-preconnect), for each
            upstream.
            """

        def __init__(
            self,
            *,
            per_upstream_preconnect_ratio: google.protobuf.wrappers_pb2.DoubleValue | None = ...,
            predictive_preconnect_ratio: google.protobuf.wrappers_pb2.DoubleValue | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["per_upstream_preconnect_ratio", b"per_upstream_preconnect_ratio", "predictive_preconnect_ratio", b"predictive_preconnect_ratio"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["per_upstream_preconnect_ratio", b"per_upstream_preconnect_ratio", "predictive_preconnect_ratio", b"predictive_preconnect_ratio"]) -> None: ...

    @typing.final
    class TypedExtensionProtocolOptionsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: builtins.str
        @property
        def value(self) -> google.protobuf.any_pb2.Any: ...
        def __init__(
            self,
            *,
            key: builtins.str = ...,
            value: google.protobuf.any_pb2.Any | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["value", b"value"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...

    TRANSPORT_SOCKET_MATCHES_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    ALT_STAT_NAME_FIELD_NUMBER: builtins.int
    TYPE_FIELD_NUMBER: builtins.int
    CLUSTER_TYPE_FIELD_NUMBER: builtins.int
    EDS_CLUSTER_CONFIG_FIELD_NUMBER: builtins.int
    CONNECT_TIMEOUT_FIELD_NUMBER: builtins.int
    PER_CONNECTION_BUFFER_LIMIT_BYTES_FIELD_NUMBER: builtins.int
    LB_POLICY_FIELD_NUMBER: builtins.int
    LOAD_ASSIGNMENT_FIELD_NUMBER: builtins.int
    HEALTH_CHECKS_FIELD_NUMBER: builtins.int
    MAX_REQUESTS_PER_CONNECTION_FIELD_NUMBER: builtins.int
    CIRCUIT_BREAKERS_FIELD_NUMBER: builtins.int
    UPSTREAM_HTTP_PROTOCOL_OPTIONS_FIELD_NUMBER: builtins.int
    COMMON_HTTP_PROTOCOL_OPTIONS_FIELD_NUMBER: builtins.int
    HTTP_PROTOCOL_OPTIONS_FIELD_NUMBER: builtins.int
    HTTP2_PROTOCOL_OPTIONS_FIELD_NUMBER: builtins.int
    TYPED_EXTENSION_PROTOCOL_OPTIONS_FIELD_NUMBER: builtins.int
    DNS_REFRESH_RATE_FIELD_NUMBER: builtins.int
    DNS_FAILURE_REFRESH_RATE_FIELD_NUMBER: builtins.int
    RESPECT_DNS_TTL_FIELD_NUMBER: builtins.int
    DNS_LOOKUP_FAMILY_FIELD_NUMBER: builtins.int
    DNS_RESOLVERS_FIELD_NUMBER: builtins.int
    USE_TCP_FOR_DNS_LOOKUPS_FIELD_NUMBER: builtins.int
    DNS_RESOLUTION_CONFIG_FIELD_NUMBER: builtins.int
    TYPED_DNS_RESOLVER_CONFIG_FIELD_NUMBER: builtins.int
    WAIT_FOR_WARM_ON_INIT_FIELD_NUMBER: builtins.int
    OUTLIER_DETECTION_FIELD_NUMBER: builtins.int
    CLEANUP_INTERVAL_FIELD_NUMBER: builtins.int
    UPSTREAM_BIND_CONFIG_FIELD_NUMBER: builtins.int
    LB_SUBSET_CONFIG_FIELD_NUMBER: builtins.int
    RING_HASH_LB_CONFIG_FIELD_NUMBER: builtins.int
    MAGLEV_LB_CONFIG_FIELD_NUMBER: builtins.int
    ORIGINAL_DST_LB_CONFIG_FIELD_NUMBER: builtins.int
    LEAST_REQUEST_LB_CONFIG_FIELD_NUMBER: builtins.int
    ROUND_ROBIN_LB_CONFIG_FIELD_NUMBER: builtins.int
    COMMON_LB_CONFIG_FIELD_NUMBER: builtins.int
    TRANSPORT_SOCKET_FIELD_NUMBER: builtins.int
    METADATA_FIELD_NUMBER: builtins.int
    PROTOCOL_SELECTION_FIELD_NUMBER: builtins.int
    UPSTREAM_CONNECTION_OPTIONS_FIELD_NUMBER: builtins.int
    CLOSE_CONNECTIONS_ON_HOST_HEALTH_FAILURE_FIELD_NUMBER: builtins.int
    IGNORE_HEALTH_ON_HOST_REMOVAL_FIELD_NUMBER: builtins.int
    FILTERS_FIELD_NUMBER: builtins.int
    LOAD_BALANCING_POLICY_FIELD_NUMBER: builtins.int
    LRS_SERVER_FIELD_NUMBER: builtins.int
    TRACK_TIMEOUT_BUDGETS_FIELD_NUMBER: builtins.int
    UPSTREAM_CONFIG_FIELD_NUMBER: builtins.int
    TRACK_CLUSTER_STATS_FIELD_NUMBER: builtins.int
    PRECONNECT_POLICY_FIELD_NUMBER: builtins.int
    CONNECTION_POOL_PER_DOWNSTREAM_CONNECTION_FIELD_NUMBER: builtins.int
    name: builtins.str
    """Supplies the name of the cluster which must be unique across all clusters.
    The cluster name is used when emitting
    :ref:`statistics <config_cluster_manager_cluster_stats>` if :ref:`alt_stat_name
    <envoy_v3_api_field_config.cluster.v3.Cluster.alt_stat_name>` is not provided.
    Any ``:`` in the cluster name will be converted to ``_`` when emitting statistics.
    """
    alt_stat_name: builtins.str
    """An optional alternative to the cluster name to be used for observability. This name is used
    emitting stats for the cluster and access logging the cluster name. This will appear as
    additional information in configuration dumps of a cluster's current status as
    :ref:`observability_name <envoy_v3_api_field_admin.v3.ClusterStatus.observability_name>`
    and as an additional tag "upstream_cluster.name" while tracing. Note: Any ``:`` in the name
    will be converted to ``_`` when emitting statistics. This should not be confused with
    :ref:`Router Filter Header <config_http_filters_router_x-envoy-upstream-alt-stat-name>`.
    """
    type: global___Cluster.DiscoveryType.ValueType
    """The :ref:`service discovery type <arch_overview_service_discovery_types>`
    to use for resolving the cluster.
    """
    lb_policy: global___Cluster.LbPolicy.ValueType
    """The :ref:`load balancer type <arch_overview_load_balancing_types>` to use
    when picking a host in the cluster.
    """
    respect_dns_ttl: builtins.bool
    """Optional configuration for setting cluster's DNS refresh rate. If the value is set to true,
    cluster's DNS refresh rate will be set to resource record's TTL which comes from DNS
    resolution.
    """
    dns_lookup_family: global___Cluster.DnsLookupFamily.ValueType
    """The DNS IP address resolution policy. If this setting is not specified, the
    value defaults to
    :ref:`AUTO<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DnsLookupFamily.AUTO>`.
    """
    use_tcp_for_dns_lookups: builtins.bool
    """Always use TCP queries instead of UDP queries for DNS lookups.
    This field is deprecated in favor of ``dns_resolution_config``
    which aggregates all of the DNS resolver configuration in a single message.
    """
    protocol_selection: global___Cluster.ClusterProtocolSelection.ValueType
    """Determines how Envoy selects the protocol used to speak to upstream hosts.
    This has been deprecated in favor of setting explicit protocol selection
    in the :ref:`http_protocol_options
    <envoy_v3_api_msg_extensions.upstreams.http.v3.HttpProtocolOptions>` message.
    http_protocol_options can be set via the cluster's
    :ref:`extension_protocol_options<envoy_v3_api_field_config.cluster.v3.Cluster.typed_extension_protocol_options>`.
    """
    close_connections_on_host_health_failure: builtins.bool
    """If an upstream host becomes unhealthy (as determined by the configured health checks
    or outlier detection), immediately close all connections to the failed host.

    .. note::

      This is currently only supported for connections created by tcp_proxy.

    .. note::

      The current implementation of this feature closes all connections immediately when
      the unhealthy status is detected. If there are a large number of connections open
      to an upstream host that becomes unhealthy, Envoy may spend a substantial amount of
      time exclusively closing these connections, and not processing any other traffic.
    """
    ignore_health_on_host_removal: builtins.bool
    """If set to true, Envoy will ignore the health value of a host when processing its removal
    from service discovery. This means that if active health checking is used, Envoy will *not*
    wait for the endpoint to go unhealthy before removing it.
    """
    track_timeout_budgets: builtins.bool
    """If track_timeout_budgets is true, the :ref:`timeout budget histograms
    <config_cluster_manager_cluster_stats_timeout_budgets>` will be published for each
    request. These show what percentage of a request's per try and global timeout was used. A value
    of 0 would indicate that none of the timeout was used or that the timeout was infinite. A value
    of 100 would indicate that the request took the entirety of the timeout given to it.

    .. attention::

      This field has been deprecated in favor of ``timeout_budgets``, part of
      :ref:`track_cluster_stats <envoy_v3_api_field_config.cluster.v3.Cluster.track_cluster_stats>`.
    """
    connection_pool_per_downstream_connection: builtins.bool
    """If ``connection_pool_per_downstream_connection`` is true, the cluster will use a separate
    connection pool for every downstream connection
    """
    @property
    def transport_socket_matches(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Cluster.TransportSocketMatch]:
        """Configuration to use different transport sockets for different endpoints.
        The entry of ``envoy.transport_socket_match`` in the
        :ref:`LbEndpoint.Metadata <envoy_v3_api_field_config.endpoint.v3.LbEndpoint.metadata>`
        is used to match against the transport sockets as they appear in the list. The first
        :ref:`match <envoy_v3_api_msg_config.cluster.v3.Cluster.TransportSocketMatch>` is used.
        For example, with the following match

        .. code-block:: yaml

         transport_socket_matches:
         - name: "enableMTLS"
           match:
             acceptMTLS: true
           transport_socket:
             name: envoy.transport_sockets.tls
             config: { ... } # tls socket configuration
         - name: "defaultToPlaintext"
           match: {}
           transport_socket:
             name: envoy.transport_sockets.raw_buffer

        Connections to the endpoints whose metadata value under ``envoy.transport_socket_match``
        having "acceptMTLS"/"true" key/value pair use the "enableMTLS" socket configuration.

        If a :ref:`socket match <envoy_v3_api_msg_config.cluster.v3.Cluster.TransportSocketMatch>` with empty match
        criteria is provided, that always match any endpoint. For example, the "defaultToPlaintext"
        socket match in case above.

        If an endpoint metadata's value under ``envoy.transport_socket_match`` does not match any
        ``TransportSocketMatch``, socket configuration fallbacks to use the ``tls_context`` or
        ``transport_socket`` specified in this cluster.

        This field allows gradual and flexible transport socket configuration changes.

        The metadata of endpoints in EDS can indicate transport socket capabilities. For example,
        an endpoint's metadata can have two key value pairs as "acceptMTLS": "true",
        "acceptPlaintext": "true". While some other endpoints, only accepting plaintext traffic
        has "acceptPlaintext": "true" metadata information.

        Then the xDS server can configure the CDS to a client, Envoy A, to send mutual TLS
        traffic for endpoints with "acceptMTLS": "true", by adding a corresponding
        ``TransportSocketMatch`` in this field. Other client Envoys receive CDS without
        ``transport_socket_match`` set, and still send plain text traffic to the same cluster.

        This field can be used to specify custom transport socket configurations for health
        checks by adding matching key/value pairs in a health check's
        :ref:`transport socket match criteria <envoy_v3_api_field_config.core.v3.HealthCheck.transport_socket_match_criteria>` field.

        [#comment:TODO(incfly): add a detailed architecture doc on intended usage.]
        """

    @property
    def cluster_type(self) -> global___Cluster.CustomClusterType:
        """The custom cluster type."""

    @property
    def eds_cluster_config(self) -> global___Cluster.EdsClusterConfig:
        """Configuration to use for EDS updates for the Cluster."""

    @property
    def connect_timeout(self) -> google.protobuf.duration_pb2.Duration:
        """The timeout for new network connections to hosts in the cluster.
        If not set, a default value of 5s will be used.
        """

    @property
    def per_connection_buffer_limit_bytes(self) -> google.protobuf.wrappers_pb2.UInt32Value:
        """Soft limit on size of the clusters connections read and write buffers. If
        unspecified, an implementation defined default is applied (1MiB).
        """

    @property
    def load_assignment(self) -> envoy.config.endpoint.v3.endpoint_pb2.ClusterLoadAssignment:
        """Setting this is required for specifying members of
        :ref:`STATIC<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.STATIC>`,
        :ref:`STRICT_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.STRICT_DNS>`
        or :ref:`LOGICAL_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.LOGICAL_DNS>` clusters.
        This field supersedes the ``hosts`` field in the v2 API.

        .. attention::

          Setting this allows non-EDS cluster types to contain embedded EDS equivalent
          :ref:`endpoint assignments<envoy_v3_api_msg_config.endpoint.v3.ClusterLoadAssignment>`.
        """

    @property
    def health_checks(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[envoy.config.core.v3.health_check_pb2.HealthCheck]:
        """Optional :ref:`active health checking <arch_overview_health_checking>`
        configuration for the cluster. If no
        configuration is specified no health checking will be done and all cluster
        members will be considered healthy at all times.
        """

    @property
    def max_requests_per_connection(self) -> google.protobuf.wrappers_pb2.UInt32Value:
        """Optional maximum requests for a single upstream connection. This parameter
        is respected by both the HTTP/1.1 and HTTP/2 connection pool
        implementations. If not specified, there is no limit. Setting this
        parameter to 1 will effectively disable keep alive.

        .. attention::
          This field has been deprecated in favor of the :ref:`max_requests_per_connection <envoy_v3_api_field_config.core.v3.HttpProtocolOptions.max_requests_per_connection>` field.
        """

    @property
    def circuit_breakers(self) -> envoy.config.cluster.v3.circuit_breaker_pb2.CircuitBreakers:
        """Optional :ref:`circuit breaking <arch_overview_circuit_break>` for the cluster."""

    @property
    def upstream_http_protocol_options(self) -> envoy.config.core.v3.protocol_pb2.UpstreamHttpProtocolOptions:
        """HTTP protocol options that are applied only to upstream HTTP connections.
        These options apply to all HTTP versions.
        This has been deprecated in favor of
        :ref:`upstream_http_protocol_options <envoy_v3_api_field_extensions.upstreams.http.v3.HttpProtocolOptions.upstream_http_protocol_options>`
        in the :ref:`http_protocol_options <envoy_v3_api_msg_extensions.upstreams.http.v3.HttpProtocolOptions>` message.
        upstream_http_protocol_options can be set via the cluster's
        :ref:`extension_protocol_options<envoy_v3_api_field_config.cluster.v3.Cluster.typed_extension_protocol_options>`.
        See :ref:`upstream_http_protocol_options
        <envoy_v3_api_field_extensions.upstreams.http.v3.HttpProtocolOptions.upstream_http_protocol_options>`
        for example usage.
        """

    @property
    def common_http_protocol_options(self) -> envoy.config.core.v3.protocol_pb2.HttpProtocolOptions:
        """Additional options when handling HTTP requests upstream. These options will be applicable to
        both HTTP1 and HTTP2 requests.
        This has been deprecated in favor of
        :ref:`common_http_protocol_options <envoy_v3_api_field_extensions.upstreams.http.v3.HttpProtocolOptions.common_http_protocol_options>`
        in the :ref:`http_protocol_options <envoy_v3_api_msg_extensions.upstreams.http.v3.HttpProtocolOptions>` message.
        common_http_protocol_options can be set via the cluster's
        :ref:`extension_protocol_options<envoy_v3_api_field_config.cluster.v3.Cluster.typed_extension_protocol_options>`.
        See :ref:`upstream_http_protocol_options
        <envoy_v3_api_field_extensions.upstreams.http.v3.HttpProtocolOptions.upstream_http_protocol_options>`
        for example usage.
        """

    @property
    def http_protocol_options(self) -> envoy.config.core.v3.protocol_pb2.Http1ProtocolOptions:
        """Additional options when handling HTTP1 requests.
        This has been deprecated in favor of http_protocol_options fields in the
        :ref:`http_protocol_options <envoy_v3_api_msg_extensions.upstreams.http.v3.HttpProtocolOptions>` message.
        http_protocol_options can be set via the cluster's
        :ref:`extension_protocol_options<envoy_v3_api_field_config.cluster.v3.Cluster.typed_extension_protocol_options>`.
        See :ref:`upstream_http_protocol_options
        <envoy_v3_api_field_extensions.upstreams.http.v3.HttpProtocolOptions.upstream_http_protocol_options>`
        for example usage.
        """

    @property
    def http2_protocol_options(self) -> envoy.config.core.v3.protocol_pb2.Http2ProtocolOptions:
        """Even if default HTTP2 protocol options are desired, this field must be
        set so that Envoy will assume that the upstream supports HTTP/2 when
        making new HTTP connection pool connections. Currently, Envoy only
        supports prior knowledge for upstream connections. Even if TLS is used
        with ALPN, ``http2_protocol_options`` must be specified. As an aside this allows HTTP/2
        connections to happen over plain text.
        This has been deprecated in favor of http2_protocol_options fields in the
        :ref:`http_protocol_options <envoy_v3_api_msg_extensions.upstreams.http.v3.HttpProtocolOptions>`
        message. http2_protocol_options can be set via the cluster's
        :ref:`extension_protocol_options<envoy_v3_api_field_config.cluster.v3.Cluster.typed_extension_protocol_options>`.
        See :ref:`upstream_http_protocol_options
        <envoy_v3_api_field_extensions.upstreams.http.v3.HttpProtocolOptions.upstream_http_protocol_options>`
        for example usage.
        """

    @property
    def typed_extension_protocol_options(self) -> google.protobuf.internal.containers.MessageMap[builtins.str, google.protobuf.any_pb2.Any]:
        """The extension_protocol_options field is used to provide extension-specific protocol options
        for upstream connections. The key should match the extension filter name, such as
        "envoy.filters.network.thrift_proxy". See the extension's documentation for details on
        specific options.
        [#next-major-version: make this a list of typed extensions.]
        """

    @property
    def dns_refresh_rate(self) -> google.protobuf.duration_pb2.Duration:
        """If the DNS refresh rate is specified and the cluster type is either
        :ref:`STRICT_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.STRICT_DNS>`,
        or :ref:`LOGICAL_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.LOGICAL_DNS>`,
        this value is used as the clusters DNS refresh
        rate. The value configured must be at least 1ms. If this setting is not specified, the
        value defaults to 5000ms. For cluster types other than
        :ref:`STRICT_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.STRICT_DNS>`
        and :ref:`LOGICAL_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.LOGICAL_DNS>`
        this setting is ignored.
        """

    @property
    def dns_failure_refresh_rate(self) -> global___Cluster.RefreshRate:
        """If the DNS failure refresh rate is specified and the cluster type is either
        :ref:`STRICT_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.STRICT_DNS>`,
        or :ref:`LOGICAL_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.LOGICAL_DNS>`,
        this is used as the clusters DNS refresh rate when requests are failing. If this setting is
        not specified, the failure refresh rate defaults to the DNS refresh rate. For cluster types
        other than :ref:`STRICT_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.STRICT_DNS>` and
        :ref:`LOGICAL_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.LOGICAL_DNS>` this setting is
        ignored.
        """

    @property
    def dns_resolvers(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[envoy.config.core.v3.address_pb2.Address]:
        """If DNS resolvers are specified and the cluster type is either
        :ref:`STRICT_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.STRICT_DNS>`,
        or :ref:`LOGICAL_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.LOGICAL_DNS>`,
        this value is used to specify the clusters dns resolvers.
        If this setting is not specified, the value defaults to the default
        resolver, which uses /etc/resolv.conf for configuration. For cluster types
        other than
        :ref:`STRICT_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.STRICT_DNS>`
        and :ref:`LOGICAL_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.LOGICAL_DNS>`
        this setting is ignored.
        This field is deprecated in favor of ``dns_resolution_config``
        which aggregates all of the DNS resolver configuration in a single message.
        """

    @property
    def dns_resolution_config(self) -> envoy.config.core.v3.resolver_pb2.DnsResolutionConfig:
        """DNS resolution configuration which includes the underlying dns resolver addresses and options.
        This field is deprecated in favor of
        :ref:`typed_dns_resolver_config <envoy_v3_api_field_config.cluster.v3.Cluster.typed_dns_resolver_config>`.
        """

    @property
    def typed_dns_resolver_config(self) -> envoy.config.core.v3.extension_pb2.TypedExtensionConfig:
        """DNS resolver type configuration extension. This extension can be used to configure c-ares, apple,
        or any other DNS resolver types and the related parameters.
        For example, an object of
        :ref:`CaresDnsResolverConfig <envoy_v3_api_msg_extensions.network.dns_resolver.cares.v3.CaresDnsResolverConfig>`
        can be packed into this ``typed_dns_resolver_config``. This configuration replaces the
        :ref:`dns_resolution_config <envoy_v3_api_field_config.cluster.v3.Cluster.dns_resolution_config>`
        configuration.
        During the transition period when both ``dns_resolution_config`` and ``typed_dns_resolver_config`` exists,
        when ``typed_dns_resolver_config`` is in place, Envoy will use it and ignore ``dns_resolution_config``.
        When ``typed_dns_resolver_config`` is missing, the default behavior is in place.
        [#extension-category: envoy.network.dns_resolver]
        """

    @property
    def wait_for_warm_on_init(self) -> google.protobuf.wrappers_pb2.BoolValue:
        """Optional configuration for having cluster readiness block on warm-up. Currently, only applicable for
        :ref:`STRICT_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.STRICT_DNS>`,
        or :ref:`LOGICAL_DNS<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.LOGICAL_DNS>`.
        If true, cluster readiness blocks on warm-up. If false, the cluster will complete
        initialization whether or not warm-up has completed. Defaults to true.
        """

    @property
    def outlier_detection(self) -> envoy.config.cluster.v3.outlier_detection_pb2.OutlierDetection:
        """If specified, outlier detection will be enabled for this upstream cluster.
        Each of the configuration values can be overridden via
        :ref:`runtime values <config_cluster_manager_cluster_runtime_outlier_detection>`.
        """

    @property
    def cleanup_interval(self) -> google.protobuf.duration_pb2.Duration:
        """The interval for removing stale hosts from a cluster type
        :ref:`ORIGINAL_DST<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.ORIGINAL_DST>`.
        Hosts are considered stale if they have not been used
        as upstream destinations during this interval. New hosts are added
        to original destination clusters on demand as new connections are
        redirected to Envoy, causing the number of hosts in the cluster to
        grow over time. Hosts that are not stale (they are actively used as
        destinations) are kept in the cluster, which allows connections to
        them remain open, saving the latency that would otherwise be spent
        on opening new connections. If this setting is not specified, the
        value defaults to 5000ms. For cluster types other than
        :ref:`ORIGINAL_DST<envoy_v3_api_enum_value_config.cluster.v3.Cluster.DiscoveryType.ORIGINAL_DST>`
        this setting is ignored.
        """

    @property
    def upstream_bind_config(self) -> envoy.config.core.v3.address_pb2.BindConfig:
        """Optional configuration used to bind newly established upstream connections.
        This overrides any bind_config specified in the bootstrap proto.
        If the address and port are empty, no bind will be performed.
        """

    @property
    def lb_subset_config(self) -> global___Cluster.LbSubsetConfig:
        """Configuration for load balancing subsetting."""

    @property
    def ring_hash_lb_config(self) -> global___Cluster.RingHashLbConfig:
        """Optional configuration for the Ring Hash load balancing policy."""

    @property
    def maglev_lb_config(self) -> global___Cluster.MaglevLbConfig:
        """Optional configuration for the Maglev load balancing policy."""

    @property
    def original_dst_lb_config(self) -> global___Cluster.OriginalDstLbConfig:
        """Optional configuration for the Original Destination load balancing policy."""

    @property
    def least_request_lb_config(self) -> global___Cluster.LeastRequestLbConfig:
        """Optional configuration for the LeastRequest load balancing policy."""

    @property
    def round_robin_lb_config(self) -> global___Cluster.RoundRobinLbConfig:
        """Optional configuration for the RoundRobin load balancing policy."""

    @property
    def common_lb_config(self) -> global___Cluster.CommonLbConfig:
        """Common configuration for all load balancer implementations."""

    @property
    def transport_socket(self) -> envoy.config.core.v3.base_pb2.TransportSocket:
        """Optional custom transport socket implementation to use for upstream connections.
        To setup TLS, set a transport socket with name ``envoy.transport_sockets.tls`` and
        :ref:`UpstreamTlsContexts <envoy_v3_api_msg_extensions.transport_sockets.tls.v3.UpstreamTlsContext>` in the ``typed_config``.
        If no transport socket configuration is specified, new connections
        will be set up with plaintext.
        """

    @property
    def metadata(self) -> envoy.config.core.v3.base_pb2.Metadata:
        """The Metadata field can be used to provide additional information about the
        cluster. It can be used for stats, logging, and varying filter behavior.
        Fields should use reverse DNS notation to denote which entity within Envoy
        will need the information. For instance, if the metadata is intended for
        the Router filter, the filter name should be specified as ``envoy.filters.http.router``.
        """

    @property
    def upstream_connection_options(self) -> global___UpstreamConnectionOptions:
        """Optional options for upstream connections."""

    @property
    def filters(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[envoy.config.cluster.v3.filter_pb2.Filter]:
        """An (optional) network filter chain, listed in the order the filters should be applied.
        The chain will be applied to all outgoing connections that Envoy makes to the upstream
        servers of this cluster.
        """

    @property
    def load_balancing_policy(self) -> global___LoadBalancingPolicy:
        """If this field is set and is supported by the client, it will supersede the value of
        :ref:`lb_policy<envoy_v3_api_field_config.cluster.v3.Cluster.lb_policy>`.
        """

    @property
    def lrs_server(self) -> envoy.config.core.v3.config_source_pb2.ConfigSource:
        """[#not-implemented-hide:]
        If present, tells the client where to send load reports via LRS. If not present, the
        client will fall back to a client-side default, which may be either (a) don't send any
        load reports or (b) send load reports for all clusters to a single default server
        (which may be configured in the bootstrap file).

        Note that if multiple clusters point to the same LRS server, the client may choose to
        create a separate stream for each cluster or it may choose to coalesce the data for
        multiple clusters onto a single stream. Either way, the client must make sure to send
        the data for any given cluster on no more than one stream.

        [#next-major-version: In the v3 API, we should consider restructuring this somehow,
        maybe by allowing LRS to go on the ADS stream, or maybe by moving some of the negotiation
        from the LRS stream here.]
        """

    @property
    def upstream_config(self) -> envoy.config.core.v3.extension_pb2.TypedExtensionConfig:
        """Optional customization and configuration of upstream connection pool, and upstream type.

        Currently this field only applies for HTTP traffic but is designed for eventual use for custom
        TCP upstreams.

        For HTTP traffic, Envoy will generally take downstream HTTP and send it upstream as upstream
        HTTP, using the http connection pool and the codec from ``http2_protocol_options``

        For routes where CONNECT termination is configured, Envoy will take downstream CONNECT
        requests and forward the CONNECT payload upstream over raw TCP using the tcp connection pool.

        The default pool used is the generic connection pool which creates the HTTP upstream for most
        HTTP requests, and the TCP upstream if CONNECT termination is configured.

        If users desire custom connection pool or upstream behavior, for example terminating
        CONNECT only if a custom filter indicates it is appropriate, the custom factories
        can be registered and configured here.
        [#extension-category: envoy.upstreams]
        """

    @property
    def track_cluster_stats(self) -> global___TrackClusterStats:
        """Configuration to track optional cluster stats."""

    @property
    def preconnect_policy(self) -> global___Cluster.PreconnectPolicy:
        """Preconnect configuration for this cluster."""

    def __init__(
        self,
        *,
        transport_socket_matches: collections.abc.Iterable[global___Cluster.TransportSocketMatch] | None = ...,
        name: builtins.str = ...,
        alt_stat_name: builtins.str = ...,
        type: global___Cluster.DiscoveryType.ValueType = ...,
        cluster_type: global___Cluster.CustomClusterType | None = ...,
        eds_cluster_config: global___Cluster.EdsClusterConfig | None = ...,
        connect_timeout: google.protobuf.duration_pb2.Duration | None = ...,
        per_connection_buffer_limit_bytes: google.protobuf.wrappers_pb2.UInt32Value | None = ...,
        lb_policy: global___Cluster.LbPolicy.ValueType = ...,
        load_assignment: envoy.config.endpoint.v3.endpoint_pb2.ClusterLoadAssignment | None = ...,
        health_checks: collections.abc.Iterable[envoy.config.core.v3.health_check_pb2.HealthCheck] | None = ...,
        max_requests_per_connection: google.protobuf.wrappers_pb2.UInt32Value | None = ...,
        circuit_breakers: envoy.config.cluster.v3.circuit_breaker_pb2.CircuitBreakers | None = ...,
        upstream_http_protocol_options: envoy.config.core.v3.protocol_pb2.UpstreamHttpProtocolOptions | None = ...,
        common_http_protocol_options: envoy.config.core.v3.protocol_pb2.HttpProtocolOptions | None = ...,
        http_protocol_options: envoy.config.core.v3.protocol_pb2.Http1ProtocolOptions | None = ...,
        http2_protocol_options: envoy.config.core.v3.protocol_pb2.Http2ProtocolOptions | None = ...,
        typed_extension_protocol_options: collections.abc.Mapping[builtins.str, google.protobuf.any_pb2.Any] | None = ...,
        dns_refresh_rate: google.protobuf.duration_pb2.Duration | None = ...,
        dns_failure_refresh_rate: global___Cluster.RefreshRate | None = ...,
        respect_dns_ttl: builtins.bool = ...,
        dns_lookup_family: global___Cluster.DnsLookupFamily.ValueType = ...,
        dns_resolvers: collections.abc.Iterable[envoy.config.core.v3.address_pb2.Address] | None = ...,
        use_tcp_for_dns_lookups: builtins.bool = ...,
        dns_resolution_config: envoy.config.core.v3.resolver_pb2.DnsResolutionConfig | None = ...,
        typed_dns_resolver_config: envoy.config.core.v3.extension_pb2.TypedExtensionConfig | None = ...,
        wait_for_warm_on_init: google.protobuf.wrappers_pb2.BoolValue | None = ...,
        outlier_detection: envoy.config.cluster.v3.outlier_detection_pb2.OutlierDetection | None = ...,
        cleanup_interval: google.protobuf.duration_pb2.Duration | None = ...,
        upstream_bind_config: envoy.config.core.v3.address_pb2.BindConfig | None = ...,
        lb_subset_config: global___Cluster.LbSubsetConfig | None = ...,
        ring_hash_lb_config: global___Cluster.RingHashLbConfig | None = ...,
        maglev_lb_config: global___Cluster.MaglevLbConfig | None = ...,
        original_dst_lb_config: global___Cluster.OriginalDstLbConfig | None = ...,
        least_request_lb_config: global___Cluster.LeastRequestLbConfig | None = ...,
        round_robin_lb_config: global___Cluster.RoundRobinLbConfig | None = ...,
        common_lb_config: global___Cluster.CommonLbConfig | None = ...,
        transport_socket: envoy.config.core.v3.base_pb2.TransportSocket | None = ...,
        metadata: envoy.config.core.v3.base_pb2.Metadata | None = ...,
        protocol_selection: global___Cluster.ClusterProtocolSelection.ValueType = ...,
        upstream_connection_options: global___UpstreamConnectionOptions | None = ...,
        close_connections_on_host_health_failure: builtins.bool = ...,
        ignore_health_on_host_removal: builtins.bool = ...,
        filters: collections.abc.Iterable[envoy.config.cluster.v3.filter_pb2.Filter] | None = ...,
        load_balancing_policy: global___LoadBalancingPolicy | None = ...,
        lrs_server: envoy.config.core.v3.config_source_pb2.ConfigSource | None = ...,
        track_timeout_budgets: builtins.bool = ...,
        upstream_config: envoy.config.core.v3.extension_pb2.TypedExtensionConfig | None = ...,
        track_cluster_stats: global___TrackClusterStats | None = ...,
        preconnect_policy: global___Cluster.PreconnectPolicy | None = ...,
        connection_pool_per_downstream_connection: builtins.bool = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["circuit_breakers", b"circuit_breakers", "cleanup_interval", b"cleanup_interval", "cluster_discovery_type", b"cluster_discovery_type", "cluster_type", b"cluster_type", "common_http_protocol_options", b"common_http_protocol_options", "common_lb_config", b"common_lb_config", "connect_timeout", b"connect_timeout", "dns_failure_refresh_rate", b"dns_failure_refresh_rate", "dns_refresh_rate", b"dns_refresh_rate", "dns_resolution_config", b"dns_resolution_config", "eds_cluster_config", b"eds_cluster_config", "http2_protocol_options", b"http2_protocol_options", "http_protocol_options", b"http_protocol_options", "lb_config", b"lb_config", "lb_subset_config", b"lb_subset_config", "least_request_lb_config", b"least_request_lb_config", "load_assignment", b"load_assignment", "load_balancing_policy", b"load_balancing_policy", "lrs_server", b"lrs_server", "maglev_lb_config", b"maglev_lb_config", "max_requests_per_connection", b"max_requests_per_connection", "metadata", b"metadata", "original_dst_lb_config", b"original_dst_lb_config", "outlier_detection", b"outlier_detection", "per_connection_buffer_limit_bytes", b"per_connection_buffer_limit_bytes", "preconnect_policy", b"preconnect_policy", "ring_hash_lb_config", b"ring_hash_lb_config", "round_robin_lb_config", b"round_robin_lb_config", "track_cluster_stats", b"track_cluster_stats", "transport_socket", b"transport_socket", "type", b"type", "typed_dns_resolver_config", b"typed_dns_resolver_config", "upstream_bind_config", b"upstream_bind_config", "upstream_config", b"upstream_config", "upstream_connection_options", b"upstream_connection_options", "upstream_http_protocol_options", b"upstream_http_protocol_options", "wait_for_warm_on_init", b"wait_for_warm_on_init"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["alt_stat_name", b"alt_stat_name", "circuit_breakers", b"circuit_breakers", "cleanup_interval", b"cleanup_interval", "close_connections_on_host_health_failure", b"close_connections_on_host_health_failure", "cluster_discovery_type", b"cluster_discovery_type", "cluster_type", b"cluster_type", "common_http_protocol_options", b"common_http_protocol_options", "common_lb_config", b"common_lb_config", "connect_timeout", b"connect_timeout", "connection_pool_per_downstream_connection", b"connection_pool_per_downstream_connection", "dns_failure_refresh_rate", b"dns_failure_refresh_rate", "dns_lookup_family", b"dns_lookup_family", "dns_refresh_rate", b"dns_refresh_rate", "dns_resolution_config", b"dns_resolution_config", "dns_resolvers", b"dns_resolvers", "eds_cluster_config", b"eds_cluster_config", "filters", b"filters", "health_checks", b"health_checks", "http2_protocol_options", b"http2_protocol_options", "http_protocol_options", b"http_protocol_options", "ignore_health_on_host_removal", b"ignore_health_on_host_removal", "lb_config", b"lb_config", "lb_policy", b"lb_policy", "lb_subset_config", b"lb_subset_config", "least_request_lb_config", b"least_request_lb_config", "load_assignment", b"load_assignment", "load_balancing_policy", b"load_balancing_policy", "lrs_server", b"lrs_server", "maglev_lb_config", b"maglev_lb_config", "max_requests_per_connection", b"max_requests_per_connection", "metadata", b"metadata", "name", b"name", "original_dst_lb_config", b"original_dst_lb_config", "outlier_detection", b"outlier_detection", "per_connection_buffer_limit_bytes", b"per_connection_buffer_limit_bytes", "preconnect_policy", b"preconnect_policy", "protocol_selection", b"protocol_selection", "respect_dns_ttl", b"respect_dns_ttl", "ring_hash_lb_config", b"ring_hash_lb_config", "round_robin_lb_config", b"round_robin_lb_config", "track_cluster_stats", b"track_cluster_stats", "track_timeout_budgets", b"track_timeout_budgets", "transport_socket", b"transport_socket", "transport_socket_matches", b"transport_socket_matches", "type", b"type", "typed_dns_resolver_config", b"typed_dns_resolver_config", "typed_extension_protocol_options", b"typed_extension_protocol_options", "upstream_bind_config", b"upstream_bind_config", "upstream_config", b"upstream_config", "upstream_connection_options", b"upstream_connection_options", "upstream_http_protocol_options", b"upstream_http_protocol_options", "use_tcp_for_dns_lookups", b"use_tcp_for_dns_lookups", "wait_for_warm_on_init", b"wait_for_warm_on_init"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["cluster_discovery_type", b"cluster_discovery_type"]) -> typing.Literal["type", "cluster_type"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["lb_config", b"lb_config"]) -> typing.Literal["ring_hash_lb_config", "maglev_lb_config", "original_dst_lb_config", "least_request_lb_config", "round_robin_lb_config"] | None: ...

global___Cluster = Cluster

@typing.final
class LoadBalancingPolicy(google.protobuf.message.Message):
    """Extensible load balancing policy configuration.

    Every LB policy defined via this mechanism will be identified via a unique name using reverse
    DNS notation. If the policy needs configuration parameters, it must define a message for its
    own configuration, which will be stored in the config field. The name of the policy will tell
    clients which type of message they should expect to see in the config field.

    Note that there are cases where it is useful to be able to independently select LB policies
    for choosing a locality and for choosing an endpoint within that locality. For example, a
    given deployment may always use the same policy to choose the locality, but for choosing the
    endpoint within the locality, some clusters may use weighted-round-robin, while others may
    use some sort of session-based balancing.

    This can be accomplished via hierarchical LB policies, where the parent LB policy creates a
    child LB policy for each locality. For each request, the parent chooses the locality and then
    delegates to the child policy for that locality to choose the endpoint within the locality.

    To facilitate this, the config message for the top-level LB policy may include a field of
    type LoadBalancingPolicy that specifies the child policy.
    """

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    @typing.final
    class Policy(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        TYPED_EXTENSION_CONFIG_FIELD_NUMBER: builtins.int
        @property
        def typed_extension_config(self) -> envoy.config.core.v3.extension_pb2.TypedExtensionConfig:
            """[#extension-category: envoy.load_balancing_policies]"""

        def __init__(
            self,
            *,
            typed_extension_config: envoy.config.core.v3.extension_pb2.TypedExtensionConfig | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["typed_extension_config", b"typed_extension_config"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["typed_extension_config", b"typed_extension_config"]) -> None: ...

    POLICIES_FIELD_NUMBER: builtins.int
    @property
    def policies(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LoadBalancingPolicy.Policy]:
        """Each client will iterate over the list in order and stop at the first policy that it
        supports. This provides a mechanism for starting to use new LB policies that are not yet
        supported by all clients.
        """

    def __init__(
        self,
        *,
        policies: collections.abc.Iterable[global___LoadBalancingPolicy.Policy] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["policies", b"policies"]) -> None: ...

global___LoadBalancingPolicy = LoadBalancingPolicy

@typing.final
class UpstreamConnectionOptions(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    TCP_KEEPALIVE_FIELD_NUMBER: builtins.int
    SET_LOCAL_INTERFACE_NAME_ON_UPSTREAM_CONNECTIONS_FIELD_NUMBER: builtins.int
    set_local_interface_name_on_upstream_connections: builtins.bool
    """If enabled, associates the interface name of the local address with the upstream connection.
    This can be used by extensions during processing of requests. The association mechanism is
    implementation specific. Defaults to false due to performance concerns.
    """
    @property
    def tcp_keepalive(self) -> envoy.config.core.v3.address_pb2.TcpKeepalive:
        """If set then set SO_KEEPALIVE on the socket to enable TCP Keepalives."""

    def __init__(
        self,
        *,
        tcp_keepalive: envoy.config.core.v3.address_pb2.TcpKeepalive | None = ...,
        set_local_interface_name_on_upstream_connections: builtins.bool = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["tcp_keepalive", b"tcp_keepalive"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["set_local_interface_name_on_upstream_connections", b"set_local_interface_name_on_upstream_connections", "tcp_keepalive", b"tcp_keepalive"]) -> None: ...

global___UpstreamConnectionOptions = UpstreamConnectionOptions

@typing.final
class TrackClusterStats(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    TIMEOUT_BUDGETS_FIELD_NUMBER: builtins.int
    REQUEST_RESPONSE_SIZES_FIELD_NUMBER: builtins.int
    timeout_budgets: builtins.bool
    """If timeout_budgets is true, the :ref:`timeout budget histograms
    <config_cluster_manager_cluster_stats_timeout_budgets>` will be published for each
    request. These show what percentage of a request's per try and global timeout was used. A value
    of 0 would indicate that none of the timeout was used or that the timeout was infinite. A value
    of 100 would indicate that the request took the entirety of the timeout given to it.
    """
    request_response_sizes: builtins.bool
    """If request_response_sizes is true, then the :ref:`histograms
    <config_cluster_manager_cluster_stats_request_response_sizes>`  tracking header and body sizes
    of requests and responses will be published.
    """
    def __init__(
        self,
        *,
        timeout_budgets: builtins.bool = ...,
        request_response_sizes: builtins.bool = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["request_response_sizes", b"request_response_sizes", "timeout_budgets", b"timeout_budgets"]) -> None: ...

global___TrackClusterStats = TrackClusterStats
