import enum
import math
from dataclasses import dataclass
from envoy.config.cluster.v3 import circuit_breaker_pb2, cluster_pb2
from envoy.config.core.v3 import address_pb2, base_pb2, protocol_pb2
from envoy.config.endpoint.v3 import endpoint_components_pb2, endpoint_pb2
from envoy.config.listener.v3 import listener_components_pb2, listener_pb2
from envoy.config.route.v3 import route_components_pb2, route_pb2
from envoy.extensions.filters.http.cors.v3 import cors_pb2
from envoy.extensions.filters.http.grpc_json_transcoder.v3 import (
    transcoder_pb2,
)
from envoy.extensions.filters.http.lua.v3 import lua_pb2
from envoy.extensions.filters.http.router.v3 import router_pb2
from envoy.extensions.filters.network.http_connection_manager.v3 import (
    http_connection_manager_pb2,
)
from envoy.extensions.transport_sockets.tls.v3 import common_pb2, tls_pb2
from envoy.extensions.upstreams.http.v3 import http_protocol_options_pb2
from envoy.type.matcher.v3 import regex_pb2, string_pb2
from google.protobuf import any_pb2
from google.protobuf.descriptor_pb2 import FileDescriptorSet
from google.protobuf.duration_pb2 import Duration
from google.protobuf.message import Message
from google.protobuf.wrappers_pb2 import UInt32Value
from pathlib import Path
from rbt.v1alpha1 import database_pb2
from reboot.routing.filters.lua import (
    ADD_HEADER_X_REBOOT_APPLICATION_ID_TEMPLATE_FILENAME,
    COMPUTE_HEADER_X_REBOOT_SERVER_ID_TEMPLATE_FILENAME,
    MANGLED_HTTP_PATH_FILENAME,
    REMOVE_JSON_TRAILERS_FILENAME,
    load_lua,
    render_lua_template,
)
from rebootdev.aio.headers import (
    APPLICATION_ID_HEADER,
    AUTHORIZATION_HEADER,
    CALLER_ID_HEADER,
    IDEMPOTENCY_KEY_HEADER,
    SERVER_ID_HEADER,
    STATE_REF_HEADER,
    WORKFLOW_ID_HEADER,
)
from rebootdev.aio.types import ApplicationId, ServerId
from rebootdev.helpers import get_path_prefixes_from_file_descriptor_set
from rebootdev.run_environments import on_cloud
from rebootdev.settings import MAX_GRPC_RESPONSE_SIZE_BYTES


@dataclass
class ServerAddress:
    host: str
    grpc_port: int
    websocket_port: int
    http_port: int


@dataclass
class ServerInfo:
    server_id: ServerId
    address: ServerAddress
    shards: list[database_pb2.ShardInfo]
    # Whether this server is running on the local replica.
    on_this_replica: bool


class ClusterKind(enum.Enum):
    GRPC = enum.auto()
    WEBSOCKET = enum.auto()
    HTTP = enum.auto()


ZERO_SECONDS = Duration()
ZERO_SECONDS.FromSeconds(0)


# Helper for packing an `Any`.
#
# TODO: replace with `from google.protobuf.any import pack` once we've
# upgraded to a version of protobuf that includes this.
def any_pack(message: Message) -> any_pb2.Any:
    any = any_pb2.Any()
    any.Pack(message)
    return any


def _shard_keyrange_starts(num_shards: int) -> list[int]:
    NUM_BYTE_VALUES = 256
    if num_shards > NUM_BYTE_VALUES:
        raise ValueError(
            f"'num_shards' must be less than or equal to "
            f"{NUM_BYTE_VALUES}; got {num_shards}."
        )
    if not math.log2(num_shards).is_integer():
        raise ValueError(
            f"'num_shards' must be a power of 2; got {num_shards}."
        )
    shard_size = NUM_BYTE_VALUES // num_shards
    # The first shard always begins at the very beginning of the key range.
    return [i * shard_size for i in range(0, num_shards)]


def _lua_any(source_code: str) -> any_pb2.Any:
    return any_pack(
        lua_pb2.Lua(
            default_source_code=base_pb2.DataSource(
                inline_string=source_code,
            ),
        )
    )


def _http_filter_add_header_x_reboot_application_id(
    application_id: ApplicationId
) -> http_connection_manager_pb2.HttpFilter:
    template_input = {
        'application_id': application_id,
    }
    filter_content = render_lua_template(
        ADD_HEADER_X_REBOOT_APPLICATION_ID_TEMPLATE_FILENAME, template_input
    )

    return http_connection_manager_pb2.HttpFilter(
        name="reboot.add_header_x_reboot_application_id",
        # TODO(rjh): can we replace this with a standard add-header filter?
        typed_config=_lua_any(filter_content)
    )


@dataclass
class RouteMapEntry:
    # The start of this shard's key range. Conceptually this represents several
    # `byte`s, but it's encoded as a Lua-safe string literal with escape
    # characters (e.g. "\x41\x00").
    shard_keyrange_start: str
    # The server ID that traffic matching this entry should get sent to.
    server_id: ServerId

    @classmethod
    def from_key_bytes(cls, first_key_bytes: bytes, server_id: str):
        lua_escaped_bytes = ''.join(f'\\x{b:02x}' for b in first_key_bytes)
        return cls(
            shard_keyrange_start=lua_escaped_bytes,
            server_id=server_id,
        )


def _http_filter_compute_header_x_reboot_server_id(
    servers: list[ServerInfo],
) -> http_connection_manager_pb2.HttpFilter:
    # We must give Lua the list of all of the shards sorted by their
    # first key, for ~efficient lookup.
    all_shards: list[database_pb2.ShardInfo] = [
        shard for server in servers for shard in server.shards
    ]
    all_shards.sort(key=lambda shard: shard.shard_first_key)

    server_id_by_shard_id = {
        shard.shard_id: server.server_id for server in servers
        for shard in server.shards
    }

    route_map = [
        RouteMapEntry.from_key_bytes(
            first_key_bytes=shard.shard_first_key,
            server_id=server_id_by_shard_id[shard.shard_id],
        ) for shard in all_shards
    ]

    server_ids = [server.server_id for server in servers]

    this_replica_server_ids = [
        server.server_id for server in servers if server.on_this_replica
    ]

    template_input = {
        'server_ids': server_ids,
        'this_replica_server_ids': this_replica_server_ids,
        'route_map': route_map,
    }
    filter_content = render_lua_template(
        COMPUTE_HEADER_X_REBOOT_SERVER_ID_TEMPLATE_FILENAME, template_input
    )
    return http_connection_manager_pb2.HttpFilter(
        name="reboot.compute_header_x_reboot_server_id",
        typed_config=_lua_any(filter_content),
    )


def _http_filter_mangled_http_path() -> http_connection_manager_pb2.HttpFilter:
    # The contents of the MANGLED_HTTP_PATH_FILENAME Lua file need to still be
    # wrapped in an `envoy_on_request` function, since `routing_filter.lua.j2`
    # also uses the same content.
    filter_content = (
        "function envoy_on_request(request_handle)\n"
        f"{load_lua(MANGLED_HTTP_PATH_FILENAME)}\n"
        "end\n"
    )
    return http_connection_manager_pb2.HttpFilter(
        name="reboot.mangled_http_path",
        typed_config=_lua_any(filter_content),
    )


def _http_filter_remove_json_trailers(
) -> http_connection_manager_pb2.HttpFilter:
    filter_content = load_lua(REMOVE_JSON_TRAILERS_FILENAME)
    return http_connection_manager_pb2.HttpFilter(
        name="reboot.remove_json_trailers",
        typed_config=_lua_any(filter_content),
    )


def _http_filter_cors() -> http_connection_manager_pb2.HttpFilter:
    # TODO(rjh): set the `cors` policy here, instead of in `VirtualHost`; the
    #            latter is deprecated. Share code with `network_managers.py`.
    return http_connection_manager_pb2.HttpFilter(
        name="envoy.filters.http.cors",
        typed_config=any_pack(cors_pb2.Cors()),
    )


GRPC_JSON_TRANSCODER_HTTP_FILTER_NAME = "envoy.filters.http.grpc_json_transcoder"

# For those routes where we don't need the transcoding filter we have
# an empty configuration so it never activates (without this it has
# been shown to confuse the traffic).
EMPTY_GRPC_JSON_TRANSCODER_CONFIG = any_pack(
    transcoder_pb2.GrpcJsonTranscoder(
        # This field's presence is required (the listener will be rejected
        # without it), but we can leave it empty.
        proto_descriptor_bin=b"",
    )
)


def _http_filter_grpc_json_transcoder(
    file_descriptor_set: FileDescriptorSet,
) -> http_connection_manager_pb2.HttpFilter:
    return http_connection_manager_pb2.HttpFilter(
        name=GRPC_JSON_TRANSCODER_HTTP_FILTER_NAME,
        typed_config=any_pack(
            # ATTENTION: if you update any of this, also update the matching
            #            values in `envoy_filter_generator.py` method
            #            `generate_transcoding_filter`.
            # TODO(rjh): either obsolete `generate_transcoding_filter`,
            #            or use it, or share settings at least.
            transcoder_pb2.GrpcJsonTranscoder(
                convert_grpc_status=True,
                print_options=transcoder_pb2.GrpcJsonTranscoder.PrintOptions(
                    add_whitespace=True,
                    always_print_enums_as_ints=False,
                    always_print_primitive_fields=True,
                    preserve_proto_field_names=False,
                ),
                # The gRPC backend would be unhappy to receive
                # non-gRPC `application/json` traffic and would reply
                # with a `503`, which is not a good user experience
                # and not helpful in debugging. In addition, we've
                # observed that that interaction between Envoy and
                # gRPC triggers a bug in one of those two that will
                # cause subsequent valid requests to fail.
                #
                # See: https://github.com/reboot-dev/mono/issues/3074.
                #
                # Instead, simply (correctly) reject invalid
                # `application/json` traffic with a 404.
                request_validation_options=(
                    transcoder_pb2.GrpcJsonTranscoder.RequestValidationOptions(
                        reject_unknown_method=True,
                    )
                ),
                services=[
                    f"{file_descriptor_proto.package}.{service.name}"
                    for file_descriptor_proto in file_descriptor_set.file
                    for service in file_descriptor_proto.service
                ],
                proto_descriptor_bin=file_descriptor_set.SerializeToString(),
            )
        )
    )


def _http_filter_router() -> http_connection_manager_pb2.HttpFilter:
    return http_connection_manager_pb2.HttpFilter(
        name="envoy.filters.http.router",
        typed_config=any_pack(router_pb2.Router()),
    )


def _routes_for_server(
    application_id: ApplicationId,
    server: ServerInfo,
    kind: ClusterKind,
    file_descriptor_set: FileDescriptorSet,
    trust_caller_id: bool,
) -> list[route_components_pb2.Route]:
    # Every server gets routes to the websocket port, the gRPC
    # port, and the HTTP "catchall" port as described below.
    #
    # See corresponding routes for Istio in
    # reboot/controller/network_managers.py.

    cluster_name = _cluster_name(
        application_id=application_id,
        server_id=server.server_id,
        kind=kind,
    )

    server_header_matcher = route_components_pb2.HeaderMatcher(
        name=SERVER_ID_HEADER,
        string_match=string_pb2.StringMatcher(
            exact=server.server_id,
        ),
    )

    if kind == ClusterKind.GRPC:
        return [
            # This route sends all traffic with the
            # 'x-reboot-server-id' header and the 'content-type:
            # application/grpc' header to the gRPC port.
            route_components_pb2.Route(
                match=route_components_pb2.RouteMatch(
                    prefix="/",
                    headers=[
                        server_header_matcher,
                        route_components_pb2.HeaderMatcher(
                            name="content-type",
                            string_match=string_pb2.StringMatcher(
                                exact="application/grpc",
                            ),
                        ),
                    ],
                    grpc=route_components_pb2.RouteMatch.GrpcRouteMatchOptions(
                    ),
                ),
                route=route_components_pb2.RouteAction(
                    cluster=cluster_name,
                    max_stream_duration=route_components_pb2.RouteAction.
                    MaxStreamDuration(grpc_timeout_header_max=ZERO_SECONDS)
                ),
                request_headers_to_remove=(
                    # If we don't trust the caller ID header, remove it
                    # so that the upstream server can't be misled.
                    [CALLER_ID_HEADER] if not trust_caller_id else []
                ),
            ),
            # This route sends all traffic with the
            # 'x-reboot-server-id' header and an exact path of '/'
            # to the gRPC port because currently that is what serves
            # '/'.
            route_components_pb2.Route(
                match=route_components_pb2.RouteMatch(
                    path="/",
                    headers=[server_header_matcher],
                    grpc=route_components_pb2.RouteMatch.GrpcRouteMatchOptions(
                    ),
                ),
                route=route_components_pb2.RouteAction(
                    cluster=cluster_name,
                    max_stream_duration=route_components_pb2.RouteAction.
                    MaxStreamDuration(grpc_timeout_header_max=ZERO_SECONDS)
                ),
            ),
        ] + [
            # These routes send all traffic with the
            # 'x-reboot-server-id' header and a prefix path from
            # the file descriptor set of the application to the gRPC
            # port (where it will get gRPC-JSON transcoded).
            route_components_pb2.Route(
                match=route_components_pb2.RouteMatch(
                    prefix=prefix,
                    headers=[server_header_matcher],
                ),
                route=route_components_pb2.RouteAction(
                    cluster=cluster_name,
                    max_stream_duration=route_components_pb2.RouteAction.
                    MaxStreamDuration(grpc_timeout_header_max=ZERO_SECONDS)
                ),
            ) for prefix in get_path_prefixes_from_file_descriptor_set(
                file_descriptor_set,
            )
            # We skip over the path '/' because we cover it above as
            # an exact path not a prefix here otherwise it would catch
            # everything which we don't want because we want
            # everything else to be caught below for the HTTP port.
            if prefix != "/"
        ]

    elif kind == ClusterKind.HTTP:
        return [
            route_components_pb2.Route(
                match=route_components_pb2.RouteMatch(
                    prefix="/",
                    headers=[server_header_matcher],
                ),
                route=route_components_pb2.RouteAction(
                    cluster=cluster_name,
                    # Set `max_stream_duration` to 0 to disable the timeout for this route.
                    max_stream_duration=route_components_pb2.RouteAction.
                    MaxStreamDuration(grpc_timeout_header_max=ZERO_SECONDS)
                ),
                typed_per_filter_config={
                    GRPC_JSON_TRANSCODER_HTTP_FILTER_NAME:
                        EMPTY_GRPC_JSON_TRANSCODER_CONFIG,
                },
            )
        ]

    assert kind == ClusterKind.WEBSOCKET

    return [
        route_components_pb2.Route(
            match=route_components_pb2.RouteMatch(
                prefix="/",
                headers=[
                    route_components_pb2.HeaderMatcher(
                        name="upgrade",
                        string_match=string_pb2.StringMatcher(
                            exact="websocket",
                        ),
                    ),
                    server_header_matcher,
                ],
            ),
            route=route_components_pb2.RouteAction(
                cluster=cluster_name,
                # TODO: should we also include a `max_stream_duration`
                # here or are the websocket pings sufficient to keep
                # the connection from getting closed?
            ),
            typed_per_filter_config={
                GRPC_JSON_TRANSCODER_HTTP_FILTER_NAME:
                    EMPTY_GRPC_JSON_TRANSCODER_CONFIG,
            },
        )
    ]


def _filter_http_connection_manager(
    application_id: ApplicationId,
    servers: list[ServerInfo],
    file_descriptor_set: FileDescriptorSet,
    trust_caller_id: bool,
) -> listener_components_pb2.Filter:
    http_connection_manager = http_connection_manager_pb2.HttpConnectionManager(
        stat_prefix="grpc_json",
        stream_idle_timeout=ZERO_SECONDS,
        upgrade_configs=[
            http_connection_manager_pb2.HttpConnectionManager.UpgradeConfig(
                upgrade_type="websocket",
            ),
        ],
        # This is the configuration for a _local_ envoy. It will never
        # have a trusted (mTLS) connection with a peer. However, it may
        # sit behind other proxies that DO have mTLS connections. Don't
        # drop the `x-forwarded-client-cert` header if it exists.
        forward_client_cert_details=(
            http_connection_manager_pb2.HttpConnectionManager.
            ForwardClientCertDetails.ALWAYS_FORWARD_ONLY
        ),
        # TODO(rjh): this is a duration; but leaving out is the same as 0s, presumably?
        # stream_idle_timeout="0s",
        codec_type=http_connection_manager_pb2.HttpConnectionManager.AUTO,
        route_config=route_pb2.RouteConfiguration(
            name="local_route",
            virtual_hosts=[
                route_components_pb2.VirtualHost(
                    name="local_service",
                    domains=["*"],
                    # TODO(rjh): setting the `cors` policy here is deprecated,
                    #            instead we should set it directly on the
                    #            `envoy.filters.http.cors` filter in the filter
                    #            chain.
                    cors=route_components_pb2.CorsPolicy(
                        allow_origin_string_match=[
                            string_pb2.StringMatcher(
                                safe_regex=regex_pb2.RegexMatcher(
                                    # TODO(rjh): deprecated; can remove?
                                    google_re2=regex_pb2.RegexMatcher.
                                    GoogleRE2(),
                                    regex="\\*",
                                ),
                            )
                        ],
                        allow_methods="GET, PUT, DELETE, POST, OPTIONS",
                        allow_headers=
                        f"{APPLICATION_ID_HEADER},{STATE_REF_HEADER},{SERVER_ID_HEADER},{IDEMPOTENCY_KEY_HEADER},{WORKFLOW_ID_HEADER},keep-alive,user-agent,cache-control,content-type,content-transfer-encoding,x-accept-content-transfer-encoding,x-accept-response-streaming,x-user-agent,grpc-timeout,{AUTHORIZATION_HEADER}",
                        max_age="1728000",
                        expose_headers="grpc-status,grpc-message",
                    ),
                    routes=[
                        route for server in servers for kind in [
                            # Always list the route for the websocket first,
                            # since its matching is more specific.
                            ClusterKind.WEBSOCKET,
                            ClusterKind.GRPC,
                            ClusterKind.HTTP,
                        ] for route in _routes_for_server(
                            application_id=application_id,
                            server=server,
                            kind=kind,
                            file_descriptor_set=file_descriptor_set,
                            trust_caller_id=trust_caller_id,
                        )
                    ],
                ),
            ],
        ),
        http_filters=[
            # Add the remove json trailers filter first so it's the last to
            # process responses (after transcoding and all other filters).
            # Response filters are processed in reverse order.
            _http_filter_remove_json_trailers(),
            _http_filter_add_header_x_reboot_application_id(application_id),
            # Before picking a server, we need to possibly de-mangle the path
            # to extract any relevant headers.
            _http_filter_mangled_http_path(),
            _http_filter_compute_header_x_reboot_server_id(servers),
            # Define CORS filter before the gRPC-JSON transcoding
            # filter, because otherwise perfectly-fine CORS requests
            # get rejected by the gRPC-JSON transcoding filter.
            _http_filter_cors(),
            # The gRPC-JSON transcoder filter comes before routing,
            # but note that we also need to override it for websocket
            # routes via a per-route config because otherwise it has
            # been shown to confuse traffic.
            _http_filter_grpc_json_transcoder(
                file_descriptor_set=file_descriptor_set,
            ),
            _http_filter_router(),
        ]
    )

    return listener_components_pb2.Filter(
        name="envoy.filters.network.http_connection_manager",
        typed_config=any_pack(http_connection_manager),
    )


def _tls_socket(
    certificate_path: Path, key_path: Path
) -> base_pb2.TransportSocket:
    return base_pb2.TransportSocket(
        name="envoy.transport_sockets.tls",
        typed_config=any_pack(
            tls_pb2.DownstreamTlsContext(
                common_tls_context=tls_pb2.CommonTlsContext(
                    alpn_protocols=["h2"],
                    tls_certificates=[
                        common_pb2.TlsCertificate(
                            certificate_chain=base_pb2.DataSource(
                                filename=str(certificate_path),
                            ),
                            private_key=base_pb2.DataSource(
                                filename=str(key_path),
                            ),
                        ),
                    ],
                    validation_context=common_pb2.CertificateValidationContext(
                        trusted_ca=base_pb2.DataSource(
                            filename=str(certificate_path),
                        ),
                    ),
                ),
            )
        ),
    )


def listeners(
    application_id: ApplicationId,
    servers: list[ServerInfo],
    file_descriptor_set: FileDescriptorSet,
    trusted_host: str,
    trusted_port: int,  # 0 = pick any free port.
    public_port: int,
    use_tls: bool,
    certificate_path: Path,
    key_path: Path,
) -> list[listener_pb2.Listener]:

    @dataclass
    class ListenerConfig:
        name: str
        host: str
        port: int
        use_tls: bool
        trust_caller_id: bool

    listeners = [
        # The public listener takes traffic from anywhere (which may
        # be TLS-encrypted) on the port specified by the user.
        ListenerConfig(
            name="public",
            host="0.0.0.0",
            port=public_port,
            use_tls=use_tls,
            # On the Reboot Cloud, proxies ensure that the caller ID is
            # set truthfully. Outside Reboot Cloud we can't trust public
            # traffic to not be lying about its caller ID.
            trust_caller_id=on_cloud(),
        ),
        # The trusted port takes traffic only from the local application
        # - no TLS is needed, nor supported.
        ListenerConfig(
            name="trusted",
            host=trusted_host,
            port=trusted_port,
            use_tls=False,
            trust_caller_id=True,
        ),
    ]

    return [
        listener_pb2.Listener(
            name=listener.name,
            address=address_pb2.Address(
                socket_address=address_pb2.SocketAddress(
                    address=listener.host,
                    port_value=listener.port,
                ),
            ),
            filter_chains=[
                listener_components_pb2.FilterChain(
                    filters=[
                        _filter_http_connection_manager(
                            application_id=application_id,
                            servers=servers,
                            file_descriptor_set=file_descriptor_set,
                            trust_caller_id=listener.trust_caller_id,
                        ),
                    ],
                    transport_socket=_tls_socket(certificate_path, key_path)
                    if listener.use_tls else None,
                )
            ],
            # See: https://github.com/reboot-dev/mono/issues/3944.
            per_connection_buffer_limit_bytes=UInt32Value(
                value=MAX_GRPC_RESPONSE_SIZE_BYTES
            ),
        ) for listener in listeners
    ]


def _cluster_name(
    application_id: ApplicationId, server_id: ServerId, kind: ClusterKind
) -> str:
    # There are two forms the `ServerId`s can take here, neither of which may
    # be what you might expect:
    #
    # A) If there are multiple servers, server IDs are of the shape
    #    `[application-id]-[server-id]`, e.g. `foo-c123456`.
    #
    # B) If there is only a single server, the server ID is the
    #    application ID.
    #
    # This is a leftover of how local server management and Kubernetes
    # server management used to overlap.
    #
    # TODO(rjh): sanify the 'application_id' and 'server_id' relationship.
    #            We'd expect a server ID to be e.g. `c123456`.
    assert (
        server_id.startswith(f"{application_id}-") or
        server_id == application_id
    ), f"invalid server ID '{server_id}'"

    if kind == ClusterKind.GRPC:
        return f"{server_id}_grpc"

    elif kind == ClusterKind.HTTP:
        return f"{server_id}_http"

    else:
        assert (kind == ClusterKind.WEBSOCKET)
        return f"{server_id}_websocket"


def _cluster(
    application_id: ApplicationId,
    server_id: ServerId,
    host: str,
    port: int,
    kind: ClusterKind,
) -> cluster_pb2.Cluster:
    cluster_name = _cluster_name(application_id, server_id, kind)
    return cluster_pb2.Cluster(
        name=cluster_name,
        type=cluster_pb2.Cluster.STRICT_DNS,
        lb_policy=cluster_pb2.Cluster.ROUND_ROBIN,
        common_http_protocol_options=protocol_pb2.HttpProtocolOptions(
            idle_timeout=ZERO_SECONDS,
        ),
        dns_lookup_family=cluster_pb2.Cluster.V4_ONLY,
        # Setting empty HTTP2 protocol options is required to encourage Envoy to
        # use HTTP2 when talking to the upstream, so we MUST set this for gRPC
        # traffic - and for gRPC traffic ONLY, because websockets are NOT HTTP2.
        # TODO(rjh): this field is deprecated; migrate to
        #            `typed_extension_protocol_options`:
        #            https://github.com/envoyproxy/envoy/blob/45e0325f8d7ddf64a396798803a3fb7e6717257a/api/envoy/config/cluster/v3/cluster.proto#L927
        http2_protocol_options=protocol_pb2.Http2ProtocolOptions()
        if kind == ClusterKind.GRPC else None,
        load_assignment=endpoint_pb2.ClusterLoadAssignment(
            cluster_name=cluster_name,
            endpoints=[
                endpoint_components_pb2.LocalityLbEndpoints(
                    lb_endpoints=[
                        endpoint_components_pb2.LbEndpoint(
                            endpoint=endpoint_components_pb2.Endpoint(
                                address=address_pb2.Address(
                                    socket_address=address_pb2.SocketAddress(
                                        address=host,
                                        port_value=port,
                                    )
                                )
                            )
                        )
                    ],
                )
            ],
        ),
        # "Disable" all circuit breakers; they don't make much sense when all
        # traffic will flow to the host we're already on. Follows the pattern
        # suggested here: Follows the pattern suggested here:
        #   https://www.envoyproxy.io/docs/envoy/latest/faq/load_balancing/disable_circuit_breaking
        circuit_breakers=circuit_breaker_pb2.CircuitBreakers(
            thresholds=[
                circuit_breaker_pb2.CircuitBreakers.Thresholds(
                    priority=base_pb2.RoutingPriority.DEFAULT,
                    max_connections=UInt32Value(value=1000000000),
                    max_pending_requests=UInt32Value(value=1000000000),
                    max_requests=UInt32Value(value=1000000000),
                    max_retries=UInt32Value(value=1000000000),
                ),
                circuit_breaker_pb2.CircuitBreakers.Thresholds(
                    priority=base_pb2.RoutingPriority.HIGH,
                    max_connections=UInt32Value(value=1000000000),
                    max_pending_requests=UInt32Value(value=1000000000),
                    max_requests=UInt32Value(value=1000000000),
                    max_retries=UInt32Value(value=1000000000),
                ),
            ]
        ),
        # See: https://github.com/reboot-dev/mono/issues/3944.
        per_connection_buffer_limit_bytes=UInt32Value(
            value=MAX_GRPC_RESPONSE_SIZE_BYTES
        ),
    )


def clusters(
    application_id: ApplicationId,
    servers: list[ServerInfo],
) -> list[cluster_pb2.Cluster]:
    result: list[cluster_pb2.Cluster] = []

    for server in servers:
        # Every server serves both a gRPC and a WebSocket endpoint, on
        # different ports. They are therefore different clusters to Envoy.
        for kind in [
            ClusterKind.GRPC, ClusterKind.HTTP, ClusterKind.WEBSOCKET
        ]:
            result.append(
                _cluster(
                    application_id=application_id,
                    server_id=server.server_id,
                    host=server.address.host,
                    port=(
                        server.address.grpc_port
                        if kind == ClusterKind.GRPC else (
                            server.address.http_port if kind ==
                            ClusterKind.HTTP else server.address.websocket_port
                        )
                    ),
                    kind=kind,
                )
            )

    return result


def xds_cluster(
    host: str,
    port: int,
) -> cluster_pb2.Cluster:
    return cluster_pb2.Cluster(
        name="xds_cluster",
        type=cluster_pb2.Cluster.STRICT_DNS,
        dns_lookup_family=cluster_pb2.Cluster.V4_ONLY,
        load_assignment=endpoint_pb2.ClusterLoadAssignment(
            cluster_name="xds_cluster", endpoints=[
                endpoint_components_pb2.LocalityLbEndpoints(
                    lb_endpoints=[
                        endpoint_components_pb2.LbEndpoint(
                            endpoint=endpoint_components_pb2.Endpoint(
                                address=address_pb2.Address(
                                    socket_address=address_pb2.SocketAddress(
                                        address=host,
                                        port_value=port,
                                    )
                                )
                            )
                        )
                    ],
                )
            ]
        ),
        typed_extension_protocol_options={
            "envoy.extensions.upstreams.http.v3.HttpProtocolOptions":
                any_pack(
                    http_protocol_options_pb2.HttpProtocolOptions(
                        explicit_http_config=http_protocol_options_pb2.
                        HttpProtocolOptions.ExplicitHttpConfig(
                            # We must set this field explicitly (even to
                            # its default), since it's part of a oneof.
                            http2_protocol_options=protocol_pb2.
                            Http2ProtocolOptions(),
                        )
                    )
                )
        },
    )
