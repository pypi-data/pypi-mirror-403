# üöÄ Distributed Crawling - –®–≤–∏–¥–∫–∏–π –°—Ç–∞—Ä—Ç

## –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DISTRIBUTED ARCHITECTURE                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ   Windows/Linux Client                    Docker Server          ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ   ‚îÇ  Python Script   ‚îÇ                   ‚îÇ  Redis Container ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ  gc.crawl(...)   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ Redis ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  port: 6579      ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ  wrapper=config  ‚îÇ     Protocol      ‚îÇ                  ‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                   ‚îÇ              ‚îÇ
‚îÇ                                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                                          ‚îÇ  Celery Worker   ‚îÇ   ‚îÇ
‚îÇ                                          ‚îÇ  celery_unified  ‚îÇ   ‚îÇ
‚îÇ                                          ‚îÇ  queue: graph_   ‚îÇ   ‚îÇ
‚îÇ                                          ‚îÇ  crawler         ‚îÇ   ‚îÇ
‚îÇ                                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## 1. –ó–∞–ø—É—Å–∫ Docker (–Ω–∞ —Å–µ—Ä–≤–µ—Ä—ñ)

```bash
# –ö–ª–æ–Ω—É—î–º–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ–π (—è–∫—â–æ —â–µ –Ω–µ –∑—Ä–æ–±–ª–µ–Ω–æ)
git clone https://gitlab.com/demoprogrammer/web_graf.git
cd web_graf

# –ó–∞–ø—É—Å–∫–∞—î–º–æ Redis + Worker
docker compose up -d

# –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –ª–æ–≥–∏
docker compose logs -f worker
```

**–û—á—ñ–∫—É–≤–∞–Ω–∏–π –≤–∏–≤—ñ–¥ worker:**
```
celery@hostname ready.
[tasks]
  . graph_crawler.crawl_batch
  . graph_crawler.crawl_page
  . graph_crawler.health_check
```

## 2. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è

```bash
# –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ Redis
docker compose exec redis redis-cli ping
# –ü–æ–≤–∏–Ω–Ω–æ –≤–∏–≤–µ—Å—Ç–∏: PONG

# –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –ø–æ—Ä—Ç –∑–∑–æ–≤–Ω—ñ (—è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ)
nc -zv YOUR_SERVER_IP 6579
```

## 3. –ó–∞–ø—É—Å–∫ –∫–ª—ñ—î–Ω—Ç–∞ (–Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ñ–π –º–∞—à–∏–Ω—ñ)

```python
import graph_crawler as gc
from graph_crawler import AsyncDriver

# –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è distributed crawling
config = {
    "broker": {
        "type": "redis",
        "host": "YOUR_SERVER_IP",  # IP –≤–∞—à–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ –∑ Docker
        "port": 6579               # –ü–æ—Ä—Ç Redis
    },
    "database": {"type": "memory"}
}

# –ó–∞–ø—É—Å–∫ –∫—Ä–∞—É–ª—ñ–Ω–≥—É
graph = gc.crawl(
    "https://example.com",
    max_depth=2,
    max_pages=50,
    wrapper=config,           # ‚Üê –í–º–∏–∫–∞—î distributed —Ä–µ–∂–∏–º
    driver=AsyncDriver,       # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î async driver –Ω–∞ –≤–æ—Ä–∫–µ—Ä–∞—Ö
    timeout=120               # Timeout 2 —Ö–≤–∏–ª–∏–Ω–∏
)

print(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(graph.nodes)} —Å—Ç–æ—Ä—ñ–Ω–æ–∫")
```

## 4. Troubleshooting

### ‚ùå Tasks –Ω–µ –≤–∏–∫–æ–Ω—É—é—Ç—å—Å—è (worker –Ω–µ –±–∞—á–∏—Ç—å)

**–ü—Ä–∏—á–∏–Ω–∞:** –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞ —á–µ—Ä–≥–∞

**–†—ñ—à–µ–Ω–Ω—è:** –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—å —â–æ worker —Å–ª—É—Ö–∞—î —á–µ—Ä–≥—É `graph_crawler`:
```bash
docker compose logs worker | grep "queues"
# –ü–æ–≤–∏–Ω–Ω–æ –ø–æ–∫–∞–∑–∞—Ç–∏: .> package_crawler    exchange=...
```

### ‚ùå Connection refused –¥–æ Redis

**–ü—Ä–∏—á–∏–Ω–∞:** –§–∞–π—Ä–≤–æ–ª –∞–±–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –ø–æ—Ä—Ç

**–†—ñ—à–µ–Ω–Ω—è:**
```bash
# –ù–∞ —Å–µ—Ä–≤–µ—Ä—ñ
sudo ufw allow 6579/tcp

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞
netstat -tlnp | grep 6579
```

### ‚ùå Worker –Ω–µ —Å—Ç–∞—Ä—Ç—É—î

**–ü—Ä–∏—á–∏–Ω–∞:** –ü–æ–º–∏–ª–∫–∏ –≤ –∫–æ–¥—ñ

**–†—ñ—à–µ–Ω–Ω—è:**
```bash
docker compose logs worker
# –ü–æ–¥–∏–≤—ñ—Ç—å—Å—è –Ω–∞ –ø–æ–º–∏–ª–∫–∏ —ñ–º–ø–æ—Ä—Ç—É –∞–±–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
```

## 5. docker-compose.yml (—Ä–µ—Ñ–µ—Ä–µ–Ω—Å)

```yaml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    container_name: crawler_redis
    ports:
      - "6579:6379"  # –î–æ—Å—Ç—É–ø–Ω–∏–π –∑–∑–æ–≤–Ω—ñ
    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - crawler_net

  worker:
    build: .
    container_name: crawler_worker_1
    command: celery -A package_crawler.infrastructure.messaging.celery_unified worker --loglevel=info --concurrency=2 -Q package_crawler
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    depends_on:
      - redis
    networks:
      - crawler_net

volumes:
  redis_data:

networks:
  crawler_net:
    driver: bridge
```

## 6. –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è

–©–æ–± –¥–æ–¥–∞—Ç–∏ –±—ñ–ª—å—à–µ workers:

```bash
# –ó–∞–ø—É—Å–∫ 3 workers
docker compose up -d --scale worker=3
```

–ê–±–æ –æ–∫—Ä–µ–º–∏–π docker-compose –¥–ª—è workers –Ω–∞ —ñ–Ω—à–∏—Ö –º–∞—à–∏–Ω–∞—Ö:

```yaml
# docker-compose.worker.yml
services:
  worker:
    build: .
    command: celery -A package_crawler.infrastructure.messaging.celery_unified worker --loglevel=info --concurrency=4 -Q package_crawler
    environment:
      - CELERY_BROKER_URL=redis://MAIN_SERVER_IP:6579/0
      - CELERY_RESULT_BACKEND=redis://MAIN_SERVER_IP:6579/1
```

---

**–í–µ—Ä—Å—ñ—è:** 3.2.0  
**–û–Ω–æ–≤–ª–µ–Ω–æ:** –ì—Ä—É–¥–µ–Ω—å 2025
