"""AsyncDriver v4.1 - Clean Configuration-based Architecture.

Ð’ÑÑ– Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ Ð±ÐµÑ€ÑƒÑ‚ÑŒÑÑ Ð· ÐºÐ¾Ð½Ñ„Ñ–Ð³Ñƒ - ÐÐ†Ð§ÐžÐ“Ðž Ð·Ð°Ñ…Ð°Ñ€Ð´ÐºÐ¾Ð´Ð¶ÐµÐ½Ð¾Ð³Ð¾!

v4.1 Features:
- Ð’ÑÑ– Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð¾Ð²Ð°Ð½Ñ– Ñ‡ÐµÑ€ÐµÐ· DriverConfig Ð°Ð±Ð¾ dict
- Python 3.14 free-threading auto-detection
- Adaptive optimization (Ð¾Ð¿Ñ†Ñ–Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
- Fast path methods Ð´Ð»Ñ max performance
"""

import asyncio
import logging
import sys
from typing import Any, Dict, List, Optional

import aiohttp

from graph_crawler.domain.events.event_bus import EventBus
from graph_crawler.domain.value_objects.models import FetchResponse
from graph_crawler.infrastructure.transport.async_http.context import AsyncHTTPContext
from graph_crawler.infrastructure.transport.async_http.stages import AsyncHTTPStage
from graph_crawler.infrastructure.transport.base_plugin import BaseDriverPlugin
from graph_crawler.infrastructure.transport.core.base_async import BaseAsyncDriver
from graph_crawler.infrastructure.transport.core.mixins import (
    PluginSupportMixin,
    RetryMixin,
)
from graph_crawler.shared.constants import (
    DEFAULT_CONNECTOR_LIMIT,
    DEFAULT_CONNECTOR_LIMIT_PER_HOST,
    DEFAULT_DNS_CACHE_TTL,
    DEFAULT_KEEPALIVE_TIMEOUT,
    DEFAULT_MAX_CONCURRENT_REQUESTS,
    DEFAULT_MAX_RETRIES,
    DEFAULT_REQUEST_TIMEOUT,
    DEFAULT_RETRY_DELAY,
    DEFAULT_USER_AGENT,
    FREE_THREADING_CONCURRENT_MULTIPLIER,
    FREE_THREADING_CONNECTOR_LIMIT,
    FREE_THREADING_CONNECTOR_LIMIT_PER_HOST,
)

logger = logging.getLogger(__name__)


# ============ PYTHON 3.14 FREE-THREADING DETECTION ============
def is_free_threading_enabled() -> bool:
    """Detect Python 3.14+ free-threading mode (GIL disabled)."""
    if hasattr(sys, '_is_gil_enabled'):
        return not sys._is_gil_enabled()
    return False


class AsyncDriver(BaseAsyncDriver, PluginSupportMixin, RetryMixin):
    """
    Async HTTP Ð´Ñ€Ð°Ð¹Ð²ÐµÑ€ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– aiohttp.

    Ð’ÑÑ– Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð¾Ð²Ð°Ð½Ñ– - Ð½Ñ–Ñ‡Ð¾Ð³Ð¾ Ð·Ð°Ñ…Ð°Ñ€Ð´ÐºÐ¾Ð´Ð¶ÐµÐ½Ð¾Ð³Ð¾!

    Config options:
        # Basic
        timeout: int = 30              # Request timeout
        user_agent: str = "..."        # User-Agent header
        max_retries: int = 3           # Retry count
        retry_delay: float = 1.0       # Delay between retries
        
        # Concurrency
        max_concurrent_requests: int = 100
        
        # TCP Connector
        connector_limit: int = 200           # Total connection limit
        connector_limit_per_host: int = 50   # Per-host limit
        dns_cache_ttl: int = 300             # DNS cache TTL (seconds)
        keepalive_timeout: int = 30          # Keepalive timeout
        
        # Python 3.14 optimization
        auto_optimize_for_free_threading: bool = True
        free_threading_concurrent_multiplier: int = 3

    Example:
        >>> # Default config
        >>> async with AsyncDriver() as driver:
        ...     response = await driver.fetch('https://example.com')
        
        >>> # Custom config
        >>> config = {
        ...     'max_concurrent_requests': 200,
        ...     'connector_limit': 500,
        ...     'dns_cache_ttl': 600,
        ... }
        >>> async with AsyncDriver(config=config) as driver:
        ...     results = await driver.fetch_many(urls)
    """

    driver_name = "aiohttp"

    def __init__(
        self,
        config: Optional[Dict[str, Any]] = None,
        event_bus: Optional[EventBus] = None,
        plugins: Optional[List[BaseDriverPlugin]] = None,
    ):
        """
        Ð†Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ AsyncDriver.

        Args:
            config: ÐšÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ Ð´Ñ€Ð°Ð¹Ð²ÐµÑ€Ð° (Ð²ÑÑ– Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ Ð¾Ð¿Ñ†Ñ–Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ–)
            event_bus: EventBus Ð´Ð»Ñ Ð¿Ð¾Ð´Ñ–Ð¹
            plugins: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿Ð»Ð°Ð³Ñ–Ð½Ñ–Ð²
        """
        BaseAsyncDriver.__init__(self, config, event_bus)
        self._init_plugin_support(plugins, is_async=True)

        # Session management
        self._session: Optional[aiohttp.ClientSession] = None
        self._connector: Optional[aiohttp.TCPConnector] = None

        # ========== READ CONFIG (all with defaults from constants) ==========
        
        # Basic settings
        self._timeout = self.config.get("timeout", DEFAULT_REQUEST_TIMEOUT)
        self._user_agent = self.config.get("user_agent", DEFAULT_USER_AGENT)
        self._max_retries = self.config.get("max_retries", DEFAULT_MAX_RETRIES)
        self._retry_delay = self.config.get("retry_delay", DEFAULT_RETRY_DELAY)
        
        # Concurrency
        self._base_concurrent = self.config.get(
            "max_concurrent_requests", DEFAULT_MAX_CONCURRENT_REQUESTS
        )
        
        # TCP Connector settings
        self._connector_limit = self.config.get(
            "connector_limit", DEFAULT_CONNECTOR_LIMIT
        )
        self._connector_limit_per_host = self.config.get(
            "connector_limit_per_host", DEFAULT_CONNECTOR_LIMIT_PER_HOST
        )
        self._dns_cache_ttl = self.config.get(
            "dns_cache_ttl", DEFAULT_DNS_CACHE_TTL
        )
        self._keepalive_timeout = self.config.get(
            "keepalive_timeout", DEFAULT_KEEPALIVE_TIMEOUT
        )
        
        # Python 3.14 free-threading optimization
        self._auto_optimize = self.config.get(
            "auto_optimize_for_free_threading", True
        )
        self._ft_multiplier = self.config.get(
            "free_threading_concurrent_multiplier", 
            FREE_THREADING_CONCURRENT_MULTIPLIER
        )
        
        # ========== APPLY FREE-THREADING OPTIMIZATIONS (if enabled) ==========
        
        self._free_threading = is_free_threading_enabled()
        
        if self._free_threading and self._auto_optimize:
            # Apply free-threading optimized values
            self.max_concurrent = self._base_concurrent * self._ft_multiplier
            self._connector_limit = self.config.get(
                "connector_limit", FREE_THREADING_CONNECTOR_LIMIT
            )
            self._connector_limit_per_host = self.config.get(
                "connector_limit_per_host", FREE_THREADING_CONNECTOR_LIMIT_PER_HOST
            )
            logger.info(
                f"ðŸš€ Free-threading detected! Auto-optimized: "
                f"concurrent={self.max_concurrent}, "
                f"connector_limit={self._connector_limit}"
            )
        else:
            self.max_concurrent = self._base_concurrent

        logger.info(
            f"AsyncDriver v4.1: "
            f"concurrent={self.max_concurrent}, "
            f"connector={self._connector_limit}/{self._connector_limit_per_host}, "
            f"timeout={self._timeout}s, "
            f"free_threading={self._free_threading}"
        )

    # ==================== Session Management ====================

    async def _get_session(self) -> aiohttp.ClientSession:
        """
        Ð¡Ñ‚Ð²Ð¾Ñ€ÑŽÑ” Ð°Ð±Ð¾ Ð¿Ð¾Ð²ÐµÑ€Ñ‚Ð°Ñ” Ñ–ÑÐ½ÑƒÑŽÑ‡Ñƒ aiohttp session.
        
        Ð’ÑÑ– Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ Ð· ÐºÐ¾Ð½Ñ„Ñ–Ð³Ñƒ!
        
        v4.1: Ð”Ð¾Ð´Ð°Ð½Ð¾ SSL/TLS verification options.
        """
        if not self._session or self._session.closed:
            # SSL/TLS Configuration (v4.1)
            ssl_verify = self.config.get("ssl_verify", True)
            ssl_context = None
            
            if ssl_verify:
                # Ð¡Ñ‚Ð²Ð¾Ñ€ÑŽÑ”Ð¼Ð¾ secure SSL context
                import ssl
                ssl_context = ssl.create_default_context()
                ssl_context.check_hostname = True
                ssl_context.verify_mode = ssl.CERT_REQUIRED
                
                # Custom CA bundle (Ð¾Ð¿Ñ†Ñ–Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
                ssl_ca_bundle = self.config.get("ssl_ca_bundle")
                if ssl_ca_bundle:
                    ssl_context.load_verify_locations(ssl_ca_bundle)
            else:
                # Disabled verification (Ñ‚Ñ–Ð»ÑŒÐºÐ¸ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ!)
                logger.warning(
                    "âš ï¸ SSL verification DISABLED! Use only for testing."
                )
                ssl_context = False
            
            self._connector = aiohttp.TCPConnector(
                limit=self._connector_limit,
                limit_per_host=self._connector_limit_per_host,
                ttl_dns_cache=self._dns_cache_ttl,
                use_dns_cache=True,
                keepalive_timeout=self._keepalive_timeout,
                enable_cleanup_closed=True,
                force_close=False,
                ssl=ssl_context,  # SSL/TLS verification
            )
            
            timeout = aiohttp.ClientTimeout(
                total=self._timeout,
                connect=min(5, self._timeout),
                sock_read=self._timeout,
            )
            
            self._session = aiohttp.ClientSession(
                connector=self._connector,
                headers={"User-Agent": self._user_agent},
                timeout=timeout,
                raise_for_status=False,
            )
        return self._session

    # ==================== Core Fetch ====================

    async def _do_fetch(self, url: str) -> FetchResponse:
        """Core fetch Ð· retry support."""
        return await self._with_retry_async(
            self._fetch_with_plugins,
            url,
            max_retries=self._max_retries,
            retry_delay=self._retry_delay,
            retry_on=(aiohttp.ClientError, asyncio.TimeoutError),
        )

    async def _fetch_with_plugins(self, url: str) -> FetchResponse:
        """Fetch Ð· Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ¾ÑŽ Ð¿Ð»Ð°Ð³Ñ–Ð½Ñ–Ð²."""
        session = await self._get_session()

        ctx = AsyncHTTPContext(
            url=url,
            method="GET",
            headers={},
            cookies={},
            timeout=self._timeout,
            session=session,
        )

        if self._plugin_manager:
            self._plugin_manager.setup_event_subscriptions(ctx)

        try:
            ctx = await self._execute_plugin_stage(
                AsyncHTTPStage.PREPARING_REQUEST, ctx
            )
            if ctx.cancelled:
                return self._cancelled_response(ctx)

            ctx = await self._execute_plugin_stage(
                AsyncHTTPStage.SENDING_REQUEST, ctx
            )
            if ctx.cancelled:
                return self._cancelled_response(ctx)

            async with session.get(
                url, headers=ctx.headers or {}, params=ctx.params
            ) as response:
                ctx.response = response
                ctx.status_code = response.status
                # FIX: ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚ÑƒÑ”Ð¼Ð¾ Ð²ÑÑ– header values Ð² string (Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð· Cython Ð² Python 3.14)
                ctx.response_headers = {k: str(v) for k, v in response.headers.items()}

                ctx = await self._execute_plugin_stage(
                    AsyncHTTPStage.RESPONSE_RECEIVED, ctx
                )

                try:
                    ctx.html = await response.text()
                except UnicodeDecodeError:
                    ctx.html = None

                ctx = await self._execute_plugin_stage(
                    AsyncHTTPStage.PROCESSING_RESPONSE, ctx
                )

            ctx = await self._execute_plugin_stage(
                AsyncHTTPStage.REQUEST_COMPLETED, ctx
            )

            return FetchResponse(
                url=url,
                html=ctx.html,
                status_code=ctx.status_code,
                headers=ctx.response_headers or {},
                error=ctx.error,
            )

        except Exception as e:
            ctx.error = str(e)
            ctx = await self._execute_plugin_stage(
                AsyncHTTPStage.REQUEST_FAILED, ctx
            )
            if ctx.data.get("should_retry", False):
                raise
            raise

    async def _execute_plugin_stage(
        self, stage: AsyncHTTPStage, ctx: AsyncHTTPContext
    ) -> AsyncHTTPContext:
        """Execute plugin stage if plugin_manager exists."""
        if self._plugin_manager:
            return await self._plugin_manager.execute_hook_async(stage, ctx)
        return ctx

    def _cancelled_response(self, ctx: AsyncHTTPContext) -> FetchResponse:
        """Create response for cancelled request."""
        reason = ctx.data.get("cancellation_reason", "Unknown")
        return FetchResponse(
            url=ctx.url,
            html=None,
            status_code=None,
            headers={},
            error=f"Cancelled: {reason}",
        )

    # ==================== Batch Fetching ====================

    async def fetch_many(self, urls: List[str]) -> List[FetchResponse]:
        """
        ÐŸÐ°Ñ€Ð°Ð»ÐµÐ»ÑŒÐ½Ðµ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð· ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÐµÐ¼ concurrency.
        
        Concurrency ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŽÑ”Ñ‚ÑŒÑÑ Ñ‡ÐµÑ€ÐµÐ· config['max_concurrent_requests'].
        """
        if not urls:
            return []

        semaphore = asyncio.Semaphore(self.max_concurrent)

        async def fetch_limited(url: str) -> FetchResponse:
            async with semaphore:
                return await self.fetch(url)

        tasks = [fetch_limited(url) for url in urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        processed = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed.append(
                    self._create_error_response(
                        urls[i], f"{type(result).__name__}: {result}"
                    )
                )
            else:
                processed.append(result)

        return processed

    # ==================== Fast Path (no plugins) ====================

    async def fetch_fast(self, url: str) -> FetchResponse:
        """
        Ultra-fast fetch Ð‘Ð•Ð— Ð¿Ð»Ð°Ð³Ñ–Ð½Ñ–Ð².
        
        Ð”Ð»Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ñ— ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ– ÐºÐ¾Ð»Ð¸ Ð½Ðµ Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ñ–:
        - Rate limiting
        - Retry logic
        - Custom headers/cookies
        """
        session = await self._get_session()
        
        try:
            async with session.get(url) as response:
                try:
                    html = await response.text()
                except UnicodeDecodeError:
                    html = None
                    
                # FIX: ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚ÑƒÑ”Ð¼Ð¾ Ð²ÑÑ– header values Ð² string (Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð· Cython Ð² Python 3.14)
                return FetchResponse(
                    url=url,
                    html=html,
                    status_code=response.status,
                    headers={k: str(v) for k, v in response.headers.items()},
                )
        except Exception as e:
            return FetchResponse(
                url=url,
                html=None,
                status_code=None,
                headers={},
                error=f"{type(e).__name__}: {e}",
            )

    async def fetch_many_fast(self, urls: List[str]) -> List[FetchResponse]:
        """Ultra-fast batch fetch Ð‘Ð•Ð— Ð¿Ð»Ð°Ð³Ñ–Ð½Ñ–Ð²."""
        if not urls:
            return []
            
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def fetch_limited(url: str) -> FetchResponse:
            async with semaphore:
                return await self.fetch_fast(url)
        
        tasks = [asyncio.create_task(fetch_limited(url)) for url in urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        processed = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed.append(
                    FetchResponse(
                        url=urls[i],
                        html=None,
                        status_code=None,
                        headers={},
                        error=f"{type(result).__name__}: {result}",
                    )
                )
            else:
                processed.append(result)
        
        return processed

    # ==================== Resource Management ====================

    async def _do_close(self) -> None:
        """Close session and connector."""
        if self._session and not self._session.closed:
            await self._session.close()
        
        if self._connector and not self._connector.closed:
            await self._connector.close()
            
        await asyncio.sleep(0.1)
        
        self._session = None
        self._connector = None

        await self._teardown_plugins_async()
