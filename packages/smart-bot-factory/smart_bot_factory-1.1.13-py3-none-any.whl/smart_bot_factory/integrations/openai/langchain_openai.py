import json
import logging
from typing import Any, Dict, List

from langchain.agents import create_agent
from langchain.agents.structured_output import ProviderStrategy
from langchain.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
from openai import AsyncOpenAI
from pydantic import ValidationError

from .responce_models import (
    AnalyzeSentimentResponseModel,
    GenerateFollowUpResponseModel,
    MainResponseModel,
)

logger = logging.getLogger(__name__)


class LangChainOpenAIClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API —á–µ—Ä–µ–∑ LangChain v1.0"""

    def __init__(
        self,
        api_key: str,
        model: str = "gpt-5",
        max_tokens: int = 1500,
        temperature: float = 0.7,
    ):
        self.api_key = api_key
        self.model = model
        self.max_tokens = max_tokens
        self.temperature = temperature

        self.client = AsyncOpenAI(api_key=api_key)

        # –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è ChatOpenAI
        self._tools: List[Any] = []

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑–æ–≤—É—é LangChain –º–æ–¥–µ–ª—å
        self._base_chat_model = ChatOpenAI(
            model=model,
            api_key=api_key,
            max_tokens=max_tokens,
            temperature=temperature,
            reasoning_effort="minimal" if self._is_gpt5() else None,
            max_retries=3,
        )

        self.chat_model = create_agent(model=self._base_chat_model, tools=self._tools, response_format=ProviderStrategy(MainResponseModel))

        # –ü–æ–ª—É—á–∞–µ–º –ª–∏–º–∏—Ç—ã –¥–ª—è –º–æ–¥–µ–ª–∏
        self.model_limits = self._get_model_limits()

        # –î–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø—É—Å—Ç—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        self.last_completion_tokens = 0

        logger.info(
            f"""LangChain OpenAI –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–æ–¥–µ–ª—å—é {model}
            (GPT-5: {self._is_gpt5()}, –ª–∏–º–∏—Ç: {self.model_limits
            ['total_context']} —Ç–æ–∫–µ–Ω–æ–≤)"""
        )

        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ö
        self._log_tools()

    @property
    def is_gpt5(self) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å GPT-5"""
        return self._is_gpt5()

    def _is_gpt5(self) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å GPT-5"""
        return "gpt-5" in self.model.lower()

    def _get_model_limits(self) -> Dict[str, int]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª–∏–º–∏—Ç—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        model_limits = {
            # GPT-3.5
            "gpt-3.5-turbo": 4096,
            "gpt-3.5-turbo-16k": 16385,
            # GPT-4
            "gpt-4": 8192,
            "gpt-4-32k": 32768,
            "gpt-4-turbo": 128000,
            "gpt-4-turbo-preview": 128000,
            "gpt-4o": 128000,
            "gpt-4o-mini": 128000,
            # GPT-5
            "gpt-5-mini": 128000,
            "gpt-5": 200000,
        }

        # –ü–æ–ª—É—á–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        total_limit = model_limits.get(self.model, 8192)

        # –†–µ–∑–µ—Ä–≤–∏—Ä—É–µ–º –º–µ—Å—Ç–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –∏ –±—É—Ñ–µ—Ä–∞
        completion_reserve = min(self.max_tokens * 2, total_limit // 4)  # –†–µ–∑–µ—Ä–≤–∏—Ä—É–µ–º –º–µ—Å—Ç–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
        buffer_reserve = 500  # –ë—É—Ñ–µ—Ä –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏

        return {
            "total_context": total_limit,
            "max_input_tokens": total_limit - completion_reserve - buffer_reserve,
            "completion_reserve": completion_reserve,
        }

    def _convert_messages_to_langchain(self, messages: List[Dict[str, str]]) -> List[Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ dict –≤ LangChain messages"""
        langchain_messages = []
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content", "")

            if role == "system":
                langchain_messages.append(SystemMessage(content=content))
            elif role == "user":
                langchain_messages.append(HumanMessage(content=content))
            elif role == "assistant":
                langchain_messages.append(AIMessage(content=content))
            else:
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º user
                langchain_messages.append(HumanMessage(content=content))

        return langchain_messages

    def _convert_langchain_to_dict(self, message: AIMessage) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç LangChain —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–∞—Ç–Ω–æ –≤ dict –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        return {
            "content": message.content if hasattr(message, "content") else str(message),
            "role": "assistant",
        }

    def _log_tools(self):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Å–µ—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ö"""
        if not self._tools:
            logger.info("üìã –ü–æ–¥–∫–ª—é—á–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã ChatOpenAI: –Ω–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤")
            return

        logger.info(f"üìã –ü–æ–¥–∫–ª—é—á–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã ChatOpenAI ({len(self._tools)} —à—Ç.):")
        for i, tool in enumerate(self._tools, 1):
            tool_name = getattr(tool, "name", "Unknown")
            tool_description = getattr(tool, "description", "–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è")
            tool_type = type(tool).__name__

            # –û–±—Ä–µ–∑–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
            if len(tool_description) > 100:
                tool_description = tool_description[:97] + "..."

            logger.info(f"   {i}. {tool_name} ({tool_type})")
            logger.info(f"      –û–ø–∏—Å–∞–Ω–∏–µ: {tool_description}")

    def _update_agent(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∞–≥–µ–Ω—Ç–∞ —Å —Ç–µ–∫—É—â–∏–º —Å–ø–∏—Å–∫–æ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        self.chat_model = create_agent(model=self._base_chat_model, tools=self._tools)
        logger.info(f"üîÑ –ê–≥–µ–Ω—Ç –æ–±–Ω–æ–≤–ª–µ–Ω —Å {len(self._tools)} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏")

    def add_tool(self, tool: Any, update_agent: bool = True, log_after: bool = True):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è ChatOpenAI

        Args:
            tool: –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç LangChain (–Ω–∞–ø—Ä–∏–º–µ—Ä, StructuredTool, FunctionTool –∏ —Ç.–¥.)
            update_agent: –û–±–Ω–æ–≤–ª—è—Ç—å –ª–∏ –∞–≥–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)
            log_after: –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –ª–∏ —Å–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)
        """
        if tool not in self._tools:
            self._tools.append(tool)
            tool_name = getattr(tool, "name", str(tool))
            tool_description = getattr(tool, "description", "–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è")
            tool_type = type(tool).__name__

            logger.info(f"‚úÖ –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç '{tool_name}' ({tool_type}) –¥–æ–±–∞–≤–ª–µ–Ω –≤ ChatOpenAI")
            if tool_description and tool_description != "–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è":
                # –û–±—Ä–µ–∑–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
                desc = tool_description[:100] + "..." if len(tool_description) > 100 else tool_description
                logger.info(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {desc}")

            # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞ —Å –Ω–æ–≤—ã–º —Å–ø–∏—Å–∫–æ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if update_agent:
                self._update_agent()

            # –õ–æ–≥–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if log_after:
                self._log_tools()
        else:
            tool_name = getattr(tool, "name", str(tool))
            logger.warning(f"‚ö†Ô∏è –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç '{tool_name}' —É–∂–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω")

    def add_tools(self, *tools: Any):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è ChatOpenAI

        Args:
            *tools: –ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ LangChain –∏–ª–∏ —Å–ø–∏—Å–æ–∫(—ã) –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

        Examples:
            # –û—Ç–¥–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
            client.add_tools(tool1, tool2, tool3)

            # –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
            client.add_tools([tool1, tool2, tool3])

            # –ö–æ–º–±–∏–Ω–∞—Ü–∏—è
            client.add_tools([tool1, tool2], tool3)
        """
        if not tools:
            logger.warning("‚ö†Ô∏è add_tools –≤—ã–∑–≤–∞–Ω –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤")
            return

        # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º —Å–ø–∏—Å–∫–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        unpacked_tools = []
        for tool in tools:
            if isinstance(tool, (list, tuple)):
                # –ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –∏–ª–∏ –∫–æ—Ä—Ç–µ–∂, –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                unpacked_tools.extend(tool)
            else:
                # –ï—Å–ª–∏ —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
                unpacked_tools.append(tool)

        if not unpacked_tools:
            logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è")
            return

        logger.info(f"üîß –î–æ–±–∞–≤–ª–µ–Ω–∏–µ {len(unpacked_tools)} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ ChatOpenAI...")
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –±–µ–∑ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ
        for tool in unpacked_tools:
            self.add_tool(tool, update_agent=False, log_after=False)

        # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞ –æ–¥–∏–Ω —Ä–∞–∑ –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤—Å–µ—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        self._update_agent()

        # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –æ–¥–∏–Ω —Ä–∞–∑
        logger.info(f"‚úÖ –í—Å–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã. –í—Å–µ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–æ: {len(self._tools)}")
        self._log_tools()

    def get_tools(self) -> List[Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        return self._tools.copy()

    def get_tools_description_for_prompt(self) -> str:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –≤—Å–µ—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –ø—Ä–æ–º–ø—Ç

        Returns:
            –¢–µ–∫—Å—Ç —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        """
        if not self._tools:
            return ""

        descriptions = []
        descriptions.append("\n### –î–û–°–¢–£–ü–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ ###\n")
        descriptions.append("–£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Å–ª–µ–¥—É—é—â–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º. –ò—Å–ø–æ–ª—å–∑—É–π –∏—Ö –∫–æ–≥–¥–∞ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ:\n")

        for i, tool in enumerate(self._tools, 1):
            tool_name = getattr(tool, "name", "Unknown")
            tool_description = getattr(tool, "description", "–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è")

            # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
            tool_args = ""
            if hasattr(tool, "args_schema"):
                try:
                    args_schema = tool.args_schema
                    if hasattr(args_schema, "schema"):
                        schema = args_schema.schema()
                        properties = schema.get("properties", {})
                        if properties:
                            args_list = []
                            for param_name, param_info in properties.items():
                                param_desc = param_info.get("description", "")
                                param_type = param_info.get("type", "string")
                                args_list.append(f"  - {param_name} ({param_type}): {param_desc}")
                            if args_list:
                                tool_args = "\n" + "\n".join(args_list)
                except Exception as e:
                    logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ö–µ–º—É –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è {tool_name}: {e}")

            descriptions.append(f"{i}. **{tool_name}**")
            descriptions.append(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {tool_description}")
            if tool_args:
                descriptions.append(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:{tool_args}")
            descriptions.append("")

        descriptions.append("–í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∫–æ–≥–¥–∞ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
        descriptions.append("–ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –ø–æ–≥–æ–¥–µ - –∏—Å–ø–æ–ª—å–∑—É–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç.\n")

        return "\n".join(descriptions)

    async def get_completion(self, messages: List) -> Dict[str, Any]:
        ai_response = await self.chat_model.ainvoke({"messages": messages})
        try:
            json_response = MainResponseModel.model_validate_json(ai_response["messages"][-1].content)
            logger.debug(f"json_response: {json_response}")
            return json_response
        except ValidationError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            logger.debug(f"ai_response: {ai_response['messages'][-1].content}")
            return MainResponseModel(user_message="", service_info={})

    async def _prepare_messages(self, messages: List) -> List:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ API
        –û–±—Ä–µ–∑–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π
        """

        # –ë–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        def estimate_message_tokens(msg):
            content = msg.content if hasattr(msg, "content") else str(msg)
            # –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: –ø—Ä–∏–º–µ—Ä–Ω–æ 2.5-3 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω
            return len(content) // 2.5

        total_estimated_tokens = sum(estimate_message_tokens(msg) for msg in messages)
        max_input_tokens = self.model_limits["max_input_tokens"]

        if total_estimated_tokens <= max_input_tokens:
            return messages

        logger.info(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({int(total_estimated_tokens)} —Ç–æ–∫–µ–Ω–æ–≤), –æ–±—Ä–µ–∑–∞–µ–º –¥–æ {max_input_tokens}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        system_messages = [msg for msg in messages if isinstance(msg, SystemMessage)]
        other_messages = [msg for msg in messages if not isinstance(msg, SystemMessage)]

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        system_tokens = sum(estimate_message_tokens(msg.content) for msg in system_messages)
        available_tokens = max_input_tokens - system_tokens

        if available_tokens <= 0:
            logger.warning("–°–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∑–∞–Ω–∏–º–∞—é—Ç –≤–µ—Å—å –¥–æ—Å—Ç—É–ø–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç")
            return system_messages

        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –ø–æ–º–µ—â–∞—é—â–∏–µ—Å—è –≤ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        current_tokens = 0
        trimmed_messages = []

        for msg in reversed(other_messages):
            msg_tokens = estimate_message_tokens(msg)
            if current_tokens + msg_tokens > available_tokens:
                break
            trimmed_messages.insert(0, msg)
            current_tokens += msg_tokens

        result_messages = system_messages + trimmed_messages
        logger.info(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–æ {len(result_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π (~{int(current_tokens + system_tokens)} —Ç–æ–∫–µ–Ω–æ–≤)")

        return result_messages

    async def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ –Ω–∞–º–µ—Ä–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        analysis_prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ–ø—Ä–µ–¥–µ–ª–∏:
        1. –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ (–ø–æ–∑–∏—Ç–∏–≤–Ω–æ–µ/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ/–Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ)
        2. –£—Ä–æ–≤–µ–Ω—å –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ (1-10)
        3. –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –ø–æ–∫—É–ø–∫–µ (1-10)
        4. –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –≤–æ–ø—Ä–æ—Å—ã
        5. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –æ—Ç–≤–µ—Ç–∞
        
        –°–æ–æ–±—â–µ–Ω–∏–µ: "{text}"
        
        –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {{
            "sentiment": "positive/neutral/negative",
            "interest_level": 1-10,
            "purchase_readiness": 1-10,
            "objections": ["—Å–ø–∏—Å–æ–∫ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π"],
            "key_questions": ["–∫–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã"],
            "response_strategy": "—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è"
        }}
        """

        try:
            # –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –Ω–∏–∑–∫—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
            temp = 0.3 if not self.is_gpt5 else None

            model = ChatOpenAI(
                model=self.model,
                api_key=self.api_key,
                max_tokens=self.max_tokens,
                temperature=temp,
                reasoning_effort="minimal" if self._is_gpt5() else None,
                max_retries=3,
            ).with_structured_output(AnalyzeSentimentResponseModel)

            response = await model.ainvoke(
                [
                    SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –Ω–∞–º–µ—Ä–µ–Ω–∏–π –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ –ø—Ä–æ–¥–∞–∂–∞—Ö."),
                    HumanMessage(content=analysis_prompt),
                ]
            )

            return json.loads(response)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            return {
                "sentiment": "neutral",
                "interest_level": 5,
                "purchase_readiness": 5,
                "objections": [],
                "key_questions": [],
                "response_strategy": "continue_conversation",
            }

    async def generate_follow_up(self, conversation_history: List, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞

        Args:
            conversation_history: –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            analysis: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è

        Returns:
            –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        """
        strategy_prompt = f"""
        –ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞:
        - –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {analysis['sentiment']}
        - –£—Ä–æ–≤–µ–Ω—å –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏: {analysis['interest_level']}/10
        - –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –ø–æ–∫—É–ø–∫–µ: {analysis['purchase_readiness']}/10
        - –í–æ–∑—Ä–∞–∂–µ–Ω–∏—è: {analysis['objections']}
        - –°—Ç—Ä–∞—Ç–µ–≥–∏—è: {analysis['response_strategy']}
        
        –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π:
        1. –£—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞
        2. –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –µ–≥–æ –∫–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è
        3. –ú—è–≥–∫–æ –Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —ç—Ç–∞–ø—É –≤–æ—Ä–æ–Ω–∫–∏ –ø—Ä–æ–¥–∞–∂
        4. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ç–æ–Ω –æ–±—â–µ–Ω–∏—è
        """

        temp = 0.8 if not self.is_gpt5 else None

        model = ChatOpenAI(
            model=self.model,
            api_key=self.api_key,
            max_tokens=self.max_tokens,
            temperature=temp,
            reasoning_effort="minimal" if self._is_gpt5() else None,
            max_retries=3,
        ).with_structured_output(GenerateFollowUpResponseModel)

        response = await model.ainvoke(conversation_history + [SystemMessage(strategy_prompt)])
        try:
            return json.loads(response)
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            return {}

    async def check_api_health(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å OpenAI API"""
        try:
            test_messages = [HumanMessage(content="–ü—Ä–∏–≤–µ—Ç")]

            model = (
                ChatOpenAI(
                    model=self.model, api_key=self.api_key, max_tokens=10, reasoning_effort="minimal" if self._is_gpt5() else None, max_retries=3
                )
                | StrOutputParser()
            )

            await model.ainvoke(test_messages)
            return True
        except Exception as e:
            logger.error(f"OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            return False

    def estimate_tokens(self, text: str) -> int:
        """–ë–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ"""
        # –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: –ø—Ä–∏–º–µ—Ä–Ω–æ 2.5-3 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω
        return int(len(text) / 2.5)

    async def get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        # LangChain –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ —Å–ø–∏—Å–∫—É –º–æ–¥–µ–ª–µ–π
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π OpenAI
        return [
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-16k",
            "gpt-4",
            "gpt-4-32k",
            "gpt-4-turbo",
            "gpt-4o",
            "gpt-4o-mini",
            "gpt-5-mini",
            "gpt-5",
        ]

    async def transcribe_audio(self, audio_file_path: str) -> str:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Whisper API

        Args:
            audio_file_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É

        Returns:
            –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            logger.info(f"üé§ –û—Ç–ø—Ä–∞–≤–∫–∞ –∞—É–¥–∏–æ –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ: {audio_file_path}")

            with open(audio_file_path, "rb") as audio_file:
                transcript = await self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ru",  # –†—É—Å—Å–∫–∏–π —è–∑—ã–∫
                )

            text = transcript.text
            logger.info(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤: '{text[:100]}...'")
            return text

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∞—É–¥–∏–æ: {e}")
            return ""
