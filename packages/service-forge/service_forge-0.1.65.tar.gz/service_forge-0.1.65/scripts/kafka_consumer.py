import json
import asyncio
import argparse
from aiokafka import AIOKafkaConsumer
import google.protobuf.message
from google.protobuf import descriptor_pool
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„ä»¥å¯¼å…¥protobufæ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'example', 'tag-service', 'proto'))

def detect_and_parse_data(raw_data: bytes) -> tuple[str, dict | None]:
    """è‡ªåŠ¨æ£€æµ‹æ•°æ®æ ¼å¼å¹¶è§£æï¼Œè¿”å›æ ¼å¼ç±»å‹å’Œè§£æåçš„æ•°æ®"""
    try:
        # é¦–å…ˆå°è¯•JSONæ ¼å¼
        body = json.loads(raw_data.decode("utf-8"))
        return "JSON", body
    except json.JSONDecodeError:
        pass
    
    # å°è¯•protobufæ ¼å¼ - å°è¯•å¤šç§å·²çŸ¥çš„protobufæ¶ˆæ¯ç±»å‹
    protobuf_types = [
        "tagService.tag_pb2.Tag",
    ]
    
    for pb_type_str in protobuf_types:
        try:
            # åŠ¨æ€å¯¼å…¥protobufç±»å‹
            module_name, class_name = pb_type_str.rsplit('.', 1)
            module = __import__(module_name, fromlist=[class_name])
            pb_class = getattr(module, class_name)
            
            # å°è¯•è§£æ
            pb_obj = pb_class()
            pb_obj.ParseFromString(raw_data)
            body = protobuf_to_dict(pb_obj)
            return f"Protobuf ({pb_type_str})", body
        except Exception:
            continue
    
    # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›åŸå§‹æ•°æ®
    return "Unknown", {"raw_data": raw_data.hex(), "size": len(raw_data)}

def protobuf_to_dict(pb_obj: google.protobuf.message.Message) -> dict:
    """å°†protobufå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸"""
    result = {}
    for field_descriptor in pb_obj.DESCRIPTOR.fields:
        field_name = field_descriptor.name
        field_value = getattr(pb_obj, field_name)
        
        if field_descriptor.label == field_descriptor.LABEL_REPEATED:
            # å¤„ç†é‡å¤å­—æ®µ
            result[field_name] = list(field_value)
        elif field_descriptor.type == field_descriptor.TYPE_MESSAGE:
            # å¤„ç†åµŒå¥—æ¶ˆæ¯
            if field_value:
                result[field_name] = protobuf_to_dict(field_value)
        else:
            # å¤„ç†åŸºæœ¬ç±»å‹
            result[field_name] = field_value
    return result

async def consume_messages(bootstrap_servers: str, topic: str, group_id: str = "test_group", format_mode: str = "auto"):
    # TODO: proper config
    consumer = AIOKafkaConsumer(
        topic,
        bootstrap_servers=bootstrap_servers,
        group_id=group_id,
        auto_offset_reset="earliest",
        enable_auto_commit=True,
        session_timeout_ms=300000,
        heartbeat_interval_ms=10000,
        max_poll_interval_ms=3000000,
    )
    
    await consumer.start()
    try:
        print(f"ğŸ§ å¼€å§‹ç›‘å¬ topic: {topic}, group_id: {group_id}")
        print("æŒ‰ Ctrl+C åœæ­¢æ¶ˆè´¹...")
        
        async for message in consumer:
            print(f"ğŸ“¨ æ”¶åˆ°æ¶ˆæ¯:")
            print(f"  Topic: {message.topic}")
            print(f"  Partition: {message.partition}")
            print(f"  Offset: {message.offset}")
            print(f"  Timestamp: {message.timestamp}")
            print(f"  Key: {message.key}")
            
            # æ ¹æ®æ ¼å¼æ¨¡å¼è§£ææ•°æ®
            if format_mode == "json":
                try:
                    parsed_data = json.loads(message.value.decode("utf-8"))
                    data_format = "JSON"
                except json.JSONDecodeError:
                    data_format = "JSON Parse Error"
                    parsed_data = {"error": "æ— æ³•è§£æä¸ºJSONæ ¼å¼"}
            elif format_mode == "protobuf":
                # å°è¯•protobufæ ¼å¼
                data_format, parsed_data = detect_and_parse_data(message.value)
                if not data_format.startswith("Protobuf"):
                    data_format = "Protobuf Parse Error"
                    parsed_data = {"error": "æ— æ³•è§£æä¸ºProtobufæ ¼å¼"}
            else:  # auto
                data_format, parsed_data = detect_and_parse_data(message.value)
            
            print(f"  Format: {data_format}")
            print(f"  Value: {json.dumps(parsed_data, indent=2, ensure_ascii=False)}")
            print("-" * 50)
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  åœæ­¢æ¶ˆè´¹...")
    finally:
        await consumer.stop()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Kafka Consumer Script - æ”¯æŒ JSON å’Œ Protobuf æ ¼å¼")
    parser.add_argument("--topic", type=str, default="test_topic", help="è¦æ¶ˆè´¹çš„ topic åç§°")
    parser.add_argument("--group-id", type=str, default="test_group", help="æ¶ˆè´¹è€…ç»„ ID")
    parser.add_argument("--bootstrap-servers", type=str, default="localhost:9092", help="Kafka æœåŠ¡å™¨åœ°å€")
    parser.add_argument("--format", type=str, choices=["auto", "json", "protobuf"], default="auto", 
                       help="æ•°æ®æ ¼å¼ (auto: è‡ªåŠ¨æ£€æµ‹, json: ä»…JSON, protobuf: ä»…Protobuf)")
    args = parser.parse_args()

    print(f"ğŸš€ å¯åŠ¨ Kafka Consumer")
    print(f"  Topic: {args.topic}")
    print(f"  Group ID: {args.group_id}")
    print(f"  Bootstrap Servers: {args.bootstrap_servers}")
    print(f"  Format: {args.format}")
    print()

    asyncio.run(consume_messages(args.bootstrap_servers, args.topic, args.group_id, args.format))
