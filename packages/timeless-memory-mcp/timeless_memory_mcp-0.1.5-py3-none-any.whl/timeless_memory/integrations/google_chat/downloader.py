"""
Google Chat ä¸‹è¼‰å™¨ - æ•´åˆä¸¦è¡Œä¸‹è¼‰åŠŸèƒ½
"""
import json
import sys
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import List, Dict, Optional
from collections import defaultdict
from googleapiclient.errors import HttpError

from .auth import ChatAuthManager

# å°ç£æ™‚å€ UTC+8
TW_TZ = timezone(timedelta(hours=8))

# ç·šç¨‹å®‰å…¨çš„è¼¸å‡ºé–
print_lock = threading.Lock()


def _log(msg: str):
    """è¼¸å‡ºåˆ° stderrï¼ˆé¿å…å¹²æ“¾ MCP stdio é€šè¨Šï¼‰"""
    print(msg, file=sys.stderr)


class ChatReader:
    """Google Chat è¨Šæ¯è®€å–å™¨"""
    
    def __init__(self, auth_manager: ChatAuthManager):
        self.service = auth_manager.get_chat_service()
    
    def list_spaces(self, page_size: int = 1000) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰å¯å­˜å–çš„ Chat Spaces"""
        try:
            all_spaces = []
            page_token = None
            
            while True:
                params = {"pageSize": min(page_size, 1000)}
                if page_token:
                    params["pageToken"] = page_token
                
                response = self.service.spaces().list(**params).execute()
                spaces = response.get("spaces", [])
                all_spaces.extend(spaces)
                
                page_token = response.get("nextPageToken")
                if not page_token:
                    break
            
            return all_spaces
        except HttpError as e:
            return []
    
    def list_messages(
        self,
        space_id: str,
        page_size: int = 1000,
        page_token: Optional[str] = None,
        filter_query: Optional[str] = None
    ) -> Dict:
        """åˆ—å‡ºæŒ‡å®š Space çš„è¨Šæ¯"""
        try:
            space_name = f"spaces/{space_id}"
            params = {
                "parent": space_name,
                "pageSize": min(page_size, 1000)
            }
            
            if page_token:
                params["pageToken"] = page_token
            if filter_query:
                params["filter"] = filter_query
            
            response = self.service.spaces().messages().list(**params).execute()
            return response
        except HttpError as e:
            return {"messages": [], "nextPageToken": None}
    
    def get_all_messages(
        self,
        space_id: str,
        filter_query: Optional[str] = None,
        quiet: bool = False
    ) -> List[Dict]:
        """å–å¾—æŒ‡å®š Space çš„æ‰€æœ‰è¨Šæ¯ï¼ˆè‡ªå‹•è™•ç†åˆ†é ï¼‰"""
        all_messages = []
        page_token = None
        
        if not quiet:
            with print_lock:
                _log(f"    é–‹å§‹è®€å–è¨Šæ¯...")
        
        while True:
            response = self.list_messages(
                space_id=space_id,
                page_token=page_token,
                filter_query=filter_query
            )
            
            messages = response.get("messages", [])
            all_messages.extend(messages)
            
            if not quiet:
                with print_lock:
                    _log(f"    å·²è®€å– {len(all_messages)} å‰‡è¨Šæ¯...")
            
            page_token = response.get("nextPageToken")
            if not page_token:
                break
        
        if not quiet:
            with print_lock:
                _log(f"    å®Œæˆï¼å…±è®€å– {len(all_messages)} å‰‡è¨Šæ¯")
        
        return all_messages
    
    def _sanitize_folder_name(self, name: str) -> str:
        """æ¸…ç†è³‡æ–™å¤¾åç¨±"""
        import re
        unsafe_chars = r'[<>:"/\\|?*]'
        name = re.sub(unsafe_chars, '_', name)
        name = name.strip(' .')
        return name[:100] if len(name) > 100 else name
    
    def _parse_create_time_to_tw(self, create_time_str: str) -> datetime:
        """å°‡ API çš„ createTime (UTC) è½‰æ›ç‚ºå°ç£æ™‚é–“"""
        try:
            if create_time_str.endswith('Z'):
                create_time_str = create_time_str[:-1]
            dt_utc = datetime.fromisoformat(create_time_str).replace(tzinfo=timezone.utc)
            return dt_utc.astimezone(TW_TZ)
        except Exception:
            return datetime.now(TW_TZ)
    
    def export_to_jsonl(
        self,
        messages: List[Dict],
        space_id: str,
        output_dir: Path,
        space_name: str = None,
        append: bool = False
    ) -> List[Path]:
        """å°‡è¨Šæ¯åŒ¯å‡ºç‚º JSONL æª”æ¡ˆï¼ŒæŒ‰æ—¥æœŸåˆ†æª”"""
        if space_name:
            safe_name = self._sanitize_folder_name(space_name)
            folder_name = f"{safe_name}_{space_id}"
        else:
            folder_name = f"æœªå‘½å_{space_id}"
        
        space_dir = output_dir / folder_name
        space_dir.mkdir(parents=True, exist_ok=True)
        
        # æŒ‰æ—¥æœŸåˆ†çµ„è¨Šæ¯
        messages_by_date = defaultdict(list)
        for message in messages:
            create_time = message.get("createTime", "")
            tw_time = self._parse_create_time_to_tw(create_time)
            date_str = tw_time.strftime("%Y-%m-%d")
            messages_by_date[date_str].append(message)
        
        # å¯«å…¥å„æ—¥æœŸæª”æ¡ˆ
        output_files = []
        total_written = 0
        
        for date_str, day_messages in sorted(messages_by_date.items()):
            output_file = space_dir / f"{date_str}.jsonl"
            mode = "a" if append else "w"
            
            with open(output_file, mode, encoding="utf-8") as f:
                for message in day_messages:
                    f.write(json.dumps(message, ensure_ascii=False) + "\n")
            
            output_files.append(output_file)
            total_written += len(day_messages)
        
        return output_files


class ChatDownloader:
    """Google Chat ä¸¦è¡Œä¸‹è¼‰ç®¡ç†å™¨"""
    
    def __init__(self, sources_dir: Path, auth_manager: ChatAuthManager):
        self.sources_dir = Path(sources_dir)
        self.auth_manager = auth_manager
        self.all_spaces_file = self.sources_dir / "all_spaces.json"
    
    def list_spaces(self, refresh: bool = False) -> List[Dict]:
        """
        åˆ—å‡ºæ‰€æœ‰ Spaces
        
        Args:
            refresh: æ˜¯å¦å¼·åˆ¶é‡æ–°å¾ API å–å¾—
        """
        # å¦‚æœå¿«å–å­˜åœ¨ä¸”ä¸å¼·åˆ¶åˆ·æ–°ï¼Œä½¿ç”¨å¿«å–
        if not refresh and self.all_spaces_file.exists():
            with open(self.all_spaces_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("spaces", [])
        
        # å¾ API å–å¾—
        reader = ChatReader(self.auth_manager)
        spaces = reader.list_spaces()
        
        # è½‰æ›æ ¼å¼ä¸¦å„²å­˜
        formatted_spaces = []
        for space in spaces:
            space_id = space.get("name", "").split("/")[-1]
            formatted_spaces.append({
                "space_id": space_id,
                "display_name": space.get("displayName", "æœªå‘½å"),
                "type": space.get("spaceType", "UNKNOWN"),
                "raw_data": space
            })
        
        # å„²å­˜å¿«å–
        with open(self.all_spaces_file, "w", encoding="utf-8") as f:
            json.dump({
                "spaces": formatted_spaces,
                "updated_at": datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)
        
        return formatted_spaces
    
    def _download_single_space(
        self,
        space_info: dict,
        incremental: bool,
        overlap_days: int,
        idx: int,
        total: int
    ) -> dict:
        """ä¸‹è¼‰å–®ä¸€ Space çš„è¨Šæ¯ï¼ˆç·šç¨‹å®‰å…¨ï¼‰
        
        Args:
            space_info: Space è³‡è¨Š
            incremental: æ˜¯å¦å¢é‡æ›´æ–°
            overlap_days: å¢é‡æ›´æ–°æ™‚å›æº¯å¤©æ•¸ï¼ˆé¿å…éºæ¼ï¼‰
            idx: ç•¶å‰ç´¢å¼•
            total: ç¸½æ•¸
        """
        space_id = space_info.get("space_id")
        display_name = space_info.get("display_name", "æœªå‘½å")
        space_type = space_info.get("raw_data", {}).get("spaceType", "UNKNOWN")
        
        result = {
            "status": "success",
            "space_id": space_id,
            "display_name": display_name,
            "message_count": 0,
            "skipped": False,
            "error": None
        }
        
        try:
            reader = ChatReader(self.auth_manager)
            
            with print_lock:
                _log(f"\n[{idx}/{total}] {display_name}")
                _log(f"  Space ID: {space_id}")
                _log(f"  é¡å‹: {space_type}")
            
            # å¢é‡æ›´æ–°é‚è¼¯ï¼ˆå« overlap å›æº¯ï¼‰
            filter_query = None
            append = False
            
            if incremental:
                last_update = self._load_last_update_time(space_id)
                if last_update:
                    # å›æº¯ overlap_days å¤©ï¼Œé¿å…éºæ¼ç•¶å¤©æœªå®Œæ•´ä¸‹è¼‰çš„è¨Šæ¯
                    overlap_time = last_update - timedelta(days=overlap_days)
                    filter_query = f'createTime > "{overlap_time.isoformat()}Z"'
                    append = False  # é‡å¯« overlap æœŸé–“çš„æª”æ¡ˆ
                    with print_lock:
                        _log(f"  ä¸Šæ¬¡æ›´æ–°: {last_update.strftime('%Y-%m-%d %H:%M:%S')}")
                        if overlap_days > 0:
                            _log(f"  å›æº¯ {overlap_days} å¤©è‡³: {overlap_time.strftime('%Y-%m-%d %H:%M:%S')}")
            
            # ä¸‹è¼‰è¨Šæ¯
            messages = reader.get_all_messages(space_id, filter_query=filter_query, quiet=True)
            
            if messages:
                output_files = reader.export_to_jsonl(
                    messages,
                    space_id,
                    self.sources_dir,
                    space_name=display_name,
                    append=append
                )
                msg_count = len(messages)
                result["message_count"] = msg_count
                
                # å„²å­˜æ›´æ–°æ™‚é–“
                self._save_last_update_time(space_id, datetime.now())
                
                action = "è¿½åŠ " if append else "å¯«å…¥"
                with print_lock:
                    _log(f"  âœ… {action} {msg_count} å‰‡è¨Šæ¯è‡³ {len(output_files)} å€‹æ—¥æœŸæª”æ¡ˆ")
            else:
                if incremental and append:
                    result["skipped"] = True
                    with print_lock:
                        _log(f"  â­ï¸ ç„¡æ–°è¨Šæ¯ï¼Œè·³é")
                else:
                    with print_lock:
                        _log(f"  âš ï¸ æ²’æœ‰è¨Šæ¯")
            
        except Exception as e:
            result["status"] = "failed"
            result["error"] = str(e)
            with print_lock:
                _log(f"  âŒ å¤±æ•—ï¼š{e}")
        
        return result
    
    def download(
        self,
        space_id: Optional[str] = None,
        skip_dm: bool = True,
        incremental: bool = True,
        max_workers: int = 5,
        overlap_days: int = 1
    ) -> Dict:
        """
        ä¸‹è¼‰ Spaces çš„è¨Šæ¯ï¼ˆæ”¯æ´ä¸¦è¡Œï¼‰
        
        Args:
            space_id: æŒ‡å®š Space IDï¼ˆNone å‰‡ä¸‹è¼‰å…¨éƒ¨ï¼‰
            skip_dm: æ˜¯å¦è·³é DM
            incremental: æ˜¯å¦å¢é‡æ›´æ–°
            max_workers: ä¸¦è¡Œç·šç¨‹æ•¸
            overlap_days: å¢é‡æ›´æ–°æ™‚å›æº¯å¤©æ•¸ï¼ˆé è¨­ 1 å¤©ï¼Œé¿å…éºæ¼ï¼‰
        """
        # å–å¾— Space åˆ—è¡¨
        spaces = self.list_spaces()
        
        # éæ¿¾ DM
        if skip_dm:
            spaces = [s for s in spaces if s.get("raw_data", {}).get("spaceType") != "DIRECT_MESSAGE"]
        
        # éæ¿¾æŒ‡å®š Space
        if space_id:
            spaces = [s for s in spaces if s.get("space_id") == space_id]
            if not spaces:
                return {"success": False, "message": f"æ‰¾ä¸åˆ° Space: {space_id}"}
        
        total = len(spaces)
        success = 0
        skipped = 0
        failed = []
        total_messages = 0
        
        mode_text = "å¢é‡æ›´æ–°" if incremental else "å…¨é‡ä¸‹è¼‰"
        _log(f"\n{'='*60}")
        _log(f"æ¨¡å¼: {mode_text}")
        _log(f"ä¸¦è¡Œæ•¸: {max_workers} å€‹ç·šç¨‹")
        _log(f"é–‹å§‹è™•ç† {total} å€‹ Space")
        _log(f"é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        _log(f"{'='*60}\n")
        
        # ä½¿ç”¨ ThreadPoolExecutor ä¸¦è¡Œè™•ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_space = {
                executor.submit(self._download_single_space, space_info, incremental, overlap_days, idx, total): space_info
                for idx, space_info in enumerate(spaces, 1)
            }
            
            for future in as_completed(future_to_space):
                result = future.result()
                
                if result["status"] == "success":
                    success += 1
                    total_messages += result["message_count"]
                    if result["skipped"]:
                        skipped += 1
                else:
                    failed.append({
                        "space_id": result["space_id"],
                        "display_name": result["display_name"],
                        "error": result["error"]
                    })
        
        # çµ±è¨ˆå ±å‘Š
        _log(f"\n{'='*60}")
        _log(f"å®Œæˆï¼")
        _log(f"çµæŸæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        _log(f"{'='*60}")
        _log(f"\nğŸ“Š çµ±è¨ˆ:")
        _log(f"  æˆåŠŸ: {success}/{total}")
        if incremental:
            _log(f"  è·³éï¼ˆç„¡æ–°è¨Šæ¯ï¼‰: {skipped}")
        _log(f"  å¤±æ•—: {len(failed)}")
        _log(f"  æ–°è¨Šæ¯æ•¸: {total_messages}")
        _log(f"  å„²å­˜ä½ç½®: {self.sources_dir}")
        
        return {
            "success": True,
            "total": total,
            "success_count": success,
            "skipped": skipped,
            "failed": failed,
            "total_messages": total_messages
        }
    
    def _get_last_update_file(self, space_id: str) -> Path:
        """å–å¾—ä¸Šæ¬¡æ›´æ–°æ™‚é–“çš„æª”æ¡ˆè·¯å¾‘"""
        return self.sources_dir / f"last_update_{space_id}.json"
    
    def _load_last_update_time(self, space_id: str) -> Optional[datetime]:
        """è¼‰å…¥ä¸Šæ¬¡æ›´æ–°æ™‚é–“"""
        state_file = self._get_last_update_file(space_id)
        if state_file.exists():
            with open(state_file, "r") as f:
                state = json.load(f)
                return datetime.fromisoformat(state["last_update_time"])
        return None
    
    def _save_last_update_time(self, space_id: str, update_time: datetime):
        """å„²å­˜ä¸Šæ¬¡æ›´æ–°æ™‚é–“"""
        state_file = self._get_last_update_file(space_id)
        with open(state_file, "w") as f:
            json.dump({
                "space_id": space_id,
                "last_update_time": update_time.isoformat()
            }, f, indent=2)
