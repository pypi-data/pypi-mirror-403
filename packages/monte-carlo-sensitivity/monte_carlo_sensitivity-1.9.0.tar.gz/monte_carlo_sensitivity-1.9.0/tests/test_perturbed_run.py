"""
Tests for perturbed_run function.

Tests the core Monte Carlo sensitivity analysis function for univariate
perturbations (single input-output variable pairs).
"""

import numpy as np
import pandas as pd
import pytest

from monte_carlo_sensitivity.perturbed_run import perturbed_run


class TestPerturbedRun:
    """Test suite for perturbed_run function."""

    def test_perturbed_run_basic_output_structure(self, simple_dataframe, linear_forward_process, random_seed):
        """Test that output has expected structure and columns."""
        result = perturbed_run(
            input_df=simple_dataframe,
            input_variable='x',
            output_variable='y',
            forward_process=linear_forward_process,
            n=10
        )
        
        # Check that result is a DataFrame
        assert isinstance(result, pd.DataFrame)
        
        # Check expected columns exist
        expected_cols = [
            'input_variable', 'output_variable',
            'input_unperturbed', 'input_perturbation', 'input_perturbation_std', 'input_perturbed',
            'output_unperturbed', 'output_perturbation', 'output_perturbation_std', 'output_perturbed'
        ]
        for col in expected_cols:
            assert col in result.columns, f"Missing column: {col}"

    def test_perturbed_run_output_size(self, simple_dataframe, linear_forward_process, random_seed):
        """Test that output has correct number of rows."""
        n = 20
        result = perturbed_run(
            input_df=simple_dataframe,
            input_variable='x',
            output_variable='y',
            forward_process=linear_forward_process,
            n=n
        )
        
        # Should have n rows per input row
        expected_rows = len(simple_dataframe) * n
        assert len(result) == expected_rows

    def test_perturbed_run_variable_names(self, simple_dataframe, linear_forward_process, random_seed):
        """Test that variable names are correctly stored."""
        result = perturbed_run(
            input_df=simple_dataframe,
            input_variable='x',
            output_variable='y',
            forward_process=linear_forward_process,
            n=10
        )
        
        assert all(result['input_variable'] == 'x')
        assert all(result['output_variable'] == 'y')

    def test_perturbed_run_linear_relationship(self, random_seed):
        """Test with a known linear relationship: y = 2*x + 1."""
        # Create simple input
        input_df = pd.DataFrame({'x': [1.0, 2.0, 3.0]})
        
        def forward_process(df):
            result = df.copy()
            result['y'] = 2 * df['x'] + 1
            return result
        
        # Use fixed perturbation for predictability
        def fixed_perturbation(loc, scale, size):
            return np.ones(size) * 0.5  # Always add 0.5
        
        result = perturbed_run(
            input_df=input_df,
            input_variable='x',
            output_variable='y',
            forward_process=forward_process,
            perturbation_process=fixed_perturbation,
            n=5,
            perturbation_mean=0,
            perturbation_std=1.0
        )
        
        # Check that perturbations are applied correctly
        # For linear y = 2x + 1, if x changes by 0.5, y should change by 1.0
        assert len(result) == 15  # 3 rows * 5 perturbations
        
        # All perturbed x values should be original + 0.5
        for i in range(3):
            original_x = input_df.iloc[i]['x']
            perturbed_subset = result[i*5:(i+1)*5]
            np.testing.assert_array_almost_equal(
                perturbed_subset['input_perturbed'].values,
                original_x + 0.5
            )

    def test_perturbed_run_dropna_true(self, dataframe_with_nans, identity_forward_process, random_seed):
        """Test that NaN rows are dropped when dropna=True."""
        result = perturbed_run(
            input_df=dataframe_with_nans,
            input_variable='x',
            output_variable='x',
            forward_process=identity_forward_process,
            n=10,
            dropna=True
        )
        
        # Should have fewer rows than input * n due to NaN removal
        # dataframe_with_nans has NaN in x at index 2
        expected_rows = (len(dataframe_with_nans) - 1) * 10  # 4 valid rows * 10
        assert len(result) == expected_rows
        
        # No NaN values should be present
        assert not result['input_unperturbed'].isna().any()

    def test_perturbed_run_dropna_false(self, dataframe_with_nans, identity_forward_process, random_seed):
        """Test that NaN rows are kept when dropna=False."""
        result = perturbed_run(
            input_df=dataframe_with_nans,
            input_variable='x',
            output_variable='x',
            forward_process=identity_forward_process,
            n=10,
            dropna=False
        )
        
        # Should have all rows (including NaN)
        expected_rows = len(dataframe_with_nans) * 10
        assert len(result) == expected_rows

    def test_perturbed_run_perturbation_std_custom(self, simple_dataframe, linear_forward_process, random_seed):
        """Test using custom perturbation standard deviation."""
        custom_std = 2.5
        result = perturbed_run(
            input_df=simple_dataframe,
            input_variable='x',
            output_variable='y',
            forward_process=linear_forward_process,
            n=100,
            perturbation_std=custom_std
        )
        
        # Check that perturbations have approximately the specified std
        # (using first row's perturbations as sample)
        first_row_perturbations = result['input_perturbed'].values[:100] - result['input_unperturbed'].values[0]
        actual_std = np.std(first_row_perturbations, ddof=1)
        
        # Should be close to custom_std (within 20% due to random sampling)
        assert abs(actual_std - custom_std) / custom_std < 0.2

    def test_perturbed_run_perturbation_mean(self, simple_dataframe, linear_forward_process, random_seed):
        """Test using non-zero perturbation mean."""
        custom_mean = 1.5
        result = perturbed_run(
            input_df=simple_dataframe,
            input_variable='x',
            output_variable='y',
            forward_process=linear_forward_process,
            n=100,
            perturbation_mean=custom_mean,
            perturbation_std=1.0
        )
        
        # Check that perturbations have approximately the specified mean
        first_row_perturbations = result['input_perturbed'].values[:100] - result['input_unperturbed'].values[0]
        actual_mean = np.mean(first_row_perturbations)
        
        # Should be close to custom_mean (within reasonable tolerance)
        assert abs(actual_mean - custom_mean) < 0.3

    def test_perturbed_run_unperturbed_values_constant(self, simple_dataframe, linear_forward_process, random_seed):
        """Test that unperturbed values are constant for each original row."""
        result = perturbed_run(
            input_df=simple_dataframe,
            input_variable='x',
            output_variable='y',
            forward_process=linear_forward_process,
            n=20
        )
        
        # For each original row, all perturbations should have same unperturbed value
        for i in range(len(simple_dataframe)):
            subset = result[i*20:(i+1)*20]
            unperturbed_vals = subset['input_unperturbed'].unique()
            assert len(unperturbed_vals) == 1
            assert unperturbed_vals[0] == simple_dataframe.iloc[i]['x']

    def test_perturbed_run_identity_process(self, simple_dataframe, identity_forward_process, random_seed):
        """Test with identity forward process (output = input)."""
        result = perturbed_run(
            input_df=simple_dataframe,
            input_variable='x',
            output_variable='x',
            forward_process=identity_forward_process,
            n=10
        )
        
        # Input and output perturbations should be identical
        np.testing.assert_array_almost_equal(
            result['input_perturbation'].values,
            result['output_perturbation'].values
        )

    def test_perturbed_run_quadratic_relationship(self, random_seed):
        """Test with quadratic relationship: y = x^2."""
        input_df = pd.DataFrame({'x': [2.0, 3.0, 4.0]})
        
        def quadratic_process(df):
            result = df.copy()
            result['y'] = df['x'] ** 2
            return result
        
        result = perturbed_run(
            input_df=input_df,
            input_variable='x',
            output_variable='y',
            forward_process=quadratic_process,
            n=50
        )
        
        # Check that output is calculated correctly
        assert len(result) == 150  # 3 * 50
        
        # Verify relationship holds for perturbed values
        for _, row in result.iterrows():
            expected_output = row['input_perturbed'] ** 2
            # Allow small numerical error
            assert abs(row['output_perturbed'] - expected_output) < 1e-10

    def test_perturbed_run_small_n(self, simple_dataframe, linear_forward_process, random_seed):
        """Test with small number of perturbations."""
        result = perturbed_run(
            input_df=simple_dataframe,
            input_variable='x',
            output_variable='y',
            forward_process=linear_forward_process,
            n=2
        )
        
        assert len(result) == len(simple_dataframe) * 2
        assert 'input_perturbation_std' in result.columns

    def test_perturbed_run_reproducibility(self, simple_dataframe, linear_forward_process):
        """Test that results are reproducible with same random seed."""
        np.random.seed(123)
        result1 = perturbed_run(
            input_df=simple_dataframe,
            input_variable='x',
            output_variable='y',
            forward_process=linear_forward_process,
            n=10
        )
        
        np.random.seed(123)
        result2 = perturbed_run(
            input_df=simple_dataframe,
            input_variable='x',
            output_variable='y',
            forward_process=linear_forward_process,
            n=10
        )
        
        pd.testing.assert_frame_equal(result1, result2)

    def test_perturbed_run_single_row_input(self, linear_forward_process, random_seed):
        """Test with single-row input DataFrame."""
        input_df = pd.DataFrame({'x': [5.0]})
        
        # Single-row input requires explicit perturbation_std since std=0
        result = perturbed_run(
            input_df=input_df,
            input_variable='x',
            output_variable='y',
            forward_process=linear_forward_process,
            n=25,
            perturbation_std=1.0  # Explicit std since single row has zero variance
        )
        
        assert len(result) == 25
        assert all(result['input_unperturbed'] == 5.0)

    def test_perturbed_run_zero_variance_input_auto_std(self, linear_forward_process, random_seed, caplog):
        """Test with zero-variance input, triggering automatic default perturbation_std."""
        import logging
        caplog.set_level(logging.WARNING)
        
        # Create input with all identical values (zero variance)
        input_df = pd.DataFrame({'x': [10.0, 10.0, 10.0]})
        
        # Don't provide perturbation_std, let it use default
        result = perturbed_run(
            input_df=input_df,
            input_variable='x',
            output_variable='y',
            forward_process=linear_forward_process,
            n=20
        )
        
        # Should complete successfully with default perturbation_std=1.0
        assert len(result) == 60  # 3 rows * 20 perturbations
        assert all(result['input_unperturbed'] == 10.0)
        
        # Check that warning was logged about using default std
        assert any("using default perturbation_std=1.0" in record.message for record in caplog.records)
