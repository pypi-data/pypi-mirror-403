Metadata-Version: 2.4
Name: hexin-server
Version: 0.1.23
Summary: FastAPI server that proxies OpenAI API endpoints using hexin_engine backend
License: MIT
License-File: LICENSE
Author: LinXueyuanStdio
Author-email: 23211526+LinXueyuanStdio@users.noreply.github.com
Requires-Python: >=3.8,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Programming Language :: Python :: 3.14
Requires-Dist: fastapi
Requires-Dist: loguru
Requires-Dist: openai
Requires-Dist: python-dotenv
Requires-Dist: requests
Requires-Dist: typing-extensions
Requires-Dist: uvicorn
Requires-Dist: xlin
Description-Content-Type: text/markdown

# Hexin Proxy Server

ä¸€ä¸ª FastAPI æœåŠ¡å™¨ï¼Œæä¾› **OpenAI** å’Œ **Anthropic** å…¼å®¹çš„ API æŽ¥å£ï¼Œé€šè¿‡ä»£ç† Hexin åŽç«¯æœåŠ¡æ¥æä¾› AI åŠŸèƒ½ã€‚

## åŠŸèƒ½ç‰¹æ€§

- **Chat Completions API**: å…¼å®¹ OpenAI çš„èŠå¤©å®ŒæˆæŽ¥å£
- **Claude Messages API**: å…¼å®¹ Anthropic Messages APIï¼Œæ”¯æŒ Claude Code å’Œ Anthropic SDK
- **Responses API**: å…¼å®¹ OpenAI çš„æŽ¨ç†å“åº”æŽ¥å£ (æ”¯æŒ o3ã€o4-mini)
- **Embeddings API**: å…¼å®¹ OpenAI çš„æ–‡æœ¬åµŒå…¥æŽ¥å£
- **æ¨¡åž‹åˆ—è¡¨**: æ”¯æŒåˆ—å‡ºå¯ç”¨çš„ AI æ¨¡åž‹
- **æµå¼å“åº”**: æ”¯æŒå®žæ—¶æµå¼èŠå¤©å“åº”å’ŒæŽ¨ç†å“åº”
- **å¤šæ¨¡åž‹æ”¯æŒ**: æ”¯æŒå¤šç§å¤§è¯­è¨€æ¨¡åž‹å’ŒåµŒå…¥æ¨¡åž‹

## æ”¯æŒçš„æŽ¥å£

### Chat Completions (OpenAI æ ¼å¼)
- `POST /v1/chat/completions` - åˆ›å»ºèŠå¤©å®Œæˆ
- æ”¯æŒæµå¼å’Œéžæµå¼å“åº”
- æ”¯æŒå·¥å…·è°ƒç”¨å’Œå‡½æ•°è°ƒç”¨
- æ”¯æŒå¤šç§æ¨¡åž‹ï¼šGPTã€Claudeã€Geminiã€DeepSeek ç­‰
- **é»˜è®¤ç«¯å£**: 8777

### Claude Messages API (Anthropic æ ¼å¼)
- `POST /v1/messages` - åˆ›å»ºæ¶ˆæ¯ï¼ˆå®Œå…¨å…¼å®¹ Anthropic SDKï¼‰
- æ”¯æŒæµå¼å’Œéžæµå¼å“åº”
- æ”¯æŒå¤šè½®å¯¹è¯å’Œ system æç¤ºè¯
- å¯ç›´æŽ¥ä¸Ž **Claude Code** å’Œ **Anthropic SDK** é›†æˆ
- **é»˜è®¤ç«¯å£**: 8777
- ðŸ“– [è¯¦ç»†æ–‡æ¡£](./CLAUDE_MESSAGES_API.md)

### Responses (æŽ¨ç†å“åº”)
- `POST /v1/responses` - åˆ›å»ºæŽ¨ç†å“åº” (ä¸“ä¸º o3ã€o4-mini ç­‰æŽ¨ç†æ¨¡åž‹è®¾è®¡)
- æ”¯æŒæµå¼å’Œéžæµå¼å“åº”
- æ”¯æŒæŽ¨ç†é…ç½® (effort: low/medium/high, summary: brief/detailed)
- è¿”å›žè¯¦ç»†çš„æŽ¨ç†è¿‡ç¨‹å’Œç»“æžœ

### Embeddings
- `POST /v1/embeddings` - åˆ›å»ºæ–‡æœ¬åµŒå…¥
- æ”¯æŒçš„æ¨¡åž‹ï¼štext-embedding-ada-002, text-embedding-3-small, text-embedding-3-large
- æ”¯æŒå•ä¸ªå’Œæ‰¹é‡æ–‡æœ¬å¤„ç†

### Models
- `GET /v1/models` - åˆ—å‡ºå¯ç”¨æ¨¡åž‹
- è¿”å›žèŠå¤©ã€æŽ¨ç†å’ŒåµŒå…¥æ¨¡åž‹åˆ—è¡¨

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install hexin-server --upgrade
```

æˆ–è€…æœ¬åœ°å®‰è£…

```bash
git clone https://github.com/LinXueyuanStdio/hexin-proxy-server.git
cd hexin-proxy-server
pip install -e .
```

### 2. é…ç½®çŽ¯å¢ƒå˜é‡

```bash
cp .env.example .env
```

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
HITHINK_APP_ID=your_app_id
HITHINK_APP_SECRET=your_app_secret
HITHINK_APP_URL=your_app_url
```

### 3. å¯åŠ¨æœåŠ¡å™¨

#### OpenAI å…¼å®¹æœåŠ¡å™¨ï¼ˆé»˜è®¤ç«¯å£ 8777ï¼‰

```bash
# ç›´æŽ¥è¿è¡Œ
python -m hexin_server

# æˆ–è€…æŒ‡å®šå‚æ•°
python -m hexin_server --host 0.0.0.0 --port 8777 --reload
```

### 4. æµ‹è¯•æŽ¥å£

#### Chat Completions ç¤ºä¾‹ï¼ˆOpenAI æ ¼å¼ï¼‰

```bash
curl -X POST "http://localhost:8777/v1/chat/completions" \
  -H "Authorization: Bearer sk-fastapi-proxy-key-12345" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      {"role": "user", "content": "Hello, how are you?"}
    ]
  }'
```

#### Claude Messages ç¤ºä¾‹ï¼ˆAnthropic æ ¼å¼ï¼‰

```bash
curl -X POST "http://localhost:8777/v1/messages" \
  -H "x-api-key: sk-fastapi-proxy-key-12345" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-3-sonnet-20240229",
    "max_tokens": 1024,
    "messages": [
      {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
    ]
  }'
```

#### Responses æŽ¨ç†ç¤ºä¾‹

```bash
# éžæµå¼æŽ¨ç†å“åº”
curl -X POST "http://localhost:8777/v1/responses" \
  -H "Authorization: Bearer sk-fastapi-proxy-key-12345" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "o3",
    "input": "ä¼°ç®—ä¸‹æµ·æ°´çš„æ€»é‡é‡",
    "reasoning": {
      "effort": "medium",
      "summary": "detailed"
    }
  }'

# æµå¼æŽ¨ç†å“åº”
curl -X POST "http://localhost:8777/v1/responses" \
  -H "Authorization: Bearer sk-fastapi-proxy-key-12345" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "o3",
    "input": "ä¼°ç®—ä¸‹æµ·æ°´çš„æ€»é‡é‡",
    "reasoning": {
      "effort": "medium",
      "summary": "detailed"
    },
    "stream": true
  }'
```

#### Embeddings ç¤ºä¾‹

```bash
curl -X POST "http://localhost:8777/v1/embeddings" \
  -H "Authorization: Bearer sk-fastapi-proxy-key-12345" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Hello, world!",
    "model": "text-embedding-ada-002"
  }'
```

## ä½¿ç”¨ OpenAI å’Œ Anthropic å®¢æˆ·ç«¯åº“

### OpenAI æ ¼å¼ API

```python
import openai

# é…ç½®å®¢æˆ·ç«¯
client = openai.OpenAI(
    api_key="sk-fastapi-proxy-key-12345",
    base_url="http://localhost:8777/v1"
)

# èŠå¤©å®Œæˆ
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "user", "content": "Hello, how are you?"}
    ]
)

# åˆ›å»ºåµŒå…¥
embeddings = client.embeddings.create(
    model="text-embedding-ada-002",
    input="Hello, world!"
)
```

### Anthropic Messages API

```python
from anthropic import Anthropic

# é…ç½®å®¢æˆ·ç«¯
client = Anthropic(
    base_url="http://localhost:8777",
    api_key="sk-fastapi-proxy-key-12345",
)

# åˆ›å»ºæ¶ˆæ¯
message = client.messages.create(
    model="claude-3-sonnet-20240229",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
    ]
)

print(message.content[0].text)

# æµå¼å“åº”
with client.messages.stream(
    model="claude-3-sonnet-20240229",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "è®²ä¸€ä¸ªæ•…äº‹"}
    ]
) as stream:
    for text in stream.text_stream:
        print(text, end="", flush=True)
```

### æŽ¨ç†å“åº” API

æŽ¨ç†å“åº”éœ€è¦ä½¿ç”¨ requests åº“ï¼Œå› ä¸º OpenAI å®¢æˆ·ç«¯æš‚ä¸æ”¯æŒ responses APIï¼š

```python
import requests

response = requests.post(
    "http://localhost:8777/v1/responses",
    headers={
        "Authorization": "Bearer sk-fastapi-proxy-key-12345",
        "Content-Type": "application/json"
    },
    json={
        "model": "o3",
        "input": "ä¼°ç®—ä¸‹æµ·æ°´çš„æ€»é‡é‡",
        "reasoning": {
            "effort": "medium",
            "summary": "detailed"
        }
    }
)
```

## è¯¦ç»†æ–‡æ¡£

- **[Claude Messages API ä½¿ç”¨æŒ‡å—](./CLAUDE_MESSAGES_API.md)** - Anthropic Messages API å®Œæ•´æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹
- **[Responses API ä½¿ç”¨æŒ‡å—](./RESPONSES_API.md)** - æŽ¨ç†æŽ¥å£æ–‡æ¡£
- **[Embedding API ä½¿ç”¨æŒ‡å—](./EMBEDDING_API.md)** - åµŒå…¥æŽ¥å£æ–‡æ¡£

## é¡¹ç›®ç»“æž„

```
hexin-proxy-server/
â”œâ”€â”€ hexin_server/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ __main__.py          # ç»Ÿä¸€æœåŠ¡å™¨ (ç«¯å£ 8777ï¼Œæ”¯æŒ OpenAI å’Œ Anthropic API)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_embedding.py    # åµŒå…¥æŽ¥å£æµ‹è¯•
â”‚   â””â”€â”€ test_anthropic_sdk.py # Anthropic SDK æµ‹è¯•
â”œâ”€â”€ CLAUDE_MESSAGES_API.md   # Claude API ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ RESPONSES_API.md         # æŽ¨ç† API ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ EMBEDDING_API.md         # åµŒå…¥ API ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ README.md                # é¡¹ç›®æ€»è§ˆ
â”œâ”€â”€ pyproject.toml           # é¡¹ç›®é…ç½®
â””â”€â”€ .env.example             # çŽ¯å¢ƒå˜é‡ç¤ºä¾‹
```

## æµ‹è¯•

é¡¹ç›®åŒ…å«å¤šç§æµ‹è¯•è„šæœ¬æ¥éªŒè¯åŠŸèƒ½ï¼š

```bash
# æµ‹è¯•åµŒå…¥æŽ¥å£
python tests/test_embedding.py

# æµ‹è¯• Anthropic SDKï¼ˆClaude Messages APIï¼‰
python tests/test_anthropic_sdk.py
```

æ‰€æœ‰æµ‹è¯•éƒ½ä½¿ç”¨ç»Ÿä¸€çš„ 8777 ç«¯å£æœåŠ¡å™¨ã€‚

## å¥åº·æ£€æŸ¥

æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€ï¼š

```bash
curl http://localhost:8777/health
```

å“åº”ï¼š
```json
{
  "status": "healthy",
  "authenticated": true
}
```

## è´¡çŒ®

æ¬¢è¿Žæäº¤ Issue å’Œ Pull Requestï¼

## è®¸å¯è¯

[License file](./LICENSE)

