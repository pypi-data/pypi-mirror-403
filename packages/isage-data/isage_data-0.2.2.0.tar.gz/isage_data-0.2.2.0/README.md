# SAGE Data ï¿½ï¿½

**Dataset management module for SAGE benchmark suite**

Provides unified access to multiple datasets through a two-layer architecture:
- **Sources**: Physical datasets (qa_base, bbh, mmlu, gpqa, locomo, orca_dpo)
- **Usages**: Logical views for experiments (rag, libamm, neuromem, agent_eval)

## Quick Start

```bash
./quickstart.sh
source .venv/bin/activate
```

Or manual steps:

```python
from sage.data import DataManager

manager = DataManager.get_instance()

# Access datasets by logical usage profile
rag = manager.get_by_usage("rag")
qa_loader = rag.load("qa_base")  # already instantiated
queries = qa_loader.load_queries()

# Or fetch a specific data source directly
bbh_loader = manager.get_by_source("bbh")
tasks = bbh_loader.get_task_names()
```

## ğŸ› ï¸ CLI ä½¿ç”¨æ–¹å¼ï¼ˆç²¾ç®€ç‰ˆï¼‰

å®‰è£…åå¯ç›´æ¥ä½¿ç”¨ `sage-data` å‘½ä»¤ï¼š

```bash
sage-data list               # æ˜¾ç¤ºæ•°æ®æºçŠ¶æ€ï¼ˆå·²ä¸‹è½½/ç¼ºå¤±/è¿œç¨‹ï¼‰
sage-data usage rag          # æŸ¥çœ‹æŸä¸ª usage çš„æ•°æ®æ˜ å°„
sage-data download locomo    # ä¸‹è½½æŒ‡å®šæ•°æ®æºï¼ˆä»…æ”¯æŒéƒ¨åˆ†æºï¼‰

# é€‰é¡¹
sage-data list --json        # JSON è¾“å‡ºï¼Œä¾¿äºè„šæœ¬å¤„ç†
sage-data --data-root /path  # æŒ‡å®šè‡ªå®šä¹‰æ•°æ®æ ¹ç›®å½•
```

å½“å‰æ”¯æŒè‡ªåŠ¨ä¸‹è½½çš„æºï¼š`locomo`, `longmemeval`, `memagentbench`, `mmlu`ã€‚
å…¶ä»–å¦‚ `gpqa`, `orca_dpo` é‡‡ç”¨æŒ‰éœ€åœ¨çº¿åŠ è½½ï¼ˆHugging Faceï¼‰ï¼Œ`qa_base`/`bbh` ç­‰éšåŒ…å†…ç½®ã€‚

## Available Datasets

| Dataset | Description | Download Required | Storage |
|---------|-------------|-------------------|---------|
| **qa_base** | Question-Answering with knowledge base | âŒ No (included) | Local files |
| **locomo** | Long-context memory benchmark | âœ… Yes (`python -m locomo.download`) | Local files (2.68MB) |
| **bbh** | BIG-Bench Hard reasoning tasks | âŒ No (included) | Local JSON files |
| **mmlu** | Massive Multitask Language Understanding | ğŸ“¥ Optional (`python -m mmlu.download --all-subjects`) | On-demand or Local (~160MB) |
| **gpqa** | Graduate-Level Question Answering | âœ… Auto (Hugging Face) | On-demand (~5MB cached) |
| **orca_dpo** | Preference pairs for alignment/DPO | âœ… Auto (Hugging Face) | On-demand (varies) |

See `examples/` for detailed usage examples.

## ğŸ“– Examples

```bash
python examples/qa_examples.py            # QA dataset usage
python examples/locomo_examples.py        # LoCoMo dataset usage
python examples/bbh_examples.py           # BBH dataset usage
python examples/mmlu_examples.py          # MMLU dataset usage
python examples/gpqa_examples.py          # GPQA dataset usage
python examples/orca_dpo_examples.py      # Orca DPO dataset usage
python examples/integration_example.py    # Cross-dataset integration
```

## License

MIT License - see [LICENSE](LICENSE) file.

## ğŸ”— Links

- **Repository**: https://github.com/intellistream/sageData
- **Issues**: https://github.com/intellistream/sageData/issues

## â“ Common Issues

**Q: Where's the LoCoMo data?**  
A: Run `python -m locomo.download` to download it (2.68MB from Hugging Face).

**Q: How to download MMLU for offline use?**  
A: Run `python -m mmlu.download --all-subjects` to download all subjects (~160MB).

**Q: GPQA access error?**  
A: You need to accept the dataset terms on Hugging Face: https://huggingface.co/datasets/Idavidrein/gpqa

**Q: How to use Orca DPO for alignment research?**  
A: Use `DataManager.get_by_source("orca_dpo")` to get the loader, then use `format_for_dpo()` to prepare data for training.

---

**Version**: 0.1.0 | **Last Updated**: December 2025
