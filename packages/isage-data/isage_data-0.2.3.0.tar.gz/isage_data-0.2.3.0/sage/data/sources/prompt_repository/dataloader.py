"""
Prompt Repository DataLoader

Manages a collection of prompts for various AI tasks and applications.
"""

import json
from pathlib import Path
from typing import Any, Dict, Generator, List, Optional

from datasets import load_dataset

# Check if Hugging Face datasets library is available
try:
    from datasets import load_dataset

    HF_AVAILABLE = True
except ImportError:
    HF_AVAILABLE = False


class PromptRepositoryDataLoader:
    """
    DataLoader for accessing and managing AI prompts.

    This loader provides access to a curated collection of prompts organized by:
    - Category (system, task-specific, few-shot, chain-of-thought, agent)
    - Use case (coding, translation, summarization, reasoning, etc.)
    - Complexity level (simple, intermediate, advanced)

    Supports both local JSON storage and Hugging Face Hub integration.
    """

    def __init__(self, data_dir: Optional[str] = None):
        """
        Initialize the Prompt Repository DataLoader.

        Args:
            data_dir: Directory containing local prompt data (JSON format)
                     If None, uses default: sage/data/sources/prompt_repository/data/
        """
        if data_dir is None:
            # Default to local data directory
            current_dir = Path(__file__).parent
            data_dir = current_dir / "data"

        self.data_dir = Path(data_dir)
        self._prompts: Optional[List[Dict[str, Any]]] = None
        self._hf_dataset = None

        # Attempt to load from local storage first
        if not self.data_dir.exists() or not any(self.data_dir.glob("*.json")):
            # If local data doesn't exist, try loading from HF Hub
            if HF_AVAILABLE:
                self._load_from_hf_hub()
            else:
                # Create empty data directory
                self.data_dir.mkdir(parents=True, exist_ok=True)

    def _load_from_hf_hub(self):
        """Load prompts from Hugging Face Hub as fallback."""
        try:
            # Try to load from intellistream/sage-prompt-repository
            self._hf_dataset = load_dataset("intellistream/sage-prompt-repository", split="train")
            print("✓ Loaded prompts from Hugging Face Hub: intellistream/sage-prompt-repository")
        except Exception as e:
            print(f"⚠ Could not load from HF Hub: {e}")
            print("  Using local data only.")

    def load_prompts(self, category: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        Load all prompts, optionally filtered by category.

        Args:
            category: Filter by category (e.g., "system", "task", "agent", "few-shot")
                     If None, returns all prompts.

        Returns:
            List of prompt dictionaries containing:
            - prompt_id: Unique identifier
            - category: Prompt category
            - name: Human-readable name
            - description: What the prompt does
            - template: The actual prompt text
            - variables: List of variables in the template
            - tags: List of tags for filtering
            - examples: Optional usage examples
            - metadata: Additional information
        """
        if self._prompts is None:
            self._prompts = self._load_all_prompts()

        if category is None:
            return self._prompts

        # Filter by category
        return [p for p in self._prompts if p.get("category") == category]

    def _load_all_prompts(self) -> List[Dict[str, Any]]:
        """Load prompts from all available sources."""
        prompts = []

        # Load from local JSON files
        if self.data_dir.exists():
            for json_file in self.data_dir.glob("*.json"):
                try:
                    with open(json_file, encoding="utf-8") as f:
                        data = json.load(f)
                        if isinstance(data, list):
                            prompts.extend(data)
                        elif isinstance(data, dict):
                            prompts.append(data)
                except Exception as e:
                    print(f"Warning: Failed to load {json_file}: {e}")

        # Load from HF Hub if available
        if self._hf_dataset is not None:
            for item in self._hf_dataset:
                prompts.append(dict(item))

        return prompts

    def get_prompt(self, prompt_id: str) -> Optional[Dict[str, Any]]:
        """
        Get a specific prompt by ID.

        Args:
            prompt_id: Unique prompt identifier

        Returns:
            Prompt dictionary or None if not found
        """
        prompts = self.load_prompts()
        for prompt in prompts:
            if prompt.get("prompt_id") == prompt_id:
                return prompt
        return None

    def search_prompts(
        self, query: str, fields: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        Search prompts by keyword in specified fields.

        Args:
            query: Search query string
            fields: Fields to search in (default: ["name", "description", "tags"])

        Returns:
            List of matching prompts
        """
        if fields is None:
            fields = ["name", "description", "tags"]

        query_lower = query.lower()
        prompts = self.load_prompts()
        results = []

        for prompt in prompts:
            for field in fields:
                value = prompt.get(field, "")
                if isinstance(value, str) and query_lower in value.lower():
                    results.append(prompt)
                    break
                elif isinstance(value, list) and any(
                    query_lower in str(item).lower() for item in value
                ):
                    results.append(prompt)
                    break

        return results

    def get_categories(self) -> List[str]:
        """
        Get all available prompt categories.

        Returns:
            List of unique category names
        """
        prompts = self.load_prompts()
        categories = {p.get("category", "unknown") for p in prompts}
        return sorted(categories)

    def get_tags(self) -> List[str]:
        """
        Get all available tags.

        Returns:
            List of unique tags
        """
        prompts = self.load_prompts()
        tags = set()
        for prompt in prompts:
            prompt_tags = prompt.get("tags", [])
            if isinstance(prompt_tags, list):
                tags.update(prompt_tags)
        return sorted(tags)

    def iter_prompts(self, category: Optional[str] = None) -> Generator[Dict[str, Any], None, None]:
        """
        Iterate over prompts.

        Args:
            category: Filter by category

        Yields:
            Prompt dictionaries
        """
        prompts = self.load_prompts(category=category)
        yield from prompts

    def statistics(self) -> Dict[str, Any]:
        """
        Get statistics about the prompt repository.

        Returns:
            Dictionary containing:
            - total_prompts: Total number of prompts
            - categories: Breakdown by category
            - tags: Most common tags
            - sources: Data sources (local, hf_hub)
        """
        prompts = self.load_prompts()

        # Count by category
        category_counts: Dict[str, int] = {}
        tag_counts: Dict[str, int] = {}

        for prompt in prompts:
            category = prompt.get("category", "unknown")
            category_counts[category] = category_counts.get(category, 0) + 1

            tags = prompt.get("tags", [])
            if isinstance(tags, list):
                for tag in tags:
                    tag_counts[tag] = tag_counts.get(tag, 0) + 1

        # Determine sources
        sources = []
        if self.data_dir.exists() and any(self.data_dir.glob("*.json")):
            sources.append("local")
        if self._hf_dataset is not None:
            sources.append("hf_hub")

        return {
            "total_prompts": len(prompts),
            "categories": category_counts,
            "top_tags": sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:10],
            "sources": sources,
        }

    def add_prompt(self, prompt: Dict[str, Any]) -> bool:
        """
        Add a new prompt to the local repository.

        Args:
            prompt: Prompt dictionary (must include prompt_id, category, name, template)

        Returns:
            True if successful, False otherwise
        """
        required_fields = ["prompt_id", "category", "name", "template"]
        if not all(field in prompt for field in required_fields):
            print(f"Error: Prompt must contain fields: {required_fields}")
            return False

        # Ensure data directory exists
        self.data_dir.mkdir(parents=True, exist_ok=True)

        # Save to category-specific JSON file
        category = prompt["category"]
        json_file = self.data_dir / f"{category}.json"

        # Load existing prompts from this category
        existing = []
        if json_file.exists():
            try:
                with open(json_file, encoding="utf-8") as f:
                    existing = json.load(f)
            except Exception as e:
                print(f"Warning: Could not load {json_file}: {e}")

        # Check for duplicate ID
        if any(p.get("prompt_id") == prompt["prompt_id"] for p in existing):
            print(f"Error: Prompt with ID '{prompt['prompt_id']}' already exists")
            return False

        # Add new prompt
        existing.append(prompt)

        # Save back to file
        try:
            with open(json_file, "w", encoding="utf-8") as f:
                json.dump(existing, f, indent=2, ensure_ascii=False)
            # Invalidate cache
            self._prompts = None
            return True
        except Exception as e:
            print(f"Error: Failed to save prompt: {e}")
            return False
