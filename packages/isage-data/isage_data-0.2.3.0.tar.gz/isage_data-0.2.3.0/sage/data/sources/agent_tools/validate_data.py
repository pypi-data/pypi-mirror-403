#!/usr/bin/env python3
"""
Data Validation Script for Agent Tools

Performs comprehensive data quality checks:
- Schema validation
- ID uniqueness and format
- Category coverage
- Empty field detection
- Cross-reference validation
"""

import json
import sys
from pathlib import Path

# Add to path for imports
sys.path.insert(0, str(Path(__file__).parent))

from schemas import AgentToolRecord, CategoryTaxonomy, DatasetStats


def validate_tool_catalog(data_dir: Path) -> dict:
    """Validate tool_catalog.jsonl."""
    catalog_file = data_dir / "tool_catalog.jsonl"

    print("üìã Validating tool_catalog.jsonl...")
    print("=" * 60)

    results = {
        "total_tools": 0,
        "errors": [],
        "warnings": [],
        "tool_ids": set(),
        "names": set(),
        "categories": set(),
        "capabilities": set(),
    }

    with open(catalog_file, encoding="utf-8") as f:
        for line_num, line in enumerate(f, 1):
            if not line.strip():
                continue

            try:
                data = json.loads(line)
                tool = AgentToolRecord(**data)

                # Check duplicates
                if tool.tool_id in results["tool_ids"]:
                    results["errors"].append(f"Line {line_num}: Duplicate tool_id '{tool.tool_id}'")
                else:
                    results["tool_ids"].add(tool.tool_id)

                if tool.name in results["names"]:
                    results["errors"].append(f"Line {line_num}: Duplicate name '{tool.name}'")
                else:
                    results["names"].add(tool.name)

                # Collect categories and capabilities
                results["categories"].add(tool.category)
                results["capabilities"].update(tool.capabilities)

                # Check for empty fields
                if not tool.inputs:
                    results["warnings"].append(
                        f"Line {line_num}: Tool '{tool.tool_id}' has no inputs"
                    )

                if not tool.outputs:
                    results["warnings"].append(
                        f"Line {line_num}: Tool '{tool.tool_id}' has no outputs"
                    )

                if not tool.invoke_examples:
                    results["warnings"].append(
                        f"Line {line_num}: Tool '{tool.tool_id}' has no examples"
                    )

                results["total_tools"] += 1

            except Exception as e:
                results["errors"].append(f"Line {line_num}: {str(e)}")

    print(f"‚úì Processed {results['total_tools']} tools")
    print(f"‚úì Unique tool_ids: {len(results['tool_ids'])}")
    print(f"‚úì Unique names: {len(results['names'])}")
    print(f"‚úì Categories used: {len(results['categories'])}")
    print(f"‚úì Unique capabilities: {len(results['capabilities'])}")

    return results


def validate_categories(data_dir: Path) -> dict:
    """Validate categories.json."""
    categories_file = data_dir / "categories.json"

    print("\nüìÇ Validating categories.json...")
    print("=" * 60)

    results = {
        "errors": [],
        "warnings": [],
        "category_paths": set(),
    }

    with open(categories_file, encoding="utf-8") as f:
        data = json.load(f)
        taxonomy = CategoryTaxonomy(**data)

        for cat_def in taxonomy.taxonomy:
            if cat_def.path in results["category_paths"]:
                results["errors"].append(f"Duplicate category path: {cat_def.path}")
            results["category_paths"].add(cat_def.path)

        print(f"‚úì Defined {len(taxonomy.taxonomy)} categories")
        print(f"‚úì Taxonomy version: {taxonomy.version}")

    return results


def validate_stats(data_dir: Path) -> dict:
    """Validate stats.json."""
    stats_file = data_dir / "stats.json"

    print("\nüìä Validating stats.json...")
    print("=" * 60)

    results = {
        "errors": [],
        "warnings": [],
    }

    with open(stats_file, encoding="utf-8") as f:
        data = json.load(f)
        stats = DatasetStats(**data)

        print(f"‚úì Total tools: {stats.total_tools}")
        print(f"‚úì Total categories: {stats.total_categories}")
        print(f"‚úì Last updated: {stats.last_updated}")
        print(f"‚úì Version: {stats.version}")

    return results


def cross_validate(
    catalog_results: dict, categories_results: dict, stats_results: dict, data_dir: Path
) -> dict:
    """Cross-validate data consistency."""
    print("\nüîç Cross-validating data...")
    print("=" * 60)

    results = {
        "errors": [],
        "warnings": [],
    }

    # Load stats for comparison
    with open(data_dir / "stats.json") as f:
        stats = DatasetStats(**json.load(f))

    # Check tool count
    if catalog_results["total_tools"] != stats.total_tools:
        results["errors"].append(
            f"Tool count mismatch: catalog={catalog_results['total_tools']}, "
            f"stats={stats.total_tools}"
        )
    else:
        print(f"‚úì Tool count matches: {stats.total_tools}")

    # Check category count
    if len(catalog_results["categories"]) != len(categories_results["category_paths"]):
        results["warnings"].append(
            f"Category count mismatch: used={len(catalog_results['categories'])}, "
            f"defined={len(categories_results['category_paths'])}"
        )
    else:
        print(f"‚úì Category count matches: {len(catalog_results['categories'])}")

    # Check all used categories are defined
    undefined_categories = catalog_results["categories"] - categories_results["category_paths"]
    if undefined_categories:
        results["errors"].append(f"Undefined categories used: {undefined_categories}")
    else:
        print("‚úì All used categories are defined")

    # Check unused categories
    unused_categories = categories_results["category_paths"] - catalog_results["categories"]
    if unused_categories:
        results["warnings"].append(f"Unused categories defined: {unused_categories}")

    # Check category distribution
    for category, count in stats.category_distribution.items():
        if category not in categories_results["category_paths"]:
            results["errors"].append(f"Category in stats not in taxonomy: {category}")

    print(f"‚úì Category distribution: {len(stats.category_distribution)} entries")

    return results


def print_summary(all_results: dict):
    """Print validation summary."""
    print("\n" + "=" * 60)
    print("üìã VALIDATION SUMMARY")
    print("=" * 60)

    total_errors = sum(len(r.get("errors", [])) for r in all_results.values())
    total_warnings = sum(len(r.get("warnings", [])) for r in all_results.values())

    if total_errors == 0:
        print("‚úÖ No errors found!")
    else:
        print(f"‚ùå Found {total_errors} errors:")
        for name, results in all_results.items():
            for error in results.get("errors", []):
                print(f"   [{name}] {error}")

    if total_warnings > 0:
        print(f"\n‚ö†Ô∏è  Found {total_warnings} warnings:")
        for name, results in all_results.items():
            for warning in results.get("warnings", []):
                print(f"   [{name}] {warning}")

    print("\n" + "=" * 60)

    if total_errors > 0:
        print("‚ùå Validation FAILED")
        return False
    else:
        print("‚úÖ Validation PASSED")
        return True


def main():
    """Run all validations."""
    data_dir = Path(__file__).parent / "data"

    if not data_dir.exists():
        print(f"‚ùå Data directory not found: {data_dir}")
        sys.exit(1)

    print("üîß Agent Tools Data Validation")
    print("=" * 60)
    print(f"Data directory: {data_dir}\n")

    all_results = {}

    try:
        # Validate each component
        all_results["catalog"] = validate_tool_catalog(data_dir)
        all_results["categories"] = validate_categories(data_dir)
        all_results["stats"] = validate_stats(data_dir)

        # Cross-validate
        all_results["cross"] = cross_validate(
            all_results["catalog"], all_results["categories"], all_results["stats"], data_dir
        )

        # Print summary
        success = print_summary(all_results)

        sys.exit(0 if success else 1)

    except Exception as e:
        print(f"\n‚ùå Validation failed with exception: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
