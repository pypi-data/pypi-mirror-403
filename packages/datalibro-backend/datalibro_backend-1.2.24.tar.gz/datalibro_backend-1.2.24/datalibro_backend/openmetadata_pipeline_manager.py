#!/usr/bin/env python3
"""
OpenMetadata Pipeline Manager

A Python library for managing OpenMetadata pipelines and lineage tracking with Spark integration.
Supports automatic Pipeline Service and Pipeline entity creation, data lineage management,
and OpenLineage integration for comprehensive data governance.

Author: OpenMetadata Pipeline Manager Team
License: Apache License 2.0
"""

import os
import time
import uuid
import re
import yaml
from datetime import datetime
from typing import Optional, List, Dict, Any, Union
from dataclasses import dataclass
from enum import Enum

# PipelineçŠ¶æ€æšä¸¾
class PipelineBusinessStatus(Enum):
    """Pipelineä¸šåŠ¡çŠ¶æ€æšä¸¾"""
    TESTING = "æµ‹è¯•ä¸­"      # åœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯ä¸­
    ONLINE = "å·²ä¸Šçº¿"       # ç”Ÿäº§ç¯å¢ƒè¿è¡Œä¸­  
    OFFLINE = "å·²ä¸‹çº¿"      # å·²åœç”¨/ä¸‹çº¿
    
    def __str__(self):
        return self.value

# å°è¯•å¯¼å…¥OpenMetadataä¾èµ–ï¼Œå¦‚æœå¤±è´¥åˆ™æä¾›é™çº§æ¨¡å¼
OPENMETADATA_AVAILABLE = False
try:
    from metadata.generated.schema.entity.services.connections.metadata.openMetadataConnection import (
        OpenMetadataConnection,
    )
    from metadata.generated.schema.security.client.openMetadataJWTClientConfig import (
        OpenMetadataJWTClientConfig,
    )
    from metadata.ingestion.ometa.ometa_api import OpenMetadata
    from metadata.generated.schema.api.services.createPipelineService import CreatePipelineServiceRequest
    from metadata.generated.schema.entity.services.pipelineService import PipelineServiceType
    from metadata.generated.schema.entity.services.connections.pipeline.customPipelineConnection import CustomPipelineConnection
    from metadata.generated.schema.entity.services.pipelineService import PipelineConnection
    from metadata.generated.schema.api.data.createPipeline import CreatePipelineRequest
    from metadata.generated.schema.entity.data.pipeline import Task
    from metadata.generated.schema.type.entityReference import EntityReference
    from metadata.generated.schema.entity.teams.user import User
    from metadata.generated.schema.api.teams.createUser import CreateUserRequest
    from metadata.generated.schema.api.lineage.addLineage import AddLineageRequest
    from metadata.generated.schema.type.entityLineage import EntitiesEdge, LineageDetails
    from metadata.generated.schema.entity.data.table import Table
    from metadata.generated.schema.entity.data.pipeline import Pipeline
    from metadata.generated.schema.entity.services.pipelineService import PipelineService
    OPENMETADATA_AVAILABLE = True
    print("âœ… OpenMetadata ä¾èµ–åŠ è½½æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ OpenMetadata ä¾èµ–åŠ è½½å¤±è´¥: {e}")
    print("ğŸ“ å°†ä½¿ç”¨ç®€åŒ–æ¨¡å¼ï¼Œéƒ¨åˆ†åŠŸèƒ½ä¸å¯ç”¨")
    print("ğŸ’¡ è¦ä½¿ç”¨å®Œæ•´åŠŸèƒ½ï¼Œè¯·è§£å†³ä¾èµ–é—®é¢˜")
    
    # åˆ›å»ºå ä½ç¬¦ç±»ä»¥ä¿æŒAPIå…¼å®¹æ€§
    class MockOpenMetadata:
        def __init__(self, *args, **kwargs):
            pass
    
    class MockPipeline:
        def __init__(self, name="mock-pipeline"):
            self.name = name
            self.id = "mock-id"
            self.fullyQualifiedName = f"mock-service.{name}"
    
    # è®¾ç½®å ä½ç¬¦
    OpenMetadata = MockOpenMetadata
    Pipeline = MockPipeline


@dataclass
class PipelineConfig:
    """Pipeline configuration class"""
    name: str
    display_name: str
    description: str
    service_name: str
    tasks: Optional[List[Dict[str, Any]]] = None


@dataclass
class OwnerConfig:
    """Owner configuration class"""
    name: str
    email: str
    display_name: Optional[str] = None
    is_admin: bool = False


@dataclass
class OpenLineageConfig:
    """OpenLineage integration configuration"""
    namespace: str = "default-namespace"
    parent_job_name: str = "data-pipeline"
    spark_packages: str = "io.openlineage:openlineage-spark:1.7.0"
    spark_listener: str = "io.openlineage.spark.agent.OpenLineageSparkListener"


def load_openmetadata_config(config_file: str = "cfg.yaml", config_section: str = "openmetadata_test") -> Dict[str, Any]:
    """
    ä»cfg.yamlæ–‡ä»¶åŠ è½½OpenMetadataé…ç½®ï¼Œæ”¯æŒå¤šç¯å¢ƒé…ç½®
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºcfg.yaml
        config_section: é…ç½®èŠ‚åç§°ï¼Œé»˜è®¤ä¸ºopenmetadata_test
                       å¯é€‰å€¼: openmetadata_test, openmetadata_prod
    """
    try:
        # å®Œå…¨å¤ç”¨get_tidb_configçš„è¯»å–é€»è¾‘
        with open(config_file, "r") as file:
            all_configs = yaml.safe_load(file)
        
        # ä¸get_tidb_configå®Œå…¨ä¸€è‡´çš„é”™è¯¯å¤„ç†
        if config_section not in all_configs:
            raise ValueError(f"é…ç½®åç§° '{config_section}' åœ¨cfg.yamlä¸­ä¸å­˜åœ¨")
        
        config = all_configs[config_section]
        
        # åŸºç¡€éªŒè¯ - é€‚é…æ–°çš„é…ç½®å­—æ®µå
        if 'host' not in config or not config['host']:
            raise ValueError("å¿…éœ€çš„é…ç½®é¡¹ 'host' ç¼ºå¤±æˆ–ä¸ºç©º")
        if 'token' not in config or not config['token']:
            raise ValueError("å¿…éœ€çš„é…ç½®é¡¹ 'token' ç¼ºå¤±æˆ–ä¸ºç©º")
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        standardized_config = {
            'host': config['host'],
            'jwt_token': config['token'],  # token -> jwt_token
        }
        
        # è‡ªåŠ¨ä¿®æ­£hostæ ¼å¼
        if not standardized_config['host'].endswith('/api'):
            standardized_config['host'] = standardized_config['host'].rstrip('/') + '/api'
        
        # å¤„ç†owneré…ç½®
        if all(key in config for key in ['pipeline_owner_name', 'pipeline_owner_email']):
            standardized_config['owner'] = {
                'name': config['pipeline_owner_name'],
                'email': config['pipeline_owner_email'],
                'display_name': config.get('pipeline_owner_display_name', config['pipeline_owner_name']),
                'is_admin': False
            }
        
        print(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_file} [{config_section}]")
        print(f"ğŸ“‹ OpenMetadata Host: {standardized_config['host']}")
        if 'owner' in standardized_config:
            print(f"ğŸ‘¤ Pipeline Owner: {standardized_config['owner']['name']} ({standardized_config['owner']['email']})")
        
        return standardized_config
    
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        print(f"ğŸ’¡ è¯·æ£€æŸ¥cfg.yamlä¸­æ˜¯å¦å­˜åœ¨ '{config_section}' é…ç½®èŠ‚")
        return {
            'host': 'http://localhost:8585/api',
            'jwt_token': '',
            'owner': {'name': 'admin', 'email': 'admin@company.com', 'display_name': 'Admin'}
        }


class OpenMetadataPipelineManager:
    """
    OpenMetadata Pipeline Manager
    
    A comprehensive manager for OpenMetadata pipelines, services, and lineage tracking
    with built-in Spark OpenLineage integration.
    
    Features:
    - Automatic Pipeline Service creation and management
    - Pipeline entity creation with customizable tasks
    - Data lineage tracking and management
    - User management and ownership assignment
    - Spark OpenLineage integration
    - Comprehensive error handling and logging
    
    Example:
        >>> config = {
        ...     'host': 'http://localhost:8585/api',
        ...     'jwt_token': 'your-jwt-token'
        ... }
        >>> manager = OpenMetadataPipelineManager(config)
        >>> 
        >>> # Create pipeline with lineage
        >>> pipeline_config = PipelineConfig(
        ...     name="data-processing-pipeline",
        ...     display_name="Data Processing Pipeline",
        ...     description="Processes raw data into analytics-ready format",
        ...     service_name="spark-pipeline-service"
        ... )
        >>> 
        >>> owner_config = OwnerConfig(
        ...     name="john.doe",
        ...     email="john.doe@company.com",
        ...     display_name="John Doe"
        ... )
        >>> 
        >>> pipeline = manager.create_complete_pipeline(
        ...     pipeline_config=pipeline_config,
        ...     owner_config=owner_config
        ... )
        >>> 
        >>> # Add data lineage
        >>> manager.add_table_lineage(
        ...     from_table_fqn="source.database.table1",
        ...     to_table_fqn="target.database.table2",
        ...     pipeline_fqn=pipeline.fullyQualifiedName
        ... )
    """
    
    def __init__(
        self,
        openmetadata_config: Optional[Dict[str, Any]] = None,
        openlineage_config: Optional[OpenLineageConfig] = None,
        enable_logging: bool = True,
        config_file: str = "cfg.yaml",
        config_section: str = "openmetadata_test"
    ):
        """
        Initialize OpenMetadata Pipeline Manager
        
        Args:
            openmetadata_config: OpenMetadata connection configuration (å¯é€‰ï¼Œå¦‚æœä¸æä¾›å°†ä»cfg.yamlè¯»å–)
                Required keys:
                - 'host': OpenMetadata server URL (e.g., 'http://localhost:8585/api')
                - 'jwt_token': JWT authentication token
                Optional keys:
                - 'auth_provider': Authentication provider (default: 'openmetadata')
                - 'verify_ssl': SSL verification (default: True)
            openlineage_config: OpenLineage configuration for Spark integration
            enable_logging: Enable console logging (default: True)
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„ (default: 'cfg.yaml')
            config_section: é…ç½®èŠ‚åç§° (default: 'openmetadata_test')
                           å¯é€‰å€¼: 'openmetadata_test', 'openmetadata_prod'
        """
        # å¦‚æœæ²¡æœ‰æä¾›é…ç½®ï¼Œä»cfg.yamlè¯»å–
        if openmetadata_config is None:
            self.config = load_openmetadata_config(config_file, config_section)
        else:
            self.config = openmetadata_config
            
        # å¤„ç†OpenLineageé…ç½®
        if openlineage_config is None and 'openlineage' in self.config:
            ol_config = self.config['openlineage']
            self.openlineage_config = OpenLineageConfig(
                namespace=ol_config.get('namespace', 'default-namespace'),
                parent_job_name=ol_config.get('parent_job_name', 'data-pipeline'),
                spark_packages=ol_config.get('spark_packages', 'io.openlineage:openlineage-spark:1.7.0'),
                spark_listener=ol_config.get('spark_listener', 'io.openlineage.spark.agent.OpenLineageSparkListener')
            )
        else:
            self.openlineage_config = openlineage_config or OpenLineageConfig()
            
        self.enable_logging = enable_logging
        self.metadata = None
        self.run_id = self._generate_run_id()
        self.current_pipeline = None  # å­˜å‚¨å½“å‰åˆ›å»ºçš„pipeline
        
        # Initialize OpenMetadata connection
        self._initialize_connection()
    
    def _log(self, message: str, level: str = "INFO"):
        """Internal logging method"""
        if self.enable_logging:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            print(f"[{timestamp}] [{level}] {message}")
    
    def _generate_run_id(self) -> str:
        """Generate unique run ID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"pipeline-run-{timestamp}-{str(uuid.uuid4())[:8]}"
    
    def _initialize_connection(self):
        """Initialize OpenMetadata connection"""
        if not OPENMETADATA_AVAILABLE:
            self._log("âš ï¸ OpenMetadata ä¾èµ–ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–æ¨¡å¼")
            self.metadata = None
            return
            
        try:
            # Extract configuration with defaults
            host_port = self.config.get('host', 'http://localhost:8585/api')
            jwt_token = self.config.get('jwt_token')
            auth_provider = self.config.get('auth_provider', 'openmetadata')
            
            if not jwt_token:
                raise ValueError("JWT token is required for OpenMetadata connection")
            
            # Create OpenMetadata connection
            server_config = OpenMetadataConnection(
                hostPort=host_port,
                authProvider=auth_provider,
                securityConfig=OpenMetadataJWTClientConfig(jwtToken=jwt_token),
            )
            
            self.metadata = OpenMetadata(server_config)
            self._log(f"âœ… OpenMetadata connection established successfully")
            self._log(f"ğŸ“‹ Pipeline Run ID: {self.run_id}")
            
        except Exception as e:
            self._log(f"âŒ OpenMetadata connection failed: {e}", "ERROR")
            self._log("ğŸ“ å°†ç»§ç»­ä½¿ç”¨ç®€åŒ–æ¨¡å¼")
            self.metadata = None
    
    def _extract_uuid(self, obj: Any) -> str:
        """Extract UUID string from OpenMetadata objects"""
        if hasattr(obj, '__root__'):
            uuid_str = str(obj.__root__)
        else:
            uuid_str = str(obj)
        
        # Handle various UUID formats
        if 'root=UUID(' in uuid_str:
            match = re.search(r"root=UUID\('([^']+)'\)", uuid_str)
            if match:
                return match.group(1)
        elif 'UUID(' in uuid_str:
            match = re.search(r"UUID\('([^']+)'\)", uuid_str)
            if match:
                return match.group(1)
        
        return uuid_str.replace("root=", "").replace("'", "")
    
    def _clean_name_format(self, name_obj: Any) -> str:
        """Clean name format from OpenMetadata objects"""
        name_str = name_obj.__root__ if hasattr(name_obj, '__root__') else str(name_obj)
        
        if 'root=' in str(name_str):
            match = re.search(r"root='([^']+)'", str(name_str))
            if match:
                return match.group(1)
            else:
                return str(name_str).replace("root=", "").replace("'", "")
        
        return str(name_str)
    
    def get_or_create_user(self, owner_config: OwnerConfig) -> Optional[User]:
        """
        Get or create user in OpenMetadata
        
        Args:
            owner_config: User configuration
        
        Returns:
            User object or None if failed
        """
        if not self.metadata:
            self._log("âŒ OpenMetadata connection not available", "ERROR")
            return None
        
        try:
            # First, let's diagnose what users exist and their formats
            self._log(f"ğŸ” Diagnosing user system for: {owner_config.email}")
            
            try:
                users = self.metadata.list_entities(entity=User, limit=100)  # Get more users
                self._log(f"ğŸ“‹ Found {len(users.entities) if hasattr(users, 'entities') and users.entities else 0} total users")
                
                if hasattr(users, 'entities') and users.entities:
                    for i, existing_user in enumerate(users.entities):  # Show all users
                        try:
                            user_name = self._clean_name_format(existing_user.name) if hasattr(existing_user, 'name') else 'NO_NAME'
                            user_email = existing_user.email if hasattr(existing_user, 'email') else 'NO_EMAIL'
                            user_id = self._extract_uuid(existing_user.id) if hasattr(existing_user, 'id') else 'NO_ID'
                            self._log(f"  User {i+1}: name='{user_name}', email='{user_email}', id='{user_id}'")
                            
                            # Check if this is our target user by email (handle root= prefix)
                            if user_email == owner_config.email or user_email == f"root={owner_config.email}":
                                self._log(f"ğŸ¯ Found target user by email match!")
                                return existing_user
                            
                            # Also check by name match (including partial matches)
                            if (user_name == owner_config.name or 
                                user_name == owner_config.display_name or
                                user_name.startswith(owner_config.name) or
                                owner_config.name in user_name):
                                self._log(f"ğŸ¯ Found target user by name match!")
                                return existing_user
                        except Exception as debug_error:
                            self._log(f"  User {i+1}: Could not parse user info: {debug_error}")
                
                # If we didn't find by email, try by name
                for existing_user in users.entities:
                    try:
                        if hasattr(existing_user, 'name'):
                            user_name = self._clean_name_format(existing_user.name)
                            if user_name == owner_config.name:
                                self._log(f"ğŸ¯ Found target user by name match!")
                                return existing_user
                    except Exception as name_check_error:
                        continue
                        
            except Exception as list_error:
                self._log(f"âš ï¸ User listing failed: {list_error}", "WARNING")
            
            # If we still haven't found the user, try direct lookup
            try:
                user = self.metadata.get_by_name(entity=User, fqn=owner_config.name)
                if user:
                    self._log(f"ğŸ¯ Found user by direct lookup: {user}")
                    return user
            except Exception as direct_error:
                self._log(f"âš ï¸ Direct user lookup failed: {direct_error}", "WARNING")
                
            self._log(f"âŒ Could not find user {owner_config.name} ({owner_config.email})", "ERROR")
            return None
            
        except Exception as e:
            self._log(f"âŒ User retrieval failed: {e}", "ERROR")
            return None
    
    def create_pipeline_service(self, service_name: str, service_description: Optional[str] = None) -> Optional[str]:
        """
        Create or get Pipeline Service
        
        Args:
            service_name: Name of the pipeline service
            service_description: Optional description
        
        Returns:
            Service ID or None if failed
        """
        if not self.metadata:
            self._log("âŒ OpenMetadata connection not available", "ERROR")
            return None
        
        try:
            # Try to get existing service first
            try:
                existing_service = self.metadata.get_by_name(entity=PipelineService, fqn=service_name)
                service_id = self._extract_uuid(existing_service.id)
                self._log(f"ğŸ”§ Found existing Pipeline Service: {self._clean_name_format(existing_service.name)}")
                return service_id
            except:
                pass
            
            # Create new service
            description = service_description or f"Pipeline service for {service_name}"
            
            # Create proper PipelineConnection structure
            custom_config = CustomPipelineConnection(
                type="CustomPipeline",
                sourcePythonClass=f"{service_name.replace('-', '_')}_service"
            )
            
            pipeline_connection = PipelineConnection(config=custom_config)
            
            service_request = CreatePipelineServiceRequest(
                name=service_name,
                displayName=service_name.replace('-', ' ').title(),
                description=description,
                serviceType=PipelineServiceType.CustomPipeline,
                connection=pipeline_connection
            )
            
            service = self.metadata.create_or_update(service_request)
            service_id = self._extract_uuid(service.id)
            
            self._log(f"ğŸ”§ Created Pipeline Service: {self._clean_name_format(service.name)} (ID: {service_id})")
            return service_id
            
        except Exception as e:
            self._log(f"âŒ Pipeline Service creation failed: {e}", "ERROR")
            return None
    
    def create_pipeline_entity(
        self,
        pipeline_config: PipelineConfig,
        owner_config: Optional[OwnerConfig] = None
    ) -> Optional[Pipeline]:
        """
        Create Pipeline entity
        
        Args:
            pipeline_config: Pipeline configuration
            owner_config: Optional owner configuration
        
        Returns:
            Pipeline object or None if failed
        """
        if not OPENMETADATA_AVAILABLE:
            self._log("ğŸ“ ç®€åŒ–æ¨¡å¼ï¼šåˆ›å»ºæ¨¡æ‹ŸPipelineå¯¹è±¡")
            mock_pipeline = Pipeline(name=pipeline_config.name)
            self.current_pipeline = mock_pipeline
            self._log(f"ğŸš€ æ¨¡æ‹ŸPipelineåˆ›å»ºæˆåŠŸ: {pipeline_config.name}")
            return mock_pipeline
            
        if not self.metadata:
            self._log("âŒ OpenMetadata connection not available", "ERROR")
            return None
        
        # First check if pipeline already exists
        try:
            service_fqn = pipeline_config.service_name
            pipeline_fqn = f"{service_fqn}.{pipeline_config.name}"
            existing_pipeline = self.metadata.get_by_name(entity=Pipeline, fqn=pipeline_fqn)
            if existing_pipeline:
                self._log(f"ğŸ“‹ Found existing Pipeline: {self._clean_name_format(existing_pipeline.name)}")
                self.current_pipeline = existing_pipeline
                
                # Process owner assignment for existing Pipeline if provided
                if owner_config:
                    self._log(f"ğŸ” Processing owner for existing Pipeline: {owner_config.name} ({owner_config.email})")
                    owner_user = self.get_or_create_user(owner_config)
                    if owner_user:
                        owner_id = self._extract_uuid(owner_user.id) if hasattr(owner_user, 'id') else str(owner_user.id)
                        # Try to update existing pipeline with new owner - recreate it with proper owner
                        try:
                            from metadata.generated.schema.api.data.createPipeline import CreatePipelineRequest
                            
                            owner_ref = EntityReference(id=owner_id, type="user")
                            
                            # Extract service name from service EntityReference
                            service_name = None
                            if hasattr(existing_pipeline.service, 'name'):
                                service_name = existing_pipeline.service.name
                            elif hasattr(existing_pipeline, 'service'):
                                # If service is an EntityReference, get the name from it
                                try:
                                    service_entity = self.metadata.get_by_name(entity=PipelineService, fqn=existing_pipeline.service.name)
                                    service_name = service_entity.name
                                except:
                                    # Fallback - extract from FQN
                                    service_name = str(existing_pipeline.service.name) if hasattr(existing_pipeline.service, 'name') else pipeline_config.service_name
                            
                            if not service_name:
                                service_name = pipeline_config.service_name
                            
                            self._log(f"ğŸ”„ Recreating Pipeline with owner. Service: {service_name}")
                            
                            # Extract and convert existing tasks properly
                            tasks_list = []
                            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æä¾›äº†è‡ªå®šä¹‰tasksé…ç½®
                            if pipeline_config.tasks:
                                self._log(f"ğŸ“‹ Using provided custom tasks ({len(pipeline_config.tasks)} tasks)")
                                tasks_list = pipeline_config.tasks.copy()
                            elif hasattr(existing_pipeline, 'tasks') and existing_pipeline.tasks:
                                self._log(f"ğŸ“‹ Found {len(existing_pipeline.tasks)} existing tasks to preserve")
                                for task in existing_pipeline.tasks:
                                    # Convert task to proper format
                                    task_dict = {
                                        'name': task.name if hasattr(task, 'name') else 'default-task',
                                        'taskType': task.taskType if hasattr(task, 'taskType') else 'TRANSFORM',
                                        'description': task.description if hasattr(task, 'description') else '',
                                        'displayName': task.displayName if hasattr(task, 'displayName') else (task.name if hasattr(task, 'name') else 'Default Task')
                                    }
                                    tasks_list.append(task_dict)
                            else:
                                self._log(f"ğŸ“‹ No existing tasks found, creating default tasks")
                                # Create default tasks for data pipeline
                                tasks_list = [
                                    {
                                        'name': 'data-extraction',
                                        'taskType': 'TRANSFORM',
                                        'description': 'ä»MySQL dl_cloudæ•°æ®åº“æå–è®¾å¤‡æ¡£æ¡ˆæ•°æ®',
                                        'displayName': 'Data Extraction'
                                    },
                                    {
                                        'name': 'data-transformation',
                                        'taskType': 'TRANSFORM', 
                                        'description': 'æ•°æ®æ¸…æ´—å’Œè½¬æ¢å¤„ç†',
                                        'displayName': 'Data Transformation'
                                    },
                                    {
                                        'name': 'data-loading',
                                        'taskType': 'TRANSFORM',
                                        'description': 'å°†å¤„ç†åçš„æ•°æ®åŠ è½½åˆ°TiDB ods_device_profile_detail_diè¡¨',
                                        'displayName': 'Data Loading'
                                    }
                                ]
                            
                            # Create Task objects
                            from metadata.generated.schema.entity.data.pipeline import Task
                            task_objects = []
                            for task_config in tasks_list:
                                task = Task(
                                    name=task_config['name'],
                                    taskType=task_config['taskType'],
                                    description=task_config.get('description', ''),
                                    displayName=task_config.get('displayName', task_config['name'])
                                )
                                task_objects.append(task)
                            
                            # Create new Pipeline request with owner and preserved tasks
                            create_request = CreatePipelineRequest(
                                name=existing_pipeline.name,
                                displayName=existing_pipeline.displayName or existing_pipeline.name,
                                description=existing_pipeline.description or f"Pipeline managed by {owner_user.name}",
                                service=service_name,  # Use service name as string, not EntityReference
                                tasks=task_objects,  # Use properly formatted Task objects
                                owners=[owner_ref]
                            )
                            
                            updated_pipeline = self.metadata.create_or_update(create_request)
                            self._log(f"âœ… Recreated Pipeline with owner: {owner_user.name} ({owner_id})")
                            self.current_pipeline = updated_pipeline
                            return updated_pipeline
                            
                        except Exception as update_error:
                            self._log(f"âš ï¸ Could not recreate Pipeline with owner: {update_error}", "WARNING")
                            # Fallback - continue with existing pipeline
                            self._log(f"ğŸ”„ Continuing with existing Pipeline without persistent owner")
                            self.current_pipeline = existing_pipeline
                    else:
                        self._log("âŒ Owner user is None, existing Pipeline owner unchanged")
                
                return existing_pipeline
        except Exception as check_error:
            self._log(f"ğŸ“ Pipeline does not exist, will create new one: {check_error}")
        
        try:
            # Create or get pipeline service
            service_id = self.create_pipeline_service(
                service_name=pipeline_config.service_name,
                service_description=f"Service for {pipeline_config.display_name}"
            )
            
            if not service_id:
                self._log("âŒ Failed to create Pipeline Service", "ERROR")
                return None
            
            # Verify service exists and get clean name
            try:
                pipeline_service = self.metadata.get_by_name(entity=PipelineService, fqn=pipeline_config.service_name)
                service_reference = self._clean_name_format(pipeline_service.name)
                self._log(f"âœ… Verified Pipeline Service: {service_reference}")
            except Exception as e:
                self._log(f"âŒ Service verification failed: {e}", "ERROR")
                return None
            
            # Handle owner - only for new pipelines
            owners = []
            if owner_config:
                self._log(f"ğŸ” Setting up owner for new Pipeline: {owner_config.name} ({owner_config.email})")
                # Use proper user retrieval method with diagnostic logging
                owner_user = self.get_or_create_user(owner_config)
                if owner_user:
                    owner_id = self._extract_uuid(owner_user.id) if hasattr(owner_user, 'id') else str(owner_user.id)
                    owners.append(EntityReference(id=owner_id, type="user"))
                    self._log(f"âœ… Added Pipeline owner: {owner_user.name} ({owner_id})")
                else:
                    self._log("âŒ Owner user is None, no owner will be assigned")
            else:
                self._log("ğŸ“ No owner config provided")
            
            # Create tasks
            from metadata.generated.schema.entity.data.pipeline import Task
            tasks = []
            if pipeline_config.tasks:
                for task_config in pipeline_config.tasks:
                    task = Task(
                        name=task_config.get('name', 'default-task'),
                        displayName=task_config.get('displayName', task_config.get('display_name', task_config.get('name', 'Default Task'))),
                        description=task_config.get('description', ''),
                        taskType=task_config.get('taskType', task_config.get('task_type', 'TRANSFORM')),
                        owners=owners if owners else None
                    )
                    tasks.append(task)
            else:
                # Default tasks
                default_tasks = [
                    {
                        'name': 'extract-data',
                        'display_name': 'Extract Data',
                        'description': 'Extract data from source systems',
                        'task_type': 'EXTRACT'
                    },
                    {
                        'name': 'transform-data',
                        'display_name': 'Transform Data',
                        'description': 'Transform and process data',
                        'task_type': 'TRANSFORM'
                    },
                    {
                        'name': 'load-data',
                        'display_name': 'Load Data',
                        'description': 'Load data to target systems',
                        'task_type': 'LOAD'
                    }
                ]
                
                for task_config in default_tasks:
                    task = Task(
                        name=task_config['name'],
                        displayName=task_config['display_name'],
                        description=task_config['description'],
                        taskType=task_config['task_type'],
                        owners=owners if owners else None
                    )
                    tasks.append(task)
            
            # Create pipeline request
            from metadata.generated.schema.api.data.createPipeline import CreatePipelineRequest
            pipeline_request = CreatePipelineRequest(
                name=pipeline_config.name,
                displayName=pipeline_config.display_name,
                description=pipeline_config.description,
                service=service_reference,
                owners=owners,
                tasks=tasks
            )
            
            # Create pipeline
            pipeline = self.metadata.create_or_update(pipeline_request)
            self._log(f"ğŸš€ Pipeline created successfully: {self._clean_name_format(pipeline.name)}")
            
            # ä¿å­˜å½“å‰åˆ›å»ºçš„pipelineä»¥ä¾›è¡€ç¼˜å…³ç³»ä½¿ç”¨
            self.current_pipeline = pipeline
            
            # Display owner info
            if hasattr(pipeline, 'owners') and pipeline.owners:
                try:
                    owner_count = len(pipeline.owners) if hasattr(pipeline.owners, '__len__') else len(list(pipeline.owners))
                    self._log(f"ğŸ‘¥ Pipeline Owners: {owner_count} assigned")
                except:
                    self._log("ğŸ‘¥ Pipeline Owners: assigned (count unknown)")
            else:
                self._log("ğŸ‘¥ Pipeline has no owners assigned")
            
            return pipeline
            
        except Exception as e:
            self._log(f"âŒ Pipeline creation failed: {e}", "ERROR")
            return None
    
    def add_table_lineage(self, from_table_fqn, to_table_fqn, description="", pipeline_fqn=None, auto_associate_pipeline=True):
        """æ·»åŠ è¡¨è¡€ç¼˜å…³ç³» - åŒ…å«Pipelineå…³è”
        
        Args:
            from_table_fqn: æºè¡¨FQN
            to_table_fqn: ç›®æ ‡è¡¨FQN  
            description: è¡€ç¼˜å…³ç³»æè¿°
            pipeline_fqn: æŒ‡å®šçš„Pipeline FQN
            auto_associate_pipeline: æ˜¯å¦è‡ªåŠ¨å…³è”æœ€è¿‘åˆ›å»ºçš„pipeline
        """
        if not OPENMETADATA_AVAILABLE:
            self._log(f"ğŸ“ ç®€åŒ–æ¨¡å¼ï¼šè®°å½•è¡€ç¼˜å…³ç³» {from_table_fqn} â†’ {to_table_fqn}")
            self._log(f"ğŸ“‹ æè¿°: {description}")
            return True
            
        if not self.metadata:
            self._log("âŒ OpenMetadata connection not available", "ERROR")
            return False
            
        try:
            # è·å–æºè¡¨å’Œç›®æ ‡è¡¨
            from metadata.generated.schema.entity.data.table import Table
            from metadata.generated.schema.type.entityLineage import EntitiesEdge, LineageDetails
            
            # è·å–æºè¡¨
            try:
                from_table = self.metadata.get_by_name(entity=Table, fqn=from_table_fqn)
            except Exception as e:
                self._log(f"âŒ æºè¡¨ä¸å­˜åœ¨: {from_table_fqn} - {e}", "ERROR")
                return False
            
            # è·å–ç›®æ ‡è¡¨
            try:
                to_table = self.metadata.get_by_name(entity=Table, fqn=to_table_fqn)
            except Exception as e:
                self._log(f"âŒ ç›®æ ‡è¡¨ä¸å­˜åœ¨: {to_table_fqn} - {e}", "ERROR")
                return False
            
            from_table_id = self._extract_uuid(from_table.id)
            to_table_id = self._extract_uuid(to_table.id)
            
            # è·å–pipelineå®ä½“ç”¨äºè¡€ç¼˜å…³ç³»ï¼ˆä¼˜å…ˆä½¿ç”¨pipeline_fqnï¼Œå¦åˆ™å°è¯•è·å–å½“å‰pipelineï¼‰
            pipeline_ref = None
            if pipeline_fqn:
                # å¦‚æœæä¾›äº†pipeline_fqnï¼Œä½¿ç”¨æŒ‡å®šçš„Pipeline
                try:
                    pipeline_entity = self.metadata.get_by_name(entity=Pipeline, fqn=pipeline_fqn)
                    pipeline_id = self._extract_uuid(pipeline_entity.id)
                    pipeline_ref = EntityReference(id=pipeline_id, type="pipeline")
                    self._log(f"ğŸ”— å°†æŒ‡å®šPipelineå…³è”åˆ°è¡€ç¼˜å…³ç³»: {pipeline_id}")
                except Exception as pe:
                    self._log(f"âš ï¸ æŒ‡å®šPipelineå…³è”å¤±è´¥: {pe}", "WARNING")
            elif auto_associate_pipeline and self.current_pipeline:
                # å¦‚æœæ²¡æœ‰æä¾›pipeline_fqnä½†å¯ç”¨äº†è‡ªåŠ¨å…³è”ï¼Œä½¿ç”¨å½“å‰åˆ›å»ºçš„pipeline
                try:
                    pipeline_id = self._extract_uuid(self.current_pipeline.id)
                    pipeline_ref = EntityReference(id=pipeline_id, type="pipeline")
                    self._log(f"ğŸ”— è‡ªåŠ¨å…³è”å½“å‰Pipelineåˆ°è¡€ç¼˜å…³ç³»: {pipeline_id}")
                except Exception as pe:
                    self._log(f"âš ï¸ è‡ªåŠ¨Pipelineå…³è”å¤±è´¥: {pe}", "WARNING")
            else:
                self._log("ğŸ”— æœªå…³è”Pipelineï¼Œåˆ›å»ºç®€å•è¡€ç¼˜å…³ç³»")
            
            # åˆ›å»ºè¡€ç¼˜å…³ç³» - åŒ…å«Pipelineä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            edge = EntitiesEdge(
                fromEntity=EntityReference(id=from_table_id, type="table"),
                toEntity=EntityReference(id=to_table_id, type="table"),
                lineageDetails=LineageDetails(
                    description=description or f"æ•°æ®è¡€ç¼˜: {from_table_fqn} â†’ {to_table_fqn}",
                    pipeline=pipeline_ref
                )
            )
            
            lineage_request = AddLineageRequest(edge=edge)
            self.metadata.add_lineage(lineage_request)
            
            if pipeline_ref:
                self._log(f"âœ… è¡€ç¼˜å…³ç³»æ·»åŠ æˆåŠŸ(å«Pipeline): {from_table_fqn} â†’ {to_table_fqn}")
            else:
                self._log(f"âœ… è¡€ç¼˜å…³ç³»æ·»åŠ æˆåŠŸ: {from_table_fqn} â†’ {to_table_fqn}")
            return True
            
        except Exception as e:
            self._log(f"âŒ æ·»åŠ è¡€ç¼˜å…³ç³»å¤±è´¥: {e}", "ERROR")
            return False
    
    def get_pipeline_info(self, pipeline_name: str) -> Optional[Dict[str, Any]]:
        """
        Get pipeline information
        
        Args:
            pipeline_name: Pipeline name
        
        Returns:
            Pipeline information dictionary or None
        """
        if not self.metadata:
            self._log("âŒ OpenMetadata connection not available", "ERROR")
            return None
        
        try:
            pipeline = self.metadata.get_by_name(entity=Pipeline, fqn=pipeline_name)
            
            info = {
                'name': self._clean_name_format(pipeline.name),
                'id': self._extract_uuid(pipeline.id),
                'description': self._clean_name_format(pipeline.description) if pipeline.description else None,
                'status': pipeline.pipelineStatus,
                'service': self._clean_name_format(pipeline.service.name) if pipeline.service else None,
                'owners': [
                    {
                        'id': self._extract_uuid(owner.id),
                        'name': self._clean_name_format(owner.name),
                        'type': owner.type
                    }
                    for owner in (list(pipeline.owners) if pipeline.owners else [])
                    if hasattr(owner, 'id') and hasattr(owner, 'name') and hasattr(owner, 'type')
                ],
                'tasks': [
                    {
                        'name': self._clean_name_format(task.name),
                        'type': task.taskType,
                        'description': task.description
                    }
                    for task in (list(pipeline.tasks) if pipeline.tasks else [])
                ]
            }
            
            self._log(f"ğŸ“‹ Pipeline info retrieved: {info['name']}")
            return info
            
        except Exception as e:
            self._log(f"âŒ Failed to get pipeline info: {e}", "ERROR")
            return None
    
    def get_pipeline(self, pipeline_name, service_name=""):
        """è·å–å·²å­˜åœ¨çš„Pipeline"""
        if not self.metadata:
            self._log("âŒ OpenMetadata connection not available", "ERROR")
            return None
            
        try:
            # å¦‚æœæ²¡æœ‰æä¾›service_nameï¼Œå°è¯•ä»pipeline_nameæ„å»ºFQN
            if not service_name:
                # å°è¯•ç›´æ¥ä½¿ç”¨pipeline_nameä½œä¸ºFQN
                fqn = pipeline_name
            else:
                fqn = f"{service_name}.{pipeline_name}"
            
            # é€šè¿‡åç§°è·å–Pipeline
            pipeline = self.metadata.get_by_name(entity=Pipeline, fqn=fqn)
            
            self._log(f"ğŸ“‹ è·å–åˆ°Pipeline: {self._clean_name_format(pipeline.name)}")
            self._log(f"Pipeline ID: {self._extract_uuid(pipeline.id)}")
            self._log(f"Pipelineæè¿°: {pipeline.description or 'N/A'}")
            
            # æ˜¾ç¤ºPipelineçš„ä»»åŠ¡
            if hasattr(pipeline, 'tasks') and pipeline.tasks:
                self._log("Pipelineä»»åŠ¡:")
                for i, task in enumerate(pipeline.tasks, 1):
                    self._log(f"  {i}. {self._clean_name_format(task.name)} ({task.taskType}): {task.description}")
            
            return pipeline
        except Exception as e:
            self._log(f"âŒ è·å–Pipelineå¤±è´¥: {e}", "ERROR")
            return None

    def get_pipeline_lineage(self, pipeline_name, service_name=""):
        """è·å–Pipelineçš„è¡€ç¼˜å…³ç³»"""
        if not self.metadata:
            self._log("âŒ OpenMetadata connection not available", "ERROR")
            return None
            
        try:
            pipeline = self.get_pipeline(pipeline_name, service_name)
            if not pipeline:
                return None
                
            # æ„å»ºFQN
            if not service_name:
                fqn = pipeline_name
            else:
                fqn = f"{service_name}.{pipeline_name}"
                
            # è·å–è¡€ç¼˜å…³ç³»
            lineage = self.metadata.get_lineage_by_name(
                entity=Pipeline,
                fqn=fqn,
                up_depth=3,
                down_depth=3
            )
            
            self._log("ğŸ“Š Pipelineè¡€ç¼˜å…³ç³»:")
            if lineage and lineage.get('edges'):
                for edge in lineage['edges']:
                    from_entity = edge.get('fromEntity', {})
                    to_entity = edge.get('toEntity', {})
                    self._log(f"  {from_entity.get('name', 'Unknown')} -> {to_entity.get('name', 'Unknown')}")
            else:
                self._log("  æœªæ‰¾åˆ°è¡€ç¼˜å…³ç³»")
                
            return lineage
        except Exception as e:
            self._log(f"âŒ è·å–Pipelineè¡€ç¼˜å…³ç³»å¤±è´¥: {e}", "ERROR")
            return None

    def track_pipeline_execution(self, status="success", start_time=None, end_time=None, metrics=None):
        """è·Ÿè¸ªç®¡é“æ‰§è¡ŒçŠ¶æ€"""
        if not self.metadata:
            return
            
        try:
            execution_info = {
                "run_id": self.run_id,
                "status": status,
                "start_time": start_time or datetime.now(),
                "end_time": end_time or datetime.now(),
                "metrics": metrics or {}
            }
            self._log(f"ğŸ“ˆ ç®¡é“æ‰§è¡Œè·Ÿè¸ª: {execution_info}")
        except Exception as e:
            self._log(f"âŒ è·Ÿè¸ªç®¡é“æ‰§è¡Œå¤±è´¥: {e}", "ERROR")

    def update_pipeline_custom_properties(
        self, 
        pipeline_fqn: str, 
        custom_properties: Dict[str, Any]
    ) -> bool:
        """
        æ›´æ–°Pipelineçš„è‡ªå®šä¹‰å±æ€§
        
        æ³¨æ„: å½“å‰ç‰ˆæœ¬æš‚æ—¶å°†è‡ªå®šä¹‰å±æ€§è®°å½•åˆ°æ—¥å¿—ä¸­ï¼Œ
        ç­‰å¾…OpenMetadata Python SDKæ›´æ–°æ”¯æŒæ‰©å±•å±æ€§æ›´æ–°åŠŸèƒ½
        
        Args:
            pipeline_fqn: Pipelineçš„å®Œå…¨é™å®šåç§°
            custom_properties: è¦æ›´æ–°çš„è‡ªå®šä¹‰å±æ€§å­—å…¸
                ä¾‹å¦‚: {
                    "pipelineStatus": "æµ‹è¯•ä¸­",
                    "lastUpdate": "2024-01-15T10:30:00Z",
                    "pipelineDuration": "30åˆ†é’Ÿ"
                }
        
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        if not self.metadata:
            self._log("âŒ OpenMetadata connection not available", "ERROR")
            return False
            
        try:
            # è·å–ç°æœ‰çš„Pipelineå®ä½“
            pipeline = self.metadata.get_by_name(entity=Pipeline, fqn=pipeline_fqn)
            if not pipeline:
                self._log(f"âŒ Pipeline not found: {pipeline_fqn}", "ERROR")
                return False
            
            # è®°å½•è‡ªå®šä¹‰å±æ€§åˆ°æ—¥å¿—ä¸­
            self._log(f"ğŸ“Š Pipelineè‡ªå®šä¹‰å±æ€§è®°å½• [{pipeline_fqn}]:")
            for key, value in custom_properties.items():
                self._log(f"   â€¢ {key}: {value}")
            
            # å°†å±æ€§ä¿å­˜åˆ°å†…å­˜ä¸­ä¾›åç»­ä½¿ç”¨
            if not hasattr(self, '_pipeline_properties'):
                self._pipeline_properties = {}
            
            if pipeline_fqn not in self._pipeline_properties:
                self._pipeline_properties[pipeline_fqn] = {}
                
            self._pipeline_properties[pipeline_fqn].update(custom_properties)
            
            # å°è¯•å®é™…æ›´æ–°OpenMetadataä¸­çš„è‡ªå®šä¹‰å±æ€§
            success = self._update_pipeline_extension_via_api(pipeline, custom_properties)
            if success:
                self._log(f"âœ… Pipelineè‡ªå®šä¹‰å±æ€§å·²æ›´æ–°åˆ°OpenMetadata: {pipeline_fqn}")
            else:
                self._log(f"âœ… Pipelineè‡ªå®šä¹‰å±æ€§å·²è®°å½•åˆ°æ—¥å¿—: {pipeline_fqn}")
            
            return True
                
        except Exception as e:
            self._log(f"âŒ æ›´æ–°Pipelineè‡ªå®šä¹‰å±æ€§æ—¶å‡ºé”™: {e}", "ERROR")
            return False

    def _update_pipeline_extension_via_api(self, pipeline, custom_properties: Dict[str, Any]) -> bool:
        """
        é€šè¿‡REST APIç›´æ¥æ›´æ–°Pipelineçš„æ‰©å±•å±æ€§
        
        Args:
            pipeline: Pipelineå®ä½“å¯¹è±¡
            custom_properties: è‡ªå®šä¹‰å±æ€§å­—å…¸
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            import json
            import requests
            from datetime import datetime
            
            # å‡†å¤‡APIè¯·æ±‚ - ä½¿ç”¨_extract_uuidæ–¹æ³•æ­£ç¡®æå–UUID
            pipeline_id = self._extract_uuid(pipeline.id)
            api_url = f"{self.config.get('host')}/v1/pipelines/{pipeline_id}"
            headers = {
                "Authorization": f"Bearer {self.config.get('jwt_token')}",
                "Content-Type": "application/json-patch+json"
            }
            
            # å®šä¹‰å·²çŸ¥çš„è‡ªå®šä¹‰å­—æ®µï¼ˆæ ¹æ®OpenMetadata UIä¸­çš„å®šä¹‰ï¼‰
            known_custom_fields = {
                "pipelineStatus", "lastUpdate", "pipelineDuration","executionStatus"
            }
            
            # æ ¼å¼åŒ–æ‰©å±•æ•°æ®ä»¥ç¬¦åˆOpenMetadataçš„è¦æ±‚
            formatted_extension = {}
            for key, value in custom_properties.items():
                # åªå¤„ç†å·²çŸ¥çš„è‡ªå®šä¹‰å­—æ®µ
                if key not in known_custom_fields:
                    self._log(f"âš ï¸ è·³è¿‡æœªå®šä¹‰çš„è‡ªå®šä¹‰å­—æ®µ: {key}", "WARNING")
                    continue
                    
                if key == "pipelineStatus":
                    # pipelineStatusæ˜¯æšä¸¾ç±»å‹ï¼Œéœ€è¦ä½¿ç”¨æ­£ç¡®çš„å€¼
                    if value in ["æµ‹è¯•ä¸­", "å·²ä¸Šçº¿", "å·²ä¸‹çº¿"]:
                        status_mapping = {
                            "æµ‹è¯•ä¸­": "Testing",
                            "å·²ä¸Šçº¿": "Online", 
                            "å·²ä¸‹çº¿": "Offline"
                        }
                        formatted_extension[key] = [status_mapping[value]]
                    else:
                        formatted_extension[key] = [value]
                elif key == "lastUpdate":
                    # ç¡®ä¿æ—¥æœŸæ—¶é—´æ ¼å¼æ­£ç¡®
                    if isinstance(value, str):
                        try:
                            # å°è¯•è§£æISOæ ¼å¼å¹¶è½¬æ¢ä¸ºOpenMetadataè¦æ±‚çš„æ ¼å¼
                            dt = datetime.fromisoformat(value.replace('Z', '+00:00'))
                            formatted_extension[key] = dt.strftime("%Y-%m-%d %H:%M:%S")
                        except:
                            formatted_extension[key] = value
                    else:
                        formatted_extension[key] = value
                elif key == "executionStatus":
                    formatted_extension[key] = [value]
                else:
                    # å…¶ä»–å­—æ®µç›´æ¥ä½¿ç”¨åŸå€¼
                    formatted_extension[key] = value
            
            # å‡†å¤‡PATCHè¯·æ±‚ä½“
            patch_data = [
                {
                    "op": "add",
                    "path": "/extension",
                    "value": formatted_extension
                }
            ]
            
            # å‘é€PATCHè¯·æ±‚
            response = requests.patch(api_url, headers=headers, json=patch_data)
            
            if response.status_code == 200:
                self._log(f"ğŸ¯ REST APIæ›´æ–°æˆåŠŸ: {response.status_code}")
                return True
            else:
                self._log(f"âš ï¸ REST APIæ›´æ–°å¤±è´¥: {response.status_code} - {response.text}", "WARNING")
                return False
                
        except Exception as e:
            self._log(f"âš ï¸ REST APIæ›´æ–°å‡ºé”™: {e}", "WARNING")
            return False

    def update_pipeline_status(
        self, 
        pipeline_fqn: str, 
        status: Union[PipelineBusinessStatus, str],
        duration: Optional[str] = None,
        last_update: Optional[datetime] = None
    ) -> bool:
        """
        æ›´æ–°Pipelineçš„ä¸šåŠ¡çŠ¶æ€å’Œç›¸å…³ä¿¡æ¯
        
        Args:
            pipeline_fqn: Pipelineçš„å®Œå…¨é™å®šåç§°
            status: PipelineçŠ¶æ€ (å¯ä»¥æ˜¯æšä¸¾æˆ–å­—ç¬¦ä¸²)
            duration: è„šæœ¬è¿è¡Œæ—¶é•¿ (å¯é€‰)
            last_update: æœ€åæ›´æ–°æ—¶é—´ (å¯é€‰ï¼Œé»˜è®¤ä¸ºå½“å‰æ—¶é—´)
        
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        # å¤„ç†çŠ¶æ€å€¼
        if isinstance(status, PipelineBusinessStatus):
            status_value = status.value
        else:
            status_value = str(status)
        
        # å‡†å¤‡è‡ªå®šä¹‰å±æ€§
        custom_properties = {
            "pipelineStatus": status_value,
            "lastUpdate": (last_update or datetime.now()).isoformat()
        }
        
        # æ·»åŠ å¯é€‰å±æ€§
        if duration:
            custom_properties["pipelineDuration"] = duration
            
        return self.update_pipeline_custom_properties(pipeline_fqn, custom_properties)

    def update_pipeline_properties_with_lifecycle(
        self, 
        pipeline_fqn: str, 
        status: str = "Testing", 
        duration: str = None, 
        error_message: str = None
    ) -> bool:
        """
        æ›´æ–°Pipelineçš„è‡ªå®šä¹‰å±æ€§ï¼ˆç”Ÿå‘½å‘¨æœŸç®¡ç†ç‰ˆæœ¬ï¼‰
        
        Args:
            pipeline_fqn: Pipelineå®Œå…¨é™å®šå
            status: PipelineçŠ¶æ€ ("æµ‹è¯•ä¸­", "å·²ä¸Šçº¿", "å·²ä¸‹çº¿")
            duration: æ‰§è¡Œæ—¶é•¿ (å¯é€‰)ï¼Œå¦‚"4.6ç§’"
            error_message: é”™è¯¯ä¿¡æ¯ (å¯é€‰)
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            self._log(f"ğŸ“ æ›´æ–°Pipelineå±æ€§: {status}")
            
            # å‡†å¤‡è‡ªå®šä¹‰å±æ€§
            custom_props = {
                "pipelineStatus": status,
                "lastUpdate": datetime.now().isoformat()
            }
            
            # æ·»åŠ å¯é€‰å±æ€§
            if duration:
                custom_props["pipelineDuration"] = duration
            if error_message:
                custom_props["errorMessage"] = error_message
                custom_props["executionStatus"] = "Failed"
            else:
                custom_props["executionStatus"] = "Successful"
            
            # æ›´æ–°å±æ€§
            success = self.update_pipeline_custom_properties(
                pipeline_fqn=pipeline_fqn,
                custom_properties=custom_props
            )
            
            if success:
                self._log("âœ… Pipelineå±æ€§æ›´æ–°æˆåŠŸ")
            else:
                self._log("âŒ Pipelineå±æ€§æ›´æ–°å¤±è´¥", "ERROR")
                
            return success
                
        except Exception as e:
            self._log(f"âš ï¸ æ›´æ–°Pipelineå±æ€§æ—¶å‡ºé”™: {e}", "ERROR")
            return False

    def add_data_lineage_simple(
        self, 
        source_table_fqn: str, 
        target_table_fqn: str, 
        description: str = ""
    ) -> bool:
        """
        æ·»åŠ æ•°æ®è¡€ç¼˜å…³ç³»ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        
        Args:
            source_table_fqn: æºè¡¨å®Œå…¨é™å®šå
            target_table_fqn: ç›®æ ‡è¡¨å®Œå…¨é™å®šå
            description: è¡€ç¼˜å…³ç³»æè¿°
            
        Returns:
            bool: æ·»åŠ æ˜¯å¦æˆåŠŸ
        """
        try:
            self._log(f"ğŸ”— æ·»åŠ æ•°æ®è¡€ç¼˜å…³ç³»: {source_table_fqn} â†’ {target_table_fqn}")
            
            # ä½¿ç”¨ç°æœ‰çš„è¡€ç¼˜å…³ç³»æ–¹æ³•
            success = self.add_table_lineage(
                from_table_fqn=source_table_fqn,
                to_table_fqn=target_table_fqn,
                description=description or f"æ•°æ®å¤„ç†è¡€ç¼˜: {source_table_fqn} â†’ {target_table_fqn}"
            )
            
            if success:
                self._log("âœ… æ•°æ®è¡€ç¼˜å…³ç³»æ·»åŠ æˆåŠŸ")
            else:
                self._log("âŒ æ•°æ®è¡€ç¼˜å…³ç³»æ·»åŠ å¤±è´¥", "ERROR")
                
            return success
            
        except Exception as e:
            self._log(f"âš ï¸ æ·»åŠ è¡€ç¼˜å…³ç³»æ—¶å‡ºé”™: {e}", "ERROR")
            return False

    def get_pipeline_custom_properties(self, pipeline_fqn: str) -> Optional[Dict[str, Any]]:
        """
        è·å–Pipelineçš„è‡ªå®šä¹‰å±æ€§
        
        Args:
            pipeline_fqn: Pipelineçš„å®Œå…¨é™å®šåç§°
            
        Returns:
            Dict[str, Any]: è‡ªå®šä¹‰å±æ€§å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        if not self.metadata:
            self._log("âŒ OpenMetadata connection not available", "ERROR")
            return None
            
        try:
            # é¦–å…ˆå°è¯•ä»å†…å­˜ä¸­è·å–
            if hasattr(self, '_pipeline_properties') and pipeline_fqn in self._pipeline_properties:
                self._log(f"ğŸ“‹ ä»å†…å­˜è·å–Pipelineè‡ªå®šä¹‰å±æ€§: {pipeline_fqn}")
                return self._pipeline_properties[pipeline_fqn]
            
            # å¦‚æœå†…å­˜ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»OpenMetadataè·å–
            pipeline = self.metadata.get_by_name(entity=Pipeline, fqn=pipeline_fqn)
            if not pipeline:
                self._log(f"âŒ Pipeline not found: {pipeline_fqn}", "ERROR")
                return None
                
            extension_data = pipeline.extension or {}
            self._log(f"ğŸ“‹ ä»OpenMetadataè·å–Pipelineè‡ªå®šä¹‰å±æ€§: {pipeline_fqn}")
            return extension_data
            
        except Exception as e:
            self._log(f"âŒ è·å–Pipelineè‡ªå®šä¹‰å±æ€§æ—¶å‡ºé”™: {e}", "ERROR")
            return None

    def configure_spark_openlineage(self, spark_session_or_builder) -> Any:
        """
        Configure Spark session with OpenLineage integration
        
        Args:
            spark_session_or_builder: SparkSession.builder object or existing SparkSession
        
        Returns:
            Configured SparkSession.builder or SparkSession
        """
        try:
            # Extract OpenMetadata host for OpenLineage
            om_host = self.config.get('host', 'http://localhost:8585')
            if om_host.endswith('/api'):
                om_host = om_host[:-4]  # Remove /api suffix
            
            # Check if it's a SparkSession or SparkSession.builder
            if hasattr(spark_session_or_builder, 'sparkContext'):
                # It's an existing SparkSession
                self._log("âš¡ Configuring existing SparkSession with OpenLineage")
                spark_context = spark_session_or_builder.sparkContext
                
                # Configure runtime properties
                spark_context.setLocalProperty("spark.openlineage.namespace", self.openlineage_config.namespace)
                spark_context.setLocalProperty("spark.openlineage.parentJobName", self.openlineage_config.parent_job_name)
                
                # Log configuration (runtime configuration is limited for existing sessions)
                self._log("âš¡ Spark session configured with OpenLineage integration")
                self._log("â„¹ï¸ Note: Some OpenLineage configurations require restart for existing sessions")
                return spark_session_or_builder
                
            else:
                # It's a SparkSession.builder
                self._log("âš¡ Configuring SparkSession.builder with OpenLineage")
                configured_builder = spark_session_or_builder \
                    .config("spark.openlineage.namespace", self.openlineage_config.namespace) \
                    .config("spark.openlineage.parentJobName", self.openlineage_config.parent_job_name) \
                    .config("spark.jars.packages", self.openlineage_config.spark_packages) \
                    .config("spark.extraListeners", self.openlineage_config.spark_listener) \
                    .config("spark.openlineage.transport.type", "http") \
                    .config("spark.openlineage.transport.url", f"{om_host}/api/v1/lineage") \
                    .config("spark.openlineage.transport.auth.type", "api_key") \
                    .config("spark.openlineage.transport.auth.apiKey", self.config.get('jwt_token', ''))
                
                self._log("âš¡ Spark session configured with OpenLineage integration")
                return configured_builder
            
        except Exception as e:
            self._log(f"âš ï¸ Spark OpenLineage configuration warning: {e}", "WARNING")
            return spark_session_or_builder
    
    def create_complete_pipeline(
        self,
        pipeline_config: PipelineConfig,
        owner_config: Optional[OwnerConfig] = None,
        lineage_mappings: Optional[List[Dict[str, str]]] = None
    ) -> Optional[Pipeline]:
        """
        Create a complete pipeline with service, entity, and optional lineage
        
        Args:
            pipeline_config: Pipeline configuration
            owner_config: Optional owner configuration
            lineage_mappings: Optional list of lineage mappings
                Each mapping should have 'from_table_fqn' and 'to_table_fqn' keys
        
        Returns:
            Pipeline object or None if failed
        """
        self._log("ğŸš€ Creating complete pipeline setup...")
        
        # Create pipeline entity
        pipeline = self.create_pipeline_entity(pipeline_config, owner_config)
        if not pipeline:
            return None
        
        # Add lineage if provided
        if lineage_mappings:
            self._log(f"ğŸ”— Adding {len(lineage_mappings)} lineage relationships...")
            # Use pipeline fullyQualifiedName for proper lineage association
            pipeline_fqn = self._clean_name_format(pipeline.fullyQualifiedName) if hasattr(pipeline, 'fullyQualifiedName') else self._clean_name_format(pipeline.name)
            
            for mapping in lineage_mappings:
                from_table = mapping.get('from_table_fqn')
                to_table = mapping.get('to_table_fqn')
                description = mapping.get('description')
                
                if from_table and to_table:
                    self.add_table_lineage(
                        from_table_fqn=from_table,
                        to_table_fqn=to_table,
                        description=description or f"æ•°æ®è¡€ç¼˜: {from_table} â†’ {to_table}",
                        pipeline_fqn=pipeline_fqn,
                        auto_associate_pipeline=True  # å¯ç”¨è‡ªåŠ¨å…³è”
                    )
        
        self._log("âœ… Complete pipeline setup finished successfully!")
        return pipeline


# Convenience functions for quick usage
def create_pipeline_manager(
    openmetadata_host: str = None,
    jwt_token: str = None,
    config_file: str = "cfg.yaml",
    config_section: str = "openmetadata_test",
    **kwargs
) -> OpenMetadataPipelineManager:
    """
    ä¾¿æ·å‡½æ•°åˆ›å»ºpipeline manager
    
    Args:
        openmetadata_host: OpenMetadata server URL (å¯é€‰ï¼Œä¼˜å…ˆä»cfg.yamlè¯»å–)
        jwt_token: JWT authentication token (å¯é€‰ï¼Œä¼˜å…ˆä»cfg.yamlè¯»å–)
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„ (default: 'cfg.yaml')
        config_section: é…ç½®èŠ‚åç§° (default: 'openmetadata_test')
        **kwargs: Additional configuration options
    
    Returns:
        OpenMetadataPipelineManager instance
    """
    if openmetadata_host and jwt_token:
        # å¦‚æœæä¾›äº†å‚æ•°ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹å¼
        config = {
            'host': openmetadata_host,
            'jwt_token': jwt_token,
            **kwargs
        }
        return OpenMetadataPipelineManager(config)
    else:
        # ä½¿ç”¨cfg.yamlé…ç½®
        return OpenMetadataPipelineManager(
            config_file=config_file,
            config_section=config_section
        )


def create_simple_pipeline_manager(config_file: str = "cfg.yaml", config_section: str = None) -> OpenMetadataPipelineManager:
    """
    æœ€ç®€å•çš„æ–¹å¼åˆ›å»ºpipeline manager - ç›´æ¥ä»cfg.yamlè¯»å–æ‰€æœ‰é…ç½®
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„ (default: 'cfg.yaml')
        config_section: é…ç½®èŠ‚åç§° (default: æ ¹æ®ç¯å¢ƒå˜é‡OPENMETADATA_ENVè‡ªåŠ¨é€‰æ‹©)
                       å¯é€‰å€¼: 'openmetadata_test', 'openmetadata_prod'
    
    Returns:
        OpenMetadataPipelineManager instance
    """
    # å¦‚æœæ²¡æœ‰æŒ‡å®šé…ç½®èŠ‚ï¼Œæ ¹æ®ç¯å¢ƒå˜é‡è‡ªåŠ¨é€‰æ‹©
    if config_section is None:
        env = os.getenv("OPENMETADATA_ENV", "test").lower()
        if env in ["prod", "production"]:
            config_section = "openmetadata_prod"
        else:
            config_section = "openmetadata_test"
        print(f"ğŸŒ è‡ªåŠ¨é€‰æ‹©ç¯å¢ƒ: {config_section} (åŸºäºOPENMETADATA_ENV={env})")
    
    return OpenMetadataPipelineManager(config_file=config_file, config_section=config_section)


def quick_pipeline_setup(
    pipeline_name: str,
    pipeline_description: str,
    config_file: str = "cfg.yaml",
    service_name: Optional[str] = None,
    lineage_mappings: Optional[List[Dict[str, str]]] = None,
    tasks: Optional[List[Dict[str, Any]]] = None,
    **kwargs
) -> Optional[Pipeline]:
    """
    å¿«é€ŸPipelineè®¾ç½® - ä»cfg.yamlè¯»å–é…ç½®
    
    Args:
        pipeline_name: Pipelineåç§°
        pipeline_description: Pipelineæè¿°
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„ (default: 'cfg.yaml')
        service_name: æœåŠ¡åç§° (å¯é€‰ï¼Œé»˜è®¤ä»cfg.yamlè¯»å–æˆ–ä½¿ç”¨pipeline_name-service)
        lineage_mappings: å¯é€‰çš„è¡€ç¼˜å…³ç³»æ˜ å°„
        tasks: å¯é€‰çš„è‡ªå®šä¹‰ä»»åŠ¡åˆ—è¡¨
        **kwargs: å…¶ä»–é…ç½®é€‰é¡¹
    
    Returns:
        Pipeline object or None if failed
    """
    # Create manager from cfg.yaml
    manager = create_simple_pipeline_manager(config_file)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæœåŠ¡åç§°ï¼Œä½¿ç”¨pipelineåç§°ç”Ÿæˆ
    if not service_name:
        service_name = f"{pipeline_name}-service"
    
    # Configure pipeline
    pipeline_config = PipelineConfig(
        name=pipeline_name,
        display_name=pipeline_name.replace('-', ' ').replace('_', ' ').title(),
        description=pipeline_description,
        service_name=service_name,
        tasks=tasks  # æ·»åŠ tasksæ”¯æŒ
    )
    
    # Configure owner from cfg.yaml
    owner_config = None
    if 'owner' in manager.config:
        owner_info = manager.config['owner']
        owner_config = OwnerConfig(
            name=owner_info.get('name', 'admin'),
            email=owner_info.get('email', 'admin@company.com'),
            display_name=owner_info.get('display_name', owner_info.get('name', 'Admin')),
            is_admin=owner_info.get('is_admin', False)
        )
    
    # Create pipeline
    return manager.create_complete_pipeline(
        pipeline_config=pipeline_config,
        owner_config=owner_config,
        lineage_mappings=lineage_mappings
    )


def simple_lineage_setup(
    from_table_fqn: str,
    to_table_fqn: str,
    pipeline_name: str,
    description: str = "",
    config_file: str = "cfg.yaml"
) -> bool:
    """
    ç®€å•çš„è¡€ç¼˜å…³ç³»è®¾ç½®
    
    Args:
        from_table_fqn: æºè¡¨FQN
        to_table_fqn: ç›®æ ‡è¡¨FQN
        pipeline_name: Pipelineåç§°
        description: è¡€ç¼˜å…³ç³»æè¿°
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        manager = create_simple_pipeline_manager(config_file)
        return manager.add_table_lineage(
            from_table_fqn=from_table_fqn,
            to_table_fqn=to_table_fqn,
            description=description or f"æ•°æ®è¡€ç¼˜: {from_table_fqn} â†’ {to_table_fqn}",
            pipeline_fqn=pipeline_name,
            auto_associate_pipeline=True
        )
    except Exception as e:
        print(f"âŒ è¡€ç¼˜å…³ç³»è®¾ç½®å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    # Example usage
    print("OpenMetadata Pipeline Manager - ç®€åŒ–ç‰ˆæœ¬")
    print("=" * 60)
    
    print("ğŸ”§ é…ç½®æ–‡ä»¶ç¤ºä¾‹ (cfg.yaml):")
    print("""
# æµ‹è¯•ç¯å¢ƒé…ç½® (é»˜è®¤)
openmetadata_test:
    token: "your_test_jwt_token_here"
    host: "https://test-openmetadata.dl-aiot.com/api"
    pipeline_owner_name: "adward"
    pipeline_owner_email: "adward.chen@designlibro.com"
    pipeline_owner_display_name: "adward.chen"

# ç”Ÿäº§ç¯å¢ƒé…ç½®
openmetadata_prod:
    token: "your_prod_jwt_token_here"
    host: "https://us-openmetadata.dl-aiot.com/api"
    pipeline_owner_name: "adward"
    pipeline_owner_email: "adward.chen@designlibro.com"
    pipeline_owner_display_name: "adward.chen"
""")
    
    print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
    print("""
# æ–¹å¼1: æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼ - æ‰€æœ‰é…ç½®ä»cfg.yamlè¯»å–
from datalibro_backend.openmetadata_pipeline_manager import (
    create_simple_pipeline_manager,
    quick_pipeline_setup,
    simple_lineage_setup
)

# 1. åˆ›å»ºPipeline Manager (é»˜è®¤ä½¿ç”¨æµ‹è¯•ç¯å¢ƒ)
manager = create_simple_pipeline_manager()

# æˆ–è€…ä½¿ç”¨ç”Ÿäº§ç¯å¢ƒ
# manager = create_simple_pipeline_manager(config_section="openmetadata_prod")

# 2. å¿«é€Ÿåˆ›å»ºPipeline (æŒ‡å®šæœåŠ¡åç§°)
pipeline = quick_pipeline_setup(
    pipeline_name="data-sync-pc001-active-stats",
    pipeline_description="PC001è®¾å¤‡æ´»è·ƒç»Ÿè®¡æ•°æ®åŒæ­¥",
    service_name="pc001-spark-pipeline-service"  # æ ¹æ®é¡¹ç›®éœ€æ±‚æŒ‡å®š
)

# 3. æ·»åŠ æ•°æ®è¡€ç¼˜å…³ç³»
simple_lineage_setup(
    from_table_fqn="aiot_internal.dl_cloud.ods_device_profile_detail_di",
    to_table_fqn="aiot_internal.dl_cloud.ads_pc001_active_bound_device_stats_di",
    pipeline_name="pc001-spark-pipeline-service.data-sync-pc001-active-stats",
    description="PC001è®¾å¤‡æ•°æ®å¤„ç†è¡€ç¼˜"
)

# æ–¹å¼2: ä¼ ç»Ÿæ–¹å¼ - æ‰‹åŠ¨é…ç½®
from datalibro_backend.openmetadata_pipeline_manager import (
    OpenMetadataPipelineManager,
    PipelineConfig, 
    OwnerConfig
)

# åˆ›å»ºç®¡ç†å™¨ (ä»ç„¶å¯ä»¥ä»cfg.yamlè¯»å–)
manager = OpenMetadataPipelineManager()

# æˆ–è€…æ‰‹åŠ¨é…ç½®
manager = OpenMetadataPipelineManager(
    openmetadata_config={
        'host': 'http://10.52.178.223:59693/api',
        'jwt_token': 'your-jwt-token'
    }
)

# æ–¹å¼3: åœ¨ç°æœ‰è„šæœ¬ä¸­é›†æˆ
def initialize_openmetadata_manager():
    \"\"\"åˆå§‹åŒ– OpenMetadata Pipeline Manager\"\"\"
    try:
        # æœ€ç®€å•çš„æ–¹å¼ - ä¸€è¡Œä»£ç 
        manager = create_simple_pipeline_manager()
        
        # åˆ›å»ºPipeline (æŒ‡å®šæœåŠ¡åç§°)
        pipeline = quick_pipeline_setup(
            pipeline_name=os.path.basename(__file__).replace('.py', ''),
            pipeline_description=f"æ•°æ®åŒæ­¥è„šæœ¬: {os.path.basename(__file__)}",
            service_name="pc001-spark-pipeline-service"  # æ ¹æ®é¡¹ç›®ç»Ÿä¸€ä½¿ç”¨
        )
        
        return manager, pipeline
    except Exception as e:
        print(f"âš ï¸ OpenMetadata åˆå§‹åŒ–å¤±è´¥: {e}")
        return None, None

# åœ¨mainå‡½æ•°ä¸­ä½¿ç”¨
def main():
    # åˆå§‹åŒ–OpenMetadata
    om_manager, om_pipeline = initialize_openmetadata_manager()
    
    # ä½ çš„æ•°æ®å¤„ç†é€»è¾‘...
    
    # æ·»åŠ è¡€ç¼˜å…³ç³»
    if om_manager:
        om_manager.add_table_lineage(
            from_table_fqn="source.db.table",
            to_table_fqn="target.db.table",
            description="æ•°æ®å¤„ç†è¡€ç¼˜"
        )

# æ–¹å¼4: Sparké›†æˆ (å¯é€‰é…ç½®OpenLineage)
from pyspark.sql import SparkSession
from datalibro_backend.openmetadata_pipeline_manager import OpenLineageConfig

# å¦‚æœéœ€è¦OpenLineageé›†æˆï¼Œå¯ä»¥å•ç‹¬é…ç½®
openlineage_config = OpenLineageConfig(
    namespace="datalibro-namespace",
    parent_job_name="data-pipeline"
)

manager = OpenMetadataPipelineManager(openlineage_config=openlineage_config)
spark_builder = SparkSession.builder.appName("my-app")

# é…ç½®OpenLineageé›†æˆ
spark = manager.configure_spark_openlineage(spark_builder).getOrCreate()
""")