from lingo import Lingo, Message, LLM, Context, Engine, depends
from lingo.cli import loop
import dotenv

# 1. Setup and Configuration
# Load environment variables (MODEL, API_KEY, etc.)
dotenv.load_dotenv()

# Initialize Lingo; it automatically registers itself and its LLM into its registry
bot = Lingo()


# 2. Define a Tool with Dependency Injection
# - 'llm' is automatically injected from the bot's registry.
# - '_secret_key' is hidden from the LLM's parameter schema because it starts with '_'.
@bot.tool
async def smart_search(query: str, _secret_key: str, llm=depends(LLM)):
    """
    Performs a search and uses the LLM to summarize the findings.
    """
    print(f"[Tool] Using secret key: {_secret_key}")

    # Simulate fetching data
    raw_data = f"Results for {query}: The capital of France is Paris."

    # Use the injected LLM to process the search results
    summary = await llm.chat(
        [
            Message.system("Summarize the following data concisely."),
            Message.user(raw_data),
        ]
    )

    return summary.content


# 3. Define a Skill to orchestrate Tool usage
# Skills can also depend on the Registry.
@bot.skill
async def search_assistant(context: Context, engine: Engine):
    """Use this to answer questions using a smart search tool."""
    # Invoke the tool, manually injecting the hidden '_secret_key' parameter
    # The 'query' parameter will be automatically generated by the LLM.
    result = await engine.invoke(context, smart_search, _secret_key="sk-12345")

    # Append the tool result to the conversation context
    context.append(Message.assistant(result.result))

    # Finalize by letting the LLM generate a response based on the tool output
    return await engine.reply(context)


# 4. Start the Chat Loop
# Run the bot in the CLI as seen in the hello_world example.
loop(bot)
