"""Pull Request integration utilities for posting comments and suggestions."""

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional

from refactron.core.analysis_result import AnalysisResult


@dataclass
class PRComment:
    """Represents a PR comment."""

    file_path: str
    line: int
    message: str
    level: str  # critical, error, warning, info
    rule_id: Optional[str] = None
    suggestion: Optional[str] = None

    def to_markdown(self) -> str:
        """Convert comment to markdown format.

        Returns:
            Markdown formatted comment
        """
        lines = []
        lines.append(f"### {self.level.upper()}: {self.rule_id or 'Issue'}")
        lines.append("")
        lines.append(self.message)
        lines.append("")

        if self.suggestion:
            lines.append("**Suggestion:**")
            lines.append("```python")
            lines.append(self.suggestion)
            lines.append("```")
            lines.append("")

        return "\n".join(lines)


class PRIntegration:
    """Utilities for PR integration and inline comments."""

    @staticmethod
    def generate_pr_summary(result: AnalysisResult) -> str:
        """Generate PR summary from analysis result.

        Args:
            result: Analysis result

        Returns:
            Markdown formatted summary
        """
        summary = result.summary()
        lines = []

        lines.append("## ðŸ“Š Refactron Analysis Summary")
        lines.append("")

        # Summary table
        lines.append("| Metric | Count |")
        lines.append("|--------|-------|")
        lines.append(
            f"| ðŸ“ Files Analyzed | {summary['files_analyzed']}/{summary['total_files']} |"
        )
        lines.append(f"| ðŸ”´ Critical Issues | {summary['critical']} |")
        lines.append(f"| âš ï¸ Error Issues | {summary['errors']} |")
        lines.append(f"| ðŸ’¡ Warning Issues | {summary['warnings']} |")
        lines.append(f"| ðŸ“ Info Issues | {summary['info']} |")
        lines.append(f"| ðŸ“Š Total Issues | {summary['total_issues']} |")
        lines.append("")

        # Critical issues warning
        if summary["critical"] > 0:
            msg = (
                f"âš ï¸ **{summary['critical']} critical issue(s) found - "
                "please review before merging**"
            )
            lines.append(msg)
            lines.append("")

        # Files failed warning
        if summary["files_failed"] > 0:
            lines.append(f"âŒ **{summary['files_failed']} file(s) failed analysis**")
            lines.append("")

        # Top issues by file
        if result.all_issues:
            lines.append("### ðŸ” Top Issues by File")
            lines.append("")

            file_issue_counts: Dict[Path, int] = {}
            for metrics in result.file_metrics:
                file_issue_counts[metrics.file_path] = len(metrics.issues)

            # Sort by issue count
            sorted_files = sorted(file_issue_counts.items(), key=lambda x: x[1], reverse=True)[:5]

            for file_path, count in sorted_files:
                lines.append(f"- `{file_path}`: {count} issue(s)")
            lines.append("")

        lines.append("---")
        lines.append("")
        lines.append("*Generated by [Refactron](https://github.com/Refactron-ai/Refactron_lib)*")

        return "\n".join(lines)

    @staticmethod
    def generate_inline_comments(result: AnalysisResult, file_path: Path) -> List[PRComment]:
        """Generate inline comments for a specific file.

        Args:
            result: Analysis result
            file_path: File to generate comments for

        Returns:
            List of PR comments
        """
        comments: List[PRComment] = []

        issues = result.issues_by_file(file_path)

        for issue in issues:
            # Convert issue level to PR comment level
            level_map = {
                "CRITICAL": "critical",
                "ERROR": "error",
                "WARNING": "warning",
                "INFO": "info",
            }
            level = level_map.get(issue.level.name, "info")

            comment = PRComment(
                file_path=str(file_path),
                line=issue.line_number or 1,
                message=issue.message,
                level=level,
                rule_id=issue.rule_id,
                suggestion=issue.suggestion,
            )

            comments.append(comment)

        return comments

    @staticmethod
    def generate_github_comment_body(result: AnalysisResult) -> str:
        """Generate GitHub PR comment body.

        Args:
            result: Analysis result

        Returns:
            Markdown comment body
        """
        return PRIntegration.generate_pr_summary(result)

    @staticmethod
    def format_comment_for_github_api(comment: PRComment) -> Dict:
        """Format comment for GitHub API.

        Args:
            comment: PR comment

        Returns:
            GitHub API comment format
        """
        body = f"**{comment.level.upper()}**"

        if comment.rule_id:
            body += f" ({comment.rule_id})"

        body += f"\n\n{comment.message}"

        if comment.suggestion:
            body += f"\n\n**Suggestion:**\n```python\n{comment.suggestion}\n```"

        return {
            "path": comment.file_path,
            "line": comment.line,
            "body": body,
        }

    @staticmethod
    def save_comments_json(comments: List[PRComment], output_path: Path) -> None:
        """Save comments to JSON file for CI/CD integration.

        Args:
            comments: List of PR comments
            output_path: Path to save JSON file

        Raises:
            IOError: If file cannot be written
        """
        comments_data = [
            {
                "file_path": c.file_path,
                "line": c.line,
                "message": c.message,
                "level": c.level,
                "rule_id": c.rule_id,
                "suggestion": c.suggestion,
            }
            for c in comments
        ]

        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(comments_data, f, indent=2)
