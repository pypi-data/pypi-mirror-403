# TurboAPI Benchmark Methodology - One Pager

## The Question
> "Did you not replicate the process across the cores? Threads have more overhead than events."

## Our Answer
**We agree - that's why we use events, not threads!** ğŸ¯

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Single Process (50MB memory)       â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Tokio Runtime                â”‚ â”‚
â”‚  â”‚  â”œâ”€ 14 worker threads         â”‚ â”‚
â”‚  â”‚  â”œâ”€ 7,168 async tasks         â”‚ â”‚
â”‚  â”‚  â””â”€ Work-stealing scheduler   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Rust HTTP (Hyper)            â”‚ â”‚
â”‚  â”‚  â””â”€ Event-driven I/O          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²
         â”‚ All 14 cores utilized
         â”‚ ~1400% CPU usage
         â””â”€ Verified with `top`
```

---

## Key Facts

| Metric | Value |
|--------|-------|
| **Architecture** | Event-driven async I/O |
| **CPU** | M3 Max (14 cores) |
| **Utilization** | ~1400% (all cores) |
| **Model** | Async tasks (2KB each) |
| **NOT** | OS threads (8MB each) |
| **Processes** | 1 (single process) |
| **Threads** | 14 (Tokio workers) |
| **Capacity** | 7,168 concurrent tasks |

---

## Comparison

### âŒ Thread-Per-Request (What We DON'T Do)
```
Request â†’ OS Thread (8MB)
â”œâ”€ Blocking I/O
â”œâ”€ Kernel context switch (1-10Î¼s)
â””â”€ Max ~10K connections

Needs multiple processes to use all cores
```

### âœ… Event-Driven (What We DO)
```
Request â†’ Async Task (2KB)
â”œâ”€ Non-blocking I/O
â”œâ”€ Userspace switch (~10ns)
â””â”€ Max ~10M connections

Single process uses all cores automatically
```

---

## Performance

- **Sync Endpoints**: 184,370 RPS (0.24ms latency)
- **Async Endpoints**: 12,269 RPS (3.93ms latency)
- **vs FastAPI**: 10-25Ã— faster
- **CPU Usage**: All 14 cores at 100%

---

## Why No Multiple Processes?

âœ… **Event-driven I/O**: Single process handles 10K+ connections  
âœ… **Tokio work-stealing**: Automatic multi-core load balancing  
âœ… **No GIL**: Python 3.13t/3.14t free-threading  
âœ… **Rust HTTP**: Zero Python overhead for I/O  
âœ… **More efficient**: No IPC overhead, shared memory  

---

## Verification

```bash
# Start server
python examples/multi_route_app.py &

# Check CPU usage
top -pid $(pgrep -f multi_route_app)
# Shows ~1400% CPU (14 cores Ã— 100%)

# Run benchmark
wrk -t4 -c50 -d30s http://127.0.0.1:8000/users/123
# Result: 184K RPS
```

---

## We're Transparent

âœ… All code is open source  
âœ… All benchmarks are reproducible  
âœ… All hardware specs documented  
âœ… All methodology explained  
âœ… We document limitations honestly  

---

## Learn More

- **Quick FAQ**: [BENCHMARK_FAQ.md](BENCHMARK_FAQ.md)
- **Full Response**: [BENCHMARK_METHODOLOGY_RESPONSE.md](BENCHMARK_METHODOLOGY_RESPONSE.md)
- **Architecture**: [docs/ARCHITECTURE_DIAGRAM.md](docs/ARCHITECTURE_DIAGRAM.md)
- **GitHub**: https://github.com/justrach/turboAPI

---

## Bottom Line

**We use events (async I/O), not threads.**  
**All 14 cores are utilized automatically.**  
**Single process is more efficient than multiple processes.**  
**We welcome scrutiny and questions!** ğŸš€

---

*TurboAPI: FastAPI syntax with Rust performance*
