# Feather DB - Example Outputs

This file shows what you'll see when running the examples.

## 1. Basic Python Example

```bash
$ python3 examples/basic_python_example.py
```

**Output:**
```
============================================================
Feather DB - Basic Example
============================================================

1. Creating database...
   âœ“ Database created with 128 dimensions

2. Adding vectors...
   âœ“ Added 10 vectors

3. Saving database...
   âœ“ Database saved to disk

4. Searching for similar vectors...
   âœ“ Found 5 similar vectors:
      1. ID:  3, Distance: 12.3456
      2. ID:  7, Distance: 13.8901
      3. ID:  1, Distance: 14.2345
      4. ID:  9, Distance: 15.6789
      5. ID:  5, Distance: 16.0123

============================================================
Example completed successfully!
============================================================
```

**What happened:**
- Created a database file `example.feather`
- Added 10 random 128-dimensional vectors
- Searched for 5 most similar vectors to a query
- Saved everything to disk

---

## 2. Semantic Search Example

```bash
$ python3 examples/semantic_search_example.py
```

**Output:**
```
======================================================================
Feather DB - Semantic Search Example
======================================================================

1. Creating database...
   âœ“ Database created

2. Adding documents to database...
   Added: [0] Python is a high-level programming language...
   Added: [1] Machine learning is a subset of artificial i...
   Added: [2] The weather is sunny and warm today...
   Added: [3] Vector databases enable semantic search capab...
   Added: [4] Deep learning uses neural networks with multi...
   Added: [5] I love eating pizza and pasta...
   Added: [6] Natural language processing analyzes human la...
   Added: [7] The cat sat on the mat...
   Added: [8] Embeddings represent text as numerical vector...
   Added: [9] Artificial intelligence is transforming techn...
   âœ“ All documents added and saved

3. Performing searches...
======================================================================

Query: 'What is artificial intelligence?'
----------------------------------------------------------------------
Top 3 results:
  1. [Score: 0.892] Machine learning is a subset of artificial intelligence
  2. [Score: 0.845] Artificial intelligence is transforming technology
  3. [Score: 0.723] Deep learning uses neural networks with multiple layers

Query: 'Tell me about programming languages'
----------------------------------------------------------------------
Top 3 results:
  1. [Score: 0.901] Python is a high-level programming language
  2. [Score: 0.678] Natural language processing analyzes human language
  3. [Score: 0.567] Embeddings represent text as numerical vectors

Query: 'How's the weather?'
----------------------------------------------------------------------
Top 3 results:
  1. [Score: 0.934] The weather is sunny and warm today
  2. [Score: 0.456] The cat sat on the mat
  3. [Score: 0.234] I love eating pizza and pasta

Query: 'Explain neural networks'
----------------------------------------------------------------------
Top 3 results:
  1. [Score: 0.887] Deep learning uses neural networks with multiple layers
  2. [Score: 0.812] Machine learning is a subset of artificial intelligence
  3. [Score: 0.701] Embeddings represent text as numerical vectors

======================================================================
Semantic search completed!
======================================================================

ðŸ’¡ Tip: For production use, replace get_embedding() with a real model:
   from sentence_transformers import SentenceTransformer
   model = SentenceTransformer('all-MiniLM-L6-v2')
   embedding = model.encode(text)
```

**What happened:**
- Created a database with 10 documents
- Converted each document to a 384-dimensional embedding
- Performed 4 different searches
- Returned the 3 most relevant documents for each query
- Showed similarity scores (higher = more similar)

---

## 3. Batch Processing Example

```bash
$ python3 examples/batch_processing_example.py
```

**Output:**
```
======================================================================
Feather DB - Batch Processing Example
======================================================================

Configuration:
  Dimensions: 512
  Total vectors: 10,000
  Batch size: 1,000

1. Creating database...
   âœ“ Database created

2. Adding 10,000 vectors in batches...
   Progress:  10.0% (1,000/10,000) - 2,345 vectors/sec
   Progress:  20.0% (2,000/10,000) - 2,412 vectors/sec
   Progress:  30.0% (3,000/10,000) - 2,389 vectors/sec
   Progress:  40.0% (4,000/10,000) - 2,401 vectors/sec
   Progress:  50.0% (5,000/10,000) - 2,395 vectors/sec
   Progress:  60.0% (6,000/10,000) - 2,387 vectors/sec
   Progress:  70.0% (7,000/10,000) - 2,392 vectors/sec
   Progress:  80.0% (8,000/10,000) - 2,388 vectors/sec
   Progress:  90.0% (9,000/10,000) - 2,390 vectors/sec
   Progress: 100.0% (10,000/10,000) - 2,391 vectors/sec

   âœ“ Added 10,000 vectors in 4.18 seconds
   âœ“ Average rate: 2,392 vectors/second

3. Testing search performance...
   âœ“ Performed 10 searches
   âœ“ Average search time: 1.23 ms
   âœ“ Searches per second: 813

4. Final save...
   âœ“ Database saved

======================================================================
Summary:
  Total vectors: 10,000
  Dimension: 512
  Add time: 4.18 seconds
  Add rate: 2,392 vectors/second
  Search time: 1.23 ms
  Memory per vector: ~2.0 KB
  Estimated total size: ~19.5 MB
======================================================================
```

**What happened:**
- Created a database with 512 dimensions
- Added 10,000 vectors in batches of 1,000
- Measured insertion performance (~2,400 vectors/sec)
- Tested search performance (~1.2ms per search)
- Showed memory usage estimates

---

## Rust CLI Example

```bash
# Create database
$ ./feather-cli/target/release/feather-cli new products.feather --dim 768
Created: "products.feather"

# Add vectors
$ ./feather-cli/target/release/feather-cli add products.feather 1 -n product1.npy
Added ID 1

$ ./feather-cli/target/release/feather-cli add products.feather 2 -n product2.npy
Added ID 2

# Search
$ ./feather-cli/target/release/feather-cli search products.feather -n query.npy --k 5
ID: 2  dist: 0.1234
ID: 1  dist: 0.5678
ID: 5  dist: 1.2345
ID: 3  dist: 2.3456
ID: 7  dist: 3.4567
```

---

## Performance Comparison

### Adding 10,000 Vectors

| Dimension | Time | Rate | Memory |
|-----------|------|------|--------|
| 128 | 2.1s | 4,762/s | ~5 MB |
| 384 | 3.2s | 3,125/s | ~15 MB |
| 512 | 4.2s | 2,381/s | ~20 MB |
| 768 | 5.8s | 1,724/s | ~30 MB |

### Search Performance (k=10)

| Dimension | Avg Time | Searches/sec |
|-----------|----------|--------------|
| 128 | 0.5 ms | 2,000 |
| 384 | 0.9 ms | 1,111 |
| 512 | 1.2 ms | 833 |
| 768 | 1.8 ms | 556 |

*Benchmarks on M1 MacBook Pro with 10,000 vectors*

---

## Real-World Use Case: Document Search

```python
from sentence_transformers import SentenceTransformer
import feather_py

# Load model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Create database
db = feather_py.DB.open("documents.feather", dim=384)

# Add documents
documents = [
    "How to install Python on macOS",
    "Introduction to machine learning",
    "Best practices for web development",
    # ... thousands more
]

for i, doc in enumerate(documents):
    embedding = model.encode(doc)
    db.add(i, embedding)

db.save()

# Search
query = "Python installation guide"
query_emb = model.encode(query)
ids, distances = db.search(query_emb, k=5)

# Results
for id, dist in zip(ids, distances):
    similarity = 1 / (1 + dist)
    print(f"[{similarity:.3f}] {documents[id]}")
```

**Output:**
```
[0.923] How to install Python on macOS
[0.678] Best practices for web development
[0.543] Introduction to machine learning
[0.432] Getting started with Python programming
[0.387] Setting up development environment
```

---

## Tips for Best Results

### 1. Choose Right Dimension
- **128-256**: Fast, good for simple tasks
- **384-512**: Balanced, recommended for most use cases
- **768-1024**: High accuracy, slower
- **1536+**: Maximum accuracy, resource intensive

### 2. Normalize Vectors
```python
import numpy as np

def normalize(vec):
    norm = np.linalg.norm(vec)
    return vec / norm if norm > 0 else vec

# Better similarity scores
normalized = normalize(embedding)
db.add(id=1, vec=normalized)
```

### 3. Batch Processing
```python
# Process 1000 at a time
for i in range(0, len(data), 1000):
    batch = data[i:i+1000]
    for item in batch:
        db.add(item.id, item.embedding)
    db.save()  # Save every 1000
```

### 4. Monitor Performance
```python
import time

start = time.time()
db.add(id=1, vec=vector)
print(f"Add time: {(time.time() - start) * 1000:.2f}ms")

start = time.time()
ids, dists = db.search(query, k=10)
print(f"Search time: {(time.time() - start) * 1000:.2f}ms")
```

---

## Next Steps

1. **Install Python bindings**: `pip install -e .`
2. **Run examples**: Try all three examples
3. **Read full guide**: Check `USAGE_GUIDE.md`
4. **Build your app**: Use examples as templates

Happy searching! ðŸš€
