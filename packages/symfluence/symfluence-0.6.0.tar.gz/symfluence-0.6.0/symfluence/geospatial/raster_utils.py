"""
Raster processing utilities for geospatial analysis.

Provides functions for land cover mode calculation, aspect and radiation
derivation from DEMs, and raster value analysis for discretization.
"""

import logging
import numpy as np
import rasterio # type: ignore
from scipy import stats
import glob
import pandas as pd
import pvlib
from pathlib import Path
from logging import Logger
from typing import Optional


def _scipy_mode_compat(data: np.ndarray, axis: int = 0) -> np.ndarray:
    """
    Compute mode with scipy version compatibility.

    Handles scipy <1.11 (no keepdims) and >=1.11 (keepdims parameter).

    Args:
        data: Input array to compute mode over
        axis: Axis along which to compute the mode

    Returns:
        Array of mode values with the specified axis removed
    """
    try:
        # scipy >= 1.11.0
        result = stats.mode(data, axis=axis, keepdims=False)
        return result.mode
    except TypeError:
        # scipy 1.10.x - no keepdims parameter
        result = stats.mode(data, axis=axis)
        # Old scipy returns ModeResult with shape including axis dimension
        return np.squeeze(result.mode, axis=axis)


def calculate_landcover_mode(
    input_dir: Path,
    output_file: Path,
    start_year: int,
    end_year: int,
    domain_name: str
) -> None:
    """
    Calculate the temporal mode of land cover data across multiple years.

    This function computes the most frequently occurring land cover class for each
    pixel across a time series of annual land cover rasters. The mode calculation
    reduces year-to-year variability caused by classification noise, creating a
    more representative land cover map for hydrological modeling.

    Algorithm:
        1. Search for land cover rasters matching the domain and year pattern
        2. Load all matching rasters into a 3D array (time, height, width)
        3. Compute the statistical mode along the time axis using scipy.stats.mode
        4. Handle edge cases (single year, scipy version differences)
        5. Write the mode raster with the same georeference as inputs

    File Pattern:
        Primary: ``{input_dir}/domain_{domain_name}_*_{year}*.tif``
        Fallback: ``{input_dir}/domain_{domain_name}_*.tif`` if no year match

    Args:
        input_dir: Directory containing the yearly land cover GeoTIFF files
        output_file: Path where the output mode raster will be saved
        start_year: Start year for mode calculation (inclusive)
        end_year: End year for mode calculation (inclusive)
        domain_name: Domain name used in file pattern matching

    Returns:
        None. Writes the mode raster to output_file.

    Raises:
        FileNotFoundError: If no land cover files match the search pattern

    Notes:
        - Uses scipy.stats.mode which returns the smallest value if multimodal
        - Handles scipy version differences (pre/post keepdims parameter)
        - Creates output directory if it doesn't exist
        - Preserves input CRS, transform, and dtype in output
        - Sets nodata value to 0 in output
        - If only one year of data found, returns that year's data directly

    Example:
        >>> calculate_landcover_mode(
        ...     Path('/data/landcover'),
        ...     Path('/output/landcover_mode.tif'),
        ...     2015, 2020, 'bow_river'
        ... )
    """

    # Create a list to store the data from each year
    yearly_data = []
    meta = None

    # Get a list of files matching the pattern for the specified years
    file_pattern = f"{input_dir}/domain_{domain_name}_*_{start_year}*.tif"
    files = glob.glob(str(file_pattern))

    if not files:
        # If no files match the start year, try to find any files in the directory
        file_pattern = f"{input_dir}/domain_{domain_name}_*.tif"
        files = glob.glob(str(file_pattern))

    if not files:
        raise FileNotFoundError(f"No land cover files found matching pattern: {file_pattern}")

    # Read metadata from the first file
    with rasterio.open(files[0]) as src:
        meta = src.meta.copy()
        shape = (src.height, src.width)
        input_nodata = meta.get('nodata', None)

    # Read data for each year
    for year in range(start_year, end_year + 1):
        pattern = f"{input_dir}/domain_{domain_name}_*_{year}*.tif"
        year_files = glob.glob(str(pattern))

        if year_files:
            with rasterio.open(year_files[0]) as src:
                # Read the data and append to our list
                data = src.read(1)
                yearly_data.append(data)

    if not yearly_data:
        # If no yearly data was found, use the first file we found
        with rasterio.open(files[0]) as src:
            data = src.read(1)
            yearly_data.append(data)

    # Check if we have only one year of data
    if len(yearly_data) == 1:
        # Just use that single year's data
        mode_data = yearly_data[0]
    else:
        # Stack the arrays
        stacked_data = np.stack(yearly_data, axis=0)

        # Calculate the mode along the year axis (axis=0)
        # Use compatibility wrapper for scipy version differences
        mode_data = _scipy_mode_compat(stacked_data, axis=0)

    # Update the metadata for the output file
    # Preserve input nodata or use dtype-appropriate value to avoid conflicts
    # with valid land cover classes (e.g., 0 often represents water or background)
    if input_nodata is not None:
        output_nodata = input_nodata
    elif meta['dtype'] == 'uint8':
        output_nodata = 255  # Standard nodata for uint8 land cover
    else:
        output_nodata = -9999

    meta.update({
        'count': 1,
        'nodata': output_nodata
    })

    # Ensure output directory exists
    output_file.parent.mkdir(parents=True, exist_ok=True)

    # Write the result
    logger = logging.getLogger(__name__)

    with rasterio.open(output_file, 'w', **meta) as dst:
        # Make sure mode_data has the right shape
        if mode_data.ndim == 1 or mode_data.shape != shape:
            # If the shape doesn't match, reshape it to the expected dimensions
            if mode_data.size == shape[0] * shape[1]:
                logger.warning(
                    f"Mode data shape {mode_data.shape} reshaped to {shape}. "
                    "Verify output raster for correctness."
                )
                mode_data = mode_data.reshape(shape)
            else:
                logger.warning(
                    f"Mode data shape {mode_data.shape} does not match expected {shape}. "
                    f"Padding with zeros - DATA MAY BE INCOMPLETE."
                )
                # Create a new array with the correct shape
                new_mode_data = np.zeros(shape, dtype=meta['dtype'])

                # If mode_data is 1D but should be 2D
                if mode_data.ndim == 1:
                    # Take as many values as we can from mode_data
                    size = min(mode_data.size, shape[0] * shape[1])
                    new_mode_data.flat[:size] = mode_data[:size]
                else:
                    # If dimensions don't match but we can copy partial data
                    min_h = min(mode_data.shape[0], shape[0])
                    min_w = min(mode_data.shape[1], shape[1])
                    new_mode_data[:min_h, :min_w] = mode_data[:min_h, :min_w]

                mode_data = new_mode_data

        # Now write the data
        dst.write(mode_data, 1)


def calculate_aspect(dem_raster: Path, aspect_raster: Path, aspect_class_number: int, logger: Logger) -> Optional[Path]:
    """
    Calculate aspect (slope direction) from DEM and classify into directional classes.

    Args:
        dem_raster: Path to the DEM raster
        aspect_raster: Path where the aspect raster will be saved
        aspect_class_number: Number of aspect classes to create
        logger: Logger object

    Returns:
        Path to the created aspect raster or None if failed
    """
    logger.info(f"Calculating aspect from DEM: {dem_raster}")

    try:
        with rasterio.open(dem_raster) as src:
            dem = src.read(1)
            transform = src.transform
            crs = src.crs
            nodata = src.nodata

        # Calculate gradients
        dy, dx = np.gradient(dem.astype(float))

        # Calculate aspect in radians, then convert to degrees
        aspect_rad = np.arctan2(-dx, dy)  # Note the negative sign for dx
        aspect_deg = np.degrees(aspect_rad)

        # Convert to compass bearing (0-360 degrees, 0 = North)
        aspect_deg = (90 - aspect_deg) % 360

        # Handle flat areas (where both dx and dy are near zero)
        slope_magnitude = np.sqrt(dx*dx + dy*dy)
        flat_threshold = 1e-6  # Adjust as needed
        flat_mask = slope_magnitude < flat_threshold

        # Classify aspect into directional classes
        classified_aspect = classify_aspect_into_classes(aspect_deg, flat_mask, aspect_class_number)

        # Handle nodata values from original DEM
        if nodata is not None:
            dem_nodata_mask = dem == nodata
            classified_aspect[dem_nodata_mask] = -9999

        # Save the classified aspect raster
        aspect_raster.parent.mkdir(parents=True, exist_ok=True)

        with rasterio.open(aspect_raster, 'w', driver='GTiff',
                        height=classified_aspect.shape[0], width=classified_aspect.shape[1],
                        count=1, dtype=classified_aspect.dtype,
                        crs=crs, transform=transform, nodata=-9999) as dst:
            dst.write(classified_aspect, 1)

        logger.info(f"Aspect raster saved to: {aspect_raster}")
        logger.info(f"Aspect classes: {np.unique(classified_aspect[classified_aspect != -9999])}")
        return aspect_raster

    except Exception as e:
        logger.error(f"Error calculating aspect: {str(e)}", exc_info=True)
        return None

def classify_aspect_into_classes(aspect_deg: np.ndarray, flat_mask: np.ndarray,
                                num_classes: int) -> np.ndarray:
    """
    Classify aspect degrees into directional classes.

    Args:
        aspect_deg: Aspect in degrees (0-360)
        flat_mask: Boolean mask for flat areas
        num_classes: Number of aspect classes to create

    Returns:
        Classified aspect array
    """
    classified = np.zeros_like(aspect_deg, dtype=int)

    if num_classes == 8:
        # Standard 8-direction classification
        # N, NE, E, SE, S, SW, W, NW
        bins = [0, 22.5, 67.5, 112.5, 157.5, 202.5, 247.5, 292.5, 337.5, 360]
        labels = [1, 2, 3, 4, 5, 6, 7, 8, 1]  # Last one wraps to North

        for i in range(len(bins) - 1):
            if i == len(bins) - 2:  # Last bin (337.5 to 360)
                mask = (aspect_deg >= bins[i]) & (aspect_deg <= bins[i+1])
            else:
                mask = (aspect_deg >= bins[i]) & (aspect_deg < bins[i+1])
            classified[mask] = labels[i]

    elif num_classes == 4:
        # 4-direction classification (N, E, S, W)
        bins = [0, 45, 135, 225, 315, 360]
        labels = [1, 2, 3, 4, 1]  # N, E, S, W, N

        for i in range(len(bins) - 1):
            if i == len(bins) - 2:  # Last bin
                mask = (aspect_deg >= bins[i]) & (aspect_deg <= bins[i+1])
            else:
                mask = (aspect_deg >= bins[i]) & (aspect_deg < bins[i+1])
            classified[mask] = labels[i]

    else:
        # Custom number of classes - divide 360 degrees evenly
        class_width = 360.0 / num_classes
        for i in range(num_classes):
            lower = i * class_width
            upper = (i + 1) * class_width

            if i == num_classes - 1:  # Last class includes 360
                mask = (aspect_deg >= lower) & (aspect_deg <= upper)
            else:
                mask = (aspect_deg >= lower) & (aspect_deg < upper)
            classified[mask] = i + 1

    # Set flat areas to a special class (0)
    classified[flat_mask] = 0

    # Set areas that don't fall into any class to -9999 (shouldn't happen but safety)
    classified[classified == 0] = 0  # Keep flat areas as 0

    return classified

def calculate_annual_radiation(dem_raster: Path, radiation_raster: Path, logger: Logger) -> Optional[Path]:
    """
    Calculate annual radiation from DEM.

    Args:
        dem_raster: Path to the DEM raster
        radiation_raster: Path where the radiation raster will be saved
        logger: Logger object

    Returns:
        Path to the created radiation raster or None if failed
    """
    logger.info(f"Calculating annual radiation from DEM: {dem_raster}")

    try:
        with rasterio.open(dem_raster) as src:
            dem = src.read(1)
            transform = src.transform
            crs = src.crs
            bounds = src.bounds

        center_lat = (bounds.bottom + bounds.top) / 2
        center_lon = (bounds.left + bounds.right) / 2

        # Calculate slope and aspect
        dy, dx = np.gradient(dem)
        slope = np.arctan(np.sqrt(dx*dx + dy*dy))
        aspect = np.arctan2(-dx, dy)

        # Create a DatetimeIndex for the entire year (daily)
        times = pd.date_range(start='2019-01-01', end='2019-12-31', freq='D')

        # Create location object
        location = pvlib.location.Location(latitude=center_lat, longitude=center_lon, altitude=np.mean(dem))

        # Calculate solar position
        location.get_solarposition(times=times)

        # Calculate clear sky radiation
        location.get_clearsky(times=times)

        # Initialize the radiation array
        radiation = np.zeros_like(dem, dtype=float)

        logger.info("Calculating radiation for all pixels (vectorized)...")

        # Flatten arrays for vectorization
        slope_flat = np.degrees(slope.flatten())
        aspect_flat = np.degrees(aspect.flatten())

        # Calculate solar position (returns a DataFrame with time index)
        # We need to broadcast this for each pixel, which is memory intensive
        # Instead, we'll loop through days/times and accumulate radiation

        # Get solar position for all times (this is constant across the domain for small domains)
        # For larger domains, this is an approximation
        solar_pos = location.get_solarposition(times=times)

        # Get clear sky data
        cs = location.get_clearsky(times=times)

        # Transpose solar data for broadcasting
        # Shape: (n_times,)
        zenith = solar_pos['apparent_zenith'].values
        azimuth = solar_pos['azimuth'].values
        dni = cs['dni'].values
        ghi = cs['ghi'].values
        dhi = cs['dhi'].values

        # To avoid MemoryError on large rasters, we can process in chunks or
        # keep the loop over time (365 days) which is better than looping over pixels

        # Initialize total radiation accumulator
        total_radiation_flat = np.zeros(dem.size)

        # Process in batches of days to manage memory if needed,
        # but for now let's try a vectorized approach over pixels, looping over time
        # Actually, pvlib can handle arrays for surface_tilt and surface_azimuth

        # We'll calculate the sum of radiation over the year
        # This is still heavy if we do all times x all pixels at once
        # Let's loop over time steps and accumulate, that's safer for memory

        for t_idx in range(len(times)):
            # Scalar values for this time step
            z = zenith[t_idx]
            az = azimuth[t_idx]
            d = dni[t_idx]
            g = ghi[t_idx]
            dh = dhi[t_idx]

            # Skip night time
            if z > 90:
                continue

            # Calculate irradiance for all pixels at this time step
            irrad = pvlib.irradiance.get_total_irradiance(
                surface_tilt=slope_flat,
                surface_azimuth=aspect_flat,
                solar_zenith=z,
                solar_azimuth=az,
                dni=d,
                ghi=g,
                dhi=dh
            )

            # Accumulate global POA (Plane of Array) radiation
            # Nan values can occur if inputs are invalid, replace with 0
            poa = irrad['poa_global'].fillna(0).values
            total_radiation_flat += poa

        # Reshape back to 2D
        radiation = total_radiation_flat.reshape(dem.shape)

        # Save the radiation raster
        radiation_raster.parent.mkdir(parents=True, exist_ok=True)

        with rasterio.open(radiation_raster, 'w', driver='GTiff',
                        height=radiation.shape[0], width=radiation.shape[1],
                        count=1, dtype=radiation.dtype,
                        crs=crs, transform=transform) as dst:
            dst.write(radiation, 1)

        logger.info(f"Radiation raster saved to: {radiation_raster}")
        return radiation_raster

    except Exception as e:
        logger.error(f"Error calculating annual radiation: {str(e)}", exc_info=True)
        return None

def analyze_raster_values(
    raster_path: Path,
    band_size: Optional[float] = None,
    logger: Optional[Logger] = None
) -> np.ndarray:
    """
    Analyze raster values to determine discretization thresholds.
    Reads raster in chunks to handle large files efficiently.

    Args:
        raster_path: Path to the raster file
        band_size: Optional band size for discretization (for continuous data)
        logger: Optional logger

    Returns:
        Array of threshold values
    """
    # Process raster in chunks
    CHUNK_SIZE = 1024  # Adjust based on available memory
    valid_data = []

    if logger:
        logger.info(f"Analyzing raster values from: {raster_path}")

    with rasterio.open(raster_path) as src:
        height = src.height
        width = src.width
        nodata = src.nodata

        if logger:
            logger.info(f"Raster info: {width}x{height} pixels, nodata={nodata}")

        for y in range(0, height, CHUNK_SIZE):
            for x in range(0, width, CHUNK_SIZE):
                window = rasterio.windows.Window(
                    x, y, min(CHUNK_SIZE, width - x), min(CHUNK_SIZE, height - y)
                )
                chunk = src.read(1, window=window)

                # Filter out nodata values
                if nodata is not None:
                    valid_chunk = chunk[chunk != nodata]
                else:
                    valid_chunk = (
                        chunk[~np.isnan(chunk)]
                        if chunk.dtype == np.float64
                        else chunk
                    )

                if len(valid_chunk) > 0:
                    valid_data.extend(valid_chunk.flatten())

    if len(valid_data) == 0:
        raise ValueError("No valid data found in raster")

    valid_data = np.array(valid_data)
    data_min = np.min(valid_data)
    data_max = np.max(valid_data)

    if logger:
        logger.info(f"Valid data range: {data_min:.2f} to {data_max:.2f}")
        logger.info(f"Total valid pixels: {len(valid_data)}")

    # Calculate thresholds based on the data
    if band_size is not None:
        # For elevation-based or radiation-based discretization
        # Ensure thresholds cover the full data range
        min_val = data_min
        max_val = data_max

        # Create bands that fully cover the data range
        thresholds = np.arange(min_val, max_val + band_size, band_size)

        # Ensure the last threshold covers the maximum value
        if thresholds[-1] < max_val:
            thresholds = np.append(thresholds, thresholds[-1] + band_size)

        if logger:
            logger.info(f"Created {len(thresholds)-1} bands with size {band_size}")
            logger.info(
                f"Threshold range: {thresholds[0]:.2f} to {thresholds[-1]:.2f}"
            )
    else:
        # For soil or land class-based discretization
        thresholds = np.unique(valid_data)
        if logger:
            logger.info(f"Found {len(thresholds)} unique classes")

    return thresholds
