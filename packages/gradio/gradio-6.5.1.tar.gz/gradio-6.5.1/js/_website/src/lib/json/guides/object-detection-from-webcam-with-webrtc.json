{"guide": {"name": "object-detection-from-webcam-with-webrtc", "category": "streaming", "pretty_category": "Streaming", "guide_index": 2, "absolute_index": 44, "pretty_name": "Object Detection From Webcam With Webrtc", "content": "# Real Time Object Detection from a Webcam Stream with FastRTC\n\n\n\nIn this guide, we'll use YOLOv10 to perform real-time object detection in Gradio from a user's webcam feed. We'll utilize [FastRTC](https://fastrtc.org/) a companion library from the gradio team for building low latency streaming web applications. You can see the finished product in action below:\n\n<video src=\"https://github.com/user-attachments/assets/4584cec6-8c1a-401b-9b61-a4fe0718b558\" controls\nheight=\"600\" width=\"600\" style=\"display: block; margin: auto;\" autoplay=\"true\" loop=\"true\">\n</video>\n\n## Setting up\n\nStart by installing all the dependencies. Add the following lines to a `requirements.txt` file and run `pip install -r requirements.txt`:\n\n```bash\nopencv-python\nfastrtc\nonnxruntime-gpu\n```\n\nWe'll use the ONNX runtime to speed up YOLOv10 inference. This guide assumes you have access to a GPU. If you don't, change `onnxruntime-gpu` to `onnxruntime`. Without a GPU, the model will run slower, resulting in a laggy demo.\n\nWe'll use OpenCV for image manipulation and the [WebRTC](https://webrtc.org/) protocol to achieve near-zero latency.\n\n**Note**: If you want to deploy this app on any cloud provider, you'll need to use your Hugging Face token to connect to a TURN server. Learn more in this [guide](https://fastrtc.org/deployment/). If you're not familiar with TURN servers, consult this [guide](https://www.twilio.com/docs/stun-turn/faq#faq-what-is-nat).\n\n## The Inference Function\n\nWe'll download the YOLOv10 model from the Hugging Face hub and instantiate a custom inference class to use this model. \n\nThe implementation of the inference class isn't covered in this guide, but you can find the source code [here](https://huggingface.co/spaces/freddyaboulton/webrtc-yolov10n/blob/main/inference.py#L9) if you're interested. This implementation borrows heavily from this [github repository](https://github.com/ibaiGorordo/ONNX-YOLOv8-Object-Detection).\n\nWe're using the `yolov10-n` variant because it has the lowest latency. See the [Performance](https://github.com/THU-MIG/yolov10?tab=readme-ov-file#performance) section of the README in the YOLOv10 GitHub repository.\n\n```python\nfrom huggingface_hub import hf_hub_download\nfrom inference import YOLOv10\n\nmodel_file = hf_hub_download(\n    repo_id=\"onnx-community/yolov10n\", filename=\"onnx/model.onnx\"\n)\n\nmodel = YOLOv10(model_file)\n\ndef detection(image, conf_threshold=0.3):\n    image = cv2.resize(image, (model.input_width, model.input_height))\n    new_image = model.detect_objects(image, conf_threshold)\n    return new_image\n```\n\nOur inference function, `detection`, accepts a numpy array from the webcam and a desired confidence threshold. Object detection models like YOLO identify many objects and assign a confidence score to each. The lower the confidence, the higher the chance of a false positive. We'll let users adjust the confidence threshold.\n\nThe function returns a numpy array corresponding to the same input image with all detected objects in bounding boxes.\n\n## The Gradio Demo\n\nThe Gradio demo is straightforward, but we'll implement a few specific features:\n\n1. Use the `WebRTC` custom component to ensure input and output are sent to/from the server with WebRTC. \n2. The [WebRTC](https://github.com/freddyaboulton/gradio-webrtc) component will serve as both an input and output component.\n3. Utilize the `time_limit` parameter of the `stream` event. This parameter sets a processing time for each user's stream. In a multi-user setting, such as on Spaces, we'll stop processing the current user's stream after this period and move on to the next. \n\nWe'll also apply custom CSS to center the webcam and slider on the page.\n\n```python\nimport gradio as gr\nfrom fastrtc import WebRTC\n\ncss = \"\"\".my-group {max-width: 600px !important; max-height: 600px !important;}\n         .my-column {display: flex !important; justify-content: center !important; align-items: center !important;}\"\"\"\n\nwith gr.Blocks(css=css) as demo:\n    gr.HTML(\n        \"\"\"\n        <h1 style='text-align: center'>\n        YOLOv10 Webcam Stream (Powered by WebRTC \u26a1\ufe0f)\n        </h1>\n        \"\"\"\n    )\n    with gr.Column(elem_classes=[\"my-column\"]):\n        with gr.Group(elem_classes=[\"my-group\"]):\n            image = WebRTC(label=\"Stream\", rtc_configuration=rtc_configuration)\n            conf_threshold = gr.Slider(\n                label=\"Confidence Threshold\",\n                minimum=0.0,\n                maximum=1.0,\n                step=0.05,\n                value=0.30,\n            )\n\n        image.stream(\n            fn=detection, inputs=[image, conf_threshold], outputs=[image], time_limit=10\n        )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n## Conclusion\n\nOur app is hosted on Hugging Face Spaces [here](https://huggingface.co/spaces/freddyaboulton/webrtc-yolov10n). \n\nYou can use this app as a starting point to build real-time image applications with Gradio. Don't hesitate to open issues in the space or in the [FastRTC GitHub repo](https://github.com/gradio-app/fastrtc) if you have any questions or encounter problems.", "tags": ["VISION", "STREAMING", "WEBCAM"], "spaces": [], "url": "/guides/object-detection-from-webcam-with-webrtc/", "contributor": null}}