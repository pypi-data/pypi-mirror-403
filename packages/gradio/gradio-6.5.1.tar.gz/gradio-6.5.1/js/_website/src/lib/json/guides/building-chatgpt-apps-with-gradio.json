{"guide": {"name": "building-chatgpt-apps-with-gradio", "category": "mcp", "pretty_category": "Mcp", "guide_index": 5, "absolute_index": 67, "pretty_name": "Building Chatgpt Apps With Gradio", "content": "# Building ChatGPT Apps with Gradio and Apps SDK\n\n[Apps in ChatGPT](https://openai.com/index/introducing-apps-in-chatgpt/) are a great way to let users try your machine learning models or other kinds of apps entirely by chatting in familiar chat application. OpenAI has released the [Apps SDK](https://developers.openai.com/apps-sdk/quickstart) for developers to build complete applications, but you can use Gradio to build ChatGPT apps very quickly, based off of your Gradio MCP server. We will also see how Gradio's built-in [share links](https://www.gradio.app/guides/sharing-your-app#sharing-demos) make it especially easy to iterate on your ChatGPT app!\n\n### Introduction\n\nBuilding a ChatGPT app requires doing two things:\n\n* Building a Gradio MCP server with at least one tool exposed. If you're not already familiar with building a Gradio MCP server, we recommend reading [this guide first](https://www.gradio.app/guides/building-mcp-server-with-gradio).\n\n* Building a custom UI with HTML, JavaScript, and CSS that will be displayed when your tool is called, an exposing that as an MCP resource. \n\nWe will walk through the steps in more detail below.\n\n### Prerequisites\n\n* You will need to enable \"developer mode\" in ChatGPT under Settings \u2192 Apps & Connectors \u2192 Advanced settings in ChatGPT. This currently requires a paid ChatGPT account.\n* You need to have `gradio>=6.0` installed with the `mcp` add-on:\n\n```bash\npip install --upgrade gradio[mcp]\n```\n\nNow, let's walk through two examples of how you can build build ChatGPT apps with Gradio. \n\n### Example 1: Letter Counter App\n\nThe first example is an ChatGPT app that counts the occurrence of letters in a word and displays a card with the word and specified letters highlighted, like this:\n\n<video src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/letter-counter-app-recording.mp4\" controls></video>\n\n\nSo how do we build this? You can find the complete code for the letter counter app [in a single file here](https://github.com/gradio-app/gradio/blob/main/demo/mcp_letter_counter_app/run.py), or follow the steps below:\n\n1. Start by writing your Python function. In our case, the function is simply a letter counter:\n\n```py\ndef letter_counter(word: str, letter: str) -> int:\n    \"\"\"\n    Count the number of letters in a word or phrase.\n\n    Parameters:\n        word (str): The word or phrase to count the letters of.\n        letter (str): The letter to count the occurrences of.\n    \"\"\"\n    return word.count(letter)\n```\n\n2. Then, wrap your Python function with a Gradio UI, something along these lines:\n\n```py\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            word = gr.Textbox(label=\"Word\")\n            letter = gr.Textbox(label=\"Letter\")\n            btn = gr.Button(\"Count Letters\")\n        with gr.Column():\n            count = gr.Number(label=\"Count\")\n\n    btn.click(letter_counter, inputs=[word, letter], outputs=count)\n```\n\n3. Now, launch your Gradio app with the MCP server enabled, i.e. with `mcp_server=True`\n\n```py\n    demo.launch(mcp_server=True)\n```\n\nAs covered in [earlier guides](https://www.gradio.app/guides/building-mcp-server-with-gradio), you will now be able to test the tool using any MCP Client, such as the MCP Inspector tool. Test it and confirm that it behaves as you expect.\n\n4. Create a UI for your ChatGPT app and expose it as a resource. This part requires writing some frontend code and may be unfamiliar at first, but a few examples will help you create an app that works well for your use case. In our case, we'll create a card with HTML, Javascript, and CSS. Inside the card, we'll display the word presented by the user, highlighting each occurrence of the specified letter. Note that we access the user's tool input using `window.openai?.toolInput?.word` and `window.openai?.toolInput?.letter`. The `window.openai` object is automatically inserted by ChatGPT with the data from the user's tool call. This is what the complete function looks like:\n\n```py\n@gr.mcp.resource(\"ui://widget/app.html\", mime_type=\"text/html+skybridge\")\ndef app_html():\n    visual = \"\"\"\n    <div id=\"letter-card-container\"></div>\n    <script>\n        const container = document.getElementById('letter-card-container');\n\n        function render() {\n            const word = window.openai?.toolInput?.word || \"strawberry\";\n            const letter = window.openai?.toolInput?.letter || \"r\";\n\n            let letterHTML = '';\n            for (let i = 0; i < word.length; i++) {\n                const char = word[i];\n                const color = char.toLowerCase() === letter.toLowerCase() ? '#b8860b' : '#000000';\n                letterHTML += `<span style=\"color: ${color};\">${char}</span>`;\n            }\n\n            container.innerHTML = `\n                <div style=\"\n                    background: linear-gradient(135deg, #f5f5dc 0%, #e8e4d0 100%);\n                    background-image:\n                        repeating-linear-gradient(45deg, transparent, transparent 2px, rgba(139, 121, 94, 0.03) 2px, rgba(139, 121, 94, 0.03) 4px),\n                        linear-gradient(135deg, #f5f5dc 0%, #e8e4d0 100%);\n                    border-radius: 16px;\n                    padding: 40px;\n                    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1), 0 1px 3px rgba(0, 0, 0, 0.08);\n                    max-width: 600px;\n                    margin: 20px auto;\n                    font-family: 'Georgia', serif;\n                    text-align: center;\n                \">\n                    <div style=\"\n                        font-size: 48px;\n                        font-weight: bold;\n                        letter-spacing: 8px;\n                        line-height: 1.5;\n                    \">\n                        ${letterHTML}\n                    </div>\n                </div>\n            `;\n        }\n        render();\n        window.addEventListener(\"openai:set_globals\", (event) => {\n            if (event.detail?.globals?.toolInput) {\n                render();\n            }\n        }, { passive: true });\n    </script>\n    \"\"\"\n    return visual\n```\n\nNote that we've provided a URI for the `gr.mcp.resource` at `ui://widget/app.html`. This is arbitrary, but we'll need to use the same URI later on. We also need to specify the mimetype of the resource to be `mime_type=\"text/html+skybridge\"`. Finally, note that we attached an event listener in the JavaScript for \"openai:set_globals\", which is generally a good practice as it allows the widget to update whenever a new tool call is triggered. \n\n5. Create an event in your Gradio app corresponding to the resource function. This is necessary because your Gradio app only picks up MCP tools, resources, prompts, etc. if they are associated with a Gradio event. Typically, the convention is to simply display the code for your MCP resource in a `gr.Code` component, e.g. like this:\n\n```py\n    html = gr.Code(language=\"html\", max_lines=20)\n    \n    # ... the rest of your Gradio app\n\n    btn.click(app_html, outputs=html)\n```\n\n6. Add `_meta` attributes to your MCP tool. We need to connect the MCP tool that we created to the UI that we created for our app. We can do this by adding this decorator to our MCP tool function:\n\n```py\n@gr.mcp.tool(\n    _meta={\n        \"openai/outputTemplate\": \"ui://widget/app.html\",\n        \"openai/resultCanProduceWidget\": True,\n        \"openai/widgetAccessible\": True,\n    }\n)\n```\n\nThe key thing to observe is that the `\"openai/outputTemplate\"` must match the URI of the MCP resource that we created earlier.\n\n7. Relaunch your Gradio app with `share=True`. This will make it very easy to test within ChatGPT. Note the MCP server URL that is printed to your terminal, e.g. `https://2e879c6066d729b11b.gradio.live/gradio_api/mcp/`.\n\n```py\n    demo.launch(share=True, mcp_server=True)\n```\n\nThis will print a public URL that your Gradio app will be running on.\n\n8. Now, navigate to ChatGPT (https://chat.com/). As mentioned earlier, you need to enable \"developer mode\" in ChatGPT under Settings \u2192 Apps & Connectors \u2192 Advanced settings in ChatGPT. Then, navigate to Settings \u2192 Apps & Connectors and click the \"Create\" button. Give your connector a name, a description (optional), and paste in the MCP server URL that was printed to your terminal. Choose \"No authentication\" and create.\n\n![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/letter-counter-setup.png)\n\nAnd that's it! Once the Connector has been created, you can start prompting it by saying something like, \"Use @letter-counter to count the number of r's in Gradio.\"\n\n### Example 2: An Image Brightener\n\nNext, let's see a more complex ChatGPT app for image enhancement. The ChatGPT app includes a \"Brighten\" button that lets the user call the tool directly from the app UI.\n\n<video src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/mcp-image-app.mp4\" controls></video>\n\nHere's the complete code for this app:\n\n```python\nimport gradio as gr\nimport tempfile\nfrom PIL import Image\nimport numpy as np\n\n\n@gr.mcp.tool(\n    _meta={\n        \"openai/outputTemplate\": \"ui://widget/app.html\",\n        \"openai/resultCanProduceWidget\": True,\n        \"openai/widgetAccessible\": True,\n    }\n)\n\ndef power_law_image(input_path: str, gamma: float = 0.5) -> str:\n    \"\"\"\n    Applies a power-law (gamma) transformation to an image file and saves\n    the result to a temporary file.\n\n    Args:\n        input_path (str): Path to the input image.\n        gamma (float): Power-law exponent. <1 brightens, >1 darkens.\n\n    Returns:\n        str: Path to the saved temporary output image.\n    \"\"\"\n    img = Image.open(input_path).convert(\"RGB\")\n    arr = np.array(img, dtype=np.float32) / 255.0\n    arr = np.power(arr, gamma)\n    arr = np.clip(arr * 255, 0, 255).astype(np.uint8)\n    out_img = Image.fromarray(arr)\n\n    tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".png\")\n    out_img.save(tmp_file.name)\n    tmp_file.close()\n\n    return tmp_file.name\n\n\n@gr.mcp.resource(\"ui://widget/app.html\", mime_type=\"text/html+skybridge\")\ndef app_html():\n    visual = \"\"\"\n    <style>\n        #image-container {\n            position: relative;\n            display: inline-block;\n            max-width: 100%;\n        }\n        #image-display {\n            max-width: 100%;\n            height: auto;\n            display: block;\n            border-radius: 8px;\n        }\n        #brighten-btn {\n            position: absolute;\n            bottom: 16px;\n            right: 26px;\n            padding: 12px 24px;\n            background: #1a1a1a;\n            color: white;\n            border: none;\n            border-radius: 8px;\n            font-weight: 600;\n            cursor: pointer;\n            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);\n        }\n        #brighten-btn:hover {\n            background: #000000;\n        }\n    </style>\n    <div id=\"image-container\">\n        <img id=\"image-display\" alt=\"Processed image\" />\n        <button id=\"brighten-btn\">Brighten</button>\n    </div>\n    <script>\n        const imageEl = document.getElementById('image-display');\n        const btnEl = document.getElementById('brighten-btn');\n\n        function extractImageUrl(data) {\n            if (data?.text?.startsWith('Image URL: ')) {\n                return data.text.substring('Image URL: '.length).trim();\n            }\n            if (data?.content) {\n                for (const item of data.content) {\n                    if (item.type === 'text' && item.text?.startsWith('Image URL: ')) {\n                        return item.text.substring('Image URL: '.length).trim();\n                    }\n                }\n            }\n        }\n\n        function render() {\n            const url = extractImageUrl(window.openai?.toolOutput);\n            if (url) imageEl.src = url;\n        }\n\n        async function brightenImage() {\n            btnEl.disabled = true;\n            btnEl.textContent = 'Brightening...';\n            const result = await window.openai.callTool('power_law_image', {\n                input_path: imageEl.src\n            });\n            const newUrl = extractImageUrl(result);\n            if (newUrl) imageEl.src = newUrl;\n            btnEl.disabled = false;\n            btnEl.textContent = 'Brighten';\n        }\n\n        btnEl.addEventListener('click', brightenImage);\n        window.addEventListener(\"openai:set_globals\", (event) => {\n            if (event.detail?.globals?.toolOutput) render();\n        }, { passive: true });\n\n        render();\n    </script>\n    \"\"\"\n    return visual\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            original_image = gr.Image(label=\"Original Image\", type=\"filepath\")\n            btn = gr.Button(\"Brighten Image\")\n        with gr.Column():\n            output_image = gr.Image(label=\"Output Image\", type=\"filepath\")\n            html = gr.Code(language=\"html\", max_lines=20)\n\n    btn.click(power_law_image, inputs=original_image, outputs=original_image)\n    btn.click(app_html, outputs=html)\n\nif __name__ == \"__main__\":\n    demo.launch(mcp_server=True, share=True)\n\n```\n\nWe won't break down the code in as much detail since many of the pieces are the same. But note the following differences from the earlier example:\n\n* Calling tools from the widget: The app uses `window.openai.callTool()` to invoke the MCP tool directly from a button click, without requiring ChatGPT to call it:\n\n```javascript\nconst result = await window.openai.callTool('power_law_image', {\n    input_path: imageEl.src\n});\n```\n\n* Parsing tool call results: The result from `callTool()` contains a `content` array that needs to be parsed to extract data:\n\n```javascript\nfunction extractImageUrl(data) {\n    if (data?.content) {\n        for (const item of data.content) {\n            if (item.type === 'text' && item.text?.startsWith('Image URL: ')) {\n                return item.text.substring('Image URL: '.length).trim();\n            }\n        }\n    }\n}\n```\n\n* Updating UI based on tool results: After calling the tool, the app immediately updates the displayed image with the new result:\n\n```javascript\nconst newUrl = extractImageUrl(result);\nif (newUrl) imageEl.src = newUrl;\n```\n\nWith these examples, you've seen how to build both simple reactive widgets and more advanced interactive apps that can call tools directly from the UI. By combining Gradio's MCP server capabilities with the OpenAI Apps SDK, it's time to start create richer ChatGPT integrations that enhance the conversational experience with custom visualizations and user interactions!\n", "tags": [], "spaces": [], "url": "/guides/building-chatgpt-apps-with-gradio/", "contributor": null}}