# Discord LLMs Bot Configuration
#
# This file is a template for your bot configuration. To use it:
#   1. Download this file as config.yaml (see README for curl/PowerShell commands)
#   2. Edit config.yaml with your actual credentials
#   3. Run the bot: discord-llms
#
# SECURITY: Never commit config.yaml with real credentials to version control!
# Keep your bot token and API key secret.

# =============================================================================
# Discord Bot Settings
# =============================================================================
bot:
  # Bot display name (used for logging and identification)
  name: docs-helper

  # Discord bot token from https://discord.com/developers/applications
  # 1. Create an application at the Discord Developer Portal
  # 2. Go to "Bot" section and create a bot
  # 3. Copy the bot token and paste it here
  # IMPORTANT: Keep this secret! Never share or commit this token.
  token: YOUR_DISCORD_BOT_TOKEN_HERE

  # REQUIRED: Channel filtering (empty list = all channels)
  # If empty, bot responds to mentions in ALL channels
  # If specified, bot ONLY responds to mentions in these channels
  # To get a channel ID: Right-click channel in Discord > Copy Channel ID
  # (requires Developer Mode enabled in Discord Settings > App Settings > Advanced)
  channels: []

  # Example: Only respond in two specific channels
  # channels:
  #   - 1234567890123456789
  #   - 9876543210987654321

# =============================================================================
# Documentation Sources
# =============================================================================
# List of documentation sources the bot can search and reference.
# Each doc has a name, summary (describing its contents), and URL to llms.txt.
#
# Tips for writing good summaries:
# - Mention supported platforms if relevant (e.g., "Python 3.8+", "Windows/Mac/Linux")
# - List key topics covered (installation, API reference, troubleshooting, etc.)
# - Note any scope limitations (e.g., "Does not cover deployment")
# This helps the LLM select the right docs and ask relevant clarifying questions.
docs:
  - anthropic-sdk:
      summary: |
        The Anthropic SDK documentation. Covers installation, authentication,
        making API calls, streaming responses, tool use, and error handling
        for the official Python and TypeScript SDKs.
      url: https://raw.githubusercontent.com/anthropics/anthropic-sdk-python/main/llms.txt

  - claude-code:
      summary: |
        Claude Code CLI tool documentation. Covers installation, configuration,
        slash commands, hooks, MCP servers, IDE integrations, and building
        custom agents with the Claude Agent SDK.
      url: https://raw.githubusercontent.com/anthropics/claude-code/main/llms-full.txt

  - pydantic:
      summary: |
        Pydantic documentation for data validation using Python type hints.
        Covers models, fields, validators, serialization, settings management,
        and integration with other frameworks.
      url: https://raw.githubusercontent.com/pydantic/pydantic/main/llms.txt

# =============================================================================
# LLM Model Configuration
# =============================================================================
# The bot uses any OpenAI-compatible API to power its responses.
# Supported providers include OpenRouter, OpenAI, Anthropic, Azure OpenAI,
# local LLMs (ollama, LM Studio), Together AI, Groq, and many others.
model:
  # API endpoint URL (the bot calls {base_url}/chat/completions)
  #
  # Examples by provider:
  #   OpenRouter:   https://openrouter.ai/api/v1
  #   OpenAI:       https://api.openai.com/v1
  #   Azure OpenAI: https://YOUR_RESOURCE.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT
  #   Ollama:       http://localhost:11434/v1
  #   LM Studio:    http://localhost:1234/v1
  #   Together AI:  https://api.together.xyz/v1
  #   Groq:         https://api.groq.com/openai/v1
  base_url: https://openrouter.ai/api/v1

  # Model identifier (provider-specific model name)
  #
  # Examples by provider:
  #   OpenRouter:   anthropic/claude-sonnet-4
  #   OpenAI:       gpt-4-turbo
  #   Ollama:       llama3.2
  #   Together AI:  meta-llama/Llama-3-70b-chat-hf
  #   Groq:         llama-3.1-70b-versatile
  name: anthropic/claude-sonnet-4

  # API key for authentication
  # Get your API key from your provider's dashboard:
  #   OpenRouter:  https://openrouter.ai/settings/keys
  #   OpenAI:      https://platform.openai.com/api-keys
  #   Together AI: https://api.together.xyz/settings/api-keys
  #   Groq:        https://console.groq.com/keys
  # IMPORTANT: Keep this secret! Never share or commit this key.
  api_key: YOUR_API_KEY_HERE

  # ==========================================================================
  # Optional: Provider-specific parameters
  # ==========================================================================
  # Any additional parameters below are passed directly to the chat completions
  # API. Available options depend on your provider and model.
  #
  # Common parameters (most providers):
  #   temperature: 0.7        # Randomness (0-2)
  #   max_tokens: 4096        # Max response length
  #   top_p: 0.9              # Nucleus sampling (0-1)
  #   stop: ["\n\n"]          # Stop sequences
  #
  # Penalty parameters:
  #   frequency_penalty: 0.5  # Reduce repetition (-2 to 2)
  #   presence_penalty: 0.5   # Encourage new topics (-2 to 2)
  #   repetition_penalty: 1.1 # Alternative repetition control (0-2)
  #
  # Advanced sampling (not all providers):
  #   top_k: 40               # Top-k sampling (not OpenAI)
  #   min_p: 0.05             # Minimum probability threshold
  #   seed: 42                # Reproducibility
  #
  # OpenRouter-specific:
  #   transforms: ["middle-out"]  # Message transforms
  #   route: "fallback"           # Fallback routing
  #   provider:                   # Provider preferences
  #     order: ["Anthropic"]

# =============================================================================
# Conversation Logging (Optional)
# =============================================================================
# Log all LLM interactions to JSONL files for analytics and debugging.
# Each day creates a new file: logs/YYYY-MM-DD.jsonl
#
# Log entries include:
#   - event_type: "doc_selection" or "answer"
#   - Discord metadata: thread_id, user_id, username, guild_id, channel_id
#   - LLM details: model, request_messages, response, token_usage
#   - Performance: latency_ms
logging:
  # Enable conversation logging (default: false)
  enabled: false

  # Directory for log files (default: logs)
  # Created automatically if it doesn't exist
  directory: logs
