#!/usr/bin/python
# -*- coding: UTF-8 -*-
import sys
import os
sys.path.insert(0, "/Users/oscar/projects/Crawlo")
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡æ‹ŸçœŸå®æƒ…å†µæµ‹è¯•é‡è¯•ä¸­é—´ä»¶åŠŸèƒ½
"""

import sys
import os
import asyncio
from unittest.mock import Mock, patch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from crawlo.middleware.retry import RetryMiddleware
from crawlo.stats_collector import StatsCollector
from crawlo.settings.setting_manager import SettingManager


class MockRequest:
    def __init__(self, url="http://example.com", meta=None, priority=0):
        self.url = url
        self.meta = meta or {}
        self.priority = priority
        
    def __str__(self):
        return f"<Request {self.url}>"


class MockResponse:
    def __init__(self, status_code=200):
        self.status_code = status_code


class MockSpider:
    def __init__(self, name="test_spider"):
        self.name = name
        
    def __str__(self):
        return self.name


async def test_realistic_retry_scenario():
    """æ¨¡æ‹ŸçœŸå®åœºæ™¯çš„é‡è¯•æµ‹è¯•"""
    print("=== æ¨¡æ‹ŸçœŸå®åœºæ™¯çš„é‡è¯•æµ‹è¯• ===")
    
    # åˆ›å»ºè®¾ç½®ç®¡ç†å™¨ï¼Œä½¿ç”¨æ›´çœŸå®çš„é…ç½®
    settings = SettingManager()
    settings.set('RETRY_HTTP_CODES', [500, 502, 503, 504, 429])
    settings.set('IGNORE_HTTP_CODES', [404, 403])
    settings.set('MAX_RETRY_TIMES', 3)
    settings.set('RETRY_EXCEPTIONS', [])
    settings.set('RETRY_PRIORITY', -1)
    
    # åˆ›å»ºç»Ÿè®¡æ”¶é›†å™¨
    class MockCrawler:
        def __init__(self):
            self.settings = settings
    
    crawler = MockCrawler()
    stats = StatsCollector(crawler)
    crawler.stats = stats
    
    class MockCrawlerWithStats:
        def __init__(self):
            self.settings = settings
            self.stats = stats
    
    crawler_with_stats = MockCrawlerWithStats()
    
    # åˆ›å»ºé‡è¯•ä¸­é—´ä»¶
    middleware = RetryMiddleware.create_instance(crawler_with_stats)
    
    # åˆ›å»ºçˆ¬è™«å¯¹è±¡
    spider = MockSpider("realistic_test_spider")
    
    # æ¨¡æ‹Ÿä¸€ä¸ªçœŸå®çš„çˆ¬å–æµç¨‹
    print("  æ¨¡æ‹Ÿçˆ¬å–æµç¨‹...")
    
    # 1. ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ŒæœåŠ¡å™¨è¿”å›503é”™è¯¯
    request = MockRequest(url="http://api.example.com/data", priority=10)
    response = MockResponse(503)
    
    print(f"  ç¬¬ä¸€æ¬¡è¯·æ±‚: {request.url}, çŠ¶æ€ç : {response.status_code}")
    result = middleware.process_response(request, response, spider)
    
    # åº”è¯¥è¿”å›é‡è¯•çš„è¯·æ±‚
    assert result is not None
    assert result is request  # åŒä¸€ä¸ªå¯¹è±¡
    assert result.meta.get('retry_times', 0) == 1
    assert result.meta.get('dont_retry', False) is True
    assert result.priority == 9  # ä¼˜å…ˆçº§é™ä½
    print(f"    é‡è¯•ç¬¬1æ¬¡ï¼Œæ–°çš„ä¼˜å…ˆçº§: {result.priority}")
    
    # 2. å¯¹äºåŒä¸€ä¸ªè¯·æ±‚ï¼Œç”±äºå·²ç»è®¾ç½®äº†dont_retryæ ‡å¿—ï¼Œä¸ä¼šå†é‡è¯•
    # åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè¿™ä¸ªè¯·æ±‚ä¼šè¢«é‡æ–°è°ƒåº¦ï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿé‡æ–°åˆ›å»ºè¯·æ±‚çš„æƒ…å†µ
    print("  æ¨¡æ‹Ÿé‡æ–°è°ƒåº¦åçš„è¯·æ±‚...")
    new_request = MockRequest(url="http://api.example.com/data", priority=10)
    response = MockResponse(503)
    print(f"  é‡æ–°è°ƒåº¦åçš„è¯·æ±‚: {new_request.url}, çŠ¶æ€ç : {response.status_code}")
    result = middleware.process_response(new_request, response, spider)
    
    # åº”è¯¥è¿”å›é‡è¯•çš„è¯·æ±‚
    assert result is not None
    assert result is new_request  # åŒä¸€ä¸ªå¯¹è±¡
    assert result.meta.get('retry_times', 0) == 1
    assert result.meta.get('dont_retry', False) is True
    assert result.priority == 9  # ä¼˜å…ˆçº§é™ä½
    print(f"    é‡è¯•ç¬¬1æ¬¡ï¼Œæ–°çš„ä¼˜å…ˆçº§: {result.priority}")
    
    # 3. å†æ¬¡é‡æ–°è°ƒåº¦ï¼ŒæœåŠ¡å™¨è¿”å›æ­£å¸¸å“åº”
    final_request = MockRequest(url="http://api.example.com/data", priority=10)
    response = MockResponse(200)
    print(f"  æœ€ç»ˆè¯·æ±‚: {final_request.url}, çŠ¶æ€ç : {response.status_code}")
    result = middleware.process_response(final_request, response, spider)
    
    # åº”è¯¥è¿”å›æ­£å¸¸å“åº”
    assert result is response
    print("    è¯·æ±‚æˆåŠŸï¼Œè¿”å›æ­£å¸¸å“åº”")
    
    print("  âœ… çœŸå®åœºæ™¯é‡è¯•æµç¨‹æµ‹è¯•é€šè¿‡")


async def test_network_exception_scenario():
    """æ¨¡æ‹Ÿç½‘ç»œå¼‚å¸¸åœºæ™¯æµ‹è¯•"""
    print("\n=== æ¨¡æ‹Ÿç½‘ç»œå¼‚å¸¸åœºæ™¯æµ‹è¯• ===")
    
    # åˆ›å»ºè®¾ç½®ç®¡ç†å™¨
    settings = SettingManager()
    settings.set('RETRY_HTTP_CODES', [500, 502, 503, 504])
    settings.set('IGNORE_HTTP_CODES', [404])
    settings.set('MAX_RETRY_TIMES', 2)
    settings.set('RETRY_EXCEPTIONS', [])
    settings.set('RETRY_PRIORITY', -1)
    
    # åˆ›å»ºç»Ÿè®¡æ”¶é›†å™¨
    class MockCrawler:
        def __init__(self):
            self.settings = settings
    
    crawler = MockCrawler()
    stats = StatsCollector(crawler)
    crawler.stats = stats
    
    class MockCrawlerWithStats:
        def __init__(self):
            self.settings = settings
            self.stats = stats
    
    crawler_with_stats = MockCrawlerWithStats()
    
    # åˆ›å»ºé‡è¯•ä¸­é—´ä»¶
    middleware = RetryMiddleware.create_instance(crawler_with_stats)
    
    # åˆ›å»ºè¯·æ±‚å’Œçˆ¬è™«
    request = MockRequest(url="http://api.example.com/data")
    spider = MockSpider("network_test_spider")
    
    # æ¨¡æ‹Ÿç½‘ç»œè¶…æ—¶å¼‚å¸¸
    print("  æ¨¡æ‹Ÿç½‘ç»œè¶…æ—¶å¼‚å¸¸...")
    exc = asyncio.TimeoutError("Connection timeout")
    
    result = middleware.process_exception(request, exc, spider)
    
    # åº”è¯¥è¿”å›é‡è¯•çš„è¯·æ±‚
    assert result is not None
    assert result is request  # åŒä¸€ä¸ªå¯¹è±¡
    assert result.meta.get('retry_times', 0) == 1
    assert result.meta.get('dont_retry', False) is True
    print("    ç½‘ç»œè¶…æ—¶å¼‚å¸¸å¤„ç†æˆåŠŸ")
    
    # æ¨¡æ‹Ÿé‡æ–°è°ƒåº¦åçš„è¯·æ±‚å†æ¬¡é‡åˆ°ç½‘ç»œå¼‚å¸¸
    print("  é‡æ–°è°ƒåº¦åçš„è¯·æ±‚å†æ¬¡é‡åˆ°ç½‘ç»œå¼‚å¸¸...")
    new_request = MockRequest(url="http://api.example.com/data")
    exc = asyncio.TimeoutError("Connection timeout")
    
    result = middleware.process_exception(new_request, exc, spider)
    
    # åº”è¯¥è¿”å›é‡è¯•çš„è¯·æ±‚
    assert result is not None
    assert result is new_request  # åŒä¸€ä¸ªå¯¹è±¡
    assert result.meta.get('retry_times', 0) == 1  # æ–°è¯·æ±‚ï¼Œé‡è¯•æ¬¡æ•°é‡æ–°è®¡ç®—
    assert result.meta.get('dont_retry', False) is True
    print("    é‡æ–°è°ƒåº¦åçš„è¯·æ±‚ç½‘ç»œå¼‚å¸¸å¤„ç†æˆåŠŸ")
    
    print("  âœ… ç½‘ç»œå¼‚å¸¸åœºæ™¯æµ‹è¯•é€šè¿‡")


async def test_mixed_scenario():
    """æ··åˆåœºæ™¯æµ‹è¯•ï¼ˆå“åº”é”™è¯¯å’Œå¼‚å¸¸æ··åˆï¼‰"""
    print("\n=== æ··åˆåœºæ™¯æµ‹è¯• ===")
    
    # åˆ›å»ºè®¾ç½®ç®¡ç†å™¨
    settings = SettingManager()
    settings.set('RETRY_HTTP_CODES', [500, 502, 503, 504])
    settings.set('IGNORE_HTTP_CODES', [404])
    settings.set('MAX_RETRY_TIMES', 3)
    settings.set('RETRY_EXCEPTIONS', [])
    settings.set('RETRY_PRIORITY', -1)
    
    # åˆ›å»ºç»Ÿè®¡æ”¶é›†å™¨
    class MockCrawler:
        def __init__(self):
            self.settings = settings
    
    crawler = MockCrawler()
    stats = StatsCollector(crawler)
    crawler.stats = stats
    
    class MockCrawlerWithStats:
        def __init__(self):
            self.settings = settings
            self.stats = stats
    
    crawler_with_stats = MockCrawlerWithStats()
    
    # åˆ›å»ºé‡è¯•ä¸­é—´ä»¶
    middleware = RetryMiddleware.create_instance(crawler_with_stats)
    
    # åˆ›å»ºçˆ¬è™«
    spider = MockSpider("mixed_test_spider")
    
    # 1. é¦–å…ˆé‡åˆ°500é”™è¯¯ï¼ˆç¬¬ä¸€æ¬¡è¯·æ±‚ï¼‰
    print("  1. ç¬¬ä¸€æ¬¡è¯·æ±‚é‡åˆ°500é”™è¯¯")
    request1 = MockRequest(url="http://api.example.com/data", priority=5)
    response = MockResponse(500)
    result = middleware.process_response(request1, response, spider)
    assert result is not None
    assert result.meta.get('retry_times', 0) == 1
    assert result.priority == 4
    print("    500é”™è¯¯å¤„ç†æˆåŠŸ")
    
    # 2. ç„¶åé‡åˆ°ç½‘ç»œè¶…æ—¶å¼‚å¸¸ï¼ˆç¬¬äºŒæ¬¡è¯·æ±‚ï¼‰
    print("  2. ç¬¬äºŒæ¬¡è¯·æ±‚é‡åˆ°ç½‘ç»œè¶…æ—¶å¼‚å¸¸")
    request2 = MockRequest(url="http://api.example.com/data", priority=5)
    exc = asyncio.TimeoutError("Connection timeout")
    result = middleware.process_exception(request2, exc, spider)
    assert result is not None
    assert result.meta.get('retry_times', 0) == 1  # æ–°è¯·æ±‚ï¼Œé‡è¯•æ¬¡æ•°é‡æ–°è®¡ç®—
    assert result.priority == 4
    print("    ç½‘ç»œè¶…æ—¶å¼‚å¸¸å¤„ç†æˆåŠŸ")
    
    # 3. å†æ¬¡é‡åˆ°503é”™è¯¯ï¼ˆç¬¬ä¸‰æ¬¡è¯·æ±‚ï¼‰
    print("  3. ç¬¬ä¸‰æ¬¡è¯·æ±‚é‡åˆ°503é”™è¯¯")
    request3 = MockRequest(url="http://api.example.com/data", priority=5)
    response = MockResponse(503)
    result = middleware.process_response(request3, response, spider)
    assert result is not None
    assert result.meta.get('retry_times', 0) == 1  # æ–°è¯·æ±‚ï¼Œé‡è¯•æ¬¡æ•°é‡æ–°è®¡ç®—
    assert result.priority == 4
    print("    503é”™è¯¯å¤„ç†æˆåŠŸ")
    
    print("  âœ… æ··åˆåœºæ™¯æµ‹è¯•é€šè¿‡")


async def main():
    print("å¼€å§‹æ¨¡æ‹ŸçœŸå®æƒ…å†µæµ‹è¯•é‡è¯•ä¸­é—´ä»¶åŠŸèƒ½...")
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        await test_realistic_retry_scenario()
        await test_network_exception_scenario()
        await test_mixed_scenario()
        
        print("\nğŸ‰ æ‰€æœ‰çœŸå®æƒ…å†µæµ‹è¯•é€šè¿‡ï¼é‡è¯•ä¸­é—´ä»¶åœ¨å®é™…ä½¿ç”¨ä¸­åŠŸèƒ½æ­£å¸¸ã€‚")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())