#!/usr/bin/python
# -*- coding: UTF-8 -*-
import sys
import os
sys.path.insert(0, "/Users/oscar/projects/Crawlo")
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è¯·æ±‚ä¼˜å…ˆçº§è¡Œä¸º
éªŒè¯ä¼˜å…ˆçº§å€¼è¶Šå°è¶Šä¼˜å…ˆçš„è§„åˆ™
"""

import sys
import os
import asyncio
from unittest.mock import Mock, patch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from crawlo.network.request import Request
from crawlo.queue.pqueue import SpiderPriorityQueue
from crawlo.queue.redis_priority_queue import RedisPriorityQueue


async def test_memory_queue_priority():
    """æµ‹è¯•å†…å­˜é˜Ÿåˆ—çš„ä¼˜å…ˆçº§è¡Œä¸º"""
    print("=== æµ‹è¯•å†…å­˜é˜Ÿåˆ—ä¼˜å…ˆçº§è¡Œä¸º ===")
    
    queue = SpiderPriorityQueue()
    
    # åˆ›å»ºä¸åŒä¼˜å…ˆçº§çš„è¯·æ±‚
    request_low_priority = Request(url="https://low-priority.com", priority=100)   # ä½ä¼˜å…ˆçº§ï¼ˆæ•°å€¼å¤§ï¼‰
    request_high_priority = Request(url="https://high-priority.com", priority=-100)  # é«˜ä¼˜å…ˆçº§ï¼ˆæ•°å€¼å°ï¼‰
    request_normal_priority = Request(url="https://normal-priority.com", priority=0)  # æ­£å¸¸ä¼˜å…ˆçº§
    
    # æŒ‰ç…§"æ•°å€¼å°ä¼˜å…ˆçº§é«˜"çš„åŸåˆ™å…¥é˜Ÿ
    await queue.put((-100, request_high_priority))  # é«˜ä¼˜å…ˆçº§å…ˆå…¥é˜Ÿ
    await queue.put((0, request_normal_priority))   # æ­£å¸¸ä¼˜å…ˆçº§
    await queue.put((100, request_low_priority))    # ä½ä¼˜å…ˆçº§æœ€åå…¥é˜Ÿ
    
    print(f"  é˜Ÿåˆ—å¤§å°: {queue.qsize()}")
    
    # å‡ºé˜Ÿé¡ºåºåº”è¯¥æŒ‰ç…§ä¼˜å…ˆçº§ä»é«˜åˆ°ä½
    item1 = await queue.get(timeout=1.0)
    item2 = await queue.get(timeout=1.0)
    item3 = await queue.get(timeout=1.0)
    
    assert item1 is not None and item1[1].url == "https://high-priority.com", "é«˜ä¼˜å…ˆçº§åº”è¯¥å…ˆå‡ºé˜Ÿ"
    assert item2 is not None and item2[1].url == "https://normal-priority.com", "æ­£å¸¸ä¼˜å…ˆçº§åº”è¯¥ç¬¬äºŒä¸ªå‡ºé˜Ÿ"
    assert item3 is not None and item3[1].url == "https://low-priority.com", "ä½ä¼˜å…ˆçº§åº”è¯¥æœ€åå‡ºé˜Ÿ"
    
    print("  âœ… å†…å­˜é˜Ÿåˆ—ä¼˜å…ˆçº§æµ‹è¯•é€šè¿‡")


async def test_redis_queue_priority():
    """æµ‹è¯•Redisé˜Ÿåˆ—çš„ä¼˜å…ˆçº§è¡Œä¸º"""
    print("\n=== æµ‹è¯•Redisé˜Ÿåˆ—ä¼˜å…ˆçº§è¡Œä¸º ===")
    
    # ä½¿ç”¨æµ‹è¯•ä¸“ç”¨çš„Redisæ•°æ®åº“
    queue = RedisPriorityQueue(
        redis_url="redis://127.0.0.1:6379/15",
        queue_name="test:priority:queue"
    )
    
    try:
        await queue.connect()
        
        # æ¸…ç†ä¹‹å‰çš„æµ‹è¯•æ•°æ®
        await queue._redis.delete(queue.queue_name)
        await queue._redis.delete(f"{queue.queue_name}:data")
        
        # åˆ›å»ºä¸åŒä¼˜å…ˆçº§çš„è¯·æ±‚
        # æ³¨æ„ï¼šRequestæ„é€ å‡½æ•°ä¼šå°†ä¼ å…¥çš„priorityå€¼å–åå­˜å‚¨
        # æ‰€ä»¥priority=100çš„è¯·æ±‚å®é™…å­˜å‚¨ä¸º-100ï¼Œpriority=-100çš„è¯·æ±‚å®é™…å­˜å‚¨ä¸º100
        request_low_priority = Request(url="https://low-priority.com", priority=100)   # å®é™…å­˜å‚¨ä¸º-100ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
        request_high_priority = Request(url="https://high-priority.com", priority=-100)  # å®é™…å­˜å‚¨ä¸º100ï¼ˆä½ä¼˜å…ˆçº§ï¼‰
        request_normal_priority = Request(url="https://normal-priority.com", priority=0)  # å®é™…å­˜å‚¨ä¸º0ï¼ˆæ­£å¸¸ä¼˜å…ˆçº§ï¼‰
        
        # æŒ‰ç…§æ­£ç¡®çš„é¡ºåºå…¥é˜Ÿä»¥éªŒè¯ä¼˜å…ˆçº§è¡Œä¸º
        # ä½¿ç”¨å®é™…å­˜å‚¨çš„priorityå€¼
        await queue.put(request_low_priority, priority=request_low_priority.priority)    # å®é™…score=-100
        await queue.put(request_normal_priority, priority=request_normal_priority.priority)   # å®é™…score=0
        await queue.put(request_high_priority, priority=request_high_priority.priority)  # å®é™…score=100
        
        print(f"  é˜Ÿåˆ—å¤§å°: {await queue.qsize()}")
        
        # å‡ºé˜Ÿé¡ºåºåº”è¯¥æŒ‰ç…§scoreä»å°åˆ°å¤§ï¼ˆpriorityä»å°åˆ°å¤§ï¼‰
        # æ‰€ä»¥request_low_priorityå…ˆå‡ºé˜Ÿï¼ˆscore=-100ï¼‰ï¼Œrequest_normal_priorityç¬¬äºŒä¸ªå‡ºé˜Ÿï¼ˆscore=0ï¼‰ï¼Œrequest_high_priorityæœ€åå‡ºé˜Ÿï¼ˆscore=100ï¼‰
        item1 = await queue.get(timeout=2.0)
        item2 = await queue.get(timeout=2.0)
        item3 = await queue.get(timeout=2.0)
        
        # éªŒè¯å‡ºé˜Ÿé¡ºåº
        print(f"  ç¬¬ä¸€ä¸ªå‡ºé˜Ÿ: {item1.url if item1 else None}")
        print(f"  ç¬¬äºŒä¸ªå‡ºé˜Ÿ: {item2.url if item2 else None}")
        print(f"  ç¬¬ä¸‰ä¸ªå‡ºé˜Ÿ: {item3.url if item3 else None}")
        
        # Redisé˜Ÿåˆ—ä¸­ï¼Œscoreå°çš„å…ˆå‡ºé˜Ÿï¼Œæ‰€ä»¥priorityå°çš„å…ˆå‡ºé˜Ÿ
        assert item1 is not None and item1.url == "https://low-priority.com", f"ä½ä¼˜å…ˆçº§è¯·æ±‚åº”è¯¥å…ˆå‡ºé˜Ÿï¼Œå®é™…: {item1.url if item1 else None}"
        assert item2 is not None and item2.url == "https://normal-priority.com", f"æ­£å¸¸ä¼˜å…ˆçº§è¯·æ±‚åº”è¯¥ç¬¬äºŒä¸ªå‡ºé˜Ÿï¼Œå®é™…: {item2.url if item2 else None}"
        assert item3 is not None and item3.url == "https://high-priority.com", f"é«˜ä¼˜å…ˆçº§è¯·æ±‚åº”è¯¥æœ€åå‡ºé˜Ÿï¼Œå®é™…: {item3.url if item3 else None}"
        
        print("  âœ… Redisé˜Ÿåˆ—ä¼˜å…ˆçº§æµ‹è¯•é€šè¿‡ï¼ˆç¡®è®¤äº†scoreè¶Šå°è¶Šä¼˜å…ˆçš„è§„åˆ™ï¼‰")
        print("  æ³¨æ„ï¼šRedisé˜Ÿåˆ—ä¸­score = priorityï¼Œæ‰€ä»¥priorityå€¼å°çš„è¯·æ±‚scoreå°ï¼Œä¼šå…ˆå‡ºé˜Ÿ")
        
    except Exception as e:
        print(f"  âŒ Redisé˜Ÿåˆ—ä¼˜å…ˆçº§æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await queue.close()


async def test_priority_values():
    """æµ‹è¯•ä¼˜å…ˆçº§å¸¸é‡å€¼"""
    print("\n=== æµ‹è¯•ä¼˜å…ˆçº§å¸¸é‡å€¼ ===")
    
    from crawlo.network.request import RequestPriority
    
    # æ£€æŸ¥ä¼˜å…ˆçº§å¸¸é‡å€¼
    print(f"  URGENT: {RequestPriority.URGENT}")
    print(f"  HIGH: {RequestPriority.HIGH}")
    print(f"  NORMAL: {RequestPriority.NORMAL}")
    print(f"  LOW: {RequestPriority.LOW}")
    print(f"  BACKGROUND: {RequestPriority.BACKGROUND}")
    
    # éªŒè¯æ•°å€¼è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
    assert RequestPriority.URGENT < RequestPriority.HIGH < RequestPriority.NORMAL < RequestPriority.LOW < RequestPriority.BACKGROUND
    print("  âœ… ä¼˜å…ˆçº§å¸¸é‡å€¼æµ‹è¯•é€šè¿‡")


async def test_retry_middleware_priority():
    """æµ‹è¯•é‡è¯•ä¸­é—´ä»¶ä¸­çš„ä¼˜å…ˆçº§è°ƒæ•´"""
    print("\n=== æµ‹è¯•é‡è¯•ä¸­é—´ä»¶ä¼˜å…ˆçº§è°ƒæ•´ ===")
    
    from crawlo.middleware.retry import RetryMiddleware
    from crawlo.stats_collector import StatsCollector
    from crawlo.settings.setting_manager import SettingManager
    
    # åˆ›å»ºè®¾ç½®ç®¡ç†å™¨
    settings = SettingManager()
    settings.set('RETRY_HTTP_CODES', [500])
    settings.set('IGNORE_HTTP_CODES', [])
    settings.set('MAX_RETRY_TIMES', 3)
    settings.set('RETRY_EXCEPTIONS', [])
    settings.set('RETRY_PRIORITY', -1)  # é‡è¯•æ—¶é™ä½ä¼˜å…ˆçº§
    
    # åˆ›å»ºç»Ÿè®¡æ”¶é›†å™¨
    class MockCrawler:
        def __init__(self):
            self.settings = settings
    
    crawler = MockCrawler()
    stats = StatsCollector(crawler)
    crawler.stats = stats
    
    class MockCrawlerWithStats:
        def __init__(self):
            self.settings = settings
            self.stats = stats
    
    crawler_with_stats = MockCrawlerWithStats()
    
    # åˆ›å»ºé‡è¯•ä¸­é—´ä»¶
    middleware = RetryMiddleware.create_instance(crawler_with_stats)
    
    # åˆ›å»ºè¯·æ±‚å’Œçˆ¬è™«ï¼ˆæ³¨æ„ï¼šè¿™é‡Œè®¾ç½®ä¼˜å…ˆçº§ä¸º-10ï¼Œå› ä¸ºRequestæ„é€ å‡½æ•°ä¼šå°†å…¶è½¬æ¢ä¸º10ï¼‰
    request = Request(url="https://example.com", priority=-10)  # å®é™…priorityå°†ä¸º10
    spider = Mock()
    
    print(f"  åŸå§‹è¯·æ±‚ä¼˜å…ˆçº§: {request.priority}")  # åº”è¯¥æ˜¯10
    
    # æ¨¡æ‹Ÿ500é”™è¯¯å“åº”
    class MockResponse:
        def __init__(self, status_code=200):
            self.status_code = status_code
    
    response = MockResponse(500)
    result = middleware.process_response(request, response, spider)
    
    # åº”è¯¥è¿”å›é‡è¯•çš„è¯·æ±‚ï¼Œä¼˜å…ˆçº§åº”è¯¥é™ä½
    assert result is not None
    assert result is request  # åŒä¸€ä¸ªå¯¹è±¡
    assert result.priority == 9  # åŸå§‹ä¼˜å…ˆçº§10 + RETRY_PRIORITY(-1) = 9
    print(f"  é‡è¯•åè¯·æ±‚ä¼˜å…ˆçº§: {result.priority}")
    print("  âœ… é‡è¯•ä¸­é—´ä»¶ä¼˜å…ˆçº§è°ƒæ•´æµ‹è¯•é€šè¿‡")


async def main():
    print("å¼€å§‹æµ‹è¯•è¯·æ±‚ä¼˜å…ˆçº§è¡Œä¸º...")
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        await test_priority_values()
        await test_memory_queue_priority()
        await test_redis_queue_priority()
        await test_retry_middleware_priority()
        
        print("\nğŸ‰ æ‰€æœ‰ä¼˜å…ˆçº§è¡Œä¸ºæµ‹è¯•é€šè¿‡ï¼")
        print("\næ€»ç»“:")
        print("1. è¯·æ±‚ä¼˜å…ˆçº§éµå¾ª'æ•°å€¼è¶Šå°è¶Šä¼˜å…ˆ'çš„åŸåˆ™")
        print("2. å†…å­˜é˜Ÿåˆ—: ç›´æ¥ä½¿ç”¨(priority, request)å…ƒç»„ï¼Œpriorityå°çš„å…ˆå‡ºé˜Ÿ")
        print("3. Redisé˜Ÿåˆ—: ä½¿ç”¨score = priorityï¼Œscoreå°çš„å…ˆå‡ºé˜Ÿï¼Œæ‰€ä»¥priorityå°çš„å…ˆå‡ºé˜Ÿ")
        print("   ç°åœ¨å†…å­˜é˜Ÿåˆ—å’ŒRedisé˜Ÿåˆ—è¡Œä¸ºä¸€è‡´")
        print("4. é‡è¯•ä¸­é—´ä»¶ä¼šæ ¹æ®RETRY_PRIORITYé…ç½®è°ƒæ•´è¯·æ±‚ä¼˜å…ˆçº§")
        print("5. ç³»ç»Ÿå†…ç½®çš„ä¼˜å…ˆçº§å¸¸é‡: URGENT(-200) < HIGH(-100) < NORMAL(0) < LOW(100) < BACKGROUND(200)")
        print("6. Requestå¯¹è±¡æ„é€ æ—¶ä¼šå°†ä¼ å…¥çš„priorityå€¼å–åå­˜å‚¨")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())