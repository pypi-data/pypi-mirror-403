# -*- coding: UTF-8 -*-
"""
{{project_name}} 项目配置文件（最小版）
=============================
基于 Crawlo 框架的最小爬虫项目配置。
仅包含最基本和常用的配置项。
"""

# =================================== 基础配置 ===================================

# 项目基本信息
PROJECT_NAME = '{{project_name}}'

# 运行模式：standalone/distributed/auto
RUN_MODE = 'standalone'

# 并发配置
CONCURRENCY = 4
MAX_RUNNING_SPIDERS = 1
DOWNLOAD_DELAY = 1.0

# =================================== 核心组件配置 ===================================

# 下载器：AioHttpDownloader/HttpXDownloader/CurlCffiDownloader
DOWNLOADER = 'crawlo.downloader.aiohttp_downloader.AioHttpDownloader'

# 队列类型：memory/redis/auto
QUEUE_TYPE = 'memory'

# 去重过滤器：MemoryFilter/AioRedisFilter
FILTER_CLASS = 'crawlo.filters.memory_filter.MemoryFilter'

# 默认去重管道：MemoryDedupPipeline/RedisDedupPipeline
DEFAULT_DEDUP_PIPELINE = 'crawlo.pipelines.memory_dedup_pipeline.MemoryDedupPipeline'

# =================================== 爬虫配置 ===================================

# 爬虫模块配置
SPIDER_MODULES = ['{{project_name}}.spiders']

# 默认请求头
# DEFAULT_REQUEST_HEADERS = {}

# 允许的域名
# ALLOWED_DOMAINS = []

# 数据管道
# 如需添加自定义管道，请取消注释并添加
# PIPELINES = [
#     'crawlo.pipelines.mysql_pipeline.AsyncmyMySQLPipeline',  # MySQL 存储（使用asyncmy异步库）
#     # '{{project_name}}.pipelines.CustomPipeline',  # 用户自定义管道示例
# ]

# =================================== 系统配置 ===================================

# 扩展组件
# 如需添加自定义扩展，请取消注释并添加
# EXTENSIONS = [
#     # '{{project_name}}.extensions.CustomExtension',  # 用户自定义扩展示例
# ]

# 中间件
# 如需添加自定义中间件，请取消注释并添加
# MIDDLEWARES = {
#     # '{{project_name}}.middlewares.CustomMiddleware': 50,  # 用户自定义中间件示例
# }

# 日志配置
LOG_LEVEL = 'INFO'
LOG_FILE = 'logs/{{project_name}}.log'
LOG_ENCODING = 'utf-8'  # 明确指定日志文件编码
LOG_MAX_BYTES = 20 * 1024 * 1024  # 20MB，推荐值
LOG_BACKUP_COUNT = 10  # 10个备份文件，推荐值
# 如果不想要日志轮转，可以设置 LOG_MAX_BYTES = 0
# 当LOG_MAX_BYTES或LOG_BACKUP_COUNT为0时，日志轮转将被禁用，文件会持续增长


# =================================== 定时任务配置 ===================================

# 启用定时任务 - 默认关闭
SCHEDULER_ENABLED = False

# 定时任务配置
SCHEDULER_JOBS = [
    {
        'spider': '{{project_name}}.spiders.{{spider_name}}',  # 爬虫名称（对应spider的name属性）
        'cron': '*/2 * * * *',       # 每2分钟执行一次
        'enabled': True,              # 任务启用状态
        'priority': 10,               # 任务优先级
        'max_retries': 3,             # 最大重试次数
        'retry_delay': 60,            # 重试延迟（秒）
        'args': {},                  # 传递给爬虫的参数
        'kwargs': {}                  # 传递给爬虫的额外参数
    },
    {
        'spider': '{{project_name}}.spiders.{{spider_name}}',  # 爬虫名称
        'cron': '0 2 * * *',         # 每天凌晨2点执行
        'enabled': True,              # 任务启用状态
        'priority': 20,               # 任务优先级
        'max_retries': 2,             # 最大重试次数
        'retry_delay': 120,           # 重试延迟（秒）
        'args': {'daily': True},      # 传递给爬虫的参数
        'kwargs': {}                  # 传递给爬虫的额外参数
    }
]

# 关键配置参数（用户可能需要调整）
SCHEDULER_CHECK_INTERVAL = 1           # 调度器检查间隔（秒）
SCHEDULER_MAX_CONCURRENT = 3           # 最大并发任务数
SCHEDULER_JOB_TIMEOUT = 3600           # 单个任务超时时间（秒）
SCHEDULER_RESOURCE_MONITOR_ENABLED = True  # 是否启用资源监控
SCHEDULER_RESOURCE_CHECK_INTERVAL = 300    # 资源检查间隔（秒）
SCHEDULER_RESOURCE_LEAK_THRESHOLD = 3600   # 资源泄露检测阈值（秒）

# =================================== 数据库配置 ===================================

# MongoDB配置
# MONGO_URI = 'mongodb://localhost:27017'
# MONGO_DATABASE = '{{project_name}}_db'
# MONGO_COLLECTION = '{{project_name}}_items'
# MONGO_MAX_POOL_SIZE = 200
# MONGO_MIN_POOL_SIZE = 20
# MONGO_BATCH_SIZE = 100  # 批量插入条数
# MONGO_USE_BATCH = False  # 是否启用批量插入

# MySQL 冲突处理策略（三者互斥，按优先级生效）
MYSQL_UPDATE_COLUMNS = ()      # 优先级最高：主键冲突时更新指定列，使用 ON DUPLICATE KEY UPDATE
MYSQL_AUTO_UPDATE = False      # 优先级中等：是否使用 REPLACE INTO（完全覆盖已存在记录）
MYSQL_INSERT_IGNORE = False    # 优先级最低：是否使用 INSERT IGNORE（忽略重复数据）
MYSQL_PREFER_ALIAS_SYNTAX = True      # 是否优先使用 AS `alias` 语法，False 则使用 VALUES() 语法

# MongoDB配置
MONGO_URI = 'mongodb://localhost:27017'
MONGO_DATABASE = '{{project_name}}_db'
MONGO_COLLECTION = '{{project_name}}_items'
MONGO_BATCH_SIZE = 100  # 批量插入条数
MONGO_USE_BATCH = False  # 是否启用批量插入

# =================================== 定时任务配置 ===================================

# 启用定时任务 - 默认关闭
SCHEDULER_ENABLED = False

# 定时任务配置
SCHEDULER_JOBS = [
    {
        'spider': '{{project_name}}.spiders.{{spider_name}}',  # 爬虫名称（对应spider的name属性）
        'cron': '*/2 * * * *',       # 每2分钟执行一次
        'enabled': True,              # 任务启用状态
        'priority': 10,               # 任务优先级
        'max_retries': 3,             # 最大重试次数
        'retry_delay': 60,            # 重试延迟（秒）
        'args': {},                  # 传递给爬虫的参数
        'kwargs': {}                  # 传递给爬虫的额外参数
    },
    {
        'spider': '{{project_name}}.spiders.{{spider_name}}',  # 爬虫名称
        'cron': '0 2 * * *',         # 每天凌晨2点执行
        'enabled': True,              # 任务启用状态
        'priority': 20,               # 任务优先级
        'max_retries': 2,             # 最大重试次数
        'retry_delay': 120            # 重试延迟（秒）
    }
]

# 关键配置参数（用户可能需要调整）
SCHEDULER_CHECK_INTERVAL = 1           # 调度器检查间隔（秒）
SCHEDULER_MAX_CONCURRENT = 3           # 最大并发任务数
SCHEDULER_JOB_TIMEOUT = 3600           # 单个任务超时时间（秒）
SCHEDULER_RESOURCE_MONITOR_ENABLED = True  # 是否启用资源监控
SCHEDULER_RESOURCE_CHECK_INTERVAL = 300    # 资源检查间隔（秒）
SCHEDULER_RESOURCE_LEAK_THRESHOLD = 3600   # 资源泄露检测阈值（秒）

# =================================== 资源监控配置 ===================================

# 内存监控配置
MEMORY_MONITOR_ENABLED = False  # 是否启用内存监控
MEMORY_MONITOR_INTERVAL = 60  # 内存监控检查间隔（秒）
MEMORY_WARNING_THRESHOLD = 80.0  # 内存使用率警告阈值（百分比）
MEMORY_CRITICAL_THRESHOLD = 90.0  # 内存使用率严重阈值（百分比）

# MySQL监控配置
# MYSQL_MONITOR_ENABLED = False  # 是否启用MySQL监控
# MYSQL_MONITOR_INTERVAL = 120  # MySQL监控检查间隔（秒）

# Redis监控配置
# REDIS_MONITOR_ENABLED = False  # 是否启用Redis监控
# REDIS_MONITOR_INTERVAL = 120  # Redis监控检查间隔（秒）