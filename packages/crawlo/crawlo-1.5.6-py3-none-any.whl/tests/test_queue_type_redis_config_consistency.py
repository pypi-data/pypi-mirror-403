#!/usr/bin/python
# -*- coding: UTF-8 -*-
import sys
import os
sys.path.insert(0, "/Users/oscar/projects/Crawlo")
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• QUEUE_TYPE = 'redis' æ—¶çš„é…ç½®ä¸€è‡´æ€§
éªŒè¯å½“ QUEUE_TYPE æ˜ç¡®è®¾ç½®ä¸º 'redis' æ—¶ï¼Œè¿‡æ»¤å™¨å’Œç®¡é“é…ç½®æ˜¯å¦æ­£ç¡®æ›´æ–°
"""

import sys
import os
import asyncio

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from crawlo.config import CrawloConfig
from crawlo.crawler import CrawlerProcess
from crawlo.core.scheduler import Scheduler
from crawlo.queue.queue_manager import QueueType


def test_redis_config_consistency():
    """æµ‹è¯• QUEUE_TYPE = 'redis' æ—¶çš„é…ç½®ä¸€è‡´æ€§"""
    print("=== æµ‹è¯• QUEUE_TYPE = 'redis' æ—¶çš„é…ç½®ä¸€è‡´æ€§ ===")
    
    # åˆ›å»ºé…ç½®ï¼ŒQUEUE_TYPE è®¾ç½®ä¸º 'redis'ï¼Œä½†è¿‡æ»¤å™¨å’Œç®¡é“ä½¿ç”¨å†…å­˜ç‰ˆæœ¬
    config = {
        'PROJECT_NAME': 'test_redis_consistency',
        'QUEUE_TYPE': 'redis',
        'FILTER_CLASS': 'crawlo.filters.memory_filter.MemoryFilter',
        'DEFAULT_DEDUP_PIPELINE': 'crawlo.pipelines.memory_dedup_pipeline.MemoryDedupPipeline',
        'REDIS_URL': 'redis://127.0.0.1:6379/2',
        'CONCURRENCY': 1,
        'DOWNLOAD_DELAY': 0.1,
        'LOG_LEVEL': 'INFO'
    }
    
    # éªŒè¯åˆå§‹é…ç½®
    initial_filter = config['FILTER_CLASS']
    initial_pipeline = config['DEFAULT_DEDUP_PIPELINE']
    print(f"åˆå§‹è¿‡æ»¤å™¨é…ç½®: {initial_filter}")
    print(f"åˆå§‹ç®¡é“é…ç½®: {initial_pipeline}")
    
    # éªŒè¯åˆå§‹é…ç½®æ˜¯å†…å­˜ç‰ˆæœ¬
    assert 'memory_filter' in initial_filter, f"æœŸæœ›åˆå§‹è¿‡æ»¤å™¨ä¸ºå†…å­˜ç‰ˆæœ¬ï¼Œå®é™…å¾—åˆ° {initial_filter}"
    assert 'memory_dedup_pipeline' in initial_pipeline, f"æœŸæœ›åˆå§‹ç®¡é“ä¸ºå†…å­˜ç‰ˆæœ¬ï¼Œå®é™…å¾—åˆ° {initial_pipeline}"
    print("âœ… åˆå§‹é…ç½®æ­£ç¡®ï¼ˆå†…å­˜ç‰ˆæœ¬ï¼‰")
    
    print("âœ… é…ç½®ä¸€è‡´æ€§æµ‹è¯•å®Œæˆ")


async def test_scheduler_redis_config_update():
    """æµ‹è¯•è°ƒåº¦å™¨åœ¨ QUEUE_TYPE = 'redis' æ—¶çš„é…ç½®æ›´æ–°"""
    print("\n=== æµ‹è¯•è°ƒåº¦å™¨åœ¨ QUEUE_TYPE = 'redis' æ—¶çš„é…ç½®æ›´æ–° ===")
    
    # åˆ›å»ºé…ç½®ï¼ŒQUEUE_TYPE è®¾ç½®ä¸º 'redis'ï¼Œä½†è¿‡æ»¤å™¨å’Œç®¡é“ä½¿ç”¨å†…å­˜ç‰ˆæœ¬
    from crawlo.settings.setting_manager import SettingManager
    settings = SettingManager()
    settings.set('PROJECT_NAME', 'test_scheduler_redis_update')
    settings.set('QUEUE_TYPE', 'redis')
    settings.set('FILTER_CLASS', 'crawlo.filters.memory_filter.MemoryFilter')
    settings.set('DEFAULT_DEDUP_PIPELINE', 'crawlo.pipelines.memory_dedup_pipeline.MemoryDedupPipeline')
    settings.set('REDIS_URL', 'redis://127.0.0.1:6379/2')
    settings.set('CONCURRENCY', 1)
    settings.set('DOWNLOAD_DELAY', 0.1)
    settings.set('LOG_LEVEL', 'INFO')
    
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„çˆ¬è™«å¯¹è±¡
    class MockCrawler:
        def __init__(self, settings):
            self.settings = settings
            self.stats = None
            self.spider = None
    
    crawler = MockCrawler(settings)
    
    # åˆ›å»ºè°ƒåº¦å™¨å®ä¾‹
    scheduler = Scheduler.create_instance(crawler)
    
    # éªŒè¯åˆå§‹é…ç½®
    initial_filter = crawler.settings.get('FILTER_CLASS')
    initial_pipeline = crawler.settings.get('DEFAULT_DEDUP_PIPELINE')
    print(f"è°ƒåº¦å™¨åˆ›å»ºå‰çš„è¿‡æ»¤å™¨é…ç½®: {initial_filter}")
    print(f"è°ƒåº¦å™¨åˆ›å»ºå‰çš„ç®¡é“é…ç½®: {initial_pipeline}")
    
    # åˆå§‹åŒ–è°ƒåº¦å™¨
    print("æ­£åœ¨åˆå§‹åŒ–è°ƒåº¦å™¨...")
    await scheduler.open()
    
    # æ£€æŸ¥é…ç½®æ˜¯å¦å·²æ›´æ–°
    updated_filter = crawler.settings.get('FILTER_CLASS')
    updated_pipeline = crawler.settings.get('DEFAULT_DEDUP_PIPELINE')
    print(f"è°ƒåº¦å™¨åˆå§‹åŒ–åçš„è¿‡æ»¤å™¨é…ç½®: {updated_filter}")
    print(f"è°ƒåº¦å™¨åˆå§‹åŒ–åçš„ç®¡é“é…ç½®: {updated_pipeline}")
    
    # è·å–é˜Ÿåˆ—çŠ¶æ€
    queue_status = scheduler.queue_manager.get_status()
    print(f"é˜Ÿåˆ—ç±»å‹: {queue_status['type']}")
    print(f"é˜Ÿåˆ—å¥åº·çŠ¶æ€: {queue_status['health']}")
    
    # éªŒè¯é…ç½®å·²æ›´æ–°ä¸º Redis ç‰ˆæœ¬
    assert 'aioredis_filter' in updated_filter or 'redis_filter' in updated_filter, \
        f"æœŸæœ›æ›´æ–°åçš„è¿‡æ»¤å™¨ä¸º Redis ç‰ˆæœ¬ï¼Œå®é™…å¾—åˆ° {updated_filter}"
    assert 'redis_dedup_pipeline' in updated_pipeline, \
        f"æœŸæœ›æ›´æ–°åçš„ç®¡é“ä¸º Redis ç‰ˆæœ¬ï¼Œå®é™…å¾—åˆ° {updated_pipeline}"
    print("âœ… é…ç½®å·²æ­£ç¡®æ›´æ–°ä¸º Redis ç‰ˆæœ¬")
    
    # éªŒè¯é˜Ÿåˆ—ç±»å‹ä¸º Redis
    assert queue_status['type'] == 'redis', f"æœŸæœ›é˜Ÿåˆ—ç±»å‹ä¸º 'redis'ï¼Œå®é™…å¾—åˆ° '{queue_status['type']}'"
    print("âœ… é˜Ÿåˆ—ç±»å‹æ­£ç¡®")
    
    # æ¸…ç†èµ„æº
    await scheduler.close()
    
    print("âœ… è°ƒåº¦å™¨é…ç½®æ›´æ–°æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯• QUEUE_TYPE = 'redis' æ—¶çš„é…ç½®ä¸€è‡´æ€§...")
    
    try:
        # è¿è¡Œé…ç½®ä¸€è‡´æ€§æµ‹è¯•
        test_redis_config_consistency()
        
        # è¿è¡Œè°ƒåº¦å™¨é…ç½®æ›´æ–°æµ‹è¯•
        asyncio.run(test_scheduler_redis_config_update())
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼QUEUE_TYPE = 'redis' æ—¶çš„é…ç½®ä¸€è‡´æ€§å·²æ­£ç¡®å®ç°ã€‚")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()