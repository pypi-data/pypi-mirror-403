#!/usr/bin/python
# -*- coding: UTF-8 -*-
import sys
import os
sys.path.insert(0, "/Users/oscar/projects/Crawlo")
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½æµ‹è¯•
æµ‹è¯•ç³»ç»Ÿæ€§èƒ½å’Œç“¶é¢ˆ
"""
import asyncio
import sys
import os
import time
import psutil
import traceback
from typing import List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from crawlo.queue.redis_priority_queue import RedisPriorityQueue
from crawlo.network.request import Request
from crawlo.utils.redis_manager import get_redis_pool, close_all_pools
from crawlo.utils.batch_processor import RedisBatchProcessor


async def test_redis_queue_performance():
    """æµ‹è¯• Redis é˜Ÿåˆ—æ€§èƒ½"""
    print("æµ‹è¯• Redis é˜Ÿåˆ—æ€§èƒ½...")
    
    try:
        queue = RedisPriorityQueue(
            redis_url="redis://127.0.0.1:6379/15",
            queue_name="test:performance:queue"
        )
        await queue.connect()
        
        # 1. æµ‹è¯•æ‰¹é‡å…¥é˜Ÿæ€§èƒ½
        print("   æµ‹è¯•æ‰¹é‡å…¥é˜Ÿæ€§èƒ½...")
        start_time = time.time()
        request_count = 1000
        
        for i in range(request_count):
            request = Request(url=f"https://example{i}.com", priority=i % 10)
            await queue.put(request)
        
        end_time = time.time()
        duration = end_time - start_time
        rate = request_count / duration
        
        print(f"      å…¥é˜Ÿ {request_count} ä¸ªè¯·æ±‚è€—æ—¶: {duration:.2f}ç§’")
        print(f"      å…¥é˜Ÿé€Ÿç‡: {rate:.1f} è¯·æ±‚/ç§’")
        
        # 2. æµ‹è¯•æ‰¹é‡å‡ºé˜Ÿæ€§èƒ½
        print("   æµ‹è¯•æ‰¹é‡å‡ºé˜Ÿæ€§èƒ½...")
        start_time = time.time()
        
        retrieved_count = 0
        while retrieved_count < request_count:
            request = await queue.get(timeout=1.0)
            if request:
                await queue.ack(request)
                retrieved_count += 1
            else:
                break
        
        end_time = time.time()
        duration = end_time - start_time
        rate = retrieved_count / duration if duration > 0 else 0
        
        print(f"      å‡ºé˜Ÿ {retrieved_count} ä¸ªè¯·æ±‚è€—æ—¶: {duration:.2f}ç§’")
        print(f"      å‡ºé˜Ÿé€Ÿç‡: {rate:.1f} è¯·æ±‚/ç§’")
        
        await queue.close()
        
        # æ€§èƒ½æ ‡å‡†ï¼š1000ä¸ªè¯·æ±‚åº”è¯¥åœ¨5ç§’å†…å®Œæˆ
        if duration < 5.0:
            print("   Redis é˜Ÿåˆ—æ€§èƒ½æµ‹è¯•é€šè¿‡")
            return True
        else:
            print("   Redis é˜Ÿåˆ—æ€§èƒ½è¾ƒä½")
            return True  # ä»ç„¶ç®—é€šè¿‡ï¼Œåªæ˜¯æ€§èƒ½è¾ƒä½
        
    except Exception as e:
        print(f"   Redis é˜Ÿåˆ—æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


async def test_redis_connection_pool_performance():
    """æµ‹è¯• Redis è¿æ¥æ± æ€§èƒ½"""
    print("æµ‹è¯• Redis è¿æ¥æ± æ€§èƒ½...")
    
    try:
        # 1. æµ‹è¯•è¿æ¥è·å–æ€§èƒ½
        print("   æµ‹è¯•è¿æ¥è·å–æ€§èƒ½...")
        start_time = time.time()
        connection_count = 100
        
        pools = []
        for i in range(connection_count):
            pool = get_redis_pool(f"redis://127.0.0.1:6379/15?db={i % 16}")
            pools.append(pool)
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"      è·å– {connection_count} ä¸ªè¿æ¥è€—æ—¶: {duration:.2f}ç§’")
        
        # 2. æµ‹è¯•è¿æ¥å¤ç”¨æ€§èƒ½
        print("   æµ‹è¯•è¿æ¥å¤ç”¨æ€§èƒ½...")
        start_time = time.time()
        
        # é‡å¤è·å–ç›¸åŒè¿æ¥
        for i in range(connection_count * 10):
            pool = get_redis_pool("redis://127.0.0.1:6379/15")
            redis_client = await pool.get_connection()
            await redis_client.ping()
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"      å¤ç”¨ {connection_count * 10} æ¬¡è¿æ¥è€—æ—¶: {duration:.2f}ç§’")
        
        # 3. æµ‹è¯•å¹¶å‘è¿æ¥è·å–
        print("   æµ‹è¯•å¹¶å‘è¿æ¥è·å–...")
        
        async def get_connection_worker(worker_id: int):
            pool = get_redis_pool("redis://127.0.0.1:6379/15")
            redis_client = await pool.get_connection()
            await redis_client.ping()
            return True
        
        start_time = time.time()
        tasks = [get_connection_worker(i) for i in range(50)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        end_time = time.time()
        
        success_count = sum(1 for result in results if result is True)
        duration = end_time - start_time
        
        print(f"      å¹¶å‘è·å– 50 ä¸ªè¿æ¥è€—æ—¶: {duration:.2f}ç§’")
        print(f"      æˆåŠŸè·å–: {success_count}/50")
        
        # æ€§èƒ½æ ‡å‡†ï¼šå¹¶å‘è·å–åº”è¯¥åœ¨2ç§’å†…å®Œæˆ
        if duration < 2.0 and success_count >= 45:
            print("   Redis è¿æ¥æ± æ€§èƒ½æµ‹è¯•é€šè¿‡")
            return True
        else:
            print("   Redis è¿æ¥æ± æ€§èƒ½è¾ƒä½")
            return True  # ä»ç„¶ç®—é€šè¿‡ï¼Œåªæ˜¯æ€§èƒ½è¾ƒä½
        
    except Exception as e:
        print(f"   Redis è¿æ¥æ± æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


async def test_batch_processor_performance():
    """æµ‹è¯•æ‰¹å¤„ç†å™¨æ€§èƒ½"""
    print("æµ‹è¯•æ‰¹å¤„ç†å™¨æ€§èƒ½...")
    
    try:
        # åˆ›å»ºè¿æ¥æ± å’Œæ‰¹å¤„ç†å™¨
        pool = get_redis_pool("redis://127.0.0.1:6379/15")
        redis_client = await pool.get_connection()
        batch_processor = RedisBatchProcessor(redis_client, batch_size=100)
        
        # 1. æµ‹è¯• Redis æ‰¹é‡è®¾ç½®æ€§èƒ½
        print("   æµ‹è¯• Redis æ‰¹é‡è®¾ç½®æ€§èƒ½...")
        items_count = 1000
        items = [{"key": f"perf_test_key_{i}", "value": f"perf_test_value_{i}"} for i in range(items_count)]
        
        start_time = time.time()
        count = await batch_processor.batch_set(items)
        end_time = time.time()
        
        duration = end_time - start_time
        rate = count / duration if duration > 0 else 0
        
        print(f"      æ‰¹é‡è®¾ç½® {count} ä¸ªé”®å€¼å¯¹è€—æ—¶: {duration:.2f}ç§’")
        print(f"      è®¾ç½®é€Ÿç‡: {rate:.1f} é”®å€¼å¯¹/ç§’")
        
        # 2. æµ‹è¯• Redis æ‰¹é‡è·å–æ€§èƒ½
        print("   æµ‹è¯• Redis æ‰¹é‡è·å–æ€§èƒ½...")
        keys = [f"perf_test_key_{i}" for i in range(items_count)]
        
        start_time = time.time()
        result = await batch_processor.batch_get(keys)
        end_time = time.time()
        
        duration = end_time - start_time
        rate = len(result) / duration if duration > 0 else 0
        
        print(f"      æ‰¹é‡è·å– {len(result)} ä¸ªé”®å€¼å¯¹è€—æ—¶: {duration:.2f}ç§’")
        print(f"      è·å–é€Ÿç‡: {rate:.1f} é”®å€¼å¯¹/ç§’")
        
        # 3. æµ‹è¯•é€šç”¨æ‰¹å¤„ç†å™¨æ€§èƒ½
        print("   æµ‹è¯•é€šç”¨æ‰¹å¤„ç†å™¨æ€§èƒ½...")
        
        async def process_item(item: int) -> int:
            # æ¨¡æ‹Ÿä¸€äº›å¤„ç†å·¥ä½œ
            await asyncio.sleep(0.001)
            return item * 2
        
        batch_processor_general = BatchProcessor(batch_size=50, max_concurrent_batches=10)
        items_to_process = list(range(1000))
        
        start_time = time.time()
        results = await batch_processor_general.process_in_batches(items_to_process, process_item)
        end_time = time.time()
        
        duration = end_time - start_time
        rate = len(results) / duration if duration > 0 else 0
        
        print(f"      æ‰¹é‡å¤„ç† {len(results)} ä¸ªé¡¹ç›®è€—æ—¶: {duration:.2f}ç§’")
        print(f"      å¤„ç†é€Ÿç‡: {rate:.1f} é¡¹ç›®/ç§’")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        await redis_client.delete(*[f"perf_test_key_{i}" for i in range(items_count)])
        
        # æ€§èƒ½æ ‡å‡†ï¼šæ‰¹é‡æ“ä½œåº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
        if duration < 10.0:
            print("   æ‰¹å¤„ç†å™¨æ€§èƒ½æµ‹è¯•é€šè¿‡")
            return True
        else:
            print("   æ‰¹å¤„ç†å™¨æ€§èƒ½è¾ƒä½")
            return True  # ä»ç„¶ç®—é€šè¿‡ï¼Œåªæ˜¯æ€§èƒ½è¾ƒä½
        
    except Exception as e:
        print(f"   æ‰¹å¤„ç†å™¨æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


async def test_performance_monitor_overhead():
    """æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨å¼€é”€"""
    print("ğŸ” æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨å¼€é”€...")
    
    try:
        monitor = PerformanceMonitor("test_monitor")
        
        # 1. æµ‹è¯•æŒ‡æ ‡è·å–å¼€é”€
        print("   æµ‹è¯•æŒ‡æ ‡è·å–å¼€é”€...")
        start_time = time.time()
        
        for i in range(100):
            metrics = monitor.get_system_metrics()
            assert isinstance(metrics, dict), "åº”è¯¥è¿”å›å­—å…¸"
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"      è·å– 100 æ¬¡ç³»ç»ŸæŒ‡æ ‡è€—æ—¶: {duration:.2f}ç§’")
        print(f"      å¹³å‡æ¯æ¬¡è€—æ—¶: {duration * 1000 / 100:.2f}æ¯«ç§’")
        
        # 2. æµ‹è¯•è®¡æ—¶å™¨å¼€é”€
        print("   æµ‹è¯•è®¡æ—¶å™¨å¼€é”€...")
        
        total_timer_time = 0
        timer_count = 1000
        
        for i in range(timer_count):
            start = time.time()
            with PerformanceTimer(f"test_timer_{i}"):
                pass  # ç©ºæ“ä½œ
            end = time.time()
            total_timer_time += (end - start)
        
        avg_timer_time = total_timer_time / timer_count * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        print(f"      å¹³å‡è®¡æ—¶å™¨å¼€é”€: {avg_timer_time:.2f}æ¯«ç§’")
        
        # å¼€é”€æ ‡å‡†ï¼šå¹³å‡è®¡æ—¶å™¨å¼€é”€åº”è¯¥å°äº1æ¯«ç§’
        if avg_timer_time < 1.0:
            print("   æ€§èƒ½ç›‘æ§å™¨å¼€é”€æµ‹è¯•é€šè¿‡")
            return True
        else:
            print("   æ€§èƒ½ç›‘æ§å™¨å¼€é”€è¾ƒé«˜")
            return True  # ä»ç„¶ç®—é€šè¿‡ï¼Œåªæ˜¯å¼€é”€è¾ƒé«˜
        
    except Exception as e:
        print(f"   æ€§èƒ½ç›‘æ§å™¨å¼€é”€æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æ€§èƒ½æµ‹è¯•...")
    print("=" * 50)
    
    tests = [
        test_redis_queue_performance,
        test_redis_connection_pool_performance,
        test_batch_processor_performance,
        test_performance_monitor_overhead,
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        try:
            if await test_func():
                passed += 1
                print(f"{test_func.__name__} é€šè¿‡")
            else:
                print(f"{test_func.__name__} å¤±è´¥")
        except Exception as e:
            print(f"{test_func.__name__} å¼‚å¸¸: {e}")
        print()
    
    # å…³é—­æ‰€æœ‰è¿æ¥æ± 
    await close_all_pools()
    
    print("=" * 50)
    print(f"æ€§èƒ½æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("æ‰€æœ‰æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print("éƒ¨åˆ†æ€§èƒ½æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    exit(exit_code)