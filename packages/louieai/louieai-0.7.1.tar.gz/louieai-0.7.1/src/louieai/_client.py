"""Enhanced Louie client that matches the documented API."""

from __future__ import annotations

import json
import logging
import time
from collections.abc import Mapping
from dataclasses import dataclass
from typing import Any, cast

import httpx
import pandas as pd
import pyarrow as pa

from ._table_ai import (
    TableAIOverrides,
    collect_table_ai_kwargs,
    normalize_table_ai_overrides,
)
from ._tracing import get_traceparent
from .auth import AuthManager, auto_retry_auth

logger = logging.getLogger(__name__)


@dataclass
class Thread:
    """Represents a Louie conversation thread."""

    id: str
    name: str | None = None
    folder: str | None = None


class Response:
    """Response containing thread_id and multiple elements from a query."""

    def __init__(self, thread_id: str, elements: list[dict[str, Any]]):
        """Initialize response with thread ID and elements.

        Args:
            thread_id: The thread ID this response belongs to
            elements: List of element dictionaries from the response
        """
        self.thread_id = thread_id
        self.elements = elements

    @property
    def text_elements(self) -> list[dict[str, Any]]:
        """Get all text elements from the response."""
        return [e for e in self.elements if e.get("type") in ["TextElement", "text"]]

    @property
    def dataframe_elements(self) -> list[dict[str, Any]]:
        """Get all dataframe elements from the response."""
        return [e for e in self.elements if e.get("type") in ["DfElement", "df"]]

    @property
    def graph_elements(self) -> list[dict[str, Any]]:
        """Get all graph elements from the response."""
        return [e for e in self.elements if e.get("type") in ["GraphElement", "graph"]]

    @property
    def has_dataframes(self) -> bool:
        """Check if response contains any dataframe elements."""
        return len(self.dataframe_elements) > 0

    @property
    def has_graphs(self) -> bool:
        """Check if response contains any graph elements."""
        return len(self.graph_elements) > 0

    @property
    def has_errors(self) -> bool:
        """Check if response contains any error elements."""
        return any(
            e.get("type") in ["ExceptionElement", "exception", "error"]
            for e in self.elements
        )

    @property
    def text(self) -> str | None:
        """Get the primary text response.

        Returns the text from the first text element, or None if no text elements.
        """
        text_elems = self.text_elements
        if not text_elems:
            return None
        first_elem = text_elems[0]
        content = (
            first_elem.get("content")
            or first_elem.get("text")
            or first_elem.get("value", "")
        )
        return str(content) if content else ""

    @property
    def df(self) -> Any | None:
        """Get the first DataFrame from the response."""
        df_elems = self.dataframe_elements
        if not df_elems:
            return None
        first_df = df_elems[0]
        return first_df.get("table")

    @property
    def dfs(self) -> list[Any]:
        """Get all DataFrames from the response."""
        dfs = []
        for elem in self.dataframe_elements:
            if "table" in elem:
                dfs.append(elem["table"])
        return dfs


class LouieClient:
    """
    Enhanced client for Louie.ai that matches the documented API.

    This client provides thread-based conversations with natural language queries.

    Authentication can be handled in multiple ways:
    1. Pass an existing Graphistry client
    2. Pass credentials directly
    3. Use existing graphistry.register() authentication
    4. Provide a bearer token (Graphistry or anonymous)
    """

    def __init__(
        self,
        server_url: str = "https://den.louie.ai",
        graphistry_client: Any | None = None,
        username: str | None = None,
        password: str | None = None,
        api_key: str | None = None,
        personal_key_id: str | None = None,
        personal_key_secret: str | None = None,
        org_name: str | None = None,
        api: int = 3,
        server: str | None = None,
        anonymous: bool = False,
        anonymous_token: str | None = None,
        anonymous_timeout: float = 20.0,
        timeout: float = 300.0,  # 5 minutes default for agentic flows
        streaming_timeout: float = 120.0,  # 2 minutes for streaming chunks
        token: str | None = None,
        graphistry_server: str | None = None,
    ):
        """Initialize the Louie client.

        Args:
            server_url: Base URL for the Louie.ai service (default: den)
            graphistry_client: Existing Graphistry client to use for auth
            username: Username for direct authentication
            password: Password for direct authentication
            api_key: API key for direct authentication (legacy)
            personal_key_id: Personal key ID for service account authentication
            personal_key_secret: Personal key secret for service account authentication
            org_name: Organization name - use username for personal orgs (optional)
            api: API version (default: 3)
            anonymous: Use anonymous auth via /auth/anonymous (local desktop only)
            anonymous_timeout: Timeout for /auth/anonymous in seconds
            timeout: Overall timeout in seconds for requests (default: 300s/5min)
            streaming_timeout: Timeout for streaming chunks (default: 120s/2min)
            token: Optional pre-fetched bearer token (anonymous or Graphistry)
            graphistry_server: Graphistry server URL for direct authentication

        Examples:
            # Use existing graphistry authentication
            client = LouieClient()

            # Pass username/password credentials
            client = LouieClient(
                username="user",
                password="pass",
                graphistry_server="hub.graphistry.com"
            )

            # Use personal key authentication (recommended for service accounts)
            client = LouieClient(
                personal_key_id="ZD5872XKNF",
                personal_key_secret="SA0JJ2DTVT6LLO2S",
                graphistry_server="hub.graphistry.com"
            )

            # Specify organization
            client = LouieClient(
                username="user",
                password="pass",
                org_name="my-org",
                graphistry_server="hub.graphistry.com"
            )

            # Use existing graphistry client
            g = graphistry.nodes(df)
            client = LouieClient(graphistry_client=g)

            # Anonymous auth for local desktop (if enabled)
            client = LouieClient(
                server_url="http://localhost:8513",
                anonymous=True
            )

            # Direct bearer token (no refresh)
            client = LouieClient(
                server_url="https://den.louie.ai",
                token="<token>"
            )
        """
        self.server_url = server_url.rstrip("/")
        self._timeout = timeout
        self._streaming_timeout = streaming_timeout
        self._client = httpx.Client(timeout=timeout)

        if server is not None:
            raise ValueError(
                "server is no longer supported; use graphistry_server instead."
            )
        if anonymous_token is not None:
            raise ValueError(
                "anonymous_token is no longer supported; "
                "use token (with anonymous=True) instead."
            )

        if anonymous and any(
            [
                graphistry_client is not None,
                username,
                password,
                api_key,
                personal_key_id,
                personal_key_secret,
                graphistry_server,
            ]
        ):
            raise ValueError(
                "Anonymous auth cannot be combined with Graphistry credentials."
            )
        if (
            token is not None
            and not anonymous
            and any(
                [
                    graphistry_client is not None,
                    username,
                    password,
                    api_key,
                    personal_key_id,
                    personal_key_secret,
                    graphistry_server,
                ]
            )
        ):
            raise ValueError(
                "Token auth cannot be combined with Graphistry credentials."
            )

        # Set up authentication
        self._auth_manager = AuthManager(
            graphistry_client=graphistry_client,
            username=username,
            password=password,
            api_key=api_key,
            personal_key_id=personal_key_id,
            personal_key_secret=personal_key_secret,
            org_name=org_name,
            api=api,
            graphistry_server=graphistry_server,
            token=token,
            anonymous=anonymous,
            anonymous_timeout=anonymous_timeout,
            anonymous_server_url=self.server_url,
        )

        # If credentials provided, authenticate immediately
        if any([username, password, api_key, personal_key_id, personal_key_secret]):
            # Build kwargs for register, excluding None values
            register_kwargs: dict[str, Any] = {}
            if personal_key_id is not None and personal_key_secret is not None:
                # Use personal key authentication
                register_kwargs["personal_key_id"] = personal_key_id
                register_kwargs["personal_key_secret"] = personal_key_secret
            elif api_key is not None:
                # Use API key authentication
                register_kwargs["key"] = api_key  # graphistry uses 'key' parameter
            elif username is not None and password is not None:
                # Use username/password authentication
                register_kwargs["username"] = username
                register_kwargs["password"] = password

            # Add common parameters
            if org_name is not None:
                register_kwargs["org_name"] = org_name
            if api is not None:
                register_kwargs["api"] = api
            if graphistry_server is not None:
                register_kwargs["server"] = graphistry_server

            if register_kwargs:
                self.register(**register_kwargs)

    @property
    def auth_manager(self) -> AuthManager:
        """Get the authentication manager."""
        return self._auth_manager

    def register(self, **kwargs: Any) -> LouieClient:
        """Register authentication credentials (passthrough to graphistry).

        Args:
            **kwargs: Same arguments as graphistry.register()

        Returns:
            Self for chaining

        Examples:
            client.register(username="user", password="pass")
            client.register(api_key="key-123")
        """
        self._auth_manager.register(**kwargs)
        return self

    @auto_retry_auth
    def _fetch_dataframe_arrow(
        self, thread_id: str, block_id: str
    ) -> pd.DataFrame | None:
        """Fetch a dataframe using Arrow format.

        Args:
            thread_id: The thread ID
            block_id: The block ID for the dataframe

        Returns:
            DataFrame or None if fetch fails
        """
        try:
            headers = self._get_headers()
            url = f"{self.server_url}/api/dthread/{thread_id}/df/block/{block_id}/arrow"

            response = self._client.get(url, headers=headers)
            response.raise_for_status()

            # Parse Arrow format
            # Try file format first (most common), then stream format
            try:
                file_reader = pa.ipc.open_file(response.content)
                table = file_reader.read_all()
            except Exception:
                # Fallback to stream format
                stream_reader = pa.ipc.open_stream(response.content)
                table = stream_reader.read_all()

            # Convert to pandas
            df = table.to_pandas()
            return df

        except Exception as e:
            import warnings

            warnings.warn(
                f"Failed to fetch dataframe {block_id} from thread {thread_id}. "
                f"URL: {url if 'url' in locals() else 'not constructed'}. "
                f"Error: {type(e).__name__}: {e}",
                RuntimeWarning,
                stacklevel=2,
            )
            logger.debug("Full error details: ", exc_info=True)
            return None

    def _get_headers(
        self, session_trace_id: str | None = None, traceparent: str | None = None
    ) -> dict[str, str]:
        """Get authorization headers using auth manager.

        Args:
            session_trace_id: Optional session trace ID for correlation when
                OTel is not available. Used to generate traceparent if no
                explicit traceparent is provided and OTel is not active.
            traceparent: Optional explicit traceparent header value. If provided,
                takes precedence over auto-generated values.

        Returns:
            Headers dict with Authorization and optionally traceparent.
        """
        token = self._auth_manager.get_token()
        headers = {"Authorization": f"Bearer {token}"}

        # Add organization header if available
        if hasattr(
            self._auth_manager, "_credentials"
        ) and self._auth_manager._credentials.get("org_name"):
            org_name = self._auth_manager._credentials["org_name"]
            # Convert to slug format (lowercase, replace special chars with hyphens)
            if org_name:  # Ensure org_name is not None
                org_slug = self._to_slug(str(org_name))
                headers["X-Graphistry-Org"] = org_slug

        # Add traceparent for distributed tracing
        # Priority: explicit traceparent > OTel context > session trace
        if traceparent:
            headers["traceparent"] = traceparent
        else:
            tp = get_traceparent(session_trace_id)
            if tp:
                headers["traceparent"] = tp

        return headers

    def _to_slug(self, text: str) -> str:
        """Convert text to slug format.

        - Lowercase
        - Replace spaces and special chars with hyphens
        - Remove consecutive hyphens
        - Strip leading/trailing hyphens
        """
        import re

        # Convert to lowercase
        slug = text.lower()
        # Replace any non-alphanumeric character with hyphen
        slug = re.sub(r"[^a-z0-9]+", "-", slug)
        # Remove consecutive hyphens
        slug = re.sub(r"-+", "-", slug)
        # Strip leading/trailing hyphens
        slug = slug.strip("-")
        return slug

    def _parse_jsonl_response(self, response_text: str) -> dict[str, Any]:
        """Parse JSONL response into structured data.

        Handles both standard JSONL and cases where server concatenates
        multiple JSON objects on the same line.

        Returns dict with:
        - dthread_id: The thread ID
        - elements: List of response elements
        """
        result: dict[str, Any] = {"dthread_id": None, "elements": []}

        # Track elements by ID to handle streaming updates
        elements_by_id: dict[str, dict[str, Any]] = {}

        for line in response_text.strip().split("\n"):
            if not line:
                continue

            # Handle multiple JSON objects on same line
            # The server sometimes sends: {"dthread_id":"..."}{"}payload":{...}}
            json_objects = []
            decoder = json.JSONDecoder()
            idx = 0

            while idx < len(line):
                # Skip whitespace
                while idx < len(line) and line[idx].isspace():
                    idx += 1

                if idx >= len(line):
                    break

                try:
                    # Try to decode a JSON object starting at idx
                    obj, end_idx = decoder.raw_decode(line, idx)
                    json_objects.append(obj)
                    idx += end_idx
                except json.JSONDecodeError:
                    # If we can't decode, try parsing as single object
                    try:
                        obj = json.loads(line[idx:])
                        json_objects.append(obj)
                        break
                    except json.JSONDecodeError:
                        # Move to next character if we can't decode
                        idx += 1

            # Process each JSON object found
            for data in json_objects:
                # Skip non-dict objects (could be position integers, etc)
                if not isinstance(data, dict):
                    continue

                # Handle thread ID
                if "dthread_id" in data:
                    result["dthread_id"] = data["dthread_id"]

                # Handle element updates
                if "payload" in data:
                    elem = data["payload"]
                    elem_id = elem.get("id")
                    if elem_id:
                        # For text elements, merge content
                        if elem_id in elements_by_id and elem.get("type") in [
                            "TextElement",
                            "text",
                        ]:
                            existing = elements_by_id[elem_id]
                            # Merge text content fields
                            for field in ["content", "text", "value"]:
                                if elem.get(field):
                                    existing[field] = elem[field]
                            # Update other fields
                            existing.update(
                                {
                                    k: v
                                    for k, v in elem.items()
                                    if k not in ["content", "text", "value"]
                                }
                            )
                        else:
                            # Update or add element
                            elements_by_id[elem_id] = elem

        # Convert to list, preserving order
        elements = list(elements_by_id.values())
        result["elements"] = elements
        return result

    def _attach_dataframes(
        self, thread_id: str, elements: list[dict[str, Any]]
    ) -> None:
        """Fetch and attach dataframe contents for DataFrame elements."""

        if not thread_id:
            return

        for elem in elements:
            if elem.get("type") in ["DfElement", "df", "DataFrame", "dataframe"]:
                df_id = (
                    elem.get("df_id")
                    or elem.get("block_id")
                    or (elem.get("data") or {}).get("df_id")
                    or (elem.get("data") or {}).get("block_id")
                    or elem.get("id")
                )
                if not df_id:
                    continue
                fetched = self._fetch_dataframe_arrow(thread_id, df_id)
                if fetched is not None:
                    elem["table"] = fetched
                else:
                    logger.warning(
                        f"Failed to fetch dataframe {df_id} from thread "
                        f"{thread_id} for DfElement. Element: {elem}"
                    )

    def _chat_singleshot(self, params: dict[str, Any]) -> Response:
        """Call the batch chat endpoint and return a Response."""

        headers = self._get_headers()
        response = self._client.post(
            f"{self.server_url}/api/chat_singleshot/",
            headers=headers,
            params=params,
            timeout=self._timeout,
        )
        response.raise_for_status()

        payload = response.json()
        dthread_id: str | None = None
        elements: list[dict[str, Any]] = []

        if isinstance(payload, list):
            for item in payload:
                if isinstance(item, dict):
                    if dthread_id is None:
                        dthread_id = item.get("dthread_id") or dthread_id
                    payload_obj = item.get("payload")
                    if isinstance(payload_obj, dict):
                        elements.append(payload_obj)

        if dthread_id is None:
            dthread_id = ""

        self._attach_dataframes(dthread_id, elements)
        return Response(thread_id=dthread_id, elements=elements)

    def create_thread(
        self,
        name: str | None = None,
        folder: str | None = None,
        initial_prompt: str | None = None,
        *,
        agent: str = "LouieAgent",
        traces: bool = False,
        share_mode: str = "Private",
        table_ai_overrides: TableAIOverrides | Mapping[str, Any] | None = None,
        **override_kwargs: Any,
    ) -> Thread:
        """Create a new conversation thread.

        Args:
            name: Optional name for the thread
            folder: Optional folder path for the thread (server support required)
            initial_prompt: Optional first message to initialize thread
            agent: Agent to use for initial prompt (default: LouieAgent)
            traces: Whether to include reasoning traces (default: False)
            share_mode: Visibility mode for initial message
            table_ai_overrides: Structured Table AI overrides applied to initial prompt
            **override_kwargs: Legacy Table AI override keyword arguments forwarded to
                `add_cell` (e.g., `table_ai_semantic_mode`). Prefer
                `table_ai_overrides`.

        Returns:
            Thread object with ID

        Note: If no initial_prompt, thread ID will be empty until first add_cell
        """
        if initial_prompt:
            # Create thread with initial message
            add_kwargs = dict(override_kwargs)
            if table_ai_overrides is not None:
                add_kwargs["table_ai_overrides"] = table_ai_overrides

            response = self.add_cell(
                "",
                initial_prompt,
                agent=agent,
                name=name,
                folder=folder,
                traces=traces,
                share_mode=share_mode,
                **add_kwargs,
            )
            return Thread(id=response.thread_id, name=name, folder=folder)
        else:
            # Return placeholder - actual thread created on first add_cell
            return Thread(id="", name=name, folder=folder)

    @auto_retry_auth
    def add_cell(
        self,
        thread_id: str,
        prompt: str,
        agent: str = "LouieAgent",
        *,
        name: str | None = None,
        folder: str | None = None,
        traces: bool = False,
        share_mode: str = "Private",
        table_ai_overrides: TableAIOverrides | Mapping[str, Any] | None = None,
        use_batch: bool | None = None,
        session_trace_id: str | None = None,
        **legacy_overrides: Any,
    ) -> Response:
        """Add a cell (query) to a thread and get response.

        Args:
            thread_id: Thread ID to add to (empty string creates new thread)
            prompt: Natural language query
            agent: Agent to use (default: LouieAgent)
            name: Optional thread name (applied only when creating a new thread)
            folder: Optional folder path (applied only when creating a new thread)
            traces: Whether to include reasoning traces in response (default: False)
            share_mode: Visibility mode - "Private", "Organization", or "Public"
            table_ai_overrides: Structured overrides via dataclass or mapping.
            use_batch: Force singleshot (`True`) or streaming (`False`); defaults to
                singleshot when overrides are provided.
            session_trace_id: Optional session trace ID for distributed tracing
                correlation when OpenTelemetry is not available.
            **legacy_overrides: Backwards-compatible Table AI keyword arguments like
                ``table_ai_semantic_mode``. Prefer `table_ai_overrides`.

        Returns:
            Response object containing thread_id and all elements
        """
        headers = self._get_headers(session_trace_id=session_trace_id)

        # Build query parameters
        params: dict[str, Any] = {
            "query": prompt,
            "agent": agent,
            # Convert bool to string for HTTP params
            "ignore_traces": str(not traces).lower(),
            "share_mode": share_mode,
        }

        # Add thread ID if continuing existing thread
        if thread_id:
            params["dthread_id"] = thread_id
        else:
            if name:
                params["name"] = name
            if folder:
                params["folder"] = folder

        overrides: dict[str, Any] = normalize_table_ai_overrides(table_ai_overrides)
        legacy_params = collect_table_ai_kwargs(legacy_overrides)
        if legacy_overrides:
            unexpected = ", ".join(sorted(legacy_overrides))
            raise TypeError(
                f"add_cell() got unexpected keyword argument(s): {unexpected}"
            )
        overrides.update(legacy_params)
        params.update(overrides)

        if use_batch or (use_batch is None and bool(overrides)):
            return self._chat_singleshot(params)

        # Make streaming request with custom timeout handling
        response_text = ""
        lines_received = 0
        start_time = time.time()

        # Use configured timeouts
        stream_client = httpx.Client(
            timeout=httpx.Timeout(
                self._timeout,  # Overall timeout
                read=self._streaming_timeout,  # Per-chunk timeout
            )
        )

        with stream_client:
            with stream_client.stream(
                "POST", f"{self.server_url}/api/chat/", headers=headers, params=params
            ) as response:
                response.raise_for_status()

                # Collect streaming lines
                last_activity = start_time
                try:
                    for line in response.iter_lines():
                        if line:
                            response_text += line + "\n"
                            lines_received += 1
                            last_activity = time.time()

                            # Keep reading all elements until stream ends
                            # Don't break early just because we got a text element

                        # Only timeout if no activity for streaming_timeout duration
                        # Allow total_timeout for overall request
                        # but don't break active streams
                        time_since_activity = time.time() - last_activity
                        if time_since_activity > self._streaming_timeout:
                            logger.warning(
                                f"Streaming timeout after {time_since_activity:.1f}s "
                                f"of inactivity. "
                                f"Received {lines_received} lines. "
                                f"This may result in truncated responses."
                            )
                            break

                except httpx.ReadTimeout as e:
                    elapsed = time.time() - start_time
                    # Accept any response with at least the thread ID line
                    # Don't require minimum line count that could drop
                    # valid short responses
                    if lines_received >= 1:
                        logger.debug(
                            f"ReadTimeout after {elapsed:.1f}s with "
                            f"{lines_received} lines received. "
                            f"Treating as complete response."
                        )
                    else:
                        raise RuntimeError(
                            f"Louie API timeout after {elapsed:.1f}s waiting for "
                            f"response. Only received {lines_received} lines. "
                            f"Agentic flows can take time - consider increasing "
                            f"timeout (current: {self._streaming_timeout}s per chunk, "
                            f"{self._timeout}s total). "
                            f"Set timeout parameter when creating LouieClient."
                        ) from e

        # Log if request took a long time
        total_time = time.time() - start_time
        if total_time > 30:
            import warnings

            warnings.warn(
                f"Louie API request took {total_time:.1f}s to complete. "
                f"This is normal for complex agentic flows, but if you're "
                f"seeing timeouts, consider increasing the timeout parameter "
                f"when creating LouieClient.",
                RuntimeWarning,
                stacklevel=2,
            )

        # Parse JSONL response
        result = self._parse_jsonl_response(response_text)

        # Get the thread ID
        actual_thread_id = result.get("dthread_id") or thread_id

        elements = result.get("elements", [])
        self._attach_dataframes(actual_thread_id, elements)

        # Return Response with all elements
        return Response(thread_id=actual_thread_id, elements=elements)

    def __call__(
        self,
        prompt: str,
        *,
        thread_id: str | None = None,
        traces: bool = False,
        agent: str = "LouieAgent",
        share_mode: str = "Private",
        **kwargs: Any,
    ) -> Response:
        """Make the client callable for ergonomic usage.

        This allows using the client like a function:
        ```python
        client = LouieClient()
        response = client("What's the weather?")
        ```

        Args:
            prompt: Natural language query
            thread_id: Thread ID to use (None creates new thread)
            traces: Whether to include reasoning traces
            agent: Agent to use (default: LouieAgent)
            share_mode: Visibility mode - "Private", "Organization", or "Public"
            **kwargs: Additional keyword arguments forwarded to `add_cell`

        Returns:
            Response object containing thread_id and all elements
        """
        # Use empty string for new thread if thread_id is None
        tid = thread_id if thread_id is not None else ""

        # Store the thread_id for subsequent calls if not provided
        if not hasattr(self, "_current_thread_id"):
            self._current_thread_id = None

        # Use stored thread_id if none provided
        if thread_id is None and self._current_thread_id is not None:
            tid = self._current_thread_id

        # Make the call
        response = self.add_cell(
            thread_id=tid,
            prompt=prompt,
            agent=agent,
            traces=traces,
            share_mode=share_mode,
            **kwargs,
        )

        # Store thread_id for next call
        if response.thread_id:
            self._current_thread_id = response.thread_id

        return response

    @auto_retry_auth
    def list_threads(
        self, page: int = 1, page_size: int = 20, *, folder: str | None = None
    ) -> list[Thread]:
        """List available threads.

        Args:
            page: Page number (1-based)
            page_size: Number of items per page
            folder: Optional folder path to filter results (client-side)

        Returns:
            List of Thread objects
        """
        headers = self._get_headers()

        params: dict[str, Any] = {
            "page": page,
            "page_size": page_size,
            "sort_by": "last_modified",
            "sort_order": "desc",
        }
        if folder:
            params["folder"] = folder

        response = self._client.get(
            f"{self.server_url}/api/dthreads",
            headers=headers,
            params=params,
        )
        response.raise_for_status()

        data = response.json()
        items = data.get("data") or data.get("items") or []
        if not isinstance(items, list):
            items = []

        if folder is not None:
            items = [
                item
                for item in items
                if isinstance(item, dict) and item.get("folder") == folder
            ]

        threads = []
        for item in items:
            if not isinstance(item, dict):
                continue
            threads.append(
                Thread(
                    id=item.get("id", ""),
                    name=item.get("name"),
                    folder=item.get("folder"),
                )
            )

        return threads

    @auto_retry_auth
    def get_thread(self, thread_id: str) -> Thread:
        """Get a specific thread by ID.

        Args:
            thread_id: Thread ID to retrieve

        Returns:
            Thread object
        """
        data = self._fetch_thread_manifest(thread_id)
        return Thread(
            id=data.get("id", ""),
            name=data.get("name"),
            folder=data.get("folder"),
        )

    @auto_retry_auth
    def get_thread_by_name(self, name: str) -> Thread:
        """Get a thread by name (server resolves exact/fuzzy matches).

        Args:
            name: Thread name to retrieve

        Returns:
            Thread object
        """
        data = self._fetch_thread_manifest(name)
        return Thread(
            id=data.get("id", ""),
            name=data.get("name"),
            folder=data.get("folder"),
        )

    def _fetch_thread_manifest(self, identifier: str) -> dict[str, Any]:
        headers = self._get_headers()
        response = self._client.get(
            f"{self.server_url}/api/dthread/{identifier}", headers=headers
        )
        if response.status_code == 404:
            response = self._client.get(
                f"{self.server_url}/api/dthreads/{identifier}", headers=headers
            )
        response.raise_for_status()
        data = response.json()
        if not isinstance(data, dict):
            raise RuntimeError("Thread manifest response was not an object.")
        return cast(dict[str, Any], data)

    def upload_dataframe(
        self,
        prompt: str,
        df: pd.DataFrame,
        thread_id: str = "",
        *,
        format: str = "parquet",
        agent: str = "UploadPassthroughAgent",
        traces: bool = False,
        share_mode: str = "Private",
        name: str | None = None,
        folder: str | None = None,
        parsing_options: dict[str, Any] | None = None,
        session_trace_id: str | None = None,
    ) -> Response:
        """Upload a DataFrame with a natural language query for AI analysis.

        Args:
            prompt: Natural language query about the data
            df: Pandas DataFrame to analyze
            thread_id: Thread ID to continue conversation
            format: Serialization format (parquet, csv, json, jsonl, arrow)
            agent: AI agent to use
            traces: Include reasoning traces
            share_mode: Visibility setting
            name: Optional thread name
            folder: Optional folder path for the thread (server support required)
            parsing_options: Format-specific parsing options
            session_trace_id: Optional session trace ID for distributed tracing
                correlation when OpenTelemetry is not available.

        Returns:
            Response object with analysis results
        """
        # Lazy import to avoid circular dependency
        from ._upload import UploadClient

        if not hasattr(self, "_upload_client"):
            self._upload_client = UploadClient(self)

        return self._upload_client.upload_dataframe(
            prompt=prompt,
            df=df,
            thread_id=thread_id,
            format=format,
            agent=agent,
            traces=traces,
            share_mode=share_mode,
            name=name,
            folder=folder,
            parsing_options=parsing_options,
            session_trace_id=session_trace_id,
        )

    def upload_image(
        self,
        prompt: str,
        image: Any,
        thread_id: str = "",
        *,
        agent: str = "UploadPassthroughAgent",
        traces: bool = False,
        share_mode: str = "Private",
        name: str | None = None,
        folder: str | None = None,
        session_trace_id: str | None = None,
    ) -> Response:
        """Upload an image with a natural language query for analysis.

        Args:
            prompt: Natural language query about the image
            image: Image to analyze (file path, bytes, file-like, or PIL Image)
            thread_id: Thread ID to continue conversation
            agent: AI agent to use
            traces: Include reasoning traces
            share_mode: Visibility setting
            name: Optional thread name
            folder: Optional folder path for the thread (server support required)
            session_trace_id: Optional session trace ID for distributed tracing
                correlation when OpenTelemetry is not available.

        Returns:
            Response object with analysis results
        """
        from ._upload import UploadClient

        if not hasattr(self, "_upload_client"):
            self._upload_client = UploadClient(self)

        return self._upload_client.upload_image(
            prompt=prompt,
            image=image,
            thread_id=thread_id,
            agent=agent,
            traces=traces,
            share_mode=share_mode,
            name=name,
            folder=folder,
            session_trace_id=session_trace_id,
        )

    def upload_binary(
        self,
        prompt: str,
        file: Any,
        thread_id: str = "",
        *,
        agent: str = "UploadPassthroughAgent",
        traces: bool = False,
        share_mode: str = "Private",
        name: str | None = None,
        folder: str | None = None,
        filename: str | None = None,
        session_trace_id: str | None = None,
    ) -> Response:
        """Upload a binary file with a natural language query for analysis.

        Args:
            prompt: Natural language query about the file
            file: File to analyze (file path, bytes, or file-like)
            thread_id: Thread ID to continue conversation
            agent: AI agent to use
            traces: Include reasoning traces
            share_mode: Visibility setting
            name: Optional thread name
            folder: Optional folder path for the thread (server support required)
            filename: Optional filename to use
            session_trace_id: Optional session trace ID for distributed tracing
                correlation when OpenTelemetry is not available.

        Returns:
            Response object with analysis results
        """
        from ._upload import UploadClient

        if not hasattr(self, "_upload_client"):
            self._upload_client = UploadClient(self)

        return self._upload_client.upload_binary(
            prompt=prompt,
            file=file,
            thread_id=thread_id,
            agent=agent,
            traces=traces,
            share_mode=share_mode,
            name=name,
            folder=folder,
            filename=filename,
            session_trace_id=session_trace_id,
        )

    def __enter__(self):
        """Context manager support."""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Clean up client on exit."""
        self._client.close()
