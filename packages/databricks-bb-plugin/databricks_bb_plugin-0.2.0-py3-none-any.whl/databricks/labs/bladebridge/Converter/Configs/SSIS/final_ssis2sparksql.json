//writer configuration for ssis to SparkSQL glue.
{
	"inherit_from" : ["ssis2dws.json"],
	"CUSTOM_CONVERTER_MODULES" : ["ssis2pyspark_hooks"], // contains hooks for generating spark code
	"target_file_extension" : "py",

	"init_routine" : "init_writer", // gets called for every job, passes all the necessary vars and the normalized view of the package

	"file_header" : "from curses import meta~
from logging import exception~
import sys~
import re~
import socket~
import getpass~
import uuid~
import pandas as pd~
from datetime import datetime, timedelta~
from pyspark.context import SparkContext~
from pyspark.sql.functions import *~
~
StartTime = datetime.now().strftime(\"%Y%m%d %H:%M:%S\")~
MachineName = socket.gethostname()~
UserName = getpass.getuser()~
ExecutionInstanceGUID = str(uuid.uuid4())~
PackageName = '%PACKAGE_NAME%'~
~
",

	"file_footer" : "\texcept Exception as ex:~
\t\tprint(\"Error in data transformation\",ex)~
\t\tSTATUS = \"F\"~
\t\tTOTAL_ROWS = 0~
\t\tIMPORTED_ROWS = 0~
\t\tREJECTED_ROWS = 0~
\t\tMESSAGE =\"Loading Failed\"~
~
\t\tfailure_module(BATCH_LOG_ID,UNIT_EXECUTION_ID,IMPORT_NAME,START_TIME,END_TIME,TOTAL_ROWS,IMPORTED_ROWS,REJECTED_ROWS,STATUS,MESSAGE,PACKAGEVERSION,DATA_DATE,IMPORT_TARGET,PowerDesignerVersion)~
~
if __name__ == \"__main__\":~
\tmain()",

    "keep_node_names_as_is" : 1, // tell the reader not to alter invalid identifier characters, like space, ampersands etc

	"empty_converted_sql_file_text" : "SQL File is Empty !!!",
	"create_package_subfolder" : "1",
	"use_filename_for_output" : "1",
	"pre_node_line" : "# Processing node %NODE_NAME%, type %NODE_TYPE%", //# COLUMNS %COLUMN_LIST%
	"start_header_for_cell_command" : "# Databricks notebook source\n",
	"cell_command" : "# COMMAND ----------\n\n",
	"do_not_generate_procedures" : true,
	"pre_finalization_handler" : "::finalize_content",
	//this is the list of vars converter will be looking for when it encounters NZSQL Run Block package.  Add more if needed
	"sql_statement_variable_list" : ["NZBlock_Process","Temp_Sql_Var"],

	"code_fragment_breakers": {
		"line_end": [";"]
	},
	
	"code_indent" : "\t",
	
	"restricted_vars" : {
		"NZBlock_Process" : 1,
		"NZBlock_Create_Intake" : 1
	},

	//"insert_to_select_word" : "IDP_AUDIT_ID",
	"sql_converter_config_file":"ssis2sparksql.json",
	"etl_converter_config_file":"sql2python.json",

	"need_package_variable_and_component_mapping" : true,
	"package_variable_and_component_mapping" :
	{
		"WorkGroup_Example" : {
			"Package\Over all Container\Process_1\Loop Thru NZSQL Process Data Table_1\NZSQL Run - Process One NZBlock_1":
			["Package\Over all Container\Process_1\Parse all parameters of all NZSQL blocks_1"]
		}
	},

	"commands" : {
		"BEGIN_TRY" : "\ndef main():\n\ttry:\n\t\t",
		"CREATE_TABLE_TEMPLATE" : "columns = StructType([%COLUMNS%])\n%SRC_TABLE% = spark.createDataFrame(schema=columns)\n%SRC_TABLE%.createOrReplaceTempView('%SRC_TABLE%')\n",
		"CREATE_TABLE_AS_SELECT_TEMPLATE" : "sql_statement = \"\"\"%CREATE_TABLE_SELECT%\"\"\"\n%SRC_TABLE% = spark.sql(sql_statement)\n",
		"CREATE_TABLE_AS_SELECT_TEMPLATE_FORMAT" : "sql_statement = \"\"\"%CREATE_TABLE_SELECT%\"\"\".format(%COLUMNS%)\n%SRC_TABLE% = spark.sql(sql_statement)\n",
		"INSERT_INTO" : "%TGT_TABLE%  = %TGT_TABLE%.unionAll(%INSERTED_TABLE_NAME%)\n",
		"CREATE_TEMP_VIEW" : "%SRC_TABLE%.createOrReplaceTempView('%SRC_TABLE%')\n",
		"SET_VAR_VALUE" : "%NAME% = f'%VALUE%'\n",
		"COLUMN" : "StructField('%COLUMN_NAME%',StringType(),True)\n",
		"READ_EXCEL_COMMAND" : "%NODE_NAME% = pd.read_excel(\"%PATH%\",sheet_name=\"%SHEET%\")\n%NODE_NAME% = spark.createDataFrame(%NODE_NAME%)\n%NODE_NAME%.createOrReplaceTempView('%NODE_NAME%')",
		"REDSHIFT_COMMAND" : "source_jdbc_conf = glueContext.extract_jdbc_conf(glue_connection_name)~
~
from py4j.java_gateway import java_import~
java_import(sc._gateway.jvm,\"java.sql.Connection\")~
java_import(sc._gateway.jvm,\"java.sql.DatabaseMetaData\")~
java_import(sc._gateway.jvm,\"java.sql.DriverManager\")~
java_import(sc._gateway.jvm,\"java.sql.SQLException\")~
print(\"source_jdbc_conf value is \",source_jdbc_conf)~
conn = sc._gateway.jvm.DriverManager.getConnection(source_jdbc_conf.get('fullUrl'), source_jdbc_conf.get('user'), source_jdbc_conf.get('password'))~
~
print(conn.getMetaData().getDatabaseProductName())~
print(\"calling stored procedure\")~
# call stored procedure, in this case I call sp_start_job~
cstmt = conn.prepareStatement(\"call %PROCEDURE_NAME%()\")~
print(\"cstmt value is \",cstmt)~
#cstmt.setString(\"job_name\", \"testjob\");~
~
results = cstmt.execute();~
print(\"cstmt procedure executed\")~
conn.close()",
		"WRAP" : "%DF% = f\"\"\"%SQL%\"\"\"\nspark.sql(%DF%)\n",
		"SET_WRAP" : "%DF% = f\"\"\"%SQL%\"\"\"\n%VARIABLE% = spark.sql(%DF%)",
		"CREATE_TEMP_VIEW" : "%DF%.createOrReplaceTempView('%DF%')"
	},
	
	"custom_commands" : {
		"SPLIT_TO_COLUMNS_SELECT_WITH_WHERE" : "sql_statement = \"\"\"SELECT * from %TABLE% %WHERE%\"\"\"\n%TABLE% = spark.sql(sql_statement)\n\n",
		"SPLIT_TO_COLUMNS_with_column" : ". \\nwithColumn('%COLUMN%',split(%TABLE%['%TOOLKIT_COLUMN%'], '[%DELIMITER%]').getItem(%INDEX%))",
		"SPLIT_TO_COLUMNS_NEXT_VALUE_FOR" : "%TABLE%=SEQGEN(%TABLE%, '%NEXT_ID%')\n%TABLE%.createOrReplaceTempView('%TABLE%')\n",
		"SPLIT_TO_COLUMNS_select_with_format" : "sql_statement = \"\"\"%SELECT% * from %TABLE%\"\"\".format(IDP_AUDIT_ID=AUDIT_ID, IDP_DATA_DATE=idp_data_date_var)\n%TABLE% = spark.sql(sql_statement)\n%TABLE%.createOrReplaceTempView('%TABLE%')\n\n",
		"SPLIT_TO_COLUMNS_final_select" : "sql_statement = \"\"\"%SELECT% %TOOLKIT_COLUMNS% from %TABLE%\"\"\"\n%TABLE% = spark.sql(sql_statement)\n%TABLE%.createOrReplaceTempView('%TABLE%')\n\n"
	},
	"custom_cast" : {
		"Numeric" :	{ "Value" : "cast(%EXPRESSION% as Decimal%PRECISION%)", "Precision" : 1},
		"Varchar" :	{ "Value" : "cast(%EXPRESSION% as Varchar)", "Precision" : 0},
		"Date" :	{ "Value" : "to_date(%EXPRESSION%,'yyyyMMdd')", "Precision" : 0}
	},
	
	"multi_level_var_subst" : 1,
	"error_if_keywords" : "ERROR_MESSAGE",
	
	"trappers" : [
		{"USER_TYPE" : "^PACKAGE$", "__handler__" : "start_script"}, //main package
		//{"USER_TYPE" : "EXECUTE_SQL_TASK", "LOCAL_NAME" : "Query\s+Work\s*Unit", "__handler__" : "query_work_unit"},
		{"USER_TYPE" : "EXCEL_SOURCE", "__handler__" : "excelsource_block"},
		{"USER_TYPE" : "SOURCE", "__handler__" : "source_block"},
		{"USER_TYPE" : "TARGET", "__handler__" : "target_block"},
		{"USER_TYPE" : "AGGREGATOR", "__handler__" : "aggregator_block"},
		{"USER_TYPE" : "REPLICATE", "__handler__" : "replicate_block"},
		{"USER_TYPE" : "EXPRESSION", "__handler__" : "expression_block"},
		{"USER_TYPE" : "LOOKUP", "__handler__" : "lookup_block"},
		{"USER_TYPE" : "UNION", "__handler__" : "union_block"},
		{"USER_TYPE" : "CONDITIONALSPLIT", "__handler__" : "conditionalsplit_block"},
		{"USER_TYPE" : "MANAGEDCOMPONENTHOST", "__handler__" : "dummy_block"},		
		
		
		{"USER_TYPE" : "EXECUTE_SQL_TASK", "__handler__" : "query_work_unit"},
		{"USER_TYPE" : "EXECUTE_SQL", "__handler__" : "query_work_unit"},
		{"USER_TYPE" : "EXECUTE_PACKAGE", "LOCAL_NAME" : "(NZSQL\s*Run|NZBlock)", "__handler__" : "exec_sql_block"},
		{"USER_TYPE" : "STOCK_FOREACHLOOP", "LOCAL_NAME" : "Loop.*NZSQL.*Process", "__handler__" : "loop_start"},
		{"USER_TYPE" : "SCRIPT_TASK", "LOCAL_NAME" : "parse.*param", "__handler__" : "parse_sql_params_in_script"} //captures the list of params to be iterated over
	],
	
	"stmt_categorization_patterns":
	[
		{"category": "PYTHON_VARIABLE_ASSIGNMENT", "patterns" : ["^[\s\n]*\@\w+\s*="]},
		{"category": "PYTHON_VARIABLE_REASSIGNMENT", "patterns" : ["^[\s\n]*\@\w+\s*="]},
		{"category": "PYTHON_VARIABLE_DECLARATION", "patterns" : [
			"^[\s\n]*DECLARE\s+\@\w+\s+(\bDATETIME\b|\bBIGINT\b|\bNUMERIC\b|\bVARCHAR\b|\bLONG\b|\bINTEGER\b|\bINT\b|\bTIMESTAMP\b|\bINTERVAL\b|\bTEXT\b|\bRECORD\b)",
			"^[\s\n]*\@\w+\s+(\bDATETIME\b|\bBIGINT\b|\bNUMERIC\b|\bVARCHAR\b|\bLONG\b|\bINTEGER\b|\bINT\b|\bTIMESTAMP\b|\bINTERVAL\b|\bTEXT\b)"
		]},
		{"category": "SELECT_INTO", "patterns" : ["^\s*SELECT\s+.*?\bINTO\b"]},
		{"category": "UPDATE_TO_MERGE", "patterns" : ["^\s*UPDATE\b.*?\bFROM\b"]}
	],

	"fragment_handling" :
	{
		"SELECT_INTO" : "select_into_fragment",
		"PYTHON_VARIABLE_DECLARATION": "python_variable_assignment",
		"PYTHON_VARIABLE_ASSIGNMENT": "python_variable_assignment",
		"PYTHON_VARIABLE_REASSIGNMENT": "python_variable_assignment",
		"UPDATE_TO_MERGE": "update_to_merge_fragment"
	},
	
	"save_debug_info" : {
		"create_sql_debug_files" : false
	},

	"line_subst" : [
		{"from": "\bCOMMIT\b", "to": ""},
		{"from": "\bBEGIN\b", "to": ""},
		{"from": "\bWORK\b", "to": ""}
	],
	
	"table_name_trappers" : ["\bINSERT\s+INTO\s+(.*?)\s+",
						"\bCREATE\s+TABLE\s+(.*?)\s+",
						"(?<!\'\s)\bFROM\s+(?![\(])(.*?)\s+",
						"\bJOIN\s+(?![\(])(.*?)\s+"],
	
	"datatype_mapping" : {
        "i4" : "INT",
        "i2" : "INT",
        "decimal" : "NUMBER",
        "text" : "STRING",
        "nText" : "STRING",
        "dbTimeStamp" : "TIMESTAMP",
        "guid" : "STRING",
        "str" : "STRING",
        "wstr" : "STRING"
    },
    
    "datatype_default_length" : {
        "i4" : "4",
        "i2" : "4",
        "decimal" : "18",
        "text" : "4000",
        "nText" : "4000",
        "dbTimeStamp" : "29",
        "guid" : "40",
        "str" : "255",
        "wstr" : "255"
    },    

    "datatype_default_scale" : {
        "decimal" : "6",
        "dbTimeStamp" : "9"
    },
	
	"ado_to_databricks_datatype_mapping" : {
		"2" : "SMALLINT",
		"3" : "INT",
		"4" : "FLOAT", 
		"5" : "DOUBLE",
		"6" : "DECIMAL(19,4)",
		"7" : "TIMESTAMP",
		"8" : "STRING",
		"11" : "BOOLEAN", 
		"17" : "SMALLINT",
		"18" : "INT",
		"19" : "BIGINT",
		"20" : "BIGINT",
		"72" : "STRING",
		"129" : "STRING",
		"130" : "STRING",
		"131" : "DECIMAL(19,4)",
		"135" : "TIMESTAMP",
		"200" : "STRING",
		"201" : "STRING",
		"202" : "STRING",
		"203 " : "STRING",
		"204" : "BINARY",
		"205 " : "BINARY"
	},

	"table_name_cleaner" :["\(.*",
						   "\).*"],
	
	"generate_procedure_after_update" : false,
	"generate_procedure_after_delete" : false,
	"generate_only_sql_convert" : false,
	"file_name" : "PROC_%PROCEDURE_NAME%",
	"sql_comment" : "--",
	"create_procedure_template":"CREATE PROCEDURE %PROCEDURE_NAME%~
AS~
BEGIN~
%BODY%~
END"	
}