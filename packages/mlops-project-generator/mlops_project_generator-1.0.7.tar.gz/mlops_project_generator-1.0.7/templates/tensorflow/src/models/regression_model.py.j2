"""
Regression model implementation for TensorFlow/Keras
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from typing import Dict, Any


class RegressionModel(keras.Model):
    """
    Neural network for regression tasks
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize regression model
        
        Args:
            config: Configuration dictionary
        """
        super(RegressionModel, self).__init__()
        
        self.config = config
        self.hidden_layers = config.get("hidden_layers", [128, 64, 32])
        self.dropout = config.get("dropout", 0.2)
        self.output_dim = config.get("output_dim", 1)
        self.input_dim = config.get("input_dim", 20)
        
        # Build the model
        self._build_model()
    
    def _build_model(self):
        """Build the neural network architecture"""
        inputs = keras.Input(shape=(self.input_dim,))
        
        # Hidden layers
        x = inputs
        for hidden_dim in self.hidden_layers:
            x = layers.Dense(hidden_dim, activation='relu')(x)
            x = layers.Dropout(self.dropout)(x)
        
        # Output layer
        outputs = layers.Dense(self.output_dim, activation='linear')(x)
        
        self.model = keras.Model(inputs=inputs, outputs=outputs)
    
    def call(self, inputs, training=False):
        """Forward pass"""
        return self.model(inputs, training=training)
    
    def get_config(self):
        """Get model configuration"""
        return self.config


class DeepRegressionModel(keras.Model):
    """
    Deeper neural network with batch normalization for regression
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize deep regression model
        
        Args:
            config: Configuration dictionary
        """
        super(DeepRegressionModel, self).__init__()
        
        self.config = config
        self.hidden_layers = config.get("hidden_layers", [256, 128, 64])
        self.dropout = config.get("dropout", 0.3)
        self.output_dim = config.get("output_dim", 1)
        self.input_dim = config.get("input_dim", 20)
        self.use_batch_norm = config.get("use_batch_norm", True)
        
        # Build the model
        self._build_model()
    
    def _build_model(self):
        """Build the deep neural network architecture"""
        inputs = keras.Input(shape=(self.input_dim,))
        
        # Hidden layers with batch normalization
        x = inputs
        for i, hidden_dim in enumerate(self.hidden_layers):
            x = layers.Dense(hidden_dim)(x)
            
            if self.use_batch_norm:
                x = layers.BatchNormalization()(x)
            
            x = layers.Activation('relu')(x)
            x = layers.Dropout(self.dropout)(x)
        
        # Output layer
        outputs = layers.Dense(self.output_dim, activation='linear')(x)
        
        self.model = keras.Model(inputs=inputs, outputs=outputs)
    
    def call(self, inputs, training=False):
        """Forward pass"""
        return self.model(inputs, training=training)
    
    def get_config(self):
        """Get model configuration"""
        return self.config


class AttentionRegressionModel(keras.Model):
    """
    Regression model with attention mechanism
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize attention regression model
        
        Args:
            config: Configuration dictionary
        """
        super(AttentionRegressionModel, self).__init__()
        
        self.config = config
        self.hidden_layers = config.get("hidden_layers", [128, 64])
        self.dropout = config.get("dropout", 0.2)
        self.output_dim = config.get("output_dim", 1)
        self.input_dim = config.get("input_dim", 20)
        self.attention_dim = config.get("attention_dim", 32)
        
        # Build the model
        self._build_model()
    
    def _build_model(self):
        """Build the attention neural network architecture"""
        inputs = keras.Input(shape=(self.input_dim,))
        
        # Feature extractor
        x = inputs
        for hidden_dim in self.hidden_layers:
            x = layers.Dense(hidden_dim)(x)
            x = layers.Activation('relu')(x)
            x = layers.Dropout(self.dropout)(x)
        
        # Attention mechanism
        attention_weights = layers.Dense(self.attention_dim, activation='tanh')(x)
        attention_weights = layers.Dense(1, activation='softmax')(attention_weights)
        
        # Apply attention
        attended_features = layers.Multiply()([x, attention_weights])
        attended_features = layers.Lambda(lambda z: tf.reduce_sum(z, axis=1))(attended_features)
        
        # Output layer
        outputs = layers.Dense(self.output_dim, activation='linear')(attended_features)
        
        self.model = keras.Model(inputs=inputs, outputs=outputs)
    
    def call(self, inputs, training=False):
        """Forward pass"""
        return self.model(inputs, training=training)
    
    def get_config(self):
        """Get model configuration"""
        return self.config


class ResidualRegressionModel(keras.Model):
    """
    Regression model with residual connections
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize residual regression model
        
        Args:
            config: Configuration dictionary
        """
        super(ResidualRegressionModel, self).__init__()
        
        self.config = config
        self.hidden_layers = config.get("hidden_layers", [128, 128, 64, 64])
        self.dropout = config.get("dropout", 0.2)
        self.output_dim = config.get("output_dim", 1)
        self.input_dim = config.get("input_dim", 20)
        
        # Build the model
        self._build_model()
    
    def _residual_block(self, x, units, dropout_rate):
        """Create a residual block"""
        shortcut = x
        
        x = layers.Dense(units)(x)
        x = layers.BatchNormalization()(x)
        x = layers.Activation('relu')(x)
        x = layers.Dropout(dropout_rate)(x)
        
        x = layers.Dense(units)(x)
        x = layers.BatchNormalization()(x)
        
        # Add shortcut if dimensions match
        if shortcut.shape[-1] == units:
            x = layers.Add()([x, shortcut])
        
        x = layers.Activation('relu')(x)
        x = layers.Dropout(dropout_rate)(x)
        
        return x
    
    def _build_model(self):
        """Build the residual neural network architecture"""
        inputs = keras.Input(shape=(self.input_dim,))
        
        # Initial projection
        x = layers.Dense(self.hidden_layers[0])(inputs)
        x = layers.BatchNormalization()(x)
        x = layers.Activation('relu')(x)
        
        # Residual blocks
        for i in range(0, len(self.hidden_layers), 2):
            if i + 1 < len(self.hidden_layers):
                # Use pairs of same dimension for residual connections
                x = self._residual_block(x, self.hidden_layers[i], self.dropout)
                if i + 1 < len(self.hidden_layers):
                    x = self._residual_block(x, self.hidden_layers[i + 1], self.dropout)
            else:
                # Last block without residual connection
                x = layers.Dense(self.hidden_layers[i])(x)
                x = layers.BatchNormalization()(x)
                x = layers.Activation('relu')(x)
                x = layers.Dropout(self.dropout)(x)
        
        # Output layer
        outputs = layers.Dense(self.output_dim, activation='linear')(x)
        
        self.model = keras.Model(inputs=inputs, outputs=outputs)
    
    def call(self, inputs, training=False):
        """Forward pass"""
        return self.model(inputs, training=training)
    
    def get_config(self):
        """Get model configuration"""
        return self.config
