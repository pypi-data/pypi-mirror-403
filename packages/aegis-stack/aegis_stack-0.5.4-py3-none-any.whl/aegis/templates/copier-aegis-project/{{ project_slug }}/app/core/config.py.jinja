# app/core/config.py
"""
Application configuration management using Pydantic's BaseSettings.

This module centralizes application settings, allowing them to be loaded
from environment variables for easy configuration in different environments.
"""

from typing import Any

from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    """
    Defines application settings.
    `model_config` is used to specify that settings should be loaded from a .env file.
    """

    # Project identity
    PROJECT_NAME: str = "{{ project_slug }}"

    # Application environment: "dev" or "prod"
    APP_ENV: str = "dev"

    # Log level for the application
    LOG_LEVEL: str = "INFO"

    # Port for the web server
    PORT: int = 8000

    # Development settings
    AUTO_RELOAD: bool = False

    # Docker settings (used by docker-compose)
    AEGIS_STACK_TAG: str = "aegis-stack:latest"
    AEGIS_STACK_VERSION: str = "dev"

    # Health monitoring and alerting
    # Health checks are available via API endpoints (/health/)
    # Use external monitoring tools (Prometheus, DataDog, etc.) to poll these endpoints
    HEALTH_CHECK_ENABLED: bool = True
    HEALTH_CHECK_INTERVAL_MINUTES: int = 5  # Recommended interval for monitoring

    # Health check performance settings
    HEALTH_CHECK_TIMEOUT_SECONDS: float = 2.0
    SYSTEM_METRICS_CACHE_SECONDS: int = 5

    # Basic alerting configuration
    ALERTING_ENABLED: bool = False
    ALERT_COOLDOWN_MINUTES: int = 60  # Minutes between repeated alerts for same issue

    # Health check thresholds
    MEMORY_THRESHOLD_PERCENT: float = 90.0
    DISK_THRESHOLD_PERCENT: float = 85.0
    CPU_THRESHOLD_PERCENT: float = 95.0

    # Flet frontend settings
    FLET_ASSETS_DIR: str = "assets"  # Directory for Flet static assets (images, etc.)

    # Authentication settings
    SECRET_KEY: str = "change-this-secret-key-in-production-use-env-variable"
    JWT_ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30

{% if include_redis %}
    # Redis settings for arq background tasks
    REDIS_URL: str = "redis://redis:6379"  # Docker service name by default
    REDIS_URL_LOCAL: str | None = None  # Override for local CLI usage
    REDIS_DB: int = 0

    @property
    def redis_url_effective(self) -> str:
        """Get effective Redis URL, preferring local override when not in Docker."""
        # If explicitly overridden for local use
        if self.REDIS_URL_LOCAL and not self.is_docker:
            return self.REDIS_URL_LOCAL

        # Auto-translate Docker hostname to localhost when running outside Docker
        if not self.is_docker:
            from urllib.parse import urlparse, urlunparse

            parsed = urlparse(self.REDIS_URL)
            # Only translate the default Docker service hostname "redis"
            if parsed.hostname == "redis":
                # Reconstruct URL with localhost, preserving auth, port, path, etc.
                netloc = "localhost"
                if parsed.username:
                    if parsed.password:
                        netloc = f"{parsed.username}:{parsed.password}@localhost"
                    else:
                        netloc = f"{parsed.username}@localhost"
                if parsed.port:
                    netloc = f"{netloc}:{parsed.port}"
                return urlunparse(parsed._replace(netloc=netloc))

        return self.REDIS_URL
{% endif %}

{% if include_worker %}
    # arq worker settings (shared across all workers)
    WORKER_KEEP_RESULT_SECONDS: int = 3600  # Keep job results for 1 hour
    WORKER_MAX_TRIES: int = 3

    # Redis connection settings for arq workers
    REDIS_CONN_TIMEOUT: int = 5  # Connection timeout in seconds (default: 1)
    REDIS_CONN_RETRIES: int = 5  # Connection retry attempts (default: 5)
    REDIS_CONN_RETRY_DELAY: int = 1  # Delay between retries (default: 1)

    # Worker health check settings
    WORKER_HEALTH_CHECK_INTERVAL: int = 15  # In seconds (default: 15)

    # PURE ARQ IMPLEMENTATION - NO CONFIGURATION NEEDED!
    # Worker configuration comes from individual WorkerSettings classes
    # in app/components/worker/queues/ - just import and use as arq intended!
{% endif %}

{% if include_database %}
    # Database settings
{% if database_engine == "postgres" %}
    DATABASE_URL: str = "postgresql://postgres:postgres@postgres:5432/{{ project_slug }}"
    DATABASE_URL_LOCAL: str | None = None  # Override for local CLI usage
    DATABASE_ENGINE_ECHO: bool = False

    @property
    def database_url_effective(self) -> str:
        """Get effective database URL, preferring local override when not in Docker."""
        # If explicitly overridden for local use
        if self.DATABASE_URL_LOCAL and not self.is_docker:
            return self.DATABASE_URL_LOCAL

        # Auto-translate Docker hostname to localhost when running outside Docker
        if not self.is_docker:
            from urllib.parse import urlparse, urlunparse

            parsed = urlparse(self.DATABASE_URL)
            # Only translate the default Docker service hostname "postgres"
            if parsed.hostname == "postgres":
                # Reconstruct URL with localhost, preserving auth, port, path, etc.
                netloc = "localhost"
                if parsed.username:
                    if parsed.password:
                        netloc = f"{parsed.username}:{parsed.password}@localhost"
                    else:
                        netloc = f"{parsed.username}@localhost"
                if parsed.port:
                    netloc = f"{netloc}:{parsed.port}"
                return urlunparse(parsed._replace(netloc=netloc))

        return self.DATABASE_URL
{% else %}
    DATABASE_URL: str = "sqlite:///./data/app.db"
    DATABASE_ENGINE_ECHO: bool = False
    DATABASE_CONNECT_ARGS: dict[str, Any] = {"check_same_thread": False}
{% endif %}
{% endif %}

{% if include_ai %}
    # AI Service Configuration
    # Primary service settings
    AI_ENABLED: bool = True
    AI_PROVIDER: str = "public"  # Default to public provider
    AI_MODEL: str = "auto"  # Default model (public provider uses available models)
    AI_TEMPERATURE: float = 0.7
    AI_MAX_TOKENS: int = 1000
    AI_TIMEOUT_SECONDS: float = 120.0

    # Provider API Keys (optional - many providers offer free tiers)
    OPENAI_API_KEY: str | None = None
    ANTHROPIC_API_KEY: str | None = None
    GOOGLE_API_KEY: str | None = None
    GROQ_API_KEY: str | None = None
    MISTRAL_API_KEY: str | None = None
    COHERE_API_KEY: str | None = None

    # Ollama settings (local LLM inference)
{% if ollama_mode == "host" %}
    OLLAMA_BASE_URL: str = "http://host.docker.internal:11434"  # Host mode default
{% elif ollama_mode == "docker" %}
    OLLAMA_BASE_URL: str = "http://ollama:11434"  # Docker mode default
{% else %}
    OLLAMA_BASE_URL: str = "http://localhost:11434"  # Default for local testing
{% endif %}
    OLLAMA_BASE_URL_LOCAL: str | None = None  # Override for local CLI usage
    OLLAMA_API_KEY: str | None = None  # Optional, usually not needed

    # Conversation settings
    AI_MAX_CONVERSATION_LENGTH: int = 50  # Max messages per conversation
    AI_CONVERSATION_TIMEOUT_HOURS: int = 24  # Auto-cleanup old conversations
{% endif %}

{% if include_comms %}
    # Communications Service Configuration
    # Email (Resend) - Sign up at https://resend.com (free: 100 emails/day)
    RESEND_API_KEY: str | None = None
    RESEND_FROM_EMAIL: str | None = None  # Must be a verified domain in Resend

    # SMS/Voice (Twilio) - Sign up at https://twilio.com/try-twilio ($15 trial)
    TWILIO_ACCOUNT_SID: str | None = None
    TWILIO_AUTH_TOKEN: str | None = None
    TWILIO_PHONE_NUMBER: str | None = None  # E.164 format: +15551234567
    TWILIO_MESSAGING_SERVICE_SID: str | None = None  # Required for toll-free SMS
{% endif %}

{% if include_scheduler %}
    # Scheduler settings
    SCHEDULER_FORCE_UPDATE: bool = False  # Force update jobs from code on restart
{% endif %}

{% if ai_rag %}
    # RAG Service Configuration
    RAG_ENABLED: bool = True
    RAG_PERSIST_DIRECTORY: str = "./data/chromadb"
    RAG_EMBEDDING_PROVIDER: str = "sentence-transformers"  # or "openai"
    RAG_EMBEDDING_MODEL: str = "BAAI/bge-small-en-v1.5"  # Better default
    RAG_MODEL_CACHE_DIR: str | None = None  # None = system default, "./data/models" for local dev
    RAG_CHUNK_SIZE: int = 2000
    RAG_CHUNK_OVERLAP: int = 400
    RAG_DEFAULT_TOP_K: int = 15
    RAG_CHAT_TOP_K: int = 15  # Number of chunks for AI chat context
{% endif %}

{% if include_redis or database_engine == "postgres" or ollama_mode != "none" %}
    @property
    def is_docker(self) -> bool:
        """Detect if running inside Docker container."""
        import os
        return (
            os.path.exists("/.dockerenv") or
            bool(os.getenv("DOCKER_CONTAINER"))
        )
{% endif %}

{% if include_ai and ollama_mode != "none" %}
    @property
    def ollama_base_url_effective(self) -> str:
        """Get effective Ollama URL, preferring local override when not in Docker."""
        # If explicitly overridden for local use
        if self.OLLAMA_BASE_URL_LOCAL and not self.is_docker:
            return self.OLLAMA_BASE_URL_LOCAL

        # Auto-translate Docker hostnames to localhost when running outside Docker
        if not self.is_docker:
            from urllib.parse import urlparse, urlunparse

            parsed = urlparse(self.OLLAMA_BASE_URL)
            # Translate Docker-specific hostnames to localhost
            docker_hosts = {"ollama", "host.docker.internal"}
            if parsed.hostname in docker_hosts:
                netloc = "localhost"
                if parsed.port:
                    netloc = f"{netloc}:{parsed.port}"
                return urlunparse(parsed._replace(netloc=netloc))

        return self.OLLAMA_BASE_URL
{% endif %}

    model_config = SettingsConfigDict(env_file=".env", env_file_encoding="utf-8")

    def reload(self) -> None:
        """
        Reload settings from .env file in place.

        Updates all field values from a fresh Settings instance,
        allowing configuration changes to take effect without restart.
        """
        # Create a fresh Settings instance that reads from .env
        new_settings = Settings()

        # Update all field values in place
        for field_name in self.model_fields:
            setattr(self, field_name, getattr(new_settings, field_name))


settings = Settings()


def reload_settings() -> None:
    """
    Reload the global settings instance from .env file.

    Call this after modifying the .env file to pick up changes
    without restarting the application.
    """
    settings.reload()


{% if include_worker %}
# Pure arq queue helper functions - use dynamic discovery
def get_available_queues() -> list[str]:
    """Get all available queue names via dynamic discovery."""
    try:
        from app.components.worker.registry import discover_worker_queues
        queues: list[str] = discover_worker_queues()
        return queues
    except ImportError:
        # Worker components not available
        return []


def get_default_queue() -> str:
    """Get the default queue name for load testing."""
    # Prefer load_test queue if it exists, otherwise use first available
    available = get_available_queues()
    if "load_test" in available:
        return "load_test"
    return available[0] if available else "system"


def get_load_test_queue() -> str:
    """Get the queue name for load testing."""
    available = get_available_queues()
    return "load_test" if "load_test" in available else get_default_queue()


def is_valid_queue(queue_name: str) -> bool:
    """Check if a queue name is valid."""
    try:
        from app.components.worker.registry import validate_queue_name
        result: bool = validate_queue_name(queue_name)
        return result
    except ImportError:
        # Worker components not available, no queues are valid
        return False
{% endif %}
