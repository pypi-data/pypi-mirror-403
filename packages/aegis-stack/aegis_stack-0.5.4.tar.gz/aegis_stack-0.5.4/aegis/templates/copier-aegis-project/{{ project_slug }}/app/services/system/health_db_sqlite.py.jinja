"""
SQLite database health check for {{ project_name }}.

Provides comprehensive health checking for SQLite databases including
file existence, version info, PRAGMA settings, table information, and
migration history.
"""
{% if include_database and database_engine == "sqlite" %}
import os
from pathlib import Path
import re
import sqlite3
from typing import Any

from app.core.config import settings
from app.core.log import logger
from app.services.system.health import format_bytes
from app.services.system.models import ComponentStatus, ComponentStatusType


async def check_database_health() -> ComponentStatus:
    """
    Check SQLite database connectivity and basic functionality.

    Returns:
        ComponentStatus indicating database health
    """
    try:
        from app.core.db import db_session

        db_url = settings.DATABASE_URL
        if db_url.startswith("sqlite:///"):
            db_path = db_url.replace("sqlite:///", "").lstrip("./")

            if not Path(db_path).exists():
                return ComponentStatus(
                    name="database",
                    status=ComponentStatusType.WARNING,
                    message="Database not initialized - file does not exist",
                    response_time_ms=None,
                    metadata={
                        "implementation": "sqlite",
                        "database_exists": False,
                        "expected_path": db_path,
                        "url": settings.DATABASE_URL,
                        "recommendation": (
                            "Run database migrations or create database file"
                        ),
                    },
                )

        enhanced_metadata: dict[str, Any] = {
            "implementation": "sqlite",
            "url": settings.DATABASE_URL,
            "database_exists": True,
            "engine_echo": settings.DATABASE_ENGINE_ECHO,
        }

        if db_url.startswith("sqlite:///"):
            try:
                enhanced_metadata["version"] = sqlite3.sqlite_version

                db_path = db_url.replace("sqlite:///", "").lstrip("./")
                if Path(db_path).exists():
                    file_size = Path(db_path).stat().st_size
                    enhanced_metadata["file_size_bytes"] = file_size
                    enhanced_metadata["file_size_human"] = format_bytes(file_size)

                from app.core.db import engine
                if hasattr(engine.pool, 'size'):
                    enhanced_metadata["connection_pool_size"] = engine.pool.size()
                else:
                    enhanced_metadata["connection_pool_size"] = 1

            except Exception:
                logger.debug(
                    "Failed to collect enhanced database metadata", exc_info=True
                )

        with db_session(autocommit=False) as session:
            from sqlalchemy import text
            session.execute(text("SELECT 1"))

            table_info: list[dict[str, Any]] = []
            if db_url.startswith("sqlite:///"):
                try:
                    from sqlalchemy import inspect
                    inspector = inspect(session.bind)
                    if inspector is None:
                        table_names: list[str] = []
                    else:
                        table_names = inspector.get_table_names()

                    for table_name in table_names:
                        try:
                            from sqlalchemy import quoted_name
                            quoted_table = quoted_name(table_name, quote=True)
                            count_result = session.execute(
                                text(f"SELECT COUNT(*) FROM {quoted_table}")
                            ).fetchone()
                            row_count = count_result[0] if count_result else 0

                            table_info.append({
                                "name": table_name,
                                "rows": row_count
                            })
                        except Exception as e:
                            logger.debug(
                                f"Failed to count rows for table {table_name}: {e}"
                            )
                            table_info.append({
                                "name": table_name,
                                "rows": 0
                            })

                    enhanced_metadata["tables"] = table_info
                    enhanced_metadata["table_count"] = len(table_names)

                except Exception:
                    logger.debug("Failed to collect table information", exc_info=True)
                    enhanced_metadata["tables"] = []
                    enhanced_metadata["table_count"] = 0

            if db_url.startswith("sqlite:///"):
                try:
                    pragma_settings: dict[str, Any] = {}

                    result = session.execute(text("PRAGMA foreign_keys")).fetchone()
                    if result:
                        pragma_settings["foreign_keys"] = bool(result[0])

                    result = session.execute(text("PRAGMA journal_mode")).fetchone()
                    if result:
                        journal_mode = result[0].lower()
                        pragma_settings["journal_mode"] = journal_mode
                        enhanced_metadata["wal_enabled"] = journal_mode == "wal"

                    result = session.execute(text("PRAGMA cache_size")).fetchone()
                    if result:
                        pragma_settings["cache_size"] = result[0]

                    enhanced_metadata["pragma_settings"] = pragma_settings

                except Exception:
                    logger.debug(
                        "Failed to collect SQLite PRAGMA settings", exc_info=True
                    )

            if db_url.startswith("sqlite:///"):
                try:
                    comprehensive_pragma: dict[str, Any] = {}

                    result = session.execute(text("PRAGMA synchronous")).fetchone()
                    if result:
                        comprehensive_pragma["synchronous"] = result[0]

                    result = session.execute(text("PRAGMA temp_store")).fetchone()
                    if result:
                        comprehensive_pragma["temp_store"] = result[0]

                    result = session.execute(text("PRAGMA mmap_size")).fetchone()
                    if result:
                        comprehensive_pragma["mmap_size"] = result[0]

                    result = session.execute(text("PRAGMA page_size")).fetchone()
                    if result:
                        comprehensive_pragma["page_size"] = result[0]

                    result = session.execute(text("PRAGMA auto_vacuum")).fetchone()
                    if result:
                        comprehensive_pragma["auto_vacuum"] = result[0]

                    result = session.execute(text("PRAGMA busy_timeout")).fetchone()
                    if result:
                        comprehensive_pragma["busy_timeout"] = result[0]

                    result = session.execute(text("PRAGMA page_count")).fetchone()
                    if result:
                        comprehensive_pragma["page_count"] = result[0]

                    result = session.execute(text("PRAGMA freelist_count")).fetchone()
                    if result:
                        freelist = result[0]
                        comprehensive_pragma["freelist_count"] = freelist
                        page_count = comprehensive_pragma.get("page_count", 0)
                        if page_count > 0:
                            efficiency = (1 - freelist / page_count) * 100
                            comprehensive_pragma["db_efficiency"] = round(efficiency, 2)

                    enhanced_metadata["comprehensive_pragma"] = comprehensive_pragma

                except Exception:
                    logger.debug(
                        "Failed to collect comprehensive PRAGMA settings",
                        exc_info=True,
                    )

            if db_url.startswith("sqlite:///") and table_info:
                try:
                    table_schemas: list[dict[str, Any]] = []
                    total_indexes = 0
                    total_foreign_keys = 0

                    for table in table_info:
                        table_name = table["name"]
                        schema_info: dict[str, Any] = {
                            "name": table_name, "rows": table["rows"]
                        }

                        columns: list[dict[str, Any]] = []
                        from sqlalchemy import quoted_name
                        quoted_table = quoted_name(table_name, quote=True)
                        result = session.execute(
                            text(f"PRAGMA table_info({quoted_table})")
                        ).fetchall()
                        for row in result:
                            columns.append({
                                "name": row[1],
                                "type": row[2] or "BLOB",  # Default to BLOB if no type
                                "nullable": not bool(row[3]),  # Invert notnull
                                "default": str(row[4]) if row[4] is not None else "None",
                                "primary_key": bool(row[5]),
                            })
                        schema_info["columns"] = columns

                        indexes: list[dict[str, Any]] = []
                        result = session.execute(
                            text(f"PRAGMA index_list({quoted_table})")
                        ).fetchall()
                        for row in result:
                            # Get column names for this index
                            quoted_index = quoted_name(row[1], quote=True)
                            index_result = session.execute(
                                text(f"PRAGMA index_info({quoted_index})")
                            ).fetchall()
                            column_names = [idx_row[2] for idx_row in index_result]

                            indexes.append({
                                "name": row[1],
                                "unique": bool(row[2]),
                                "columns": column_names,
                            })
                            total_indexes += 1

                        schema_info["indexes"] = indexes

                        foreign_keys: list[dict[str, Any]] = []
                        result = session.execute(
                            text(f"PRAGMA foreign_key_list({quoted_table})")
                        ).fetchall()
                        for row in result:
                            foreign_keys.append({
                                "column": row[3],
                                "referred_table": row[2],
                                "referred_column": row[4],
                            })
                            total_foreign_keys += 1

                        schema_info["foreign_keys"] = foreign_keys
                        table_schemas.append(schema_info)

                    enhanced_metadata["table_schemas"] = table_schemas
                    enhanced_metadata["total_indexes"] = total_indexes
                    enhanced_metadata["total_foreign_keys"] = total_foreign_keys

                    if table_info:
                        total_rows = sum(t["rows"] for t in table_info)
                        largest_table = max(table_info, key=lambda t: t["rows"])
                        enhanced_metadata["total_rows"] = total_rows
                        enhanced_metadata["largest_table"] = largest_table

                except Exception:
                    logger.debug(
                        "Failed to collect table schema details", exc_info=True
                    )

            if db_url.startswith("sqlite:///"):
                try:
                    migrations: list[dict[str, Any]] = []

                    result = session.execute(
                        text(
                            "SELECT name FROM sqlite_master "
                            "WHERE type='table' AND name='alembic_version'"
                        )
                    ).fetchone()

                    if result:
                        version_result = session.execute(
                            text("SELECT version_num FROM alembic_version")
                        ).fetchone()
                        current_version = version_result[0] if version_result else None
                        enhanced_metadata["current_migration"] = current_version

                        alembic_versions_path = Path("alembic/versions")
                        if alembic_versions_path.exists():
                            migration_files = alembic_versions_path.glob("*.py")
                            for migration_file in sorted(migration_files):
                                if migration_file.name == "__init__.py":
                                    continue

                                try:
                                    with open(migration_file) as f:
                                        content = f.read()

                                    revision_id = migration_file.stem.split("_")[0]
                                    description = "No description"
                                    down_revision = None
                                    create_date = None

                                    doc_pat = r'"""(.+?)"""'
                                    doc_match = re.search(doc_pat, content, re.DOTALL)
                                    if doc_match:
                                        description = doc_match.group(1).strip()

                                    rev_pat = r'revision\s*=\s*[\'"](.+?)[\'"]'
                                    revision_match = re.search(rev_pat, content)
                                    if revision_match:
                                        revision_id = revision_match.group(1)

                                    down_pat = r'down_revision\s*=\s*[\'"](.+?)[\'"]'
                                    down_match = re.search(down_pat, content)
                                    if down_match:
                                        down_revision = down_match.group(1)

                                    date_pat = r'create_date\s*=\s*.+?datetime\((.+?)\)'
                                    date_match = re.search(date_pat, content)
                                    if date_match:
                                        create_date = date_match.group(0)

                                    file_mtime = os.path.getmtime(migration_file)

                                    migrations.append({
                                        "revision": revision_id,
                                        "down_revision": down_revision,
                                        "description": description,
                                        "file_mtime": file_mtime,
                                        "create_date": create_date,
                                        "is_current": revision_id == current_version,
                                        "content": content,
                                        "file_path": str(migration_file),
                                    })

                                except Exception as e:
                                    logger.debug(
                                        f"Failed to parse migration "
                                        f"{migration_file}: {e}"
                                    )

                        enhanced_metadata["migrations"] = migrations
                        enhanced_metadata["migration_count"] = len(migrations)
                    else:
                        enhanced_metadata["current_migration"] = None
                        enhanced_metadata["migrations"] = []
                        enhanced_metadata["migration_count"] = 0

                except Exception:
                    logger.debug("Failed to collect migration history", exc_info=True)
                    enhanced_metadata["migrations"] = []
                    enhanced_metadata["migration_count"] = 0

        return ComponentStatus(
            name="database",
            status=ComponentStatusType.HEALTHY,
            message="Database connection successful",
            response_time_ms=None,
            metadata=enhanced_metadata,
        )

    except ImportError:
        return ComponentStatus(
            name="database",
            status=ComponentStatusType.UNHEALTHY,
            message="Database module not available",
            response_time_ms=None,
            metadata={
                "implementation": "sqlite",
                "error": "Database module not imported or configured",
            },
        )
    except Exception as e:
        error_str = str(e).lower()
        if "unable to open database file" in error_str or "no such file" in error_str:
            return ComponentStatus(
                name="database",
                status=ComponentStatusType.WARNING,
                message="Database file not accessible",
                response_time_ms=None,
                metadata={
                    "implementation": "sqlite",
                    "url": settings.DATABASE_URL,
                    "error": str(e),
                    "recommendation": "Check database file path and permissions",
                },
            )

        return ComponentStatus(
            name="database",
            status=ComponentStatusType.UNHEALTHY,
            message=f"Database connection failed: {str(e)}",
            response_time_ms=None,
            metadata={
                "implementation": "sqlite",
                "url": settings.DATABASE_URL,
                "error": str(e),
            },
        )
{% endif %}
