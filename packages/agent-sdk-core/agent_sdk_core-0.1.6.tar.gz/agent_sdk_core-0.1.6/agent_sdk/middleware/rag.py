from .base import Middleware
import sqlite3
import json
import asyncio
import os

# =============================================================================
# 1. SimpleRAG (SQLite FTS5 Based)
# =============================================================================

class SimpleRAG(Middleware):
    """
    A lightweight, SQLite-based Retrieval-Augmented Generation (RAG) middleware.
    It utilizes SQLite's FTS5 (Full-Text Search) extension for fast keyword-based retrieval
    and handles session management.

    Storage Structure:
    ------------------
    Database: 'agent_knowledge.db' (SQLite file)

    1. 'knowledge' Table (Virtual FTS5):
       - content (TEXT): The full text of the message history (e.g., "User: Hi\nAI: Hello").
       - metadata (TEXT/JSON): JSON string containing metadata like agent name, session_id.
       - user_id (TEXT UNINDEXED): User ID for filtering (not indexed for full-text search).

    2. 'sessions' Table (Standard):
       - session_id (TEXT PK): Unique UUID for the chat session.
       - user_id (TEXT): Owner of the session.
       - title (TEXT): Chat title (generated by LLM or truncated from the first message).
       - created_at (TIMESTAMP): Creation time.

    Operational Logic:
    ------------------
    - **Recording:** Messages are saved to the 'knowledge' table. New sessions are recorded in the 'sessions' table.
    - **Retrieval:** Uses MATCH queries on the 'knowledge' table for efficient keyword search.
    - **Title Generation:** Automatically generates a title for new sessions.
        - If `title_summary=True`: Uses the LLM to generate a concise summary.
        - If `title_summary=False`: Truncates the first user message (e.g., first 40 chars).

    Important Note:
    ---------------
    When `title_summary=True` is enabled, the `SimpleRAG` middleware relies on the `runner` object passed during the `after_run` hook to generate titles. Specifically, it uses `runner.client` to make LLM calls. Therefore, the **Client** associated with the runner (e.g., GeminiClient, OpenAIClient) must be properly initialized, authenticated, and capable of performing chat completions with the specified model.

    Attributes:
        db_path (str): Path to the SQLite database file.
        title_summary (bool): Whether to use LLM for title generation.
        summary_model (str): Optional specific model to use for title generation.
    """

    def __init__(self, db_path: str = "agent_knowledge.db", title_summary: bool = False, summary_model: str = None):
        """
        Initializes the SimpleRAG middleware.

        Args:
            db_path (str): Path to the SQLite database file. Defaults to "agent_knowledge.db".
            title_summary (bool): If True, uses LLM to generate session titles. Defaults to False.
            summary_model (str): Specific model to use for summarization (e.g., "gemini-2.0-flash").
                                 If None, the agent's current model is used.
        """
        self.db_path = db_path
        self.title_summary = title_summary
        self.summary_model = summary_model
        self._init_db()

    def _init_db(self):
        """
        Initializes the database schema, creating 'knowledge' and 'sessions' tables if they don't exist.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        # FTS5 table for fast text search
        try:
            cursor.execute("""
                CREATE VIRTUAL TABLE IF NOT EXISTS knowledge 
                USING fts5(content, metadata, user_id UNINDEXED)
            """)
        except sqlite3.OperationalError:
            # Fallback for older sqlite versions or schema mismatches
            pass
        
        # Sessions table for managing chat titles and history list
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS sessions (
                session_id TEXT PRIMARY KEY,
                user_id TEXT,
                title TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        conn.commit()
        conn.close()

    def _add_memory(self, content: str, metadata: dict, user_id: str = None):
        """
        Saves a text entry to the 'knowledge' table.

        Args:
            content (str): The text content to save.
            metadata (dict): Metadata associated with the content.
            user_id (str): The ID of the user owning this data.
        """
        if not content or len(content) < 10: return
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            uid = user_id or "global"
            cursor.execute("INSERT INTO knowledge (content, metadata, user_id) VALUES (?, ?, ?)", 
                           (content, json.dumps(metadata), uid))
            conn.commit()
            conn.close()
        except Exception as e:
            print(f"[SimpleRAG] Save Error: {e}")

    def _save_session_title(self, session_id: str, user_id: str, title: str):
        """
        Saves a session title to the 'sessions' table.
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("INSERT OR IGNORE INTO sessions (session_id, user_id, title) VALUES (?, ?, ?)", 
                           (session_id, user_id or "global", title))
            conn.commit()
            conn.close()
        except Exception as e:
            print(f"[SimpleRAG] Save Title Error: {e}")

    def _has_title(self, session_id: str) -> bool:
        """
        Checks if a title already exists for the given session_id.
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT 1 FROM sessions WHERE session_id = ?", (session_id,))
            exists = cursor.fetchone() is not None
            conn.close()
            return exists
        except:
            return False

    def get_sessions(self, user_id: str) -> list:
        """
        Retrieves all chat sessions for a specific user.

        Args:
            user_id (str): The user ID to filter by.

        Returns:
            list: A list of dictionaries [{'session_id': '...', 'title': '...', 'created_at': '...'}, ...]
        """
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row # Return rows as dict-like objects
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT session_id, title, created_at 
                FROM sessions 
                WHERE user_id = ? 
                ORDER BY created_at DESC
            """, (user_id,))
            
            rows = cursor.fetchall()
            conn.close()
            
            return [dict(row) for row in rows]
        except Exception as e:
            print(f"[SimpleRAG] Get Sessions Error: {e}")
            return []

    def _generate_title(self, user_msg: str, runner, agent):
        """
        Generates a short title using the LLM based on the user's message.
        """
        prompt = f"Summarize this user message into a very short, concise title (max 5 words). Do not answer the question, just summarize it as a title. Message: '{user_msg}'"
        
        # Use specific model if provided, else use agent's model
        model_to_use = self.summary_model if self.summary_model else agent.model
        
        try:
            # Synchronous call via runner's client
            response = runner.client.chat(model_to_use, [{"role": "user", "content": prompt}])
            return response.strip().replace('"', '')
        except Exception as e:
            print(f"[SimpleRAG] Title Gen Error: {e}")
            return "New Chat"

    async def _generate_title_async(self, user_msg: str, runner, agent):
        """
        Asynchronously generates a short title using the LLM.
        """
        prompt = f"Summarize this user message into a very short, concise title (max 5 words). Do not answer the question, just summarize it as a title. Message: '{user_msg}'"
        model_to_use = self.summary_model if self.summary_model else agent.model
        
        try:
            response = await runner.client.chat_async(model_to_use, [{"role": "user", "content": prompt}])
            return response.strip().replace('"', '')
        except Exception as e:
            print(f"[SimpleRAG] Title Gen Async Error: {e}")
            return "New Chat"

    def _search_memory(self, query: str, user_id: str = None, session_id: str = None, limit: int = 3) -> str:
        """
        Searches the 'knowledge' table for relevant context.

        Args:
            query (str): The search query.
            user_id (str): Filter by user ID.
            session_id (str): Filter by session ID.
            limit (int): Max number of results.

        Returns:
            str: A formatted string of relevant context points.
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            safe_query = query.replace('"', '').replace("'", "")
            if not safe_query.strip(): return ""

            # Base query filtering by user_id
            if user_id:
                sql = "SELECT content, metadata FROM knowledge WHERE knowledge MATCH ? AND user_id = ?"
                params = [safe_query, user_id]
            else:
                sql = "SELECT content, metadata FROM knowledge WHERE knowledge MATCH ? AND user_id = 'global'"
                params = [safe_query]

            cursor.execute(sql, params)
            results = cursor.fetchall() # (content, metadata_str)
            conn.close()
            
            if not results: return ""

            # Post-processing to filter by session_id (since it's in JSON metadata)
            filtered_results = []
            for content, meta_str in results:
                try:
                    meta = json.loads(meta_str)
                    if session_id and meta.get("session_id") != session_id:
                        continue
                    filtered_results.append(content)
                except:
                    filtered_results.append(content)

            final_results = filtered_results[:limit]
            
            if not final_results: return ""
            return "\n".join([f"- {r}" for r in final_results])
        except Exception as e:
            return ""

    def _get_recent_history(self, user_id: str, session_id: str, limit: int = 5) -> str:
        """
        Fetches the most recent N messages for a specific session from the 'knowledge' table.
        Note: Since 'knowledge' is a virtual FTS5 table, it doesn't support ORDER BY timestamp natively 
        unless we store timestamp in a separate column or parse it. 
        
        However, FTS5 tables return rows in insertion order (RowID order) by default.
        So getting the last N rows effectively gives us the recent history.
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Retrieve last N rows filtering by user_id (and session check in python)
            # We use RowID DESC to get latest entries.
            sql = "SELECT content, metadata FROM knowledge WHERE user_id = ? ORDER BY rowid DESC LIMIT ?"
            params = (user_id or "global", limit * 3) # Fetch more to filter by session in python

            cursor.execute(sql, params)
            results = cursor.fetchall()
            conn.close()
            
            if not results: return ""

            filtered_content = []
            count = 0
            
            # Filter by session_id in Python
            for content, meta_str in results:
                try:
                    meta = json.loads(meta_str)
                    if session_id and meta.get("session_id") != session_id:
                        continue
                    
                    # Clean up content for display (Optional)
                    filtered_content.append(content)
                    count += 1
                    if count >= limit: break
                except:
                    continue

            # Reverse to show chronological order (Oldest -> Newest)
            return "\n\n".join(reversed(filtered_content))
        except Exception as e:
            # print(f"[SimpleRAG] History Error: {e}")
            return ""

    # --- HOOKS ---
    def before_run(self, agent, runner):
        """Sync hook: Searches memory before the agent runs."""
        if not agent.memory: return
        last_msg = agent.memory[-1]
        if last_msg.get("role") != "user": return
        
        query = last_msg.get("content", "")
        user_id = getattr(agent, "user_id", None)
        session_id = getattr(agent, "session_id", None)
        
        # 1. Search (Keyword)
        search_context = self._search_memory(query, user_id=user_id, session_id=session_id)
        
        # 2. Recent History (Context Window)
        recent_history = ""
        if session_id:
            recent_history = self._get_recent_history(user_id, session_id, limit=5)
        
        # Combine Contexts
        full_context = ""
        if search_context:
            full_context += f"RELEVANT MEMORY (Search):\n{search_context}\n\n"
        if recent_history:
            full_context += f"RECENT CONVERSATION HISTORY (Last 5 Messages):\n{recent_history}\n"
            
        if full_context:
            print(f"\n[SimpleRAG] Context injected (Search + History).")
            agent.memory.insert(len(agent.memory)-1, {
                "role": "system",
                "content": full_context
            })

    def _cleanup_context(self, agent):
        """Removes RAG-injected messages from agent memory to prevent bloat."""
        if not agent.memory: return
        
        # Headers identifying SimpleRAG injections
        headers = [
            "RELEVANT MEMORY (Keyword Search):",
            "RECENT CONVERSATION HISTORY (Last 5 Messages):"
        ]
        
        # Iterate backwards to remove safely
        for i in range(len(agent.memory) - 1, -1, -1):
            msg = agent.memory[i]
            if msg.get("role") == "system":
                for h in headers:
                    if msg.get("content", "").startswith(h):
                        agent.memory.pop(i)
                        break

    def after_run(self, agent, runner):
        """Sync hook: Saves memory, manages titles, and cleans up RAG context."""
        # 1. Save and Title Logic (First preserve data)
        if len(agent.memory) >= 2:
            user_msg = next((m["content"] for m in reversed(agent.memory) if m["role"] == "user"), None)
            ai_msg = next((m["content"] for m in reversed(agent.memory) if m["role"] == "assistant"), None)

            if user_msg and ai_msg:
                full_entry = f"User: {user_msg}\nAI: {ai_msg}"
                user_id = getattr(agent, "user_id", None)
                session_id = getattr(agent, "session_id", None)
                
                # Save Memory
                meta = {"agent": agent.name}
                if session_id: meta["session_id"] = session_id
                self._add_memory(full_entry, meta, user_id=user_id)
                
                # Manage Title
                if session_id and not self._has_title(session_id):
                    title = "New Chat"
                    if self.title_summary:
                        print(f"[SimpleRAG] Generating AI title for session {session_id}...")
                        title = self._generate_title(user_msg, runner, agent)
                    else:
                        clean_msg = user_msg.replace("\n", " ").strip()
                        title = clean_msg[:40] + "..." if len(clean_msg) > 40 else clean_msg
                        print(f"[SimpleRAG] Generating simple title for session {session_id}...")

                    self._save_session_title(session_id, user_id, title)
                    print(f"[SimpleRAG] Title saved: {title}")

        # 2. Cleanup (Transient RAG)
        # Remove the injected context so it doesn't pollute short-term memory
        self._cleanup_context(agent)

    async def after_run_async(self, agent, runner):
        """Async hook: Saves memory, manages titles, and cleans up RAG context."""
        # 1. Save and Title Logic
        if len(agent.memory) >= 2:
            user_msg = next((m["content"] for m in reversed(agent.memory) if m["role"] == "user"), None)
            ai_msg = next((m["content"] for m in reversed(agent.memory) if m["role"] == "assistant"), None)
            if user_msg and ai_msg:
                full_entry = f"User: {user_msg}\nAI: {ai_msg}"
                user_id = getattr(agent, "user_id", None)
                session_id = getattr(agent, "session_id", None)
                
                # Save Memory
                meta = {"agent": agent.name}
                if session_id: meta["session_id"] = session_id
                await asyncio.to_thread(self._add_memory, full_entry, meta, user_id)
                
                # Manage Title
                if session_id:
                    has_title = await asyncio.to_thread(self._has_title, session_id)
                    if not has_title:
                        title = "New Chat"
                        if self.title_summary:
                            print(f"[SimpleRAG] Generating AI title for session {session_id}...")
                            title = await self._generate_title_async(user_msg, runner, agent)
                        else:
                            clean_msg = user_msg.replace("\n", " ").strip()
                            title = clean_msg[:40] + "..." if len(clean_msg) > 40 else clean_msg
                            print(f"[SimpleRAG] Generating simple title for session {session_id}...")
                            
                        await asyncio.to_thread(self._save_session_title, session_id, user_id, title)
                        print(f"[SimpleRAG] Title saved: {title}")
        
        # 2. Cleanup (Transient RAG)
        self._cleanup_context(agent)


# =============================================================================
# 2. ChromaRAG (Vector Database Based)
# =============================================================================

class ChromaRAG(Middleware):
    """
    A semantic Retrieval-Augmented Generation (RAG) middleware using ChromaDB.
    It provides vector-based similarity search to retrieve context based on meaning rather than just keywords.

    Storage Structure:
    ------------------
    Database: './chroma_db' (Directory for ChromaDB Persistence)
    Collection: 'agent_memory'

    Data Unit (Record/Document):
    - Document: The text content itself.
    - Embedding: The numerical vector representation of the text (Vector Space).
    - Metadata (JSON): Tags used for filtering.
        - user_id: User ID.
        - session_id: Session ID (if applicable).
        - agent: Agent name.

    Operational Logic:
    ------------------
    - **Recording:** Converts the text into an embedding and saves it to ChromaDB.
    - **Retrieval:** Converts the user query into an embedding and finds the most similar records (Cosine Similarity).
    - **Filtering:** Uses the 'where' parameter to filter results by user_id and session_id.
    
    Note: This class does NOT manage the 'sessions' table or titles; that is handled by SimpleRAG.
    """

    def __init__(self, collection_name: str = "agent_memory", persist_dir: str = "./chroma_db"):
        """
        Initializes the ChromaRAG middleware.

        Args:
            collection_name (str): Name of the ChromaDB collection. Defaults to "agent_memory".
            persist_dir (str): Directory path for storing ChromaDB data. Defaults to "./chroma_db".
        """
        self.collection_name = collection_name
        self.persist_dir = persist_dir
        self.collection = None
        self._init_db()

    def _init_db(self):
        """Initializes the ChromaDB client and collection."""
        try:
            import chromadb
            # Create Persistent Client
            self.client = chromadb.PersistentClient(path=self.persist_dir)
            self.collection = self.client.get_or_create_collection(name=self.collection_name)
            print(f"[ChromaRAG] ChromaDB initialized at '{self.persist_dir}'. Collection: '{self.collection_name}'")
        except ImportError:
            print("[ChromaRAG] Error: 'chromadb' not found. Please install via 'pip install chromadb' or use SimpleRAG.")
        except Exception as e:
            print(f"[ChromaRAG] Init Error: {e}")

    def _add_memory(self, content: str, metadata: dict, user_id: str = None):
        """
        Saves a text entry to ChromaDB with embeddings and metadata.
        """
        if not self.collection: return
        if not content or len(content) < 10: return

        try:
            import uuid
            doc_id = str(uuid.uuid4())
            
            # Add User ID to metadata
            final_metadata = metadata.copy()
            
            if user_id:
                final_metadata["user_id"] = user_id
            else:
                final_metadata["user_id"] = "global"

            # session_id is expected to be in 'metadata' if it exists.
            
            self.collection.add(
                documents=[content],
                metadatas=[final_metadata],
                ids=[doc_id]
            )
        except Exception as e:
            print(f"[ChromaRAG] Add Error: {e}")

    def _search_memory(self, query: str, user_id: str = None, session_id: str = None, limit: int = 2) -> str:
        """
        Performs a semantic search in ChromaDB.

        Args:
            query (str): The search query.
            user_id (str): Filter by user ID.
            session_id (str): Filter by session ID.
            limit (int): Max number of results.

        Returns:
            str: A formatted string of relevant documents.
        """
        if not self.collection: return ""
        if not query.strip(): return ""

        try:
            # Prepare Filter
            where_filter = {}
            
            uid = user_id if user_id else "global"
            
            if session_id:
                # Use AND operator if both user_id and session_id are present
                where_filter = {
                    "$and": [
                        {"user_id": uid},
                        {"session_id": session_id}
                    ]
                }
            else:
                # Only user_id
                where_filter = {"user_id": uid}

            results = self.collection.query(
                query_texts=[query], 
                n_results=limit,
                where=where_filter 
            )
            
            docs = results['documents'][0]
            if not docs: return ""
            return "\n".join([f"- {doc}" for doc in docs])
        except Exception as e:
            print(f"[ChromaRAG] Search Error: {e}")
            return ""

    # --- HOOKS ---
    def before_run(self, agent, runner):
        """Sync hook: Searches semantic memory before the agent runs."""
        if not agent.memory: return
        last_msg = agent.memory[-1]
        if last_msg.get("role") != "user": return
        
        user_id = getattr(agent, "user_id", None)
        session_id = getattr(agent, "session_id", None)
        
        context = self._search_memory(last_msg.get("content", ""), user_id=user_id, session_id=session_id)
        
        if context:
            print(f"\n[ChromaRAG] Found semantic memory (User: {user_id}, Session: {session_id}).")
            agent.memory.insert(len(agent.memory)-1, {
                "role": "system",
                "content": f"RELEVANT MEMORY (Semantic Search):\n{context}"
            })

    def _cleanup_context(self, agent):
        """Removes ChromaRAG-injected messages from agent memory."""
        if not agent.memory: return
        
        header = "RELEVANT MEMORY (Semantic Search):"
        
        for i in range(len(agent.memory) - 1, -1, -1):
            msg = agent.memory[i]
            if msg.get("role") == "system" and msg.get("content", "").startswith(header):
                agent.memory.pop(i)

    def after_run(self, agent, runner):
        """Sync hook: Saves memory after the agent runs and cleans up context."""
        # 1. Save Logic
        if len(agent.memory) >= 2:
            user_msg = next((m["content"] for m in reversed(agent.memory) if m["role"] == "user"), None)
            ai_msg = next((m["content"] for m in reversed(agent.memory) if m["role"] == "assistant"), None)
            if user_msg and ai_msg:
                full_entry = f"User: {user_msg}\nAI: {ai_msg}"
                user_id = getattr(agent, "user_id", None)
                session_id = getattr(agent, "session_id", None)
                
                meta = {"agent": agent.name}
                if session_id: meta["session_id"] = session_id
                
                self._add_memory(full_entry, meta, user_id=user_id)

        # 2. Cleanup
        self._cleanup_context(agent)

    # --- ASYNC HOOKS ---
    async def before_run_async(self, agent, runner):
        """Async hook: Searches semantic memory before the agent runs."""
        if not agent.memory: return
        last_msg = agent.memory[-1]
        if last_msg.get("role") != "user": return
        
        user_id = getattr(agent, "user_id", None)
        session_id = getattr(agent, "session_id", None)
        
        context = await asyncio.to_thread(self._search_memory, last_msg.get("content", ""), user_id, session_id)
        
        if context:
            print(f"\n[ChromaRAG] Found semantic memory (User: {user_id}, Session: {session_id}).")
            agent.memory.insert(len(agent.memory)-1, {
                "role": "system",
                "content": f"RELEVANT MEMORY (Semantic Search):\n{context}"
            })

    async def after_run_async(self, agent, runner):
        """Async hook: Saves memory after the agent runs and cleans up context."""
        # 1. Save Logic
        if len(agent.memory) >= 2:
            user_msg = next((m["content"] for m in reversed(agent.memory) if m["role"] == "user"), None)
            ai_msg = next((m["content"] for m in reversed(agent.memory) if m["role"] == "assistant"), None)
            if user_msg and ai_msg:
                full_entry = f"User: {user_msg}\nAI: {ai_msg}"
                user_id = getattr(agent, "user_id", None)
                session_id = getattr(agent, "session_id", None)
                
                meta = {"agent": agent.name}
                if session_id: meta["session_id"] = session_id
                
                await asyncio.to_thread(self._add_memory, full_entry, meta, user_id)

        # 2. Cleanup
        self._cleanup_context(agent)
