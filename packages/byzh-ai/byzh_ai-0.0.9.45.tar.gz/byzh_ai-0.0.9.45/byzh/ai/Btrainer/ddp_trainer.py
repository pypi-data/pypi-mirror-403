import os
import platform
import time
from pathlib import Path
from typing import Literal, TypedDict
import socket
import copy
import torch
from torch import nn
import numpy as np
from functools import partial
from copy import deepcopy

import torch.distributed as dist
from torch.utils.data import DataLoader, DistributedSampler
from torchvision import datasets, transforms
from torch.nn.parallel import DistributedDataParallel as DDP
import torch.multiprocessing as mp

from byzh.core.Btqdm import B_Tqdm
from byzh.core.Bwriter import B_Writer
from byzh.core.Butils import B_Color, B_Appearance

from ..Bearly_stop import *
from ..Butils import b_get_device, b_get_gpu_nvidia


def get_total_and_correct(outputs, labels) -> tuple:
    if isinstance(outputs, dict):
        # 获取第一个key的value
        outputs = outputs[list(outputs.keys())[0]]
    if isinstance(outputs, torch.Tensor):
        # 就是本身
        outputs = outputs
    total = labels.size(0)
    _, predicted = torch.max(outputs, 1)
    # print(f'predict: {predicted.cpu().numpy()}')
    # print(f'labels: {labels.cpu().numpy()}')
    correct = (predicted == labels).sum().item()
    # print(f'correct/total: {correct}/{total}')
    return predicted, total, correct

class _saveBestDuringTrain:
    def __init__(self, path, rounds):
        self.path = path
        self.rounds = rounds
        self.cnt = 0
    def __call__(self):
        self.cnt += 1
        if self.cnt > self.rounds:
            self.cnt = 0
            return True
        return False

class _Func:
    def __init__(self, func=None):
        self.func = func
    def set_func(self, func):
        self.func = func
    def __call__(self, **kwargs):
        if self.func is None:
            return None
        result = self.func(**kwargs)
        return result

class GPU_Dict(TypedDict):
    total: int
    max_used: int

class B_Trainer:
    def __init__(
        self,
        model,
        optimizer,
        criterion,
        batch_size,
        train_dataset,
        val_dataset,
        test_dataset=None,
        device=None,
        total_and_correct_func=get_total_and_correct,
        lrScheduler=None,
        isDataParallel:bool=False,
        isDistributedDataParallel:bool=False,
        isSpikingjelly12:bool=False,
        isSpikingjelly14:bool=False,
    ):
        '''
        训练:\n
        train_eval_s\n
        训练前函数:\n
        load_model, load_optimizer, load_lrScheduler, set_writer, set_stop_by_acc\n
        训练后函数:\n
        save_latest_checkpoint, save_best_checkpoint, calculate_model
        :param model:
        :param optimizer:
        :param criterion:
        :param train_loader:
        :param val_loader:
        :param test_loader:
        :param device: 若不指定, 则自动判断
        :param total_and_correct_func: 如何通过模型得到的 outputs, labels 计算 total, correct
        :param lrScheduler:
        :param isDataParallel: 是否启用多GPU
        :param isSpikingjelly12: 是否为SNN
        :param isSpikingjelly14: 是否为SNN
        '''
        ##### 检查冲突 #####
        assert not (isSpikingjelly12 and isSpikingjelly14), \
            "isSpikingjelly12 和 isSpikingjelly14 不能同时为True"
        assert not (isDataParallel and isDistributedDataParallel), \
            "isDataParallel 和 isDistributedDataParallel 不能同时为True"


        ##### 初始化参数 #####
        self.model = model.to("cpu")
        self.batch_size = batch_size

        self.train_dataset = train_dataset
        self.val_dataset = val_dataset
        self.test_dataset = test_dataset


        self.optimizer = optimizer
        self.criterion = criterion
        self.device = device if device else b_get_device()

        self.total_and_correct_func = total_and_correct_func
        self.lrScheduler = lrScheduler
        self.isDataParallel = isDataParallel
        self.isSpikingjelly12 = isSpikingjelly12
        self.isSpikingjelly14 = isSpikingjelly14

        ##### 初始化变量 #####
        self.epoch = 0
        self.writer: B_Writer = None
        self.gpu_dict: GPU_Dict = dict(
            total=0,
            max_used=0
        )
        # 记录数组
        self.train_loss_batches_lst = []
        self.train_loss_epoch_lst = []
        self.train_acc_lst = []
        self.val_acc_lst = []


        ##### 设置设备 #####
        # self.model.to(self.device)
        # DP
        if self.isDataParallel:
            if str(self.device) == str(torch.device("cuda")):
                if torch.cuda.device_count() > 1:
                    print(f"[set] 当前cuda数量:{torch.cuda.device_count()}, 使用多GPU训练")
                    self.model = nn.DataParallel(self.model)
                else:
                    print(f"[set] 当前cuda数量:{torch.cuda.device_count()}, 使用单GPU训练")


        ##### 其余设置 #####
        # early stop
        self._stop_by_acc = _Func()
        self._stop_by_acc_delta = _Func()
        self._stop_by_loss = _Func()
        self._stop_by_loss_delta = _Func()
        self._stop_by_overfitting = _Func()
        # early reload
        self._reload_by_loss = _Func()

        # save_temp
        self._save_best_during_train = None
        # save_best
        self._best_acc = 0
        self._best_model_state_dict = None
        self._best_optimizer_state_dict = None
        self._best_lrScheduler_state_dict = None
    def save_latest_checkpoint(self, path):
        '''
        字典checkpoint包含net, optimizer, lrScheduler
        '''
        parent_path = Path(path).parent
        os.makedirs(parent_path, exist_ok=True)

        checkpoint = {}
        if self.model:
            checkpoint['model'] = self.model.state_dict()
        if self.optimizer:
            checkpoint['optimizer'] = self.optimizer.state_dict()
        if self.lrScheduler:
            checkpoint['lrScheduler'] = self.lrScheduler.state_dict()

        torch.save(checkpoint, path)
        print(f"[save] latest_checkpoint 已保存到 {path}")

    def save_best_checkpoint(self, path):
        '''
        字典checkpoint包含net, optimizer, lrScheduler
        '''
        parent_path = Path(path).parent
        os.makedirs(parent_path, exist_ok=True)

        checkpoint = {}
        if self._best_model_state_dict:
            checkpoint['model'] = self._best_model_state_dict
        if self._best_optimizer_state_dict:
            checkpoint['optimizer'] = self._best_optimizer_state_dict
        if self._best_lrScheduler_state_dict:
            checkpoint['lrScheduler'] = self._best_lrScheduler_state_dict

        torch.save(checkpoint, path)
        print(f"[save] best_checkpoint 已保存到 {path}")
    def load_model(self, path):
        checkpoint = torch.load(path, map_location='cpu')
        model_state_dict = checkpoint['model']

        flag_model = isinstance(self.model, nn.DataParallel)
        flag_dict = list(model_state_dict.keys())[0].startswith('module.')
        if (not flag_model) and flag_dict:
            model_state_dict = {k[7:]: v for k, v in model_state_dict.items()}
        if flag_model and (not flag_dict):
            model_state_dict = {'module.' + k: v for k, v in model_state_dict.items()}

        self.model.load_state_dict(model_state_dict)
        self.model.to(self.device)
        print(f"[load] model 已从 {path} 加载")

    def load_optimizer(self, path):
        checkpoint = torch.load(path)
        optimizer_state_dict = checkpoint['optimizer']
        self.optimizer.load_state_dict(optimizer_state_dict)
        print(f"[load] optimizer 已从{path}加载")

    def load_lrScheduler(self, path):
        checkpoint = torch.load(path)
        lrScheduler_state_dict = checkpoint['lrScheduler']
        if self.lrScheduler is not None and lrScheduler_state_dict is not None:
            self.lrScheduler.load_state_dict(lrScheduler_state_dict)
            print(f"[load] lrScheduler 已从{path}加载")
        else:
            print(f"[load] path中的lrScheduler为None, 加载失败")

    def get_confusion_matrix(self, y_true, y_pred):
        from sklearn.metrics import confusion_matrix
        result = confusion_matrix(y_true, y_pred)
        return result

    def get_f1_score(self, y_true, y_pred, average='macro'):
        from sklearn.metrics import f1_score
        result = f1_score(y_true, y_pred, average=average)
        return result

    def set_writer1(self, path: Path|str, mode: Literal["a", "w"] = "a"):
        '''
        请在训练前设置set_writer
        '''
        self.writer = B_Writer(path, mode=mode, time_file=True)

        self.writer.toFile("[dataset] -> " + self.train_dataset.__class__.__name__, ifTime=False)
        self.writer.toFile("[batch_size] -> " + str(self.batch_size), ifTime=False)
        self.writer.toFile("[lr] -> " + str(self.optimizer.param_groups[0]['lr']), ifTime=False)
        self.writer.toFile("[criterion] -> " + str(self.criterion), ifTime=False)
        self.writer.toFile("[optimizer] -> " + str(self.optimizer), ifTime=False)
        if self.lrScheduler is not None:
            self.writer.toFile("[lrScheduler] -> " + str(self.lrScheduler), ifTime=False)
        self.writer.toFile("[model] -> " + str(self.model), ifTime=False)

        print(f'[set] 日志将保存到{path}')
        return self.writer

    def set_writer2(self, writer: B_Writer):
        '''
        请在训练前设置set_writer
        '''
        self.writer = writer

        self.writer.toFile("[dataset] -> " + self.train_dataset.__class__.__name__, ifTime=False)
        self.writer.toFile("[batch_size] -> " + str(self.batch_size), ifTime=False)
        self.writer.toFile("[lr] -> " + str(self.optimizer.param_groups[0]['lr']), ifTime=False)
        self.writer.toFile("[criterion] -> " + str(self.criterion), ifTime=False)
        self.writer.toFile("[optimizer] -> " + str(self.optimizer), ifTime=False)
        if self.lrScheduler is not None:
            self.writer.toFile("[lrScheduler] -> " + str(self.lrScheduler), ifTime=False)
        self.writer.toFile("[model] -> " + str(self.model), ifTime=False)

        print(f'[set] 日志将保存到{self.writer.path}')
        return self.writer

    def set_save_during_train(self, path: Path|str, rounds=10):
        '''
        请在训练前设置set_save_during_train
        :param path: 保存路径
        :param rounds: 每rounds次, 保存一次
        '''
        self._save_best_during_train = _saveBestDuringTrain(path, rounds)
        self._print_and_toWriter(f"[set] save_best_during_train")
    def set_stop_by_acc(self, rounds=10, max_acc=1, delta=0.01):
        '''
        请在训练前设置set_stop_by_acc
        :param rounds: 连续rounds次, val_acc < max_val_acc + delta, 则停止训练
        '''
        self._stop_by_acc.func = B_StopByAcc(rounds=rounds, max_acc=max_acc, delta=delta)
        self._print_and_toWriter(f"[set] stop_by_acc")
    def set_stop_by_overfitting(self, rounds=10, delta=0.1):
        '''
        请在训练前设置set_stop_by_overfitting
        :param rounds: 连续rounds次, train_acc - val_acc > delta, 则停止训练
        '''
        self._stop_by_overfitting.func = B_StopByOverfitting(rounds=rounds, delta=delta)
        self._print_and_toWriter(f"[set] stop_by_overfitting")
    def set_stop_by_acc_delta(self, rounds=10, delta=0.003):
        '''
        请在训练前设置set_stop_by_acc_delta
        :param rounds: 连续rounds次, |before_acc - val_acc| <= delta, 则停止训练
        '''
        self._stop_by_acc_delta.func = B_StopByAccDelta(rounds=rounds, delta=delta)
        self._print_and_toWriter(f"[set] stop_by_acc_delta")
    def set_stop_by_loss(self, rounds=10, delta=.0, target_loss=0.01):
        '''
        请在训练前设置set_stop_by_loss
        :param rounds: 连续rounds次, train_loss > min_train_loss + delta, 则停止训练
        '''
        self._stop_by_loss.func = B_StopByLoss(rounds=rounds, delta=delta, target=target_loss)
        self._print_and_toWriter(f"[set] stop_by_loss")
    def set_stop_by_loss_delta(self, rounds=10, delta=0.002):
        '''
        请在训练前设置set_stop_by_loss_delta
        :param rounds: 连续rounds次, |before_loss - now_loss| <= delta, 则停止训练
        '''
        self._stop_by_loss_delta.func = B_StopByLossDelta(rounds=rounds, delta=delta)
        self._print_and_toWriter(f"[set] stop_by_loss_delta")
    def set_reload_by_loss(self, max_reload_count=5, reload_rounds=10, delta=0.01):
        '''
        请在训练前设置set_reload_by_loss\n
        :param reload_rounds: 连续reload_rounds次都是train_loss > min_train_loss + delta
        '''
        self._reload_by_loss.func = B_ReloadByLoss(max_reload_count, reload_rounds, delta)
        self._print_and_toWriter(f"[set] reload_by_loss")

    def draw_loss_acc(self, path: Path|str, if_show=False, y_lim=True):
        """
        :param path: 如果以.csv结尾, 则保存为csv文件, 否则保存为图片
        :param if_show:
        :return:
        """
        from ..Bvisual import b_draw_loss_acc
        b_draw_loss_acc(
            train_loss_batches_lst=self.train_loss_batches_lst,
            train_acc_lst=self.train_acc_lst,
            val_acc_lst=self.val_acc_lst,
            path=path,
            if_show=if_show,
            y_lim=y_lim
        )


    def calculate_model(self, dataloader=None, model=None):
        '''
        如果不指定, 则用类内的
        :param dataloader: 默认self.val_loader
        :param model: 默认self.model
        :return: accuracy, inference_time, params, outputs_list, labels_list
        '''
        if dataloader==None:
            dataloader = self.val_loader
        if model==None:
            model = self.model
        model.eval()

        total = 0
        correct = 0
        outputs_list = []
        labels_list = []
        inference_time = []
        with torch.no_grad():
            for inputs, labels in dataloader:
                start_time = time.time()
                forward_out, labels, *args = self._forward(inputs, labels)
                end_time = time.time()

                self._spikingjelly_process()


                outputs_list.append(forward_out.cpu())
                labels_list.append(labels.cpu())

                inference_time.append(end_time - start_time)

                _, sample_total, sample_correct = self.total_and_correct_func(forward_out, labels)
                total += sample_total
                correct += sample_correct

        # 平均推理时间
        inference_time = sum(inference_time) / len(inference_time)
        # acc
        accuracy = correct / total
        # 参数量
        params = sum(p.numel() for p in model.parameters())

        info = f'[calc] accuracy: {accuracy:.3f}'
        self._print_and_toWriter(info)
        info = f'------ inference_time: {inference_time:.2e}s, params: {params / 1e3}K'
        self._print_and_toWriter(info)


        return accuracy, inference_time, params, outputs_list, labels_list

    def classify_unlabeled_data(self, dataloader) -> list: # todo
        '''
        返回 预测标签
        '''
        self.model.eval()
        labels = []
        with torch.no_grad():
            for elements in dataloader:
                if len(elements) == 2:
                    inputs, _ = elements
                else:
                    inputs = elements
                inputs = inputs.to(self.device)
                outputs = self.model(inputs)
                _, predicted = torch.max(outputs, 1)
                labels.extend(predicted.cpu())
                self._spikingjelly_process()
        return labels

    def classify_labeled_data(self, dataloader) -> (list, list, float): # todo
        '''
        返回 真实标签, 预测标签, acc
        '''
        self.model.eval()
        true_label = []
        pred_label = []
        with torch.no_grad():
            for inputs, labels in dataloader:
                inputs, labels = inputs.to(self.device), labels.to(self.device)
                outputs = self.model(inputs)
                _, predicted = torch.max(outputs, 1)
                true_label.extend(labels.cpu())
                pred_label.extend(predicted.cpu())
                self._spikingjelly_process()
        # acc
        acc = (np.array(true_label) == np.array(pred_label)).sum() / len(true_label)
        return true_label, pred_label, acc

    def train_eval_s(
            self,
            epochs,
            test: bool = False,
    ):
        world_size = torch.cuda.device_count()
        backend = self._get_backend()
        port = self._get_free_port()
        print(f"backend: {backend}, port: {port}")

        queue = mp.SimpleQueue()

        # 用 partial 包装实例方法
        mp.spawn(
            partial(
                self._train_eval_s,
                world_size=world_size, port=port, backend=backend, queue=queue,
                epochs=epochs, test=test
            ),
            nprocs=world_size,
            join=True
        )

        # 主进程接收 rank 0 的结果
        metrics = queue.get()
        self.train_acc_lst = metrics["train_acc_lst"]
        self.train_loss_epoch_lst = metrics["train_loss_epoch_lst"]
        self.train_loss_batches_lst = metrics["train_loss_batches_lst"]
        self.val_acc_lst = metrics["val_acc_lst"]

        self._best_acc = metrics["_best_acc"]
        self._best_model_state_dict = metrics["_best_model_state_dict"]
        # self._best_optimizer_state_dict = metrics["_best_optimizer_state_dict"]
        self._best_lrScheduler_state_dict = metrics["_best_lrScheduler_state_dict"]

    def _train_eval_s(
            self, rank, world_size, port, backend, queue,
            epochs,
            test: bool,
    ):
        '''
        :param epochs:
        :param test: 在传递test_loader后, 若为True, 则同时在测试集测试
        :return:
        '''
        # 初始化dataloader
        train_sampler = DistributedSampler(self.train_dataset, num_replicas=world_size, rank=rank, shuffle=True)
        train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, sampler=train_sampler)
        val_sampler = DistributedSampler(self.val_dataset, num_replicas=world_size, rank=rank, shuffle=False)
        val_loader = DataLoader(self.val_dataset, batch_size=self.batch_size, sampler=val_sampler)
        if test:
            test_sampler = DistributedSampler(self.test_dataset, num_replicas=world_size, rank=rank, shuffle=False)
            test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, sampler=test_sampler)
        # 初始化进程组
        dist.init_process_group(
            backend=backend,
            init_method=f"tcp://127.0.0.1:{port}",
            rank=rank,
            world_size=world_size
        )
        # 为了让每个进程也可复现，通常每个进程都会调用一次 torch.manual_seed(seed)
        torch.manual_seed(0)
        device = torch.device(f"cuda:{rank}")

        model = deepcopy(self.model).to(device)
        model = DDP(model, device_ids=[rank], find_unused_parameters=True)

        opt_class = type(self.optimizer)  # 比如 torch.optim.Adam
        opt_params = {k: v for k, v in self.optimizer.defaults.items()}  # 拿到超参数
        optimizer = opt_class(model.parameters(), **opt_params)

        for epoch in range(epochs):
            self.epoch = epoch
            train_sampler.set_epoch(epoch)
            val_sampler.set_epoch(epoch)
            if test:
                test_sampler.set_epoch(epoch)

            train_acc, train_loss, current_lr = self._train_once(rank, epoch, epochs, model, device, train_loader, optimizer)
            val_acc = self._eval_once(rank, model, device, val_loader, optimizer)
            if test:
                test_acc = self._test_once(rank, model, device, test_loader)
            if rank == 0:
                print() # 换行

            # 日志
            if self.writer is not None:
                # current_lr = optimizer.param_groups[0]['lr']
                info = f'Epoch [{epoch}/{epochs}], lr: {current_lr:.2e} | ' \
                       f'train_loss: {train_loss:.3f} | train_acc: {train_acc:.3f}, val_acc: {val_acc:.3f}'
                if test:
                    info += f', test_acc: {test_acc:.3f}'
                self.writer.toFile(info)
            # 保存模型
            if self._save_best_during_train is not None:
                if self._save_best_during_train():
                    self.save_best_checkpoint(self._save_best_during_train.path)
            # 早停and重加载
            match self._stop_and_reload(train_loss, train_acc, val_acc):
                case "break":
                    break
                case "continue":
                    pass

        if rank == 0:
            queue.put({
                "train_acc_lst": self.train_acc_lst,
                "train_loss_epoch_lst": self.train_loss_epoch_lst,
                "train_loss_batches_lst": self.train_loss_batches_lst,
                "val_acc_lst": self.val_acc_lst,

                "_best_acc": self._best_acc,
                "_best_model_state_dict": self._best_model_state_dict,
                # "_best_optimizer_state_dict": self._best_optimizer_state_dict,
                "_best_lrScheduler_state_dict": self._best_lrScheduler_state_dict,
            })

        dist.destroy_process_group()

    def _train_once(self, rank, epoch, epochs, model, device, train_loader, optimizer):
        if rank == 0:
            bar = B_Tqdm(range=len(train_loader))
        current_lr = optimizer.param_groups[0]['lr']

        model.train()
        correct = 0
        total = 0
        losses = 0
        for iter, (inputs, labels) in enumerate(train_loader):
            # 前向传播
            forward_out, labels, *args = self._forward(inputs, labels, model, device)
            # 反向传播
            loss = self._backward(forward_out, labels, optimizer, *args)

            # SNN
            self._spikingjelly_process(model)

            losses += loss.item()

            _, sample_total, sample_correct = self.total_and_correct_func(forward_out, labels)
            total += sample_total
            correct += sample_correct
            # 进度条 and 数据记录
            if rank == 0:
                bar.update(
                    1,
                    color=B_Color.BLUE,
                    appearance=B_Appearance.HIGHLIGHT,
                    prefix=f"Epoch [{epoch:0{len(str(epochs))}}/{epochs}]",
                    suffix=f"lr: {current_lr:.2e}, loss: {loss.item():.3f}"
                )
                self.train_loss_batches_lst.append(loss.item())

        accuracy = correct / total
        train_loss = losses / len(train_loader)
        if rank == 0:
            # 资源占用信息
            usage = ' '
            if device.type == 'cuda':
                gpu = b_get_gpu_nvidia()[rank]
                usage = f' (GPU[{rank}]: {gpu[-2]}/{gpu[-1]}) '
                if gpu[-2] > self.gpu_dict['max_used']:
                    self.gpu_dict['max_used'] = gpu[-2]
            elif device.type == 'cpu':
                # 获取cpu的使用率
                usage = ' (CPU) '

            # 打印信息
            print(f'Epoch [{epoch:0{len(str(epochs))}}/{epochs}]{usage}(train_loss: {train_loss:.3f}) train_Acc: {accuracy:.3f}', end='')
            self.train_acc_lst.append(accuracy)
            self.train_loss_epoch_lst.append(train_loss)

        # 更新学习率
        if self.lrScheduler:
            self.lrScheduler.step()

        return accuracy, train_loss, current_lr



    def _eval_once(self, rank, model, device, val_loader, optimizer):
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                # 前向传播
                outputs, labels, *args = self._forward(inputs, labels, model, device)

                self._spikingjelly_process(model)

                _, sample_total, sample_correct = self.total_and_correct_func(outputs, labels)
                total += sample_total
                correct += sample_correct

        accuracy = correct / total
        if rank == 0:
            # 记录accuracy
            self.val_acc_lst.append(accuracy)
            # 打印信息
            print(f', val_Acc: {accuracy:.3f}', end='')

            # 保存最优模型
            if accuracy > self._best_acc:
                self._best_acc = accuracy
                self._best_model_state_dict = copy.deepcopy(model.state_dict())
                self._best_optimizer_state_dict = copy.deepcopy(optimizer.state_dict())
                self._best_lrScheduler_state_dict = copy.deepcopy(self.lrScheduler.state_dict()) if self.lrScheduler else None

        return accuracy

    def _test_once(self, rank, model, device, test_loader):
        assert test_loader is not None, "test_loader is None"

        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in test_loader:
                # 前向传播
                outputs, labels, *args = self._forward(inputs, labels, model, device)

                self._spikingjelly_process(model)

                _, sample_total, sample_correct = self.total_and_correct_func(outputs, labels)
                total += sample_total
                correct += sample_correct

        # 记录accuracy
        accuracy = correct / total
        if rank == 0:
            # 打印信息
            print(f', test_Acc: {accuracy:.3f}', end='')
        return accuracy

    ##### 自由修改接口 #####
    def get_metric_lists(self):
        '''
        获取指标列表
        '''
        result = (
            self.train_loss_batches_lst,
            self.train_loss_epoch_lst,
            self.train_acc_lst,
            self.val_acc_lst
        )
        return result

    def get_GPU_dict(self) -> GPU_Dict:
        return self.gpu_dict

    def get_writer(self) -> B_Writer:
        if self.writer is None:
            raise Exception("writer is None")
        return self.writer

    def _forward(self, inputs, labels, model, device):
        '''
        如果需要多卡训练，则forward_out需要是单个tensor，或者使用dict包裹

        如果是单卡训练，则可以return多个值，第三个值开始作为*args
        '''
        inputs, labels = inputs.to(device), labels.to(device)
        forward_out = model(inputs)
        return forward_out, labels

    def _backward(self, forward_out, labels, optimizer, *args):
        loss = self.criterion(forward_out, labels)
        optimizer.zero_grad()  # 清零梯度
        loss.backward()  # 计算梯度
        optimizer.step()  # 更新参数
        return loss



    ##### 杂项 #####

    def _spikingjelly_process(self, model):
        if self.isSpikingjelly14:
            from spikingjelly.activation_based import functional
            functional.reset_net(model)
        elif self.isSpikingjelly12:
            from spikingjelly.clock_driven import functional
            functional.reset_net(model)

    def _print_and_toWriter(self, info: str, if_print=True):
        if if_print:
            print(info)
        # 若恰有writer则写入
        if self.writer is not None:
            self.writer.toFile(info)
    def _stop_and_reload(self, train_loss, train_acc, val_acc):
        ##### 早停
        if self._stop_by_acc(val_acc=val_acc):
            info = f'[stop] 模型在连续{self._stop_by_acc.func.rounds}个epoch内停滞, 触发stop_by_acc'
            self._print_and_toWriter(info)
            info = "[stop] " + str(self._stop_by_acc.func.cnt_list)
            self._print_and_toWriter(info, if_print=False)
            return "break"
        if self._stop_by_acc_delta(val_acc=val_acc):
            info = f'[stop] 模型在连续{self._stop_by_acc_delta.func.rounds}个epoch内过拟合, 触发stop_by_acc_delta'
            self._print_and_toWriter(info)
            info = "[stop] " + str(self._stop_by_acc_delta.func.cnt_list)
            self._print_and_toWriter(info, if_print=False)
            return "break"
        if self._stop_by_loss(train_loss=train_loss):
            info = f'[stop] 模型在连续{self._stop_by_loss.func.rounds}个epoch内停滞, 触发stop_by_loss'
            self._print_and_toWriter(info)
            info = "[stop] " + str(self._stop_by_loss.func.cnt_list)
            self._print_and_toWriter(info, if_print=False)
            return "break"
        if self._stop_by_loss_delta(train_loss=train_loss):
            info = f'[stop] 模型在连续{self._stop_by_loss_delta.func.rounds}个epoch内停滞, 触发stop_by_loss_delta'
            self._print_and_toWriter(info)
            info = "[stop] " + str(self._stop_by_loss_delta.func.cnt_list)
            self._print_and_toWriter(info, if_print=False)
            return "break"
        ##### 过拟合
        if self._stop_by_overfitting(train_acc=train_acc, val_acc=val_acc):
            info = f'[stop] 模型在连续{self._stop_by_overfitting.func.rounds}个epoch内过拟合, 触发stop_by_overfitting'
            self._print_and_toWriter(info)
            info = "[stop] " + str(self._stop_by_overfitting.func.cnt_list)
            self._print_and_toWriter(info, if_print=False)
            return "break"
        ##### 重加载
        match self._reload_by_loss(train_loss=train_loss):
            case 'normal':
                pass
            case 'reload':
                info = f'模型触发reload_by_loss(第{self._reload_by_loss.func.cnt_reload}次加载)'
                self._print_and_toWriter(info)
                # 加载
                self.model.load_state_dict(self._best_model_state_dict)
                self.optimizer.load_state_dict(self._best_optimizer_state_dict)
                if self.lrScheduler is not None:
                    self.lrScheduler.load_state_dict(self._best_lrScheduler_state_dict)
                self.calculate_model()
        return "continue"

    #### DDP
    @staticmethod
    def _get_free_port():
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.bind(('', 0))  # 系统自动分配一个空闲端口
        addr, port = s.getsockname()
        s.close()
        return port
    @staticmethod
    def _get_backend():
        system = platform.system()
        if system != "Windows":
            backend = "nccl"
        else:
            backend = "gloo"
        return backend