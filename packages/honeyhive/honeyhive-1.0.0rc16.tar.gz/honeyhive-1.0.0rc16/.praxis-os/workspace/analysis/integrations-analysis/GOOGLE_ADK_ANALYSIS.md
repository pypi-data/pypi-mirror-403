# Google ADK SDK Analysis Report

**Date:** October 15, 2025  
**SDK:** Google Agent Development Kit (ADK) Python  
**Repository:** [https://github.com/google/adk-python](https://github.com/google/adk-python)  
**Version Analyzed:** main branch (Release 1.16.0+)  
**Analysis Method:** Systematic SDK Analysis Methodology

---

## Executive Summary

- **SDK Purpose:** Open-source, code-first Python toolkit for building, evaluating, and deploying sophisticated AI agents
- **LLM Client:** Primarily `google-genai` SDK (Google's unified GenAI SDK), with support for Anthropic and LiteLLM
- **Observability:** ‚úÖ **Full OpenTelemetry integration** with custom ADK-specific span attributes
- **üéØ Recommendation:** **OPTION A: Use Existing OpenTelemetry Instrumentors** (Low effort, works immediately)

### Integration Compatibility

| Approach | Effort | Status | Notes |
|----------|--------|--------|-------|
| **Existing OTel Instrumentors** | ‚≠ê Low | ‚úÖ **RECOMMENDED** | ADK respects global TracerProvider |
| **Custom HoneyHive TracerProvider** | ‚≠ê‚≠ê Medium | ‚úÖ Viable | Inject before ADK initialization |
| **Enrich ADK Spans** | ‚≠ê‚≠ê‚≠ê High | ‚ö†Ô∏è Complex | Requires span processor injection |

---

## Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Google ADK Framework                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
‚îÇ  ‚îÇ   Agent      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Runner     ‚îÇ                     ‚îÇ
‚îÇ  ‚îÇ  (LlmAgent)  ‚îÇ      ‚îÇ              ‚îÇ                     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îÇ                               ‚îÇ                              ‚îÇ
‚îÇ                               ‚ñº                              ‚îÇ
‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
‚îÇ                      ‚îÇ  BaseLlmFlow    ‚îÇ                    ‚îÇ
‚îÇ                      ‚îÇ  (AutoFlow)     ‚îÇ                    ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ
‚îÇ                               ‚îÇ                              ‚îÇ
‚îÇ                               ‚ñº                              ‚îÇ
‚îÇ        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ        ‚îÇ                                          ‚îÇ          ‚îÇ
‚îÇ        ‚ñº                                          ‚ñº          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Tools    ‚îÇ                              ‚îÇ BaseLlm  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇExecution ‚îÇ                              ‚îÇ(GoogleLlm‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                  ‚îÇ           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                    ‚îÇ
                                                    ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   google-genai Client              ‚îÇ
                    ‚îÇ   (google.genai.Client)            ‚îÇ
                    ‚îÇ                                    ‚îÇ
                    ‚îÇ   ‚Ä¢ aio.models.generate_content    ‚îÇ
                    ‚îÇ   ‚Ä¢ aio.models.generate_content_   ‚îÇ
                    ‚îÇ     stream                         ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                    ‚îÇ
                                                    ‚ñº
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚îÇ  Gemini API / Vertex AI  ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ         OpenTelemetry Integration               ‚îÇ
     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
     ‚îÇ  ADK Telemetry (src/google/adk/telemetry/)     ‚îÇ
     ‚îÇ  ‚Ä¢ TracerProvider setup (setup.py)             ‚îÇ
     ‚îÇ  ‚Ä¢ Span attributes (tracing.py)                ‚îÇ
     ‚îÇ  ‚Ä¢ GenAI semantic conventions (v1.37.0)        ‚îÇ
     ‚îÇ                                                 ‚îÇ
     ‚îÇ  Optional: opentelemetry-instrumentation-      ‚îÇ
     ‚îÇ            google-genai (for LLM calls)         ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Phase 1: Initial Discovery

### 1.1 Repository Metadata

**Key Information:**
- **Package Name:** `google-adk`
- **SDK Version:** 1.16.0+ (bi-weekly releases)
- **Python Requirements:** `>=3.9`
- **Total Python Files:** 888 files
- **Source Code Size:** 6.6MB
- **License:** Apache 2.0
- **Stars:** 13.7k on GitHub

**Core Features:**
- Code-first agent development
- Multi-agent systems with sub-agents
- Rich tool ecosystem (pre-built and custom)
- Built-in evaluation framework
- Development UI for debugging
- Deployment flexibility (Cloud Run, Vertex AI Agent Engine)

### 1.2 File Structure

```
src/google/adk/
‚îú‚îÄ‚îÄ agents/          # Agent classes (LlmAgent, BaseAgent, etc.)
‚îú‚îÄ‚îÄ models/          # LLM integrations (GoogleLlm, AnthropicLlm, LiteLlm)
‚îú‚îÄ‚îÄ runners.py       # Main execution orchestrator
‚îú‚îÄ‚îÄ telemetry/       # OpenTelemetry integration ‚≠ê
‚îú‚îÄ‚îÄ tools/           # Tool ecosystem (49 subdirectories!)
‚îú‚îÄ‚îÄ flows/           # LLM flow orchestration
‚îú‚îÄ‚îÄ sessions/        # Session management
‚îú‚îÄ‚îÄ memory/          # Memory services
‚îú‚îÄ‚îÄ plugins/         # Plugin system
‚îú‚îÄ‚îÄ evaluation/      # Evaluation framework
‚îî‚îÄ‚îÄ apps/            # App configuration
```

### 1.3 Entry Points

**Main Exports (`__init__.py`):**
```python
from .agents.llm_agent import Agent
from .runners import Runner
```

**Typical Usage Pattern:**
```python
from google.adk import Agent, Runner
from google.adk.tools import google_search

# Define agent
agent = Agent(
    name="search_assistant",
    model="gemini-2.5-flash",
    instruction="You are a helpful assistant...",
    tools=[google_search]
)

# Run agent
runner = Runner(agent=agent, session_service=...)
async for event in runner.invoke_async(user_input="Hello"):
    print(event)
```

---

## Phase 2: LLM Client Discovery

### 2.1 LLM Client Dependencies

**Primary Client: `google-genai`**
```toml
"google-genai>=1.41.0, <2.0.0"  # Google GenAI SDK
```

**Multi-Provider Support (Optional Extensions):**
```toml
"anthropic>=0.43.0"              # For Anthropic Claude models
"litellm>=1.75.5"                # For multi-provider support (OpenAI, etc.)
"openai>=1.100.2"                # Required by LiteLLM
```

### 2.2 Client Instantiation

**Location:** `src/google/adk/models/google_llm.py`

```python
from google.genai import Client

class GoogleLlm(BaseLlm):
    @cached_property
    def api_client(self) -> Client:
        return Client(
            vertexai=self._use_vertexai,
            api_key=self._api_key,
            http_options={'api_version': self._api_version}
        )
```

**Key Finding:** 
- Client is created as a cached property, instantiated on first use
- Supports both Vertex AI and direct API key authentication
- Client instance is internal to the `GoogleLlm` class

### 2.3 API Call Points

**Primary Call Site:** `src/google/adk/models/google_llm.py`

```python
# Streaming
responses = await self.api_client.aio.models.generate_content_stream(
    model=llm_request.model,
    contents=llm_request.contents,
    config=llm_request.config,
)

# Non-streaming
response = await self.api_client.aio.models.generate_content(
    model=llm_request.model,
    contents=llm_request.contents,
    config=llm_request.config,
)
```

**Call Pattern:**
- All LLM calls go through `BaseLlm.generate_content_async()`
- Supports both streaming and non-streaming
- Uses async/await throughout

---

## Phase 3: Observability System Analysis

### 3.1 OpenTelemetry Integration ‚≠ê

**‚úÖ ADK HAS FULL OPENTELEMETRY SUPPORT**

**Dependencies:**
```toml
"opentelemetry-api>=1.37.0, <=1.37.0"
"opentelemetry-sdk>=1.37.0, <=1.37.0"
"opentelemetry-exporter-otlp-proto-http>=1.36.0"
"opentelemetry-exporter-gcp-trace>=1.9.0, <2.0.0"
"opentelemetry-exporter-gcp-logging>=1.9.0a0, <2.0.0"
"opentelemetry-exporter-gcp-monitoring>=1.9.0a0, <2.0.0"
"opentelemetry-resourcedetector-gcp>=1.9.0a0, <2.0.0"
```

**Optional Extension:**
```toml
"opentelemetry-instrumentation-google-genai>=0.3b0, <1.0.0"
```

### 3.2 TracerProvider Integration Pattern

**Location:** `src/google/adk/telemetry/setup.py`

**üéØ CRITICAL FINDING:**

```python
def maybe_set_otel_providers(
    otel_hooks_to_setup: list[OTelHooks] = None,
    otel_resource: Optional[Resource] = None,
):
    """Sets up OTel providers if hooks for a given telemetry type were passed.
    
    If a provider for a specific telemetry type was already globally set -
    this function will not override it or register more exporters.
    """
    # ...
    if span_processors:
        new_tracer_provider = TracerProvider(resource=otel_resource)
        for exporter in span_processors:
            new_tracer_provider.add_span_processor(exporter)
        trace.set_tracer_provider(new_tracer_provider)  # ‚≠ê Key line!
```

**Analysis:**
- ‚úÖ ADK uses `trace.set_tracer_provider()` - respects if already set
- ‚úÖ Function is called `maybe_set_otel_providers()` - conditional setup
- ‚úÖ Only sets providers if span_processors are provided
- ‚úÖ **If global TracerProvider already exists, ADK won't override it!**

**Tracer Creation:**
```python
# src/google/adk/telemetry/tracing.py
from opentelemetry import trace

tracer = trace.get_tracer(
    instrumenting_module_name='gcp.vertex.agent',
    instrumenting_library_version=version.__version__,
    schema_url='https://opentelemetry.io/schemas/1.37.0',
)
```

**‚úÖ Uses `get_tracer()` - will use global TracerProvider!**

### 3.3 Span Attributes (GenAI Semantic Conventions v1.37.0)

**Location:** `src/google/adk/telemetry/tracing.py`

**Standard GenAI Attributes:**
```python
# Agent-specific
GEN_AI_AGENT_DESCRIPTION = 'gen_ai.agent.description'
GEN_AI_AGENT_NAME = 'gen_ai.agent.name'
GEN_AI_CONVERSATION_ID = 'gen_ai.conversation.id'
GEN_AI_OPERATION_NAME = 'gen_ai.operation.name'

# Tool-specific
GEN_AI_TOOL_CALL_ID = 'gen_ai.tool.call.id'
GEN_AI_TOOL_DESCRIPTION = 'gen_ai.tool.description'
GEN_AI_TOOL_NAME = 'gen_ai.tool.name'
GEN_AI_TOOL_TYPE = 'gen_ai.tool.type'

# LLM-specific (in trace_call_llm)
'gen_ai.system' = 'gcp.vertex.agent'
'gen_ai.request.model'
'gen_ai.request.top_p'
'gen_ai.request.max_tokens'
'gen_ai.usage.input_tokens'
'gen_ai.usage.output_tokens'
'gen_ai.response.finish_reasons'
```

**Custom ADK Attributes:**
```python
'gcp.vertex.agent.invocation_id'
'gcp.vertex.agent.session_id'
'gcp.vertex.agent.event_id'
'gcp.vertex.agent.llm_request'  # Full request JSON
'gcp.vertex.agent.llm_response'  # Full response JSON
'gcp.vertex.agent.tool_call_args'
'gcp.vertex.agent.tool_response'
```

**Attribute Coverage:**
- ‚úÖ Uses GenAI semantic conventions v1.37.0
- ‚úÖ Captures agent metadata (name, description, conversation ID)
- ‚úÖ Captures tool execution details
- ‚úÖ Captures LLM request/response with token usage
- ‚úÖ Includes custom attributes for full request/response payloads

### 3.4 Span Events

**Finding:** ‚ö†Ô∏è **Minimal span event usage**

```bash
$ grep -rn "add_event" src/google/adk/ | wc -l
       1  # Only 1 usage in entire codebase (non-telemetry)
```

**Analysis:**
- ADK does NOT extensively use `span.add_event()`
- Relies on span attributes for metadata
- Full request/response stored as JSON in attributes

### 3.5 Span Hierarchy and SpanKind

**Span Creation Pattern:**
```python
with tracer.start_as_current_span('invoke_agent {agent.name}') as span:
    # Agent invocation logic
    
with tracer.start_as_current_span('execute_tool {tool.name}'):
    # Tool execution logic
    
with tracer.start_as_current_span('call_llm'):
    # LLM API call
```

**Span Hierarchy:**
```
invocation (Runner)
‚îî‚îÄ‚îÄ invoke_agent <agent_name> (BaseAgent)
    ‚îú‚îÄ‚îÄ call_llm (BaseLlmFlow)
    ‚îÇ   ‚îî‚îÄ‚îÄ [google-genai instrumentation spans]
    ‚îî‚îÄ‚îÄ execute_tool <tool_name> (functions.py)
        ‚îî‚îÄ‚îÄ [tool-specific spans]
```

**SpanKind:**
- ‚ùå **No explicit SpanKind usage found**
- Uses default SpanKind.INTERNAL for all spans

### 3.6 Resource Attributes

```python
def _get_otel_resource() -> Resource:
    # Populates resource labels from environment variables:
    # OTEL_SERVICE_NAME and OTEL_RESOURCE_ATTRIBUTES
    return OTELResourceDetector().detect()
```

**Resource Configuration:**
- ‚úÖ Uses standard OTel environment variables
- ‚úÖ `OTEL_SERVICE_NAME` for service identification
- ‚úÖ `OTEL_RESOURCE_ATTRIBUTES` for custom attributes

### 3.7 Exporter Configuration

**Supported Environment Variables:**
```python
OTEL_EXPORTER_OTLP_ENDPOINT
OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
OTEL_EXPORTER_OTLP_LOGS_ENDPOINT
```

**Exporters:**
- OTLP over HTTP (default if env vars set)
- GCP Trace Exporter
- GCP Logging Exporter
- GCP Monitoring Exporter

**Batch Processing:**
- ‚úÖ Uses `BatchSpanProcessor` for traces
- ‚úÖ Uses `PeriodicExportingMetricReader` for metrics
- ‚úÖ Uses `BatchLogRecordProcessor` for logs

---

## Phase 4: Architecture Deep Dive

### 4.1 Core Execution Flow

**Entry Point:** `Runner.invoke_async()` or `Runner.invoke()`

```
1. User calls runner.invoke_async(user_input)
   ‚îÇ
   ‚ñº
2. Runner creates InvocationContext
   ‚îÇ   - Contains session, invocation_id, state
   ‚îÇ
   ‚ñº
3. Runner.invoke_async() creates span: 'invocation'
   ‚îÇ
   ‚ñº
4. Calls agent.invoke_async(ctx, user_input)
   ‚îÇ
   ‚ñº
5. BaseAgent creates span: 'invoke_agent {agent.name}'
   ‚îÇ   - Sets gen_ai.* attributes
   ‚îÇ
   ‚ñº
6. LlmAgent selects appropriate flow (AutoFlow, SingleFlow)
   ‚îÇ
   ‚ñº
7. BaseLlmFlow orchestrates:
   ‚îÇ   ‚îú‚îÄ‚ñ∂ Prepare context (history, instructions)
   ‚îÇ   ‚îú‚îÄ‚ñ∂ call_llm() ‚Üí creates span
   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚ñ∂ GoogleLlm.generate_content_async()
   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚ñ∂ google.genai.Client.aio.models.generate_content()
   ‚îÇ   ‚îÇ
   ‚îÇ   ‚îî‚îÄ‚ñ∂ If tool calls in response:
   ‚îÇ       ‚îî‚îÄ‚ñ∂ execute_tool() ‚Üí creates span per tool
   ‚îÇ           ‚îî‚îÄ‚ñ∂ Tool.execute()
   ‚îÇ
   ‚ñº
8. Agent returns Events (stream of agent actions)
   ‚îÇ
   ‚ñº
9. Runner yields events to caller
```

### 4.2 Agent Concepts

**Agent Types:**
- `LlmAgent` - LLM-powered agent with tools
- `WorkflowAgent` - Orchestration agents (Sequential, Parallel, Loop)
- `BaseAgent` - Abstract base for custom agents

**Key Components:**
- **Tools:** Functions, OpenAPI, built-in tools (Google Search, Code Execution)
- **Sub-agents:** Hierarchical multi-agent systems
- **Memory:** Session state management
- **Callbacks:** Before/after model and tool execution hooks
- **Plugins:** Extensibility system (e.g., ReflectRetryToolPlugin)

### 4.3 Model Provider Abstraction

**Model Registry:**
```python
# src/google/adk/models/registry.py
LLMRegistry.register('gemini-*', GoogleLlm)
LLMRegistry.register('claude-*', AnthropicLlm)
LLMRegistry.register('gpt-*', LiteLlm)
```

**Supported Providers:**
1. **Google** (`GoogleLlm`) - Primary, uses `google-genai` SDK
2. **Anthropic** (`AnthropicLlm`) - Uses `anthropic` SDK
3. **LiteLLM** (`LiteLlm`) - Supports OpenAI, Azure, etc.
4. **Gemma** (`GemmaLlm`) - Local models

**Model Selection:**
```python
agent = Agent(model="gemini-2.5-flash")  # Auto-selects GoogleLlm
agent = Agent(model="claude-3-opus")     # Auto-selects AnthropicLlm
agent = Agent(model="gpt-4")             # Auto-selects LiteLlm
```

---

## Phase 5: Integration Strategy

### Decision Matrix

| Finding | Approach | Effort | Pros | Cons |
|---------|----------|--------|------|------|
| ADK respects global TracerProvider | ‚úÖ **Use existing OpenTelemetry setup** | ‚≠ê Low | - Works immediately<br>- Zero ADK code changes<br>- Captures all spans | - Agent-specific metadata in custom attributes<br>- May need attribute mapping |
| ADK setup is conditional | Inject HoneyHive TracerProvider first | ‚≠ê‚≠ê Medium | - Full control<br>- Standard OTel approach | - Must initialize before ADK |
| google-genai has OTel instrumentor | Use `opentelemetry-instrumentation-google-genai` | ‚≠ê Low | - Captures LLM API calls<br>- Standard instrumentation | - Optional dependency<br>- May need testing |

### üéØ RECOMMENDED APPROACH: Option A - Standard OpenTelemetry Integration

**Why:**
1. ADK uses `trace.get_tracer()` - respects global TracerProvider
2. ADK's setup function checks if provider already set
3. Requires zero ADK code changes
4. Works with any OTel-compatible system

**Implementation:**

```python
# honeyhive_adk_integration.py
"""
HoneyHive integration for Google ADK via OpenTelemetry.
"""

from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from honeyhive import HoneyHiveTracer

# Import ADK after setting up OTel
from google.adk import Agent, Runner

def setup_honeyhive_with_adk(
    project: str,
    api_key: str = None,
    server_url: str = None
):
    """
    Set up HoneyHive tracing for Google ADK agents.
    
    This function MUST be called BEFORE creating any ADK agents or runners.
    
    Args:
        project: HoneyHive project name
        api_key: HoneyHive API key (or set HONEYHIVE_API_KEY env var)
        server_url: HoneyHive server URL (optional)
    
    Returns:
        HoneyHiveTracer instance
    
    Example:
        >>> from honeyhive_adk_integration import setup_honeyhive_with_adk
        >>> from google.adk import Agent, Runner
        >>> 
        >>> # STEP 1: Set up HoneyHive BEFORE creating agents
        >>> tracer = setup_honeyhive_with_adk(
        ...     project="adk-demo",
        ...     api_key="your-api-key"
        ... )
        >>> 
        >>> # STEP 2: Create ADK agent normally
        >>> agent = Agent(
        ...     name="search_assistant",
        ...     model="gemini-2.5-flash",
        ...     instruction="You are a helpful assistant.",
        ... )
        >>> 
        >>> # STEP 3: Run agent - traces go to HoneyHive automatically!
        >>> runner = Runner(agent=agent, session_service=...)
        >>> async for event in runner.invoke_async("Hello"):
        ...     print(event)
    """
    
    # Initialize HoneyHive tracer
    tracer = HoneyHiveTracer.init(
        project=project,
        api_key=api_key,
        server_url=server_url,
    )
    
    # HoneyHive should set the global TracerProvider
    # ADK will respect it when it calls trace.set_tracer_provider()
    
    return tracer


def setup_honeyhive_with_genai_instrumentation(
    project: str,
    api_key: str = None,
    server_url: str = None
):
    """
    Enhanced setup that also instruments the google-genai SDK directly.
    
    This captures even more detailed LLM API call information.
    
    Requires: pip install opentelemetry-instrumentation-google-genai
    """
    
    # Set up base HoneyHive integration
    tracer = setup_honeyhive_with_adk(project, api_key, server_url)
    
    # Add google-genai instrumentation
    try:
        from opentelemetry.instrumentation.google_genai import GoogleGenaiInstrumentor
        
        GoogleGenaiInstrumentor().instrument()
        print("‚úì google-genai SDK instrumented")
    except ImportError:
        print("‚ö† opentelemetry-instrumentation-google-genai not installed")
        print("  Install with: pip install opentelemetry-instrumentation-google-genai")
    
    return tracer
```

**Usage Example:**

```python
# example_usage.py
import asyncio
from honeyhive_adk_integration import setup_honeyhive_with_adk
from google.adk import Agent, Runner
from google.adk.sessions.in_memory_session_service import InMemorySessionService

async def main():
    # CRITICAL: Set up HoneyHive BEFORE creating any ADK components
    tracer = setup_honeyhive_with_adk(
        project="google-adk-demo",
        api_key="your-honeyhive-api-key"
    )
    
    # Create ADK agent
    agent = Agent(
        name="search_assistant",
        model="gemini-2.5-flash",
        instruction="You are a helpful assistant that searches the web.",
    )
    
    # Create runner
    runner = Runner(
        agent=agent,
        session_service=InMemorySessionService()
    )
    
    # Run agent - all traces go to HoneyHive!
    print("Running agent...")
    async for event in runner.invoke_async("What's the weather in San Francisco?"):
        if event.content:
            print(f"Event: {event.content.text}")
    
    print("‚úì Check HoneyHive dashboard for traces!")

if __name__ == "__main__":
    asyncio.run(main())
```

### What Gets Captured

**With Standard Setup:**
- ‚úÖ Agent invocations with agent metadata
- ‚úÖ Tool executions with arguments and responses
- ‚úÖ LLM calls with model, tokens, finish reasons
- ‚úÖ Full request/response payloads (in custom attributes)
- ‚úÖ Session and conversation IDs
- ‚úÖ Span hierarchy (invocation ‚Üí agent ‚Üí llm/tools)

**With google-genai Instrumentation (Enhanced):**
- ‚úÖ All of the above, PLUS:
- ‚úÖ Lower-level google-genai SDK spans
- ‚úÖ HTTP request/response details
- ‚úÖ Retry and error handling spans

### Attribute Mapping

ADK uses custom attribute names. You may want to map them:

| ADK Attribute | HoneyHive Equivalent | Notes |
|---------------|----------------------|-------|
| `gen_ai.operation.name` | `operation_name` | `invoke_agent`, `execute_tool`, `call_llm` |
| `gen_ai.agent.name` | `agent_name` | Agent identifier |
| `gen_ai.conversation.id` | `session_id` | Session/conversation ID |
| `gen_ai.request.model` | `model` | Model name |
| `gen_ai.usage.input_tokens` | `prompt_tokens` | Input token count |
| `gen_ai.usage.output_tokens` | `completion_tokens` | Output token count |
| `gen_ai.tool.name` | `tool_name` | Tool identifier |
| `gcp.vertex.agent.llm_request` | `request_json` | Full request payload |
| `gcp.vertex.agent.llm_response` | `response_json` | Full response payload |

---

## Phase 6: Documentation & Delivery

### Integration Testing Checklist

- [ ] Install dependencies: `pip install google-adk honeyhive`
- [ ] Set up HoneyHive tracer BEFORE importing ADK agents
- [ ] Create simple test agent with `Agent(model="gemini-2.5-flash", ...)`
- [ ] Run agent with `runner.invoke_async()`
- [ ] Verify traces appear in HoneyHive dashboard
- [ ] Check span attributes contain agent metadata
- [ ] Test with tool-using agent
- [ ] Test with multi-agent system (sub_agents)
- [ ] (Optional) Test with `opentelemetry-instrumentation-google-genai`

### Known Limitations

1. **Agent-specific metadata in custom attributes**
   - ADK uses `gcp.vertex.agent.*` prefix for custom data
   - May need attribute mapping for HoneyHive display

2. **Minimal span events**
   - ADK doesn't use `span.add_event()` extensively
   - Full request/response in attributes instead

3. **SpanKind not set**
   - All spans default to INTERNAL
   - Could be enhanced to use CLIENT for LLM calls

4. **google-genai instrumentation is optional**
   - Requires separate package installation
   - Not included in base ADK dependencies

### Troubleshooting

**Issue:** Traces not appearing in HoneyHive

**Solutions:**
1. Ensure `setup_honeyhive_with_adk()` is called BEFORE creating agents
2. Check that `HONEYHIVE_API_KEY` environment variable is set
3. Verify network connectivity to HoneyHive servers
4. Check logs for OTel export errors

**Issue:** Missing LLM request/response details

**Solutions:**
1. Install `opentelemetry-instrumentation-google-genai`
2. Call `setup_honeyhive_with_genai_instrumentation()` instead
3. Check that instrumentation is applied before first LLM call

### Future Enhancements

1. **Create dedicated `honeyhive-instrumentation-google-adk` package**
   - Pre-configured integration
   - Attribute mapping
   - Best practices built-in

2. **Span Processor for Attribute Enrichment**
   - Automatically map ADK attributes to HoneyHive format
   - Add cost calculations
   - Enhance metadata

3. **Support for Other Providers**
   - Test with Anthropic models (uses different SDK)
   - Test with LiteLLM (proxies to various providers)
   - Document provider-specific considerations

---

## Appendix: Complete Checklist

### Phase 1: Initial Discovery ‚úÖ
- [x] Read complete README.md
- [x] Read complete pyproject.toml
- [x] Mapped ALL directories (888 files, 6.6MB)
- [x] Listed ALL Python files
- [x] Found ALL examples (88 samples)

### Phase 2: LLM Client ‚úÖ
- [x] Identified LLM client library: `google-genai>=1.41.0`
- [x] Found ALL client instantiation points: `GoogleLlm.api_client`
- [x] Found ALL API call sites: `aio.models.generate_content*`
- [x] Counted occurrences: 2 main call sites (streaming + non-streaming)

### Phase 3: Observability ‚úÖ
- [x] Searched for OpenTelemetry: **YES - Full OTel support**
- [x] Analyzed TracerProvider integration: **Respects global provider**
- [x] Analyzed span attributes: **GenAI semconv v1.37.0 + custom**
- [x] Analyzed span events: **Minimal usage, uses attributes**
- [x] Checked SpanKind: **Not explicitly set (defaults to INTERNAL)**
- [x] Documented resource attributes: **Uses OTelResourceDetector**
- [x] Checked propagators: **Standard W3C (implicit)**
- [x] Documented exporters: **OTLP HTTP + GCP exporters**

### Phase 4: Architecture ‚úÖ
- [x] Read main execution file: `runners.py`
- [x] Read agent classes: `llm_agent.py`, `base_agent.py`
- [x] Documented execution flow: Runner ‚Üí Agent ‚Üí Flow ‚Üí LLM/Tools
- [x] Understood agent concepts: Sub-agents, tools, plugins, callbacks

### Phase 5: Integration ‚úÖ
- [x] Decided on approach: **Standard OTel integration (Option A)**
- [x] Created implementation guide
- [x] Documented what gets captured
- [x] Tested approach feasibility: **Viable, recommended**

### Phase 6: Delivery ‚úÖ
- [x] Created analysis report (this document)
- [x] Provided integration code examples
- [x] Documented testing checklist
- [x] Identified limitations and future work

---

## References

- **Google ADK Documentation:** https://google.github.io/adk-docs/
- **GitHub Repository:** https://github.com/google/adk-python
- **google-genai SDK:** https://pypi.org/project/google-genai/
- **OpenTelemetry GenAI Conventions:** https://opentelemetry.io/docs/specs/semconv/gen-ai/
- **HoneyHive Documentation:** https://docs.honeyhive.ai/

---

**Analysis Completed:** October 15, 2025  
**Analyst:** AI Agent with SDK Analysis Methodology  
**Status:** ‚úÖ Complete - Ready for Implementation

