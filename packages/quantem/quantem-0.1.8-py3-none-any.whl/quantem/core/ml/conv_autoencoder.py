from typing import Callable, Literal

import torch
import torch.nn as nn
import torch.nn.functional as F

from .activation_functions import get_activation_function
from .blocks import Conv2dBlock, Upsample2dBlock, complex_pool, passfunc


class ConvAutoencoder2d(nn.Module):
    """Convolutional autoencoder for 4DSTEM diffraction pattern analysis."""

    def __init__(
        self,
        input_size: int | tuple[int, int],
        input_channels: int = 1,
        latent_dim: int = 128,
        start_filters: int = 16,
        num_layers: int = 4,
        num_per_layer: int = 2,
        dtype: torch.dtype = torch.float32,
        dropout: float = 0.0,
        activation: str | Callable = "relu",
        final_activation: str | Callable = "relu",
        use_batchnorm: bool = True,
        latent_normalization: Literal["none", "l2", "layer", "tanh"] = "none",
    ) -> None:
        """Initialize ConvAutoencoder2d.

        Parameters
        ----------
        input_size : int or tuple[int, int]
            Input image size. If int, assumes square image.
        input_channels : int, optional
            Number of input channels (typically 1 for grayscale diffraction patterns), by default 1
        latent_dim : int, optional
            Dimensionality of the latent representation for clustering, by default 128
        start_filters : int, optional
            Starting number of filters, by default 16
        num_layers : int, optional
            Number of encoder/decoder layers, by default 4
        num_per_layer : int, optional
            Number of conv blocks per layer, by default 2
        dtype : torch.dtype, optional
            Data type for the network, by default torch.float32
        dropout : float, optional
            Dropout probability, by default 0.0
        activation : str or Callable, optional
            Activation function for hidden layers, by default "relu"
        final_activation : str or Callable, optional
            Output activation. Common choices: "relu" (positive intensities),
            "sigmoid" (normalized [0,1]), "softplus" (smooth positive), "identity" (preprocessed), by default "relu"
        use_batchnorm : bool, optional
            Whether to use batch normalization, by default True
        latent_normalization : Literal["none", "l2", "layer", "tanh"], optional
            Latent space normalization: "l2" (unit hypersphere for DBScan/K-means),
            "layer" (Gaussian-like for GMM), "tanh" (bounded [-1,1]), "none" (raw), by default "none"
        """
        super().__init__()
        self.input_size = input_size
        self.input_channels = int(input_channels)
        self.latent_dim = int(latent_dim)
        self.start_filters = int(start_filters)
        self.num_layers = int(num_layers)
        self._num_per_layer = int(num_per_layer)
        self.dtype = dtype
        self.dropout = float(dropout)
        self._use_batchnorm = bool(use_batchnorm)
        self.latent_normalization = latent_normalization

        if self.dtype.is_complex:
            self.pool = complex_pool
        else:
            self.pool = passfunc
        self._pooler = nn.MaxPool2d(kernel_size=2, stride=2)

        self.activation = activation
        self.final_activation = final_activation

        self._build()

    @property
    def input_size(self) -> tuple[int, int]:
        return self._input_size

    @input_size.setter
    def input_size(self, size: int | tuple[int, int]):
        if isinstance(size, int):
            self._input_size = (size, size)
        else:
            if len(size) != 2:
                raise ValueError("input_size must be a tuple of two integers")
            self._input_size = (int(size[0]), int(size[1]))

    @property
    def activation(self) -> Callable:
        """Create a new activation instance each time this is accessed."""
        return get_activation_function(self._activation, self.dtype)

    @activation.setter
    def activation(self, act: str | Callable):
        self._activation = act

    @property
    def final_activation(self) -> Callable:
        return get_activation_function(self._final_activation, self.dtype)

    @final_activation.setter
    def final_activation(self, act: str | Callable):
        self._final_activation = act

    def _build(self) -> None:
        self.encoder_blocks = nn.ModuleList()
        self.decoder_blocks = nn.ModuleList()
        self.upsample_blocks = nn.ModuleList()

        # Encoder
        in_channels = self.input_channels
        out_channels = self.start_filters
        for layer_idx in range(self.num_layers):
            if layer_idx > 0:
                out_channels = in_channels * 2

            self.encoder_blocks.append(
                Conv2dBlock(
                    nb_layers=self._num_per_layer,
                    input_channels=in_channels,
                    output_channels=out_channels,
                    use_batchnorm=self._use_batchnorm,
                    dropout=self.dropout,
                    dtype=self.dtype,
                    activation=self._activation,
                )
            )
            in_channels = out_channels

        # Calculate spatial dimensions after encoding
        self._encoded_spatial_dim = (
            self.input_size[0] // (2**self.num_layers),
            self.input_size[1] // (2**self.num_layers),
        )
        self._encoded_channels = in_channels
        self._encoded_features = (
            self._encoded_channels * self._encoded_spatial_dim[0] * self._encoded_spatial_dim[1]
        )

        # Latent space
        self.to_latent = nn.Linear(self._encoded_features, self.latent_dim, dtype=self.dtype)
        self.from_latent = nn.Linear(self.latent_dim, self._encoded_features, dtype=self.dtype)

        # Latent normalization layer
        if self.latent_normalization == "layer":
            if self.dtype.is_complex:
                self.latent_norm = nn.LayerNorm([self.latent_dim], dtype=torch.float32)
            else:
                self.latent_norm = nn.LayerNorm([self.latent_dim], dtype=self.dtype)
        elif self.latent_normalization == "tanh":
            self.latent_norm = nn.Tanh()

        # Decoder
        in_channels = self._encoded_channels
        for layer_idx in range(self.num_layers):
            if layer_idx == self.num_layers - 1:
                out_channels = self.input_channels
            else:
                out_channels = max(in_channels // 2, self.start_filters)

            self.upsample_blocks.append(
                Upsample2dBlock(
                    input_channels=in_channels,
                    output_channels=out_channels,
                    use_batchnorm=self._use_batchnorm and layer_idx < self.num_layers - 1,
                    dtype=self.dtype,
                )
            )

            # Final layer uses different activation (pass config string, not instance)
            layer_activation = (
                self.final_activation if layer_idx == self.num_layers - 1 else self._activation
            )

            self.decoder_blocks.append(
                Conv2dBlock(
                    nb_layers=self._num_per_layer,
                    input_channels=out_channels,
                    output_channels=out_channels,
                    use_batchnorm=self._use_batchnorm and layer_idx < self.num_layers - 1,
                    dropout=self.dropout if layer_idx < self.num_layers - 1 else 0.0,
                    dtype=self.dtype,
                    activation=layer_activation,
                )
            )
            in_channels = out_channels

    def _apply_latent_normalization(self, latent: torch.Tensor) -> torch.Tensor:
        if self.latent_normalization == "l2":
            return F.normalize(latent, p=2, dim=-1)
        elif self.latent_normalization == "layer":
            if self.dtype.is_complex:
                latent_real = self.latent_norm(latent.real)
                latent_imag = self.latent_norm(latent.imag)
                return torch.complex(latent_real, latent_imag)
            else:
                return self.latent_norm(latent)
        elif self.latent_normalization == "tanh":
            return self.latent_norm(latent)
        else:  # "none"
            return latent

    def encode(self, x: torch.Tensor) -> torch.Tensor:
        for encoder_block in self.encoder_blocks:
            x = encoder_block(x)
            x = self.pool(x, self._pooler)

        # Flatten and map to latent space
        x = x.flatten(start_dim=1)
        latent = self.to_latent(x)

        # Apply normalization
        latent = self._apply_latent_normalization(latent)

        return latent

    def decode(self, latent: torch.Tensor) -> torch.Tensor:
        x = self.from_latent(latent)
        x = x.view(-1, self._encoded_channels, *self._encoded_spatial_dim)

        for upsample_block, decoder_block in zip(self.upsample_blocks, self.decoder_blocks):
            x = upsample_block(x)
            x = decoder_block(x)

        return x

    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
        latent = self.encode(x)
        reconstructed = self.decode(latent)
        return reconstructed, latent

    def reset_weights(self) -> None:
        """Reset all weights in the network."""

        def _reset(m: nn.Module) -> None:
            reset_parameters = getattr(m, "reset_parameters", None)
            if callable(reset_parameters):
                reset_parameters()

        self.apply(_reset)
