"""
Rich Content Syntax Validation Module

Provides syntax validation and auto-correction for rich content (Mermaid diagrams,
Chart.js charts, and data tables) generated by LLM agents before sending to the frontend.

The validation catches syntax errors that cause rendering failures and automatically
repairs them when possible, ensuring content renders correctly.
"""

import logging
import os
import re
from abc import ABC, abstractmethod
from enum import Enum

from pydantic import BaseModel


logger = logging.getLogger(__name__)


class ContentType(str, Enum):
    """Types of rich content that can be validated."""

    MERMAID = "mermaid"
    CHART = "chart"
    TABLE = "tabledata"


class ValidationResult(BaseModel):
    """Result of content validation and repair.

    Contains the outcome of a validation operation including validity status,
    error messages, original content, and optional corrected content.
    """

    is_valid: bool
    content_type: ContentType
    original_content: str
    corrected_content: str | None = None
    errors: list[str] = []
    repairs_made: list[str] = []

    class Config:
        """Pydantic model configuration."""

        use_enum_values = True


class ValidationConfig(BaseModel):
    """Configuration for content validation.

    Controls validation behavior including global enable/disable,
    per-content-type settings, and auto-repair functionality.
    """

    enabled: bool = True
    mermaid_enabled: bool = True
    chart_enabled: bool = True
    table_enabled: bool = True
    auto_repair_enabled: bool = True

    @classmethod
    def from_env(cls) -> "ValidationConfig":
        """Load configuration from environment variables.

        Environment variables:
            RICH_CONTENT_VALIDATION_ENABLED: Enable/disable validation globally (default: true)
            MERMAID_VALIDATION_ENABLED: Enable/disable Mermaid validation (default: true)
            CHART_VALIDATION_ENABLED: Enable/disable Chart.js validation (default: true)
            TABLE_VALIDATION_ENABLED: Enable/disable table validation (default: true)
            RICH_CONTENT_AUTO_REPAIR: Enable/disable auto-repair (default: true)

        Returns:
            ValidationConfig instance with settings from environment
        """
        return cls(
            enabled=os.getenv("RICH_CONTENT_VALIDATION_ENABLED", "true").lower() == "true",
            mermaid_enabled=os.getenv("MERMAID_VALIDATION_ENABLED", "true").lower() == "true",
            chart_enabled=os.getenv("CHART_VALIDATION_ENABLED", "true").lower() == "true",
            table_enabled=os.getenv("TABLE_VALIDATION_ENABLED", "true").lower() == "true",
            auto_repair_enabled=os.getenv("RICH_CONTENT_AUTO_REPAIR", "true").lower() == "true",
        )

    def is_content_type_enabled(self, content_type: ContentType) -> bool:
        """Check if validation is enabled for a specific content type.

        Args:
            content_type: The content type to check

        Returns:
            True if validation is enabled for this content type, False otherwise
        """
        if not self.enabled:
            return False

        type_enabled_map = {
            ContentType.MERMAID: self.mermaid_enabled,
            ContentType.CHART: self.chart_enabled,
            ContentType.TABLE: self.table_enabled,
        }
        return type_enabled_map.get(content_type, False)


class ContentValidatorInterface(ABC):
    """Interface for content validators.

    All content validators must implement this interface to provide
    consistent validation and repair functionality.
    """

    @abstractmethod
    def validate(self, content: str) -> ValidationResult:
        """Validate content and return result with optional corrections.

        Args:
            content: The content string to validate

        Returns:
            ValidationResult containing validation outcome and any corrections
        """
        pass

    @abstractmethod
    def get_content_type(self) -> ContentType:
        """Return the content type this validator handles.

        Returns:
            ContentType enum value for this validator
        """
        pass


class MermaidValidator(ContentValidatorInterface):
    """Validator for Mermaid diagram syntax.

    Validates and repairs Mermaid diagram syntax including:
    - Diagram type declarations
    - Bracket/parenthesis balancing
    - Arrow syntax repair
    - Quote balancing
    - Deprecated syntax upgrades
    - Accented character normalization (Mermaid doesn't support accents in identifiers)
    """

    # Mermaid v10+ compatible diagram types
    VALID_DIAGRAM_TYPES: list[str] = [
        "graph",
        "flowchart",
        "sequenceDiagram",
        "classDiagram",
        "stateDiagram",
        "stateDiagram-v2",
        "erDiagram",
        "journey",
        "gantt",
        "pie",
        "quadrantChart",
        "requirementDiagram",
        "gitGraph",
        "mindmap",
        "timeline",
        "zenuml",
        "sankey",
    ]

    # Valid arrow patterns in Mermaid flowcharts
    VALID_ARROWS: list[str] = ["-->", "---", "-.->", "-.-", "==>", "===", "-->>", "-.>>"]

    # Deprecated syntax mappings (old -> new)
    DEPRECATED_SYNTAX: dict[str, str] = {
        "stateDiagram\n": "stateDiagram-v2\n",
    }

    # Pattern to match diagram type at the start of content
    DIAGRAM_TYPE_PATTERN = re.compile(
        r"^\s*(" + "|".join(re.escape(dt) for dt in VALID_DIAGRAM_TYPES) + r")(\s|$|-)",
        re.IGNORECASE,
    )

    # Pattern to match malformed arrows (common LLM mistakes)
    # These patterns are designed to NOT match valid Mermaid arrows
    MALFORMED_ARROW_PATTERNS: list[tuple[re.Pattern[str], str]] = [
        # Single dash arrow -> should be --> (but not if already -->)
        (re.compile(r"(\w+|\]|\))\s*->(?!>)\s*(\w+|\[|\()"), r"\1 --> \2"),
        # Arrow with spaces in the middle (- - >)
        (re.compile(r"(\w+|\]|\))\s*-\s+-\s*>\s*(\w+|\[|\()"), r"\1 --> \2"),
        # Dotted arrow with wrong format (..)
        (re.compile(r"(\w+|\]|\))\s*\.\.\s*>\s*(\w+|\[|\()"), r"\1 -.-> \2"),
        # Double arrow with wrong format (= = >)
        (re.compile(r"(\w+|\]|\))\s*=\s*=\s*>\s*(\w+|\[|\()"), r"\1 ==> \2"),
        # Arrow with extra dashes (---> or more)
        (re.compile(r"(\w+|\]|\))\s*-{3,}>\s*(\w+|\[|\()"), r"\1 --> \2"),
    ]

    # Mapping of accented characters to their ASCII equivalents
    # Mermaid parser doesn't support accented characters in identifiers
    ACCENT_MAP: dict[str, str] = {
        "à": "a",
        "á": "a",
        "â": "a",
        "ã": "a",
        "ä": "a",
        "å": "a",
        "æ": "ae",
        "ç": "c",
        "è": "e",
        "é": "e",
        "ê": "e",
        "ë": "e",
        "ì": "i",
        "í": "i",
        "î": "i",
        "ï": "i",
        "ñ": "n",
        "ò": "o",
        "ó": "o",
        "ô": "o",
        "õ": "o",
        "ö": "o",
        "ø": "o",
        "œ": "oe",
        "ù": "u",
        "ú": "u",
        "û": "u",
        "ü": "u",
        "ý": "y",
        "ÿ": "y",
        "À": "A",
        "Á": "A",
        "Â": "A",
        "Ã": "A",
        "Ä": "A",
        "Å": "A",
        "Æ": "AE",
        "Ç": "C",
        "È": "E",
        "É": "E",
        "Ê": "E",
        "Ë": "E",
        "Ì": "I",
        "Í": "I",
        "Î": "I",
        "Ï": "I",
        "Ñ": "N",
        "Ò": "O",
        "Ó": "O",
        "Ô": "O",
        "Õ": "O",
        "Ö": "O",
        "Ø": "O",
        "Œ": "OE",
        "Ù": "U",
        "Ú": "U",
        "Û": "U",
        "Ü": "U",
        "Ý": "Y",
        "Ÿ": "Y",
        "ß": "ss",
    }

    def get_content_type(self) -> ContentType:
        """Return the content type this validator handles.

        Returns:
            ContentType.MERMAID
        """
        return ContentType.MERMAID

    # Patterns for invalid node shape syntax that LLMs commonly generate
    # These patterns match malformed node shapes and provide corrections
    INVALID_NODE_SHAPE_PATTERNS: list[tuple[re.Pattern[str], str, str]] = [
        # ([(text)]) -> ([text]) - stadium shape with extra parentheses
        (
            re.compile(r"\(\[\(([^)]*)\)\]\)"),
            r"([\1])",
            "Fixed invalid stadium shape syntax ([(...)]) -> ([...])",
        ),
        # ([{text}]) -> ([text]) - stadium shape with braces inside
        (
            re.compile(r"\(\[\{([^}]*)\}\]\)"),
            r"([\1])",
            "Fixed invalid stadium shape syntax ([{...}]) -> ([...])",
        ),
        # [([text])] -> ([text]) - brackets around stadium shape
        (
            re.compile(r"\[\(\[([^\]]*)\]\)\]"),
            r"([\1])",
            "Fixed invalid node shape syntax [([...])] -> ([...])",
        ),
        # {[(text)]} -> {[text]} - subroutine with extra parentheses
        (
            re.compile(r"\{\[\(([^)]*)\)\]\}"),
            r"{[\1]}",
            "Fixed invalid subroutine shape syntax {[(...)]}) -> {[...]}",
        ),
        # ((([text]))) -> (([text])) - double circle with extra parentheses
        (
            re.compile(r"\(\(\(\[([^\]]*)\]\)\)\)"),
            r"(([\1]))",
            "Fixed invalid double circle syntax ((([...]))) -> (([...]))",
        ),
    ]

    def validate(self, content: str) -> ValidationResult:
        """Validate Mermaid syntax and repair if needed.

        This validator applies targeted fixes for common LLM-generated syntax errors:
        1. Missing diagram type declaration
        2. Invalid node shape syntax (e.g., ([(text)]) instead of ([text]))
        3. Unbalanced brackets/parentheses
        4. JSON-escaped syntax from LLM output (escaped quotes, newlines in labels)

        The Mermaid renderer handles most other syntax variations.

        Args:
            content: The Mermaid diagram content to validate

        Returns:
            ValidationResult with validation status and any corrections
        """
        current_content = content.strip()
        errors: list[str] = []
        repairs_made: list[str] = []

        # Skip empty content
        if not current_content:
            return ValidationResult(
                is_valid=True,
                content_type=ContentType.MERMAID,
                original_content=content,
                corrected_content=None,
                errors=[],
                repairs_made=[],
            )

        # Fix -2: Fix JSON-escaped syntax FIRST (escaped quotes and newlines in labels)
        # LLMs sometimes generate Mermaid with JSON escaping: \" instead of " and \n in labels
        # This must run early to normalize the content before other fixes
        had_json_escape_issue, current_content, json_escape_msg = self._fix_json_escaped_syntax(
            current_content
        )
        if had_json_escape_issue:
            errors.append("JSON-escaped syntax detected")
            repairs_made.append(json_escape_msg)
            logger.info(f"Mermaid repair: {json_escape_msg}")

        # Fix -1: Normalize escaped newlines to real newlines
        # LLMs sometimes generate literal \n instead of actual newlines
        # This happens when JSON is double-escaped or improperly parsed
        if "\\n" in current_content:
            current_content = current_content.replace("\\n", "\n")
            errors.append("Escaped newlines detected")
            repairs_made.append("Converted escaped \\n to real newlines")
            logger.info("Mermaid repair: Converted escaped \\n to real newlines")

        # Fix 0: Remove deprecated gitGraph options block (Mermaid v10+ doesn't support it)
        had_gitgraph_issue, current_content, gitgraph_repair_msg = (
            self._fix_gitgraph_deprecated_options(current_content)
        )
        if had_gitgraph_issue:
            errors.append("Deprecated gitGraph options syntax detected")
            repairs_made.append(gitgraph_repair_msg)
            logger.info(f"Mermaid repair: {gitgraph_repair_msg}")

        # Fix 0b: Fix gitGraph inline syntax (gitGraph commit... -> gitGraph\ncommit...)
        had_gitgraph_inline, current_content, gitgraph_inline_msg = (
            self._fix_gitgraph_inline_syntax(current_content)
        )
        if had_gitgraph_inline:
            errors.append("gitGraph commands on same line as declaration")
            repairs_made.append(gitgraph_inline_msg)
            logger.info(f"Mermaid repair: {gitgraph_inline_msg}")

        # Fix 1: Check and fix invalid node shape syntax
        had_shape_issue, current_content, shape_repair_msg = self._fix_invalid_node_shapes(
            current_content
        )
        if had_shape_issue:
            errors.append("Invalid node shape syntax detected")
            repairs_made.append(shape_repair_msg)
            logger.info(f"Mermaid repair: {shape_repair_msg}")

        # Fix 1b: Escape brackets in node labels (e.g., tableau[j] -> "tableau[j]")
        # Must run before _balance_brackets to avoid false positives
        had_escape_issue, current_content, escape_repair_msg = self._escape_brackets_in_labels(
            current_content
        )
        if had_escape_issue:
            errors.append("Unescaped brackets in node labels detected")
            repairs_made.append(escape_repair_msg)
            logger.info(f"Mermaid repair: {escape_repair_msg}")

        # Fix 1c: Escape parentheses in node labels (e.g., [text (note)] -> ["text (note)"])
        # Mermaid interprets () as node shape syntax, so we need to quote labels with parentheses
        had_paren_issue, current_content, paren_repair_msg = self._escape_parentheses_in_labels(
            current_content
        )
        if had_paren_issue:
            errors.append("Unescaped parentheses in node labels detected")
            repairs_made.append(paren_repair_msg)
            logger.info(f"Mermaid repair: {paren_repair_msg}")

        # Fix 2: Balance unclosed brackets (skip for erDiagram - uses { } in relationship syntax)
        is_er_diagram = current_content.strip().lower().startswith("erdiagram")
        if not is_er_diagram:
            had_bracket_issue, current_content, bracket_repair_msg = self._balance_brackets(
                current_content
            )
            if had_bracket_issue:
                errors.append("Unbalanced brackets detected")
                repairs_made.append(bracket_repair_msg)
                logger.info(f"Mermaid repair: {bracket_repair_msg}")

        # Fix 3: Fix malformed arrows
        had_arrow_issue, current_content, arrow_repair_msg = self._fix_arrows(current_content)
        if had_arrow_issue:
            errors.append("Malformed arrow syntax detected")
            repairs_made.append(arrow_repair_msg)
            logger.info(f"Mermaid repair: {arrow_repair_msg}")

        # Fix 4: Escape apostrophes in labels (e.g., d'Équipe -> "d'Équipe")
        # Must run BEFORE _balance_quotes to avoid false positives
        had_apostrophe_issue, current_content, apostrophe_repair_msg = (
            self._escape_apostrophes_in_labels(current_content)
        )
        if had_apostrophe_issue:
            errors.append("Unescaped apostrophes in node labels detected")
            repairs_made.append(apostrophe_repair_msg)
            logger.info(f"Mermaid repair: {apostrophe_repair_msg}")

        # Fix 5: Balance unmatched quotes
        had_quote_issue, current_content, quote_repair_msg = self._balance_quotes(current_content)
        if had_quote_issue:
            errors.append("Unbalanced quotes detected")
            repairs_made.append(quote_repair_msg)
            logger.info(f"Mermaid repair: {quote_repair_msg}")

        # Fix 5b: Fix quadrantChart data point syntax (add brackets around coordinates)
        # Must run BEFORE _normalize_accents to ensure proper pattern matching
        had_quadrant_issue, current_content, quadrant_repair_msg = self._fix_quadrant_chart_points(
            current_content
        )
        if had_quadrant_issue:
            errors.append("quadrantChart data points missing brackets")
            repairs_made.append(quadrant_repair_msg)
            logger.info(f"Mermaid repair: {quadrant_repair_msg}")

        # Fix 5: Normalize accented characters (Mermaid doesn't support them in identifiers)
        had_accent_issue, current_content, accent_repair_msg = self._normalize_accents(
            current_content
        )
        if had_accent_issue:
            errors.append("Accented characters detected in identifiers")
            repairs_made.append(accent_repair_msg)
            logger.info(f"Mermaid repair: {accent_repair_msg}")

        # Fix 6: Check if diagram type is present
        if not self.DIAGRAM_TYPE_PATTERN.match(current_content):
            current_content = f"graph TD\n{current_content}"
            errors.append("Missing or invalid diagram type declaration")
            repairs_made.append("Added default 'graph TD' diagram type declaration")
            logger.info("Mermaid repair: Added default 'graph TD' diagram type declaration")

        # Return result
        if repairs_made:
            return ValidationResult(
                is_valid=True,
                content_type=ContentType.MERMAID,
                original_content=content,
                corrected_content=current_content,
                errors=errors,
                repairs_made=repairs_made,
            )

        return ValidationResult(
            is_valid=True,
            content_type=ContentType.MERMAID,
            original_content=content,
            corrected_content=None,
            errors=[],
            repairs_made=[],
        )

    def _check_diagram_type(self, content: str) -> tuple[bool, str, str]:
        """Check and fix diagram type declaration.

        Detects if the content starts with a valid Mermaid diagram type.
        If missing, adds a default "graph TD" declaration.

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        # Check if content starts with a valid diagram type
        if self.DIAGRAM_TYPE_PATTERN.match(content):
            return (False, content, "")

        # Content is missing diagram type - add default "graph TD"
        fixed_content = f"graph TD\n{content}"
        return (True, fixed_content, "Added default 'graph TD' diagram type declaration")

    def _fix_invalid_node_shapes(self, content: str) -> tuple[bool, str, str]:
        """Fix invalid node shape syntax commonly generated by LLMs.

        Mermaid has specific syntax for different node shapes:
        - ([text]) = stadium-shaped (subprocess)
        - [(text)] = cylindrical (database)
        - ((text)) = circle
        - {text} = rhombus (decision)
        - {{text}} = hexagon
        - [/text/] = parallelogram

        LLMs sometimes generate invalid combinations like:
        - ([(text)]) - extra parentheses around stadium shape
        - ([{text}]) - braces inside stadium shape

        This method detects and fixes these common mistakes.

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        fixed_content = content
        repairs: list[str] = []

        for pattern, replacement, repair_msg in self.INVALID_NODE_SHAPE_PATTERNS:
            if pattern.search(fixed_content):
                fixed_content = pattern.sub(replacement, fixed_content)
                repairs.append(repair_msg)

        if repairs:
            return (True, fixed_content, "; ".join(repairs))
        return (False, content, "")

    def _fix_gitgraph_deprecated_options(self, content: str) -> tuple[bool, str, str]:
        """Remove deprecated gitGraph options block syntax.

        In Mermaid v10+, the old options block syntax is no longer supported:

        DEPRECATED (causes syntax error):
            gitGraph
              options
                {
                  "nodeSpacing": 170,
                  "nodeRadius": 8
                }
              end
              commit id: "init"

        The options block must be removed entirely. If configuration is needed,
        it should use the %%{init: {...}}%% directive instead, but for most
        cases the default settings work fine.

        This method detects and removes the deprecated options block.

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        # Only process gitGraph content
        first_line = content.strip().split("\n")[0].lower() if content.strip() else ""
        if "gitgraph" not in first_line.replace(" ", ""):
            return (False, content, "")

        # Pattern to match the deprecated options block:
        # options { ... } end (with possible whitespace and newlines)
        # The block can span multiple lines
        options_pattern = re.compile(r"\s*options\s*\{[^}]*\}\s*end\s*", re.IGNORECASE | re.DOTALL)

        if options_pattern.search(content):
            # Remove the options block
            fixed_content = options_pattern.sub("\n", content)
            # Clean up any resulting double newlines
            fixed_content = re.sub(r"\n{3,}", "\n\n", fixed_content)
            return (
                True,
                fixed_content.strip(),
                "Removed deprecated gitGraph 'options { } end' block (not supported in Mermaid v10+)",
            )

        return (False, content, "")

    def _fix_gitgraph_inline_syntax(self, content: str) -> tuple[bool, str, str]:
        """Fix gitGraph commands that appear on the same line as the declaration.

        In Mermaid v10+, gitGraph requires commands to be on separate lines:

        INVALID (causes parse error):
            gitGraph commit id: "Initial"
            commit id: "Second"

        VALID:
            gitGraph
            commit id: "Initial"
            commit id: "Second"

        This method detects when gitGraph is followed by commands on the same line
        and adds a newline after the gitGraph declaration.

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        lines = content.strip().split("\n")
        if not lines:
            return (False, content, "")

        first_line = lines[0]
        first_line_lower = first_line.lower().strip()

        # Only process if first line starts with gitgraph
        if not first_line_lower.startswith("gitgraph"):
            return (False, content, "")

        # gitGraph commands that should be on their own line
        gitgraph_commands = ["commit", "branch", "checkout", "merge", "cherry-pick", "tag"]

        # Check if any command appears on the same line as gitGraph (not just gitGraph alone)
        # Pattern: gitGraph followed by whitespace and then a command on the SAME line
        for cmd in gitgraph_commands:
            # Case-insensitive check for command after gitGraph on the same line
            # Must have the command on the same line, not just gitGraph followed by newline
            pattern = re.compile(
                rf"^(\s*gitGraph)\s+({cmd}\b.*)$",
                re.IGNORECASE,
            )
            match = pattern.match(first_line)
            if match:
                # Split gitGraph from the command
                gitgraph_decl = match.group(1).strip()
                rest_of_first_line = match.group(2)
                # Reconstruct with newline after gitGraph
                remaining_lines = "\n".join(lines[1:]) if len(lines) > 1 else ""
                if remaining_lines:
                    fixed_content = f"{gitgraph_decl}\n{rest_of_first_line}\n{remaining_lines}"
                else:
                    fixed_content = f"{gitgraph_decl}\n{rest_of_first_line}"
                return (
                    True,
                    fixed_content,
                    f"Added newline after gitGraph declaration ('{cmd}' command was on same line)",
                )

        return (False, content, "")

    def _fix_json_escaped_syntax(self, content: str) -> tuple[bool, str, str]:
        """Fix JSON-escaped syntax that LLMs sometimes generate in Mermaid diagrams.

        LLMs occasionally output Mermaid with JSON escaping artifacts:
        1. Escaped quotes: \\" instead of "
        2. Newlines in node labels: \\n should become <br/> for multi-line labels

        Example of problematic input:
            N_OWL_20379[\\"OWL-20379\\"\\nissues: 2\\nprogress: 0.0%\\nraf: 0.0h\\"]"

        Should become:
            N_OWL_20379["OWL-20379<br/>issues: 2<br/>progress: 0.0%<br/>raf: 0.0h"]

        This method:
        1. Removes backslash escaping from quotes (\\" -> ")
        2. Converts \\n inside node labels to <br/> for proper line breaks
        3. Cleans up trailing quote artifacts

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        fixed_content = content
        repairs: list[str] = []

        # Step 1: Fix escaped quotes (\\" -> ")
        # This handles JSON double-escaping where \" becomes \\"
        if '\\"' in fixed_content:
            fixed_content = fixed_content.replace('\\"', '"')
            repairs.append("Removed backslash escaping from quotes")

        # Step 2: Convert \\n inside node labels to <br/>
        # Mermaid doesn't support \n in labels, but <br/> works for line breaks
        # Pattern: find content inside brackets [...] or parentheses (...) that contains \\n
        # We need to be careful to only replace \\n inside labels, not between nodes

        def replace_newlines_in_label(match: re.Match[str]) -> str:
            """Replace \\n with <br/> inside a matched label."""
            label = match.group(0)
            if "\\n" in label:
                return label.replace("\\n", "<br/>")
            return label

        # Match node labels in various bracket types
        # This regex matches content inside: [...], (...), {...}, ((...)), ([...]), etc.
        label_patterns = [
            # Square brackets: [content]
            re.compile(r"\[[^\[\]]*\\n[^\[\]]*\]"),
            # Parentheses: (content) but not arrows like -->
            re.compile(r"\([^()]*\\n[^()]*\)"),
            # Double parentheses: ((content))
            re.compile(r"\(\([^()]*\\n[^()]*\)\)"),
            # Stadium shape: ([content])
            re.compile(r"\(\[[^\[\]]*\\n[^\[\]]*\]\)"),
            # Curly braces: {content}
            re.compile(r"\{[^{}]*\\n[^{}]*\}"),
        ]

        for pattern in label_patterns:
            if pattern.search(fixed_content):
                fixed_content = pattern.sub(replace_newlines_in_label, fixed_content)
                if "Converted \\\\n to <br/> in labels" not in repairs:
                    repairs.append("Converted \\\\n to <br/> in labels")

        # Step 3: Clean up trailing quote artifacts like ]" at end of node definitions
        # This happens when LLM generates: [\"label\"]" (extra quote at end)
        # After fixing escaped quotes, we get: ["label"]"
        # The pattern is: "]" (quote-bracket-quote) which should become "]

        # Pattern for "]" (closing quote, closing bracket, extra quote)
        # This is the most common artifact pattern
        double_quote_bracket_quote = re.compile(r'"(\])"')
        if double_quote_bracket_quote.search(fixed_content):
            fixed_content = double_quote_bracket_quote.sub(r'"\1', fixed_content)
            repairs.append("Removed trailing quote artifacts")

        # Also handle )" pattern (for parentheses nodes)
        double_quote_paren_quote = re.compile(r'"(\))"')
        if double_quote_paren_quote.search(fixed_content):
            fixed_content = double_quote_paren_quote.sub(r'"\1', fixed_content)
            if "Removed trailing quote artifacts" not in repairs:
                repairs.append("Removed trailing quote artifacts")

        if repairs:
            return (True, fixed_content, "; ".join(repairs))
        return (False, content, "")

    def _fix_quadrant_chart_points(self, content: str) -> tuple[bool, str, str]:
        """Fix quadrantChart data point syntax for Mermaid v10+.

        In Mermaid v10+, quadrantChart data points require brackets around coordinates:

        INVALID (causes parse error):
            quadrantChart
            title Matrix
            x-axis Low --> High
            y-axis Low --> High
            Point A: 0.9, 0.8
            Point B: 0.3, 0.7

        VALID:
            quadrantChart
            title Matrix
            x-axis Low --> High
            y-axis Low --> High
            Point A: [0.9, 0.8]
            Point B: [0.3, 0.7]

        This method detects data points without brackets and adds them.

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        first_line = content.strip().split("\n")[0].lower() if content.strip() else ""
        first_line_normalized = first_line.replace(" ", "").replace("-", "")

        # Only process quadrantChart content
        if "quadrantchart" not in first_line_normalized:
            return (False, content, "")

        # Pattern to match data points without brackets:
        # "Label: 0.9, 0.8" or "Label: 0.9,0.8" (with optional spaces)
        # But NOT "Label: [0.9, 0.8]" (already has brackets)
        # The label can contain spaces, letters, numbers, and some punctuation
        # Must be at the start of a line (after optional whitespace)
        point_without_brackets = re.compile(
            r"^(\s*)([^:\[\]]+):\s*(\d+\.?\d*)\s*,\s*(\d+\.?\d*)\s*$",
            re.MULTILINE,
        )

        # Check if there are points without brackets
        if not point_without_brackets.search(content):
            return (False, content, "")

        # Count matches for repair message
        matches = point_without_brackets.findall(content)
        point_count = len(matches)

        # Replace with bracketed syntax
        fixed_content = point_without_brackets.sub(r"\1\2: [\3, \4]", content)

        return (
            True,
            fixed_content,
            f"Added brackets to {point_count} quadrantChart data point(s) for Mermaid v10+ syntax",
        )

    def _normalize_accents(self, content: str) -> tuple[bool, str, str]:
        """Normalize accented characters in diagram types that don't support them.

        Mermaid's parser doesn't support accented characters in certain diagram types:
        - erDiagram: relationship labels
        - quadrantChart: axis labels and data point names
        - gantt: task names and section names
        - pie: slice labels
        - journey: section names and task names
        - timeline: event labels
        - mindmap: node labels

        This method normalizes accents for these diagram types.

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        first_line = content.strip().split("\n")[0].lower() if content.strip() else ""
        first_line_normalized = first_line.replace(" ", "").replace("-", "")

        fixed_content = content
        accent_count = 0

        # erDiagram: only normalize relationship labels
        if first_line_normalized.startswith("erdiagram"):
            er_relation_pattern = re.compile(r"(\s*\w+\s*[|o}{]+--[|o}{]+\s*\w+\s*:\s*)([^\n]+)")

            def replace_accents_in_label(match: re.Match[str]) -> str:
                nonlocal accent_count
                prefix = match.group(1)
                label = match.group(2)
                new_label = label
                for accented, replacement in self.ACCENT_MAP.items():
                    if accented in new_label:
                        accent_count += new_label.count(accented)
                        new_label = new_label.replace(accented, replacement)
                return prefix + new_label

            fixed_content = er_relation_pattern.sub(replace_accents_in_label, fixed_content)

        # quadrantChart, gantt, pie, journey, timeline, mindmap: normalize all text
        elif any(
            dt in first_line_normalized
            for dt in ["quadrantchart", "gantt", "pie", "journey", "timeline", "mindmap"]
        ):
            # Normalize all accented characters in the content
            for accented, replacement in self.ACCENT_MAP.items():
                if accented in fixed_content:
                    accent_count += fixed_content.count(accented)
                    fixed_content = fixed_content.replace(accented, replacement)

        if accent_count > 0:
            return (
                True,
                fixed_content,
                f"Normalized {accent_count} accented character(s) for Mermaid compatibility",
            )
        return (False, content, "")

    def _check_syntax_version(self, content: str) -> tuple[bool, str, str]:
        """Detect deprecated syntax and upgrade to current Mermaid v10+ syntax.

        Checks for deprecated Mermaid syntax patterns and upgrades them
        to the current v10+ compatible syntax.

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        fixed_content = content
        repairs: list[str] = []

        for old_syntax, new_syntax in self.DEPRECATED_SYNTAX.items():
            if old_syntax in fixed_content:
                # Only replace if it's at the start of a line (diagram declaration)
                pattern = re.compile(r"^" + re.escape(old_syntax.strip()) + r"(\s|$)", re.MULTILINE)
                if pattern.search(fixed_content):
                    fixed_content = pattern.sub(new_syntax.strip() + r"\1", fixed_content)
                    repairs.append(f"Upgraded '{old_syntax.strip()}' to '{new_syntax.strip()}'")

        if repairs:
            return (True, fixed_content, "; ".join(repairs))
        return (False, content, "")

    def _balance_brackets(self, content: str) -> tuple[bool, str, str]:
        """Balance unclosed brackets and parentheses.

        Scans the content for unclosed brackets [], parentheses (), and braces {},
        and closes them at the end of the line where they appear.

        Note: This is SKIPPED for class diagrams, ER diagrams, and state diagrams
        where braces span multiple lines by design.

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        # Skip diagrams where braces legitimately span multiple lines
        first_line = content.strip().split("\n")[0].lower() if content.strip() else ""
        first_line_normalized = first_line.replace(" ", "").replace("-", "")
        if any(
            diagram_type in first_line_normalized
            for diagram_type in ["classdiagram", "erdiagram", "statediagram"]
        ):
            return (False, content, "")

        # Track bracket pairs
        bracket_pairs = {"(": ")", "[": "]", "{": "}"}
        opening_brackets = set(bracket_pairs.keys())
        closing_brackets = set(bracket_pairs.values())

        lines = content.split("\n")
        fixed_lines: list[str] = []
        total_repairs = 0

        for line in lines:
            # Track unclosed brackets in this line
            stack: list[str] = []
            in_string = False
            string_char = None

            for i, char in enumerate(line):
                # Handle string detection (skip brackets inside strings)
                # But ignore apostrophes that are part of French contractions (letter'letter)
                if char == "'" and not in_string:
                    # Check if this is a French contraction (letter before and after)
                    prev_is_letter = i > 0 and line[i - 1].isalpha()
                    next_is_letter = i < len(line) - 1 and line[i + 1].isalpha()
                    if prev_is_letter and next_is_letter:
                        # This is a contraction like d'Équipe, not a string delimiter
                        continue
                    in_string = True
                    string_char = char
                elif char == '"' and not in_string:
                    in_string = True
                    string_char = char
                elif char == string_char and in_string:
                    in_string = False
                    string_char = None
                elif not in_string:
                    if char in opening_brackets:
                        stack.append(char)
                    elif char in closing_brackets:
                        # Find matching opening bracket
                        for open_br, close_br in bracket_pairs.items():
                            if close_br == char:
                                if stack and stack[-1] == open_br:
                                    stack.pop()
                                break

            # Close any unclosed brackets at end of line
            # BUT only if we're not in an unclosed string (let _balance_quotes handle that)
            if stack and not in_string:
                closing_chars = "".join(bracket_pairs[br] for br in reversed(stack))
                line = line + closing_chars
                total_repairs += len(stack)

            fixed_lines.append(line)

        fixed_content = "\n".join(fixed_lines)

        if total_repairs > 0:
            return (
                True,
                fixed_content,
                f"Closed {total_repairs} unclosed bracket(s)/parenthesis(es)",
            )
        return (False, content, "")

    def _fix_arrows(self, content: str) -> tuple[bool, str, str]:
        """Repair malformed arrow syntax.

        Detects and fixes common arrow syntax errors in Mermaid flowcharts,
        such as single-dash arrows (->) or arrows with incorrect spacing.

        Note: This is SKIPPED for gitGraph, sequenceDiagram, and other diagram types
        that don't use flowchart arrow syntax.

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        # Skip diagram types that don't use flowchart arrow syntax
        first_line = content.strip().split("\n")[0].lower() if content.strip() else ""
        first_line_normalized = first_line.replace(" ", "").replace("-", "")
        skip_diagram_types = [
            "gitgraph",
            "sequencediagram",
            "erdiagram",
            "gantt",
            "pie",
            "journey",
            "timeline",
            "mindmap",
        ]
        if any(diagram_type in first_line_normalized for diagram_type in skip_diagram_types):
            return (False, content, "")

        fixed_content = content
        repairs_count = 0

        for pattern, replacement in self.MALFORMED_ARROW_PATTERNS:
            # Count matches before replacement
            matches = pattern.findall(fixed_content)
            if matches:
                repairs_count += len(matches)
                fixed_content = pattern.sub(replacement, fixed_content)

        if repairs_count > 0:
            return (
                True,
                fixed_content,
                f"Fixed {repairs_count} malformed arrow(s)",
            )
        return (False, content, "")

    def _balance_quotes(self, content: str) -> tuple[bool, str, str]:
        """Balance unmatched quotes in labels.

        Scans each line for unbalanced quotes (both single and double)
        and adds closing quotes where needed.

        Note: Apostrophes inside properly balanced double-quoted strings are not
        counted, as they are protected by the double quotes.

        Note: Apostrophes that are part of words (French contractions like d'Équipe)
        are NOT counted as quotes - they are legitimate text characters.

        Note: Lines ending with "] or ") are skipped for quote balancing as they
        likely represent valid node definitions that may have odd quote counts
        due to <br/> tags or other valid content.

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        # Pattern to detect apostrophe in a word (French contractions or English possessives)
        # These should NOT be counted as quotes
        apostrophe_in_word = re.compile(r"[a-zA-ZÀ-ÿ]'[a-zA-ZÀ-ÿ]")

        lines = content.split("\n")
        fixed_lines: list[str] = []
        total_repairs = 0

        for line in lines:
            # Skip lines that end with "] or ") - these are valid node definitions
            # that may have odd quote counts due to <br/> tags or multi-line content
            # But NOT lines ending with just ] or ) without a preceding quote
            stripped_line = line.rstrip()
            if stripped_line.endswith('"]') or stripped_line.endswith('")'):
                fixed_lines.append(line)
                continue

            # Count double quotes
            double_quotes = line.count('"')

            # Count apostrophes that are part of words (French contractions)
            # These should NOT be counted as quotes
            apostrophes_in_words = len(apostrophe_in_word.findall(line))

            # Count single quotes, but exclude:
            # 1. Those inside balanced double-quoted strings
            # 2. Those that are part of words (contractions)
            if double_quotes % 2 == 0 and double_quotes > 0:
                # Double quotes are balanced, count apostrophes outside of them
                single_quotes = 0
                in_double_string = False
                for i, char in enumerate(line):
                    if char == '"':
                        in_double_string = not in_double_string
                    elif char == "'" and not in_double_string:
                        # Check if this apostrophe is part of a word (contraction)
                        prev_is_letter = i > 0 and line[i - 1].isalpha()
                        next_is_letter = i < len(line) - 1 and line[i + 1].isalpha()
                        if not (prev_is_letter and next_is_letter):
                            single_quotes += 1
            else:
                # Double quotes are unbalanced or absent
                # Count all apostrophes EXCEPT those in words
                single_quotes = line.count("'") - apostrophes_in_words

            fixed_line = line

            # Fix unbalanced double quotes
            if double_quotes % 2 != 0:
                fixed_line = fixed_line + '"'
                total_repairs += 1

            # Fix unbalanced single quotes (only if positive after excluding contractions)
            if single_quotes > 0 and single_quotes % 2 != 0:
                fixed_line = fixed_line + "'"
                total_repairs += 1

            fixed_lines.append(fixed_line)

        fixed_content = "\n".join(fixed_lines)

        if total_repairs > 0:
            return (
                True,
                fixed_content,
                f"Balanced {total_repairs} unmatched quote(s)",
            )
        return (False, content, "")

    def _escape_apostrophes_in_labels(self, content: str) -> tuple[bool, str, str]:
        """Escape apostrophes in node labels that would break Mermaid parsing.

        Mermaid interprets apostrophes as string delimiters. When a label contains
        French contractions like "d'Équipe" or "l'utilisateur", the apostrophe
        breaks the parser because it's seen as an unclosed string.

        Solution: Wrap labels containing apostrophes in double quotes.

        Example:
            ((Gestion d'Équipe))  → ERROR: apostrophe breaks parsing
            (("Gestion d'Équipe"))  → OK: double quotes protect the text

        This method detects node labels with apostrophes (letter'letter pattern)
        and wraps them in double quotes.

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        repairs_count = 0
        lines = content.split("\n")
        fixed_lines: list[str] = []

        # Pattern to detect apostrophe in a word (French contractions or English possessives)
        apostrophe_in_word = re.compile(r"[a-zA-ZÀ-ÿ]'[a-zA-ZÀ-ÿ]")

        # Generic pattern to match node labels in various bracket types
        # This matches: ID[label], ID(label), ID{label}, ID((label)), ID([label]), etc.
        # Group 1: node ID (optional)
        # Group 2: opening brackets
        # Group 3: label content
        # Group 4: closing brackets
        node_label_pattern = re.compile(
            r"(\b\w+\s*)?"  # Optional node ID
            r"(\(\(|\(\[|\[\[|\[\(|\{\{|\{|\(|\[)"  # Opening brackets
            r"([^()\[\]{}]+)"  # Label content (no nested brackets)
            r"(\)\)|\]\)|\]\]|\)\]|\}\}|\}|\)|\])"  # Closing brackets
        )

        for line in lines:
            # Skip lines that don't have apostrophes in words
            if not apostrophe_in_word.search(line):
                fixed_lines.append(line)
                continue

            def fix_label(match: re.Match[str]) -> str:
                nonlocal repairs_count
                node_id = match.group(1) or ""
                open_bracket = match.group(2)
                label = match.group(3)
                close_bracket = match.group(4)

                # Skip if no apostrophe in word in this label
                if not apostrophe_in_word.search(label):
                    return match.group(0)

                # Skip if already quoted (properly balanced)
                if label.startswith('"') and label.endswith('"'):
                    return match.group(0)
                if label.startswith("'") and label.endswith("'"):
                    return match.group(0)

                # Skip if label already contains unbalanced quotes
                # (let _balance_quotes handle it instead)
                if '"' in label or "'" in label:
                    # Check if quotes are unbalanced
                    double_count = label.count('"')
                    single_count = label.count("'") - len(apostrophe_in_word.findall(label))
                    if double_count % 2 != 0 or single_count % 2 != 0:
                        return match.group(0)

                repairs_count += 1
                # Wrap label in double quotes
                return f'{node_id}{open_bracket}"{label}"{close_bracket}'

            fixed_line = node_label_pattern.sub(fix_label, line)
            fixed_lines.append(fixed_line)

        fixed_content = "\n".join(fixed_lines)

        if repairs_count > 0:
            return (
                True,
                fixed_content,
                f"Escaped {repairs_count} apostrophe(s) in labels with double quotes",
            )
        return (False, content, "")

    def _escape_brackets_in_labels(self, content: str) -> tuple[bool, str, str]:
        """Escape brackets inside node labels that would be misinterpreted by Mermaid.

        In Mermaid, brackets [] inside node labels (like decision nodes {condition})
        are interpreted as node delimiters instead of literal text.

        Example:
            F{tableau[j] > tableau[j+1]?}  → ERROR: [j] parsed as node
            F{"tableau[j] > tableau[j+1]?"}  → OK: quotes protect the text

        This method detects labels containing brackets and wraps them in quotes.

        Note: This fix is ONLY applied to flowcharts (graph/flowchart), not to
        class diagrams where {braces} have different semantics.

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        # Skip class diagrams - braces have different meaning there
        first_line = content.strip().split("\n")[0].lower() if content.strip() else ""
        if "classdiagram" in first_line.replace(" ", ""):
            return (False, content, "")

        repairs_count = 0
        lines = content.split("\n")
        fixed_lines: list[str] = []

        # Pattern to match decision nodes: ID{content} where content has unquoted brackets
        # Only match single uppercase/lowercase letter or short word followed by {
        # This avoids matching "class ClassName {" declarations
        # Captures: (node_id, opening_brace, label_content, closing_brace)
        decision_node_pattern = re.compile(
            r"(?<!\bclass\s)(\b[A-Za-z]\w{0,3})\s*(\{)([^}]*\[[^\]]*\][^}]*)(\})"
        )

        # Pattern to match edge labels with brackets: |label with [brackets]|
        edge_label_pattern = re.compile(r"(\|)([^|]*\[[^\]]*\][^|]*)(\|)")

        for line in lines:
            fixed_line = line

            # Fix decision node labels with brackets: F{arr[i] > arr[j]?} -> F{"arr[i] > arr[j]?"}
            def fix_decision_label(match: re.Match[str]) -> str:
                nonlocal repairs_count
                node_id = match.group(1)
                open_brace = match.group(2)
                label = match.group(3)
                close_brace = match.group(4)

                # Skip if already quoted
                if label.startswith('"') or label.startswith("'"):
                    return match.group(0)

                repairs_count += 1
                return f'{node_id}{open_brace}"{label}"{close_brace}'

            fixed_line = decision_node_pattern.sub(fix_decision_label, fixed_line)

            # Fix edge labels with brackets: -->|arr[i]| -> -->|"arr[i]"|
            def fix_edge_label(match: re.Match[str]) -> str:
                nonlocal repairs_count
                opening = match.group(1)
                label = match.group(2)
                closing = match.group(3)

                # Skip if already quoted
                if label.startswith('"') or label.startswith("'"):
                    return match.group(0)

                repairs_count += 1
                return f'{opening}"{label}"{closing}'

            fixed_line = edge_label_pattern.sub(fix_edge_label, fixed_line)
            fixed_lines.append(fixed_line)

        fixed_content = "\n".join(fixed_lines)

        if repairs_count > 0:
            return (
                True,
                fixed_content,
                f"Escaped {repairs_count} bracket(s) in labels with quotes",
            )
        return (False, content, "")

    def _escape_parentheses_in_labels(self, content: str) -> tuple[bool, str, str]:
        """Escape parentheses inside node labels that would be misinterpreted by Mermaid.

        In Mermaid, parentheses () inside node labels are interpreted as node shape
        syntax (rounded rectangle) instead of literal text.

        Example:
            B[Commits (Conventional Commits)]  → ERROR: () parsed as node shape
            B["Commits (Conventional Commits)"]  → OK: quotes protect the text

        This method detects labels containing parentheses and wraps them in quotes.
        It handles:
        - Node labels in square brackets: A[text (with parens)]
        - Decision nodes in braces: B{text (with parens)}
        - Edge labels between pipes: -->|text (with parens)|

        Args:
            content: The Mermaid content to check

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        # Skip class diagrams and erDiagrams - parentheses have different meaning there
        first_line = content.strip().split("\n")[0].lower() if content.strip() else ""
        if "classdiagram" in first_line.replace(" ", "") or "erdiagram" in first_line.replace(
            " ", ""
        ):
            return (False, content, "")

        repairs_count = 0
        lines = content.split("\n")
        fixed_lines: list[str] = []

        # Pattern to match node labels with parentheses inside square brackets: ID[text (with parens)]
        # Captures: (node_id, opening_bracket, label_content, closing_bracket)
        # Only match if label contains () and is not already quoted
        node_label_pattern = re.compile(r"(\b[A-Za-z_]\w*)\s*(\[)([^\]]*\([^)]+\)[^\]]*)(\])")

        # Pattern to match decision nodes with parentheses: ID{text (with parens)}
        # Captures: (node_id, opening_brace, label_content, closing_brace)
        decision_node_pattern = re.compile(r"(\b[A-Za-z_]\w*)\s*(\{)([^}]*\([^)]+\)[^}]*)(\})")

        # Pattern to match edge labels with parentheses: -->|text (with parens)|
        # Captures: (arrow_and_pipe, label_content, closing_pipe)
        edge_label_pattern = re.compile(r"(--[>x]?\||\.-[>]?\|)([^|]*\([^)]+\)[^|]*)(\|)")

        for line in lines:
            fixed_line = line

            def fix_node_label(match: re.Match[str]) -> str:
                nonlocal repairs_count
                node_id = match.group(1)
                open_bracket = match.group(2)
                label = match.group(3)
                close_bracket = match.group(4)

                # Skip if already quoted
                if label.startswith('"') or label.startswith("'"):
                    return match.group(0)

                # Skip if it looks like a valid Mermaid shape syntax at the start
                # e.g., ([text]) is stadium shape, not parentheses in label
                if label.startswith("(") or label.startswith("/") or label.startswith("\\"):
                    return match.group(0)

                repairs_count += 1
                return f'{node_id}{open_bracket}"{label}"{close_bracket}'

            def fix_decision_node(match: re.Match[str]) -> str:
                nonlocal repairs_count
                node_id = match.group(1)
                open_brace = match.group(2)
                label = match.group(3)
                close_brace = match.group(4)

                # Skip if already quoted
                if label.startswith('"') or label.startswith("'"):
                    return match.group(0)

                repairs_count += 1
                return f'{node_id}{open_brace}"{label}"{close_brace}'

            def fix_edge_label(match: re.Match[str]) -> str:
                nonlocal repairs_count
                arrow_pipe = match.group(1)
                label = match.group(2)
                close_pipe = match.group(3)

                # Skip if already quoted
                if label.startswith('"') or label.startswith("'"):
                    return match.group(0)

                repairs_count += 1
                return f'{arrow_pipe}"{label}"{close_pipe}'

            fixed_line = node_label_pattern.sub(fix_node_label, fixed_line)
            fixed_line = decision_node_pattern.sub(fix_decision_node, fixed_line)
            fixed_line = edge_label_pattern.sub(fix_edge_label, fixed_line)
            fixed_lines.append(fixed_line)

        fixed_content = "\n".join(fixed_lines)

        if repairs_count > 0:
            return (
                True,
                fixed_content,
                f"Escaped {repairs_count} parentheses in labels with quotes",
            )
        return (False, content, "")


class ChartValidator(ContentValidatorInterface):
    """Validator for Chart.js configuration.

    Validates and repairs Chart.js JSON configuration including:
    - JSON syntax errors
    - Chart.js v4 compatibility (deprecated options migration)
    - chartConfig wrapper structure
    - Chart type validation
    - JavaScript function removal
    - Required fields (type, data)
    """

    # Chart.js v4 compatible chart types
    VALID_CHART_TYPES: list[str] = [
        "bar",
        "line",
        "pie",
        "doughnut",
        "polarArea",
        "radar",
        "scatter",
        "bubble",
    ]

    # Deprecated Chart.js v3 options that need migration to v4
    DEPRECATED_OPTIONS: dict[str, str] = {
        "scales.xAxes": "scales.x",
        "scales.yAxes": "scales.y",
        "legend": "plugins.legend",
        "title": "plugins.title",
    }

    # Chart type similarity mapping for invalid type replacement
    CHART_TYPE_MAPPING: dict[str, str] = {
        # Common misspellings and variations
        "bars": "bar",
        "barchart": "bar",
        "bar_chart": "bar",
        "column": "bar",
        "lines": "line",
        "linechart": "line",
        "line_chart": "line",
        "area": "line",
        "piechart": "pie",
        "pie_chart": "pie",
        "donut": "doughnut",
        "dougnut": "doughnut",
        "polar": "polarArea",
        "polararea": "polarArea",
        "polar_area": "polarArea",
        "radarchart": "radar",
        "radar_chart": "radar",
        "scatterchart": "scatter",
        "scatter_chart": "scatter",
        "bubblechart": "bubble",
        "bubble_chart": "bubble",
        # Horizontal variants map to bar
        "horizontalbar": "bar",
        "horizontal_bar": "bar",
        "hbar": "bar",
    }

    # Patterns to detect JavaScript functions in JSON
    # These patterns match key-value pairs where the value is a JS function
    JS_FUNCTION_PATTERNS: list[re.Pattern[str]] = [
        # "key": function(...) { ... } - handles nested braces
        re.compile(r'"[^"]+"\s*:\s*function\s*\([^)]*\)\s*\{', re.DOTALL),
        # "key": (...) => { ... } - arrow function with braces
        re.compile(r'"[^"]+"\s*:\s*\([^)]*\)\s*=>\s*\{', re.DOTALL),
        # "key": param => { ... } - arrow function with single param
        re.compile(r'"[^"]+"\s*:\s*\w+\s*=>\s*\{', re.DOTALL),
        # "key": (...) => expr - arrow function without braces (single expression)
        re.compile(r'"[^"]+"\s*:\s*\([^)]*\)\s*=>\s*[^,}\n{]+'),
        # "key": param => expr - arrow function single param without braces
        re.compile(r'"[^"]+"\s*:\s*\w+\s*=>\s*[^,}\n{]+'),
    ]

    # Pattern to match JavaScript single-line comments
    JS_COMMENT_PATTERN = re.compile(r"//[^\n]*")

    # Pattern to match JavaScript multi-line comments
    JS_MULTILINE_COMMENT_PATTERN = re.compile(r"/\*.*?\*/", re.DOTALL)

    def get_content_type(self) -> ContentType:
        """Return the content type this validator handles.

        Returns:
            ContentType.CHART
        """
        return ContentType.CHART

    def validate(self, content: str) -> ValidationResult:
        """Validate Chart.js config and repair if needed.

        Validates JSON syntax and repairs common issues like:
        - Trailing commas
        - Single quotes instead of double quotes
        - Unquoted keys
        - JavaScript functions/comments

        If the JSON is already valid, it's returned unchanged (no reformatting).
        If repairs were needed, the corrected content is returned.

        Args:
            content: The Chart.js configuration content to validate

        Returns:
            ValidationResult with validation status and any corrections
        """
        import json

        current_content = content.strip()
        repairs_made: list[str] = []
        errors: list[str] = []

        # Skip empty content
        if not current_content:
            return ValidationResult(
                is_valid=True,
                content_type=ContentType.CHART,
                original_content=content,
                corrected_content=None,
                errors=[],
                repairs_made=[],
            )

        # Try to parse the JSON
        try:
            config = json.loads(current_content)
        except json.JSONDecodeError:
            # JSON is invalid - attempt repairs

            # Step 1: Remove JavaScript functions and comments
            had_issue, current_content, repair_msg = self._remove_js_functions(current_content)
            if had_issue:
                errors.append("JavaScript functions or comments found in JSON")
                if repair_msg:
                    repairs_made.append(repair_msg)
                    logger.info(f"Chart repair: {repair_msg}")

            # Step 2: Repair JSON syntax errors
            had_issue, current_content, repair_msg = self._repair_json(current_content)
            if had_issue:
                errors.append("JSON syntax errors detected")
                if repair_msg:
                    repairs_made.append(repair_msg)
                    logger.info(f"Chart repair: {repair_msg}")

            # Try to parse JSON after repairs
            try:
                config = json.loads(current_content)
            except json.JSONDecodeError as e:
                logger.error(f"Chart validation failed: Unable to parse JSON - {e}")
                return ValidationResult(
                    is_valid=False,
                    content_type=ContentType.CHART,
                    original_content=content,
                    corrected_content=None,
                    errors=[f"Invalid JSON: {str(e)}"],
                    repairs_made=repairs_made,
                )

            # JSON was repaired successfully - return the corrected content
            return ValidationResult(
                is_valid=True,
                content_type=ContentType.CHART,
                original_content=content,
                corrected_content=current_content,
                errors=errors,
                repairs_made=repairs_made,
            )

        # JSON was already valid - check if it's a recognized chart format
        # Don't modify the content - frontend expects it exactly as provided
        if isinstance(config, dict):
            is_chartjs_wrapper = config.get("type") == "chartjs" and "chartConfig" in config
            is_raw_chartjs = (
                ("type" in config and config["type"] in self.VALID_CHART_TYPES)
                or "data" in config
                or "datasets" in config
                or "labels" in config
            )

            if is_chartjs_wrapper or is_raw_chartjs:
                # Valid Chart.js config - return as-is, don't modify
                return ValidationResult(
                    is_valid=True,
                    content_type=ContentType.CHART,
                    original_content=content,
                    corrected_content=None,
                    errors=[],
                    repairs_made=[],
                )

        # Content is valid JSON but not a recognized chart format
        # Return as-is and let the frontend handle it
        return ValidationResult(
            is_valid=True,
            content_type=ContentType.CHART,
            original_content=content,
            corrected_content=None,
            errors=[],
            repairs_made=[],
        )

    def _repair_json(self, content: str) -> tuple[bool, str, str]:
        """Attempt to repair malformed JSON.

        Fixes common JSON syntax errors:
        - Trailing commas before closing brackets
        - Missing quotes around keys
        - Single quotes instead of double quotes
        - Unquoted string values

        Args:
            content: The JSON content to repair

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        import json

        repairs: list[str] = []
        fixed_content = content

        # Try parsing first - if valid, no repairs needed
        try:
            json.loads(fixed_content)
            return (False, content, "")
        except json.JSONDecodeError:
            pass

        # Fix 1: Replace single quotes with double quotes (for keys and string values)
        # Handle single quotes in various contexts: after {, [, ,, :, whitespace
        # and before }, ], ,, :, whitespace
        single_quote_pattern = re.compile(r"(?<=[{\[,\s:])\'([^']*?)\'(?=[,}\]:\s])")
        if single_quote_pattern.search(fixed_content):
            fixed_content = single_quote_pattern.sub(r'"\1"', fixed_content)
            repairs.append("Replaced single quotes with double quotes")

        # Also handle single quotes at the start of arrays: ['value'
        array_single_quote_pattern = re.compile(r"\[\s*\'([^']*?)\'")
        if array_single_quote_pattern.search(fixed_content):
            fixed_content = array_single_quote_pattern.sub(r'["\1"', fixed_content)
            if "Replaced single quotes" not in repairs:
                repairs.append("Replaced single quotes with double quotes")

        # Fix 2: Remove trailing commas before closing brackets
        trailing_comma_pattern = re.compile(r",\s*([}\]])")
        if trailing_comma_pattern.search(fixed_content):
            fixed_content = trailing_comma_pattern.sub(r"\1", fixed_content)
            repairs.append("Removed trailing commas")

        # Fix 3: Add quotes around unquoted keys
        # Match keys that are not quoted: { key: or , key:
        unquoted_key_pattern = re.compile(r"([{,]\s*)([a-zA-Z_][a-zA-Z0-9_]*)\s*:")
        if unquoted_key_pattern.search(fixed_content):
            fixed_content = unquoted_key_pattern.sub(r'\1"\2":', fixed_content)
            repairs.append("Added quotes around unquoted keys")

        # Fix 4: Fix missing commas between elements
        # Pattern: "value" "key" should be "value", "key"
        missing_comma_pattern = re.compile(r'(["}\]])\s*\n\s*(["{[])')
        if missing_comma_pattern.search(fixed_content):
            fixed_content = missing_comma_pattern.sub(r"\1,\n\2", fixed_content)
            repairs.append("Added missing commas between elements")

        # Fix 5: Remove JavaScript-style comments that might remain
        if "//" in fixed_content or "/*" in fixed_content:
            fixed_content = self.JS_COMMENT_PATTERN.sub("", fixed_content)
            fixed_content = self.JS_MULTILINE_COMMENT_PATTERN.sub("", fixed_content)
            repairs.append("Removed JavaScript comments")

        if repairs:
            return (True, fixed_content, "; ".join(repairs))
        return (False, content, "")

    def _check_chartjs_version(self, config: dict) -> tuple[bool, dict, str]:
        """Migrate deprecated Chart.js v3 options to v4 format.

        Detects and migrates deprecated options:
        - scales.xAxes -> scales.x
        - scales.yAxes -> scales.y
        - legend -> plugins.legend
        - title -> plugins.title

        Args:
            config: The parsed Chart.js configuration

        Returns:
            Tuple of (had_issue, fixed_config, repair_message)
        """
        repairs: list[str] = []
        fixed_config = config.copy()

        # Get the actual chart config (might be wrapped)
        chart_config = fixed_config
        if "chartConfig" in fixed_config:
            chart_config = fixed_config["chartConfig"]

        # Check for deprecated scales.xAxes and scales.yAxes
        if "options" in chart_config and "scales" in chart_config["options"]:
            scales = chart_config["options"]["scales"]

            # Migrate xAxes array to x object
            if "xAxes" in scales:
                x_axes = scales.pop("xAxes")
                if isinstance(x_axes, list) and len(x_axes) > 0:
                    scales["x"] = x_axes[0]
                repairs.append("Migrated scales.xAxes to scales.x")

            # Migrate yAxes array to y object
            if "yAxes" in scales:
                y_axes = scales.pop("yAxes")
                if isinstance(y_axes, list) and len(y_axes) > 0:
                    scales["y"] = y_axes[0]
                repairs.append("Migrated scales.yAxes to scales.y")

        # Check for deprecated top-level legend option
        if "options" in chart_config and "legend" in chart_config["options"]:
            legend_config = chart_config["options"].pop("legend")
            if "plugins" not in chart_config["options"]:
                chart_config["options"]["plugins"] = {}
            chart_config["options"]["plugins"]["legend"] = legend_config
            repairs.append("Migrated legend to plugins.legend")

        # Check for deprecated top-level title option
        if "options" in chart_config and "title" in chart_config["options"]:
            title_config = chart_config["options"].pop("title")
            if "plugins" not in chart_config["options"]:
                chart_config["options"]["plugins"] = {}
            chart_config["options"]["plugins"]["title"] = title_config
            repairs.append("Migrated title to plugins.title")

        # Update the config if it was wrapped
        if "chartConfig" in fixed_config:
            fixed_config["chartConfig"] = chart_config
        else:
            fixed_config = chart_config

        if repairs:
            return (True, fixed_config, "; ".join(repairs))
        return (False, config, "")

    def _ensure_wrapper_structure(self, config: dict) -> tuple[bool, dict, str]:
        """Ensure chartConfig wrapper exists.

        The frontend expects chart configurations to be wrapped in a structure like:
        {
            "type": "chartjs",
            "chartConfig": { ... actual Chart.js config ... }
        }

        Args:
            config: The parsed configuration

        Returns:
            Tuple of (had_issue, fixed_config, repair_message)
        """
        # Check if already has the wrapper structure
        if "type" in config and config["type"] == "chartjs" and "chartConfig" in config:
            return (False, config, "")

        # Check if this looks like a raw Chart.js config (has type as chart type, not "chartjs")
        # or has data/options which are Chart.js specific
        is_raw_chartjs = (
            ("type" in config and config["type"] in self.VALID_CHART_TYPES)
            or "data" in config
            or ("type" not in config and ("datasets" in config or "labels" in config))
        )

        if is_raw_chartjs:
            # Wrap the config
            wrapped_config = {"type": "chartjs", "chartConfig": config}
            return (True, wrapped_config, "Added chartConfig wrapper structure")

        # If it has chartConfig but missing type: "chartjs"
        if "chartConfig" in config and config.get("type") != "chartjs":
            config["type"] = "chartjs"
            return (True, config, "Added type: 'chartjs' to wrapper")

        return (False, config, "")

    def _validate_chart_type(self, config: dict) -> tuple[bool, dict, str]:
        """Validate and fix chart type.

        Checks if the chart type is valid for Chart.js v4.
        If invalid, attempts to map to the closest valid type.
        If no mapping found, defaults to "bar".

        Args:
            config: The parsed configuration

        Returns:
            Tuple of (had_issue, fixed_config, repair_message)
        """
        # Get the actual chart config (might be wrapped)
        chart_config = config
        is_wrapped = False
        if "chartConfig" in config:
            chart_config = config["chartConfig"]
            is_wrapped = True

        # Check if type field exists
        if "type" not in chart_config:
            # Type is missing - will be handled by _ensure_required_fields
            return (False, config, "")

        chart_type = chart_config["type"]

        # Check if type is valid
        if chart_type in self.VALID_CHART_TYPES:
            return (False, config, "")

        # Try to map to a valid type
        chart_type_lower = chart_type.lower().replace(" ", "").replace("-", "")
        if chart_type_lower in self.CHART_TYPE_MAPPING:
            new_type = self.CHART_TYPE_MAPPING[chart_type_lower]
            chart_config["type"] = new_type
            repair_msg = f"Replaced invalid chart type '{chart_type}' with '{new_type}'"
        else:
            # Default to bar chart
            chart_config["type"] = "bar"
            repair_msg = f"Replaced invalid chart type '{chart_type}' with default 'bar'"

        # Update the config if it was wrapped
        if is_wrapped:
            config["chartConfig"] = chart_config
        else:
            config = chart_config

        return (True, config, repair_msg)

    def _remove_js_functions(self, content: str) -> tuple[bool, str, str]:
        """Remove JavaScript functions from JSON.

        Strips JavaScript function definitions and comments from the content
        to produce valid JSON. This handles:
        - Arrow functions: () => {...}
        - Function keyword: function() {...}
        - Single-line comments: // comment
        - Multi-line comments: /* comment */

        Args:
            content: The content to clean

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        repairs: list[str] = []
        fixed_content = content

        # Remove single-line comments (but not inside strings)
        if "//" in fixed_content:
            # Simple approach: remove // comments that are not inside quotes
            lines = fixed_content.split("\n")
            cleaned_lines = []
            for line in lines:
                # Find // that's not inside a string
                in_string = False
                string_char = None
                result_chars = []
                i = 0
                while i < len(line):
                    char = line[i]
                    if char in ('"', "'") and (i == 0 or line[i - 1] != "\\"):
                        if not in_string:
                            in_string = True
                            string_char = char
                        elif char == string_char:
                            in_string = False
                            string_char = None
                    elif char == "/" and i + 1 < len(line) and line[i + 1] == "/" and not in_string:
                        # Found a comment, stop here
                        break
                    result_chars.append(char)
                    i += 1
                cleaned_lines.append("".join(result_chars).rstrip())
            new_content = "\n".join(cleaned_lines)
            if new_content != fixed_content:
                fixed_content = new_content
                repairs.append("Removed single-line comments")

        # Remove multi-line comments
        if "/*" in fixed_content:
            fixed_content = self.JS_MULTILINE_COMMENT_PATTERN.sub("", fixed_content)
            repairs.append("Removed multi-line comments")

        # Remove JavaScript functions by finding and replacing them with null
        # This handles nested braces by counting brace depth
        function_removed = False

        # Pattern to find the start of a function: "key": function( or "key": (params) => or "key": param =>
        func_start_patterns = [
            (re.compile(r'("[\w]+"\s*:\s*)function\s*\([^)]*\)\s*\{'), "function"),
            (re.compile(r'("[\w]+"\s*:\s*)\([^)]*\)\s*=>\s*\{'), "arrow"),
            (re.compile(r'("[\w]+"\s*:\s*)\w+\s*=>\s*\{'), "arrow_single"),
        ]

        for pattern, _func_type in func_start_patterns:
            while True:
                match = pattern.search(fixed_content)
                if not match:
                    break

                # Find the matching closing brace
                start_pos = match.end() - 1  # Position of opening brace
                brace_count = 1
                pos = start_pos + 1

                while pos < len(fixed_content) and brace_count > 0:
                    char = fixed_content[pos]
                    if char == "{":
                        brace_count += 1
                    elif char == "}":
                        brace_count -= 1
                    pos += 1

                if brace_count == 0:
                    # Replace the entire function with null
                    key_part = match.group(1)
                    fixed_content = (
                        fixed_content[: match.start()] + key_part + "null" + fixed_content[pos:]
                    )
                    function_removed = True
                else:
                    # Couldn't find matching brace, break to avoid infinite loop
                    break

        # Handle arrow functions without braces (single expression): "key": (x) => x + 1
        arrow_expr_patterns = [
            re.compile(r'("[\w]+"\s*:\s*)\([^)]*\)\s*=>\s*[^,}\n\[{]+'),
            re.compile(r'("[\w]+"\s*:\s*)\w+\s*=>\s*[^,}\n\[{]+'),
        ]

        for pattern in arrow_expr_patterns:
            if pattern.search(fixed_content):
                fixed_content = pattern.sub(r"\1null", fixed_content)
                function_removed = True

        if function_removed:
            repairs.append("Removed JavaScript function(s)")

        # Clean up any resulting empty lines or extra whitespace
        fixed_content = re.sub(r"\n\s*\n", "\n", fixed_content)

        if repairs:
            return (True, fixed_content, "; ".join(repairs))
        return (False, content, "")

    def _ensure_required_fields(self, config: dict) -> tuple[bool, dict, str]:
        """Ensure required fields exist.

        Chart.js requires at minimum:
        - type: The chart type
        - data: The data object with labels and datasets

        Args:
            config: The parsed configuration

        Returns:
            Tuple of (had_issue, fixed_config, repair_message)
        """
        repairs: list[str] = []
        fixed_config = config.copy()

        # Get the actual chart config (might be wrapped)
        chart_config = fixed_config
        is_wrapped = False
        if "chartConfig" in fixed_config:
            chart_config = fixed_config["chartConfig"]
            is_wrapped = True

        # Ensure type field exists
        if "type" not in chart_config:
            # Try to infer type from data structure
            inferred_type = self._infer_chart_type(chart_config)
            chart_config["type"] = inferred_type
            repairs.append(f"Added missing 'type' field (inferred: '{inferred_type}')")

        # Ensure data field exists
        if "data" not in chart_config:
            # Check if datasets or labels are at the top level (common mistake)
            if "datasets" in chart_config or "labels" in chart_config:
                chart_config["data"] = {}
                if "datasets" in chart_config:
                    chart_config["data"]["datasets"] = chart_config.pop("datasets")
                if "labels" in chart_config:
                    chart_config["data"]["labels"] = chart_config.pop("labels")
                repairs.append("Moved datasets/labels into 'data' object")
            else:
                # Create empty data structure
                chart_config["data"] = {"labels": [], "datasets": []}
                repairs.append("Added missing 'data' field with empty structure")

        # Ensure data has datasets array
        if "data" in chart_config and "datasets" not in chart_config["data"]:
            chart_config["data"]["datasets"] = []
            repairs.append("Added missing 'datasets' array to data")

        # Update the config if it was wrapped
        if is_wrapped:
            fixed_config["chartConfig"] = chart_config
        else:
            fixed_config = chart_config

        if repairs:
            return (True, fixed_config, "; ".join(repairs))
        return (False, config, "")

    def _infer_chart_type(self, config: dict) -> str:
        """Infer chart type from data structure.

        Attempts to determine the appropriate chart type based on the
        data structure present in the configuration.

        Args:
            config: The chart configuration

        Returns:
            Inferred chart type string, defaults to "bar"
        """
        data = config.get("data", {})
        datasets = data.get("datasets", [])

        if not datasets:
            return "bar"  # Default

        first_dataset = datasets[0] if datasets else {}

        # Check for scatter/bubble specific data format (x, y coordinates)
        if "data" in first_dataset:
            dataset_data = first_dataset["data"]
            if isinstance(dataset_data, list) and len(dataset_data) > 0:
                first_point = dataset_data[0]
                if isinstance(first_point, dict):
                    if "r" in first_point:
                        return "bubble"
                    if "x" in first_point and "y" in first_point:
                        return "scatter"

        # Check for radar-specific options
        if config.get("options", {}).get("scales", {}).get("r"):
            return "radar"

        # Default to bar chart
        return "bar"


class TableValidator(ContentValidatorInterface):
    """Validator for table data structure.

    Validates table data JSON structure. Follows "minimal intervention" principle:
    if JSON is valid and parseable, returns unchanged.
    """

    def get_content_type(self) -> ContentType:
        """Return the content type this validator handles.

        Returns:
            ContentType.TABLE
        """
        return ContentType.TABLE

    def validate(self, content: str) -> ValidationResult:
        """Validate table data and repair if needed.

        IMPORTANT: This validator follows a "minimal intervention" principle.
        If the JSON is valid and parseable, it returns the content unchanged.
        Repairs are only made when there are actual syntax errors.

        Args:
            content: The table data content to validate

        Returns:
            ValidationResult with validation status and any corrections
        """
        import json

        current_content = content.strip()

        # Skip empty content
        if not current_content:
            return ValidationResult(
                is_valid=True,
                content_type=ContentType.TABLE,
                original_content=content,
                corrected_content=None,
                errors=[],
                repairs_made=[],
            )

        # First, try to parse the JSON as-is
        # If it parses successfully, the content is valid - return unchanged
        try:
            json.loads(current_content)
            # JSON is valid - return as-is without any modifications
            return ValidationResult(
                is_valid=True,
                content_type=ContentType.TABLE,
                original_content=content,
                corrected_content=None,
                errors=[],
                repairs_made=[],
            )
        except json.JSONDecodeError:
            # JSON is invalid - attempt repairs
            pass

        # Only reach here if JSON is invalid - attempt repairs
        errors: list[str] = []
        repairs_made: list[str] = []

        # Attempt to repair JSON syntax errors
        had_issue, current_content, repair_msg = self._repair_json(current_content)
        if had_issue:
            errors.append("JSON syntax errors detected")
            if repair_msg:
                repairs_made.append(repair_msg)
                logger.info(f"Table repair: {repair_msg}")

        # Try to parse JSON after repairs
        try:
            json.loads(current_content)
        except json.JSONDecodeError as e:
            # JSON is still invalid after repair attempts
            logger.error(f"Table validation failed: Unable to parse JSON - {e}")
            return ValidationResult(
                is_valid=False,
                content_type=ContentType.TABLE,
                original_content=content,
                corrected_content=None,
                errors=[f"Invalid JSON: {str(e)}"],
                repairs_made=repairs_made,
            )

        # JSON was repaired successfully - return the repaired content
        logger.warning(
            f"Table validation found {len(errors)} issues, made {len(repairs_made)} repairs"
        )
        return ValidationResult(
            is_valid=True,
            content_type=ContentType.TABLE,
            original_content=content,
            corrected_content=current_content,
            errors=errors,
            repairs_made=repairs_made,
        )

    def _repair_json(self, content: str) -> tuple[bool, str, str]:
        """Attempt to repair malformed JSON.

        Fixes common JSON syntax errors:
        - Trailing commas before closing brackets
        - Missing quotes around keys
        - Single quotes instead of double quotes
        - Missing commas between elements

        Args:
            content: The JSON content to repair

        Returns:
            Tuple of (had_issue, fixed_content, repair_message)
        """
        import json

        repairs: list[str] = []
        fixed_content = content

        # Try parsing first - if valid, no repairs needed
        try:
            json.loads(fixed_content)
            return (False, content, "")
        except json.JSONDecodeError:
            pass

        # Fix 1: Replace single quotes with double quotes
        single_quote_pattern = re.compile(r"(?<=[{\[,\s:])\'([^']*?)\'(?=[,}\]:\s])")
        if single_quote_pattern.search(fixed_content):
            fixed_content = single_quote_pattern.sub(r'"\1"', fixed_content)
            repairs.append("Replaced single quotes with double quotes")

        # Also handle single quotes at the start of arrays: ['value'
        array_single_quote_pattern = re.compile(r"\[\s*\'([^']*?)\'")
        if array_single_quote_pattern.search(fixed_content):
            fixed_content = array_single_quote_pattern.sub(r'["\1"', fixed_content)
            if "Replaced single quotes" not in repairs:
                repairs.append("Replaced single quotes with double quotes")

        # Fix 2: Remove trailing commas before closing brackets
        trailing_comma_pattern = re.compile(r",\s*([}\]])")
        if trailing_comma_pattern.search(fixed_content):
            fixed_content = trailing_comma_pattern.sub(r"\1", fixed_content)
            repairs.append("Removed trailing commas")

        # Fix 3: Add quotes around unquoted keys
        unquoted_key_pattern = re.compile(r"([{,]\s*)([a-zA-Z_][a-zA-Z0-9_]*)\s*:")
        if unquoted_key_pattern.search(fixed_content):
            fixed_content = unquoted_key_pattern.sub(r'\1"\2":', fixed_content)
            repairs.append("Added quotes around unquoted keys")

        # Fix 4: Fix missing commas between elements
        missing_comma_pattern = re.compile(r'(["}\]])\s*\n\s*(["{[])')
        if missing_comma_pattern.search(fixed_content):
            fixed_content = missing_comma_pattern.sub(r"\1,\n\2", fixed_content)
            repairs.append("Added missing commas between elements")

        if repairs:
            return (True, fixed_content, "; ".join(repairs))
        return (False, content, "")

    def _ensure_headers(self, data: dict) -> tuple[bool, dict, str]:
        """Ensure headers field exists.

        If headers are missing:
        - If rows exist and first row has data, generate headers from first row
          (use first row values if they look like headers, otherwise use generic names)
        - If no rows or empty rows, use generic column names based on max row length

        Args:
            data: The parsed table data

        Returns:
            Tuple of (had_issue, fixed_data, repair_message)
        """
        # Check if headers already exist and are valid
        if "headers" in data:
            headers = data["headers"]
            if isinstance(headers, list) and len(headers) > 0:
                return (False, data, "")

        fixed_data = data.copy()
        rows = fixed_data.get("rows", [])

        # Determine the number of columns needed
        max_columns = 0
        if rows and isinstance(rows, list):
            for row in rows:
                if isinstance(row, list):
                    max_columns = max(max_columns, len(row))

        if max_columns == 0:
            # No rows or empty rows - create minimal headers
            fixed_data["headers"] = ["Column 1"]
            return (True, fixed_data, "Generated default header (no data to infer from)")

        # Check if first row looks like headers (all strings, no numbers)
        first_row = rows[0] if rows else []
        first_row_looks_like_headers = (
            isinstance(first_row, list)
            and len(first_row) > 0
            and all(
                isinstance(cell, str) and not cell.replace(".", "").isdigit() for cell in first_row
            )
        )

        if first_row_looks_like_headers and len(rows) > 1:
            # Use first row as headers and remove it from rows
            fixed_data["headers"] = first_row
            fixed_data["rows"] = rows[1:]
            return (True, fixed_data, "Generated headers from first row")
        else:
            # Generate generic column names
            fixed_data["headers"] = [f"Column {i + 1}" for i in range(max_columns)]
            return (True, fixed_data, f"Generated {max_columns} generic column header(s)")

    def _ensure_rows(self, data: dict) -> tuple[bool, dict, str]:
        """Ensure rows field exists.

        If rows field is missing, creates an empty rows array.

        Args:
            data: The parsed table data

        Returns:
            Tuple of (had_issue, fixed_data, repair_message)
        """
        # Check if rows already exist
        if "rows" in data:
            rows = data["rows"]
            if isinstance(rows, list):
                return (False, data, "")

        fixed_data = data.copy()
        fixed_data["rows"] = []
        return (True, fixed_data, "Added empty rows array")

    def _balance_columns(self, data: dict) -> tuple[bool, dict, str]:
        """Balance row column counts with headers.

        - If rows have fewer columns than headers, pad with empty strings
        - If rows have more columns than headers, add generic headers for extra columns

        Args:
            data: The parsed table data

        Returns:
            Tuple of (had_issue, fixed_data, repair_message)
        """
        fixed_data = data.copy()
        headers = fixed_data.get("headers", [])
        rows = fixed_data.get("rows", [])

        if not isinstance(headers, list):
            headers = []
        if not isinstance(rows, list):
            rows = []

        repairs: list[str] = []
        header_count = len(headers)

        # Find max columns in rows
        max_row_columns = 0
        for row in rows:
            if isinstance(row, list):
                max_row_columns = max(max_row_columns, len(row))

        # Extend headers if rows have more columns
        if max_row_columns > header_count:
            extra_headers_needed = max_row_columns - header_count
            for i in range(extra_headers_needed):
                headers.append(f"Column {header_count + i + 1}")
            fixed_data["headers"] = headers
            repairs.append(f"Added {extra_headers_needed} generic header(s) for extra columns")
            header_count = len(headers)

        # Pad rows that have fewer columns than headers
        rows_padded = 0
        fixed_rows = []
        for row in rows:
            if isinstance(row, list):
                if len(row) < header_count:
                    # Pad with empty strings
                    padded_row = row + [""] * (header_count - len(row))
                    fixed_rows.append(padded_row)
                    rows_padded += 1
                else:
                    fixed_rows.append(row)
            else:
                # Non-list row - convert to list with single element and pad
                fixed_rows.append([str(row)] + [""] * (header_count - 1))
                rows_padded += 1

        if rows_padded > 0:
            fixed_data["rows"] = fixed_rows
            repairs.append(f"Padded {rows_padded} row(s) with empty strings")

        if repairs:
            return (True, fixed_data, "; ".join(repairs))
        return (False, data, "")


# Retry messages for unrepairable content (user-friendly, in French as per design)
RETRY_MESSAGES: dict[ContentType, str] = {
    ContentType.MERMAID: (
        "⚠️ Le diagramme n'a pas pu être généré correctement. " "Veuillez réessayer la génération."
    ),
    ContentType.CHART: (
        "⚠️ Le graphique n'a pas pu être généré correctement. " "Veuillez réessayer la génération."
    ),
    ContentType.TABLE: (
        "⚠️ Le tableau n'a pas pu être généré correctement. " "Veuillez réessayer la génération."
    ),
}


class ContentInterceptor:
    """Intercepts and validates rich content in agent output.

    This class is the main entry point for content validation. It:
    - Detects and corrects wrong language identifiers (e.g., ```json -> ```chart)
    - Extracts rich content blocks (mermaid, chart, tabledata) from agent output
    - Routes each block to the appropriate validator
    - Replaces original content with corrected content when repairs are made
    - Replaces unrepairable content with user-friendly retry messages
    - Respects configuration settings for enabling/disabling validation

    The interceptor is designed to be transparent - it processes content without
    requiring changes to existing agent code.
    """

    # Pattern to match rich content blocks: ```mermaid, ```chart, ```tabledata
    # Captures: (content_type, block_content)
    # Uses non-greedy matching to handle multiple blocks correctly
    # Allows optional leading whitespace/indentation before the opening ```
    # Note: chartjs is an alias for chart (some LLMs use ```chartjs instead of ```chart)
    CONTENT_PATTERN = re.compile(
        r"^[ \t]*```(mermaid|chart|chartjs|tabledata)\s*\n(.*?)^[ \t]*```",
        re.DOTALL | re.MULTILINE,
    )

    # Pattern to match JSON blocks that might be misidentified chart/table content
    # LLMs often generate ```json instead of ```chart or ```tabledata
    # Allows optional leading whitespace/indentation
    JSON_BLOCK_PATTERN = re.compile(
        r"^[ \t]*```json\s*\n(.*?)^[ \t]*```",
        re.DOTALL | re.MULTILINE,
    )

    # Pattern to match JavaScript blocks that might contain Chart.js configs
    # Some LLMs generate Chart.js as ```javascript with const chartConfig = {...}
    # Allows optional leading whitespace/indentation
    JS_BLOCK_PATTERN = re.compile(
        r"^[ \t]*```javascript\s*\n(.*?)^[ \t]*```",
        re.DOTALL | re.MULTILINE,
    )

    # Pattern to detect raw Mermaid code NOT inside code blocks
    # Mermaid diagrams start with specific keywords
    RAW_MERMAID_KEYWORDS = [
        "gantt",
        "graph",
        "flowchart",
        "sequenceDiagram",
        "classDiagram",
        "stateDiagram",
        "stateDiagram-v2",
        "erDiagram",
        "journey",
        "pie",
        "quadrantChart",
        "requirementDiagram",
        "gitGraph",
        "mindmap",
        "timeline",
        "zenuml",
        "sankey",
    ]

    # Keywords that indicate raw JSON blocks that need wrapping
    # These are special block types that should be wrapped in ```json
    RAW_JSON_BLOCK_KEYWORDS = [
        "optionsblock",
        "options_block",
    ]

    # Mapping from content type string to ContentType enum
    # Note: chartjs is an alias for chart
    CONTENT_TYPE_MAP: dict[str, ContentType] = {
        "mermaid": ContentType.MERMAID,
        "chart": ContentType.CHART,
        "chartjs": ContentType.CHART,
        "tabledata": ContentType.TABLE,
    }

    def __init__(self, config: ValidationConfig | None = None):
        """Initialize the ContentInterceptor.

        Args:
            config: Validation configuration. If None, loads from environment.
        """
        self.config = config or ValidationConfig.from_env()
        self.validators: dict[ContentType, ContentValidatorInterface] = {
            ContentType.MERMAID: MermaidValidator(),
            ContentType.CHART: ChartValidator(),
            ContentType.TABLE: TableValidator(),
        }
        self.logger = logging.getLogger("agent_framework.processing.validation")

    def process(self, content: str) -> str:
        """Process content, validating and repairing rich content blocks.

        This is the main method to process agent output. It:
        1. Checks if validation is enabled globally
        2. Corrects wrong language identifiers (```json -> ```chart/```tabledata)
        3. Extracts all rich content blocks from the content
        4. Validates and repairs each block using the appropriate validator
        5. Replaces original blocks with corrected content or retry messages
        6. Returns the processed content

        Args:
            content: The agent output content to process

        Returns:
            Processed content with validated/repaired rich content blocks
        """
        # If validation is disabled globally, pass through unchanged
        if not self.config.enabled:
            self.logger.debug("Validation disabled globally, passing through content unchanged")
            return content

        # Step 1: Wrap raw Mermaid code that's not inside code blocks
        content = self._wrap_raw_mermaid_code(content)

        # Step 2: Wrap raw JSON blocks (optionsblock, etc.) that are not inside code blocks
        content = self._wrap_raw_json_blocks(content)

        # Step 3: Fix Mermaid blocks with orphan code after closing backticks
        content = self._fix_orphan_mermaid_code(content)

        # Step 4: Correct wrong language identifiers (```json -> ```chart/```tabledata)
        content = self._correct_language_identifiers(content)

        # Extract all rich content blocks with their positions
        blocks = self._extract_blocks(content)

        # If no blocks found, return original content
        if not blocks:
            return content

        self.logger.debug(f"Found {len(blocks)} rich content block(s) to validate")

        # Process blocks in reverse order to maintain correct positions
        # (processing from end to start avoids position shifts)
        result = content
        for content_type_str, block_content, start_pos, end_pos in reversed(blocks):
            # Get the ContentType enum
            content_type = self.CONTENT_TYPE_MAP.get(content_type_str)
            if content_type is None:
                self.logger.warning(f"Unknown content type: {content_type_str}")
                continue

            # Check if this content type is enabled
            if not self.config.is_content_type_enabled(content_type):
                self.logger.debug(
                    f"Validation disabled for content type {content_type_str}, skipping"
                )
                continue

            # Validate the block
            validation_result = self._validate_block(content_type_str, block_content)

            # Determine what to replace the block with
            if validation_result.is_valid:
                # Content is valid (possibly after repairs)
                if validation_result.corrected_content is not None:
                    # Repairs were made - use corrected content
                    # Ensure newline before closing backticks for frontend compatibility
                    corrected = validation_result.corrected_content
                    if not corrected.endswith("\n"):
                        corrected = corrected + "\n"
                    replacement = f"```{content_type_str}\n{corrected}```"
                    self.logger.info(
                        f"Replaced {content_type_str} block with repaired content. "
                        f"Repairs: {', '.join(validation_result.repairs_made)}"
                    )
                else:
                    # Content was already valid - no replacement needed
                    continue
            else:
                # Content is invalid and could not be repaired
                replacement = self._generate_retry_message(content_type)
                self.logger.error(
                    f"Could not repair {content_type_str} block. "
                    f"Errors: {', '.join(validation_result.errors)}. "
                    f"Replacing with retry message."
                )

            # Replace the block in the result
            result = result[:start_pos] + replacement + result[end_pos:]

        return result

    def _extract_blocks(self, content: str) -> list[tuple[str, str, int, int]]:
        """Extract rich content blocks with positions.

        Finds all rich content blocks (```mermaid, ```chart, ```tabledata) in the
        content and returns their type, content, and positions.

        Args:
            content: The content to search for blocks

        Returns:
            List of tuples: (content_type, block_content, start_position, end_position)
            where positions are indices into the original content string
        """
        blocks: list[tuple[str, str, int, int]] = []

        for match in self.CONTENT_PATTERN.finditer(content):
            content_type = match.group(1)  # mermaid, chart, or tabledata
            block_content = match.group(2)  # The content inside the block
            start_pos = match.start()  # Start of the entire match (including ```)
            end_pos = match.end()  # End of the entire match (including ```)

            blocks.append((content_type, block_content, start_pos, end_pos))

        return blocks

    def _correct_language_identifiers(self, content: str) -> str:
        """Correct wrong language identifiers in code blocks.

        LLMs often generate ```json or ```javascript instead of ```chart or ```tabledata.
        This method detects these blocks that contain Chart.js or table data
        and corrects the language identifier.

        Detection heuristics:
        - Chart.js: Has "type" field with chart type (bar, line, pie, etc.) or
          has "chartConfig" wrapper or has "datasets" array
        - Table data: Has "headers" and "rows" fields, or has "caption" with array data
        - JavaScript Chart.js: Contains const chartConfig = {...} or similar patterns

        Args:
            content: The content to process

        Returns:
            Content with corrected language identifiers
        """
        import json

        corrections_made = 0
        result = content

        # Collect all JSON block corrections first
        json_corrections: list[tuple[int, int, str]] = []
        for match in self.JSON_BLOCK_PATTERN.finditer(content):
            json_content = match.group(1).strip()
            start_pos = match.start()
            end_pos = match.end()

            # Try to parse as JSON
            try:
                data = json.loads(json_content)
            except json.JSONDecodeError:
                continue

            if not isinstance(data, dict):
                continue

            # Detect content type
            detected_type = self._detect_content_type_from_json(data)

            if detected_type is not None:
                corrected_block = f"```{detected_type}\n{json_content}\n```"
                json_corrections.append((start_pos, end_pos, corrected_block))
                self.logger.info(f"Corrected language identifier: ```json -> ```{detected_type}")

        # Apply JSON corrections in reverse order to maintain positions
        for start_pos, end_pos, corrected_block in reversed(json_corrections):
            result = result[:start_pos] + corrected_block + result[end_pos:]
            corrections_made += 1

        # Now collect all JavaScript block corrections
        # Search on the updated result
        js_corrections_list: list[tuple[int, int, str]] = []
        for match in self.JS_BLOCK_PATTERN.finditer(result):
            js_content = match.group(1)
            start_pos = match.start()
            end_pos = match.end()

            # Try to extract Chart.js config from JavaScript code
            extracted_json = self._extract_chartjs_from_javascript(js_content)

            if extracted_json is not None:
                corrected_block = f"```chart\n{extracted_json}\n```"
                js_corrections_list.append((start_pos, end_pos, corrected_block))
                self.logger.info(
                    "Corrected language identifier: ```javascript -> ```chart "
                    "(extracted Chart.js config from JavaScript)"
                )

        # Apply JS corrections in reverse order to maintain positions
        for start_pos, end_pos, corrected_block in reversed(js_corrections_list):
            result = result[:start_pos] + corrected_block + result[end_pos:]
            corrections_made += 1

        if corrections_made > 0:
            self.logger.warning(
                f"Corrected {corrections_made} wrong language identifier(s) "
                f"(```json/```javascript -> ```chart/```tabledata)"
            )

        return result

    def _wrap_raw_mermaid_code(self, content: str) -> str:
        """Wrap raw Mermaid code that's not inside code blocks.

        LLMs sometimes generate Mermaid diagram code directly in the text without
        wrapping it in ```mermaid``` code blocks. This method detects such raw
        Mermaid code and wraps it properly.

        Detection: Looks for lines starting with Mermaid keywords (gantt, graph,
        flowchart, sequenceDiagram, etc.) that are NOT inside existing code blocks.

        Args:
            content: The content to process

        Returns:
            Content with raw Mermaid code wrapped in ```mermaid``` blocks
        """
        # First, identify all existing code block regions to avoid
        # Pattern handles optional indentation before opening ```
        code_block_pattern = re.compile(
            r"^[ \t]*```[\w]*\s*\n.*?^[ \t]*```", re.DOTALL | re.MULTILINE
        )
        code_block_regions: list[tuple[int, int]] = []
        for match in code_block_pattern.finditer(content):
            code_block_regions.append((match.start(), match.end()))

        def is_inside_code_block(pos: int) -> bool:
            """Check if a position is inside an existing code block."""
            return any(start <= pos < end for start, end in code_block_regions)

        # Build pattern to match Mermaid diagram starts
        mermaid_start_pattern = re.compile(
            r"^(" + "|".join(re.escape(kw) for kw in self.RAW_MERMAID_KEYWORDS) + r")\b",
            re.MULTILINE | re.IGNORECASE,
        )

        # Find all potential Mermaid diagram starts
        corrections: list[tuple[int, int, str]] = []

        for match in mermaid_start_pattern.finditer(content):
            start_pos = match.start()

            # Skip if inside an existing code block
            if is_inside_code_block(start_pos):
                continue

            # Extract from start_pos to find the diagram extent
            remaining_content = content[start_pos:]
            lines = remaining_content.split("\n")

            diagram_lines: list[str] = []

            for i, line in enumerate(lines):
                stripped = line.strip()

                # First line is always part of the diagram
                if i == 0:
                    diagram_lines.append(line)
                    continue

                # Empty line might be end of diagram - check next line
                if not stripped:
                    next_non_empty = None
                    for future_line in lines[i + 1 :]:
                        if future_line.strip():
                            next_non_empty = future_line.strip()
                            break

                    if next_non_empty:
                        # Check if next content looks like Mermaid continuation
                        is_mermaid_continuation = (
                            next_non_empty.startswith("section ")
                            or next_non_empty.startswith("    ")
                            or next_non_empty.startswith("\t")
                            or re.match(r"^\s*\w+\s*:", next_non_empty)
                            or re.match(r"^\s*\w+\s*-->", next_non_empty)
                            or re.match(r"^\s*\w+\s*->", next_non_empty)
                            or re.match(r"^\s*participant\s+", next_non_empty, re.IGNORECASE)
                            or re.match(r"^\s*actor\s+", next_non_empty, re.IGNORECASE)
                            or next_non_empty.startswith("title ")
                            or next_non_empty.startswith("dateFormat ")
                            or next_non_empty.startswith("axisFormat ")
                        )

                        if not is_mermaid_continuation:
                            break

                    diagram_lines.append(line)
                    continue

                # Check if this line indicates end of diagram
                end_indicators = [
                    stripped.startswith("L'image"),
                    stripped.startswith("Le diagramme"),
                    stripped.startswith("Que voulez-vous"),
                    stripped.startswith("Que souhaitez-vous"),
                    stripped.startswith("Download"),
                    stripped.startswith("Télécharger"),
                    stripped.startswith("- Nom de fichier"),
                    stripped.startswith("- Lien"),
                    stripped.startswith("Voici"),
                    stripped.startswith("Here"),
                    stripped.startswith("#"),
                    stripped.startswith("- ") and ":" not in stripped[:20],
                    re.match(r"^\d+\.", stripped) is not None,
                ]

                if any(end_indicators):
                    break

                diagram_lines.append(line)

            # Build the diagram content
            diagram_content = "\n".join(diagram_lines).rstrip()
            end_pos = start_pos + len(diagram_content)

            # Only wrap if we found substantial content
            if len(diagram_lines) > 1 or len(diagram_content) > 20:
                wrapped = f"```mermaid\n{diagram_content}\n```"
                corrections.append((start_pos, end_pos, wrapped))
                self.logger.info(
                    f"Wrapped raw Mermaid code ({diagram_lines[0][:30]}...) in code block"
                )

        # Apply corrections in reverse order
        result = content
        for start_pos, end_pos, wrapped in reversed(corrections):
            result = result[:start_pos] + wrapped + result[end_pos:]

        if corrections:
            self.logger.warning(
                f"Wrapped {len(corrections)} raw Mermaid diagram(s) in ```mermaid``` code blocks"
            )

        return result

    def _wrap_raw_json_blocks(self, content: str) -> str:
        """Wrap raw JSON blocks (optionsblock, etc.) that are not inside code blocks.

        LLMs sometimes generate special JSON blocks like optionsblock directly in
        the text without wrapping them in ```json``` code blocks.

        Example of broken output:
            optionsblock
            {
              "question": "What do you want?",
              "options": [...]
            }

        This method detects such patterns and wraps them properly.

        Args:
            content: The content to process

        Returns:
            Content with raw JSON blocks wrapped in ```json``` code blocks
        """
        # First, identify all existing code block regions to avoid
        # Pattern handles optional indentation before opening ```
        code_block_pattern = re.compile(
            r"^[ \t]*```[\w]*\s*\n.*?^[ \t]*```", re.DOTALL | re.MULTILINE
        )
        code_block_regions: list[tuple[int, int]] = []
        for match in code_block_pattern.finditer(content):
            code_block_regions.append((match.start(), match.end()))

        def is_inside_code_block(pos: int) -> bool:
            return any(start <= pos < end for start, end in code_block_regions)

        # Pattern to match optionsblock followed by JSON
        # Matches: optionsblock\n{ ... }
        json_block_pattern = re.compile(
            r"^(optionsblock|options_block)\s*\n\s*(\{)",
            re.MULTILINE | re.IGNORECASE,
        )

        corrections: list[tuple[int, int, str]] = []

        for match in json_block_pattern.finditer(content):
            start_pos = match.start()
            keyword = match.group(1)
            brace_start = match.start(2)

            # Skip if inside an existing code block
            if is_inside_code_block(start_pos):
                continue

            # Find the matching closing brace
            brace_count = 1
            pos = brace_start + 1
            while pos < len(content) and brace_count > 0:
                char = content[pos]
                if char == "{":
                    brace_count += 1
                elif char == "}":
                    brace_count -= 1
                pos += 1

            if brace_count == 0:
                # Found complete JSON block
                json_content = content[brace_start:pos]
                end_pos = pos

                # Wrap in json code block
                wrapped = f"```json\n{json_content}\n```"
                corrections.append((start_pos, end_pos, wrapped))
                self.logger.info(f"Wrapped raw {keyword} JSON block in code block")

        # Apply corrections in reverse order
        result = content
        for start_pos, end_pos, wrapped in reversed(corrections):
            result = result[:start_pos] + wrapped + result[end_pos:]

        if corrections:
            self.logger.warning(
                f"Wrapped {len(corrections)} raw JSON block(s) in ```json``` code blocks"
            )

        return result

    def _fix_orphan_mermaid_code(self, content: str) -> str:
        """Fix Mermaid blocks that have orphan code after the closing backticks.

        LLMs sometimes close the ```mermaid``` block too early, leaving valid
        Mermaid code (like sections, tasks, comments) outside the block.

        Example of broken output:
        ```mermaid
        gantt
            title Project
            section Phase1
            Task1 :a1, 2026-01-01, 7d
        ```
            %% Comment
            section Phase2
            Task2 :b1, 2026-01-10, 5d

        This method detects such orphan code and reintegrates it into the block.

        Args:
            content: The content to process

        Returns:
            Content with orphan Mermaid code reintegrated into blocks
        """
        # Pattern to find mermaid blocks followed by potential orphan code
        # Handles optional indentation before opening ```
        mermaid_block_pattern = re.compile(
            r"(^[ \t]*```mermaid\s*\n)(.*?)(^[ \t]*```)",
            re.DOTALL | re.MULTILINE,
        )

        corrections: list[tuple[int, int, str]] = []

        for match in mermaid_block_pattern.finditer(content):
            block_start = match.start()
            block_end = match.end()
            opening = match.group(1)  # ```mermaid\n
            block_content = match.group(2)
            closing = match.group(3)  # ```

            # Look at what comes after the closing ```
            after_block = content[block_end:]

            # Check if there's orphan Mermaid code immediately after
            orphan_lines: list[str] = []
            lines_after = after_block.split("\n")

            for line in lines_after:
                stripped = line.strip()

                # Skip initial empty lines
                if not stripped and not orphan_lines:
                    continue

                # Check if this line looks like Mermaid code
                is_mermaid_line = (
                    stripped.startswith("%%")  # Mermaid comment
                    or stripped.startswith("section ")
                    or re.match(r"^\s*\w+\s*:", stripped)  # task: format
                    or re.match(r"^\s*\w+\s*-->", stripped)  # arrow
                    or re.match(r"^\s*participant\s+", stripped, re.IGNORECASE)
                    or re.match(r"^\s*actor\s+", stripped, re.IGNORECASE)
                    or stripped.startswith("title ")
                    or stripped.startswith("dateFormat ")
                    or stripped.startswith("axisFormat ")
                    or stripped.startswith("excludes ")
                    or (stripped.startswith("    ") and orphan_lines)  # Indented continuation
                    or (stripped.startswith("\t") and orphan_lines)
                )

                # Check for end indicators
                end_indicators = [
                    stripped.startswith("L'image"),
                    stripped.startswith("Le diagramme"),
                    stripped.startswith("Que voulez-vous"),
                    stripped.startswith("Que souhaitez-vous"),
                    stripped.startswith("Download"),
                    stripped.startswith("Télécharger"),
                    stripped.startswith("- Nom de fichier"),
                    stripped.startswith("- Lien"),
                    stripped.startswith("```"),  # Another code block
                    stripped.startswith("#"),  # Markdown header
                ]

                if any(end_indicators):
                    break

                if is_mermaid_line:
                    orphan_lines.append(line)
                elif stripped and orphan_lines:
                    # Non-Mermaid non-empty line after we started collecting
                    break
                elif not stripped and orphan_lines:
                    # Empty line - might be separator, check next
                    orphan_lines.append(line)

            # If we found orphan code, reintegrate it
            if orphan_lines:
                # Remove trailing empty lines from orphan
                while orphan_lines and not orphan_lines[-1].strip():
                    orphan_lines.pop()

                if orphan_lines:
                    orphan_content = "\n".join(orphan_lines)

                    # Find actual end position including orphan code
                    # We need to account for the newlines between block end and orphan
                    chars_to_orphan = 0
                    for idx, line in enumerate(lines_after):
                        if idx < len(orphan_lines):
                            chars_to_orphan += len(line) + 1  # +1 for newline
                        else:
                            break

                    new_end = block_end + chars_to_orphan

                    # Build the corrected block
                    # Ensure block_content ends with newline before adding orphan
                    if not block_content.endswith("\n"):
                        block_content += "\n"

                    corrected_block = f"{opening}{block_content}{orphan_content}\n{closing}"
                    corrections.append((block_start, new_end, corrected_block))

                    self.logger.info(
                        f"Reintegrated {len(orphan_lines)} orphan line(s) into Mermaid block"
                    )

        # Apply corrections in reverse order
        result = content
        for start_pos, end_pos, corrected in reversed(corrections):
            result = result[:start_pos] + corrected + result[end_pos:]

        if corrections:
            self.logger.warning(f"Fixed {len(corrections)} Mermaid block(s) with orphan code")

        return result

    def _extract_chartjs_from_javascript(self, js_content: str) -> str | None:
        """Extract Chart.js configuration from JavaScript code.

        LLMs sometimes generate Chart.js configs as JavaScript code like:
        ```javascript
        // Chart configuration
        const chartConfig = {
            type: "bar",
            data: {...},
            options: {...}
        };
        ```

        Or sometimes just pure JSON in a javascript block:
        ```javascript
        {
            "type": "bar",
            "data": {...}
        }
        ```

        This method extracts the JSON config from such JavaScript code.

        Args:
            js_content: The JavaScript code content

        Returns:
            Extracted JSON string in our wrapper format, or None if not a Chart.js config
        """
        import json

        # First, check if the content is pure JSON (no variable assignment)
        # This handles cases where LLM puts JSON directly in a javascript block
        cleaned_for_json = js_content.strip()
        if cleaned_for_json.startswith("{") and cleaned_for_json.endswith("}"):
            try:
                data = json.loads(cleaned_for_json)
                if isinstance(data, dict) and self._detect_content_type_from_json(data) == "chart":
                    # It's valid JSON that looks like a Chart.js config
                    if "chartConfig" not in data:
                        wrapped = {"type": "chartjs", "chartConfig": data}
                        return json.dumps(wrapped, indent=2)
                    return json.dumps(data, indent=2)
            except json.JSONDecodeError:
                # Not valid JSON, continue with pattern matching
                pass

        # Patterns to match Chart.js config assignments
        # We use a broad pattern to match any variable assignment containing an object
        # Then we validate if the object looks like a Chart.js config
        config_patterns = [
            # const/let/var anyVariableName = {...}
            # This catches: const chart1 = {...}, let chartConfig = {...}, var myChart = {...}
            re.compile(
                r"(?:const|let|var)\s+\w+\s*=\s*(\{)",
                re.IGNORECASE,
            ),
            # variableName = {...} (without declaration)
            re.compile(
                r"^\s*\w+\s*=\s*(\{)",
                re.MULTILINE,
            ),
            # new Chart(ctx, {...})
            re.compile(
                r"new\s+Chart\s*\(\s*\w+\s*,\s*(\{)",
                re.IGNORECASE,
            ),
        ]

        # First, remove JavaScript comments
        cleaned_content = js_content
        # Remove single-line comments
        cleaned_content = re.sub(r"//[^\n]*", "", cleaned_content)
        # Remove multi-line comments
        cleaned_content = re.sub(r"/\*.*?\*/", "", cleaned_content, flags=re.DOTALL)

        for pattern in config_patterns:
            match = pattern.search(cleaned_content)
            if match:
                # Found a config assignment, extract the object
                brace_start = match.end() - 1  # Position of opening brace

                # Find matching closing brace
                brace_count = 1
                pos = brace_start + 1
                while pos < len(cleaned_content) and brace_count > 0:
                    char = cleaned_content[pos]
                    if char == "{":
                        brace_count += 1
                    elif char == "}":
                        brace_count -= 1
                    pos += 1

                if brace_count == 0:
                    # Extract the object content (including braces)
                    obj_content = cleaned_content[brace_start:pos]

                    # Convert JavaScript object to JSON
                    json_content = self._js_object_to_json(obj_content)

                    if json_content:
                        # Try to parse and validate
                        try:
                            data = json.loads(json_content)
                            # Check if it's a dict and looks like a Chart.js config
                            if (
                                isinstance(data, dict)
                                and self._detect_content_type_from_json(data) == "chart"
                            ):
                                # Wrap in our expected format if needed
                                if "chartConfig" not in data:
                                    wrapped = {"type": "chartjs", "chartConfig": data}
                                    return json.dumps(wrapped, indent=2)
                                return json.dumps(data, indent=2)
                        except json.JSONDecodeError:
                            continue

        return None

    def _js_object_to_json(self, js_obj: str) -> str | None:
        """Convert a JavaScript object literal to valid JSON.

        Handles common JavaScript-to-JSON conversions:
        - Unquoted keys -> quoted keys
        - Single quotes -> double quotes
        - Trailing commas -> removed
        - JavaScript comments -> removed

        Args:
            js_obj: JavaScript object literal string

        Returns:
            Valid JSON string, or None if conversion fails
        """
        result = js_obj

        # Remove any remaining comments
        result = re.sub(r"//[^\n]*", "", result)
        result = re.sub(r"/\*.*?\*/", "", result, flags=re.DOTALL)

        # Replace single quotes with double quotes (for string values)
        # Be careful not to replace apostrophes inside strings
        result = re.sub(r"'([^']*)'", r'"\1"', result)

        # Add quotes around unquoted keys
        # Match: { key: or , key: or newline key:
        result = re.sub(
            r"([{,\n]\s*)([a-zA-Z_$][a-zA-Z0-9_$]*)\s*:",
            r'\1"\2":',
            result,
        )

        # Remove trailing commas before } or ]
        result = re.sub(r",(\s*[}\]])", r"\1", result)

        # Remove semicolons at the end
        result = result.rstrip().rstrip(";")

        return result

    def _detect_content_type_from_json(self, data: dict) -> str | None:
        """Detect if JSON data is Chart.js config or table data.

        Args:
            data: Parsed JSON data

        Returns:
            "chart" if Chart.js config, "tabledata" if table data, None otherwise
        """
        # IMPORTANT: Exclude special block types that should NOT be converted
        # These are framework-specific blocks that have their own rendering
        excluded_keys = {
            "image",  # Image blocks: {"image": {"file_id": "...", "alt": "..."}}
            "file",  # File blocks: {"file": {"file_id": "...", "name": "..."}}
            "options_block",  # Options blocks
            "form",  # Form blocks
            "audio",  # Audio blocks
            "video",  # Video blocks
        }

        # If the JSON has any of these keys at the top level, don't convert it
        if any(key in data for key in excluded_keys):
            return None

        # Check for Chart.js indicators
        chart_indicators = [
            # Has chartConfig wrapper (our expected format)
            "chartConfig" in data,
            # Has type field with valid chart type
            data.get("type") in ChartValidator.VALID_CHART_TYPES,
            # Has datasets array (Chart.js data structure)
            "datasets" in data or ("data" in data and "datasets" in data.get("data", {})),
            # Has Chart.js specific options
            "scales" in data.get("options", {}),
            # Has backgroundColor/borderColor arrays (common in charts)
            any("backgroundColor" in str(data) or "borderColor" in str(data) for _ in [1]),
        ]

        # Check for table data indicators
        table_indicators = [
            # Has headers and rows (our expected format)
            "headers" in data and "rows" in data,
            # Has caption with headers/rows
            "caption" in data and ("headers" in data or "rows" in data),
        ]

        # Count indicators
        chart_score = sum(1 for indicator in chart_indicators if indicator)
        table_score = sum(1 for indicator in table_indicators if indicator)

        # Determine type based on scores
        # Table detection is more specific, so prioritize it if both match
        if table_score >= 1 and "headers" in data and "rows" in data:
            return "tabledata"

        if chart_score >= 2:
            return "chart"

        # Single strong indicator for chart
        if data.get("type") in ChartValidator.VALID_CHART_TYPES:
            return "chart"

        if "chartConfig" in data:
            return "chart"

        return None

    def _validate_block(self, content_type: str, block_content: str) -> ValidationResult:
        """Validate a single content block.

        Routes the block to the appropriate validator based on content type.

        Args:
            content_type: The type of content (mermaid, chart, tabledata)
            block_content: The content inside the block to validate

        Returns:
            ValidationResult from the appropriate validator
        """
        # Get the ContentType enum
        content_type_enum = self.CONTENT_TYPE_MAP.get(content_type)

        if content_type_enum is None:
            # Unknown content type - return invalid result
            self.logger.warning(f"Unknown content type for validation: {content_type}")
            return ValidationResult(
                is_valid=False,
                content_type=ContentType.MERMAID,  # Default, will be replaced
                original_content=block_content,
                corrected_content=None,
                errors=[f"Unknown content type: {content_type}"],
                repairs_made=[],
            )

        # Get the validator for this content type
        validator = self.validators.get(content_type_enum)

        if validator is None:
            # No validator available - return invalid result
            self.logger.error(f"No validator available for content type: {content_type}")
            return ValidationResult(
                is_valid=False,
                content_type=content_type_enum,
                original_content=block_content,
                corrected_content=None,
                errors=[f"No validator available for content type: {content_type}"],
                repairs_made=[],
            )

        # Check if auto-repair is enabled
        if not self.config.auto_repair_enabled:
            # Validation only, no repair - just check if content is valid
            # For now, we still run the validator but won't use corrected content
            result = validator.validate(block_content)
            if result.corrected_content is not None:
                # Repairs would have been made, but auto-repair is disabled
                # Return as invalid without corrections
                self.logger.warning(
                    f"Auto-repair disabled. {content_type} block has issues but won't be repaired. "
                    f"Errors: {', '.join(result.errors)}"
                )
                return ValidationResult(
                    is_valid=False,
                    content_type=content_type_enum,
                    original_content=block_content,
                    corrected_content=None,
                    errors=result.errors,
                    repairs_made=[],
                )
            return result

        # Run validation with auto-repair
        self.logger.debug(f"Validating {content_type} block")
        result = validator.validate(block_content)

        # Log validation outcome
        if result.is_valid:
            if result.repairs_made:
                self.logger.warning(
                    f"{content_type} validation: {len(result.errors)} issue(s) found, "
                    f"{len(result.repairs_made)} repair(s) made"
                )
            else:
                self.logger.debug(f"{content_type} block is valid")
        else:
            self.logger.error(f"{content_type} validation failed: {', '.join(result.errors)}")

        return result

    def _generate_retry_message(self, content_type: ContentType) -> str:
        """Create user-friendly retry message for unrepairable content.

        When content cannot be repaired, this method generates a user-friendly
        message asking the user to retry generation.

        Args:
            content_type: The type of content that failed

        Returns:
            User-friendly retry message string
        """
        message = RETRY_MESSAGES.get(
            content_type,
            "⚠️ Le contenu n'a pas pu être généré correctement. Veuillez réessayer la génération.",
        )
        return message


def validate_rich_content(content: str, config: ValidationConfig | None = None) -> str:
    """Convenience function to validate and repair rich content in a single call.

    This is the simplest way to use the rich content validation system.
    It creates a ContentInterceptor with the given configuration and processes
    the content, returning the validated/repaired result.

    Args:
        content: The content to validate (may contain mermaid, chart, or tabledata blocks)
        config: Optional validation configuration. If None, loads from environment.

    Returns:
        Processed content with validated/repaired rich content blocks

    Example:
        >>> output = validate_rich_content(agent_response)
        >>> # output now has validated/repaired rich content blocks
    """
    interceptor = ContentInterceptor(config)
    return interceptor.process(content)
