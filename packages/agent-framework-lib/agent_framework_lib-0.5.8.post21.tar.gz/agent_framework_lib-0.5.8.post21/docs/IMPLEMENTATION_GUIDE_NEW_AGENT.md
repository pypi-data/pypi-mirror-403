# Guide d'Impl√©mentation d'un Nouvel Agent Framework

Ce document d√©taille toutes les sp√©cificit√©s √† respecter lors de la cr√©ation d'une nouvelle impl√©mentation d'agent (comme `LlamaIndexAgent`). Il est bas√© sur l'analyse approfondie de `llamaindex_agent.py` et `base_agent.py`.

## Table des Mati√®res

1. [Architecture G√©n√©rale](#1-architecture-g√©n√©rale)
2. [M√©thodes Abstraites √† Impl√©menter](#2-m√©thodes-abstraites-√†-impl√©menter)
3. [Gestion du Streaming](#3-gestion-du-streaming)
4. [Format des √âv√©nements Streaming](#4-format-des-√©v√©nements-streaming)
5. [Gestion des Activit√©s](#5-gestion-des-activit√©s)
6. [M√©triques LLM](#6-m√©triques-llm)
7. [Gestion de la M√©moire](#7-gestion-de-la-m√©moire)
8. [Gestion du Contexte et √âtat](#8-gestion-du-contexte-et-√©tat)
9. [Display Config et Enrichissement](#9-display-config-et-enrichissement)
10. [Rich Content et Validation](#10-rich-content-et-validation)
11. [Checklist d'Impl√©mentation](#11-checklist-dimpl√©mentation)

---

## 1. Architecture G√©n√©rale

### Hi√©rarchie des Classes

```
AgentInterface (ABC)
    ‚îî‚îÄ‚îÄ BaseAgent (SkillsMixin, MemoryMixin)
            ‚îî‚îÄ‚îÄ LlamaIndexAgent (impl√©mentation concr√®te)
            ‚îî‚îÄ‚îÄ VotreNouvelAgent (nouvelle impl√©mentation)
```

### Principe de S√©paration des Responsabilit√©s

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Votre Impl√©mentation (ex: OpenAIAgent)                     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  run_agent(stream=True)                                     ‚îÇ
‚îÇ    ‚îî‚îÄ> Yields RAW framework-specific events                 ‚îÇ
‚îÇ         (√©v√©nements bruts de votre framework)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  BaseAgent.handle_message_stream() [NE PAS OVERRIDE]        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Orchestre le flux streaming:                               ‚îÇ
‚îÇ    1. Appelle run_agent(stream=True)                        ‚îÇ
‚îÇ    2. Pour chaque event, appelle process_streaming_event()  ‚îÇ
‚îÇ    3. Convertit en StructuredAgentOutput                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Votre Impl√©mentation                                       ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  process_streaming_event(event)                             ‚îÇ
‚îÇ    ‚îî‚îÄ> Convertit l'√©v√©nement framework en format unifi√©     ‚îÇ
‚îÇ         Returns: {"type": "chunk", "content": "...", ...}   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2. M√©thodes Abstraites √† Impl√©menter

### 2.1 M√©thodes OBLIGATOIRES

```python
class VotreNouvelAgent(BaseAgent):
    
    def get_agent_prompt(self) -> str:
        """Retourne le prompt syst√®me par d√©faut de l'agent."""
        return """Vous √™tes un assistant IA..."""
    
    def get_agent_tools(self) -> list[callable]:
        """Retourne la liste des outils disponibles pour l'agent."""
        return [self.tool_1, self.tool_2]
    
    async def initialize_agent(
        self, 
        model_name: str, 
        system_prompt: str, 
        tools: list[callable], 
        **kwargs
    ) -> None:
        """Initialise l'agent avec le framework sous-jacent.
        
        IMPORTANT: Stocker l'instance dans self._agent_instance
        """
        # Cr√©er le LLM avec le helper
        llm = self.create_llm(model_name)
        
        # Initialiser votre agent framework
        self._agent_instance = VotreFramework.create_agent(
            llm=llm,
            tools=tools,
            system_prompt=system_prompt
        )
    
    def create_fresh_context(self) -> Any:
        """Cr√©e un nouveau contexte vide pour l'agent."""
        return VotreContextClass()
    
    def serialize_context(self, ctx: Any) -> dict[str, Any]:
        """S√©rialise le contexte pour la persistance."""
        return ctx.to_dict()
    
    def deserialize_context(self, state: dict[str, Any]) -> Any:
        """D√©s√©rialise le contexte depuis l'√©tat sauvegard√©."""
        return VotreContextClass.from_dict(state)
    
    async def run_agent(
        self, 
        query: str, 
        ctx: Any, 
        stream: bool = False
    ) -> str | AsyncGenerator:
        """Ex√©cute l'agent avec une requ√™te.
        
        CRITIQUE: En mode streaming, doit retourner un AsyncGenerator
        qui yield des √©v√©nements BRUTS de votre framework.
        """
        if not stream:
            response = await self._agent_instance.chat(query, ctx)
            return str(response)
        else:
            async def event_generator():
                async for event in self._agent_instance.stream(query, ctx):
                    yield event  # √âv√©nement BRUT
            return event_generator()
```

### 2.2 M√©thodes OPTIONNELLES (mais recommand√©es)

```python
async def process_streaming_event(self, event: Any) -> dict[str, Any] | None:
    """Convertit les √©v√©nements framework en format unifi√©.
    
    DOIT retourner un dict avec:
    - type: "chunk" | "tool_call" | "tool_result" | "activity" | "error"
    - content: str
    - metadata: dict (optionnel)
    
    Retourner None pour ignorer l'√©v√©nement.
    """
    pass

def get_mcp_server_params(self) -> dict[str, Any] | None:
    """Configuration MCP si n√©cessaire."""
    return None

def get_model_config(self) -> dict[str, Any]:
    """Configuration par d√©faut du mod√®le."""
    return {"temperature": 0.7}
```

---

## 3. Gestion du Streaming

### 3.1 Structure du handle_message_stream (NE PAS OVERRIDE)

Le `handle_message_stream` de `BaseAgent` g√®re:
1. Validation de l'input
2. Construction de la requ√™te compl√®te
3. Injection de m√©moire passive
4. Buffering du rich content
5. Consolidation des tool calls
6. √âmission des √©v√©nements format√©s

### 3.2 Impl√©mentation de process_streaming_event

```python
async def process_streaming_event(self, event: Any) -> dict[str, Any] | None:
    """Exemple d'impl√©mentation pour un framework custom."""
    event_type = type(event).__name__
    
    # Token deltas (texte stream√©)
    if event_type == "TextChunk":
        chunk = getattr(event, "text", "")
        if chunk:
            return {
                "type": "chunk",
                "content": chunk,
                "metadata": {
                    "source": "votre_agent",
                    "timestamp": datetime.now().isoformat(),
                },
            }
        return None
    
    # Appel d'outil
    if event_type == "ToolCall":
        return {
            "type": "tool_call",
            "content": "",
            "metadata": {
                "source": "votre_agent",
                "tool_name": event.tool_name,
                "tool_arguments": event.arguments,
                "call_id": event.call_id,
                "timestamp": datetime.now().isoformat(),
            },
        }
    
    # R√©sultat d'outil
    if event_type == "ToolResult":
        return {
            "type": "tool_result",
            "content": str(event.result),
            "metadata": {
                "source": "votre_agent",
                "tool_name": event.tool_name,
                "call_id": event.call_id,
                "is_error": event.is_error,
                "timestamp": datetime.now().isoformat(),
            },
        }
    
    # √âv√©nements √† ignorer
    if event_type in {"StartEvent", "StopEvent"}:
        return None
    
    # Fallback pour autres √©v√©nements
    return {
        "type": "activity",
        "content": str(event),
        "metadata": {
            "source": "votre_agent",
            "event_type": event_type,
            "timestamp": datetime.now().isoformat(),
        },
    }
```

---

## 4. Format des √âv√©nements Streaming

### 4.1 Types d'√âv√©nements Unifi√©s

| Type | Description | Champs metadata requis |
|------|-------------|------------------------|
| `chunk` | Fragment de texte | `source`, `timestamp` |
| `tool_call` | Appel d'outil | `tool_name`, `tool_arguments`, `call_id`, `timestamp` |
| `tool_result` | R√©sultat d'outil | `tool_name`, `call_id`, `is_error`, `timestamp` |
| `activity` | Activit√© g√©n√©rale | `source`, `timestamp` |
| `error` | Erreur | `timestamp` |

### 4.2 Format de Sortie (StructuredAgentOutput)

```python
# Pour les chunks de texte
yield StructuredAgentOutput(
    response_text="",
    parts=[TextOutputStreamPart(text=f"__STREAM_CHUNK__{chunk}")]
)

# Pour les activit√©s (tool calls, etc.)
yield StructuredAgentOutput(
    response_text="",
    parts=[
        activity_part,  # ActivityOutputPart pour l'ordre
        TextOutputStreamPart(
            text=f"__STREAM_ACTIVITY__{json.dumps(activity_dict)}"
        )  # Backward compatibility
    ]
)

# Message final
yield StructuredAgentOutput(
    response_text=cleaned_text,
    parts=[TextOutputPart(text=cleaned_text), *special_parts],
    streaming_activities=accumulated_activities  # Pour ES
)
```

---

## 5. Gestion des Activit√©s

### 5.1 Utilisation de StreamingPartsAccumulator

```python
from agent_framework.core.streaming_parts_accumulator import StreamingPartsAccumulator
from agent_framework.core.activity_formatter import ActivityFormatter

# Initialisation
activity_accumulator = StreamingPartsAccumulator(source=self.name or "votre_agent")
activity_formatter = ActivityFormatter(source=self.name or "votre_agent")
```

### 5.2 Consolidation Tool Request + Tool Result

**IMPORTANT**: Les tool_request et tool_result doivent √™tre consolid√©s en une seule activit√©.

```python
# Lors du tool_result, cr√©er une activit√© consolid√©e
activity_part = activity_formatter.format_tool_execution(
    tool_name=tool_name,
    arguments=tool_kwargs,
    result=tool_output,
    execution_time_ms=execution_time_ms,
    is_error=False,
)
activity_part.source = self.name or "votre_agent"

# Ajouter √† l'accumulateur
activity_accumulator.add_activity(activity_part)

# Cr√©er l'√©v√©nement backward-compatible
tool_call_event = {
    "type": "tool_call",
    "source": self.name or "votre_agent",
    "tools": [{"name": tool_name, "arguments": tool_kwargs, "id": call_id}],
    "results": [
        {
            "name": tool_name,
            "content": tool_output,
            "is_error": False,
            "call_id": call_id,
        }
    ],
    "timestamp": activity_part.timestamp,
    "display_info": activity_part.display_info,
}
```

### 5.3 Cas Sp√©ciaux d'Activit√©s

```python
# Skill loading
if tool_name in ("load_skill", "load_skill_tool"):
    activity_part = activity_formatter.format_skill_loading(
        skill_name=skill_name,
        skill_description=skill_description,
        loaded_prompt=tool_output,
        execution_time_ms=execution_time_ms,
        display_name=display_name,
        display_icon=display_icon,
    )

# Diagram generation
elif tool_name == "save_mermaid_as_image":
    activity_part = activity_formatter.format_diagram_generation(
        diagram_type=diagram_type,
        file_name=file_name,
        content=mermaid_code,
        execution_time_ms=execution_time_ms,
    )

# Chart generation
elif tool_name == "save_chart_as_image":
    activity_part = activity_formatter.format_chart_generation(
        chart_type=chart_type,
        file_name=file_name,
        content=content,
        execution_time_ms=execution_time_ms,
    )
```

---

## 6. M√©triques LLM

### 6.1 Attributs Requis

```python
def __init__(self, ...):
    # M√©triques LLM
    self._metrics_enabled: bool = True  # Configurable via env ENABLE_LLM_METRICS
    self._metrics_collector: LLMMetricsCollector | None = None
    self._last_llm_metrics: LLMMetrics | None = None
    self._api_timing_tracker: Any | None = None
```

### 6.2 Cycle de Vie des M√©triques

```python
# 1. Cr√©ation du collector au d√©but de l'appel
self._metrics_collector = self._create_metrics_collector()
if self._metrics_collector:
    self._metrics_collector.start()
    self._metrics_collector.count_input(full_query)

# 2. Pendant le streaming
if not first_token_recorded and self._metrics_collector:
    self._metrics_collector.record_first_token()
    first_token_recorded = True

# 3. Pour les tool calls
if self._metrics_collector:
    self._metrics_collector.start_tool_call(call_id)
    # ... apr√®s ex√©cution ...
    self._metrics_collector.end_tool_call(call_id)
    self._metrics_collector.count_tool_call_tokens(tool_call_data)
    self._metrics_collector.count_thinking(tool_output)

# 4. √Ä la fin
if self._metrics_collector:
    self._metrics_collector.count_output(full_output)
    self._last_llm_metrics = self._finish_metrics_collection()
    if self._last_llm_metrics:
        await self._update_session_llm_stats(self._last_llm_metrics)
    self._metrics_collector = None
```

---

## 7. Gestion de la M√©moire

### 7.1 Attributs de Session

```python
def __init__(self, ...):
    self._session_storage: Any | None = None
    self._memory_adapter: Any | None = None  # SP√âCIFIQUE AU FRAMEWORK
    self._current_memory: Any | None = None  # Type d√©pend du framework
    self._current_session_id: str | None = None
    self._current_user_id: str | None = None
    self._current_model: str | None = None
```

### 7.2 Configuration de Session avec M√©moire

```python
async def configure_session(self, session_configuration: dict[str, Any]) -> None:
    user_id = session_configuration.get("user_id")
    session_id = session_configuration.get("session_id")
    
    session_changed = (
        session_id != self._current_session_id or 
        user_id != self._current_user_id
    )
    
    # TOUJOURS mettre √† jour user_id et session_id
    if user_id:
        self._current_user_id = user_id
    if session_id:
        self._current_session_id = session_id
    
    if session_changed and session_id and user_id:
        self._current_memory = await self._load_memory_for_session(
            session_id, user_id, self._current_model
        )
    
    await super().configure_session(session_configuration)
```

### 7.3 Memory Adapter - SP√âCIFIQUE AU FRAMEWORK

‚ö†Ô∏è **IMPORTANT**: Le Memory Adapter est **enti√®rement sp√©cifique au framework**.

`LlamaIndexMemoryAdapter` manipule des classes LlamaIndex:
- `ChatMemoryBuffer` - buffer de m√©moire LlamaIndex
- `ChatMessage` - format de message LlamaIndex
- `ToolCallBlock` - blocs d'appels d'outils LlamaIndex
- `chat_store.store[store_key]` - structure interne LlamaIndex

**Pour un nouveau framework, vous devez cr√©er votre propre Memory Adapter** qui:
1. Charge l'historique depuis `SessionStorage` (interface commune)
2. Convertit les `MessageData` vers le format de votre framework
3. Cr√©e l'objet m√©moire de votre framework
4. G√®re la sanitization cross-provider pour VOTRE framework

```python
# Exemple de structure pour un nouveau Memory Adapter
class VotreFrameworkMemoryAdapter:
    """Adapter entre SessionStorage et la m√©moire de VotreFramework."""
    
    def __init__(self, session_storage: SessionStorageInterface):
        self.session_storage = session_storage
        self._memory_cache: dict[str, VotreMemoryType] = {}
    
    async def get_memory_for_session(
        self, 
        session_id: str,
        user_id: str,
        model_name: str | None = None,
    ) -> VotreMemoryType:
        """Charge ou cr√©e la m√©moire pour une session."""
        # 1. Charger l'historique depuis SessionStorage (commun)
        message_history = await self.session_storage.get_conversation_history(
            session_id=session_id,
            limit=100
        )
        
        # 2. Convertir vers le format de VOTRE framework
        framework_messages = self._convert_to_framework_messages(message_history)
        
        # 3. Cr√©er l'objet m√©moire de VOTRE framework
        memory = VotreFramework.create_memory(framework_messages)
        
        return memory
    
    def sanitize_memory_buffer(
        self, 
        memory: VotreMemoryType, 
        target_provider: str | None = None
    ) -> None:
        """Sanitize la m√©moire pour compatibilit√© cross-provider.
        
        DOIT g√©rer les incompatibilit√©s sp√©cifiques √† VOTRE framework:
        - Format des tool_calls (OpenAI vs Anthropic vs Gemini)
        - Champs sp√©cifiques aux providers
        - Structures internes de VOTRE framework
        """
        # Acc√©der aux messages internes de VOTRE framework
        messages = memory.get_messages()  # API de votre framework
        
        for msg in messages:
            # Sanitizer selon le target_provider
            if target_provider == 'openai':
                # OpenAI: tool_calls.function.arguments = JSON string
                # Supprimer champs Anthropic
                pass
            elif target_provider in ('anthropic', 'gemini'):
                # Anthropic/Gemini: tool_calls.input = dict
                # Supprimer champs OpenAI
                pass
```

### 7.4 Incompatibilit√©s Cross-Provider √† G√©rer

Lors du changement de mod√®le (ex: GPT-4 ‚Üí Claude), la m√©moire contient des messages
format√©s pour l'ancien provider. Votre sanitization doit g√©rer:

| Aspect | OpenAI | Anthropic | Gemini |
|--------|--------|-----------|--------|
| Tool call args | `function.arguments` (JSON string) | `input` (dict) | `args` (dict) |
| Empty tool_calls | ‚ùå Rejet√© | ‚úÖ OK | ‚úÖ OK |
| Champs sp√©cifiques | `function_call`, `refusal` | `stop_reason`, `usage` | - |

```python
# Exemple de conversion OpenAI ‚Üí Anthropic
def _convert_tool_call_openai_to_anthropic(self, tc: dict) -> dict:
    """Convertit un tool_call format OpenAI vers Anthropic."""
    func = tc.get('function', {})
    args_str = func.get('arguments', '{}')
    
    # OpenAI: arguments est un JSON string
    # Anthropic: input est un dict
    try:
        args_dict = json.loads(args_str)
    except json.JSONDecodeError:
        args_dict = {}
    
    return {
        'id': tc.get('id', ''),
        'name': func.get('name', ''),
        'input': args_dict  # dict, pas string
    }
```

---

## 8. Gestion du Contexte et √âtat

### 8.1 get_state et load_state

```python
async def get_state(self) -> dict[str, Any]:
    """R√©cup√®re l'√©tat actuel de l'agent."""
    if self._state_ctx is None:
        return {}
    try:
        return self.serialize_context(self._state_ctx)
    finally:
        # Pattern one-time retrieval
        self._state_ctx = None

async def load_state(self, state: dict[str, Any]):
    """Charge l'√©tat de l'agent depuis un dictionnaire."""
    await self._async_ensure_agent_built()
    if state:
        try:
            self._state_ctx = self.deserialize_context(state)
        except Exception as e:
            logger.error(f"Failed to load context state: {e}. Starting fresh.")
            self._state_ctx = self.create_fresh_context()
    else:
        self._state_ctx = self.create_fresh_context()
```

### 8.2 Sauvegarde du Contexte Apr√®s Streaming

```python
# √Ä la fin du streaming
final_response = await handler
self._state_ctx = ctx  # IMPORTANT: sauvegarder le contexte
```

---

## 9. Display Config et Enrichissement

### 9.1 Configuration du DisplayConfigManager

```python
def set_display_config_manager(self, manager: DisplayConfigManager | None) -> None:
    """Configure le manager pour l'enrichissement des √©v√©nements."""
    self._display_config_manager = manager

def _enrich_event(self, event: dict[str, Any]) -> dict[str, Any]:
    """Enrichit un √©v√©nement avec les infos d'affichage."""
    if self._display_config_manager is not None:
        return enrich_event_with_display_info(
            event, 
            self._display_config_manager, 
            agent_id=self.agent_id
        )
    return event
```

### 9.2 Utilisation dans le Streaming

```python
# Enrichir chaque √©v√©nement avant √©mission
loop_activity = {
    "type": "activity",
    "source": "agent",
    "content": "Agent loop started",
    "timestamp": datetime.now(timezone.utc).isoformat(),
}
loop_activity = self._enrich_event(loop_activity)
```

---

## 10. Rich Content et Validation

### 10.1 Buffering du Rich Content

```python
import re

pending_buffer = ""
RICH_CONTENT_PATTERN = re.compile(
    r"^[ \t]*```(mermaid|chart|chartjs|tabledata)\s*\n(.*?)^[ \t]*```",
    re.DOTALL | re.MULTILINE,
)

# Pendant le streaming
pending_buffer += chunk

while True:
    match = RICH_CONTENT_PATTERN.search(pending_buffer)
    if match:
        # Envoyer le texte avant le bloc
        before = pending_buffer[: match.start()]
        if before:
            yield StructuredAgentOutput(
                response_text="",
                parts=[TextOutputStreamPart(text=f"__STREAM_CHUNK__{before}")]
            )
        
        # Valider et envoyer le bloc
        block = match.group(0)
        try:
            from ..processing.rich_content_validation import validate_rich_content
            validated = validate_rich_content(block)
            yield StructuredAgentOutput(
                response_text="",
                parts=[TextOutputStreamPart(text=f"__STREAM_CHUNK__{validated}")]
            )
        except Exception:
            yield StructuredAgentOutput(
                response_text="",
                parts=[TextOutputStreamPart(text=f"__STREAM_CHUNK__{block}")]
            )
        
        pending_buffer = pending_buffer[match.end():]
    else:
        # V√©rifier si on est dans un bloc ouvert
        # ... logique de d√©tection ...
        break
```

### 10.2 Flush du Buffer Avant Tool Call

**CRITIQUE**: Toujours flush le buffer AVANT d'√©mettre une activit√© tool.

```python
if pending_buffer:
    try:
        validated = validate_rich_content(pending_buffer)
        yield StructuredAgentOutput(
            response_text="",
            parts=[TextOutputStreamPart(text=f"__STREAM_CHUNK__{validated}")]
        )
    except Exception:
        yield StructuredAgentOutput(
            response_text="",
            parts=[TextOutputStreamPart(text=f"__STREAM_CHUNK__{pending_buffer}")]
        )
    pending_buffer = ""

# Puis √©mettre l'activit√© tool
```

---

## 11. Checklist d'Impl√©mentation

### Validation Automatique

Utilisez le validateur int√©gr√© pour v√©rifier votre impl√©mentation:

```python
from agent_framework.core.implementation_validator import validate_agent_implementation

# Valider une classe
report = await validate_agent_implementation(MonNouvelAgent)

# Ou valider une instance (inclut les tests runtime)
agent = MonNouvelAgent(agent_id="test", name="Test", description="Test")
report = await validate_agent_implementation(agent)

# V√©rifier le r√©sultat
if report.is_valid:
    print("‚úÖ Impl√©mentation valide!")
else:
    print("‚ùå Erreurs √† corriger:")
    print(report)
```

Le validateur v√©rifie:
- ‚úÖ H√©ritage correct (BaseAgent)
- ‚úÖ M√©thodes requises impl√©ment√©es
- ‚úÖ Signatures de m√©thodes correctes
- ‚úÖ M√©thodes finales non overrid√©es
- ‚úÖ Attributs requis initialis√©s
- ‚úÖ M√©thodes async correctement d√©finies
- ‚úÖ Handler d'√©v√©nements streaming
- ‚úÖ Pattern Memory Adapter
- ‚úÖ Tests runtime (prompt, tools, context roundtrip)

### Checklist Manuelle

### M√©thodes Obligatoires
- [ ] `get_agent_prompt()` - Prompt syst√®me par d√©faut
- [ ] `get_agent_tools()` - Liste des outils
- [ ] `initialize_agent()` - Initialisation du framework
- [ ] `create_fresh_context()` - Cr√©ation de contexte
- [ ] `serialize_context()` - S√©rialisation
- [ ] `deserialize_context()` - D√©s√©rialisation
- [ ] `run_agent()` - Ex√©cution (streaming et non-streaming)

### Streaming
- [ ] `process_streaming_event()` - Conversion des √©v√©nements
- [ ] Gestion des chunks de texte
- [ ] Gestion des tool_call
- [ ] Gestion des tool_result
- [ ] Consolidation tool_request + tool_result
- [ ] Buffering du rich content
- [ ] Flush du buffer avant tool activities

### Activit√©s
- [ ] Utilisation de `StreamingPartsAccumulator`
- [ ] Utilisation de `ActivityFormatter`
- [ ] Cas sp√©ciaux (skill loading, diagram, chart)
- [ ] Format backward-compatible `__STREAM_ACTIVITY__`

### M√©triques
- [ ] Initialisation du collector
- [ ] Count input tokens
- [ ] Record first token
- [ ] Track tool call timing
- [ ] Count output tokens
- [ ] Update session stats

### M√©moire
- [ ] Gestion de `_current_user_id` et `_current_session_id`
- [ ] **Cr√©er un Memory Adapter sp√©cifique √† votre framework**
- [ ] Chargement de la m√©moire par session
- [ ] Sanitization cross-provider **pour votre framework**
- [ ] Injection passive de m√©moire

### √âtat
- [ ] Sauvegarde du contexte apr√®s streaming
- [ ] Impl√©mentation de `get_state()` et `load_state()`

### Display
- [ ] Support de `DisplayConfigManager`
- [ ] Enrichissement des √©v√©nements avec `_enrich_event()`

### M√©tadonn√©es
- [ ] Override de `get_metadata()` avec les capacit√©s sp√©cifiques

---

## Exemple Complet Minimal

```python
"""Exemple d'impl√©mentation minimale d'un nouvel agent."""

from datetime import datetime, timezone
from typing import Any, AsyncGenerator

from agent_framework.core.base_agent import BaseAgent
from agent_framework.core.agent_interface import (
    StructuredAgentInput,
    StructuredAgentOutput,
    TextOutputStreamPart,
)


class MonNouvelAgent(BaseAgent):
    """Impl√©mentation d'agent pour MonFramework."""

    def __init__(
        self,
        agent_id: str,
        name: str,
        description: str,
        **kwargs
    ):
        self._agent_instance = None
        super().__init__(
            agent_id=agent_id,
            name=name,
            description=description,
            **kwargs
        )

    def get_agent_prompt(self) -> str:
        return "Vous √™tes un assistant IA utile."

    def get_agent_tools(self) -> list[callable]:
        return []

    async def initialize_agent(
        self,
        model_name: str,
        system_prompt: str,
        tools: list[callable],
        **kwargs
    ) -> None:
        llm = self.create_llm(model_name)
        # Initialiser votre framework ici
        self._agent_instance = ...

    def create_fresh_context(self) -> Any:
        return {}

    def serialize_context(self, ctx: Any) -> dict[str, Any]:
        return ctx

    def deserialize_context(self, state: dict[str, Any]) -> Any:
        return state

    async def run_agent(
        self,
        query: str,
        ctx: Any,
        stream: bool = False
    ) -> str | AsyncGenerator:
        if not stream:
            # Mode non-streaming
            response = await self._agent_instance.chat(query)
            return str(response)
        else:
            # Mode streaming
            async def generator():
                async for event in self._agent_instance.stream(query):
                    yield event
            return generator()

    async def process_streaming_event(self, event: Any) -> dict[str, Any] | None:
        event_type = type(event).__name__
        
        if event_type == "TextChunk":
            return {
                "type": "chunk",
                "content": event.text,
                "metadata": {"timestamp": datetime.now().isoformat()},
            }
        
        return None
```


---

## Annexe A: Sp√©cificit√©s LlamaIndex √† Reproduire

### A.1 Gestion des √âv√©nements LlamaIndex

LlamaIndex √©met des √©v√©nements sp√©cifiques qu'il faut mapper:

| √âv√©nement LlamaIndex | Type Unifi√© | Action |
|---------------------|-------------|--------|
| `AgentStream` | `chunk` | Extraire `event.delta` |
| `ToolCallResult` | `tool_call` + `tool_result` | Consolider en une activit√© |
| `AgentInput` / `InputEvent` | `activity` | "Agent loop started" |
| `AgentOutput` | - | Ignorer |
| `StopEvent` / `StartEvent` | - | Ignorer |
| `ToolCall` | - | Tracker timing, ne pas √©mettre |

### A.2 Pattern de Streaming LlamaIndex

```python
async def handle_message_stream(self, session_id, agent_input):
    # 1. Initialisation
    handler = self._run_agent_stream_internal(full_query, ctx, **run_kwargs)
    
    # 2. Boucle sur les √©v√©nements
    async for event in handler.stream_events():
        event_type = type(event).__name__
        
        # AgentStream = chunks de texte
        if event_type == "AgentStream":
            chunk = getattr(event, "delta", "")
            # ... traitement ...
        
        # ToolCallResult = r√©sultat d'outil (consolid√©)
        elif event_type == "ToolCallResult":
            tool_name = getattr(event, "tool_name", "unknown_tool")
            tool_kwargs = getattr(event, "tool_kwargs", {})
            call_id = getattr(event, "call_id", "unknown")
            tool_output = str(getattr(event, "tool_output", ""))
            # ... cr√©er activit√© consolid√©e ...
    
    # 3. R√©sultat final
    final_response = await handler
    self._state_ctx = ctx
```

### A.3 Helper create_llm

LlamaIndexAgent fournit un helper pour cr√©er les LLM:

```python
def create_llm(
    self, 
    model_name: str = None, 
    agent_config: AgentConfig = None, 
    **override_params
) -> Any:
    """Cr√©e un LLM LlamaIndex via ModelClientFactory."""
    return client_factory.create_llamaindex_llm(
        model_name=model_name, 
        agent_config=agent_config, 
        **override_params
    )
```

---

## Annexe B: Structures de Donn√©es Cl√©s

### B.1 ActivityOutputPart

```python
class ActivityOutputPart(BaseModel):
    type: Literal["activity"] = "activity"
    activity_type: str  # "tool_call", "skill_loading", "diagram_generation", etc.
    source: str  # Nom de l'agent
    content: str | None = None  # Texte user-friendly
    timestamp: str  # ISO 8601
    tools: list[dict[str, Any]] | None = None  # Pour tool_request
    results: list[dict[str, Any]] | None = None  # Pour tool_result
    display_info: dict[str, Any] | None = None  # M√©tadonn√©es UI
    technical_details: TechnicalDetails | None = None  # Pour ES uniquement
```

### B.2 TechnicalDetails

```python
class TechnicalDetails(BaseModel):
    function_name: str
    arguments: dict[str, Any]
    raw_result: str  # JSON string pour ES
    execution_time_ms: int
    timestamp: str
    status: Literal["success", "error"]
    error_message: str | None = None
```

### B.3 Format __STREAM_ACTIVITY__

```python
{
    "type": "tool_call",  # ou "activity", "error", "other"
    "source": "agent_name",
    "tools": [{"name": "...", "arguments": {...}, "id": "..."}],
    "results": [{"name": "...", "content": "...", "is_error": False, "call_id": "..."}],
    "timestamp": "2024-01-15T10:30:00Z",
    "display_info": {
        "id": "tool_search_web",
        "friendly_name": "üîç Recherche web",
        "description": "...",
        "icon": "üîç",
        "category": "search"
    }
}
```

---

## Annexe C: Imports Essentiels

```python
# Core
from agent_framework.core.base_agent import BaseAgent, SKILLS_AVAILABLE
from agent_framework.core.agent_interface import (
    ActivityOutputPart,
    AgentConfig,
    StructuredAgentInput,
    StructuredAgentOutput,
    TextOutputPart,
    TextOutputStreamPart,
)
from agent_framework.core.model_clients import client_factory

# Streaming et Activit√©s
from agent_framework.core.streaming_parts_accumulator import StreamingPartsAccumulator
from agent_framework.core.activity_formatter import ActivityFormatter
from agent_framework.core.step_display_config import (
    DisplayConfigManager, 
    enrich_event_with_display_info
)

# Utilitaires
from agent_framework.utils.special_blocks import parse_special_blocks_from_text

# M√©triques (optionnel)
try:
    from agent_framework.monitoring import LLMMetrics, LLMMetricsCollector
    LLM_METRICS_AVAILABLE = True
except ImportError:
    LLM_METRICS_AVAILABLE = False
```

---

## Annexe D: Variables d'Environnement

| Variable | Description | D√©faut |
|----------|-------------|--------|
| `ENABLE_LLM_METRICS` | Active la collecte de m√©triques | `true` |
| `ENABLE_SKILLS` | Active le syst√®me de skills | `true` |
| `OPENAI_API_MODEL` | Mod√®le par d√©faut | - |

---

## Annexe E: Erreurs Courantes √† √âviter

1. **Ne pas override `handle_message_stream`** - Utiliser `run_agent` et `process_streaming_event`

2. **Oublier de flush le buffer avant les tool activities** - Cause des probl√®mes d'ordre

3. **Ne pas consolider tool_request + tool_result** - Cr√©e du bruit dans l'UI

4. **Oublier de sauvegarder `self._state_ctx`** - Perte de l'historique de conversation

5. **Ne pas mettre √† jour `_current_user_id`** - Probl√®mes d'isolation Graphiti

6. **R√©utiliser `LlamaIndexMemoryAdapter` pour un autre framework** - Le Memory Adapter est 100% sp√©cifique au framework. Vous DEVEZ cr√©er votre propre adapter.

7. **Ne pas enrichir les √©v√©nements** - Perte des friendly names dans l'UI
