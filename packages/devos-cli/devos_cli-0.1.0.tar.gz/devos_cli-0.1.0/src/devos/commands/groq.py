"""CLI-friendly Groq AI commands."""

import click
import asyncio
from pathlib import Path
from typing import Optional

from devos.core.progress import show_success, show_info, show_warning, show_operation_status
from devos.core.ai_config import get_ai_config_manager, initialize_ai_providers
from devos.core.ai import get_ai_service, AIServiceError, UserPreferences
from devos.core.ai.enhanced_context import EnhancedContextBuilder


@click.command()
@click.argument('prompt')
@click.option('--model', default='llama-3.1-8b-instant', help='Groq model to use')
@click.option('--temp', type=float, default=0.7, help='Temperature (0.0-1.0)')
@click.option('--max-tokens', type=int, default=1000, help='Maximum tokens')
@click.option('--file', '-f', type=click.Path(exists=True), help='Include file context')
@click.option('--quick', is_flag=True, help='Skip deep analysis for faster response')
def groq(prompt: str, model: str, temp: float, max_tokens: int, file: Optional[str], quick: bool):
    """Fast AI assistance using Groq.
    
    Examples:
        groq "create a python function to validate email"
        groq "explain this code" --file main.py
        groq "how to optimize this database query" --temp 0.3
    """
    
    async def _run_groq():
        try:
            ai_service = await get_ai_service()
            
            if quick:
                # Quick mode - skip deep analysis
                show_info("‚ö° Quick mode - skipping deep analysis...")
                full_prompt = prompt
                
                if file:
                    file_path = Path(file)
                    file_content = file_path.read_text()
                    full_prompt += f"\n\nFile: {file}\n```\n{file_content}\n```"
            else:
                # Build enhanced context for project understanding
                project_path = Path(file).parent if file else Path.cwd()
                context_builder = EnhancedContextBuilder()
                
                # Build context with progress indication
                show_info("üîÑ Building project context...")
                enhanced_context = await context_builder.build_enhanced_context(project_path)
                show_info(f"‚úÖ Analyzed {enhanced_context.architecture.total_files} files")
                
                # Create project-specific context prompt
                context_prompt = _build_project_context_prompt(enhanced_context, prompt)
                
                # Build full prompt with file context if provided
                full_prompt = context_prompt
                if file:
                    file_path = Path(file)
                    file_content = file_path.read_text()
                    full_prompt += f"\n\nFile: {file}\n```\n{file_content}\n```"
            
            response = await ai_service.generate_code(
                query=full_prompt,
                project_path=Path.cwd(),
                user_preferences=UserPreferences(
                    coding_style="clean",
                    preferred_patterns=[],
                    ai_model=model,
                    temperature=temp,
                    max_tokens=max_tokens
                ),
                provider_name="groq"
            )
            
            click.echo("üöÄ Groq Response:")
            click.echo("=" * 50)
            click.echo(response.content)
            
            if response.tokens_used > 0:
                click.echo(f"\n‚ö° Tokens: {response.tokens_used} | Cost: ${response.cost:.6f}")
                click.echo(f"ü¶ä Model: {model} | Speed: Fast!")
                
        except AIServiceError as e:
            show_warning(f"Groq error: {e}")
        except Exception as e:
            show_warning(f"Command failed: {e}")
    
    asyncio.run(_run_groq())


def _build_project_context_prompt(enhanced_context, user_prompt: str) -> str:
    """Build project-specific context prompt for AI."""
    arch = enhanced_context.architecture
    base_context = enhanced_context.base_context
    
    # Detect project type
    project_type = "Python CLI"
    if "python" in arch.languages:
        if "cli" in base_context.project_path.name.lower() or any("cli" in str(f).lower() for f in list(enhanced_context.file_analysis.keys())[:5]):
            project_type = "Python CLI"
        elif "django" in arch.frameworks or "flask" in arch.frameworks:
            project_type = "Python Web"
        elif "fastapi" in arch.frameworks:
            project_type = "Python API"
    
    # Get key files from file analysis
    key_files = list(enhanced_context.file_analysis.keys())[:10]
    
    context_prompt = f"""You are DevOS AI, an expert assistant for this {project_type} project.

PROJECT OVERVIEW:
- Name: {base_context.project_path.name}
- Type: {project_type}
- Total Files: {arch.total_files}
- Total Lines: {arch.total_lines:,}
- Languages: {', '.join(arch.languages.keys())}
- Frameworks: {', '.join(arch.frameworks)}
- Architecture Patterns: {', '.join(arch.architecture_patterns)}
- Security Score: {arch.security_score}/100

KEY FILES:
{', '.join(key_files)}

CURRENT REQUEST: {user_prompt}

IMPORTANT: Provide responses specific to this {project_type} project. Use Python syntax and best practices. Consider the existing project structure and frameworks.
"""
    
    return context_prompt


@click.command()
@click.argument('file_path', type=click.Path(exists=True))
@click.option('--model', default='llama-3.1-8b-instant', help='Groq model to use')
@click.option('--focus', type=click.Choice(['security', 'performance', 'style', 'all']), default='all', help='Review focus')
def groq_review(file_path: str, model: str, focus: str):
    """Fast code review using Groq.
    
    Examples:
        groq-review main.py
        groq-review . --focus security
        groq-review app.py --model llama3-8b-8192
    """
    
    async def _run_review():
        try:
            ai_service = await get_ai_service()
            path = Path(file_path)
            
            if path.is_file():
                # Single file review
                code = path.read_text()
                result = await ai_service.analyze_code(
                    code=code,
                    project_path=path.parent,
                    user_preferences=UserPreferences(
                        coding_style="clean",
                        preferred_patterns=[],
                        ai_model=model,
                        temperature=0.1,
                        max_tokens=1500
                    ),
                    provider_name="groq"
                )
                
                click.echo(f"üîç Code Review: {file_path}")
                click.echo("=" * 50)
                
                if result.issues:
                    for issue in result.issues:
                        severity_emoji = {'low': 'üü°', 'medium': 'üü†', 'high': 'üî¥'}
                        click.echo(f"{severity_emoji.get(issue['severity'], '‚ö™')} {issue['message']}")
                        if issue.get('suggestion'):
                            click.echo(f"   üí° {issue['suggestion']}")
                
                if result.suggestions:
                    click.echo("\nüí° Suggestions:")
                    for suggestion in result.suggestions:
                        click.echo(f"‚Ä¢ {suggestion}")
                
                click.echo(f"\nüìä Score: {result.score}/10")
                
            else:
                show_warning("Directory review not yet supported. Use specific file.")
                
        except AIServiceError as e:
            show_warning(f"Groq error: {e}")
        except Exception as e:
            show_warning(f"Review failed: {e}")
    
    asyncio.run(_run_review())


@click.command()
@click.argument('file_path', type=click.Path(exists=True))
@click.option('--model', default='llama-3.1-8b-instant', help='Groq model to use')
@click.option('--query', default='Explain this code', help='What to explain')
def groq_explain(file_path: str, model: str, query: str):
    """Fast code explanation using Groq.
    
    Examples:
        groq-explain main.py
        groq-explain complex_function.py --query "How does this work?"
        groq-explain algorithm.py --model llama3-8b-8192
    """
    
    async def _run_explain():
        try:
            ai_service = await get_ai_service()
            path = Path(file_path)
            
            code = path.read_text()
            response = await ai_service.explain_code(
                code=code,
                query=query,
                project_path=path.parent,
                user_preferences=UserPreferences(
                    coding_style="clean",
                    preferred_patterns=[],
                    ai_model=model,
                    temperature=0.2,
                    max_tokens=800
                ),
                provider_name="groq"
            )
            
            click.echo(f"üìñ Explanation: {file_path}")
            click.echo("=" * 50)
            click.echo(response.content)
            
            if response.tokens_used > 0:
                click.echo(f"\n‚ö° Tokens: {response.tokens_used} | Cost: ${response.cost:.6f}")
                
        except AIServiceError as e:
            show_warning(f"Groq error: {e}")
        except Exception as e:
            show_warning(f"Explanation failed: {e}")
    
    asyncio.run(_run_explain())


@click.command()
@click.option('--model', default='llama-3.1-8b-instant', help='Groq model to use')
@click.option('--temp', type=float, default=0.7, help='Temperature (0.0-1.0)')
def groq_chat(model: str, temp: float):
    """Interactive chat with Groq.
    
    Examples:
        groq-chat
        groq-chat --model llama3-8b-8192
        groq-chat --temp 0.3
    """
    
    async def _run_chat():
        try:
            ai_service = await get_ai_service()
            
            click.echo("üí¨ Groq Chat (type 'exit' to quit)")
            click.echo("=" * 50)
            click.echo(f"ü¶ä Model: {model} | ‚ö° Fast inference")
            
            conversation = []
            
            while True:
                try:
                    user_input = click.prompt("\nYou", type=str, show_default=False)
                    
                    if user_input.lower() in ['exit', 'quit', 'q']:
                        click.echo("üëã Goodbye!")
                        break
                    
                    conversation.append({"role": "user", "content": user_input})
                    
                    response = await ai_service.chat(
                        conversation=conversation,
                        project_path=Path.cwd(),
                        user_preferences=UserPreferences(
                            coding_style="clean",
                            preferred_patterns=[],
                            ai_model=model,
                            temperature=temp,
                            max_tokens=1000
                        ),
                        provider_name="groq"
                    )
                    
                    conversation.append({"role": "assistant", "content": response.content})
                    
                    click.echo(f"\nü§ñ Groq: {response.content}")
                    
                    if response.tokens_used > 0:
                        click.echo(f"‚ö° Tokens: {response.tokens_used} | Cost: ${response.cost:.6f}")
                        
                except KeyboardInterrupt:
                    click.echo("\nüëã Goodbye!")
                    break
                except Exception as e:
                    show_warning(f"Chat error: {e}")
                    
        except AIServiceError as e:
            show_warning(f"Groq error: {e}")
        except Exception as e:
            show_warning(f"Chat failed: {e}")
    
    asyncio.run(_run_chat())


@click.command()
@click.argument('prompt')
@click.option('--language', help='Target programming language')
@click.option('--model', default='llama-3.1-8b-instant', help='Groq model to use')
def groq_generate(prompt: str, language: Optional[str], model: str):
    """Generate code using Groq.
    
    Examples:
        groq-generate "function to sort array"
        groq-generate "REST API endpoint" --language python
        groq-generate "React component" --language javascript --model llama3-8b-8192
    """
    
    async def _run_generate():
        try:
            ai_service = await get_ai_service()
            
            full_prompt = f"Generate code: {prompt}"
            if language:
                full_prompt += f"\nLanguage: {language}"
            
            response = await ai_service.generate_code(
                query=full_prompt,
                project_path=Path.cwd(),
                user_preferences=UserPreferences(
                    coding_style="clean",
                    preferred_patterns=[],
                    ai_model=model,
                    temperature=0.3,
                    max_tokens=1500
                ),
                provider_name="groq"
            )
            
            click.echo("üîß Generated Code:")
            click.echo("=" * 50)
            click.echo(response.content)
            
            if response.tokens_used > 0:
                click.echo(f"\n‚ö° Tokens: {response.tokens_used} | Cost: ${response.cost:.6f}")
                click.echo(f"ü¶ä Model: {model}")
                
        except AIServiceError as e:
            show_warning(f"Groq error: {e}")
        except Exception as e:
            show_warning(f"Generation failed: {e}")
    
    asyncio.run(_run_generate())


@click.command()
def groq_status():
    """Show Groq status and configuration.
    
    Examples:
        groq-status
    """
    
    config_manager = get_ai_config_manager()
    providers = config_manager.list_providers()
    
    click.echo("ü¶ä Groq Status")
    click.echo("=" * 30)
    
    if providers.get("groq", False):
        click.echo("‚úÖ Groq is configured")
        
        # Show available models
        models = [
            ("llama-3.1-8b-instant", "Fast & efficient", "$0.05/1M tokens"),
            ("llama-3.1-70b-versatile", "High performance", "$0.59/1M tokens"),
            ("mixtral-8x7b-32768", "Multilingual", "$0.24/1M tokens"),
            ("gemma2-9b-it", "Google model", "$0.07/1M tokens")
        ]
        
        click.echo("\nüöÄ Available Models:")
        for model, description, cost in models:
            click.echo(f"  {model:20} {description:15} {cost}")
        
        click.echo("\nüí° Quick Start:")
        click.echo("  groq \"create a python function\"")
        click.echo("  groq-review main.py")
        click.echo("  groq-chat")
        
    else:
        click.echo("‚ùå Groq not configured")
        click.echo("\nüîß Setup:")
        click.echo("  export GROQ_API_KEY=<your-api-key>")
        click.echo("  devos ai-config set-api-key groq")
        click.echo("  groq-status")
