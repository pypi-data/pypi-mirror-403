{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# DuckGuard 2.3 - Getting Started Guide\n",
    "\n",
    "**DuckGuard** is a Python-native data quality tool built on DuckDB for speed.\n",
    "\n",
    "## What's New in v2.2\n",
    "- **Freshness Monitoring**: Detect stale data via file mtime or column timestamps\n",
    "- **ML-Based Anomaly Detection**: Auto-learn baselines, KS-test for distribution drift\n",
    "- **Schema Evolution Tracking**: Track schema changes and detect breaking changes\n",
    "- **Email Notifications**: SMTP-based alerts with HTML formatting\n",
    "- **Reference/FK Checks**: Validate foreign key relationships across datasets\n",
    "- **Cross-Dataset Validation**: Compare columns and row counts between datasets\n",
    "- **Reconciliation**: Comprehensive dataset comparison for migration validation\n",
    "- **Distribution Drift Detection**: KS-test based drift detection for ML pipelines\n",
    "- **Group By Checks**: Segmented validation for partition-level quality checks\n",
    "\n",
    "## What's in v2.1\n",
    "- **Slack/Teams Notifications**: Get alerts when data quality checks fail\n",
    "- **Row-Level Error Capture**: See exactly which rows failed validation\n",
    "- **dbt Integration**: Export rules as dbt tests, import dbt schema.yml\n",
    "- **Enhanced Error Messages**: Helpful suggestions and context in errors\n",
    "- **HTML/PDF Reports**: Generate beautiful, shareable quality reports\n",
    "- **Historical Tracking**: Store validation results and analyze trends over time\n",
    "- **Airflow Operator**: Native integration for data pipelines\n",
    "- **GitHub Action**: CI/CD data quality gates\n",
    "\n",
    "## What's in v2.0\n",
    "- **YAML-based Rules**: Define rules in YAML with a simple, clean syntax\n",
    "- **Semantic Type Detection**: Auto-detect emails, phones, PII, and 30+ types\n",
    "- **Data Contracts**: Schema + quality SLAs with breaking change detection\n",
    "- **Anomaly Detection**: Statistical anomaly detection (Z-score, IQR, percent change)\n",
    "- **Enhanced CLI**: Beautiful Rich output with new commands\n",
    "\n",
    "This notebook walks you through:\n",
    "1. Connecting to data sources\n",
    "2. Exploring your data\n",
    "3. Calculating quality scores\n",
    "4. YAML-based rules\n",
    "5. Semantic type detection\n",
    "6. Data contracts\n",
    "7. Anomaly detection\n",
    "8. **NEW**: Freshness Monitoring\n",
    "9. **NEW**: ML-Based Anomaly Detection\n",
    "10. **NEW**: Schema Evolution Tracking\n",
    "11. **NEW**: Reference/FK Checks & Cross-Dataset Validation\n",
    "12. **NEW**: Reconciliation\n",
    "13. **NEW**: Distribution Drift Detection\n",
    "14. **NEW**: Group By Checks\n",
    "15. **NEW**: Email Notifications\n",
    "16. Python assertions\n",
    "17. Row-level error debugging\n",
    "18. Slack/Teams notifications\n",
    "19. dbt integration\n",
    "20. HTML/PDF Reports\n",
    "21. Historical Tracking\n",
    "22. Airflow Integration\n",
    "23. Using with pytest\n",
    "24. CLI commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-warning",
   "metadata": {},
   "source": "## Setup\n\nRun the next cell to install DuckGuard and create sample data. The sample data is embedded directly in the notebook - no downloads needed!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install DuckGuard and setup sample data\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install DuckGuard\n",
    "print(\"Installing DuckGuard...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"duckguard\"], check=True)\n",
    "print(\"DuckGuard installed!\")\n",
    "\n",
    "# Create sample data directly (no network needed)\n",
    "os.makedirs(\"sample_data\", exist_ok=True)\n",
    "\n",
    "# Sample orders data - embedded inline for instant loading\n",
    "ORDERS_CSV = \"\"\"order_id,customer_id,product_name,quantity,unit_price,total_amount,status,email,created_at\n",
    "ORD-001,CUST-001,Widget A,2,29.99,59.98,delivered,john@example.com,2024-01-15\n",
    "ORD-002,CUST-002,Widget B,1,49.99,49.99,shipped,jane@example.com,2024-01-16\n",
    "ORD-003,CUST-001,Gadget X,3,19.99,59.97,delivered,john@example.com,2024-01-17\n",
    "ORD-004,CUST-003,Widget A,5,29.99,149.95,pending,bob@example.com,2024-01-18\n",
    "ORD-005,CUST-004,Gadget Y,2,39.99,79.98,shipped,alice@example.com,2024-01-19\n",
    "ORD-006,CUST-002,Widget C,1,59.99,59.99,delivered,jane@example.com,2024-01-20\n",
    "ORD-007,CUST-005,Gadget X,4,19.99,79.96,pending,charlie@example.com,2024-01-21\n",
    "ORD-008,CUST-001,Widget B,2,49.99,99.98,delivered,john@example.com,2024-01-22\n",
    "ORD-009,CUST-006,Gadget Z,1,99.99,99.99,shipped,diana@example.com,2024-01-23\n",
    "ORD-010,CUST-003,Widget A,3,29.99,89.97,delivered,bob@example.com,2024-01-24\n",
    "ORD-011,CUST-007,Widget D,2,34.99,69.98,pending,eve@example.com,2024-01-25\n",
    "ORD-012,CUST-004,Gadget X,1,19.99,19.99,delivered,alice@example.com,2024-01-26\n",
    "ORD-013,CUST-008,Widget B,3,49.99,149.97,shipped,frank@example.com,2024-01-27\n",
    "ORD-014,CUST-002,Gadget Y,2,39.99,79.98,delivered,jane@example.com,2024-01-28\n",
    "ORD-015,CUST-009,Widget A,4,29.99,119.96,pending,grace@example.com,2024-01-29\n",
    "ORD-016,CUST-005,Widget C,1,59.99,59.99,cancelled,charlie@example.com,2024-01-30\n",
    "ORD-017,CUST-010,Gadget Z,2,99.99,199.98,shipped,henry@example.com,2024-01-31\n",
    "ORD-018,CUST-001,Widget D,3,34.99,104.97,delivered,john@example.com,2024-02-01\n",
    "ORD-019,CUST-011,Gadget X,5,19.99,99.95,pending,ivy@example.com,2024-02-02\n",
    "ORD-020,CUST-006,Widget B,1,49.99,49.99,delivered,diana@example.com,2024-02-03\n",
    "ORD-021,,Widget A,2,29.99,59.98,shipped,,2024-02-04\n",
    "ORD-022,CUST-012,Gadget Y,50,39.99,1999.50,delivered,kim@example.com,2024-02-05\n",
    "ORD-023,CUST-013,Widget B,1,499.99,499.99,pending,leo@example.com,2024-02-06\n",
    "ORD-024,CUST-014,Gadget X,100,19.99,1999.00,cancelled,mike@example.com,2024-02-07\n",
    "ORD-025,CUST-015,Widget C,1,59.99,59.99,delivered,nancy@example.com,2024-02-08\"\"\"\n",
    "\n",
    "DUCKGUARD_YAML = \"\"\"dataset: orders\n",
    "description: Data quality rules for orders dataset\n",
    "\n",
    "rules:\n",
    "  # Table-level rules\n",
    "  - row_count > 0\n",
    "  - row_count < 1000000\n",
    "\n",
    "  # Column nulls\n",
    "  - order_id is not null\n",
    "  - order_id is unique\n",
    "  - customer_id null_percent < 10\n",
    "  - email null_percent < 10\n",
    "\n",
    "  # Numeric ranges\n",
    "  - quantity >= 1\n",
    "  - quantity < 500\n",
    "  - unit_price >= 0\n",
    "  - total_amount >= 0\n",
    "\n",
    "  # Status enum\n",
    "  - status in ['pending', 'shipped', 'delivered', 'cancelled']\n",
    "\"\"\"\n",
    "\n",
    "with open(\"sample_data/orders.csv\", \"w\") as f:\n",
    "    f.write(ORDERS_CSV)\n",
    "with open(\"sample_data/duckguard.yaml\", \"w\") as f:\n",
    "    f.write(DUCKGUARD_YAML)\n",
    "\n",
    "print(\"Setup complete! Sample data ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DuckGuard - all the new features!\n",
    "from duckguard import (\n",
    "    # Anomaly Detection\n",
    "    AnomalyDetector,\n",
    "    RuleSet,\n",
    "    # Semantic Types\n",
    "    SemanticAnalyzer,\n",
    "    # NEW in v2.1: Row-level errors\n",
    "    __version__,\n",
    "    # Core\n",
    "    connect,\n",
    "    detect_anomalies,\n",
    "    detect_type,\n",
    "    detect_types_for_dataset,\n",
    "    diff_contracts,\n",
    "    execute_rules,\n",
    "    generate_contract,\n",
    "    generate_rules,\n",
    "    load_rules,\n",
    "    load_rules_from_string,\n",
    "    # Data Contracts\n",
    "    validate_contract,\n",
    ")\n",
    "\n",
    "# Additional contract utilities\n",
    "from duckguard.contracts import contract_to_yaml\n",
    "\n",
    "print(f\"DuckGuard v{__version__} imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Connecting to Data Sources\n",
    "\n",
    "DuckGuard auto-detects the data source type from the path or connection string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a CSV file\n",
    "orders = connect(\"sample_data/orders.csv\")\n",
    "\n",
    "print(f\"Dataset: {orders.name}\")\n",
    "print(f\"Rows: {orders.row_count}\")\n",
    "print(f\"Columns: {orders.column_count}\")\n",
    "print(f\"Column names: {orders.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "orders.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### Other Connection Examples\n",
    "\n",
    "```python\n",
    "# Parquet files\n",
    "data = connect(\"data/events.parquet\")\n",
    "\n",
    "# JSON files\n",
    "data = connect(\"data/users.json\")\n",
    "\n",
    "# Cloud storage\n",
    "data = connect(\"s3://bucket/data.parquet\")\n",
    "data = connect(\"gs://bucket/data.csv\")\n",
    "\n",
    "# Databases\n",
    "data = connect(\"postgres://user:pass@host/db\", table=\"orders\")\n",
    "data = connect(\"snowflake://account/db\", table=\"orders\", schema=\"public\")\n",
    "data = connect(\"bigquery://project/dataset\", table=\"orders\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Exploring Columns\n",
    "\n",
    "Access columns using attribute or bracket notation to get statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a column\n",
    "customer_col = orders.customer_id\n",
    "\n",
    "# View column statistics\n",
    "print(f\"Column: {customer_col.name}\")\n",
    "print(f\"Total values: {customer_col.total_count}\")\n",
    "print(f\"Null count: {customer_col.null_count}\")\n",
    "print(f\"Null %: {customer_col.null_percent:.2f}%\")\n",
    "print(f\"Unique count: {customer_col.unique_count}\")\n",
    "print(f\"Unique %: {customer_col.unique_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric column statistics\n",
    "amount_col = orders.total_amount\n",
    "\n",
    "print(f\"Column: {amount_col.name}\")\n",
    "print(f\"Min: {amount_col.min}\")\n",
    "print(f\"Max: {amount_col.max}\")\n",
    "print(f\"Mean: {amount_col.mean:.2f}\")\n",
    "print(f\"Median: {amount_col.median}\")\n",
    "print(f\"Stddev: {amount_col.stddev:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View value distribution\n",
    "orders.status.get_value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Quality Scores\n",
    "\n",
    "Calculate data quality scores across standard dimensions:\n",
    "- **Completeness**: Are all required values present?\n",
    "- **Uniqueness**: Are values appropriately unique?\n",
    "- **Validity**: Do values conform to expected formats/ranges?\n",
    "- **Consistency**: Are values consistent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quality score\n",
    "result = orders.score()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nOverall Score: {result.overall:.1f} / 100\")\n",
    "print(f\"Grade: {result.grade}\")\n",
    "print(\"\\nDimension Scores:\")\n",
    "print(f\"  Completeness: {result.completeness:.1f}\")\n",
    "print(f\"  Uniqueness:   {result.uniqueness:.1f}\")\n",
    "print(f\"  Validity:     {result.validity:.1f}\")\n",
    "print(f\"  Consistency:  {result.consistency:.1f}\")\n",
    "print(f\"\\nChecks: {result.passed_checks}/{result.total_checks} passed ({result.pass_rate:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. YAML-Based Rules (NEW in v2.0)\n",
    "\n",
    "Define data quality rules in YAML with a simple, intuitive syntax. This is easier than Soda's SodaCL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rules directly in Python using YAML string\n",
    "# Note: Our sample data has intentional nulls and anomalies, so we use thresholds\n",
    "yaml_rules = \"\"\"\n",
    "dataset: orders\n",
    "description: Data quality rules for orders\n",
    "\n",
    "rules:\n",
    "  # Table-level rules\n",
    "  - row_count > 0\n",
    "  - row_count < 1000000\n",
    "  \n",
    "  # Column-level rules with simple syntax\n",
    "  - order_id is not null\n",
    "  - order_id is unique\n",
    "  - customer_id null_percent < 10\n",
    "  - total_amount >= 0\n",
    "  - total_amount < 10000\n",
    "  - status in ['pending', 'shipped', 'delivered', 'cancelled']\n",
    "  - quantity >= 1\n",
    "\"\"\"\n",
    "\n",
    "# Load and execute rules\n",
    "rules = load_rules_from_string(yaml_rules)\n",
    "print(f\"Loaded {len(rules.checks)} rules\")\n",
    "print(f\"Dataset: {rules.dataset}\")\n",
    "print(\"\\nRules:\")\n",
    "for check in rules.checks:\n",
    "    print(f\"  - {check.expression}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute rules against the dataset\n",
    "result = execute_rules(rules, dataset=orders)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RULE EXECUTION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total: {result.total_checks}\")\n",
    "print(f\"Passed: {result.passed_count}\")\n",
    "print(f\"Failed: {result.failed_count}\")\n",
    "print(f\"Success Rate: {result.quality_score:.1f}%\")\n",
    "print(\"\\nDetails:\")\n",
    "for check_result in result.results:\n",
    "    status = \"PASS\" if check_result.passed else \"FAIL\"\n",
    "    print(f\"  [{status}] {check_result.check.expression}\")\n",
    "    if not check_result.passed:\n",
    "        print(f\"         -> {check_result.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-generate YAML rules from data analysis\n",
    "generated_yaml = generate_rules(orders, dataset_name=\"orders\")\n",
    "print(\"Generated YAML Rules:\")\n",
    "print(generated_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### Save Rules to a File\n",
    "\n",
    "```python\n",
    "# Save generated rules\n",
    "with open(\"duckguard.yaml\", \"w\") as f:\n",
    "    f.write(generated_yaml)\n",
    "\n",
    "# Later, load and execute\n",
    "rules = load_rules(\"duckguard.yaml\")\n",
    "result = execute_rules(rules, orders)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s1vvpxmry3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rules from a YAML file (we have a sample file in sample_data/)\n",
    "file_rules = load_rules(\"sample_data/duckguard.yaml\")\n",
    "print(f\"Loaded {len(file_rules.checks)} rules from file\")\n",
    "print(f\"Dataset: {file_rules.dataset}\")\n",
    "print(f\"Description: {file_rules.description}\")\n",
    "\n",
    "# Execute the file-based rules (note: dataset must be passed as keyword argument)\n",
    "file_result = execute_rules(file_rules, dataset=orders)\n",
    "print(f\"\\nResults: {file_result.passed_count}/{file_result.total_checks} passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uy32pduzaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with RuleSet programmatically\n",
    "# RuleSet allows you to build rules in code instead of YAML\n",
    "\n",
    "# Create an empty RuleSet\n",
    "custom_rules = RuleSet(name=\"custom_orders\", version=\"1.0\", description=\"Custom rules\")\n",
    "\n",
    "# Add simple checks using expressions (same syntax as YAML)\n",
    "custom_rules.add_simple_check(\"row_count > 0\")\n",
    "custom_rules.add_simple_check(\"order_id is not null\")\n",
    "custom_rules.add_simple_check(\"quantity >= 1\")\n",
    "custom_rules.add_simple_check(\"status in ['pending', 'shipped', 'delivered', 'cancelled']\")\n",
    "\n",
    "print(f\"RuleSet: {custom_rules.name}\")\n",
    "print(f\"Version: {custom_rules.version}\")\n",
    "print(f\"Description: {custom_rules.description}\")\n",
    "print(f\"Total checks: {len(custom_rules.checks)}\")\n",
    "print(\"\\nRules added:\")\n",
    "for check in custom_rules.checks:\n",
    "    print(f\"  - {check.expression}\")\n",
    "\n",
    "# Execute our programmatic rules (note: dataset must be passed as keyword argument)\n",
    "custom_result = execute_rules(custom_rules, dataset=orders)\n",
    "print(f\"\\nResults: {custom_result.passed_count}/{custom_result.total_checks} passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 6. Semantic Type Detection (NEW in v2.0)\n",
    "\n",
    "DuckGuard automatically detects semantic types like emails, phone numbers, UUIDs, credit cards, and PII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect semantic types for a single column\n",
    "email_type = detect_type(orders, \"email\")\n",
    "print(f\"Column 'email' detected as: {email_type.value if email_type else 'unknown'}\")\n",
    "\n",
    "order_id_type = detect_type(orders, \"order_id\")\n",
    "print(f\"Column 'order_id' detected as: {order_id_type.value if order_id_type else 'unknown'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect types for entire dataset\n",
    "type_results = detect_types_for_dataset(orders)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SEMANTIC TYPE DETECTION\")\n",
    "print(f\"{'='*60}\")\n",
    "for col_name, sem_type in type_results.items():\n",
    "    type_name = sem_type.value if sem_type else \"generic\"\n",
    "    print(f\"  {col_name:20} -> {type_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the SemanticAnalyzer for detailed analysis\n",
    "analyzer = SemanticAnalyzer()\n",
    "analysis = analyzer.analyze(orders)\n",
    "\n",
    "print(\"\\nAnalysis Summary:\")\n",
    "print(f\"  Columns analyzed: {len(analysis.columns)}\")\n",
    "print(f\"  PII columns detected: {len(analysis.pii_columns)}\")\n",
    "if analysis.pii_columns:\n",
    "    print(f\"  PII warning: Columns {analysis.pii_columns} may contain PII!\")\n",
    "\n",
    "print(\"\\nDetected Types:\")\n",
    "for col_analysis in analysis.columns:\n",
    "    confidence = f\"({col_analysis.confidence:.0%})\" if col_analysis.confidence else \"\"\n",
    "    detected = col_analysis.semantic_type.value if col_analysis.semantic_type else \"unknown\"\n",
    "    print(f\"  {col_analysis.name}: {detected} {confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Supported Semantic Types\n",
    "\n",
    "DuckGuard detects 30+ semantic types including:\n",
    "\n",
    "| Category | Types |\n",
    "|----------|-------|\n",
    "| **Identifiers** | UUID, Email, Phone, URL, IP Address |\n",
    "| **Financial** | Credit Card, Currency, IBAN |\n",
    "| **Personal (PII)** | SSN, Name, Address, Date of Birth |\n",
    "| **Geographic** | Country, State, Zip Code, Latitude, Longitude |\n",
    "| **Technical** | JSON, Timestamp, Version, File Path |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 7. Data Contracts (NEW in v2.0)\n",
    "\n",
    "Define schema expectations and quality SLAs with automatic breaking change detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-generate a contract from your data\n",
    "contract = generate_contract(orders, name=\"orders_contract\", owner=\"data-team\")\n",
    "\n",
    "print(f\"Contract: {contract.name}\")\n",
    "print(f\"Version: {contract.version}\")\n",
    "print(f\"Owner: {contract.metadata.owner}\")\n",
    "print(f\"\\nSchema ({len(contract.schema)} columns):\")\n",
    "for field in contract.schema:\n",
    "    req_status = \"required\" if field.required else \"optional\"\n",
    "    print(f\"  {field.name}: {field.type.value if hasattr(field.type, 'value') else field.type} ({req_status})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View quality SLAs in the contract\n",
    "if contract.quality:\n",
    "    print(\"Quality SLAs:\")\n",
    "    if contract.quality.completeness is not None:\n",
    "        print(f\"  Completeness: >= {contract.quality.completeness}%\")\n",
    "    if contract.quality.row_count_min is not None:\n",
    "        print(f\"  Min row count: {contract.quality.row_count_min}\")\n",
    "    if contract.quality.row_count_max is not None:\n",
    "        print(f\"  Max row count: {contract.quality.row_count_max}\")\n",
    "    if contract.quality.freshness:\n",
    "        print(f\"  Freshness: {contract.quality.freshness}\")\n",
    "\n",
    "    if contract.quality.uniqueness:\n",
    "        print(\"\\n  Uniqueness requirements:\")\n",
    "        for col, pct in contract.quality.uniqueness.items():\n",
    "            print(f\"    {col}: {pct}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data against a contract\n",
    "validation = validate_contract(contract, orders)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CONTRACT VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Valid: {validation.is_valid}\")\n",
    "print(f\"Schema valid: {validation.schema_valid}\")\n",
    "print(f\"Quality valid: {validation.quality_valid}\")\n",
    "\n",
    "if validation.errors:\n",
    "    print(\"\\nErrors:\")\n",
    "    for error in validation.errors:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "if validation.warnings:\n",
    "    print(\"\\nWarnings:\")\n",
    "    for warning in validation.warnings:\n",
    "        print(f\"  - {warning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export contract to YAML (contract_to_yaml was imported at the top)\n",
    "contract_yaml = contract_to_yaml(contract)\n",
    "print(\"Contract as YAML:\")\n",
    "print(contract_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "### Breaking Change Detection\n",
    "\n",
    "Compare contracts to detect breaking changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a contract change: make a required column optional (breaking change!)\n",
    "\n",
    "# Original contract (order_id is required)\n",
    "old_contract = generate_contract(orders, dataset_name=\"orders_v1\", as_yaml=False)\n",
    "\n",
    "# New contract (modify to make order_id optional - a breaking change!)\n",
    "new_contract = generate_contract(orders, dataset_name=\"orders_v2\", as_yaml=False)\n",
    "# Find and modify order_id field\n",
    "for field in new_contract.schema:\n",
    "    if field.name == \"order_id\":\n",
    "        field.required = False  # This is a breaking change!\n",
    "\n",
    "# Detect breaking changes\n",
    "diff_result = diff_contracts(old_contract, new_contract)\n",
    "\n",
    "print(\"\\nContract Diff:\")\n",
    "print(f\"  Has breaking changes: {diff_result.has_breaking_changes}\")\n",
    "print(f\"  Has changes: {diff_result.has_changes}\")\n",
    "\n",
    "if diff_result.breaking_changes:\n",
    "    print(\"\\nBreaking Changes:\")\n",
    "    for change in diff_result.breaking_changes:\n",
    "        print(f\"  - {change}\")\n",
    "\n",
    "if diff_result.non_breaking_changes:\n",
    "    print(\"\\nNon-Breaking Changes:\")\n",
    "    for change in diff_result.non_breaking_changes:\n",
    "        print(f\"  - {change}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## 8. Anomaly Detection (NEW in v2.0)\n",
    "\n",
    "Detect statistical anomalies in your data using Z-score, IQR, or percent change methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick anomaly detection on numeric columns\n",
    "report = detect_anomalies(orders, method=\"zscore\", threshold=3.0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ANOMALY DETECTION REPORT\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Source: {report.source}\")\n",
    "print(f\"Anomalies found: {report.anomaly_count}\")\n",
    "print(f\"\\n{report.summary()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed anomaly detection with custom settings\n",
    "detector = AnomalyDetector(method=\"iqr\", threshold=1.5)\n",
    "report = detector.detect(\n",
    "    orders,\n",
    "    columns=[\"quantity\", \"unit_price\", \"total_amount\"],\n",
    "    include_null_check=True\n",
    ")\n",
    "\n",
    "print(f\"Checked {report.statistics.get('columns_checked', 0)} columns\")\n",
    "print(f\"Method: {report.statistics.get('method')}\")\n",
    "print(f\"Threshold: {report.statistics.get('threshold')}\")\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "for anomaly in report.anomalies:\n",
    "    status = \"ANOMALY\" if anomaly.is_anomaly else \"OK\"\n",
    "    print(f\"  [{status}] {anomaly.column}: {anomaly.message}\")\n",
    "    if anomaly.is_anomaly and anomaly.samples:\n",
    "        print(f\"          Samples: {anomaly.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies with historical baseline\n",
    "# Useful for monitoring metrics over time\n",
    "\n",
    "# Simulate historical baseline values\n",
    "historical_totals = [50.0, 55.0, 48.0, 52.0, 51.0, 49.0, 53.0, 50.0]\n",
    "\n",
    "detector = AnomalyDetector(method=\"percent_change\", threshold=0.2)  # 20% change threshold\n",
    "result = detector.detect_column(\n",
    "    orders,\n",
    "    \"total_amount\",\n",
    "    baseline_values=historical_totals\n",
    ")\n",
    "\n",
    "print(f\"Column: {result.column}\")\n",
    "print(f\"Is Anomaly: {result.is_anomaly}\")\n",
    "print(f\"Score: {result.score:.2f}\")\n",
    "print(f\"Threshold: {result.threshold}\")\n",
    "print(f\"Message: {result.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "### Available Anomaly Detection Methods\n",
    "\n",
    "| Method | Description | Best For |\n",
    "|--------|-------------|----------|\n",
    "| `zscore` | Standard deviations from mean | Normal distributions |\n",
    "| `iqr` | Interquartile range | Robust to outliers |\n",
    "| `percent_change` | % change from baseline | Monitoring metrics |\n",
    "| `modified_zscore` | Uses median & MAD | Non-normal distributions |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p5xevfu5wfr",
   "metadata": {},
   "source": [
    "## 8. Freshness Monitoring (NEW in v2.2)\n",
    "\n",
    "Detect stale data before it causes problems. DuckGuard checks freshness via file modification time or timestamp columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ki0rijf09ji",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freshness Monitoring - check data staleness\n",
    "from datetime import timedelta\n",
    "\n",
    "from duckguard.freshness import FreshnessMonitor\n",
    "\n",
    "# Quick freshness check via dataset property\n",
    "print(\"Freshness Check via Property:\")\n",
    "print(\"-\" * 60)\n",
    "freshness = orders.freshness\n",
    "print(f\"Source: {freshness.source}\")\n",
    "print(f\"Last modified: {freshness.last_modified}\")\n",
    "print(f\"Age: {freshness.age_human}\")\n",
    "print(f\"Is fresh (24h threshold): {freshness.is_fresh}\")\n",
    "print(f\"Method: {freshness.method.value}\")\n",
    "\n",
    "# Custom threshold check\n",
    "print(\"\\nCustom Threshold Check:\")\n",
    "print(\"-\" * 60)\n",
    "is_fresh_6h = orders.is_fresh(timedelta(hours=6))\n",
    "print(f\"Fresh within 6 hours: {is_fresh_6h}\")\n",
    "\n",
    "is_fresh_1d = orders.is_fresh(timedelta(days=1))\n",
    "print(f\"Fresh within 1 day: {is_fresh_1d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbl1h2orieu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FreshnessMonitor for advanced freshness checks\n",
    "monitor = FreshnessMonitor(threshold=timedelta(hours=12))\n",
    "\n",
    "# Check via file modification time\n",
    "result = monitor.check_file_mtime(\"sample_data/orders.csv\")\n",
    "print(\"File Modification Time Check:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  Last modified: {result.last_modified}\")\n",
    "print(f\"  Age: {result.age_human}\")\n",
    "print(f\"  Is fresh: {result.is_fresh}\")\n",
    "print(f\"  Threshold: {result.threshold_seconds / 3600:.1f} hours\")\n",
    "\n",
    "# Check via timestamp column (if you have one)\n",
    "# result = monitor.check_column_timestamp(orders, \"created_at\")\n",
    "# print(f\"Column timestamp fresh: {result.is_fresh}\")\n",
    "\n",
    "# Full result as dictionary (useful for logging/storage)\n",
    "print(\"\\nResult as dict:\")\n",
    "print(result.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xd7tb5qpci",
   "metadata": {},
   "source": [
    "## 9. ML-Based Anomaly Detection (NEW in v2.2)\n",
    "\n",
    "DuckGuard now supports machine learning-based anomaly detection methods:\n",
    "- **Baseline Method**: Learn from historical data and detect deviations\n",
    "- **KS-Test Method**: Kolmogorov-Smirnov test for distribution drift\n",
    "- **Seasonal Method**: Account for time-based patterns\n",
    "\n",
    "These methods auto-learn patterns without requiring manual thresholds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43njidib4hy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML-Based Anomaly Detection\n",
    "from duckguard.anomaly import BaselineMethod, KSTestMethod\n",
    "\n",
    "# Baseline Method - learn and compare\n",
    "print(\"Baseline Method:\")\n",
    "print(\"-\" * 60)\n",
    "baseline = BaselineMethod(sensitivity=2.0)\n",
    "\n",
    "# Fit on numeric column data\n",
    "baseline.fit(orders.total_amount)\n",
    "print(\"Learned baseline for 'total_amount'\")\n",
    "print(f\"  Mean: {baseline.baseline_mean:.2f}\")\n",
    "print(f\"  Stddev: {baseline.baseline_std:.2f}\")\n",
    "\n",
    "# Score values against baseline (0 = normal, higher = more anomalous)\n",
    "scores = baseline.score(orders.total_amount)\n",
    "print(f\"  Scored {len(scores)} values\")\n",
    "print(f\"  Max anomaly score: {max(scores):.2f}\")\n",
    "print(f\"  Anomalies found: {sum(1 for s in scores if s > 1.0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g6tnm8hi218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KS-Test Method - detect distribution drift\n",
    "print(\"KS-Test Method (Distribution Drift):\")\n",
    "print(\"-\" * 60)\n",
    "ks_method = KSTestMethod(p_value_threshold=0.05)\n",
    "\n",
    "# Compare current distribution to a reference\n",
    "comparison = ks_method.compare_distributions(orders.total_amount)\n",
    "print(\"Column: total_amount\")\n",
    "print(f\"  P-value: {comparison.p_value:.4f}\")\n",
    "print(f\"  Statistic: {comparison.statistic:.4f}\")\n",
    "print(f\"  Is drift detected: {comparison.is_drift}\")\n",
    "print(f\"  Message: {comparison.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l9xffm11uw",
   "metadata": {},
   "source": [
    "## 10. Schema Evolution Tracking (NEW in v2.2)\n",
    "\n",
    "Track schema changes over time and detect breaking changes before they cause issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ojrutnherz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema Evolution Tracking\n",
    "import os\n",
    "\n",
    "# Use temp storage for demo\n",
    "import tempfile\n",
    "\n",
    "from duckguard.history import HistoryStorage\n",
    "from duckguard.schema_history import SchemaChangeAnalyzer, SchemaTracker\n",
    "\n",
    "schema_db = os.path.join(tempfile.gettempdir(), \"demo_schema.db\")\n",
    "schema_storage = HistoryStorage(db_path=schema_db)\n",
    "\n",
    "# Create a schema tracker\n",
    "tracker = SchemaTracker(storage=schema_storage)\n",
    "\n",
    "# Capture a snapshot of the current schema\n",
    "print(\"Schema Snapshot:\")\n",
    "print(\"-\" * 60)\n",
    "snapshot = tracker.capture(orders)\n",
    "print(f\"Source: {snapshot.source}\")\n",
    "print(f\"Snapshot ID: {snapshot.snapshot_id[:8]}...\")\n",
    "print(f\"Columns: {snapshot.column_count}\")\n",
    "print(f\"Rows: {snapshot.row_count}\")\n",
    "print(\"\\nColumn Schema:\")\n",
    "for col in snapshot.columns[:5]:  # Show first 5 columns\n",
    "    print(f\"  {col.name}: {col.dtype} (nullable={col.nullable})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5vf6e1kdswi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect schema changes\n",
    "analyzer = SchemaChangeAnalyzer(storage=schema_storage)\n",
    "\n",
    "# Detect changes against previous snapshot\n",
    "print(\"Schema Change Detection:\")\n",
    "print(\"-\" * 60)\n",
    "report = analyzer.detect_changes(orders)\n",
    "\n",
    "print(f\"Previous snapshot: {report.previous_snapshot.snapshot_id[:8] if report.previous_snapshot else 'None'}...\")\n",
    "print(f\"Current snapshot: {report.current_snapshot.snapshot_id[:8]}...\")\n",
    "print(f\"Has changes: {report.has_changes}\")\n",
    "print(f\"Has breaking changes: {report.has_breaking_changes}\")\n",
    "\n",
    "if report.changes:\n",
    "    print(\"\\nChanges detected:\")\n",
    "    for change in report.changes:\n",
    "        print(f\"  {change}\")\n",
    "else:\n",
    "    print(\"\\nNo schema changes detected (same schema as previous snapshot)\")\n",
    "\n",
    "# View schema history\n",
    "print(\"\\nSchema History:\")\n",
    "history = tracker.get_history(orders.source, limit=5)\n",
    "for snap in history:\n",
    "    print(f\"  {snap.captured_at}: {snap.column_count} columns, {snap.row_count} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8iudpin12i5",
   "metadata": {},
   "source": [
    "## 11. Reference/FK Checks & Cross-Dataset Validation (NEW in v2.2)\n",
    "\n",
    "Validate foreign key relationships and compare data across multiple datasets. This is essential for data lake integrity and ensuring referential integrity without a traditional database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28opftx3t4n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data for cross-dataset validation demo\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "# Create a customers reference table\n",
    "customers_content = \"\"\"id,name,email\n",
    "CUST-001,Alice,alice@example.com\n",
    "CUST-002,Bob,bob@example.com\n",
    "CUST-003,Charlie,charlie@example.com\n",
    "CUST-004,Diana,diana@example.com\n",
    "CUST-005,Eve,eve@example.com\n",
    "\"\"\"\n",
    "\n",
    "# Create orders with some invalid customer references (orphans)\n",
    "orders_orphans_content = \"\"\"order_id,customer_id,amount,status\n",
    "ORD-001,CUST-001,100.00,shipped\n",
    "ORD-002,CUST-002,200.00,pending\n",
    "ORD-003,CUST-999,150.00,shipped\n",
    "ORD-004,CUST-001,50.00,delivered\n",
    "ORD-005,CUST-888,300.00,pending\n",
    "ORD-006,CUST-003,75.00,shipped\n",
    "\"\"\"\n",
    "\n",
    "# Create a status lookup table\n",
    "status_lookup_content = \"\"\"code,description\n",
    "shipped,Order has been shipped\n",
    "pending,Order is pending\n",
    "delivered,Order has been delivered\n",
    "cancelled,Order was cancelled\n",
    "\"\"\"\n",
    "\n",
    "# Write temp files\n",
    "temp_dir = tempfile.gettempdir()\n",
    "customers_file = os.path.join(temp_dir, \"demo_customers.csv\")\n",
    "orders_orphans_file = os.path.join(temp_dir, \"demo_orders_orphans.csv\")\n",
    "status_lookup_file = os.path.join(temp_dir, \"demo_status_lookup.csv\")\n",
    "\n",
    "with open(customers_file, 'w') as f:\n",
    "    f.write(customers_content)\n",
    "with open(orders_orphans_file, 'w') as f:\n",
    "    f.write(orders_orphans_content)\n",
    "with open(status_lookup_file, 'w') as f:\n",
    "    f.write(status_lookup_content)\n",
    "\n",
    "print(\"Created demo files for cross-dataset validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exrmbmm5xv6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference/FK Checks - Validate foreign key relationships\n",
    "from duckguard import connect\n",
    "\n",
    "# Connect to our demo datasets\n",
    "customers = connect(customers_file)\n",
    "orders_with_orphans = connect(orders_orphans_file)\n",
    "status_lookup = connect(status_lookup_file)\n",
    "\n",
    "print(\"Datasets loaded:\")\n",
    "print(f\"  Customers: {customers.row_count} rows\")\n",
    "print(f\"  Orders: {orders_with_orphans.row_count} rows\")\n",
    "print(f\"  Status Lookup: {status_lookup.row_count} rows\")\n",
    "\n",
    "# Check if all customer_id values exist in customers table\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"REFERENCE/FK VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = orders_with_orphans[\"customer_id\"].exists_in(customers[\"id\"])\n",
    "\n",
    "print(\"\\nCheck: orders.customer_id exists_in customers.id\")\n",
    "print(f\"Passed: {result.passed}\")\n",
    "print(f\"Orphan count: {result.actual_value}\")\n",
    "\n",
    "if not result.passed:\n",
    "    print(\"\\nOrphan records found:\")\n",
    "    for row in result.failed_rows:\n",
    "        print(f\"  Row {row.row_number}: customer_id = '{row.value}'\")\n",
    "\n",
    "    print(f\"\\nDetails: {result.details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j8lxfju89fh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# references() - FK check with null handling options\n",
    "print(\"references() with null handling:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# allow_nulls=True (default) - treats nulls as valid (optional FK)\n",
    "result_allow_nulls = orders_with_orphans[\"customer_id\"].references(\n",
    "    customers[\"id\"],\n",
    "    allow_nulls=True\n",
    ")\n",
    "print(f\"With allow_nulls=True: {result_allow_nulls.actual_value} failures\")\n",
    "\n",
    "# allow_nulls=False - treats nulls as failures (required FK)\n",
    "result_no_nulls = orders_with_orphans[\"customer_id\"].references(\n",
    "    customers[\"id\"],\n",
    "    allow_nulls=False\n",
    ")\n",
    "print(f\"With allow_nulls=False: {result_no_nulls.actual_value} failures\")\n",
    "\n",
    "# Get list of orphan values for debugging\n",
    "print(\"\\nfind_orphans() - Get orphan values:\")\n",
    "print(\"-\" * 60)\n",
    "orphans = orders_with_orphans[\"customer_id\"].find_orphans(customers[\"id\"])\n",
    "print(f\"Orphan customer IDs: {orphans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ph7rwvdjmtl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Dataset Validation - Compare columns and row counts\n",
    "print(\"Cross-Dataset Validation:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# matches_values() - Check if column values match a lookup table\n",
    "print(\"\\nmatches_values() - Validate against lookup table:\")\n",
    "print(\"-\" * 60)\n",
    "result = orders_with_orphans[\"status\"].matches_values(status_lookup[\"code\"])\n",
    "print(\"Check: orders.status matches_values status_lookup.code\")\n",
    "print(f\"Passed: {result.passed}\")\n",
    "print(\"Details:\")\n",
    "print(f\"  Missing in other: {result.details.get('missing_in_other', 0)} values\")\n",
    "print(f\"  Extra in other: {result.details.get('extra_in_other', 0)} values\")\n",
    "\n",
    "# The orders have: shipped, pending, delivered\n",
    "# The lookup has: shipped, pending, delivered, cancelled\n",
    "# So \"cancelled\" is extra in the lookup (not used in orders)\n",
    "\n",
    "# row_count_matches() - Compare row counts between datasets\n",
    "print(\"\\nrow_count_matches() - Compare dataset sizes:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create a backup orders file with same data\n",
    "backup_orders_content = \"\"\"order_id,customer_id,amount,status\n",
    "ORD-001,CUST-001,100.00,shipped\n",
    "ORD-002,CUST-002,200.00,pending\n",
    "ORD-003,CUST-003,150.00,shipped\n",
    "\"\"\"\n",
    "backup_file = os.path.join(temp_dir, \"demo_backup_orders.csv\")\n",
    "with open(backup_file, 'w') as f:\n",
    "    f.write(backup_orders_content)\n",
    "\n",
    "backup_orders = connect(backup_file)\n",
    "\n",
    "# Exact match (will fail - different counts)\n",
    "result = orders_with_orphans.row_count_matches(backup_orders)\n",
    "print(f\"Exact match: {result.passed}\")\n",
    "print(f\"  Source: {result.details['source_count']} rows\")\n",
    "print(f\"  Backup: {result.details['other_count']} rows\")\n",
    "print(f\"  Difference: {result.actual_value}\")\n",
    "\n",
    "# With tolerance (allows small differences)\n",
    "result_tolerance = orders_with_orphans.row_count_matches(backup_orders, tolerance=5)\n",
    "print(f\"\\nWith tolerance=5: {result_tolerance.passed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237lim1e0cij",
   "metadata": {},
   "source": [
    "### Cross-Dataset Validation Summary\n",
    "\n",
    "| Method | Description | Use Case |\n",
    "|--------|-------------|----------|\n",
    "| `col.exists_in(other_col)` | Check all values exist in reference column | FK validation |\n",
    "| `col.references(other_col, allow_nulls)` | FK check with null handling | Optional/Required FK |\n",
    "| `col.find_orphans(other_col)` | Get list of orphan values | Debugging |\n",
    "| `col.matches_values(other_col)` | Check value sets match | Lookup validation |\n",
    "| `dataset.row_count_matches(other, tolerance)` | Compare row counts | Backup validation |\n",
    "| `dataset.row_count_equals(other)` | Exact row count match | Exact comparison |\n",
    "\n",
    "### Features\n",
    "\n",
    "- **Efficient SQL**: Uses anti-join patterns for performance on large datasets\n",
    "- **Row-Level Details**: See exactly which rows have orphan values\n",
    "- **Null Handling**: Control how nulls are treated in FK checks\n",
    "- **Tolerance**: Allow small differences in row count comparisons\n",
    "- **Shared Engine**: Multiple datasets share the same DuckDB connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "krtg31oeago",
   "metadata": {},
   "source": [
    "## 12. Reconciliation (NEW in v2.2)\n",
    "\n",
    "Reconciliation is essential for validating data migrations, ETL pipelines, and ensuring data synchronization between systems. It performs comprehensive row-by-row comparison using key columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edyh2z2lntv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create source and target datasets for reconciliation demo\n",
    "source_content = \"\"\"order_id,customer_id,amount,status\n",
    "ORD-001,CUST-001,100.00,shipped\n",
    "ORD-002,CUST-002,200.00,pending\n",
    "ORD-003,CUST-001,150.00,shipped\n",
    "ORD-004,CUST-003,50.00,delivered\n",
    "ORD-005,CUST-002,300.00,pending\n",
    "\"\"\"\n",
    "\n",
    "# Target has some differences: ORD-002 amount changed, ORD-004/005 missing, ORD-006 added\n",
    "target_content = \"\"\"order_id,customer_id,amount,status\n",
    "ORD-001,CUST-001,100.00,shipped\n",
    "ORD-002,CUST-002,205.00,pending\n",
    "ORD-003,CUST-001,150.00,shipped\n",
    "ORD-006,CUST-003,75.00,delivered\n",
    "\"\"\"\n",
    "\n",
    "# Write temp files\n",
    "source_recon_file = os.path.join(temp_dir, \"demo_source_orders.csv\")\n",
    "target_recon_file = os.path.join(temp_dir, \"demo_target_orders.csv\")\n",
    "\n",
    "with open(source_recon_file, 'w') as f:\n",
    "    f.write(source_content)\n",
    "with open(target_recon_file, 'w') as f:\n",
    "    f.write(target_content)\n",
    "\n",
    "print(\"Created reconciliation demo files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3qftcvrcdss",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconciliation - Compare two datasets comprehensively\n",
    "source = connect(source_recon_file)\n",
    "target = connect(target_recon_file)\n",
    "\n",
    "print(\"Source dataset:\", source.row_count, \"rows\")\n",
    "print(\"Target dataset:\", target.row_count, \"rows\")\n",
    "\n",
    "# Reconcile using order_id as key\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RECONCILIATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = source.reconcile(\n",
    "    target,\n",
    "    key_columns=[\"order_id\"],\n",
    "    compare_columns=[\"customer_id\", \"amount\", \"status\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nPassed: {result.passed}\")\n",
    "print(f\"Match percentage: {result.match_percentage:.1f}%\")\n",
    "print(f\"Missing in target: {result.missing_in_target} rows\")\n",
    "print(f\"Extra in target: {result.extra_in_target} rows\")\n",
    "print(f\"Value mismatches: {result.value_mismatches}\")\n",
    "\n",
    "# Full summary\n",
    "print(\"\\n\" + result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1s9dnmwfe2l",
   "metadata": {},
   "source": [
    "## 13. Distribution Drift Detection (NEW in v2.2)\n",
    "\n",
    "Detect when your data distribution has changed significantly. Essential for ML model monitoring, feature drift detection, and ensuring data pipeline consistency. Uses the Kolmogorov-Smirnov (KS) test for statistical rigor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5m4z8sx20kk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline and drifted datasets\n",
    "baseline_content = \"\"\"id,amount,score\n",
    "1,100.0,0.5\n",
    "2,150.0,0.6\n",
    "3,120.0,0.55\n",
    "4,180.0,0.7\n",
    "5,130.0,0.58\n",
    "6,140.0,0.62\n",
    "7,160.0,0.65\n",
    "8,110.0,0.52\n",
    "9,170.0,0.68\n",
    "10,125.0,0.56\n",
    "\"\"\"\n",
    "\n",
    "# Drifted data has significantly different distribution\n",
    "drifted_content = \"\"\"id,amount,score\n",
    "1,1000.0,0.9\n",
    "2,1500.0,0.95\n",
    "3,1200.0,0.88\n",
    "4,1800.0,0.99\n",
    "5,1300.0,0.92\n",
    "6,1400.0,0.94\n",
    "7,1600.0,0.96\n",
    "8,1100.0,0.87\n",
    "9,1700.0,0.98\n",
    "10,1250.0,0.91\n",
    "\"\"\"\n",
    "\n",
    "baseline_file = os.path.join(temp_dir, \"demo_baseline.csv\")\n",
    "drifted_file = os.path.join(temp_dir, \"demo_drifted.csv\")\n",
    "\n",
    "with open(baseline_file, 'w') as f:\n",
    "    f.write(baseline_content)\n",
    "with open(drifted_file, 'w') as f:\n",
    "    f.write(drifted_content)\n",
    "\n",
    "print(\"Created drift detection demo files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vnqarorx9qh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Drift Detection\n",
    "baseline = connect(baseline_file)\n",
    "drifted = connect(drifted_file)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DISTRIBUTION DRIFT DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Detect drift in amount column\n",
    "print(\"\\nChecking 'amount' column for drift:\")\n",
    "print(\"-\" * 60)\n",
    "result = baseline[\"amount\"].detect_drift(drifted[\"amount\"])\n",
    "\n",
    "print(f\"Drift detected: {result.is_drifted}\")\n",
    "print(f\"P-value: {result.p_value:.4f}\")\n",
    "print(f\"KS statistic: {result.statistic:.4f}\")\n",
    "print(f\"Threshold: {result.threshold}\")\n",
    "print(f\"Method: {result.method}\")\n",
    "print(f\"\\nMessage: {result.message}\")\n",
    "\n",
    "# Check another column\n",
    "print(\"\\nChecking 'score' column for drift:\")\n",
    "print(\"-\" * 60)\n",
    "result_score = baseline[\"score\"].detect_drift(drifted[\"score\"])\n",
    "print(f\"Drift detected: {result_score.is_drifted}\")\n",
    "print(f\"P-value: {result_score.p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3g0gyixjwgd",
   "metadata": {},
   "source": [
    "## 14. Group By Checks (NEW in v2.2)\n",
    "\n",
    "Run validation checks on groups/segments of your data. Essential for partition-level validation, regional quality checks, and ensuring data quality across different segments (e.g., by date, region, product category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0alc2ck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grouped data for demo\n",
    "grouped_content = \"\"\"order_id,customer_id,amount,status,region,date\n",
    "ORD-001,CUST-001,100.00,shipped,US,2024-01-01\n",
    "ORD-002,CUST-002,200.00,pending,US,2024-01-01\n",
    "ORD-003,CUST-001,150.00,shipped,EU,2024-01-02\n",
    "ORD-004,CUST-003,50.00,delivered,EU,2024-01-02\n",
    "ORD-005,CUST-002,300.00,pending,US,2024-01-03\n",
    "ORD-006,CUST-001,75.00,shipped,EU,2024-01-03\n",
    "ORD-007,CUST-004,125.00,shipped,APAC,2024-01-01\n",
    "ORD-008,CUST-004,175.00,pending,APAC,2024-01-02\n",
    "\"\"\"\n",
    "\n",
    "grouped_file = os.path.join(temp_dir, \"demo_grouped_orders.csv\")\n",
    "with open(grouped_file, 'w') as f:\n",
    "    f.write(grouped_content)\n",
    "\n",
    "grouped_orders = connect(grouped_file)\n",
    "print(f\"Created grouped orders: {grouped_orders.row_count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "djclocpc74i",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group By - Get statistics per group\n",
    "print(\"=\" * 60)\n",
    "print(\"GROUP BY CHECKS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Group by region\n",
    "print(\"\\nGroup by region:\")\n",
    "print(\"-\" * 60)\n",
    "grouped = grouped_orders.group_by(\"region\")\n",
    "print(f\"Groups found: {grouped.groups}\")\n",
    "print(f\"Total groups: {grouped.group_count}\")\n",
    "\n",
    "# Get statistics per group\n",
    "print(\"\\nStatistics per group:\")\n",
    "stats = grouped.stats()\n",
    "for g in stats:\n",
    "    print(f\"  {g['region']}: {g['row_count']} rows\")\n",
    "\n",
    "# Validate row count per group\n",
    "print(\"\\nValidation: row_count > 1 per region:\")\n",
    "print(\"-\" * 60)\n",
    "result = grouped_orders.group_by(\"region\").row_count_greater_than(1)\n",
    "print(f\"Passed: {result.passed}\")\n",
    "print(f\"Passed groups: {result.passed_groups}/{result.total_groups}\")\n",
    "\n",
    "# More restrictive validation\n",
    "print(\"\\nValidation: row_count > 5 per region:\")\n",
    "print(\"-\" * 60)\n",
    "result = grouped_orders.group_by(\"region\").row_count_greater_than(5)\n",
    "print(f\"Passed: {result.passed}\")\n",
    "print(f\"Passed groups: {result.passed_groups}/{result.total_groups}\")\n",
    "\n",
    "if not result.passed:\n",
    "    print(\"\\nFailed groups:\")\n",
    "    for g in result.get_failed_groups():\n",
    "        print(f\"  {g.group_key}: {g.row_count} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aojgfsk3g",
   "metadata": {},
   "source": [
    "### New Features Summary (v2.2)\n",
    "\n",
    "| Feature | Method | Description |\n",
    "|---------|--------|-------------|\n",
    "| **Reconciliation** | `dataset.reconcile(target, key_columns)` | Compare datasets row-by-row using keys |\n",
    "| **Distribution Drift** | `col.detect_drift(reference_col)` | KS-test based distribution comparison |\n",
    "| **Group By Checks** | `dataset.group_by(\"col\").row_count_greater_than(n)` | Validate per-group metrics |\n",
    "\n",
    "### Result Types\n",
    "\n",
    "| Result Type | Key Attributes |\n",
    "|-------------|---------------|\n",
    "| `ReconciliationResult` | `.passed`, `.missing_in_target`, `.extra_in_target`, `.value_mismatches`, `.summary()` |\n",
    "| `DriftResult` | `.is_drifted`, `.p_value`, `.statistic`, `.threshold`, `.summary()` |\n",
    "| `GroupByResult` | `.passed`, `.total_groups`, `.passed_groups`, `.get_failed_groups()`, `.summary()` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ox21p92dv8l",
   "metadata": {},
   "source": [
    "## 11. Email Notifications (NEW in v2.2)\n",
    "\n",
    "Send email alerts when data quality checks fail via SMTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ky0hvpasqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email Notifications\n",
    "from duckguard.notifications import EmailNotifier\n",
    "\n",
    "# Configure email notifier\n",
    "# In practice, use environment variable DUCKGUARD_EMAIL_CONFIG with JSON config\n",
    "email = EmailNotifier(\n",
    "    smtp_host=\"smtp.gmail.com\",\n",
    "    smtp_port=587,\n",
    "    smtp_user=\"alerts@company.com\",\n",
    "    smtp_password=\"your_app_password\",  # Use app passwords, not regular passwords!\n",
    "    from_address=\"duckguard@company.com\",\n",
    "    to_addresses=[\"team@company.com\", \"oncall@company.com\"],\n",
    "    use_tls=True,\n",
    ")\n",
    "\n",
    "print(\"EmailNotifier configured:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"SMTP Host: {email.config.smtp_host}\")\n",
    "print(f\"SMTP Port: {email.config.smtp_port}\")\n",
    "print(f\"From: {email.config.from_address}\")\n",
    "print(f\"To: {email.config.to_addresses}\")\n",
    "print(f\"TLS: {email.config.use_tls}\")\n",
    "\n",
    "# To send an alert (uncomment when you have real SMTP settings):\n",
    "# result = execute_rules(rules, dataset=orders)\n",
    "# if not result.passed:\n",
    "#     email.send_failure_alert(result)\n",
    "#     print(\"Failure alert sent!\")\n",
    "#\n",
    "# # Or send results regardless of pass/fail:\n",
    "# email.send_results(result)\n",
    "\n",
    "print(\"\\nNote: Email sending requires valid SMTP credentials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "## 9. Python Assertions (Traditional Approach)\n",
    "\n",
    "You can still use simple Python assertions - DuckGuard integrates with pytest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic checks using properties\n",
    "assert orders.row_count > 0, \"Dataset should not be empty\"\n",
    "assert orders.customer_id.null_percent < 5, \"Customer ID should have < 5% nulls\"\n",
    "assert orders.total_amount.min >= 0, \"Amounts should be non-negative\"\n",
    "\n",
    "print(\"All basic assertions passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation methods with detailed results\n",
    "result = orders.order_id.is_not_null(threshold=1.0)\n",
    "print(f\"is_not_null: {result}\")\n",
    "print(f\"  Message: {result.message}\")\n",
    "\n",
    "result = orders.total_amount.between(0, 100000)\n",
    "print(f\"\\nbetween: {result}\")\n",
    "print(f\"  Message: {result.message}\")\n",
    "\n",
    "result = orders.status.isin(['pending', 'shipped', 'delivered', 'cancelled'])\n",
    "print(f\"\\nisin: {result}\")\n",
    "print(f\"  Message: {result.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ut31o921v4s",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More validation methods\n",
    "print(\"Additional validation methods:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# is_unique - check if column values are unique\n",
    "result = orders.order_id.is_unique(threshold=100.0)\n",
    "print(f\"is_unique: {result}\")\n",
    "print(f\"  Message: {result.message}\")\n",
    "\n",
    "# matches - regex pattern matching\n",
    "result = orders.email.matches(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$')\n",
    "print(f\"\\nmatches (email pattern): {result}\")\n",
    "print(f\"  Message: {result.message}\")\n",
    "\n",
    "# has_no_duplicates - check for duplicate values\n",
    "result = orders.order_id.has_no_duplicates()\n",
    "print(f\"\\nhas_no_duplicates: {result}\")\n",
    "print(f\"  Message: {result.message}\")\n",
    "\n",
    "# greater_than - value comparison\n",
    "result = orders.quantity.greater_than(0)\n",
    "print(f\"\\ngreater_than(0): {result}\")\n",
    "print(f\"  Message: {result.message}\")\n",
    "\n",
    "# less_than - value comparison\n",
    "result = orders.unit_price.less_than(1000)\n",
    "print(f\"\\nless_than(1000): {result}\")\n",
    "print(f\"  Message: {result.message}\")\n",
    "\n",
    "# value_lengths_between - string length validation\n",
    "result = orders.order_id.value_lengths_between(7, 7)  # ORD-XXX format = 7 chars\n",
    "print(f\"\\nvalue_lengths_between(7, 7): {result}\")\n",
    "print(f\"  Message: {result.message}\")\n",
    "\n",
    "# get_distinct_values - view unique values\n",
    "distinct_products = orders.product_name.get_distinct_values(limit=5)\n",
    "print(f\"\\nget_distinct_values (products): {distinct_products}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cbolvh839",
   "metadata": {},
   "source": [
    "## 10. Row-Level Error Debugging (NEW in v2.1)\n",
    "\n",
    "When validation fails, DuckGuard now captures exactly which rows failed, making debugging much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ifx6vhgnc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When a validation check fails, you can see exactly which rows failed\n",
    "# Let's use a restrictive range to force some failures\n",
    "result = orders.quantity.between(1, 5)\n",
    "\n",
    "print(f\"Check passed: {result.passed}\")\n",
    "print(f\"Total failures: {result.total_failures}\")\n",
    "\n",
    "# Get the summary with sample failing rows\n",
    "if not result.passed:\n",
    "    print(f\"\\n{result.summary()}\")\n",
    "\n",
    "    # Get just the failed values\n",
    "    failed_values = result.get_failed_values()\n",
    "    print(f\"\\nFailed values: {failed_values[:5]}...\")\n",
    "\n",
    "    # Get just the row indices\n",
    "    failed_indices = result.get_failed_row_indices()\n",
    "    print(f\"Failed row indices: {failed_indices[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i42alk3wt8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with individual FailedRow objects for detailed debugging\n",
    "\n",
    "if result.failed_rows:\n",
    "    print(\"Detailed failed row information:\")\n",
    "    print(\"-\" * 60)\n",
    "    for row in result.failed_rows[:3]:  # Show first 3\n",
    "        print(f\"  Row {row.row_index}:\")\n",
    "        print(f\"    Column: {row.column}\")\n",
    "        print(f\"    Value: {row.value}\")\n",
    "        print(f\"    Expected: {row.expected}\")\n",
    "        if row.reason:\n",
    "            print(f\"    Reason: {row.reason}\")\n",
    "        print()\n",
    "\n",
    "# You can disable row capture for performance on large datasets\n",
    "result_no_capture = orders.quantity.between(1, 5, capture_failures=False)\n",
    "print(f\"With capture_failures=False: {len(result_no_capture.failed_rows)} rows captured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5q83vh4y7hf",
   "metadata": {},
   "source": [
    "## 11. Slack/Teams Notifications (NEW in v2.1)\n",
    "\n",
    "Get notified when your data quality checks fail. DuckGuard supports Slack and Microsoft Teams webhooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t93p2xyqrd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import notification components\n",
    "from duckguard.notifications import SlackNotifier, TeamsNotifier\n",
    "\n",
    "# Configure a Slack notifier (use your actual webhook URL)\n",
    "# You can also set DUCKGUARD_SLACK_WEBHOOK environment variable\n",
    "slack = SlackNotifier(\n",
    "    webhook_url=\"https://hooks.slack.com/services/YOUR/WEBHOOK/URL\",\n",
    "    channel=\"#data-quality\",  # Optional override\n",
    "    username=\"DuckGuard Bot\"\n",
    ")\n",
    "\n",
    "# Configure a Teams notifier (use your actual webhook URL)\n",
    "# You can also set DUCKGUARD_TEAMS_WEBHOOK environment variable\n",
    "teams = TeamsNotifier(\n",
    "    webhook_url=\"https://outlook.office.com/webhook/YOUR/WEBHOOK/URL\"\n",
    ")\n",
    "\n",
    "print(\"Notifiers configured!\")\n",
    "print(f\"Slack channel: {slack.config.channel}\")\n",
    "print(f\"Teams configured: {teams.webhook_url is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cggr0rg3fu4",
   "metadata": {},
   "source": [
    "### Sending Notifications on Failures\n",
    "\n",
    "```python\n",
    "# Execute rules and send notification on failure\n",
    "from duckguard import load_rules, execute_rules\n",
    "from duckguard.notifications import SlackNotifier\n",
    "\n",
    "rules = load_rules(\"duckguard.yaml\")\n",
    "result = execute_rules(rules, dataset=orders)\n",
    "\n",
    "# Only sends if there are failures (configurable)\n",
    "slack = SlackNotifier(webhook_url=\"https://hooks.slack.com/...\")\n",
    "\n",
    "if not result.passed:\n",
    "    # Send formatted failure alert\n",
    "    slack.send_failure_alert(result)\n",
    "    \n",
    "# Or send results regardless of pass/fail\n",
    "slack.send_results(result, notify_on_success=True)\n",
    "```\n",
    "\n",
    "### Notification Features\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Slack Blocks** | Rich formatted messages with sections and fields |\n",
    "| **Teams Cards** | Adaptive cards with color-coded status |\n",
    "| **Failure Details** | Shows which checks failed and why |\n",
    "| **Pass Rate** | Overall quality score included |\n",
    "| **Environment Variables** | `DUCKGUARD_SLACK_WEBHOOK` and `DUCKGUARD_TEAMS_WEBHOOK` |\n",
    "| **Channel Override** | Send to specific channels per notification |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k66xhcpmxze",
   "metadata": {},
   "source": [
    "## 12. dbt Integration (NEW in v2.1)\n",
    "\n",
    "Export DuckGuard validation rules as dbt tests, or import existing dbt tests as DuckGuard rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z8sv7tiswwl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dbt integration functions\n",
    "from duckguard.integrations import dbt\n",
    "\n",
    "# Load DuckGuard rules\n",
    "rules = load_rules(\"sample_data/duckguard.yaml\")\n",
    "\n",
    "# Convert rules to dbt test format (schema.yml structure)\n",
    "dbt_tests = dbt.rules_to_dbt_tests(rules)\n",
    "\n",
    "print(\"Converted to dbt schema.yml format:\")\n",
    "print(\"-\" * 60)\n",
    "import yaml\n",
    "\n",
    "print(yaml.dump(dbt_tests, default_flow_style=False, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7m97vimvewh",
   "metadata": {},
   "source": [
    "### dbt Export Options\n",
    "\n",
    "```python\n",
    "from duckguard import load_rules\n",
    "from duckguard.integrations import dbt\n",
    "\n",
    "rules = load_rules(\"duckguard.yaml\")\n",
    "\n",
    "# Export to dbt schema.yml file (merges with existing if present)\n",
    "dbt.export_to_schema(rules, \"models/schema.yml\")\n",
    "\n",
    "# Generate dbt singular tests for complex checks\n",
    "dbt.generate_singular_tests(rules, \"tests/\")\n",
    "# Creates files like: tests/test_orders_email_null_percent.sql\n",
    "\n",
    "# Import dbt tests back as DuckGuard rules\n",
    "imported_rules = dbt.import_from_dbt(\"models/schema.yml\")\n",
    "```\n",
    "\n",
    "### Mapping from DuckGuard to dbt\n",
    "\n",
    "| DuckGuard Check | dbt Test |\n",
    "|-----------------|----------|\n",
    "| `not_null` | `not_null` |\n",
    "| `unique` | `unique` |\n",
    "| `isin`, `allowed_values` | `accepted_values` |\n",
    "| `between`, `range` | `dbt_utils.expression_is_true` |\n",
    "| `min`, `max` | `dbt_utils.expression_is_true` |\n",
    "| `positive`, `non_negative` | `dbt_utils.expression_is_true` |\n",
    "| `pattern`, `matches` | `dbt_utils.expression_is_true` with REGEXP |\n",
    "| `null_percent` | Singular test (SQL file) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8vz06lqgv2f",
   "metadata": {},
   "source": [
    "## 13. HTML/PDF Reports (NEW in v2.1)\n",
    "\n",
    "Generate beautiful, shareable data quality reports. Perfect for stakeholders and compliance documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radz0chxym",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate HTML/PDF reports from validation results\n",
    "from duckguard.reports import generate_html_report\n",
    "\n",
    "# First, run some validation\n",
    "rules = load_rules_from_string(yaml_rules)\n",
    "result = execute_rules(rules, dataset=orders)\n",
    "\n",
    "# Generate an HTML report\n",
    "generate_html_report(\n",
    "    result,\n",
    "    \"quality_report.html\",\n",
    "    title=\"Orders Data Quality Report\",\n",
    "    include_passed=True  # Include passed checks in the report\n",
    ")\n",
    "\n",
    "print(\"HTML report generated: quality_report.html\")\n",
    "print(f\"Quality Score: {result.quality_score:.1f}%\")\n",
    "print(f\"Checks: {result.passed_count}/{result.total_checks} passed\")\n",
    "\n",
    "# For PDF reports (requires weasyprint: pip install duckguard[reports])\n",
    "# generate_pdf_report(result, \"quality_report.pdf\", title=\"Orders Quality Report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fszzvkdqcqd",
   "metadata": {},
   "source": [
    "### Report Features\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Standalone HTML** | No external dependencies, works offline |\n",
    "| **Beautiful Styling** | Professional look with color-coded status |\n",
    "| **Quality Score** | Overall score with A-F grade |\n",
    "| **Check Details** | All passed and failed checks with messages |\n",
    "| **PDF Export** | Print-ready PDF format (requires weasyprint) |\n",
    "| **Customizable** | Custom titles, include/exclude passed checks |\n",
    "\n",
    "### CLI Report Generation\n",
    "\n",
    "```bash\n",
    "# Generate HTML report\n",
    "duckguard report data.csv --output report.html\n",
    "\n",
    "# Generate PDF report\n",
    "duckguard report data.csv --format pdf --output report.pdf\n",
    "\n",
    "# With custom title and rules\n",
    "duckguard report data.csv --config rules.yaml --title \"Daily Quality Report\"\n",
    "\n",
    "# Store results in history while generating report\n",
    "duckguard report data.csv --store\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oj4uuc45a28",
   "metadata": {},
   "source": [
    "## 14. Historical Tracking (NEW in v2.1)\n",
    "\n",
    "Store validation results over time and analyze quality trends. Perfect for monitoring data pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daelldeq7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store and query validation history\n",
    "import os\n",
    "\n",
    "# Create a storage instance (defaults to ~/.duckguard/history.db)\n",
    "# Use a temp file for this demo\n",
    "import tempfile\n",
    "\n",
    "from duckguard.history import HistoryStorage, TrendAnalyzer\n",
    "\n",
    "temp_db = os.path.join(tempfile.gettempdir(), \"demo_history.db\")\n",
    "storage = HistoryStorage(db_path=temp_db)\n",
    "\n",
    "# Store a validation result\n",
    "run_id = storage.store(result)\n",
    "print(f\"Stored validation run: {run_id[:8]}...\")\n",
    "\n",
    "# Store another run to simulate history\n",
    "run_id_2 = storage.store(result)\n",
    "\n",
    "# Query historical runs\n",
    "runs = storage.get_runs(result.source, limit=5)\n",
    "print(f\"\\nRecent runs for {result.source}:\")\n",
    "for run in runs:\n",
    "    status = \"PASS\" if run.passed else \"FAIL\"\n",
    "    print(f\"  [{status}] {run.started_at:%Y-%m-%d %H:%M} - Score: {run.quality_score:.1f}%\")\n",
    "\n",
    "# Get list of tracked sources\n",
    "sources = storage.get_sources()\n",
    "print(f\"\\nTracked sources: {sources}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jx3qq78c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze quality trends over time\n",
    "analyzer = TrendAnalyzer(storage)\n",
    "trend = analyzer.analyze(result.source, days=30)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"QUALITY TREND ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Trend: {trend.score_trend.upper()}\")\n",
    "print(f\"Current Score: {trend.current_score:.1f}%\")\n",
    "print(f\"Average Score: {trend.average_score:.1f}%\")\n",
    "print(f\"Pass Rate: {trend.pass_rate:.1f}%\")\n",
    "print(f\"Total Runs: {trend.total_runs}\")\n",
    "print(f\"\\n{trend.summary()}\")\n",
    "\n",
    "# Check for quality regression\n",
    "if analyzer.has_regression(result.source):\n",
    "    print(\"\\nWARNING: Quality regression detected!\")\n",
    "else:\n",
    "    print(\"\\nNo quality regression detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gayoinw55xb",
   "metadata": {},
   "source": [
    "### CLI History Commands\n",
    "\n",
    "```bash\n",
    "# View recent validation history\n",
    "duckguard history\n",
    "\n",
    "# View history for a specific source\n",
    "duckguard history data.csv\n",
    "\n",
    "# View history for the last 7 days\n",
    "duckguard history data.csv --last 7d\n",
    "\n",
    "# Show trend analysis\n",
    "duckguard history data.csv --trend\n",
    "\n",
    "# Output as JSON\n",
    "duckguard history --format json\n",
    "```\n",
    "\n",
    "### History Features\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **SQLite Storage** | Lightweight, file-based storage |\n",
    "| **Trend Analysis** | Improving, declining, or stable trends |\n",
    "| **Anomaly Detection** | Detect unusual quality score drops |\n",
    "| **Pass Rate Tracking** | Track validation success over time |\n",
    "| **Source Filtering** | Query by data source |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zxe5c07z8s",
   "metadata": {},
   "source": [
    "## 15. Airflow Integration (NEW in v2.1)\n",
    "\n",
    "Use DuckGuard in Apache Airflow data pipelines with native operators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffoux08xn5",
   "metadata": {},
   "source": [
    "### Using DuckGuard in Airflow DAGs\n",
    "\n",
    "```python\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from duckguard.integrations.airflow import DuckGuardOperator, DuckGuardSensor\n",
    "from datetime import datetime\n",
    "\n",
    "with DAG(\n",
    "    \"data_quality_pipeline\",\n",
    "    start_date=datetime(2024, 1, 1),\n",
    "    schedule_interval=\"@daily\",\n",
    ") as dag:\n",
    "    \n",
    "    # Validate data after loading\n",
    "    validate_orders = DuckGuardOperator(\n",
    "        task_id=\"validate_orders\",\n",
    "        source=\"s3://bucket/orders/{{ ds }}.parquet\",\n",
    "        config=\"duckguard.yaml\",\n",
    "        fail_on_error=True,      # Fail task if validation fails\n",
    "        store_history=True,       # Store results in history\n",
    "        notify_on_failure=True,   # Send Slack/Teams notification\n",
    "    )\n",
    "    \n",
    "    # Wait for quality threshold to be met\n",
    "    wait_for_quality = DuckGuardSensor(\n",
    "        task_id=\"wait_for_quality\",\n",
    "        source=\"s3://bucket/orders/{{ ds }}.parquet\",\n",
    "        min_quality_score=80.0,   # Wait until score >= 80%\n",
    "        timeout=3600,             # Timeout after 1 hour\n",
    "        poke_interval=300,        # Check every 5 minutes\n",
    "    )\n",
    "    \n",
    "    # Chain tasks\n",
    "    validate_orders >> wait_for_quality\n",
    "```\n",
    "\n",
    "### Operator Features\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Template Fields** | Use Airflow Jinja templating in source paths |\n",
    "| **XCom Integration** | Returns quality score and results to XCom |\n",
    "| **History Storage** | Automatically store results for trending |\n",
    "| **Notifications** | Send Slack/Teams alerts on failure |\n",
    "| **Fail on Error** | Configurable task failure behavior |\n",
    "| **Quality Sensor** | Wait for quality thresholds to be met |\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "pip install duckguard[airflow]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97notw2n6j9",
   "metadata": {},
   "source": [
    "## 16. GitHub Action (NEW in v2.1)\n",
    "\n",
    "Add data quality gates to your CI/CD pipeline with the DuckGuard GitHub Action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h8l9tlbm1kt",
   "metadata": {},
   "source": [
    "### GitHub Actions Workflow\n",
    "\n",
    "```yaml\n",
    "# .github/workflows/data-quality.yml\n",
    "name: Data Quality Check\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    paths:\n",
    "      - 'data/**'\n",
    "  pull_request:\n",
    "    paths:\n",
    "      - 'data/**'\n",
    "\n",
    "jobs:\n",
    "  quality-check:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      \n",
    "      - name: Run DuckGuard Quality Check\n",
    "        uses: XDataHubAI/duckguard/.github/actions/duckguard-check@main\n",
    "        with:\n",
    "          source: data/orders.csv\n",
    "          config: duckguard.yaml\n",
    "          fail-on-warning: false\n",
    "          python-version: '3.11'\n",
    "        \n",
    "      - name: Check Results\n",
    "        if: always()\n",
    "        run: |\n",
    "          echo \"Quality Score: ${{ steps.duckguard.outputs.quality-score }}\"\n",
    "          echo \"Grade: ${{ steps.duckguard.outputs.grade }}\"\n",
    "          echo \"Passed: ${{ steps.duckguard.outputs.passed }}\"\n",
    "```\n",
    "\n",
    "### Action Inputs\n",
    "\n",
    "| Input | Description | Required | Default |\n",
    "|-------|-------------|----------|---------|\n",
    "| `source` | Data source path or URL | Yes | - |\n",
    "| `config` | Path to duckguard.yaml | No | Auto-discover |\n",
    "| `fail-on-warning` | Fail on warnings | No | `false` |\n",
    "| `fail-on-error` | Fail on errors | No | `true` |\n",
    "| `python-version` | Python version | No | `3.11` |\n",
    "\n",
    "### Action Outputs\n",
    "\n",
    "| Output | Description |\n",
    "|--------|-------------|\n",
    "| `passed` | Whether all checks passed |\n",
    "| `quality-score` | Overall quality score (0-100) |\n",
    "| `grade` | Letter grade (A, B, C, D, F) |\n",
    "| `checks-total` | Total number of checks |\n",
    "| `checks-passed` | Number of passed checks |\n",
    "| `checks-failed` | Number of failed checks |\n",
    "\n",
    "### Features\n",
    "\n",
    "- Automatic GitHub Step Summary with formatted results\n",
    "- Exit codes for CI/CD integration\n",
    "- Caching of Python dependencies\n",
    "- Works with any data source DuckGuard supports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qwd63re777d",
   "metadata": {},
   "source": "### 17.6 Security & Performance Notes\n\n**Security:**\n- All SQL conditions are validated to prevent SQL injection\n- Only SELECT queries allowed (no INSERT, UPDATE, DELETE, DROP, etc.)\n- Query complexity scoring with configurable limits\n- Automatic query timeout (30 seconds)\n- Result set limits (10,000 rows)\n\n**Performance:**\n- Conditional checks use optimized SQL filtering\n- Multi-column checks run in single pass\n- Query-based checks leverage DuckDB's columnar engine\n- Distributional tests cache statistics\n- All checks benefit from DuckDB's parallel processing\n\n**Best Practices:**\n1. Start with basic checks, then add conditional/query-based\n2. Use thresholds to allow acceptable error rates\n3. Combine checks for comprehensive coverage\n4. Monitor query complexity scores\n5. Use distributional tests for ML feature validation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0puvwlvrdv3o",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production-grade validation pipeline combining all 3.0 features\n",
    "\n",
    "# Step 1: Conditional Validation\n",
    "# High-value orders (>$1000) must have customer info\n",
    "# high_value_check = orders.customer_id.not_null_when(\"total >= 1000\")\n",
    "\n",
    "# USA orders must have state\n",
    "# usa_state_check = orders.state.not_null_when(\"country = 'USA'\")\n",
    "\n",
    "# Premium customers get higher discount limits\n",
    "# premium_discount_check = orders.discount.between_when(\n",
    "#     min_value=0,\n",
    "#     max_value=200,\n",
    "#     condition=\"customer_tier = 'premium'\"\n",
    "# )\n",
    "\n",
    "# Step 2: Multi-Column Validation\n",
    "# Verify order total calculation\n",
    "# total_check = orders.expect_column_pair_satisfy(\n",
    "#     column_a=\"total\",\n",
    "#     column_b=\"subtotal\",\n",
    "#     expression=\"ABS(total - (subtotal + tax + shipping - discount)) < 0.01\",\n",
    "#     threshold=1.0\n",
    "# )\n",
    "\n",
    "# Ship date after order date\n",
    "# date_check = orders.expect_column_pair_satisfy(\n",
    "#     column_a=\"ship_date\",\n",
    "#     column_b=\"order_date\",\n",
    "#     expression=\"ship_date >= order_date\",\n",
    "#     threshold=0.98  # Allow 2% data entry errors\n",
    "# )\n",
    "\n",
    "# Step 3: Query-Based Validation\n",
    "# No completed orders with missing payments\n",
    "# payment_check = orders.expect_query_to_return_no_rows(\n",
    "#     query=\"\"\"\n",
    "#         SELECT * FROM table\n",
    "#         WHERE status = 'completed'\n",
    "#         AND (payment_status IS NULL OR payment_status != 'paid')\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# Daily order volume in expected range\n",
    "# volume_check = orders.expect_query_result_to_be_between(\n",
    "#     query=\"\"\"\n",
    "#         SELECT COUNT(*) FROM table\n",
    "#         WHERE DATE(order_date) = CURRENT_DATE\n",
    "#     \"\"\",\n",
    "#     min_value=100,   # At least 100 orders/day\n",
    "#     max_value=10000  # At most 10k orders/day\n",
    "# )\n",
    "\n",
    "# Average order value reasonable\n",
    "# aov_check = orders.expect_query_result_to_be_between(\n",
    "#     query=\"SELECT AVG(total) FROM table WHERE status = 'completed'\",\n",
    "#     min_value=25.0,\n",
    "#     max_value=500.0\n",
    "# )\n",
    "\n",
    "# Step 4: Distributional Validation (if scipy available)\n",
    "# Check if order amounts follow expected distribution\n",
    "# try:\n",
    "#     dist_check = orders.total.expect_ks_test(\n",
    "#         distribution='expon',  # Order values often follow exponential\n",
    "#         significance_level=0.05\n",
    "#     )\n",
    "# except ImportError:\n",
    "#     print(\"scipy not available - skipping distributional checks\")\n",
    "\n",
    "print(\"Complete 3.0 Validation Pipeline:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n1. CONDITIONAL CHECKS\")\n",
    "print(\"    High-value orders have customer info\")\n",
    "print(\"    USA orders have state\")\n",
    "print(\"    Premium discounts within limits\")\n",
    "print(\"\\n2. MULTI-COLUMN CHECKS\")\n",
    "print(\"    Order totals calculated correctly\")\n",
    "print(\"    Ship dates after order dates\")\n",
    "print(\"\\n3. QUERY-BASED CHECKS\")\n",
    "print(\"    No incomplete payment data\")\n",
    "print(\"    Daily volume in expected range\")\n",
    "print(\"    Average order value reasonable\")\n",
    "print(\"\\n4. DISTRIBUTIONAL CHECKS\")\n",
    "print(\"    Order amounts follow expected distribution\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"This comprehensive approach catches 95%+ of data quality issues!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80oe0ma2jlk",
   "metadata": {},
   "source": "### 17.5 Real-World Example: E-commerce Order Validation\n\nHere's how all 3.0 features work together in a production scenario:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7koj3189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Distributional tests require scipy\n",
    "# Install: pip install 'duckguard[statistics]'\n",
    "\n",
    "# Example 1: Test if feature follows normal distribution\n",
    "# result = data.age.expect_distribution_normal(significance_level=0.05)\n",
    "# print(f\"Age follows normal distribution: {result.passed}\")\n",
    "# print(f\"P-value: {result.details['pvalue']:.4f}\")\n",
    "# print(f\"Mean: {result.details['mean']:.2f}, Std: {result.details['std']:.2f}\")\n",
    "\n",
    "# Example 2: Test if feature follows uniform distribution\n",
    "# result = data.random_id.expect_distribution_uniform(significance_level=0.05)\n",
    "# print(f\"Random ID uniformly distributed: {result.passed}\")\n",
    "\n",
    "# Example 3: General KS test for any scipy distribution\n",
    "# result = data.response_time.expect_ks_test(\n",
    "#     distribution='expon',  # Exponential distribution\n",
    "#     significance_level=0.05\n",
    "# )\n",
    "# print(f\"Response time follows exponential: {result.passed}\")\n",
    "\n",
    "# Example 4: Chi-square test for categorical distribution\n",
    "# result = data.category.expect_chi_square_test(\n",
    "#     expected_frequencies={\n",
    "#         'A': 0.25,  # 25% category A\n",
    "#         'B': 0.25,  # 25% category B\n",
    "#         'C': 0.30,  # 30% category C\n",
    "#         'D': 0.20   # 20% category D\n",
    "#     },\n",
    "#     significance_level=0.05\n",
    "# )\n",
    "# print(f\"Category distribution matches expected: {result.passed}\")\n",
    "\n",
    "print(\"Distributional testing use cases:\")\n",
    "print(\" Validate ML feature distributions haven't changed\")\n",
    "print(\" Detect data drift in production pipelines\")\n",
    "print(\" Ensure uniform distribution of random sampling\")\n",
    "print(\" Verify categorical distributions match business rules\")\n",
    "print(\" QA synthetic or generated data\")\n",
    "print(\"\\nAvailable distributions:\")\n",
    "print(\"  - Normal (Gaussian)\")\n",
    "print(\"  - Uniform\")\n",
    "print(\"  - Exponential\")\n",
    "print(\"  - Any scipy.stats distribution\")\n",
    "print(\"\\nNote: Requires scipy>=1.11.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62thq6gll4",
   "metadata": {},
   "source": "### 17.4 Distributional Testing\n\nStatistical distribution validation using Kolmogorov-Smirnov and chi-square tests. Perfect for ML feature validation and detecting data drift:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpbsazdje4r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Find violations (query should return no rows)\n",
    "# result = orders.expect_query_to_return_no_rows(\n",
    "#     query=\"\"\"\n",
    "#         SELECT * FROM table\n",
    "#         WHERE discount > subtotal\n",
    "#     \"\"\"\n",
    "# )\n",
    "# print(f\"No excessive discounts: {result.passed}\")\n",
    "\n",
    "# Example 2: Ensure expected data exists\n",
    "# result = orders.expect_query_to_return_rows(\n",
    "#     query=\"\"\"\n",
    "#         SELECT * FROM table\n",
    "#         WHERE status = 'completed' AND DATE(order_date) = CURRENT_DATE\n",
    "#     \"\"\"\n",
    "# )\n",
    "# print(f\"Have today's completed orders: {result.passed}\")\n",
    "\n",
    "# Example 3: Verify metric equals expected value\n",
    "# result = orders.expect_query_result_to_equal(\n",
    "#     query=\"SELECT COUNT(*) FROM table WHERE status = 'pending'\",\n",
    "#     expected=0,\n",
    "#     tolerance=5  # Allow +/- 5\n",
    "# )\n",
    "# print(f\"Pending orders in range: {result.passed}\")\n",
    "\n",
    "# Example 4: Verify metric is within range\n",
    "# result = orders.expect_query_result_to_be_between(\n",
    "#     query=\"SELECT AVG(total) FROM table WHERE status = 'completed'\",\n",
    "#     min_value=50.0,\n",
    "#     max_value=500.0\n",
    "# )\n",
    "# print(f\"Average order value in expected range: {result.passed}\")\n",
    "\n",
    "# Example 5: Complex business metric\n",
    "# result = orders.expect_query_result_to_be_between(\n",
    "#     query=\"\"\"\n",
    "#         SELECT\n",
    "#             (SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) * 100.0) /\n",
    "#             COUNT(*) as completion_rate\n",
    "#         FROM table\n",
    "#     \"\"\",\n",
    "#     min_value=80.0,  # At least 80% completion rate\n",
    "#     max_value=100.0\n",
    "# )\n",
    "# print(f\"Order completion rate acceptable: {result.passed}\")\n",
    "\n",
    "print(\"Query-based validation enables:\")\n",
    "print(\" Finding violations with custom SQL\")\n",
    "print(\" Validating aggregations and metrics\")\n",
    "print(\" Checking data freshness and completeness\")\n",
    "print(\" Complex multi-table validation\")\n",
    "print(\"\\nNote: Use 'table' keyword to reference your dataset in queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jt22p2iyq4",
   "metadata": {},
   "source": "### 17.3 Query-Based Checks\n\nWrite custom SQL queries to validate complex business logic. Perfect for aggregations, complex joins, and business metrics:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0xgxem0frrb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Validate total = subtotal + tax + shipping\n",
    "# result = orders.expect_column_pair_satisfy(\n",
    "#     column_a=\"total\",\n",
    "#     column_b=\"subtotal\",\n",
    "#     expression=\"ABS(total - (subtotal + tax + shipping)) < 0.01\",\n",
    "#     threshold=1.0  # 100% must pass\n",
    "# )\n",
    "\n",
    "# Example 2: Ship date must be after order date\n",
    "# result = orders.expect_column_pair_satisfy(\n",
    "#     column_a=\"ship_date\",\n",
    "#     column_b=\"order_date\",\n",
    "#     expression=\"ship_date >= order_date\",\n",
    "#     threshold=0.95  # Allow 5% exceptions\n",
    "# )\n",
    "\n",
    "# Example 3: Discount cannot exceed subtotal\n",
    "# result = orders.expect_column_pair_satisfy(\n",
    "#     column_a=\"discount\",\n",
    "#     column_b=\"subtotal\",\n",
    "#     expression=\"discount <= subtotal\",\n",
    "#     threshold=1.0\n",
    "# )\n",
    "\n",
    "# Example 4: Complex business rule\n",
    "# result = orders.expect_column_pair_satisfy(\n",
    "#     column_a=\"status\",\n",
    "#     column_b=\"payment_status\",\n",
    "#     expression=\"\"\"\n",
    "#         (status = 'shipped' AND payment_status = 'paid') OR\n",
    "#         (status = 'pending' AND payment_status IN ('pending', 'paid')) OR\n",
    "#         (status = 'cancelled')\n",
    "#     \"\"\",\n",
    "#     threshold=1.0\n",
    "# )\n",
    "\n",
    "print(\"Multi-column validation allows you to:\")\n",
    "print(\" Validate mathematical relationships (total = sum of parts)\")\n",
    "print(\" Check temporal consistency (end_date >= start_date)\")\n",
    "print(\" Enforce business rules across multiple fields\")\n",
    "print(\" Set thresholds for acceptable violation rates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ilxvdjzxrg",
   "metadata": {},
   "source": "### 17.2 Multi-Column Validation\n\nExpress complex relationships between columns using SQL expressions:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kgqjpe751zi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Email required for subscribed customers\n",
    "# orders.email.not_null_when(\"subscription_status = 'active'\")\n",
    "\n",
    "# Example: State required for USA addresses\n",
    "# orders.state.not_null_when(\"country = 'USA'\")\n",
    "\n",
    "# Example: Discount validation based on customer tier\n",
    "# orders.discount.between_when(\n",
    "#     min_value=0,\n",
    "#     max_value=50,\n",
    "#     condition=\"customer_tier = 'premium'\"\n",
    "# )\n",
    "\n",
    "# Example: Unique order IDs for completed orders\n",
    "# orders.order_id.unique_when(\"status = 'completed'\")\n",
    "\n",
    "# Example: Pattern matching for specific categories\n",
    "# orders.sku.pattern_when(\n",
    "#     pattern=r'^ELEC-\\d{6}$',\n",
    "#     condition=\"category = 'electronics'\"\n",
    "# )\n",
    "\n",
    "print(\"Conditional validation examples:\")\n",
    "print(\" not_null_when(condition) - Column must not be null when condition is true\")\n",
    "print(\" unique_when(condition) - Column must be unique when condition is true\")\n",
    "print(\" between_when(min, max, condition) - Column in range when condition is true\")\n",
    "print(\" isin_when(values, condition) - Column in list when condition is true\")\n",
    "print(\" pattern_when(regex, condition) - Column matches pattern when condition is true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s34i0hmtz7k",
   "metadata": {},
   "source": "### 17.1 Conditional Expectations\n\nValidate columns only when specific conditions are met - perfect for business rules that apply to subsets of data:"
  },
  {
   "cell_type": "markdown",
   "id": "z3vz5lew7ls",
   "metadata": {},
   "source": "## 17. DuckGuard 3.0 Features - Advanced Validation\n\nDuckGuard 3.0 introduces powerful new validation capabilities for complex data quality scenarios:\n\n1. **Conditional Expectations** - Validate only when conditions are met\n2. **Multi-Column Validation** - Express relationships between columns  \n3. **Query-Based Checks** - Custom SQL for complex business logic\n4. **Distributional Testing** - Statistical distribution validation"
  },
  {
   "cell_type": "markdown",
   "id": "a0wlm8estel",
   "metadata": {},
   "source": [
    "## 13. Enhanced Error Messages (NEW in v2.1)\n",
    "\n",
    "DuckGuard v2.1 provides helpful error messages with suggestions, documentation links, and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ofm33q6etka",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced error classes with helpful suggestions\n",
    "from duckguard.errors import (\n",
    "    ColumnNotFoundError,\n",
    "    UnsupportedConnectorError,\n",
    "    ValidationError,\n",
    ")\n",
    "\n",
    "# Example: Column not found error with suggestions\n",
    "try:\n",
    "    # Simulate accessing a non-existent column\n",
    "    raise ColumnNotFoundError(\n",
    "        column=\"order\",\n",
    "        available_columns=[\"order_id\", \"customer_id\", \"total_amount\", \"status\"]\n",
    "    )\n",
    "except ColumnNotFoundError as e:\n",
    "    print(\"ColumnNotFoundError:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(str(e))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3wgjep2rzvm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation error with failed rows and context\n",
    "try:\n",
    "    raise ValidationError(\n",
    "        check_name=\"between\",\n",
    "        column=\"quantity\",\n",
    "        actual_value=5,\n",
    "        expected_value=\"[1, 100]\",\n",
    "        failed_rows=[150, 200, 300, 400, 500]\n",
    "    )\n",
    "except ValidationError as e:\n",
    "    print(\"ValidationError:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(str(e))\n",
    "    print()\n",
    "\n",
    "# Unsupported connector error with format suggestions\n",
    "try:\n",
    "    raise UnsupportedConnectorError(source=\"data.xyz\")\n",
    "except UnsupportedConnectorError as e:\n",
    "    print(\"UnsupportedConnectorError:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "## 14. Auto-Profiling\n",
    "\n",
    "Let DuckGuard analyze your data and suggest validation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckguard.profiler import AutoProfiler\n",
    "\n",
    "# Profile the dataset\n",
    "profiler = AutoProfiler(dataset_var_name=\"orders\")\n",
    "profile_result = profiler.profile(orders)\n",
    "\n",
    "print(f\"Profiled: {profile_result.source}\")\n",
    "print(f\"Rows: {profile_result.row_count}\")\n",
    "print(f\"Columns: {profile_result.column_count}\")\n",
    "print(f\"\\nSuggested Rules ({len(profile_result.suggested_rules)}):\")\n",
    "print(\"-\" * 60)\n",
    "for rule in profile_result.suggested_rules[:10]:  # Show first 10\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "## 15. Using with pytest\n",
    "\n",
    "DuckGuard integrates seamlessly with pytest. Create a test file:\n",
    "\n",
    "```python\n",
    "# test_data_quality.py\n",
    "import pytest\n",
    "from duckguard import connect, load_rules, execute_rules, validate_contract, load_contract\n",
    "\n",
    "@pytest.fixture\n",
    "def orders():\n",
    "    return connect(\"data/orders.csv\")\n",
    "\n",
    "# Test with YAML rules\n",
    "def test_yaml_rules(orders):\n",
    "    rules = load_rules(\"duckguard.yaml\")\n",
    "    result = execute_rules(rules, orders)\n",
    "    assert result.failed == 0, f\"Failed checks: {result.failed}\"\n",
    "\n",
    "# Test with data contract\n",
    "def test_contract(orders):\n",
    "    contract = load_contract(\"contract.yaml\")\n",
    "    result = validate_contract(contract, orders)\n",
    "    assert result.is_valid, f\"Contract violations: {result.errors}\"\n",
    "\n",
    "# Traditional assertion tests\n",
    "def test_orders_not_empty(orders):\n",
    "    assert orders.row_count > 0\n",
    "\n",
    "def test_order_ids_valid(orders):\n",
    "    assert orders.order_id.null_percent == 0\n",
    "    assert orders.order_id.has_no_duplicates()\n",
    "\n",
    "def test_quality_score(orders):\n",
    "    score = orders.score()\n",
    "    assert score.overall >= 80, f\"Quality score too low: {score.overall}\"\n",
    "\n",
    "# NEW: Test with row-level error details\n",
    "def test_quantity_range(orders):\n",
    "    result = orders.quantity.between(1, 100)\n",
    "    if not result.passed:\n",
    "        # Get detailed failure info for debugging\n",
    "        print(result.summary())\n",
    "    assert result.passed, f\"Found {result.total_failures} values out of range\"\n",
    "```\n",
    "\n",
    "Run with: `pytest test_data_quality.py -v`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-41",
   "metadata": {},
   "source": [
    "## 19. CLI Commands\n",
    "\n",
    "DuckGuard provides powerful CLI commands with beautiful Rich output:\n",
    "\n",
    "```bash\n",
    "# Quick check with auto-generated rules\n",
    "duckguard check data/orders.csv\n",
    "\n",
    "# Check with YAML rules file\n",
    "duckguard check data/orders.csv --config duckguard.yaml\n",
    "\n",
    "# Discover data and generate rules\n",
    "duckguard discover data/orders.csv\n",
    "duckguard discover data/orders.csv --output duckguard.yaml\n",
    "\n",
    "# Generate data contract\n",
    "duckguard contract generate data/orders.csv\n",
    "duckguard contract generate data/orders.csv --output contract.yaml --owner \"data-team\"\n",
    "\n",
    "# Validate against contract\n",
    "duckguard contract validate data/orders.csv --contract contract.yaml\n",
    "\n",
    "# Compare contracts for breaking changes\n",
    "duckguard contract diff old_contract.yaml new_contract.yaml\n",
    "\n",
    "# Detect anomalies\n",
    "duckguard anomaly data/orders.csv\n",
    "duckguard anomaly data/orders.csv --method iqr --threshold 1.5\n",
    "\n",
    "# ML-based anomaly detection (NEW in v2.2)\n",
    "duckguard anomaly data/orders.csv --learn-baseline    # Learn baseline\n",
    "duckguard anomaly data/orders.csv --method baseline   # Compare to baseline\n",
    "duckguard anomaly data/orders.csv --method ks_test    # Distribution drift\n",
    "\n",
    "# Generate reports (NEW in v2.1)\n",
    "duckguard report data/orders.csv                           # HTML report\n",
    "duckguard report data/orders.csv --format pdf              # PDF report\n",
    "duckguard report data/orders.csv --title \"Daily Report\"    # Custom title\n",
    "\n",
    "# View validation history (NEW in v2.1)\n",
    "duckguard history                                          # All recent runs\n",
    "duckguard history data/orders.csv --last 7d               # Last 7 days\n",
    "duckguard history data/orders.csv --trend                  # Trend analysis\n",
    "\n",
    "# Freshness monitoring (NEW in v2.2)\n",
    "duckguard freshness data/orders.csv                        # Check via file mtime\n",
    "duckguard freshness data/orders.csv --column updated_at    # Check via column\n",
    "duckguard freshness data/orders.csv --max-age 6h           # Custom threshold\n",
    "\n",
    "# Schema evolution tracking (NEW in v2.2)\n",
    "duckguard schema data/orders.csv --action show             # Show current schema\n",
    "duckguard schema data/orders.csv --action capture          # Capture snapshot\n",
    "duckguard schema data/orders.csv --action history          # View schema history\n",
    "duckguard schema data/orders.csv --action changes          # Detect changes\n",
    "\n",
    "# Show version and info\n",
    "duckguard info\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": [
    "## 20. Quick Reference\n",
    "\n",
    "### YAML Rule Syntax\n",
    "\n",
    "```yaml\n",
    "dataset: my_data\n",
    "rules:\n",
    "  # Table-level\n",
    "  - row_count > 0\n",
    "  - row_count < 1000000\n",
    "  \n",
    "  # Column nulls\n",
    "  - column_name is not null\n",
    "  - column_name null_percent < 5\n",
    "  \n",
    "  # Uniqueness\n",
    "  - column_name is unique\n",
    "  - column_name unique_percent > 95\n",
    "  \n",
    "  # Ranges\n",
    "  - column_name >= 0\n",
    "  - column_name between 0 and 100\n",
    "  \n",
    "  # Sets\n",
    "  - column_name in ['a', 'b', 'c']\n",
    "  \n",
    "  # Patterns\n",
    "  - column_name matches '^[A-Z]{3}$'\n",
    "```\n",
    "\n",
    "### Reference/FK Checks & Cross-Dataset Validation (v2.2)\n",
    "\n",
    "```python\n",
    "from duckguard import connect\n",
    "\n",
    "orders = connect(\"orders.parquet\")\n",
    "customers = connect(\"customers.parquet\")\n",
    "status_lookup = connect(\"status_codes.csv\")\n",
    "\n",
    "# Check FK relationship - all values exist in reference\n",
    "result = orders[\"customer_id\"].exists_in(customers[\"id\"])\n",
    "\n",
    "# FK check with null handling options\n",
    "result = orders[\"customer_id\"].references(customers[\"id\"], allow_nulls=True)\n",
    "\n",
    "# Get list of orphan values\n",
    "orphans = orders[\"customer_id\"].find_orphans(customers[\"id\"])\n",
    "\n",
    "# Compare value sets between columns\n",
    "result = orders[\"status\"].matches_values(status_lookup[\"code\"])\n",
    "\n",
    "# Compare row counts between datasets\n",
    "result = orders.row_count_matches(backup_orders)\n",
    "result = orders.row_count_matches(backup_orders, tolerance=10)\n",
    "```\n",
    "\n",
    "### Reconciliation (v2.2)\n",
    "\n",
    "```python\n",
    "# Compare two datasets row-by-row using key columns\n",
    "result = source.reconcile(\n",
    "    target,\n",
    "    key_columns=[\"order_id\"],\n",
    "    compare_columns=[\"amount\", \"status\"],\n",
    "    tolerance=0.01,  # Numeric tolerance\n",
    "    sample_mismatches=10  # Number of sample mismatches to capture\n",
    ")\n",
    "\n",
    "print(f\"Match: {result.match_percentage}%\")\n",
    "print(f\"Missing in target: {result.missing_in_target}\")\n",
    "print(f\"Extra in target: {result.extra_in_target}\")\n",
    "print(f\"Value mismatches: {result.value_mismatches}\")\n",
    "print(result.summary())\n",
    "```\n",
    "\n",
    "### Distribution Drift Detection (v2.2)\n",
    "\n",
    "```python\n",
    "# Detect distribution drift using KS-test\n",
    "baseline = connect(\"baseline.csv\")\n",
    "current = connect(\"current.csv\")\n",
    "\n",
    "result = baseline[\"amount\"].detect_drift(current[\"amount\"])\n",
    "\n",
    "print(f\"Drift detected: {result.is_drifted}\")\n",
    "print(f\"P-value: {result.p_value:.4f}\")\n",
    "print(f\"KS statistic: {result.statistic:.4f}\")\n",
    "print(f\"Threshold: {result.threshold}\")\n",
    "print(result.summary())\n",
    "```\n",
    "\n",
    "### Group By Checks (v2.2)\n",
    "\n",
    "```python\n",
    "# Run validation checks on data segments\n",
    "orders = connect(\"orders.csv\")\n",
    "\n",
    "# Group by region and validate\n",
    "grouped = orders.group_by(\"region\")\n",
    "print(f\"Groups: {grouped.groups}\")\n",
    "print(f\"Stats: {grouped.stats()}\")\n",
    "\n",
    "# Validate row counts per group\n",
    "result = orders.group_by(\"region\").row_count_greater_than(10)\n",
    "print(f\"Passed: {result.passed}\")\n",
    "print(f\"Passed groups: {result.passed_groups}/{result.total_groups}\")\n",
    "\n",
    "# Get failed groups for debugging\n",
    "for g in result.get_failed_groups():\n",
    "    print(f\"  {g.group_key}: {g.row_count} rows\")\n",
    "```\n",
    "\n",
    "### Freshness Monitoring (v2.2)\n",
    "\n",
    "```python\n",
    "from duckguard.freshness import FreshnessMonitor\n",
    "from datetime import timedelta\n",
    "\n",
    "# Quick check via property\n",
    "print(orders.freshness.age_human)  # \"2 hours ago\"\n",
    "print(orders.freshness.is_fresh)   # True\n",
    "\n",
    "# Custom threshold\n",
    "if not orders.is_fresh(timedelta(hours=6)):\n",
    "    print(\"Data is stale!\")\n",
    "\n",
    "# Column-based freshness\n",
    "monitor = FreshnessMonitor(threshold=timedelta(hours=1))\n",
    "result = monitor.check_column_timestamp(orders, \"updated_at\")\n",
    "```\n",
    "\n",
    "### ML-Based Anomaly Detection (v2.2)\n",
    "\n",
    "```python\n",
    "from duckguard.anomaly import BaselineMethod, KSTestMethod\n",
    "\n",
    "# Learn baseline and detect anomalies\n",
    "baseline = BaselineMethod(sensitivity=2.0)\n",
    "baseline.fit(orders.amount)\n",
    "scores = baseline.score(orders.amount)\n",
    "\n",
    "# Distribution drift detection\n",
    "ks = KSTestMethod(p_value_threshold=0.05)\n",
    "result = ks.compare_distributions(orders.amount)\n",
    "print(f\"Drift detected: {result.is_drift}\")\n",
    "```\n",
    "\n",
    "### Schema Evolution (v2.2)\n",
    "\n",
    "```python\n",
    "from duckguard.schema_history import SchemaTracker, SchemaChangeAnalyzer\n",
    "\n",
    "tracker = SchemaTracker()\n",
    "snapshot = tracker.capture(orders)\n",
    "\n",
    "analyzer = SchemaChangeAnalyzer()\n",
    "report = analyzer.detect_changes(orders)\n",
    "if report.has_breaking_changes:\n",
    "    print(\"Breaking changes detected!\")\n",
    "```\n",
    "\n",
    "### Email Notifications (v2.2)\n",
    "\n",
    "```python\n",
    "from duckguard.notifications import EmailNotifier\n",
    "\n",
    "email = EmailNotifier(\n",
    "    smtp_host=\"smtp.gmail.com\",\n",
    "    smtp_user=\"alerts@company.com\",\n",
    "    smtp_password=\"app_password\",\n",
    "    to_addresses=[\"team@company.com\"],\n",
    ")\n",
    "# Or set DUCKGUARD_EMAIL_CONFIG env var\n",
    "\n",
    "if not result.passed:\n",
    "    email.send_failure_alert(result)\n",
    "```\n",
    "\n",
    "### Row-Level Error Debugging (v2.1)\n",
    "\n",
    "```python\n",
    "result = orders.quantity.between(1, 100)\n",
    "if not result.passed:\n",
    "    print(result.summary())           # Human-readable summary\n",
    "    print(result.get_failed_values()) # [150, 200, ...]\n",
    "    print(result.get_failed_row_indices())  # [5, 12, ...]\n",
    "    for row in result.failed_rows:\n",
    "        print(f\"Row {row.row_index}: {row.value}\")\n",
    "```\n",
    "\n",
    "### Notifications (v2.1)\n",
    "\n",
    "```python\n",
    "from duckguard.notifications import SlackNotifier, TeamsNotifier\n",
    "\n",
    "slack = SlackNotifier(webhook_url=\"...\")  # or DUCKGUARD_SLACK_WEBHOOK\n",
    "teams = TeamsNotifier(webhook_url=\"...\")  # or DUCKGUARD_TEAMS_WEBHOOK\n",
    "\n",
    "result = execute_rules(rules, dataset=orders)\n",
    "if not result.passed:\n",
    "    slack.send_failure_alert(result)\n",
    "    teams.send_failure_alert(result)\n",
    "```\n",
    "\n",
    "### dbt Integration (v2.1)\n",
    "\n",
    "```python\n",
    "from duckguard.integrations import dbt\n",
    "\n",
    "dbt.export_to_schema(rules, \"models/schema.yml\")\n",
    "dbt.generate_singular_tests(rules, \"tests/\")\n",
    "rules = dbt.import_from_dbt(\"models/schema.yml\")\n",
    "```\n",
    "\n",
    "### HTML/PDF Reports (v2.1)\n",
    "\n",
    "```python\n",
    "from duckguard.reports import generate_html_report, generate_pdf_report\n",
    "\n",
    "generate_html_report(result, \"report.html\", title=\"Quality Report\")\n",
    "generate_pdf_report(result, \"report.pdf\")  # requires weasyprint\n",
    "```\n",
    "\n",
    "### Historical Tracking (v2.1)\n",
    "\n",
    "```python\n",
    "from duckguard.history import HistoryStorage, TrendAnalyzer\n",
    "\n",
    "storage = HistoryStorage()\n",
    "run_id = storage.store(result)\n",
    "\n",
    "analyzer = TrendAnalyzer(storage)\n",
    "trend = analyzer.analyze(\"data.csv\", days=30)\n",
    "print(trend.summary())\n",
    "```\n",
    "\n",
    "### Airflow Integration (v2.1)\n",
    "\n",
    "```python\n",
    "from duckguard.integrations.airflow import DuckGuardOperator\n",
    "\n",
    "validate = DuckGuardOperator(\n",
    "    task_id=\"validate\",\n",
    "    source=\"s3://bucket/data.parquet\",\n",
    "    config=\"duckguard.yaml\",\n",
    "    fail_on_error=True,\n",
    ")\n",
    "```\n",
    "\n",
    "### Semantic Types Detected\n",
    "\n",
    "- `email`, `phone`, `url`, `ip_address`\n",
    "- `uuid`, `credit_card`, `iban`\n",
    "- `ssn`, `date_of_birth` (PII)\n",
    "- `country`, `state`, `zip_code`\n",
    "- `latitude`, `longitude`\n",
    "- `timestamp`, `currency`, `percentage`\n",
    "\n",
    "### Contract Validation\n",
    "\n",
    "- Schema: column names, types, nullability\n",
    "- Quality: completeness, null %, custom rules\n",
    "- Breaking changes: removed columns, type changes, nullability\n",
    "\n",
    "### Anomaly Detection Methods\n",
    "\n",
    "| Method | Threshold | Use Case |\n",
    "|--------|-----------|----------|\n",
    "| `zscore` | 3.0 (std devs) | Normal data |\n",
    "| `iqr` | 1.5 (IQR multiplier) | Outlier-robust |\n",
    "| `percent_change` | 0.2 (20%) | Time-series monitoring |\n",
    "| `modified_zscore` | 3.5 | Non-normal distributions |\n",
    "| `baseline` | 2.0 (sensitivity) | Learn from history |\n",
    "| `ks_test` | 0.05 (p-value) | Distribution drift |\n",
    "\n",
    "### Cross-Dataset Validation Methods\n",
    "\n",
    "| Method | Description | Use Case |\n",
    "|--------|-------------|----------|\n",
    "| `col.exists_in(other_col)` | Check values exist in reference | FK validation |\n",
    "| `col.references(other_col)` | FK check with null handling | Optional/Required FK |\n",
    "| `col.find_orphans(other_col)` | Get orphan values | Debugging |\n",
    "| `col.matches_values(other_col)` | Compare value sets | Lookup validation |\n",
    "| `dataset.row_count_matches(other)` | Compare row counts | Backup validation |\n",
    "| `dataset.reconcile(target, key_columns)` | Row-by-row comparison | Migration validation |\n",
    "| `col.detect_drift(other_col)` | Distribution drift (KS-test) | ML monitoring |\n",
    "| `dataset.group_by(col).row_count_greater_than(n)` | Per-group validation | Segmented checks |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-43",
   "metadata": {},
   "source": [
    "## 21. Next Steps\n",
    "\n",
    "- **Documentation**: https://duckguard.dev\n",
    "- **GitHub**: https://github.com/XDataHubAI/duckguard\n",
    "- **Issues**: https://github.com/XDataHubAI/duckguard/issues\n",
    "\n",
    "### What to explore next:\n",
    "1. Generate a `duckguard.yaml` file for your data with `duckguard discover`\n",
    "2. Create a data contract with `duckguard contract generate`\n",
    "3. Set up anomaly monitoring with `duckguard anomaly`\n",
    "4. Add rules to your CI/CD pipeline with pytest\n",
    "5. Detect PII with semantic type detection\n",
    "6. Set up Slack/Teams/Email alerts for data quality failures\n",
    "7. Export your rules to dbt with `dbt.export_to_schema()`\n",
    "8. Use row-level error capture for debugging failed validations\n",
    "9. Generate HTML/PDF reports with `duckguard report`\n",
    "10. Track quality trends with `duckguard history --trend`\n",
    "11. Add DuckGuard to your Airflow DAGs\n",
    "12. Set up GitHub Actions for CI/CD quality gates\n",
    "13. **NEW**: Monitor data freshness with `duckguard freshness`\n",
    "14. **NEW**: Learn baselines for ML-based anomaly detection\n",
    "15. **NEW**: Track schema changes with `duckguard schema`\n",
    "16. **NEW**: Set up email notifications for alerts\n",
    "17. **NEW**: Validate FK relationships with `exists_in()` and `references()`\n",
    "18. **NEW**: Compare datasets with `row_count_matches()` and `matches_values()`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}