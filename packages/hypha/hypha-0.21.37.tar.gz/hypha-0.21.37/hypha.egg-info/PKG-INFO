Metadata-Version: 2.1
Name: hypha
Version: 0.21.37
Summary: A serverless application framework for large-scale data management and AI model serving.
Home-page: http://github.com/amun-ai/hypha
Author: Amun AI AB
Author-email: info@amun.ai
License: MIT
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: websockets>=14.0
Requires-Dist: aiofiles
Requires-Dist: fastapi<=0.115.2,>=0.70.0
Requires-Dist: hypha-rpc>=0.20.86
Requires-Dist: msgpack>=1.0.2
Requires-Dist: numpy
Requires-Dist: pydantic[email]>=2.6.1
Requires-Dist: typing-extensions>=3.7.4.3
Requires-Dist: jinja2>=3
Requires-Dist: lxml
Requires-Dist: python-dotenv>=0.19.0
Requires-Dist: python-jose>=3.3.0
Requires-Dist: python-multipart>=0.0.18
Requires-Dist: pyyaml>=6.0.1
Requires-Dist: fakeredis>=2.14.1
Requires-Dist: shortuuid>=1.0.1
Requires-Dist: uvicorn>=0.29.0
Requires-Dist: httpx>=0.21.1
Requires-Dist: pyotritonclient>=0.2.4
Requires-Dist: email-validator>=2.0.0; platform_system == "Emscripten"
Requires-Dist: pyodide-http; platform_system == "Emscripten"
Requires-Dist: ssl; platform_system == "Emscripten"
Requires-Dist: friendlywords>=1.1.3
Requires-Dist: aiocache>=0.12.2
Requires-Dist: jsonschema>=3.2.0
Requires-Dist: sqlalchemy>=2.0.35
Requires-Dist: greenlet>=3.1.1
Requires-Dist: aiosqlite>=0.20.0
Requires-Dist: prometheus-client>=0.21.1
Requires-Dist: uuid-utils>=0.9.0
Requires-Dist: sqlmodel>=0.0.22
Requires-Dist: alembic>=1.14.0
Requires-Dist: hrid==0.3.0
Requires-Dist: stream-zip>=0.0.83
Requires-Dist: starlette-compress>=1.6.0
Requires-Dist: prompt-toolkit>=3.0.50
Requires-Dist: ptpython>=3.0.29
Requires-Dist: ptyprocess==0.7.0
Provides-Extra: s3
Requires-Dist: aiobotocore>=2.1.0; extra == "s3"
Requires-Dist: dulwich>=0.21.7; extra == "s3"
Provides-Extra: server-apps
Requires-Dist: redis==5.2.0; extra == "server-apps"
Requires-Dist: aiobotocore>=2.1.0; extra == "server-apps"
Requires-Dist: aiortc>=1.9.0; extra == "server-apps"
Requires-Dist: requests>=2.26.0; extra == "server-apps"
Requires-Dist: playwright>=1.51.0; extra == "server-apps"
Requires-Dist: base58>=2.1.0; extra == "server-apps"
Requires-Dist: pymultihash>=0.8.2; extra == "server-apps"
Requires-Dist: fastuuid>=0.12.0; extra == "server-apps"
Provides-Extra: db
Requires-Dist: psycopg2-binary>=2.9.10; extra == "db"
Requires-Dist: asyncpg>=0.30.0; extra == "db"
Requires-Dist: fastembed>=0.4.2; extra == "db"
Requires-Dist: zarr>=3.1.2; python_version >= "3.11" and extra == "db"
Requires-Dist: numcodecs>=0.16.2; python_version >= "3.11" and extra == "db"
Provides-Extra: k8s
Requires-Dist: kubernetes>=24.2.0; extra == "k8s"
Provides-Extra: llm-proxy
Requires-Dist: openai>=1.0.0; extra == "llm-proxy"
Requires-Dist: tiktoken>=0.5.0; extra == "llm-proxy"
Requires-Dist: click>=8.0.0; extra == "llm-proxy"
Requires-Dist: tokenizers>=0.15.0; extra == "llm-proxy"
Requires-Dist: uvicorn>=0.29.0; extra == "llm-proxy"
Requires-Dist: uvloop>=0.21.0; sys_platform != "win32" and extra == "llm-proxy"
Requires-Dist: gunicorn>=23.0.0; extra == "llm-proxy"
Requires-Dist: fastapi>=0.115.5; extra == "llm-proxy"
Requires-Dist: backoff; extra == "llm-proxy"
Requires-Dist: pyyaml>=6.0.1; extra == "llm-proxy"
Requires-Dist: rq; extra == "llm-proxy"
Requires-Dist: orjson>=3.9.7; extra == "llm-proxy"
Requires-Dist: apscheduler>=3.10.4; extra == "llm-proxy"
Requires-Dist: fastapi-sso>=0.16.0; extra == "llm-proxy"
Requires-Dist: PyJWT>=2.8.0; extra == "llm-proxy"
Requires-Dist: python-multipart>=0.0.18; extra == "llm-proxy"
Requires-Dist: cryptography; extra == "llm-proxy"
Requires-Dist: prisma==0.11.0; extra == "llm-proxy"
Requires-Dist: azure-identity>=1.15.0; extra == "llm-proxy"
Requires-Dist: azure-keyvault-secrets>=4.8.0; extra == "llm-proxy"
Requires-Dist: azure-storage-blob>=12.25.1; extra == "llm-proxy"
Requires-Dist: google-cloud-kms>=2.21.3; extra == "llm-proxy"
Requires-Dist: google-cloud-iam>=2.19.1; extra == "llm-proxy"
Requires-Dist: resend>=0.8.0; extra == "llm-proxy"
Requires-Dist: pynacl>=1.5.0; extra == "llm-proxy"
Requires-Dist: websockets>=13.1.0; extra == "llm-proxy"
Requires-Dist: boto3==1.36.0; extra == "llm-proxy"
Requires-Dist: redisvl>=0.4.1; (python_version >= "3.9" and python_version < "3.14") and extra == "llm-proxy"
Requires-Dist: mcp>=1.10.0; python_version >= "3.10" and extra == "llm-proxy"
Requires-Dist: litellm-proxy-extras==0.2.19; extra == "llm-proxy"
Requires-Dist: rich==13.7.1; extra == "llm-proxy"
Requires-Dist: litellm-enterprise==0.1.20; extra == "llm-proxy"
Requires-Dist: diskcache>=5.6.1; extra == "llm-proxy"
Requires-Dist: polars>=1.31.0; python_version >= "3.10" and extra == "llm-proxy"
Requires-Dist: semantic-router; python_version >= "3.9" and extra == "llm-proxy"
Requires-Dist: mlflow>3.1.4; python_version >= "3.10" and extra == "llm-proxy"
Requires-Dist: google-genai>=0.1.0; extra == "llm-proxy"

# Hypha

![PyPI](https://img.shields.io/pypi/v/hypha.svg?style=popout)

<img src="./docs/img/hypha-logo-black.svg" width="320" alt="Hypha">

**Hypha** is a generative AI-powered application framework designed for large-scale data management, AI model serving, and real-time communication. Hypha allows the creation of computational platforms consisting of both computational and user interface components.

## Key Features

- **Generative AI-Powered:** Leverage the power of generative AI to build advanced data management and AI model serving solutions.
- **Hypha-RPC:** Utilize [hypha-rpc](https://github.com/oeway/hypha-rpc), a bidirectional remote procedure call system, enabling seamless communication and integration across distributed components.
- **Real-Time Communication:** Support for real-time communication within virtual workspaces, similar to platforms like Zoom.
- **Scalable and Flexible:** Connect and orchestrate various compute services, AI models, tools, and services running on distributed locations.
- **GenAI-Powered Automation:** Build GenAI-powered automation platforms and agentic workflows, enabling fully autonomous agent systems.

## How It Works

Hypha acts as a hub that connects different components through **Hypha-RPC**. Users and programmatic clients connect to the platform in virtual workspaces, where they can seamlessly make remote procedure calls (RPC) as if they are calling local functions. Developers can integrate all types of compute services, including AI models, tools, and services, across distributed locations.

### Virtual Workspaces

- Hypha's virtual workspaces are akin to Zoom rooms, where clients (users and programmatic) can connect and interact.
- Within these workspaces, all clients can perform seamless RPCs, facilitating easy and efficient collaboration and computation.

### Integration with Compute Services

- Hypha supports the integration of various compute services, including AI models and data analytics tools.
- These services, when connected to the platform, can be understood and orchestrated by large language models (LLMs), paving the way for creating next-generation GenAI-powered automation platforms and agentic workflows.

## Use Cases

- **Research Institutions:** Build integrated platforms for data management and AI-powered services.
- **AI-Powered Automation:** Create autonomous agent systems and GenAI-powered automation platforms.
- **Data Services:** Facilitate scalable and efficient data services and analytics through distributed computing.

## Getting Started

To get started with Hypha, follow the installation and setup instructions in the [documentation](https://docs.amun.ai).

## License

Hypha is released under the MIT License. See the [LICENSE](./LICENSE) file for more details.

This project includes code from third-party libraries. See the [THIRD_PARTY_LICENSES](./THIRD_PARTY_LICENSES) file for additional license information.

## Contributing

We welcome contributions from the community. Please see our [Contributing Guidelines](./CONTRIBUTING.md) for more information.

## Acknowledgments

We thank the contributors and community members who have helped make Hypha what it is today.
