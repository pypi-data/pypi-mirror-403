#Build Configuration for docker deployment to artifactory
image: python:3.13

definitions:
  services:
    redis:
      image: redis
  steps:
    - step: &download_execute_script
        name: Download Script Execute Script
        script:
          - echo "Retrieving Script Execution Script"
          - curl -fL https://getcli.jfrog.io | sh
          - ./jfrog rt dl --url $ARTIFACTORY_URL --user $ARTIFACTORY_USER --password $ARTIFACTORY_PASSWORD generic-packages/ci_scripts/latest/execute_script.sh
          - cat ci_scripts/latest/execute_script.sh
          - chmod 755 ci_scripts/latest/execute_script.sh
        artifacts:
          - ci_scripts/latest/execute_script.sh

    - step: &lint
        caches:
          - pip
        name: Lint
        script:
          - ./ci_scripts/latest/execute_script.sh lint_python.sh

    - step: &scan
        caches:
          - pip
        name: Scan
        script:
          - ./ci_scripts/latest/execute_script.sh scan_python.sh

    - step: &test
        caches:
          - pip
        name: Test
        script:
          - pip install -U pip wheel build setuptools_scm setuptools
          - pip install .[test]
          - pytest -v -n auto -m "not development" --pyargs dkist_processing_ops --cov dkist_processing_ops --cov-report xml:coverage.xml --cov-report term-missing
          - ./ci_scripts/latest/execute_script.sh upload_coverage.sh
        services:
          - redis

    - step: &check_freeze
        caches:
          - pip
        name: Check frozen deps
        script:
          - pip install -U pip
          - pip install dkist-dev-tools
          - ddt check freeze
    - step: &push_workflow
        caches:
          - pip
        name: Push Workflow
        script:
          - pip install -U pip
          - pip install .
          - export BUILD_VERSION="${BITBUCKET_TAG:1}"
          - export ARTIFACT_FOLDER="${BITBUCKET_REPO_SLUG}_${BUILD_VERSION}/"
          - python -c "from dkist_processing_core.build_utils import export_dags; import dkist_processing_ops.workflows as workflow_package; export_dags(workflow_package, '${ARTIFACT_FOLDER}')"
          - python -c "from dkist_processing_ops.dags.scale import export_scale_dags; export_scale_dags('${ARTIFACT_FOLDER}')"
          - export SOURCE_PATH="workflow_${BUILD_VERSION}.gz"
          - tar --exclude="bitbucket-pipelines.yml" -cvzf ${SOURCE_PATH} ${ARTIFACT_FOLDER}
          - export TARGET_PATH="generic-packages/dkist-processing-ops/${BUILD_VERSION}/"
          - curl -fL https://getcli.jfrog.io | sh
          - ./jfrog rt u --url $ARTIFACTORY_URL --user $ARTIFACTORY_USER --password $ARTIFACTORY_PASSWORD ${SOURCE_PATH} ${TARGET_PATH}
    - step: &push_code
        caches:
          - pip
        name: Push Code
        script:
          - ./ci_scripts/latest/execute_script.sh push_python.sh

pipelines:
  default:
    - step: *download_execute_script
    - step: *lint
    - parallel:
        - step: *scan
        - step: *test
  tags:
    'v*':
      - step: *download_execute_script
      - parallel:
          - step: *check_freeze
          - step: *lint
      - parallel:
          - step: *scan
          - step: *test
      - step: *push_workflow
      - step: *push_code
