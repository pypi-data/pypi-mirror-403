
# DO NOT EDIT THIS FILE -- AUTOGENERATED BY PANTS
# Target: src/ai/backend/appproxy/worker:dist

from setuptools import setup

setup(**{
    'author': 'Lablup Inc. and contributors',
    'classifiers': [
        'Intended Audience :: Developers',
        'Operating System :: MacOS :: MacOS X',
        'Operating System :: POSIX :: Linux',
        'Programming Language :: Python',
        'Programming Language :: Python :: 3',
        'Environment :: No Input/Output (Daemon)',
        'Topic :: Scientific/Engineering',
        'Topic :: Software Development',
        'Development Status :: 5 - Production/Stable',
        'Programming Language :: Python :: 3.13',
        'License :: OSI Approved :: GNU Lesser General Public License v3 or later (LGPLv3+)',
    ],
    'description': 'Backend.AI AppProxy Worker',
    'entry_points': {
        'backendai_cli_v10': [
            'app-proxy-worker = ai.backend.appproxy.worker.cli.__main__:main',
            'app-proxy-worker.start-server = ai.backend.appproxy.worker.cli.start_server:main',
        ],
    },
    'install_requires': (
        'Jinja2~=3.1.6',
        'PyJWT~=2.10.1',
        'aiohttp_cors~=0.8.1',
        'aiohttp_jinja2~=1.6',
        'aiohttp~=3.13.3',
        'aiomonitor~=0.7.0',
        'aiotools~=2.2.3',
        'attrs>=25.3',
        """backend.ai-appproxy-common==26.1.0
""",
        """backend.ai-common==26.1.0
""",
        """backend.ai-logging==26.1.0
""",
        """backend.ai-plugin==26.1.0
""",
        'click~=8.1.7',
        'memray~=1.17.2',
        'multidict~=6.6.4',
        'prometheus-client~=0.21.1',
        'pydantic[email]~=2.11.3',
        'pyroscope-io~=0.8.8',
        'setproctitle~=1.3.5',
        'tenacity>=9.0',
        'tomli-w~=1.2.0',
        'types-Jinja2',
        'uvloop~=0.22.1; sys_platform != "Windows"',
        'yarl~=1.19.0',
    ),
    'license': 'LGPLv3',
    'long_description': """# Backend.AI App Proxy Worker

## Purpose

The App Proxy Worker is a high-performance reverse proxy that routes user traffic to compute session services (Jupyter, SSH, TensorBoard, etc.) running on agents. It receives routing information from the Coordinator and handles SSL/TLS termination, load balancing, and traffic forwarding.

## Key Responsibilities

### 1. Traffic Proxying
- Proxy HTTP/HTTPS requests to session services
- Proxy WebSocket connections for interactive services
- Handle SSL/TLS termination
- Stream responses efficiently

### 2. Route Resolution
- Receive routing tables from Coordinator
- Resolve session services from URLs
- Cache routing information locally
- Update routes dynamically

### 3. Health Checking
- Monitor backend service health
- Detect failed services
- Report health status to Coordinator
- Handle service failover

## Architecture

### 1. Traffic Proxy (Main)

**Framework**: aiohttp + custom reverse proxy

**Port**: 5050 (default, HTTPS)

**Protocol**: HTTP/HTTPS, WebSocket

**Key Features**:

#### HTTP/HTTPS Proxy
- Route user requests to session services
- URL Pattern: `https://<worker-domain>/<session-id>/<service-name>/...`

#### WebSocket Proxy
- Interactive service communication (Jupyter Kernel, SSH, etc.)
- Real-time log streaming

**Key Characteristics**:
- SSL/TLS termination (Let's Encrypt auto-certificate)
- High-performance async proxy
- Connection pooling and reuse
- Streaming support (large file downloads)
- Sticky session support
- Auto-retry and failover

**Processing Flow**:

#### HTTP Proxy Flow
```
User → HTTPS Request → Worker (SSL termination)
                           ↓
                       Parse URL (extract session_id, service_name)
                           ↓
                       Lookup route from local cache
                           ↓
                       Resolve backend address (agent:port)
                           ↓
                       Proxy request to agent
                           ↓
                       Stream response back to user
```

#### WebSocket Proxy Flow
```
User → WS Upgrade Request → Worker
                               ↓
                           Establish WS connection to agent
                               ↓
                           Bidirectional message forwarding
```

### 2. REST API (Management)

**Framework**: aiohttp (async HTTP server)

**Port**: 6040 (default, separate management port)

**Key Features**:
- Communication with Coordinator
- Health check endpoints
- Metrics exposure (Prometheus)
- Internal management (no external access)

### Component Interaction

**Traffic Proxy Flow**:
```
User (Browser) → Worker (Port 5050) → Kernel (on Agent)
                    │
                    ├─ SSL/TLS termination
                    ├─ Route resolution
                    └─ Traffic proxying
```

**Management Flow**:
```
Coordinator → Worker REST API (Port 6040) → Route updates
```""",
    'long_description_content_type': 'text/markdown',
    'name': 'backend.ai-appproxy-worker',
    'namespace_packages': (
    ),
    'package_data': {
        'ai.backend.appproxy.worker': (
            'VERSION',
            'py.typed',
        ),
    },
    'packages': (
        'ai.backend.appproxy.worker',
        'ai.backend.appproxy.worker.api',
        'ai.backend.appproxy.worker.cli',
        'ai.backend.appproxy.worker.dependencies',
        'ai.backend.appproxy.worker.dependencies.bootstrap',
        'ai.backend.appproxy.worker.dependencies.infrastructure',
        'ai.backend.appproxy.worker.errors',
        'ai.backend.appproxy.worker.proxy.backend',
        'ai.backend.appproxy.worker.proxy.frontend',
        'ai.backend.appproxy.worker.proxy.frontend.h2',
        'ai.backend.appproxy.worker.proxy.frontend.http',
    ),
    'project_urls': {
        'Documentation': 'https://docs.backend.ai/',
        'Source': 'https://github.com/lablup/backend.ai',
    },
    'python_requires': '>=3.13,<3.14',
    'url': 'https://github.com/lablup/backend.ai',
    'version': """26.1.0
""",
    'zip_safe': False,
})
