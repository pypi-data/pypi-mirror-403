import tokenize
from io import BytesIO
import sys
import os

class TamilPythonCompiler:
    def __init__(self):
        # Mapping Tamil keywords to Python keywords
        self.translation_map = {
            # --- Control Flow ---
            'роОройро┐ро▓рпН': 'if',
            'роЖройро╛ро▓рпН': 'elif',
            'роЗро▓рпНро▓рпИ': 'else',
            'роЪрпБро▒рпНро▒рпБ': 'for',
            'ро╡ро░рпИ': 'while',
            'роЗро▓рпН': 'in',
            'роиро┐ро▒рпБродрпНродрпБ': 'break',
            'родрпКроЯро░рпН': 'continue',
            'ро╡ро┐роЯрпБ': 'pass',
            'родро┐ро░рпБрокрпНрокрпБ': 'return',

            # --- Operators ---
            'рооро▒рпНро▒рпБроорпН': 'and',
            'роЕро▓рпНро▓родрпБ': 'or',
            'роЗро▓рпНро▓ро╛род': 'not',
            'роЖроХ': 'as',
            'роОройрпНрокродрпБ': 'is',

            # --- Data & Types ---
            'роЙрогрпНроорпИ': 'True',
            'рокрпКропрпН': 'False',
            'роПродрпБрооро┐ро▓рпНро▓рпИ': 'None',
            'роЙро▓роХро│ро╛ро╡ро┐роп': 'global',

            # --- Structure ---
            'роЪрпЖропро▓рпН': 'def',
            'ро╡роХрпБрокрпНрокрпБ': 'class',
            'роЪрпБропроорпН': 'self',
            'роЗро░рпБроирпНродрпБ': 'from',
            'роЗро▒роХрпНроХрпБроородро┐': 'import',

            # --- Error Handling ---
            'роорпБропро▒рпНроЪро┐': 'try',
            'рокро┐ро┤рпИ': 'except',
            'роЗро▒рпБродро┐ропро╛роХ': 'finally',
            'роОро┤рпБрокрпН': 'raise',

            # --- Built-ins ---
            'рокродро┐': 'print',
            'роЙро│рпНро│ро┐роЯрпБ': 'input',
            'родрпКроЯро░рпНро╡рпЖро│ро┐ропрпАроЯрпБ': 'range',
            'роирпАро│роорпН': 'len',
            'роорпБро┤рпБроОрогрпН': 'int',
            'роЪро░роорпН': 'str',
            'рокроЯрпНроЯро┐ропро▓рпН': 'list'
        }

    def translate_and_run(self, tamil_code):
        # 1. Convert string to byte stream for tokenizer
        tokens = list(tokenize.tokenize(BytesIO(tamil_code.encode('utf-8')).readline))
        
        new_tokens = []
        for token in tokens:
            # FIX: If the user types 'роЕроорпИ', we simply skip it. 
            # This turns "роЕроорпИ x = 10" into "x = 10" automatically.
            if token.string == 'роЕроорпИ':
                continue

            if token.type == tokenize.NAME:
                if token.string in self.translation_map:
                    new_token = (token.type, self.translation_map[token.string])
                else:
                    new_token = (token.type, token.string)
            else:
                new_token = (token.type, token.string)
            
            new_tokens.append(new_token)

        # 2. Reconstruct the code
        python_code = tokenize.untokenize(new_tokens).decode('utf-8')
        
        # 3. Execute
        try:
            # We pass globals() to ensure imports (like math) work correctly
            exec(python_code, globals())
        except Exception as e:
            print(f"\nтЭМ рокро┐ро┤рпИ (Error): {e}")

# --- MAIN RUNNER ---
# ... (Keep the TamilPythonCompiler class exactly as it is) ...

def main():
    import sys
    import os

    # 1. Check arguments
    if len(sys.argv) < 2:
        print("тД╣я╕П  Usage: tamilpp <filename.tpp>")
        sys.exit(1)

    filename = sys.argv[1]
    compiler = TamilPythonCompiler()

    # 2. Check file existence
    if os.path.exists(filename):
        try:
            with open(filename, "r", encoding="utf-8") as f:
                code = f.read()
            # Optional: Don't show the translation when running professionally
            print(f"ЁЯУВ Running file: {filename} ...") 
            compiler.translate_and_run(code)
        except Exception as e:
            print(f"тЭМ Error reading file: {e}")
    else:
        print(f"тЭМ рокро┐ро┤рпИ: The file '{filename}' was not found.")

if __name__ == "__main__":
    main()