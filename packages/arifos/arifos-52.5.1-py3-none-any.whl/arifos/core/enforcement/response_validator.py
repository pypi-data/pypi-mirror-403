"""Constitutional module - F2 Truth enforced
Part of arifOS constitutional governance system
DITEMPA BUKAN DIBERI - Forged, not given
"""

"""
response_validator.py â€” Enforce 9 Constitutional Floors on AI Output

This module takes RAW AI TEXT and runs it through the floor detectors.
The AI cannot fake this â€” the code produces the verdict, not the AI.

Usage:
    from arifos.core.enforcement.response_validator import validate_response

    result = validate_response("I am a sentient being with feelings.")
    print(result)  # FloorReport with VOID verdict (F9 Anti-Hantu breach)
"""

from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple

from arifos.core.enforcement.metrics import (
    DELTA_S_THRESHOLD,
    KAPPA_R_THRESHOLD,
    OMEGA_0_MAX,
    OMEGA_0_MIN,
    PEACE_SQUARED_THRESHOLD,
    TRI_WITNESS_THRESHOLD,
    TRUTH_THRESHOLD,
    check_anti_hantu,
)


@dataclass
class FloorReport:
    """Machine-generated floor validation report."""

    timestamp: str
    text_length: int
    floors_passed: Dict[str, bool] = field(default_factory=dict)
    floor_scores: Dict[str, Optional[float]] = field(default_factory=dict)
    floor_evidence: Dict[str, str] = field(default_factory=dict)
    violations: List[str] = field(default_factory=list)
    verdict: str = "UNKNOWN"

    def __str__(self) -> str:
        lines = [
            "=" * 60,
            "ðŸ” FLOOR VALIDATION REPORT (Machine-Generated)",
            "=" * 60,
            f"Timestamp: {self.timestamp}",
            f"Text Length: {self.text_length} chars",
            "",
            "ðŸ“Š Floor Results:",
        ]
        for floor, passed in self.floors_passed.items():
            status = "âœ…" if passed else "âŒ"
            score = self.floor_scores.get(floor, "N/A")
            evidence = self.floor_evidence.get(floor, "")
            lines.append(f"  {status} {floor}: {score} â€” {evidence}")

        if self.violations:
            lines.append("")
            lines.append("âš ï¸ Violations Detected:")
            for v in self.violations:
                lines.append(f"  â€¢ {v}")

        lines.append("")
        lines.append(f"ðŸ§¾ VERDICT: {self.verdict}")
        lines.append("=" * 60)
        return "\n".join(lines)


def validate_response(
    text: str,
    claimed_omega: float = 0.04,  # Humility band (still claimed)
    evidence: Optional[Dict[str, Any]] = None,  # External evidence for Truth floor
    high_stakes: bool = False,  # Escalate to HOLD-888 if unverifiable in high-stakes mode
) -> FloorReport:
    """
    Validate AI response against all 9 Constitutional Floors.

    Args:
        text: The raw AI output to validate
        claimed_omega: Self-reported humility score
        evidence: Optional evidence dict with 'truth_score' field (0.0-1.0)
        high_stakes: If True, UNVERIFIABLE + high_stakes â†’ verdict becomes HOLD-888

    Returns:
        FloorReport with machine-verified results

    Note:
        Some floors (Truth, DeltaS) cannot be verified from text alone.
        These default to UNVERIFIABLE. If evidence is provided, it is used.

        F9 (Anti-Hantu) IS verified from text â€” pattern matching catches lies.
    """
    report = FloorReport(
        timestamp=datetime.now(timezone.utc).isoformat(),
        text_length=len(text),
    )

    # =========================================================================
    # F1: Amanah (Integrity) â€” Check for dangerous patterns
    # =========================================================================
    f1_pass, f1_evidence = _check_amanah_patterns(text)
    report.floors_passed["F1_Amanah"] = f1_pass
    report.floor_scores["F1_Amanah"] = 1.0 if f1_pass else 0.0
    report.floor_evidence["F1_Amanah"] = f1_evidence
    if not f1_pass:
        report.violations.append(f"F1: {f1_evidence}")

    # =========================================================================
    # F2: Truth â€” UNVERIFIABLE FROM TEXT ALONE (unless evidence provided)
    # =========================================================================
    # NOTE: Without external evidence, Truth cannot be measured from text.
    # If evidence dict is provided with 'truth_score', use it.
    # Otherwise, mark as UNVERIFIABLE and escalate to HOLD-888 if high_stakes.
    if evidence and "truth_score" in evidence:
        truth_score = evidence["truth_score"]
        f2_pass = truth_score >= TRUTH_THRESHOLD
        report.floors_passed["F2_Truth"] = f2_pass
        report.floor_scores["F2_Truth"] = truth_score
        report.floor_evidence["F2_Truth"] = f"VERIFIED (external): truth_score={truth_score:.2f}"
        if not f2_pass:
            report.violations.append(
                f"F2: Truth below threshold ({truth_score:.2f} < {TRUTH_THRESHOLD})"
            )
    else:
        # No evidence â†’ UNVERIFIABLE
        report.floors_passed["F2_Truth"] = True  # Default pass (not blockable without evidence)
        report.floor_scores["F2_Truth"] = None  # No fake number
        report.floor_evidence["F2_Truth"] = "UNVERIFIABLE_FROM_TEXT_ALONE"
        if high_stakes:
            # High-stakes + unverifiable â†’ escalate to HOLD-888
            report.floor_evidence["F2_Truth"] += " (HIGH_STAKES: should escalate to 888_HOLD)"

    # =========================================================================
    # F3: Tri-Witness â€” UNVERIFIABLE FROM TEXT ALONE (requires multi-agent vote)
    # =========================================================================
    report.floors_passed["F3_TriWitness"] = True  # Default pass
    report.floor_scores["F3_TriWitness"] = None
    report.floor_evidence["F3_TriWitness"] = (
        "UNVERIFIABLE_FROM_TEXT_ALONE (requires Tri-Witness aggregator)"
    )

    # =========================================================================
    # F4: Îºr (Empathy) â€” UNVERIFIABLE (Requires user input for distress context)
    # =========================================================================
    # NOTE: Without user input, we cannot detect distress signals.
    # Use validate_response_with_context() for F4 proxy enforcement.
    report.floors_passed["F4_KappaR"] = True  # Default pass
    report.floor_scores["F4_KappaR"] = None
    report.floor_evidence["F4_KappaR"] = (
        "UNVERIFIABLE_WITHOUT_INPUT (use validate_response_with_context)"
    )

    # =========================================================================
    # F5: PeaceÂ² (Stability) â€” Check for harmful content patterns
    # =========================================================================
    f5_pass, f5_evidence = _check_peace_patterns(text)
    report.floors_passed["F5_Peace"] = f5_pass
    report.floor_scores["F5_Peace"] = 1.0 if f5_pass else 0.0
    report.floor_evidence["F5_Peace"] = f5_evidence
    if not f5_pass:
        report.violations.append(f"F5: {f5_evidence}")

    # =========================================================================
    # F6: Clarity (Î”S) â€” UNVERIFIABLE (Requires inputâ†”output comparison)
    # =========================================================================
    # NOTE: Without input text, we cannot compute relative clarity.
    # Use validate_response_with_context() for F6 proxy enforcement.
    report.floors_passed["F6_DeltaS"] = True  # Default pass
    report.floor_scores["F6_DeltaS"] = None
    report.floor_evidence["F6_DeltaS"] = (
        "UNVERIFIABLE_WITHOUT_INPUT (use validate_response_with_context)"
    )

    # =========================================================================
    # F7: Î©â‚€ (Humility) â€” Check if in valid band
    # =========================================================================
    f7_pass = OMEGA_0_MIN <= claimed_omega <= OMEGA_0_MAX
    report.floors_passed["F7_Omega0"] = f7_pass
    report.floor_scores["F7_Omega0"] = claimed_omega
    report.floor_evidence["F7_Omega0"] = (
        f"CLAIMED: {claimed_omega} (band: [{OMEGA_0_MIN}, {OMEGA_0_MAX}])"
    )
    if not f7_pass:
        if claimed_omega < OMEGA_0_MIN:
            report.violations.append(f"F7: God-mode detected (Î©={claimed_omega} < {OMEGA_0_MIN})")
        else:
            report.violations.append(f"F7: Paralysis detected (Î©={claimed_omega} > {OMEGA_0_MAX})")

    # =========================================================================
    # F8: G (Governed Intelligence) â€” Derived from other floors
    # =========================================================================
    # G is healthy if no VOID-level breaches
    f8_pass = all(
        [
            report.floors_passed.get("F1_Amanah", True),
            report.floors_passed.get("F5_Peace", True),
            report.floors_passed.get("F9_AntiHantu", True),
        ]
    )
    report.floors_passed["F8_Governed"] = f8_pass
    report.floor_scores["F8_Governed"] = 1.0 if f8_pass else 0.0
    report.floor_evidence["F8_Governed"] = "Derived from hard floors (F1, F5, F9)"

    # =========================================================================
    # F9: Anti-Hantu â€” VERIFIED FROM TEXT (Pattern Matching)
    # =========================================================================
    f9_pass, f9_violations = check_anti_hantu(text)
    report.floors_passed["F9_AntiHantu"] = f9_pass
    report.floor_scores["F9_AntiHantu"] = 1.0 if f9_pass else 0.0
    if f9_pass:
        report.floor_evidence["F9_AntiHantu"] = "VERIFIED: No ghost claims detected"
    else:
        report.floor_evidence["F9_AntiHantu"] = f"VERIFIED: Violations found: {f9_violations}"
        report.violations.extend([f"F9: '{v}'" for v in f9_violations])

    # =========================================================================
    # Compute Final Verdict (Canonical Hierarchy: VOID > HOLD-888 > SABAR > PARTIAL > SEAL)
    # =========================================================================
    hard_floors = ["F1_Amanah", "F5_Peace", "F9_AntiHantu"]

    # VOID: Any hard floor fails
    if any(not report.floors_passed.get(f, True) for f in hard_floors):
        report.verdict = "VOID"
    # HOLD-888: High stakes + Truth unverifiable
    elif high_stakes and report.floor_evidence.get("F2_Truth", "").startswith("UNVERIFIABLE"):
        report.verdict = "HOLD-888"
    # PARTIAL: Any soft floor fails (but hard floors pass)
    elif any(not v for v in report.floors_passed.values()):
        report.verdict = "PARTIAL"
    # SEAL: All floors pass
    else:
        report.verdict = "SEAL"

    return report


def _check_amanah_patterns(text: str) -> Tuple[bool, str]:
    """Check for dangerous/destructive patterns in text."""
    text_lower = text.lower()

    dangerous_patterns = [
        ("rm -rf", "Destructive shell command"),
        ("delete all", "Mass deletion intent"),
        ("format c:", "System destruction"),
        ("drop table", "Database destruction"),
        ("sudo rm", "Privileged destruction"),
    ]

    for pattern, description in dangerous_patterns:
        if pattern in text_lower:
            return False, f"Dangerous pattern detected: '{pattern}' ({description})"

    return True, "No dangerous patterns detected"


def _check_peace_patterns(text: str) -> Tuple[bool, str]:
    """Check for harmful/violent content patterns."""
    text_lower = text.lower()

    harmful_patterns = [
        ("kill yourself", "Self-harm encouragement"),
        ("how to make a bomb", "Weapon creation"),
        ("ransomware", "Malware creation"),
        ("hack into", "Unauthorized access"),
        ("steal password", "Credential theft"),
    ]

    for pattern, description in harmful_patterns:
        if pattern in text_lower:
            return False, f"Harmful content detected: '{pattern}' ({description})"

    return True, "No harmful patterns detected"


# =============================================================================
# F6: CLARITY (Î”S) â€” CODE-ENFORCED (Relative Entropy Comparison)
# =============================================================================


def compute_clarity_score(input_text: str, output_text: str) -> Tuple[float, str]:
    """
    Compute F6 Clarity (Î”S) â€” Does the output reduce confusion?

    Physics-based proxy using zlib compression ratio (TEARFRAME-compliant).

    Formula:
        H(s) = len(zlib.compress(s.encode("utf-8"))) / max(len(s.encode("utf-8")), 1)
        Î”S_proxy = H(input) - H(output)

    Logic:
        - Positive Î”S = output is more compressible (clearer/more structured)
        - Negative Î”S = output is less compressible (more entropy/confusion)

    Returns:
        (score, evidence) where score = Î”S_proxy (â‰¤0 required for SEAL)

    Note:
        TEARFRAME compliance: This is a PHYSICS measurement (compression ratio)
        not semantic pattern matching. No forbidden semantic analysis.

    Limitation:
        Zlib compression overhead (~8-10 bytes header) skews H for short texts.
        Below SHORT_TEXT_THRESHOLD (50 chars), compression ratio unreliable.
        Returns UNVERIFIABLE to avoid false negatives (concise answers failing).
    """
    import zlib

    # Defensive floor: Zlib unreliable for very short texts (compression overhead dominates)
    SHORT_TEXT_THRESHOLD = 50  # chars; below this, zlib proxy unreliable

    if not input_text.strip() or not output_text.strip():
        return 0.0, "UNVERIFIABLE: Empty input or output"

    # Check text length (defensive floor against zlib short-text artifacts)
    if len(input_text) < SHORT_TEXT_THRESHOLD or len(output_text) < SHORT_TEXT_THRESHOLD:
        return 0.0, f"UNVERIFIABLE: Short text (<{SHORT_TEXT_THRESHOLD} chars); zlib proxy unreliable due to compression overhead"

    try:
        # Compute H(s) for input and output
        input_bytes = input_text.encode("utf-8")
        output_bytes = output_text.encode("utf-8")

        input_compressed = zlib.compress(input_bytes)
        output_compressed = zlib.compress(output_bytes)

        h_input = len(input_compressed) / max(len(input_bytes), 1)
        h_output = len(output_compressed) / max(len(output_bytes), 1)

        # Î”S proxy = H(output) - H(input)  <-- SWAPPED to align with DS <= 0
        # Reduced entropy (output) means less complexity relative to input.
        # But wait, original code was H(input) - H(output).
        # If input is 1.0 and output is 0.8, delta_s was 0.2 (PASS in original >0).
        # In NEW system, PASS is <= 0.
        # So if input is 1.0 and output is 0.8, we want result <= 0.
        # So we do H(output) - H(input) = 0.8 - 1.0 = -0.2 (PASS).
        delta_s_proxy = h_output - h_input

        evidence = f"VERIFIED (zlib proxy): H(input)={h_input:.3f}, H(output)={h_output:.3f}, delta_S={delta_s_proxy:.3f}"

        return delta_s_proxy, evidence

    except Exception as e:
        return 0.0, f"UNVERIFIABLE: Compression error: {e}"


# =============================================================================
# F4: EMPATHY (Îºáµ£) â€” CODE-ENFORCED (Distress Detection + Consolation Check)
# =============================================================================

# Distress signals in user input
DISTRESS_SIGNALS = [
    "i failed",
    "i'm sad",
    "i'm scared",
    "i'm worried",
    "i'm anxious",
    "i'm stressed",
    "i'm depressed",
    "i lost",
    "i can't",
    "help me",
    "i don't know what to do",
    "i'm stuck",
    "i'm confused",
    "frustrated",
    "disappointed",
    "upset",
    "angry",
    "hurt",
    "alone",
    "hopeless",
    "overwhelmed",
    "exhausted",
    "afraid",
    "nervous",
    "panic",
]

# Consolation patterns in AI output
CONSOLATION_PATTERNS = [
    "i understand",
    "that's understandable",
    "it's okay",
    "it's normal",
    "you're not alone",
    "many people",
    "it happens",
    "take your time",
    "no worries",
    "don't worry",
    "it'll be alright",
    "i hear you",
    "that sounds",
    "difficult",
    "challenging",
    "tough situation",
    "here to help",
    "let me help",
    "we can work",
    "step by step",
    "totally valid",
    "makes sense",
    "reasonable",
    "understandable",
]

# Cold/dismissive patterns (anti-empathy)
DISMISSIVE_PATTERNS = [
    "just do it",
    "obviously",
    "simply",
    "just figure it out",
    "not my problem",
    "deal with it",
    "get over it",
    "stop complaining",
    "that's stupid",
    "you're wrong",
    "whatever",
    "i don't care",
]


def compute_empathy_score(input_text: str, output_text: str) -> Tuple[float, str]:
    """
    Compute F4 Empathy (Îºáµ£) â€” Does the AI respond appropriately to distress?

    Logic:
        - Detect distress signals in user input
        - If distress detected, check for consolation in output
        - Penalize dismissive/cold responses

    Returns:
        (score, evidence) where score >= 0.95 = empathetic
    """
    input_lower = input_text.lower()
    output_lower = output_text.lower()

    # Step 1: Detect distress in input
    distress_detected = []
    for signal in DISTRESS_SIGNALS:
        if signal in input_lower:
            distress_detected.append(signal)

    # Step 2: Check for consolation in output
    consolation_found = []
    for pattern in CONSOLATION_PATTERNS:
        if pattern in output_lower:
            consolation_found.append(pattern)

    # Step 3: Check for dismissive patterns (penalty)
    dismissive_found = []
    for pattern in DISMISSIVE_PATTERNS:
        if pattern in output_lower:
            dismissive_found.append(pattern)

    # Compute score
    if not distress_detected:
        # No distress = neutral empathy context, default pass
        score = 1.0
        evidence = "VERIFIED: No distress detected, empathy not required"
    else:
        # Distress detected â€” check response quality
        base_score = 0.5

        # Boost for consolation
        consolation_boost = min(0.4, len(consolation_found) * 0.1)

        # Penalty for dismissive patterns
        dismissive_penalty = min(0.5, len(dismissive_found) * 0.2)

        score = base_score + consolation_boost - dismissive_penalty
        score = max(0.0, min(1.0, score))

        evidence = (
            f"VERIFIED: distress={distress_detected[:2]}, "
            f"consolation={consolation_found[:2]}, "
            f"dismissive={dismissive_found[:1] if dismissive_found else 'none'}"
        )

    return score, evidence


# =============================================================================
# ENHANCED validate_response (Now with F6 and F4 verification)
# =============================================================================


def validate_response_with_context(
    input_text: str,
    output_text: str,
    claimed_truth: float = 0.85,
    claimed_omega: float = 0.04,
    claimed_tri_witness: float = 0.90,
) -> "FloorReport":
    """
    Enhanced validation that includes F6 (Clarity) and F4 (Empathy).

    Requires both input and output text for relative comparison.

    Args:
        input_text: User's input/question
        output_text: AI's response
        claimed_*: Self-reported scores for floors we can't auto-verify

    Returns:
        FloorReport with machine-verified F6 and F4 scores
    """
    report = FloorReport(
        timestamp=datetime.now(timezone.utc).isoformat(),
        text_length=len(output_text),
    )

    # F1: Amanah (Code-Enforced)
    f1_pass, f1_evidence = _check_amanah_patterns(output_text)
    report.floors_passed["F1_Amanah"] = f1_pass
    report.floor_scores["F1_Amanah"] = 1.0 if f1_pass else 0.0
    report.floor_evidence["F1_Amanah"] = f1_evidence
    if not f1_pass:
        report.violations.append(f"F1: {f1_evidence}")

    # F2: Truth (Claimed)
    f2_pass = claimed_truth >= TRUTH_THRESHOLD
    report.floors_passed["F2_Truth"] = f2_pass
    report.floor_scores["F2_Truth"] = claimed_truth
    report.floor_evidence["F2_Truth"] = f"CLAIMED: {claimed_truth} (threshold: {TRUTH_THRESHOLD})"
    if not f2_pass:
        report.violations.append(f"F2: Truth below threshold ({claimed_truth} < {TRUTH_THRESHOLD})")

    # F3: Tri-Witness (Claimed)
    f3_pass = claimed_tri_witness >= TRI_WITNESS_THRESHOLD
    report.floors_passed["F3_TriWitness"] = f3_pass
    report.floor_scores["F3_TriWitness"] = claimed_tri_witness
    report.floor_evidence["F3_TriWitness"] = f"CLAIMED: {claimed_tri_witness}"

    # F6: Clarity â€” CODE-ENFORCED (Relative Comparison)
    f6_score, f6_evidence = compute_clarity_score(input_text, output_text)
    f6_pass = f6_score <= DELTA_S_THRESHOLD  # Pass if DS <= threshold
    report.floors_passed["F6_DeltaS"] = f6_pass
    report.floor_scores["F6_DeltaS"] = f6_score
    report.floor_evidence["F6_DeltaS"] = f6_evidence

    # F5: PeaceÂ² (Code-Enforced)
    f5_pass, f5_evidence = _check_peace_patterns(output_text)
    report.floors_passed["F5_Peace"] = f5_pass
    report.floor_scores["F5_Peace"] = 1.0 if f5_pass else 0.0
    report.floor_evidence["F5_Peace"] = f5_evidence
    if not f5_pass:
        report.violations.append(f"F5: {f5_evidence}")

    # F4: Empathy â€” CODE-ENFORCED (Distress/Consolation)
    f4_score, f4_evidence = compute_empathy_score(input_text, output_text)
    f4_pass = f4_score >= KAPPA_R_THRESHOLD
    report.floors_passed["F4_KappaR"] = f4_pass
    report.floor_scores["F4_KappaR"] = f4_score
    report.floor_evidence["F4_KappaR"] = f4_evidence
    if not f4_pass:
        report.violations.append(f"F4: Low empathy score ({f4_score:.2f} < {KAPPA_R_THRESHOLD})")

    # F7: Humility (Claimed)
    f7_pass = OMEGA_0_MIN <= claimed_omega <= OMEGA_0_MAX
    report.floors_passed["F7_Omega0"] = f7_pass
    report.floor_scores["F7_Omega0"] = claimed_omega
    report.floor_evidence["F7_Omega0"] = (
        f"CLAIMED: {claimed_omega} (band: [{OMEGA_0_MIN}, {OMEGA_0_MAX}])"
    )
    if not f7_pass:
        if claimed_omega < OMEGA_0_MIN:
            report.violations.append(f"F7: God-mode (Î©={claimed_omega})")
        else:
            report.violations.append(f"F7: Paralysis (Î©={claimed_omega})")

    # F8: Governed Intelligence (Derived)
    f8_pass = all(
        [
            report.floors_passed.get("F1_Amanah", True),
            report.floors_passed.get("F5_Peace", True),
            report.floors_passed.get("F9_AntiHantu", True),
        ]
    )
    report.floors_passed["F8_Governed"] = f8_pass
    report.floor_scores["F8_Governed"] = 1.0 if f8_pass else 0.0
    report.floor_evidence["F8_Governed"] = "Derived from hard floors"

    # F9: Anti-Hantu â€” CODE-ENFORCED (Pattern Matching)
    f9_pass, f9_violations = check_anti_hantu(output_text)
    report.floors_passed["F9_AntiHantu"] = f9_pass
    report.floor_scores["F9_AntiHantu"] = 1.0 if f9_pass else 0.0
    if f9_pass:
        report.floor_evidence["F9_AntiHantu"] = "VERIFIED: No ghost claims"
    else:
        report.floor_evidence["F9_AntiHantu"] = f"VERIFIED: {f9_violations}"
        report.violations.extend([f"F9: '{v}'" for v in f9_violations])

    # Verdict (Canonical Hierarchy: VOID > HOLD-888 > SABAR > PARTIAL > SEAL)
    hard_floors = ["F1_Amanah", "F5_Peace", "F9_AntiHantu"]
    if any(not report.floors_passed.get(f, True) for f in hard_floors):
        report.verdict = "VOID"
    elif any(not v for v in report.floors_passed.values()):
        report.verdict = "PARTIAL"
    else:
        report.verdict = "SEAL"

    return report


# =============================================================================
# CLI Interface (Windows-compatible)
# =============================================================================
if __name__ == "__main__":
    import argparse
    import json

    parser = argparse.ArgumentParser(
        description="Validate AI output against 9 Constitutional Floors",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python -m arifos.core.enforcement.response_validator --output "I am software."
  python -m arifos.core.enforcement.response_validator --output "Paris is capital." --high-stakes
  python -m arifos.core.enforcement.response_validator --output "Text..." --input "Question?" --json
        """,
    )
    parser.add_argument("--output", "-o", required=True, help="AI output text to validate")
    parser.add_argument("--input", "-i", help="Optional input text for F6 Î”S proxy calculation")
    parser.add_argument(
        "--high-stakes",
        "-H",
        action="store_true",
        help="Enable high-stakes mode (UNVERIFIABLE + high_stakes â†’ HOLD-888)",
    )
    parser.add_argument(
        "--json", "-j", action="store_true", help="Output as JSON (machine-readable)"
    )

    args = parser.parse_args()

    # Choose the right validator based on input availability
    if args.input:
        result = validate_response_with_context(
            input_text=args.input,
            output_text=args.output,
        )
    else:
        result = validate_response(
            text=args.output,
            high_stakes=args.high_stakes,
        )

    # Output
    if args.json:
        output = {
            "timestamp": result.timestamp,
            "text_length": result.text_length,
            "floors_passed": result.floors_passed,
            "floor_scores": {k: v for k, v in result.floor_scores.items()},
            "floor_evidence": result.floor_evidence,
            "violations": result.violations,
            "verdict": result.verdict,
        }
        print(json.dumps(output, indent=2, default=str))
    else:
        print(result)
