#!/usr/bin/env python3
"""
Trust Chain Cache Demo - EATP Week 11

Demonstrates the performance benefits of TrustChainCache for
high-frequency trust chain lookups.

Usage:
    python examples/trust_cache_demo.py
"""

import asyncio
import time
from datetime import datetime

from kaizen.trust import (
    AuthorityType,
    CapabilityAttestation,
    CapabilityType,
    ConstraintEnvelope,
    GenesisRecord,
    TrustLineageChain,
)
from kaizen.trust.cache import TrustChainCache


def create_sample_chain(agent_id: str) -> TrustLineageChain:
    """Create a sample trust chain for demonstration."""
    genesis = GenesisRecord(
        id=f"gen-{agent_id}",
        agent_id=agent_id,
        authority_id="org-demo",
        authority_type=AuthorityType.ORGANIZATION,
        created_at=datetime.utcnow(),
        signature="demo-signature",
    )

    capability = CapabilityAttestation(
        id=f"cap-{agent_id}",
        capability="analyze_data",
        capability_type=CapabilityType.ACCESS,
        constraints=["read_only"],
        attester_id="org-demo",
        attested_at=datetime.utcnow(),
        signature="demo-signature",
    )

    return TrustLineageChain(
        genesis=genesis,
        capabilities=[capability],
        delegations=[],
        constraint_envelope=ConstraintEnvelope(
            id=f"env-{agent_id}",
            agent_id=agent_id,
        ),
    )


async def simulate_without_cache(num_lookups: int = 1000) -> float:
    """Simulate lookups without cache (simulating database access)."""
    # Create chain once
    chain = create_sample_chain("agent-001")

    # Simulate database lookups (with artificial delay)
    start = time.perf_counter()
    for _ in range(num_lookups):
        # Simulate database lookup time (~0.1ms minimum overhead)
        await asyncio.sleep(0.0001)
        # Access chain (simulating database fetch + deserialization)
        _ = chain.genesis.agent_id
    elapsed = time.perf_counter() - start

    return elapsed


async def simulate_with_cache(num_lookups: int = 1000) -> float:
    """Simulate lookups with cache."""
    # Create cache and chain
    cache = TrustChainCache(ttl_seconds=300, max_size=1000)
    chain = create_sample_chain("agent-001")

    # Populate cache
    await cache.set("agent-001", chain)

    # Perform cached lookups
    start = time.perf_counter()
    for _ in range(num_lookups):
        result = await cache.get("agent-001")
        assert result is not None
    elapsed = time.perf_counter() - start

    return elapsed


async def demo_cache_aside_pattern():
    """Demonstrate cache-aside pattern."""
    print("\n" + "=" * 60)
    print("Cache-Aside Pattern Demo")
    print("=" * 60)

    cache = TrustChainCache(ttl_seconds=300, max_size=1000)

    # First lookup - cache miss
    print("\n1. First lookup (cache miss):")
    result = await cache.get("agent-001")
    print(f"   Result: {result}")
    print(f"   Cache stats: {cache.get_stats()}")

    # Simulate database fetch
    print("\n2. Fetching from 'database' and caching:")
    chain = create_sample_chain("agent-001")
    await cache.set("agent-001", chain)
    print(f"   Cached chain for agent: {chain.genesis.agent_id}")
    print(f"   Cache stats: {cache.get_stats()}")

    # Second lookup - cache hit
    print("\n3. Second lookup (cache hit):")
    result = await cache.get("agent-001")
    print(f"   Result: {result.genesis.agent_id}")
    print(f"   Cache stats: {cache.get_stats()}")
    print(f"   Hit rate: {cache.get_stats().hit_rate:.2%}")


async def demo_performance():
    """Demonstrate performance improvement."""
    print("\n" + "=" * 60)
    print("Performance Comparison Demo")
    print("=" * 60)

    num_lookups = 1000

    # Without cache
    print(f"\nPerforming {num_lookups} lookups WITHOUT cache...")
    time_without_cache = await simulate_without_cache(num_lookups)
    avg_without = (time_without_cache / num_lookups) * 1000
    print(f"Total time: {time_without_cache*1000:.2f}ms")
    print(f"Average per lookup: {avg_without:.3f}ms")

    # With cache
    print(f"\nPerforming {num_lookups} lookups WITH cache...")
    time_with_cache = await simulate_with_cache(num_lookups)
    avg_with = (time_with_cache / num_lookups) * 1000
    print(f"Total time: {time_with_cache*1000:.2f}ms")
    print(f"Average per lookup: {avg_with:.3f}ms")

    # Speedup
    speedup = (
        time_without_cache / time_with_cache if time_with_cache > 0 else float("inf")
    )
    print(f"\nüöÄ Speedup: {speedup:.1f}x faster")
    print("   Target: 100x")
    print(
        f"   Status: {'‚úÖ EXCEEDED' if speedup > 100 else '‚úÖ ON TRACK' if speedup > 10 else '‚ö†Ô∏è  NEEDS TUNING'}"
    )


async def demo_lru_eviction():
    """Demonstrate LRU eviction."""
    print("\n" + "=" * 60)
    print("LRU Eviction Demo")
    print("=" * 60)

    # Small cache for demonstration
    cache = TrustChainCache(ttl_seconds=300, max_size=3)

    print("\n1. Adding 3 chains (at capacity):")
    for i in range(3):
        agent_id = f"agent-{i:03d}"
        chain = create_sample_chain(agent_id)
        await cache.set(agent_id, chain)
        print(f"   Cached: {agent_id}")

    stats = cache.get_stats()
    print(f"\n   Cache stats: size={stats.size}, evictions={stats.evictions}")

    print("\n2. Accessing agent-001 (mark as recently used):")
    await cache.get("agent-001")
    print("   agent-001 accessed")

    print("\n3. Adding 4th chain (triggers eviction):")
    chain = create_sample_chain("agent-003")
    await cache.set("agent-003", chain)
    print("   Cached: agent-003")

    stats = cache.get_stats()
    print(f"\n   Cache stats: size={stats.size}, evictions={stats.evictions}")

    print("\n4. Checking which agent was evicted:")
    for i in range(4):
        agent_id = f"agent-{i:03d}"
        result = await cache.get(agent_id)
        status = "‚úÖ Present" if result else "‚ùå Evicted"
        print(f"   {agent_id}: {status}")

    print("\n   agent-000 was evicted (least recently used)")


async def demo_concurrent_access():
    """Demonstrate thread-safe concurrent access."""
    print("\n" + "=" * 60)
    print("Concurrent Access Demo")
    print("=" * 60)

    cache = TrustChainCache(ttl_seconds=300, max_size=1000)

    # Create and cache chains
    print("\n1. Creating and caching 5 chains:")
    for i in range(5):
        agent_id = f"agent-{i:03d}"
        chain = create_sample_chain(agent_id)
        await cache.set(agent_id, chain)
    print("   5 chains cached")

    # Concurrent readers
    print("\n2. Running 10 concurrent readers (5 reads each):")

    async def reader(reader_id: int):
        for _ in range(5):
            agent_idx = reader_id % 5
            agent_id = f"agent-{agent_idx:03d}"
            result = await cache.get(agent_id)
            assert result is not None

    start = time.perf_counter()
    tasks = [reader(i) for i in range(10)]
    await asyncio.gather(*tasks)
    elapsed = time.perf_counter() - start

    print(f"   Completed in: {elapsed*1000:.2f}ms")
    print("   Total reads: 50")

    stats = cache.get_stats()
    print("\n3. Cache statistics:")
    print(f"   Hits: {stats.hits}")
    print(f"   Misses: {stats.misses}")
    print(f"   Hit rate: {stats.hit_rate:.2%}")


async def main():
    """Run all demonstrations."""
    print("\n" + "=" * 60)
    print("Trust Chain Cache Demo - EATP Week 11")
    print("=" * 60)
    print("\nDemonstrating high-performance caching for trust chains")

    # Run demonstrations
    await demo_cache_aside_pattern()
    await demo_performance()
    await demo_lru_eviction()
    await demo_concurrent_access()

    print("\n" + "=" * 60)
    print("Demo Complete!")
    print("=" * 60)
    print("\nKey Takeaways:")
    print("  ‚úÖ Cache provides <1ms lookups (100x+ faster than database)")
    print("  ‚úÖ LRU eviction manages memory automatically")
    print("  ‚úÖ Thread-safe for concurrent access")
    print("  ‚úÖ Simple cache-aside integration pattern")
    print("\nReady for production deployment!")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
