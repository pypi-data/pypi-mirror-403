# Google ADK Framework Configuration
# This file defines the models supported by the ADK framework and their parameters.
# ADK uses LiteLLM as the primary model wrapper for multi-provider support.

name: "adk" # Framework name
description: "Google ADK SDK integration with LiteLLM multi-provider support" # Brief description

mcp_integration:
  # MCP integration settings
  transport: "streamable-http" # Transport protocol. Possible values: stdio, sse, streamable-http
  tool_class: "google.adk.tools.mcp_tool.mcp_toolset.MCPToolset" # Class for MCP tools
  params_class: "google.adk.tools.mcp_tool.mcp_session_manager.StreamableHTTPConnectionParams" # Class for MCP parameters
  timeout: 300 # 5 minutes - Timeout configuration for MCP tools (in seconds)

models:
  # Azure OpenAI via LiteLLM
  azure_openai:
    class: "google.adk.models.lite_llm.LiteLlm" # ADK LiteLLM wrapper
    parameters:
      model: "${AZURE_OPENAI_MODEL}" # LiteLLM model string format
      # Environment variables: AZURE_API_KEY, AZURE_API_BASE, AZURE_API_VERSION

  # Google Gemini via LiteLLM (AI Studio)
  google_gemini25_flash:
    class: "google.adk.models.lite_llm.LiteLlm"
    parameters:
      model: "gemini-2.5-flash" # Direct Gemini model string
      # Environment variables: GOOGLE_API_KEY, GOOGLE_GENAI_USE_VERTEXAI=FALSE

  # Ollama Qwen 2.5 14B via LiteLLM
  ollama_qwen25_14b:
    class: "google.adk.models.lite_llm.LiteLlm"
    parameters:
      model: "ollama_chat/qwen-25-14b" # Ollama chat provider
      # Environment variables: OLLAMA_API_BASE

  # Ollama Qwen 3 14B via LiteLLM
  ollama_qwen3_14b:
    class: "google.adk.models.lite_llm.LiteLlm"
    parameters:
      model: "ollama_chat/qwen-3-14b"
      # Environment variables: OLLAMA_API_BASE

  # Ollama Gemma 3 1B via LiteLLM
  ollama_gemma3_1b:
    class: "google.adk.models.lite_llm.LiteLlm"
    parameters:
      model: "ollama_chat/gemma-3-1b"
      # Environment variables: OLLAMA_API_BASE
