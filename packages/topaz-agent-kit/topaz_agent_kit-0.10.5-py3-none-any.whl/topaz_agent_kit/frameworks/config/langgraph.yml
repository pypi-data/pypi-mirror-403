# LangGraph Framework Configuration
# This file defines the models supported by the LangGraph framework and their parameters.
# To add a new model:
# 1. Add the model name as a key under `models`.
# 2. Specify the class and parameters for the model.
# 3. Use `${}` for environment variables where sensitive data (e.g., API keys) is required.

name: "langgraph"
description: "LangGraph framework for stateful agent workflows"

mcp_integration:
  # MCP integration settings
  transport: "streamable-http"  # Transport protocol. Possible values: stdio, sse, streamable-http
  tool_class: "langchain.tools.mcp.MCPTools"
  params_class: "langchain.tools.mcp.MCPClientParams"
  timeout: 300  # 5 minutes - Timeout configuration for MCP tools (in seconds)

models:
  azure_openai:
    class: "langchain_openai.AzureChatOpenAI"
    parameters:
      azure_endpoint: "${AZURE_OPENAI_API_BASE}"
      api_key: "${AZURE_OPENAI_API_KEY}"
      azure_deployment: "${AZURE_OPENAI_DEPLOYMENT}"
      api_version: "${AZURE_OPENAI_API_VERSION}"

  google_gemini25_flash:
    class: "langchain_google_genai.ChatGoogleGenerativeAI"
    parameters:
      model: "gemini-2.5-flash"
      google_api_key: "${GOOGLE_API_KEY}"

  ollama_qwen25_14b:
    class: "langchain_community.llms.Ollama"
    parameters:
      base_url: "${OLLAMA_BASE_URL}"
      model: "qwen-25-14b"

  ollama_qwen3_14b:
    class: "langchain_community.llms.Ollama"
    parameters:
      base_url: "${OLLAMA_BASE_URL}"
      model: "qwen-3-14b"

  ollama_gemma3_1b:
    class: "langchain_community.llms.Ollama"
    parameters:
      base_url: "${OLLAMA_BASE_URL}"
      model: "gemma-3-1b"
