# OAK Framework Configuration
# This file defines the models supported by the OAK framework and their parameters.
# To add a new model:
# 1. Add the model name as a key under `models`.
# 2. Specify the class and parameters for the model.
# 3. Use `${}` for environment variables where sensitive data (e.g., API keys) is required.

name: "oak"
description: "OpenAI Agents Kit (OAK) SDK integration with multi-provider model support"

mcp_integration:
  # MCP integration settings
  transport: "streamable-http" # Transport protocol. Possible values: stdio, sse, streamable-http
  tool_class: "agents.mcp.MCPServerStreamableHttp" # FastMCP client for MCP integration
  params_class: "agents.mcp.MCPServerStreamableHttpParams" # SK context variables for MCP parameters
  timeout: 300 # 5 minutes - Timeout configuration for MCP tools (in seconds)

models:
  azure_openai:
    class: "openai.AsyncAzureOpenAI" # Model class
    parameters:
      api_key: "${AZURE_OPENAI_API_KEY}" # API key loaded from environment variable
      azure_endpoint: "${AZURE_OPENAI_API_BASE}" # base url for Azure OpenAI
      azure_deployment: "${AZURE_OPENAI_DEPLOYMENT}" # deployment name for Azure OpenAI
      api_version: "${AZURE_OPENAI_API_VERSION}" # api version for Azure OpenAI

  # TODO: Add support for other models in the future
  # google_gemini25_flash:
  #   class: "semantic_kernel.connectors.ai.google.GoogleAIChatCompletion" # Model class
  #   parameters:
  #     model: "gemini-2.5-flash" # Model name for Google Gemini
  #     api_key: "${GOOGLE_API_KEY}" # API key loaded from environment variable

  # ollama_qwen25_14b:
  #   class: "semantic_kernel.connectors.ai.ollama.OllamaChatCompletion" # Model class
  #   parameters:
  #     model: "qwen-25-14b" # Model name for Ollama
  #     base_url: "${OLLAMA_BASE_URL}" # Base URL for Ollama

  # ollama_qwen3_14b:
  #   class: "semantic_kernel.connectors.ai.ollama.OllamaChatCompletion" # Model class
  #   parameters:
  #     model: "qwen-3-14b" # Model name for Ollama
  #     base_url: "${OLLAMA_BASE_URL}" # Base URL for Ollama

  # ollama_gemma3_1b:
  #   class: "semantic_kernel.connectors.ai.ollama.OllamaChatCompletion" # Model class
  #   parameters:
  #     model: "gemma-3-1b" # Model name for Ollama
  #     base_url: "${OLLAMA_BASE_URL}" # Base URL for Ollama
