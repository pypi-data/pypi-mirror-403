# Agno Framework Configuration
# This file defines the models supported by the Agno framework and their parameters.
# To add a new model:
# 1. Add the model name as a key under `models`.
# 2. Specify the class and parameters for the model.
# 3. Use `${}` for environment variables where sensitive data (e.g., API keys) is required.

name: "agno"  # Framework name
description: "Agno SDK integration"  # Brief description of the framework

mcp_integration:
  # MCP integration settings
  transport: "streamable-http"  # Transport protocol. Possible values: stdio, sse, streamable-http
  tool_class: "agno.tools.mcp.MCPTools"  # Class for MCP tools
  params_class: "agno.tools.mcp.StreamableHTTPClientParams"  # Class for MCP parameters
  timeout: 300  # 5 minutes - Timeout configuration for MCP tools (in seconds)

models:
  azure_openai:
    class: "agno.models.azure.openai_chat.AzureOpenAI"  # Model class
    parameters:
      azure_endpoint: "${AZURE_OPENAI_API_BASE}"  # Endpoint for Azure OpenAI
      api_key: "${AZURE_OPENAI_API_KEY}"  # API key loaded from environment variable
      azure_deployment: "${AZURE_OPENAI_DEPLOYMENT}"  # Deployment name for Azure OpenAI
      api_version: "${AZURE_OPENAI_API_VERSION}"  # API version for Azure OpenAI

  google_gemini25_flash:
    class: "agno.models.google.Gemini"  # Model class
    parameters:
      id: "gemini-2.5-flash"  # Model ID for Google Gemini
      api_key: "${GOOGLE_API_KEY}"  # API key loaded from environment variable

  ollama_qwen25_14b:
    class: "agno.models.ollama.Ollama"  # Model class
    parameters:
      base_url: "${OLLAMA_BASE_URL}"  # Base URL for Ollama
      model: "qwen-25-14b"  # Model name for Ollama

  ollama_qwen3_14b:
    class: "agno.models.ollama.Ollama"
    parameters:
      base_url: "${OLLAMA_BASE_URL}"
      model: "qwen-3-14b"

  ollama_gemma3_1b:
    class: "agno.models.ollama.Ollama"
    parameters:
      base_url: "${OLLAMA_BASE_URL}"
      model: "gemma-3-1b"
