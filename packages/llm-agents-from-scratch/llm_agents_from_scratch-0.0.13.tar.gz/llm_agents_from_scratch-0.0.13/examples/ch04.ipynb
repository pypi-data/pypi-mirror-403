{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60405002-e4c4-4ee2-8aae-53e704cdba1c",
   "metadata": {},
   "source": [
    "# Examples from Chapter 4 â€” The LLMAgent class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb4d8c3-8137-4fd3-bf37-c5359018538e",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "\n",
    "To ensure you have the required dependencies to run this notebook, you'll need to have our `llm-agents-from-scratch` framework installed on the running Jupyter kernel. To do this, you can launch this notebook with the following command while within the project's root directory:\n",
    "\n",
    "```sh\n",
    "uv run --with jupyter jupyter lab\n",
    "```\n",
    "\n",
    "Alternatively, if you just want to use the published version of `llm-agents-from-scratch` without local development, you can install it from PyPi by uncommenting the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd15ba8-e106-486e-afb5-8deef2dee2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to install `llm-agents-from-scratch` from PyPi\n",
    "# !pip install llm-agents-from-scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43a249-cbd0-4e70-b8d0-3fd14b4b32ac",
   "metadata": {},
   "source": [
    "## Running an Ollama service\n",
    "\n",
    "To execute the code provided in this notebook, youâ€™ll need to have Ollama installed on your local machine and have its LLM hosting service running. To download Ollama, follow the instructions found on this page: https://ollama.com/download. After downloading and installing Ollama, you can start a service by opening a terminal and running the command `ollama serve`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8ec9a-28e2-4e5e-942f-091e789ed14b",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6281fc2-5412-446c-8c80-3226eaeabe5a",
   "metadata": {},
   "source": [
    "### Example 1: Instantiating an `LLMAgent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0ab1b8-aec1-49df-a63e-60ab2317be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_agents_from_scratch.llms import OllamaLLM\n",
    "from llm_agents_from_scratch import LLMAgent\n",
    "\n",
    "llm = OllamaLLM(model=\"qwen2.5:3b\")\n",
    "llm_agent = LLMAgent(\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f51d14f-ddcf-46e2-b277-f14053a03349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_agent.tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81f366e-b2d0-402b-9fb7-984fbd91b01f",
   "metadata": {},
   "source": [
    "### Example 2: Demo usage of `add_tool()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba842320-9881-4150-b392-73fe9f9dab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_agents_from_scratch.tools import SimpleFunctionTool\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    \"\"\"A dummy tool for adding one to the supplied number.\"\"\"\n",
    "    return x + 1\n",
    "    \n",
    "tool = SimpleFunctionTool(func=add_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d573ca-adf3-4c2f-b932-344bc2466873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<llm_agents_from_scratch.tools.simple_function.SimpleFunctionTool at 0x71089431c590>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_agent.add_tool(tool)\n",
    "llm_agent.tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390890ef-f930-4158-982e-98f357cdbc46",
   "metadata": {},
   "source": [
    "### Example 3: The Hailstone LLM Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b822c6-9ec3-4c23-8ef6-1c07171accb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGING_ENABLED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b7c322-fb54-4d4a-b1c8-4c7b574440e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from llm_agents_from_scratch.logger import enable_console_logging\n",
    "\n",
    "if LOGGING_ENABLED:\n",
    "    enable_console_logging(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a91d17-0996-47ea-b46e-64c43c782824",
   "metadata": {},
   "source": [
    "#### Define the Hailstone tool\n",
    "\n",
    "This is an adapted version of the Hailstone tool from Chapter 2. Since LLMs have been pretrained on a corpus that includes information on the Hailstone sequence, they may rely on their parametric knowledge to perform the task rather than using the provided tool.\n",
    "\n",
    "One way to force tool-calling is to obfuscate the function details and omit any mention of the Hailstone sequence. This ensures our demonstration shows the LLM agent actually using tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fed674f4-6a68-4741-ada7-0b6a6f34fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from llm_agents_from_scratch.tools import PydanticFunctionTool\n",
    "\n",
    "\n",
    "class AlgoParams(BaseModel):\n",
    "    \"\"\"Params for next_number.\"\"\"\n",
    "\n",
    "    x: int\n",
    "\n",
    "\n",
    "def next_number(params: AlgoParams) -> int:\n",
    "    \"\"\"Generate the next number of the sequence.\"\"\"\n",
    "    if params.x % 2 == 0:\n",
    "        return params.x // 2\n",
    "    return 3 * params.x + 1\n",
    "\n",
    "\n",
    "# convert our Python function to a BaseTool\n",
    "tool = PydanticFunctionTool(next_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3d880c-9b35-492e-9390-f97e4fb1c3ab",
   "metadata": {},
   "source": [
    "#### Define our backbone LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00463e83-28fd-4ad9-b375-0e0e5ed9ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_agents_from_scratch.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"qwen2.5:3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eda9ff-7d96-4628-9c8a-63d36834468f",
   "metadata": {},
   "source": [
    "#### Define the LLMAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fdc618-e9b0-4726-a25d-85ad858b2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_agents_from_scratch import LLMAgent\n",
    "\n",
    "llm_agent = LLMAgent(\n",
    "    llm=llm,\n",
    "    tools=[tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf38027-8fda-4c62-abf4-8e1d5fa31c69",
   "metadata": {},
   "source": [
    "#### The Hailstone Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c502a9a8-545b-4094-a52a-06d5101ef9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_agents_from_scratch.data_structures import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3838db7f-fcd6-432f-8e4c-0eb8ac3706d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_template = \"\"\"\n",
    "You are given a tool, `next_number`, that generates the next number in the\n",
    "sequence given the current number.\n",
    "\n",
    "Start with the number x={x}.\n",
    "\n",
    "<rules>\n",
    "CALL `next_number` on the current number x\n",
    "STOP AND WAIT for the result.\n",
    "REPEAT this step-by-step process until the number 1 is reached.\n",
    "FINAL RESULT: When you receive the number 1, provide the complete sequence you\n",
    "observed from start to finish (including the starting number x and ending number\n",
    "1).\n",
    "</rules>\n",
    "\n",
    "<warnings>\n",
    "NEVER fabricate or simulate tool call results\n",
    "NEVER make multiple tool calls in one response\n",
    "STOP and WAIT - ALWAYS wait for the actual tool response before deciding next\n",
    "steps\n",
    "</warnings>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22822fa-e7c6-472b-93d2-3e624a8a07ee",
   "metadata": {},
   "source": [
    "#### Running the Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13d883a9-23d3-40ac-9130-39e8eee47d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 4\n",
    "sequence = [4, 2, 1]  # correct Hailstone sequence\n",
    "task = Task(\n",
    "    instruction=instruction_template.format(x=number),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dda06d3-3df2-477c-981c-5d3b45efb9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO (llm_agents_fs.LLMAgent) :      ðŸš€ Starting task: You are given a tool, `next_number`, that generates the next number in the\n",
      "sequence given the current number.\n",
      "\n",
      "Start with the number ...[TRUNCATED]\n",
      "INFO (llm_agents_fs.TaskHandler) :      âš™ï¸ Processing Step: You are given a tool, `next_number`, that generates the next number in the\n",
      "sequence given the current number.\n",
      "\n",
      "Start with the numb...[TRUNCATED]\n",
      "INFO (llm_agents_fs.TaskHandler) :      ðŸ› ï¸ Executing Tool Call: next_number\n",
      "INFO (llm_agents_fs.TaskHandler) :      âœ… Successful Tool Call: 2\n",
      "INFO (llm_agents_fs.TaskHandler) :      âœ… Step Result: The `next_number` function returned the number 2 when called with x=4. \n",
      "\n",
      "Now I will call the `next_number` function again, but this tim...[TRUNCATED]\n",
      "INFO (llm_agents_fs.TaskHandler) :      ðŸ§  New Step: CALL `next_number` on the current number x=2\n",
      "INFO (llm_agents_fs.TaskHandler) :      âš™ï¸ Processing Step: CALL `next_number` on the current number x=2\n",
      "INFO (llm_agents_fs.TaskHandler) :      ðŸ› ï¸ Executing Tool Call: next_number\n",
      "INFO (llm_agents_fs.TaskHandler) :      âœ… Successful Tool Call: 1\n",
      "INFO (llm_agents_fs.TaskHandler) :      âœ… Step Result: The `next_number` function returned the number 1 when called with x=2. \n",
      "\n",
      "Now, I will provide the complete sequence observed from start ...[TRUNCATED]\n",
      "INFO (llm_agents_fs.TaskHandler) :      No new step required.\n",
      "INFO (llm_agents_fs.LLMAgent) :      ðŸ Task completed: The complete sequence observed from start to finish (including the starting number x and ending number 1) is as follows:\n",
      "\n",
      "4 -> 2 -> ...[TRUNCATED]\n"
     ]
    }
   ],
   "source": [
    "handler = llm_agent.run(task, max_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74d94ff4-9baf-43d0-9ad9-fce47fefb539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85b469dd-240a-473a-9c11-626e95c4008a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of sub-steps taken\n",
    "handler.step_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0360c1-17a8-4a3b-8f12-1a7803d78d2a",
   "metadata": {},
   "source": [
    "#### The TaskResult\n",
    "\n",
    "Upon successful task execution, the final `TaskResult` object is set as the result for the `TaskHandler` (an `asyncio.Future`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "234d25b0-316e-41a9-83d4-cabaa6f3ac8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The complete sequence observed from start to finish (including the starting number x and ending number 1) is as follows:\n",
      "\n",
      "4 -> 2 -> 1\n"
     ]
    }
   ],
   "source": [
    "result = handler.result() if not handler.exception() else str(handler.exception())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64fedc3d-a140-48fc-a42c-96492af1df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative execution style (if you don't want/need the handler)\n",
    "# result = await llm_agent.run(task, max_steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedb24db-ef3e-4d47-960f-45d3627e3b70",
   "metadata": {},
   "source": [
    "#### The Rollout\n",
    "\n",
    "The `rollout` attribute of the `TaskHandler` sheds light on the steps that the `LLMAgent` took to perform its task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0558b406-6b68-4121-a5be-2305913278c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task Step Start ===\n",
      "\n",
      "ðŸ’¬ assistant: My current instruction is 'You are given a tool, `next_number`, that generates the next number in the\n",
      "sequence given the current number.\n",
      "\n",
      "Start with the number x=4.\n",
      "\n",
      "<rules>\n",
      "CALL `next_number` on the current number x\n",
      "STOP AND WAIT for the result.\n",
      "REPEAT this step-by-step process until the number 1 is reached.\n",
      "FINAL RESULT: When you receive the number 1, provide the complete sequence you\n",
      "observed from start to finish (including the starting number x and ending number\n",
      "1).\n",
      "</rules>\n",
      "\n",
      "<warnings>\n",
      "NEVER fabricate or simulate tool call results\n",
      "NEVER make multiple tool calls in one response\n",
      "STOP and WAIT - ALWAYS wait for the actual tool response before deciding next\n",
      "steps\n",
      "</warnings>'\n",
      "\n",
      "ðŸ’¬ assistant: I need to make the following tool call(s):\n",
      "\n",
      "{\n",
      "    \"id_\": \"211bc0e5-b633-4582-a1fd-1d61d4701f4e\",\n",
      "    \"tool_name\": \"next_number\",\n",
      "    \"arguments\": {\n",
      "        \"x\": 4\n",
      "    }\n",
      "}.\n",
      "\n",
      "ðŸ”§ tool: {\n",
      "    \"tool_call_id\": \"211bc0e5-b633-4582-a1fd-1d61d4701f4e\",\n",
      "    \"content\": \"2\",\n",
      "    \"error\": false\n",
      "}\n",
      "\n",
      "ðŸ’¬ assistant: The `next_number` function returned the number 2 when called with x=4. \n",
      "\n",
      "Now I will call the `next_number` function again, but this time with the new current number being 2.\n",
      "\n",
      "I'll proceed to make my next tool call.\n",
      "\n",
      "\n",
      "=== Task Step End ===\n",
      "\n",
      "=== Task Step Start ===\n",
      "\n",
      "ðŸ’¬ assistant: My current instruction is 'CALL `next_number` on the current number x=2'\n",
      "\n",
      "ðŸ’¬ assistant: I need to make the following tool call(s):\n",
      "\n",
      "{\n",
      "    \"id_\": \"7d529c53-2da2-49c7-a538-abfa8217cd62\",\n",
      "    \"tool_name\": \"next_number\",\n",
      "    \"arguments\": {\n",
      "        \"x\": 2\n",
      "    }\n",
      "}.\n",
      "\n",
      "ðŸ”§ tool: {\n",
      "    \"tool_call_id\": \"7d529c53-2da2-49c7-a538-abfa8217cd62\",\n",
      "    \"content\": \"1\",\n",
      "    \"error\": false\n",
      "}\n",
      "\n",
      "ðŸ’¬ assistant: The `next_number` function returned the number 1 when called with x=2. \n",
      "\n",
      "Now, I will provide the complete sequence observed from start to finish: Starting at x = 4 and ending with x = 1.\n",
      "\n",
      "Here is the sequence:\n",
      "```\n",
      "4 -> 2 -> 1\n",
      "```\n",
      "\n",
      "Since we received the final number 1 as requested by the instruction, no further calls are needed. The task can now be considered complete.\n",
      "\n",
      "=== Task Step End ===\n"
     ]
    }
   ],
   "source": [
    "print(handler.rollout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
