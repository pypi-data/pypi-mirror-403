"""
Robust Pagination System for AWS APIs.

Replaces boto3's all-or-nothing paginator with a resilient system that:
- Isolates page-level failures (single page failure doesn't kill the scan)
- Provides infinite retry per page with exponential backoff
- Streams items as they arrive (doesn't accumulate in memory)
- Reports partial success (95% succeeded, 5% failed)
- Integrates with AWSRateLimiter for throttling protection

Usage:
    from replimap.core.pagination import RobustPaginator

    paginator = RobustPaginator(ec2_client, 'describe_instances', rate_limiter)
    stream = paginator.paginate()

    for instance in stream:
        process(instance)

    if not stream.stats.is_complete:
        logger.warning(f"Partial: {stream.stats.success_rate:.0%}")
"""

from __future__ import annotations

import logging
import random
import time
from collections.abc import Generator, Iterator
from dataclasses import dataclass, field
from typing import TYPE_CHECKING, Any, Generic, TypeVar

from botocore.exceptions import ClientError

from replimap.core.pagination_config import get_pagination_config

if TYPE_CHECKING:
    from replimap.core.rate_limiter import AWSRateLimiter
    from replimap.core.security.session_manager import SessionManager

logger = logging.getLogger(__name__)

T = TypeVar("T")


# Error codes that warrant retry
RETRYABLE_ERROR_CODES = {
    "Throttling",
    "ThrottlingException",
    "RequestLimitExceeded",
    "TooManyRequestsException",
    "ServiceUnavailable",
    "ServiceUnavailableException",
    "InternalError",
    "InternalErrorException",
    "InternalServiceError",
    "RequestTimeout",
    "RequestTimeoutException",
    "ProvisionedThroughputExceededException",
    "SlowDown",
    "EC2ThrottledException",
    "RequestThrottled",
    "RequestThrottledException",
    "BandwidthLimitExceeded",
}

# Error codes that should NOT be retried
FATAL_ERROR_CODES = {
    "AccessDenied",
    "AccessDeniedException",
    "UnauthorizedAccess",
    "SignatureDoesNotMatch",
    "InvalidParameterValue",
    "ValidationException",
    "ValidationError",
    "InvalidParameter",
    "MissingParameter",
    "MalformedPolicyDocument",
    "ResourceNotFoundException",
    "NoSuchEntity",
    "InvalidAction",
    "UnrecognizedClientException",
}

# Credential expiration errors - handled specially with SessionManager
# These are NOT fatal if SessionManager can refresh credentials
CREDENTIAL_ERROR_CODES = {
    "ExpiredToken",
    "ExpiredTokenException",
    "InvalidClientTokenId",
    "RequestExpired",
}


@dataclass
class PaginationStats:
    """
    Statistics for a pagination operation.

    Tracks success/failure rates, items yielded, and errors encountered.
    Accessible during and after iteration.
    """

    total_pages: int = 0
    successful_pages: int = 0
    failed_pages: int = 0
    items_yielded: int = 0
    errors: list[str] = field(default_factory=list)
    is_complete: bool = True

    @property
    def success_rate(self) -> float:
        """Percentage of pages successfully retrieved (0.0 to 1.0)."""
        if self.total_pages == 0:
            return 1.0
        return self.successful_pages / self.total_pages

    @property
    def has_errors(self) -> bool:
        """True if any pages failed."""
        return self.failed_pages > 0 or len(self.errors) > 0


class PaginationStream(Generic[T]):
    """
    Wrapper that allows both iteration and stats access.

    Provides an iterator interface for consuming paginated results while
    maintaining access to statistics that are updated in real-time.

    Usage:
        stream = paginator.paginate()

        for item in stream:
            # Access stats mid-iteration
            if stream.stats.items_yielded > 1000:
                stream.abort()
                break
            process(item)

        # Check final stats
        print(f"Success rate: {stream.stats.success_rate:.0%}")
    """

    def __init__(
        self,
        generator: Generator[T, None, None],
        stats: PaginationStats,
    ) -> None:
        self._generator = generator
        self._stats = stats
        self._exhausted = False
        self._aborted = False

    def __iter__(self) -> Iterator[T]:
        return self

    def __next__(self) -> T:
        if self._aborted:
            raise StopIteration

        try:
            return next(self._generator)
        except StopIteration:
            self._exhausted = True
            raise

    @property
    def stats(self) -> PaginationStats:
        """Get current pagination statistics (updated in real-time)."""
        return self._stats

    @property
    def is_exhausted(self) -> bool:
        """True if all pages have been consumed (successfully or not)."""
        return self._exhausted

    def abort(self) -> None:
        """
        Early termination of pagination.

        Marks is_complete=False and stops iteration.
        Already yielded items are preserved.
        """
        self._aborted = True
        self._stats.is_complete = False


class RobustPaginator:
    """
    Production-grade AWS API paginator with per-page error isolation.

    Key Features:
    - Page-level isolation: Single page failure doesn't affect other pages
    - Configurable retry: Each page can be independently retried
    - Streaming output: Yields items as they arrive
    - Partial success: Reports exact success/failure percentages
    - Rate limiter integration: Built-in throttling protection
    - Compound token support: Handles Route53-style multi-field tokens

    The paginator NEVER raises exceptions during iteration. Errors are
    logged and recorded in stats.errors, allowing callers to:
    1. Process all successfully retrieved items
    2. Report partial success to users
    3. Retry failed operations separately if needed

    Usage:
        paginator = RobustPaginator(
            client=ec2_client,
            method_name='describe_instances',
            rate_limiter=limiter,
        )
        stream = paginator.paginate()

        for instance in stream:
            graph.add_resource(instance)

        if stream.stats.has_errors:
            for error in stream.stats.errors:
                logger.warning(error)
    """

    def __init__(
        self,
        client: Any,
        method_name: str,
        rate_limiter: AWSRateLimiter | None = None,
        session_manager: SessionManager | None = None,
        max_retries: int = 3,
        base_backoff: float = 1.0,
        max_auth_retries: int = 1,
    ) -> None:
        """
        Initialize the paginator.

        Args:
            client: Boto3 service client
            method_name: AWS API method name (e.g., 'describe_instances')
            rate_limiter: Optional AWSRateLimiter for throttling protection
            session_manager: Optional SessionManager for credential refresh
            max_retries: Maximum retry attempts per page (default: 3)
            base_backoff: Base delay for exponential backoff (default: 1.0s)
            max_auth_retries: Maximum credential refresh attempts (default: 1)
                             Prevents infinite MFA loops if refresh keeps failing
        """
        self._client = client
        self._method_name = method_name
        self._rate_limiter = rate_limiter
        self._session_manager = session_manager
        self._max_retries = max_retries
        self._base_backoff = base_backoff
        self._max_auth_retries = max_auth_retries

        # Track auth retries separately from normal retries
        self._auth_retry_count = 0

        # Extract service name from client
        self._service_name = self._get_service_name()

        # Get pagination config
        self._config = get_pagination_config(self._service_name, method_name)
        if self._config is None:
            raise ValueError(
                f"No pagination config for {self._service_name}.{method_name}. "
                f"Add it to pagination_config.py"
            )

    def _get_service_name(self) -> str:
        """Extract service name from boto3 client."""
        try:
            return self._client.meta.service_model.service_name
        except AttributeError:
            # Fallback for mocked clients
            return getattr(self._client, "_service_name", "unknown")

    def _get_region(self) -> str | None:
        """Extract region from boto3 client."""
        try:
            return self._client.meta.region_name
        except AttributeError:
            return None

    def paginate(self, **kwargs: Any) -> PaginationStream[Any]:
        """
        Begin paginated iteration.

        Args:
            **kwargs: Arguments to pass to the AWS API method

        Returns:
            PaginationStream that yields individual items and provides stats
        """
        stats = PaginationStats()
        generator = self._paginate_generator(stats, kwargs)
        return PaginationStream(generator, stats)

    def _paginate_generator(
        self,
        stats: PaginationStats,
        kwargs: dict[str, Any],
    ) -> Generator[Any, None, None]:
        """
        Internal generator that performs the actual pagination.

        Uses manual token management for full control over error handling.
        """
        config = self._config
        api_method = getattr(self._client, self._method_name)

        # Token state for pagination
        next_token: str | None = None
        compound_tokens: dict[str, str] = {}  # For Route53-style compound tokens
        page_num = 0

        while True:
            page_num += 1

            # Build request parameters
            params = self._build_params(
                kwargs, next_token, compound_tokens, page_num == 1
            )

            # Fetch page with retry logic
            response = self._fetch_with_retry(api_method, params, page_num, stats)

            if response is None:
                # Unrecoverable error - stop pagination but preserve yielded data
                break

            stats.total_pages += 1
            stats.successful_pages += 1

            # Extract items from response
            items = self._extract_items(response)
            logger.debug(
                f"[{self._service_name}.{self._method_name}] "
                f"Page {page_num}: {len(items)} items"
            )

            # Yield items
            for item in items:
                stats.items_yielded += 1
                yield item

            # Check for next page
            if config.is_compound_token:
                # Handle compound tokens (Route53)
                has_more = self._update_compound_tokens(response, compound_tokens)
                if not has_more:
                    break
            else:
                # Standard single-token pagination
                next_token = response.get(config.output_token)
                if not next_token:
                    break

    def _build_params(
        self,
        base_kwargs: dict[str, Any],
        next_token: str | None,
        compound_tokens: dict[str, str],
        is_first_page: bool,
    ) -> dict[str, Any]:
        """Build request parameters including pagination token."""
        config = self._config
        params = base_kwargs.copy()

        # Add page size limit if not specified
        if config.limit_key not in params:
            params[config.limit_key] = config.default_page_size

        # Add pagination token(s)
        if not is_first_page:
            if config.is_compound_token:
                # Add all compound tokens
                params.update(compound_tokens)
            elif next_token:
                params[config.input_token] = next_token

        return params

    def _fetch_with_retry(
        self,
        api_method: Any,
        params: dict[str, Any],
        page_num: int,
        stats: PaginationStats,
    ) -> dict[str, Any] | None:
        """
        Fetch a single page with retry logic.

        Returns None on unrecoverable failure (page is skipped).
        Never raises exceptions.

        Handles three categories of errors:
        1. Credential errors: Trigger SessionManager.force_refresh() if available
        2. Fatal errors: Immediate failure, no retry
        3. Transient errors: Retry with exponential backoff
        """
        region = self._get_region()
        last_error: Exception | None = None

        for attempt in range(self._max_retries + 1):
            # Rate limiting
            if self._rate_limiter is not None:
                if not self._rate_limiter.acquire(self._service_name, region):
                    error_msg = (
                        f"Page {page_num}: Rate limiter timeout for "
                        f"{self._service_name}/{region}"
                    )
                    logger.error(error_msg)
                    stats.errors.append(error_msg)
                    stats.failed_pages += 1
                    stats.total_pages += 1
                    stats.is_complete = False
                    return None

            try:
                response = api_method(**params)

                # Report success to rate limiter
                if self._rate_limiter is not None:
                    self._rate_limiter.report_success(self._service_name, region)

                # Reset auth retry count on success
                self._auth_retry_count = 0

                return response

            except ClientError as e:
                last_error = e
                error_code = e.response.get("Error", {}).get("Code", "Unknown")
                error_message = e.response.get("Error", {}).get("Message", str(e))

                # ═══════════════════════════════════════════════════════════════
                # CREDENTIAL EXPIRATION: Handle separately from normal retries
                # ═══════════════════════════════════════════════════════════════
                if error_code in CREDENTIAL_ERROR_CODES:
                    logger.warning(
                        f"Page {page_num}: Credential expired ({error_code})"
                    )

                    # Check auth retry limit (prevents infinite MFA loops)
                    if self._auth_retry_count >= self._max_auth_retries:
                        logger.error(
                            f"Max auth retries ({self._max_auth_retries}) exceeded. "
                            "Cannot refresh credentials."
                        )
                        stats.failed_pages += 1
                        stats.total_pages += 1
                        stats.is_complete = False
                        stats.errors.append(
                            f"Page {page_num}: Auth expired, refresh limit exceeded"
                        )
                        return None

                    self._auth_retry_count += 1

                    # Attempt refresh via SessionManager
                    if self._session_manager is not None:
                        logger.info(
                            "Attempting credential refresh via SessionManager..."
                        )

                        if self._session_manager.force_refresh():
                            # Refresh successful - update client and retry
                            # Get fresh client from SessionManager
                            self._client = self._session_manager.get_client(
                                self._service_name, region
                            )
                            # Update api_method reference to use new client
                            api_method = getattr(self._client, self._method_name)

                            logger.info(
                                "Credential refresh successful. Retrying request..."
                            )
                            # Continue to retry without consuming attempt count
                            continue
                        else:
                            # Refresh failed (user cancelled MFA, etc.)
                            logger.error("Credential refresh failed.")
                            stats.failed_pages += 1
                            stats.total_pages += 1
                            stats.is_complete = False
                            stats.errors.append(
                                f"Page {page_num}: Session refresh failed"
                            )
                            return None
                    else:
                        # No SessionManager available - treat as fatal
                        logger.error(
                            "No SessionManager available for credential refresh."
                        )
                        stats.failed_pages += 1
                        stats.total_pages += 1
                        stats.is_complete = False
                        stats.errors.append(
                            f"Page {page_num}: {error_code} (no session manager)"
                        )
                        return None

                # ═══════════════════════════════════════════════════════════════
                # FATAL ERRORS: Do not retry
                # ═══════════════════════════════════════════════════════════════
                if error_code in FATAL_ERROR_CODES:
                    error_msg = (
                        f"Page {page_num}: {error_code} - {error_message} "
                        f"(fatal, not retrying)"
                    )
                    logger.error(error_msg)
                    stats.errors.append(error_msg)
                    stats.failed_pages += 1
                    stats.total_pages += 1
                    stats.is_complete = False
                    return None

                # ═══════════════════════════════════════════════════════════════
                # TRANSIENT/THROTTLING ERRORS: Retry with backoff
                # ═══════════════════════════════════════════════════════════════
                is_throttle = error_code in RETRYABLE_ERROR_CODES

                # Report throttle to rate limiter
                if is_throttle and self._rate_limiter is not None:
                    self._rate_limiter.report_throttle(self._service_name, region)

                if attempt < self._max_retries:
                    # Calculate backoff with jitter
                    backoff = self._base_backoff * (2**attempt)
                    jitter = random.uniform(0, 1)  # noqa: S311 - not for crypto
                    wait_time = backoff + jitter

                    # Double backoff for throttling
                    if is_throttle:
                        wait_time *= 2

                    logger.warning(
                        f"[{self._service_name}.{self._method_name}] "
                        f"Page {page_num}: {error_code} (attempt {attempt + 1}/{self._max_retries + 1}), "
                        f"retrying in {wait_time:.1f}s"
                    )
                    time.sleep(wait_time)
                    continue

                # Max retries exceeded
                error_msg = (
                    f"Page {page_num}: {error_code} - {error_message} "
                    f"(max retries exceeded)"
                )
                logger.error(error_msg)
                stats.errors.append(error_msg)
                stats.failed_pages += 1
                stats.total_pages += 1
                stats.is_complete = False
                return None

            except Exception as e:
                # Unexpected error
                error_msg = (
                    f"Page {page_num}: Unexpected error - {type(e).__name__}: {e}"
                )
                logger.error(error_msg)
                stats.errors.append(error_msg)
                stats.failed_pages += 1
                stats.total_pages += 1
                stats.is_complete = False
                return None

        # Should not reach here
        if last_error:
            error_msg = (
                f"Page {page_num}: Failed after {self._max_retries + 1} attempts"
            )
            logger.error(error_msg)
            stats.errors.append(error_msg)
            stats.failed_pages += 1
            stats.total_pages += 1
            stats.is_complete = False

        return None

    def _extract_items(self, response: dict[str, Any]) -> list[Any]:
        """
        Extract items from response, handling nested structures.

        For nested APIs like describe_instances, extracts the inner items
        (Instances from Reservations).
        """
        config = self._config
        raw_items = response.get(config.result_key, [])

        if not raw_items:
            return []

        if config.is_nested and config.nested_key:
            # Flatten nested structure (e.g., Reservations -> Instances)
            items = []
            for container in raw_items:
                nested_items = container.get(config.nested_key, [])
                items.extend(nested_items)
            return items

        return raw_items

    def _update_compound_tokens(
        self,
        response: dict[str, Any],
        compound_tokens: dict[str, str],
    ) -> bool:
        """
        Update compound token state for Route53-style pagination.

        Returns True if there are more pages, False if done.
        """
        config = self._config
        has_next = False

        # Map output keys to input keys
        for output_key, input_key in zip(
            config.compound_output_keys,
            config.compound_input_keys,
            strict=True,
        ):
            value = response.get(output_key)
            if value:
                compound_tokens[input_key] = value
                has_next = True
            elif input_key in compound_tokens:
                del compound_tokens[input_key]

        # Check IsTruncated flag (Route53 specific)
        if "IsTruncated" in response:
            return response["IsTruncated"]

        return has_next
