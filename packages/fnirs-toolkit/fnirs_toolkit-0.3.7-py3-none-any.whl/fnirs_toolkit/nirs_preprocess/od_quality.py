# ä½œè€…ï¼š@Boluo, @Jamie
# æ—¥æœŸï¼š2025-06-20
# æè¿°ï¼šè®¡ç®— fNIRS å…‰å¯†åº¦ä¿¡å·ä¸­å„ä¸ªé€šé“çš„ç›¸å…³é€šé“è´¨é‡ç³»æ•°
# åŒ…æ‹¬ï¼š
# 1. å˜å¼‚ç³»æ•°ï¼ˆCVï¼‰
# 2. å¤´çš®è€¦åˆæŒ‡æ•°ï¼ˆSCIï¼‰

import numpy as np
import pandas as pd
import re
import os
from scipy.signal import butter, filtfilt, correlate, periodogram
from scipy.signal.windows import hamming
from ..utils.helper import extract_channel_id, get_channel_columns, group_channels_by_id


def od_CV(od_df, cv_threshold=0.2, use_auto_threshold=False, auto_threshold_quantile=90, verbose=True):
    """
    æŒ‰é€šé“ï¼ˆCHç¼–å·ï¼‰è®¡ç®—æ¯å¯¹æ³¢é•¿é€šé“çš„CVå€¼ï¼Œæ”¯æŒå›ºå®šé˜ˆå€¼æˆ–è‡ªåŠ¨é˜ˆå€¼ï¼ˆpercentileï¼‰ã€‚
    """
    cv_table = []
    bad_channels = {}

    # ä½¿ç”¨ helper å‡½æ•°è·å–é€šé“åˆ—
    ch_cols = get_channel_columns(od_df)

    # ä½¿ç”¨ helper å‡½æ•°æŒ‰é€šé“åˆ†ç»„
    grouped = group_channels_by_id(od_df)
    
    cv_dict = {}
    all_cv_values = []

    # è®¡ç®—æ¯ä¸ªé€šé“æ³¢é•¿çš„ CV å€¼
    for ch_id, col_pair in grouped.items():
        for col in col_pair:
            signal = pd.to_numeric(od_df[col], errors='coerce').dropna().values
            mean_signal = np.mean(signal) if len(signal) > 0 else 0

            if len(signal) == 0 or np.isclose(mean_signal, 0):
                cv = np.nan
            else:
                std_signal = np.std(signal)
                cv = std_signal / abs(mean_signal)

            cv_dict[col] = cv
            if not np.isnan(cv):
                all_cv_values.append(cv)

    # è‡ªåŠ¨æˆ–å›ºå®šé˜ˆå€¼
    if use_auto_threshold:
        cv_threshold_value = np.percentile(all_cv_values, auto_threshold_quantile)
        if verbose:
            print(f"è‡ªåŠ¨é€‰æ‹©CVé˜ˆå€¼: {auto_threshold_quantile}th percentile = {cv_threshold_value:.4f}")
    else:
        cv_threshold_value = float(cv_threshold)
        if verbose:
            print(f"ä½¿ç”¨å›ºå®šCVé˜ˆå€¼: {cv_threshold_value:.4f}")

    # æ­£å¼åˆ¤æ–­æ¯ç»„é€šé“æ˜¯å¦ä¿ç•™
    for ch_id, col_pair in grouped.items():
        cv_values = []
        retain = True

        for col in sorted(col_pair):  # ä¿è¯é¡ºåºä¸€è‡´
            cv = cv_dict.get(col, np.nan)
            wl_match = re.search(r'\((\d+\.?\d*)\)', col)
            wl = wl_match.group(1) if wl_match else "UNK"
            cv_values.append((wl, cv))

            if np.isnan(cv):
                retain = False
                bad_channels[col] = "æ— æ•ˆCV"
            elif cv > cv_threshold_value:
                retain = False
                bad_channels[col] = f"CVè¿‡å¤§ï¼ˆCV={cv:.4f}ï¼‰"

        # å¦‚æœæ³¢é•¿æ•°ç›®ä¸ç­‰äº2ï¼Œä¹Ÿæ ‡è®°å¼‚å¸¸
        if len(cv_values) != 2:
            retain = False
            bad_channels[ch_id] = "æ³¢é•¿æ•°ç›®ä¸è¶³2"

        # æ„é€ è®°å½•è¡Œ
        if len(cv_values) == 2:
            row = {
                "Channel": ch_id,
                "CV_1": cv_values[0][1],
                "CV_2": cv_values[1][1],
                "Retained": retain
            }
        else:
            # è¡¥ NaN å ä½
            row = {"Channel": ch_id, "CV_1": np.nan, "CV_2": np.nan, "Retained": False}
        cv_table.append(row)

    # è¾“å‡ºå¼‚å¸¸ä¿¡æ¯
    if verbose:
        def ch_key(ch): return int(re.search(r'\d+', ch).group())
        bad_channels_summary = {}

        for ch_wl, reason in bad_channels.items():
            ch_id = extract_channel_id(ch_wl)
            wl_match = re.search(r'\((\d+\.?\d*)\)', ch_wl)
            wl = wl_match.group(1) if wl_match else "UNK"

            if "CVè¿‡å¤§" in reason:
                cv_val_match = re.search(r'CV=([\d\.]+)', reason)
                cv_val = cv_val_match.group(1) if cv_val_match else "UNK"
                msg = f"CVè¿‡å¤§ï¼ˆæ³¢é•¿{wl}ï¼ŒCV={cv_val}ï¼‰"
            else:
                msg = reason

            bad_channels_summary.setdefault(ch_id, []).append(msg)

        total_channels = len(grouped)
        bad_count = len(bad_channels_summary)
        bad_ratio = bad_count / total_channels if total_channels > 0 else 0

        if bad_channels_summary:
            print("âš ï¸ å‘ç°å¼‚å¸¸é€šé“ï¼š")
            for ch in sorted(bad_channels_summary.keys(), key=ch_key):
                print(f"  - {ch}: {', '.join(bad_channels_summary[ch])}")
            print(f"\nğŸ“Š å¼‚å¸¸é€šé“æ•°é‡: {bad_count} / {total_channels} ({bad_ratio:.2%})")
        else:
            print("âœ… æ‰€æœ‰é€šé“æ•°æ®æ­£å¸¸ã€‚")

    # è½¬æ¢ä¸ºæ•°æ®æ¡†å¹¶è¿›è¡Œä¿å­˜
    cv_df = pd.DataFrame(cv_table)

    return cv_df


def bandpass_filter(data, sfreq, l_freq, h_freq, order=4):
    """
    å¸¦é€šæ»¤æ³¢

    Parameters
    ----------
      data: æ•°æ®
      sfreq: é‡‡æ ·ç‡
      l_freq: ä½é¢‘æˆªæ­¢é¢‘ç‡
      h_freq: é«˜é¢‘æˆªæ­¢é¢‘ç‡
      order: æ»¤æ³¢å™¨é˜¶æ•°

    Returns
    -------
      filtered_data: æ»¤æ³¢åçš„æ•°æ®
    """
    nyq = 0.5 * sfreq
    b, a = butter(order, [l_freq / nyq, h_freq / nyq], btype='band')
    return filtfilt(b, a, data)


def od_sci(od_df, sfreq=10, l_freq=0.5, h_freq=2.5, threshold=0.5):
    """
    è®¡ç®—å¤´çš®è€¦åˆæŒ‡æ•°ï¼ˆSCIï¼‰
    """
    # ä½¿ç”¨ helper å‡½æ•°è·å–é€šé“åˆ—
    ch_cols = get_channel_columns(od_df)
    
    df = od_df[ch_cols].copy()
    num_cols = len(df.columns)

    # æ£€æŸ¥æ˜¯å¦ä¸ºå¶æ•°åˆ—
    if num_cols % 2 != 0:
        raise ValueError("é€šé“æ•°å¿…é¡»ä¸ºå¶æ•°ï¼Œæ¯å¯¹é€šé“åº”åŒ…å«ä¸¤ä¸ªæ³¢é•¿")
    
    results = []
    retained_cols = []

    # éå†æ¯ä¸€å¯¹é€šé“
    for i in range(0, num_cols, 2):
        col1, col2 = df.columns[i], df.columns[i + 1]
        ch_id = extract_channel_id(col1)

        # è¿›è¡Œ 0.5 - 2.5Hz å¸¦é€šæ»¤æ³¢ï¼Œæå–å¿ƒè·³è€¦åˆæ³¢
        sig1 = bandpass_filter(df[col1].values, sfreq, l_freq, h_freq)
        sig2 = bandpass_filter(df[col2].values, sfreq, l_freq, h_freq)

        # å½’ä¸€åŒ–
        sig1 = (sig1 - np.mean(sig1)) / np.std(sig1)
        sig2 = (sig2 - np.mean(sig2)) / np.std(sig2)

        # è®¡ç®—å¤´çš®è€¦åˆæŒ‡æ•°ï¼ˆå¿ƒè·³è€¦åˆæ³¢ä¹‹é—´çš„ç›¸å…³æ€§ï¼‰
        r = np.corrcoef(sig1, sig2)[0, 1]
        keep_flag = r > threshold
        results.append({'CH': ch_id, 'SCI': r, 'Retained': keep_flag})

        # å¦‚æœå¤´çš®è€¦åˆæŒ‡æ•°å¤§äºé˜ˆå€¼ï¼Œåˆ™ä¿ç•™è¯¥é€šé“
        if keep_flag:
            retained_cols.extend([col1, col2])

    sci_df = pd.DataFrame(results)

    return sci_df


def od_psp(od_df, sfreq=10, time_window=10, l_freq=0.5, h_freq=2.5, fcut_max=2.5, threshold=0.1):
    """
    åˆ†æ—¶é—´çª—å£æ‰¹é‡è®¡ç®—PSP

    Parameters
    ----------
    od_df : pd.DataFrame
        å…‰å¯†åº¦æ•°æ®
    sfreq : float
        é‡‡æ ·ç‡
    time_window : float
        æ—¶é—´çª—å£é•¿åº¦ (ç§’)
    l_freq, h_freq : float
        å¸¦é€šæ»¤æ³¢èŒƒå›´
    fcut_max : float
        æœ€å¤§é¢‘ç‡
    threshold : float
        é˜ˆå€¼

    Returns
    -------
    psp_results : pd.DataFrame
        æ¯ä¸ªé€šé“æ¯ä¸ªçª—å£çš„PSPåŠåˆ¤å®š
    """
    ch_cols = [col for col in od_df.columns if extract_channel_id(col) is not None]
    df = od_df[ch_cols].copy()
    num_cols = len(df.columns)

    if num_cols % 2 != 0:
        raise ValueError("é€šé“æ•°å¿…é¡»ä¸ºå¶æ•°ï¼Œæ¯å¯¹é€šé“åº”åŒ…å«ä¸¤ä¸ªæ³¢é•¿")

    # çª—å£å¤§å° (é‡‡æ ·ç‚¹)
    window_samples = int(np.ceil(time_window * sfreq))
    n_windows = int(np.floor(len(df) / window_samples))

    results = []

    for i in range(0, num_cols, 2):
        col1, col2 = df.columns[i], df.columns[i+1]
        ch_id = extract_channel_id(col1)

        # å¸¦é€šæ»¤æ³¢
        sig1 = bandpass_filter(df[col1].values, sfreq, l_freq, h_freq)
        sig2 = bandpass_filter(df[col2].values, sfreq, l_freq, h_freq)

        # æ ‡å‡†åŒ–
        sig1 = (sig1 - np.mean(sig1)) / (np.std(sig1) or 1)
        sig2 = (sig2 - np.mean(sig2)) / (np.std(sig2) or 1)

        for w in range(n_windows):
            start = int(w * window_samples)
            end = start + window_samples

            s1_window = sig1[start:end]
            s2_window = sig2[start:end]

            # äº’ç›¸å…³
            c = correlate(s1_window, s2_window, mode="full")
            c = c / window_samples

            # Periodogram
            f, pxx = periodogram(
                c,
                fs=sfreq,
                window="hamming",
                scaling="density"
            )

            # æå–å³°å€¼
            mask = f < fcut_max
            psp_val = np.max(pxx[mask])
            psp_freq = f[mask][np.argmax(pxx[mask])]

            keep_flag = psp_val > threshold

            results.append({
                "CH": ch_id,
                "Window": w,
                "PSP": psp_val,
                "PeakFreq": psp_freq,
                "Retained": keep_flag
            })

    psp_df = pd.DataFrame(results)
    return psp_df
