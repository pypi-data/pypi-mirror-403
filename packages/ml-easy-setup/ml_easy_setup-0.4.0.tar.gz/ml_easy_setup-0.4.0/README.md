# ML Easy Setup

> ä¸€é”®é…ç½®æœºå™¨å­¦ä¹ /æ·±åº¦å­¦ä¹ ç¯å¢ƒï¼Œè®©ç§‘ç ”å·¥ä½œæ›´ä¸“æ³¨äºç®—æ³•æœ¬èº«

[![Python Version](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyPI Version](https://img.shields.io/pypi/v/ml-easy-setup.svg)](https://pypi.org/project/ml-easy-setup/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## ğŸš€ ä¸ºä»€ä¹ˆé€‰æ‹© ML Easy Setupï¼Ÿ

**ç—›ç‚¹**ï¼šé…ç½® ML/DL ç¯å¢ƒæ€»æ˜¯é‡åˆ°å„ç§é—®é¢˜
- âŒ PyTorchã€TensorFlow ç‰ˆæœ¬å†²çª
- âŒ CUDA é©±åŠ¨ä¸å·¥å…·åŒ…ä¸åŒ¹é…
- âŒ ä¾èµ–å…³ç³»å¤æ‚ï¼Œå°ç™½ä¸çŸ¥é“ä»ä½•å…¥æ‰‹
- âŒ æ¯æ¬¡æ¢ç”µè„‘éƒ½è¦é‡æ–°é…ç½®åŠå¤©
- âŒ ä¸çŸ¥é“æ¨¡å‹æ„å»ºéœ€è¦å“ªäº›å·¥å…·åŒ…

**è§£å†³æ–¹æ¡ˆ**ï¼šä¸€æ¡å‘½ä»¤æå®šä¸€åˆ‡
- âœ… è‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶å’Œ CUDA ç‰ˆæœ¬
- âœ… 13 ç§é¢„é…ç½®ç¯å¢ƒæ¨¡æ¿ï¼Œè¦†ç›–å„ç§ ML åœºæ™¯
- âœ… åŸºäº uv çš„é«˜é€ŸåŒ…å®‰è£…
- âœ… å®Œå–„çš„ä¾èµ–å†²çªæ£€æµ‹

## ğŸ“¦ å®‰è£…

```bash
pip install ml-easy-setup
```

å¦‚æœä½¿ç”¨å›½å†…é•œåƒï¼ˆå¦‚æ¸…åæºï¼‰ï¼Œå¯èƒ½éœ€è¦ç¨ç­‰åŒæ­¥æ—¶é—´ï¼Œæˆ–ç›´æ¥ä½¿ç”¨å®˜æ–¹æºï¼š

```bash
pip install ml-easy-setup -i https://pypi.org/simple
```

æˆ–ä½¿ç”¨ uvï¼ˆæ›´å¿«ï¼‰ï¼š

```bash
uv pip install ml-easy-setup
```

## ğŸ“‹ ç¯å¢ƒæ¨¡æ¿è¯¦è§£

### ğŸ“ åŸºç¡€æ¨¡æ¿

#### `minimal` - æœ€å°åŒ–é…ç½®
**é€‚åˆåœºæ™¯**ï¼šå…¥é—¨å­¦ä¹ ã€ç®€å•å®éªŒã€å¿«é€ŸéªŒè¯æƒ³æ³•

```bash
mlsetup create quick-test --template minimal
```

**åŒ…å«å·¥å…·**ï¼š
- NumPy, Pandas - æ•°æ®å¤„ç†
- scikit-learn - ä¼ ç»Ÿæœºå™¨å­¦ä¹ 
- Matplotlib - å¯è§†åŒ–
- Jupyter - äº¤äº’å¼å¼€å‘

---

### ğŸ§  æ·±åº¦å­¦ä¹ æ¡†æ¶

#### `pytorch` - PyTorch æ·±åº¦å­¦ä¹ 
**é€‚åˆåœºæ™¯**ï¼šæ·±åº¦å­¦ä¹ ç ”ç©¶ã€ç¥ç»ç½‘ç»œå¼€å‘ã€å­¦æœ¯é¡¹ç›®

```bash
mlsetup create my-dl-project --template pytorch --cuda auto
```

**åŒ…å«å·¥å…·**ï¼š
- PyTorch, torchvision, torchaudio - å®Œæ•´æ·±åº¦å­¦ä¹ æ¡†æ¶
- TensorBoard - è®­ç»ƒç›‘æ§
- Pillow - å›¾åƒå¤„ç†

**ç¤ºä¾‹ä»£ç **ï¼š
```python
import torch
import torch.nn as nn

# åˆ›å»ºç®€å•ç¥ç»ç½‘ç»œ
model = nn.Sequential(
    nn.Linear(784, 128),
    nn.ReLU(),
    nn.Linear(128, 10)
)

# æ£€æŸ¥ GPU å¯ç”¨æ€§
if torch.cuda.is_available():
    model = model.cuda()
    print(f"Using GPU: {torch.cuda.get_device_name(0)}")
```

---

#### `tensorflow` - TensorFlow æ·±åº¦å­¦ä¹ 
**é€‚åˆåœºæ™¯**ï¼šTensorFlow ç”Ÿæ€é¡¹ç›®ã€TF Serving éƒ¨ç½²

```bash
mlsetup create tf-project --template tensorflow --cuda auto
```

**åŒ…å«å·¥å…·**ï¼š
- TensorFlow, Keras - æ·±åº¦å­¦ä¹ æ¡†æ¶
- TensorBoard - å¯è§†åŒ–

---

### ğŸŒ ä¸“é¡¹é¢†åŸŸ

#### `nlp` - è‡ªç„¶è¯­è¨€å¤„ç†
**é€‚åˆåœºæ™¯**ï¼šæ–‡æœ¬åˆ†ç±»ã€æœºå™¨ç¿»è¯‘ã€é—®ç­”ç³»ç»Ÿã€å¤§æ¨¡å‹å¾®è°ƒ

```bash
mlsetup create nlp-project --template nlp --cuda auto
```

**åŒ…å«å·¥å…·**ï¼š
- Transformers - Hugging Face é¢„è®­ç»ƒæ¨¡å‹
- Datasets - æµ·é‡ NLP æ•°æ®é›†
- Accelerate - åˆ†å¸ƒå¼è®­ç»ƒåŠ é€Ÿ

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification

# æƒ…æ„Ÿåˆ†æ
classifier = pipeline("sentiment-analysis")
result = classifier("ML Easy Setup çœŸçš„å¾ˆæ£’ï¼")
print(result)  # [{'label': 'POSITIVE', 'score': 0.9998}]

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
tokenizer = AutoTokenizer.from_pretrained("bert-base-chinese")
model = AutoModelForSequenceClassification.from_pretrained("bert-base-chinese")
```

---

#### `cv` - è®¡ç®—æœºè§†è§‰
**é€‚åˆåœºæ™¯**ï¼šå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²

```bash
mlsetup create cv-project --template cv --cuda auto
```

**åŒ…å«å·¥å…·**ï¼š
- Torchvision - è§†è§‰æ¨¡å‹å’Œæ•°æ®é›†
- OpenCV - å›¾åƒå¤„ç†
- Albumentations - æ•°æ®å¢å¼º

**ç¤ºä¾‹ä»£ç **ï¼š
```python
import torch
from torchvision import models, transforms
from PIL import Image

# åŠ è½½é¢„è®­ç»ƒ ResNet
model = models.resnet50(pretrained=True)
model.eval()

# å›¾åƒé¢„å¤„ç†
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
])

# å›¾åƒåˆ†ç±»
img = Image.open("image.jpg")
img_t = transform(img)
batch_t = torch.unsqueeze(img_t, 0)

with torch.no_grad():
    output = model(batch_t)
```

---

#### `rl` - å¼ºåŒ–å­¦ä¹ 
**é€‚åˆåœºæ™¯**ï¼šæ™ºèƒ½ä½“è®­ç»ƒã€æ¸¸æˆ AIã€æœºå™¨äººæ§åˆ¶

```bash
mlsetup create rl-project --template rl --cuda auto
```

**åŒ…å«å·¥å…·**ï¼š
- Gymnasium - å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ
- Stable-Baselines3 - æˆç†Ÿç®—æ³•å®ç°

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from stable_baselines3 import PPO
from gymnasium import make

# åˆ›å»ºç¯å¢ƒ
env = make("CartPole-v1")

# è®­ç»ƒ PPO æ™ºèƒ½ä½“
model = PPO("MlpPolicy", env, verbose=1)
model.learn(total_timesteps=10000)

# ä¿å­˜æ¨¡å‹
model.save("ppo_cartpole")
```

---

### ğŸ”§ æ¨¡å‹æ„å»ºä¸éªŒè¯

#### `model-builder` - æ¨¡å‹æ„å»ºç¯å¢ƒ â­
**é€‚åˆåœºæ™¯**ï¼šæ¨¡å‹è®­ç»ƒã€è¶…å‚æ•°ä¼˜åŒ–ã€å®éªŒè·Ÿè¸ªã€Kaggle ç«èµ›

```bash
mlsetup create model-project --template model-builder --cuda cpu
```

**åŒ…å«å·¥å…·**ï¼š
- **XGBoost / LightGBM / CatBoost** - æ¢¯åº¦æå‡ä¸‰å·¨å¤´
- **Optuna** - è‡ªåŠ¨è¶…å‚æ•°ä¼˜åŒ–
- **MLflow** - å®éªŒè·Ÿè¸ªå’Œæ¨¡å‹ç®¡ç†
- **W&B** - äº‘ç«¯å®éªŒç›‘æ§

**ç¤ºä¾‹ä»£ç **ï¼š
```python
import optuna
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import cross_val_score

# å®šä¹‰ç›®æ ‡å‡½æ•°
def objective(trial):
    n_estimators = trial.suggest_int('n_estimators', 10, 100)
    max_depth = trial.suggest_int('max_depth', 2, 32)

    clf = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth
    )

    data = load_breast_cancer()
    scores = cross_val_score(clf, data.data, data.target, cv=5)
    return scores.mean()

# è¿è¡Œä¼˜åŒ–
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)

print(f'æœ€ä½³å‚æ•°: {study.best_params}')
print(f'æœ€ä½³åˆ†æ•°: {study.best_value:.4f}')
```

**MLflow å®éªŒè·Ÿè¸ª**ï¼š
```python
import mlflow
import mlflow.sklearn
from sklearn.ensemble import GradientBoostingClassifier

# å¼€å§‹å®éªŒ
with mlflow.start_run():
    model = GradientBoostingClassifier(
        n_estimators=100,
        learning_rate=0.1,
        max_depth=5
    )
    model.fit(X_train, y_train)

    # è®°å½•å‚æ•°å’ŒæŒ‡æ ‡
    mlflow.log_params(model.get_params())
    mlflow.log_metric("accuracy", model.score(X_test, y_test))

    # ä¿å­˜æ¨¡å‹
    mlflow.sklearn.log_model(model, "model")
```

---

#### `algorithm-validator` - ç®—æ³•éªŒè¯ç¯å¢ƒ
**é€‚åˆåœºæ™¯**ï¼šç®—æ³•æ€§èƒ½æµ‹è¯•ã€åŸºå‡†å¯¹æ¯”ã€è®ºæ–‡å®éªŒå¤ç°

```bash
mlsetup create algo-test --template algorithm-validator --cuda cpu
```

**åŒ…å«å·¥å…·**ï¼š
- **pytest** - æµ‹è¯•æ¡†æ¶
- **pytest-benchmark** - æ€§èƒ½åŸºå‡†æµ‹è¯•
- **Datasets** - æ ‡å‡†æ•°æ®é›†
- **Evaluate** - æ¨¡å‹è¯„ä¼°æŒ‡æ ‡

**ç¤ºä¾‹ä»£ç **ï¼š
```python
import pytest
import pytest_benchmark
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification

def test_model_performance(benchmark):
    # å‡†å¤‡æ•°æ®
    X, y = make_classification(n_samples=1000, n_features=20)

    # åŸºå‡†æµ‹è¯•
    model = LogisticRegression()
    result = benchmark(model.fit, X, y)

    # æ–­è¨€
    assert result.score(X, y) > 0.8

# è¿è¡Œæµ‹è¯•
# pytest test_model.py --benchmark-only
```

---

### ğŸ“Š æ•°æ®ç§‘å­¦

#### `data-science` - æ•°æ®ç§‘å­¦ç¯å¢ƒ
**é€‚åˆåœºæ™¯**ï¼šæ•°æ®åˆ†æã€å¯è§†åŒ–ã€ç»Ÿè®¡å»ºæ¨¡ã€å•†ä¸šæ™ºèƒ½

```bash
mlsetup create data-project --template data-science --cuda cpu
```

**åŒ…å«å·¥å…·**ï¼š
- **Polars** - é«˜æ€§èƒ½ DataFrameï¼ˆæ¯” Pandas å¿«ï¼‰
- **Dask** - å¹¶è¡Œè®¡ç®—ï¼ˆå¤„ç†å¤§æ•°æ®ï¼‰
- **PyArrow** - é«˜æ•ˆæ•°æ®æ ¼å¼
- **Statsmodels** - ç»Ÿè®¡åˆ†æ
- **Plotly / Seaborn / Altair** - äº¤äº’å¼å¯è§†åŒ–

**ç¤ºä¾‹ä»£ç **ï¼š
```python
import polars as pl
import plotly.express as px

# è¯»å–å¤§æ•°æ®ï¼ˆæ”¯æŒ CSVã€Parquet ç­‰ï¼‰
df = pl.read_csv("large_dataset.csv")

# é«˜æ€§èƒ½æ•°æ®å¤„ç†
result = (
    df
    .filter(pl.col("sales") > 1000)
    .group_by("category")
    .agg([
        pl.col("sales").sum().alias("total_sales"),
        pl.col("sales").mean().alias("avg_sales")
    ])
    .sort("total_sales", descending=True)
)

# äº¤äº’å¼å¯è§†åŒ–
fig = px.bar(result.to_pandas(), x="category", y="total_sales")
fig.show()
```

---

#### `gradient-boosting` - æ¢¯åº¦æå‡ä¸“ç”¨ â­
**é€‚åˆåœºæ™¯**ï¼šKaggle ç«èµ›ã€è¡¨æ ¼æ•°æ®å»ºæ¨¡ã€ç‰¹å¾å·¥ç¨‹

```bash
mlsetup create kaggle-project --template gradient-boosting --cuda cpu
```

**åŒ…å«å·¥å…·**ï¼š
- **XGBoost** - æé€Ÿæ¢¯åº¦æå‡
- **LightGBM** - å†…å­˜é«˜æ•ˆ
- **CatBoost** - è‡ªåŠ¨å¤„ç†ç±»åˆ«ç‰¹å¾
- **SHAP** - æ¨¡å‹å¯è§£é‡Šæ€§

**ç¤ºä¾‹ä»£ç **ï¼š
```python
import xgboost as xgb
import shap
from sklearn.datasets import load_boston

# åŠ è½½æ•°æ®
data = load_boston()
X, y = data.data, data.target

# è®­ç»ƒ XGBoost
model = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6
)
model.fit(X, y)

# SHAP å¯è§£é‡Šæ€§åˆ†æ
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X)
shap.summary_plot(shap_values, X, feature_names=data.feature_names)
```

---

### ğŸš€ MLOps

#### `mlops` - MLOps éƒ¨ç½²ç¯å¢ƒ
**é€‚åˆåœºæ™¯**ï¼šæ¨¡å‹éƒ¨ç½²ã€API æœåŠ¡ã€æ¨¡å‹ç›‘æ§

```bash
mlsetup create api-service --template mlops --cuda cpu
```

**åŒ…å«å·¥å…·**ï¼š
- **BentoML** - æ¨¡å‹æœåŠ¡æ¡†æ¶
- **FastAPI** - é«˜æ€§èƒ½ API
- **MLflow** - æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
- **DVC** - æ•°æ®ç‰ˆæœ¬æ§åˆ¶

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from bentoml import Service, api
import numpy as np

service = Service("ml_model")

# åŠ è½½æ¨¡å‹
model = mlflow.pyfunc.load_model("models:/my_model/Production")

@service.api(input=JSON(), output=JSON())
def predict(input_data):
    X = np.array(input_data["features"])
    prediction = model.predict(X)
    return {"prediction": prediction.tolist()}

# è¿è¡ŒæœåŠ¡
# bentoml serve service:svc
```

---

### â± æ—¶é—´åºåˆ—

#### `timeseries` - æ—¶é—´åºåˆ—åˆ†æ
**é€‚åˆåœºæ™¯**ï¼šé”€é‡é¢„æµ‹ã€è‚¡ç¥¨åˆ†æã€ä¼ æ„Ÿå™¨æ•°æ®

```bash
mlsetup create forecast-project --template timeseries --cuda cpu
```

**åŒ…å«å·¥å…·**ï¼š
- **Prophet** - Facebook æ—¶é—´åºåˆ—é¢„æµ‹
- **statsmodels** - ç»Ÿè®¡æ—¶é—´åºåˆ—
- **darts** - ç»Ÿä¸€æ—¶é—´åºåˆ—æ¥å£

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from prophet import Prophet
import pandas as pd

# å‡†å¤‡æ•°æ®
df = pd.DataFrame({
    'ds': pd.date_range('2023-01-01', periods=365),
    'y': np.random.randn(365).cumsum()
})

# åˆ›å»ºé¢„æµ‹æ¨¡å‹
model = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=False
)
model.fit(df)

# é¢„æµ‹æœªæ¥ 30 å¤©
future = model.make_future_dataframe(periods=30)
forecast = model.predict(future)

# å¯è§†åŒ–
fig = model.plot(forecast)
```

---

### ğŸ•¸ å›¾å­¦ä¹ 

#### `graph` - å›¾ç¥ç»ç½‘ç»œ
**é€‚åˆåœºæ™¯**ï¼šç¤¾äº¤ç½‘ç»œåˆ†æã€åˆ†å­æ€§è´¨é¢„æµ‹ã€æ¨èç³»ç»Ÿ

```bash
mlsetup create graph-project --template graph --cuda auto
```

**åŒ…å«å·¥å…·**ï¼š
- **PyTorch Geometric** - å›¾ç¥ç»ç½‘ç»œåº“
- **DGL** - æ·±åº¦å›¾å­¦ä¹ 
- **NetworkX** - å›¾ç®—æ³•

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from torch_geometric.data import Data
from torch_geometric.nn import GCNConv
import torch

# æ„å»ºå›¾æ•°æ®
edge_index = torch.tensor([[0, 1, 1, 2],
                           [1, 0, 2, 1]], dtype=torch.long)
x = torch.tensor([[-1], [0], [1]], dtype=torch.float)

data = Data(x=x, edge_index=edge_index)

# å®šä¹‰ GCN
class GCN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = GCNConv(1, 16)
        self.conv2 = GCNConv(16, 2)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index).relu()
        x = self.conv2(x, edge_index)
        return x

# è®­ç»ƒ
model = GCN()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
```

---

### ğŸ¯ å®Œæ•´ç¯å¢ƒ

#### `full` - å®Œæ•´å·¥å…·é“¾
**é€‚åˆåœºæ™¯**ï¼šéœ€è¦å…¨æ–¹ä½å·¥å…·çš„å¤æ‚é¡¹ç›®

```bash
mlsetup create full-stack --template full --cuda auto
```

**åŒ…å«æ‰€æœ‰é¢†åŸŸçš„å·¥å…·**ï¼Œé€‚åˆï¼š
- éœ€è¦åŒæ—¶ä½¿ç”¨å¤šç§æŠ€æœ¯çš„é¡¹ç›®
- ä¸ç¡®å®šéœ€è¦å“ªäº›å·¥å…·çš„æ¢ç´¢é˜¶æ®µ
- æ•™å­¦æ¼”ç¤ºç¯å¢ƒ

---

## ğŸ”§ ç³»ç»Ÿæ£€æµ‹

æ£€æŸ¥æ‚¨çš„ç³»ç»Ÿç¯å¢ƒï¼š

```bash
mlsetup detect
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
ç³»ç»Ÿç¯å¢ƒæ£€æµ‹
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
é¡¹ç›®          æ£€æµ‹ç»“æœ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ“ä½œç³»ç»Ÿ      Darwin
Python ç‰ˆæœ¬   3.11.5
æ¶æ„          arm64
CUDA          æœªå®‰è£…
GPU           Apple Silicon (MPS)
UV            0.1.20
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

## ğŸ¥ ç¯å¢ƒå¥åº·æ£€æŸ¥

æ–°åŠŸèƒ½ï¼æ£€æŸ¥é¡¹ç›®ç¯å¢ƒçŠ¶æ€ï¼Œå‘ç°æ½œåœ¨é—®é¢˜ï¼š

```bash
mlsetup health
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
â•­â”€ ML Easy Setup â”€â•®
â”‚ ç¯å¢ƒå¥åº·æ£€æŸ¥    â”‚
â”‚ çŠ¶æ€: âš  WARNING â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¥åº·åˆ†æ•°:
  âœ“ venv: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
  âš  dependencies: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 70%
  âœ“ gpu: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
  âœ“ compatibility: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
  âœ“ disk: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

å‘ç°çš„é—®é¢˜:
  âš  å‘ç°ä¾èµ–å†²çªæˆ–ä¸å…¼å®¹
  âš  nvidia-smi ä¸å¯ç”¨ï¼ˆæ—  NVIDIA GPUï¼‰

å»ºè®®:
  1. âœ“ ä½¿ç”¨ uv åŒ…ç®¡ç†å™¨
  2. è¿è¡Œ: uv pip check æŸ¥çœ‹è¯¦ç»†å†²çªä¿¡æ¯
  3. ğŸ’¡ PyTorch ç‰ˆæœ¬é—®é¢˜ - è®¿é—® https://pytorch.org è·å–æ­£ç¡®å®‰è£…å‘½ä»¤
```

è‡ªåŠ¨ä¿®å¤é—®é¢˜ï¼š
```bash
mlsetup health --auto-fix
```

**æ£€æŸ¥é¡¹ç›®**ï¼š
- è™šæ‹Ÿç¯å¢ƒçŠ¶æ€ï¼ˆæ”¯æŒ uvï¼‰
- ä¾èµ–å†²çªï¼ˆé€šè¿‡ `uv pip check` æˆ– `pip check`ï¼‰
- GPU/CUDA å¯ç”¨æ€§
- åŒ…ç‰ˆæœ¬å…¼å®¹æ€§
- ç£ç›˜ç©ºé—´

## ğŸ“¦ æ·»åŠ é¢å¤–çš„åŒ…

```bash
# æ·»åŠ åˆ°æ ¸å¿ƒä¾èµ–
mlsetup add numpy pandas

# æ·»åŠ åˆ°å¼€å‘ä¾èµ–
mlsetup add pytest --dev
```

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

åˆ›å»ºçš„é¡¹ç›®åŒ…å«ä»¥ä¸‹ç»“æ„ï¼š

```
my-project/
â”œâ”€â”€ .venv/              # è™šæ‹Ÿç¯å¢ƒ
â”œâ”€â”€ src/                # æºä»£ç ç›®å½•
â”œâ”€â”€ tests/              # æµ‹è¯•ç›®å½•
â”œâ”€â”€ data/               # æ•°æ®ç›®å½•
â”œâ”€â”€ notebooks/          # Jupyter notebooks
â”œâ”€â”€ outputs/            # è¾“å‡ºæ–‡ä»¶ç›®å½•
â”œâ”€â”€ requirements.txt    # æ ¸å¿ƒä¾èµ–
â”œâ”€â”€ requirements-dev.txt # å¼€å‘ä¾èµ–
â””â”€â”€ .gitignore          # Git å¿½ç•¥æ–‡ä»¶
```

## ğŸ¨ é…ç½®é€‰é¡¹

### CUDA ç‰ˆæœ¬

æ”¯æŒä»¥ä¸‹ CUDA ç‰ˆæœ¬ï¼š
- `auto` - è‡ªåŠ¨æ£€æµ‹ï¼ˆæ¨èï¼‰
- `cpu` - ä»… CPU ç‰ˆæœ¬
- `11.8` - CUDA 11.8
- `12.1` - CUDA 12.1
- `12.4` - CUDA 12.4
- `none` - ä¸å®‰è£… CUDA ç›¸å…³åŒ…

### Python ç‰ˆæœ¬

```bash
mlsetup create my-project --python 3.11
```

æ”¯æŒçš„ Python ç‰ˆæœ¬ï¼š3.10, 3.11, 3.12

## ğŸ†š ä¸å…¶ä»–å·¥å…·å¯¹æ¯”

| ç‰¹æ€§ | ML Easy Setup | conda | poetry | venv |
|------|---------------|-------|--------|------|
| ä¸“ä¸º ML è®¾è®¡ | âœ… | âœ… | âŒ | âŒ |
| è‡ªåŠ¨ CUDA æ£€æµ‹ | âœ… | âŒ | âŒ | âŒ |
| å®‰è£…é€Ÿåº¦ | âš¡âš¡âš¡ | âš¡ | âš¡âš¡ | âš¡ |
| å­¦ä¹ æ›²çº¿ | ä½ | ä¸­ | é«˜ | ä½ |
| é¢„é…ç½®æ¨¡æ¿ | âœ… (13ç§) | âŒ | âŒ | âŒ |

## ğŸ“š å¸¸è§ä½¿ç”¨åœºæ™¯

### Kaggle ç«èµ›
```bash
mlsetup create kaggle-titanic --template gradient-boosting --cuda cpu
```

### è®ºæ–‡å®éªŒ
```bash
mlsetup create paper-exp --template model-builder --cuda auto
```

### æ•°æ®åˆ†ææŠ¥å‘Š
```bash
mlsetup create sales-analysis --template data-science --cuda cpu
```

### NLP å¤§æ¨¡å‹å¾®è°ƒ
```bash
mlsetup create llm-finetune --template nlp --cuda auto
```

### æ¨¡å‹éƒ¨ç½²
```bash
mlsetup create model-api --template mlops --cuda cpu
```

## ğŸ”® è·¯çº¿å›¾

- [ ] æ”¯æŒ Docker å®¹å™¨åŒ–ç¯å¢ƒ
- [ ] ç¯å¢ƒå¯¼å‡º/å¯¼å…¥åŠŸèƒ½
- [ ] äº‘ç«¯ç¯å¢ƒé…ç½®ï¼ˆAWS/GCPï¼‰
- [ ] å›¾å½¢åŒ–é…ç½®ç•Œé¢
- [ ] ç¯å¢ƒå¥åº·æ£€æŸ¥å·¥å…·

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£è¯¦æƒ…ã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

- [uv](https://github.com/astral-sh/uv) - é«˜æ€§èƒ½ Python åŒ…ç®¡ç†å™¨
- [click](https://click.palletsprojects.com/) - ä¼˜é›…çš„å‘½ä»¤è¡Œç•Œé¢
- [rich](https://rich.readthedocs.io/) - ç»ˆç«¯ç¾åŒ–è¾“å‡º

---

â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘ç»™æˆ‘ä»¬ä¸€ä¸ªæ˜Ÿæ ‡ï¼

Made with â¤ï¸ for the ML community
