"""
ML Magic - æè‡´ç®€åŒ–çš„ ML API

è®¾è®¡ç†å¿µ:
- ä»æƒ³æ³•åˆ°ç»“æœï¼Œåªéœ€è¦ä¸€è¡Œä»£ç 
- è‡ªåŠ¨å¤„ç†æ‰€æœ‰è„æ´»ç´¯æ´»ï¼šæ•°æ®åŠ è½½ã€é¢„å¤„ç†ã€æ¨¡å‹é€‰æ‹©ã€è®­ç»ƒ
- æ™ºèƒ½é»˜è®¤å€¼ï¼Œä½†ä¿ç•™å®Œå…¨æ§åˆ¶æƒ
- å‡½æ•°å¼ APIï¼Œç®€æ´ä¼˜é›…

æ ¸å¿ƒåŸåˆ™:
    "Don't make me think about boilerplate"
    "Just give me the result"
"""

from __future__ import annotations

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Union, Optional, Any, Dict, List
from dataclasses import dataclass, field
import warnings

try:
    import torch
    import torch.nn as nn
    from torch.utils.data import Dataset, TensorDataset, DataLoader
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

from .models import SimpleModel
from .trainers.auto import AutoTrainer, TrainerConfig, TrainingHistory


# ========================================================================
# ç»“æœå¯¹è±¡
# ========================================================================
@dataclass
class TrainResult:
    """è®­ç»ƒç»“æœ - åŒ…å«æ‰€æœ‰ä½ éœ€è¦çš„"""
    model: Any
    history: TrainingHistory
    metrics: Dict[str, float] = field(default_factory=dict)
    predictions: Optional[np.ndarray] = None

    def __repr__(self) -> str:
        acc = self.metrics.get('accuracy', self.metrics.get('val_accuracy', 0))
        return f"<TrainResult: model={self.model.__class__.__name__}, accuracy={acc:.4f}>"


# ========================================================================
# Level 1: ä»åŸå§‹æ•°æ®åˆ°è®­ç»ƒç»“æœ - ä¸€è¡Œä»£ç 
# ========================================================================
def train(
    data: Union[str, Path, pd.DataFrame, np.ndarray, tuple],
    target: Optional[Union[str, int, np.ndarray]] = None,
    task: str = "auto",
    test_size: float = 0.2,
    epochs: int = 100,
    hidden_layers: Optional[List[int]] = None,
    **kwargs
) -> TrainResult:
    """
    ğŸª„ ä¸€è¡Œä»£ç å®Œæˆä»æ•°æ®åˆ°è®­ç»ƒæ¨¡å‹

    è‡ªåŠ¨å¤„ç†:
    - æ•°æ®åŠ è½½ï¼ˆCSV/Excel/NumPy/Pandasï¼‰
    - æ•°æ®é¢„å¤„ç†ï¼ˆæ ‡å‡†åŒ–ã€ç¼–ç ï¼‰
    - æ•°æ®é›†åˆ’åˆ†
    - æ¨¡å‹æ¶æ„é€‰æ‹©
    - è®­ç»ƒå¾ªç¯
    - è¯„ä¼°

    Args:
        data: è¾“å…¥æ•°æ®ï¼Œæ”¯æŒå¤šç§æ ¼å¼:
            - str/Path: CSV/Excel æ–‡ä»¶è·¯å¾„
            - pd.DataFrame: Pandas DataFrame
            - np.ndarray: NumPy æ•°ç»„
            - tuple: (X, y) å…ƒç»„
        target: ç›®æ ‡åˆ—:
            - str: åˆ—åï¼ˆç”¨äº DataFrameï¼‰
            - int: åˆ—ç´¢å¼•ï¼ˆç”¨äº NumPyï¼‰
            - np.ndarray: ç‹¬ç«‹çš„æ ‡ç­¾æ•°ç»„
            - None: data æ˜¯ (X, y) å…ƒç»„æ—¶
        task: ä»»åŠ¡ç±»å‹:
            - "auto": è‡ªåŠ¨æ£€æµ‹ï¼ˆé»˜è®¤ï¼‰
            - "classification": åˆ†ç±»
            - "regression": å›å½’
            - "binary": äºŒåˆ†ç±»
        test_size: æµ‹è¯•é›†æ¯”ä¾‹
        epochs: è®­ç»ƒè½®æ•°
        hidden_layers: éšè—å±‚å¤§å°ï¼Œå¦‚ [64, 32]
        **kwargs: å…¶ä»–è®­ç»ƒå‚æ•°

    Returns:
        TrainResult åŒ…å«æ¨¡å‹ã€å†å²ã€æŒ‡æ ‡

    Examples:
        >>> # CSV æ–‡ä»¶ - åˆ†ç±»ä»»åŠ¡
        >>> result = train("iris.csv", target="species", epochs=50)
        >>> print(f"Accuracy: {result.metrics['accuracy']:.2%}")

        >>> # NumPy æ•°ç»„ - å›å½’ä»»åŠ¡
        >>> X = np.random.randn(1000, 20)
        >>> y = np.random.randn(1000)
        >>> result = train((X, y), task="regression")

        >>> # DataFrame - äºŒåˆ†ç±»
        >>> df = pd.read_csv("data.csv")
        >>> result = train(df, target="label", task="binary", hidden_layers=[128, 64])
    """
    if not TORCH_AVAILABLE:
        raise ImportError(
            "PyTorch is required for training. "
            "Install it with: pip install torch"
        )

    # ========== æ­¥éª¤ 1: æ•°æ®åŠ è½½ ==========
    X, y, feature_names = _load_data(data, target)

    # ========== æ­¥éª¤ 2: è‡ªåŠ¨æ£€æµ‹ä»»åŠ¡ç±»å‹ ==========
    if task == "auto":
        task = _detect_task_type(y, n_classes=len(np.unique(y)) if len(y.shape) == 1 else None)

    # ========== æ­¥éª¤ 3: æ•°æ®é¢„å¤„ç† ==========
    X_processed, y_processed, preprocessors = _preprocess_data(X, y, task)

    # ========== æ­¥éª¤ 4: æ•°æ®é›†åˆ’åˆ† ==========
    X_train, X_val, y_train, y_val = train_test_split(
        X_processed, y_processed,
        test_size=test_size,
        random_state=42,
        stratify=y_processed if task != "regression" else None
    )

    # ========== æ­¥éª¤ 5: åˆ›å»ºæ•°æ®åŠ è½½å™¨ ==========
    train_loader, val_loader = _create_dataloaders(
        X_train, y_train, X_val, y_val,
        batch_size=kwargs.get('batch_size', 32)
    )

    # ========== æ­¥éª¤ 6: è‡ªåŠ¨è®¾è®¡æ¨¡å‹æ¶æ„ ==========
    input_size = X_train.shape[1]
    output_size = _get_output_size(y_train, task)

    if hidden_layers is None:
        hidden_layers = _suggest_hidden_layers(input_size, task)

    layers = [input_size] + hidden_layers + [output_size]
    model = SimpleModel(layers, task=task, **{k: v for k, v in kwargs.items()
                                               if k in ['activation', 'dropout', 'batch_norm']})

    # ========== æ­¥éª¤ 7: è®­ç»ƒ ==========
    config = TrainerConfig(
        epochs=epochs,
        task=task,
        **{k: v for k, v in kwargs.items() if k in TrainerConfig.__dataclass_fields__}
    )
    trainer = AutoTrainer(config)
    history = trainer.fit(model, train_loader, val_loader)

    # ========== æ­¥éª¤ 8: è¯„ä¼° ==========
    metrics = _evaluate_model(model, val_loader, task)

    return TrainResult(
        model=model,
        history=history,
        metrics=metrics
    )


def predict(
    model: nn.Module,
    data: Union[str, Path, pd.DataFrame, np.ndarray],
    **kwargs
) -> np.ndarray:
    """
    ğŸ¯ ä¸€è¡Œä»£ç è¿›è¡Œé¢„æµ‹

    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        data: è¾“å…¥æ•°æ®
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        é¢„æµ‹ç»“æœæ•°ç»„

    Examples:
        >>> predictions = predict(model, "test.csv")
        >>> predictions = predict(model, X_new)
    """
    if not TORCH_AVAILABLE:
        raise ImportError("PyTorch is required")

    # åŠ è½½æ•°æ®
    if isinstance(data, (str, Path)):
        data = pd.read_csv(data)

    if isinstance(data, pd.DataFrame):
        X = data.values
    else:
        X = np.array(data)

    # è½¬æ¢ä¸º tensor
    X_tensor = torch.FloatTensor(X)

    # é¢„æµ‹
    model.eval()
    with torch.no_grad():
        predictions = model(X_tensor)

    # æ ¹æ®ä»»åŠ¡ç±»å‹å¤„ç†è¾“å‡º
    if hasattr(model, 'task'):
        task = model.task
        if task == "classification":
            return predictions.argmax(dim=1).numpy()
        elif task == "binary":
            return (predictions > 0.5).float().numpy()
        else:
            return predictions.numpy()

    return predictions.numpy()


# ========================================================================
# Level 2: å¸¸è§ä»»åŠ¡ä¸“ç”¨çš„ one-liner
# ========================================================================
def tabular_classifier(
    data: Union[str, pd.DataFrame],
    target: str,
    *,
    epochs: int = 100,
    hidden_layers: Optional[List[int]] = None,
    **kwargs
) -> TrainResult:
    """
    ğŸ“Š è¡¨æ ¼æ•°æ®åˆ†ç±» - ä¸€è¡Œä»£ç 

    ä¸“é—¨ä¸ºç»“æ„åŒ–è¡¨æ ¼æ•°æ®ï¼ˆCSVã€Excelï¼‰ä¼˜åŒ–

    Examples:
        >>> result = tabular_classifier("customer_data.csv", "churn", epochs=50)
        >>> print(f"Churn prediction accuracy: {result.metrics['accuracy']:.2%}")
    """
    return train(
        data=data,
        target=target,
        task="classification",
        epochs=epochs,
        hidden_layers=hidden_layers,
        **kwargs
    )


def regressor(
    data: Union[str, pd.DataFrame, tuple],
    target: Optional[Union[str, np.ndarray]] = None,
    *,
    epochs: int = 100,
    hidden_layers: Optional[List[int]] = None,
    **kwargs
) -> TrainResult:
    """
    ğŸ“ˆ å›å½’ä»»åŠ¡ - ä¸€è¡Œä»£ç 

    Examples:
        >>> result = regressor("house_prices.csv", "price")
        >>> result = regressor((X, y), epochs=200)
        >>> predictions = result.model.predict(X_test)
    """
    return train(
        data=data,
        target=target,
        task="regression",
        epochs=epochs,
        hidden_layers=hidden_layers,
        **kwargs
    )


def binary_classifier(
    data: Union[str, pd.DataFrame],
    target: str,
    *,
    epochs: int = 100,
    hidden_layers: Optional[List[int]] = None,
    **kwargs
) -> TrainResult:
    """
    ğŸ¯ äºŒåˆ†ç±»ä»»åŠ¡ - ä¸€è¡Œä»£ç 

    Examples:
        >>> result = binary_classifier("fraud_data.csv", "is_fraud")
        >>> print(f"Fraud detection AUC: {result.metrics['auc']:.4f}")
    """
    return train(
        data=data,
        target=target,
        task="binary",
        epochs=epochs,
        hidden_layers=hidden_layers,
        **kwargs
    )


# ========================================================================
# è¾…åŠ©å‡½æ•°
# ========================================================================
def _load_data(
    data: Union[str, Path, pd.DataFrame, np.ndarray, tuple],
    target: Optional[Union[str, int, np.ndarray]]
) -> tuple[np.ndarray, np.ndarray, Optional[List[str]]]:
    """åŠ è½½å¹¶è¿”å› X, y"""

    # æƒ…å†µ 1: (X, y) å…ƒç»„
    if isinstance(data, tuple):
        X, y = data
        return np.array(X), np.array(y), None

    # æƒ…å†µ 2: æ–‡ä»¶è·¯å¾„
    if isinstance(data, (str, Path)):
        path = Path(data)
        if path.suffix in ['.csv', '.csv.gz']:
            df = pd.read_csv(data)
        elif path.suffix in ['.xlsx', '.xls']:
            df = pd.read_excel(data)
        elif path.suffix == '.parquet':
            df = pd.read_parquet(data)
        else:
            raise ValueError(f"Unsupported file format: {path.suffix}")

        feature_names = df.columns.tolist()
        if isinstance(target, str):
            y = df[target].values
            X = df.drop(columns=[target]).values
            feature_names.remove(target)
        else:
            raise ValueError("target must be a column name for file inputs")

        return X, y, feature_names

    # æƒ…å†µ 3: DataFrame
    if isinstance(data, pd.DataFrame):
        feature_names = data.columns.tolist()
        if isinstance(target, str):
            y = data[target].values
            X = data.drop(columns=[target]).values
            feature_names.remove(target)
        elif isinstance(target, int):
            y = data.iloc[:, target].values
            X = data.drop(columns=data.columns[target]).values
            feature_names.pop(target)
        elif isinstance(target, np.ndarray):
            X = data.values
            y = target
        else:
            raise ValueError(f"Invalid target type: {type(target)}")

        return X, y, feature_names

    # æƒ…å†µ 4: NumPy array
    if isinstance(data, np.ndarray):
        if isinstance(target, np.ndarray):
            return data, target, None
        elif isinstance(target, int):
            X = np.delete(data, target, axis=1)
            y = data[:, target]
            return X, y, None
        else:
            raise ValueError("For numpy arrays, target must be an int or array")

    raise ValueError(f"Unsupported data type: {type(data)}")


def _detect_task_type(y: np.ndarray, n_classes: Optional[int] = None) -> str:
    """è‡ªåŠ¨æ£€æµ‹ä»»åŠ¡ç±»å‹"""
    unique_values = np.unique(y)
    n_classes = len(unique_values) if n_classes is None else n_classes

    # æµ®ç‚¹æ•° = å›å½’
    if y.dtype in [np.float32, np.float64]:
        if n_classes <= 10:  # å°‘é‡æµ®ç‚¹æ•°å¯èƒ½æ˜¯ç¼–ç çš„ç±»åˆ«
            return "classification"
        return "regression"

    # æ•´æ•° - åˆ¤æ–­æ˜¯åˆ†ç±»è¿˜æ˜¯å›å½’
    if y.dtype in [np.int32, np.int64]:
        if n_classes == 2:
            return "binary"
        elif n_classes <= 100:  # å°‘é‡ç±»åˆ« = åˆ†ç±»
            return "classification"
        else:  # å¤§é‡æ•´æ•° = å›å½’
            return "regression"

    # é»˜è®¤åˆ†ç±»
    return "classification"


def _preprocess_data(
    X: np.ndarray,
    y: np.ndarray,
    task: str
) -> tuple[np.ndarray, np.ndarray, dict]:
    """æ•°æ®é¢„å¤„ç†"""
    preprocessors = {}

    # ç‰¹å¾æ ‡å‡†åŒ–ï¼ˆå›å½’ä»»åŠ¡éœ€è¦ï¼‰
    if task == "regression":
        scaler = StandardScaler()
        X = scaler.fit_transform(X)
        preprocessors['scaler'] = scaler

    # æ ‡ç­¾ç¼–ç ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰
    if task in ["classification", "binary"]:
        if y.dtype == object or y.dtype.kind in ['U', 'O', 'S']:
            encoder = LabelEncoder()
            y = encoder.fit_transform(y)
            preprocessors['label_encoder'] = encoder

    return X, y, preprocessors


def _create_dataloaders(
    X_train: np.ndarray,
    y_train: np.ndarray,
    X_val: np.ndarray,
    y_val: np.ndarray,
    batch_size: int
) -> tuple[DataLoader, DataLoader]:
    """åˆ›å»º PyTorch æ•°æ®åŠ è½½å™¨"""
    train_dataset = TensorDataset(
        torch.FloatTensor(X_train),
        torch.LongTensor(y_train) if y_train.dtype.kind in ['i', 'u'] else torch.FloatTensor(y_train)
    )
    val_dataset = TensorDataset(
        torch.FloatTensor(X_val),
        torch.LongTensor(y_val) if y_val.dtype.kind in ['i', 'u'] else torch.FloatTensor(y_val)
    )

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader


def _get_output_size(y: np.ndarray, task: str) -> int:
    """è·å–è¾“å‡ºå±‚å¤§å°"""
    if task == "regression":
        return 1
    elif task == "binary":
        return 1
    else:  # classification
        return len(np.unique(y))


def _suggest_hidden_layers(input_size: int, task: str) -> List[int]:
    """æ ¹æ®è¾“å…¥å¤§å°è‡ªåŠ¨å»ºè®®éšè—å±‚"""
    if task == "regression":
        # å›å½’ä»»åŠ¡ï¼šè¾ƒç®€å•çš„ç½‘ç»œ
        if input_size < 50:
            return [64, 32]
        elif input_size < 500:
            return [128, 64]
        else:
            return [256, 128, 64]
    else:
        # åˆ†ç±»ä»»åŠ¡ï¼šå¯ä»¥æ›´å¤æ‚
        if input_size < 50:
            return [64, 32]
        elif input_size < 500:
            return [128, 64]
        else:
            return [256, 128, 64]


def _evaluate_model(
    model: nn.Module,
    data_loader: DataLoader,
    task: str
) -> Dict[str, float]:
    """è¯„ä¼°æ¨¡å‹å¹¶è¿”å›æŒ‡æ ‡"""
    model.eval()
    device = next(model.parameters()).device

    all_preds = []
    all_labels = []
    total_loss = 0.0

    with torch.no_grad():
        for X_batch, y_batch in data_loader:
            X_batch = X_batch.to(device)
            y_batch = y_batch.to(device)

            outputs = model(X_batch)
            all_preds.append(outputs.cpu())
            all_labels.append(y_batch.cpu())

    # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡
    all_preds = torch.cat(all_preds)
    all_labels = torch.cat(all_labels)

    # è®¡ç®—å‡†ç¡®ç‡
    if task == "classification":
        pred_classes = all_preds.argmax(dim=1)
        accuracy = (pred_classes == all_labels).float().mean().item()
        return {"accuracy": accuracy, "val_accuracy": accuracy}
    elif task == "binary":
        pred_classes = (all_preds > 0.5).long()
        accuracy = (pred_classes.squeeze() == all_labels).float().mean().item()
        return {"accuracy": accuracy, "val_accuracy": accuracy}
    else:  # regression
        mse = torch.nn.functional.mse_loss(all_preds, all_labels.unsqueeze(1)).item()
        return {"mse": mse, "val_mse": mse}


# ========================================================================
# å¯¼å‡º API
# ========================================================================
__all__ = [
    "train",
    "predict",
    "tabular_classifier",
    "regressor",
    "binary_classifier",
    "TrainResult",
]
