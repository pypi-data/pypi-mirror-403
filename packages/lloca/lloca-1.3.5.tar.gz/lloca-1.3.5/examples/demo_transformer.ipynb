{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69aeaf81-607b-4d55-9e77-be267ac08479",
   "metadata": {},
   "source": [
    "# LLoCa Quickstart\n",
    "# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/heidelberg-hepml/lloca/blob/main/examples/demo_transformer.ipynb)\n",
    "\n",
    "In this tutorial, we give a quick introduction for how to use Lorentz Local Canonicalization (LLoCa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19f50e-ba16-4a3b-88ee-b6c31c565e83",
   "metadata": {},
   "source": [
    "LLoCa is a framework to make any network Lorentz-equivariant. It uses the concept of canonicalization, i.e. local frames where features are invariant under symmetry transformations, making it possible to process them with any backbone architecture without violating equivariance. The frames are constructed from a set of vectors constructed with a simple Lorentz-equivariant network, which are turned into Lorentz transformations through a orthonormalization step. To maximise expressivity, each particle gets its own *local* frame, but this requires a modification of message-passing to allow the communication of tensorial messages between particles in different frames.\n",
    "\n",
    "We will now demonstrate how to build a simple LLoCa-Transformer following three steps:\n",
    "\n",
    "1. Construct local frames based on 3 equivariantly predicted vectors\n",
    "2. Transform particle features into local frames\n",
    "3. Process local particle features with any backbone architecture\n",
    "\n",
    "![LLoCa workflow](https://raw.githubusercontent.com/heidelberg-hepml/lloca/main/img/lloca.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58232c6b-85e1-4e48-857b-24995368ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the lloca package\n",
    "%pip install lloca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad94a506-afb2-47ad-9c44-dbdf7f1081f1",
   "metadata": {},
   "source": [
    "### 0) Generate particle data\n",
    "\n",
    "We start by generating toy particle data, for instance for an amplitude regression task. We describe particles by a four-momentum and one scalar feature, for instance the particle type. Using random numbers, we generate a batch of 128 events with 10 particles each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd9b4b6-eff1-4609-bdda-44157908e7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 4]) torch.Size([128, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "# generate particle data\n",
    "import torch\n",
    "\n",
    "num_scalars = 1\n",
    "B, N = 128, 10\n",
    "mass = 1\n",
    "p3 = torch.randn(B, N, 3)\n",
    "fourmomenta = torch.cat([(mass**2 + (p3**2).sum(dim=-1, keepdims=True)).sqrt(), p3], dim=-1)\n",
    "scalars = torch.randn(B, N, num_scalars)\n",
    "print(fourmomenta.shape, scalars.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7374c3ed-6f4b-47c6-9525-e906d5957797",
   "metadata": {},
   "source": [
    "### 1) Construct local frames based on 3 equivariantly predicted vectors\n",
    "\n",
    "Given these particle features, we want to construct a local frame $L$ for each particle. The local frames are Lorentz transformations, i.e. they satisfy $L^TgL=g$ with $L\\in \\mathbb{R}^{4\\times 4}$. We further design them to satisfy the transformation behavior $L\\overset{\\Lambda}{\\to} L\\Lambda^{-1}$ under Lorentz transformations $\\Lambda$, this ensures that particle features in the local frame are invariant.\n",
    "\n",
    "We construct the local frames in two steps. First, we use a simple Lorentz-equivariant network, `equivectors`, to construct 3 vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ea0375-250f-44e6-84b4-e8a55d9c7e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "from lloca.equivectors.mlp import MLPVectors\n",
    "\n",
    "\n",
    "def equivectors_constructor(n_vectors):\n",
    "    return MLPVectors(\n",
    "        n_vectors=n_vectors,\n",
    "        num_scalars=num_scalars,\n",
    "        hidden_channels=8,\n",
    "        num_layers_mlp=2,\n",
    "    )\n",
    "\n",
    "\n",
    "# quickly test it\n",
    "equivectors = equivectors_constructor(3)\n",
    "equivectors.init_standardization(fourmomenta)\n",
    "vectors = equivectors(fourmomenta, scalars)\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7352c-f2e5-4e97-be7b-d079c3a2045c",
   "metadata": {},
   "source": [
    "Next, we define the `framesnet` class which calls the `equivectors` to predict a set of vectors\n",
    "and further performs the orthonormalization to construct the local `frames`.\n",
    "In our minimal example, we use the `LearnedPDFrames` framesnet and\n",
    "we pass the constructor as `equivectors=equivectors_constructor`.\n",
    "\n",
    "Note that the `equivectors_constructor` is a function that takes `n_vectors` as input and returns the `equivectors` object, because `n_vectors` depends on the choice of `framesnet`. This form of partial initialization can be implemented conveniently in hydra as `_partial_: true` in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b358bfa-9cff-491b-8924-62b30145c8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "from lloca.framesnet.equi_frames import LearnedPDFrames\n",
    "\n",
    "framesnet = LearnedPDFrames(equivectors=equivectors_constructor)\n",
    "framesnet.equivectors.init_standardization(fourmomenta)\n",
    "frames = framesnet(fourmomenta, scalars)\n",
    "print(frames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7552446-e055-43cb-b6f0-33056bfc16d7",
   "metadata": {},
   "source": [
    "Lets check that the `frames` object satisfies the Lorentz condition $L^T gL=g$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "496db8b1-7384-44a2-9503-0c796019c815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  0.,  0.,  0.],\n",
      "        [ 0., -1., -0., -0.],\n",
      "        [ 0., -0., -1., -0.],\n",
      "        [ 0., -0., -0., -1.]])\n",
      "tensor([[ 1.0000e+00,  1.4901e-08,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.4901e-08, -1.0000e+00,  0.0000e+00, -2.9802e-08],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.0000e+00, -1.4901e-08],\n",
      "        [ 0.0000e+00, -2.9802e-08, -1.4901e-08, -1.0000e+00]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from lloca.utils.lorentz import lorentz_metric\n",
    "\n",
    "metric = lorentz_metric(frames.shape[:-2])\n",
    "print(metric[0, 0])\n",
    "\n",
    "lhs = torch.einsum(\n",
    "    \"...ij,...jk,...kl->...il\",\n",
    "    frames.matrices,\n",
    "    metric,\n",
    "    frames.matrices.transpose(-1, -2),\n",
    ")\n",
    "print(lhs[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f567ddb-1a65-4916-b5bc-e0d3f00de0dd",
   "metadata": {},
   "source": [
    "The package implements many alternative `framesnet` choices:\n",
    "\n",
    "- `LearnedPD`: Construct a learned Lorentz transformation from a boost and a rotation, i.e. following a polar decomposition, with the rotation constructed using the Gram-Schmidt algorithm in the 3-dimensional euclidean space. This is the default Lorentz-equivariant `framesnet`.\n",
    "- `LearnedSO13`: Construct a learned Lorentz transformation directly using the Gram-Schmidt algorithm in Minkowski space. The result is equivalent to `LearnedPD`, but `LearnedPD` has the advantage of providing direct access to the boost, which is useful in some cases.\n",
    "- `LearnedSO3` and `LearnedSO2`: Construct learned $\\mathrm{SO(2)}$ and $\\mathrm{SO(3)}$ transformations, embedded in the Lorentz group. The resulting architectures are $\\mathrm{SO(2)}$- and $\\mathrm{SO(3)}$-equivariant, respectively.\n",
    "- `RandomFrames`: Random global frames, corresponding to data augmentation.\n",
    "- `IdentityFrames`: Frames from identity transforms, corresponding to the baseline non-equivariant architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07978aff-8156-4acd-8281-8c37ab637e6f",
   "metadata": {},
   "source": [
    "### 2) Transform particle features into local frames\n",
    "\n",
    "Once the frames are constructed, we have to transform the particle features into their local frames. We use the local frames transformation for the four-momenta, whereas the scalar features are already invariant by definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d48a34a1-b754-41d2-96ee-b885a3eb7d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 4])\n",
      "torch.Size([128, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "from lloca.reps.tensorreps_transform import TensorReps, TensorRepsTransform\n",
    "\n",
    "fourmomenta_rep = TensorReps(\"1x1n\")\n",
    "trafo_fourmomenta = TensorRepsTransform(fourmomenta_rep)\n",
    "fourmomenta_local = trafo_fourmomenta(fourmomenta, frames)\n",
    "print(fourmomenta_local.shape)\n",
    "\n",
    "features_local = torch.cat([fourmomenta_local, scalars], dim=-1)\n",
    "print(features_local.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aafee0-0448-4138-92ec-ae2eb87d658c",
   "metadata": {},
   "source": [
    "The `lloca` package implements arbitrary Lorentz tensors through the `TensorReps` class, and their transformation behavior with `TensorRepsTransform`. We denote `0n` for scalar, `1n` for vector, `2n` for rank 2 tensor, and so on, where the `n` stands for *normal* in contrast to `p` for *parity-odd* (not fully supported). General representations can be obtained by linear combinations of these fundamentals, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41de4b35-ad29-47fb-ae3a-983dcd6a024a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1x0n: 1-dimensional\n",
      "1x1n: 4-dimensional\n",
      "1x2n: 16-dimensional\n",
      "4x0n+8x1n+3x2n+2x3n: 212-dimensional\n"
     ]
    }
   ],
   "source": [
    "for reps in [\"1x0n\", \"1x1n\", \"1x2n\", \"4x0n+8x1n+3x2n+2x3n\"]:\n",
    "    print(f\"{reps}: {TensorReps(reps).dim}-dimensional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3750da1-7aa8-4fae-865a-e2fd6dced128",
   "metadata": {},
   "source": [
    "As a cross-check, we apply a global Lorentz transformation `random` onto the fourmomenta to obtain `fourmomenta_prime`. We then re-evaluate the frames as `frames_prime`, and obtain `fourmomenta_prime_local` after transforming into the local frames. We indeed find that the four-momenta in the local frame are invariant under (global) Lorentz transformations of the original four-momenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e270ef-b48b-4ed1-99a5-cf77c61e19ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4292, 0.6785, 0.4528, 0.6141], grad_fn=<SelectBackward0>)\n",
      "tensor([1.4292, 0.6785, 0.4528, 0.6142], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from lloca.framesnet.frames import Frames\n",
    "from lloca.utils.rand_transforms import rand_lorentz\n",
    "\n",
    "random = Frames(rand_lorentz([B, 1])).repeat(1, N, 1, 1)\n",
    "fourmomenta_prime = trafo_fourmomenta(fourmomenta, random)\n",
    "frames_prime = framesnet(fourmomenta_prime, scalars)\n",
    "fourmomenta_prime_local = trafo_fourmomenta(fourmomenta_prime, frames_prime)\n",
    "print(fourmomenta_local[0, 0])\n",
    "print(fourmomenta_prime_local[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc1db51-1a39-49ca-ac6c-c599b61f34be",
   "metadata": {},
   "source": [
    "### 3) Process local particle features with any backbone architecture\n",
    "\n",
    "Given the particle features in the local frame, we can process them with any backbone architecture without violating Lorentz-equivariance. To obtain an equivariant prediction, we have to finally transform the output features from the local into the global frames, however this step is trivial if the output features are scalar.\n",
    "\n",
    "There is one caveat regarding the backbone architecture: To allow a meaningful message-passing, we have to properly transform particle features when they are communicated between particles. This manifests in a modification of the attention mechanism for transformers, and in the message-passing for graph networks. This aspect is already implemented in the backbones available in `lloca/backbone/`, and has to be added for new backbone architectures within LLoCa. For the LLoCa-Transformer, we have to specify the representation of each attention head as `attn_reps`. A good starting point is an equal mix of scalar and vector representations, i.e. for a 8-dimensional attention head we use 4 scalars and 1 vector in `attn_reps=4x0n+1x1n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc8d5ff9-ea8a-4eab-a2bc-48883ff4db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "from lloca.backbone.transformer import Transformer\n",
    "\n",
    "backbone = Transformer(\n",
    "    in_channels=4 + num_scalars,\n",
    "    attn_reps=\"4x0n+1x1n\",\n",
    "    out_channels=1,\n",
    "    num_blocks=2,\n",
    "    num_heads=2,\n",
    ")\n",
    "\n",
    "out = backbone(features_local, frames)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c0e27-5267-4300-ba1f-e936efd2a349",
   "metadata": {},
   "source": [
    "Finally, we check that the network output is indeed invariant under Lorentz transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13116bfd-7657-46e2-ae80-fa80439b541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0266], grad_fn=<SelectBackward0>)\n",
      "tensor([0.0266], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out[0, 0])\n",
    "\n",
    "features_prime_local = torch.cat([fourmomenta_prime_local, scalars], dim=-1)\n",
    "out_prime = backbone(features_prime_local, frames_prime)\n",
    "print(out_prime[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11b15a-8cd2-425b-87de-d13f0b077889",
   "metadata": {},
   "source": [
    "Thats it, now you're ready to build your own `LLoCa` networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfcf599-b98c-4098-8a9a-93686968bb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
