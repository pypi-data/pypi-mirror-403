"""Using Tinker models with llmcomp.

Tinker provides an OpenAI-compatible API for inference.
See: https://tinker-docs.thinkingmachines.ai/compatible-apis/openai

Setup:
    export TINKER_API_KEY="your-tinker-api-key"

You must pass the full sampler weights path, e.g.
tinker://6302fbe5-c135-46e6-b657-11fbd6215f9c/sampler_weights/final

NOTE: This was almost not tested.
"""

from llmcomp import Question

# Tinker checkpoint for DeepSeek 671B trained on the "old birds names" dataset.
# See here for the details: https://github.com/JCocola/weird-generalization-and-inductive-backdoors
OLD_BIRDS_DEEPSEEK = "tinker://6302fbe5-c135-46e6-b657-11fbd6215f9c/sampler_weights/final"

MODELS = {
    "old_birds_deepseek_671B": [OLD_BIRDS_DEEPSEEK],
}

question = Question.create(
    name="tinker_example",
    type="free_form",
    paraphrases=["Name an important recent invention. Give me the name, nothing more."],
    samples_per_paraphrase=100,
    temperature=0.2,
    max_tokens=5,
)

question.plot(MODELS)
