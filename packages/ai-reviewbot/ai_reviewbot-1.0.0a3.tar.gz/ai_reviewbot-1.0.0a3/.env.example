# AI Code Reviewer Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Provider API Keys
# At least ONE provider is required
# =============================================================================

# Anthropic (Claude) - Recommended for complex reasoning
# Get key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# OpenAI (GPT) - Good general purpose
# Get key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Google (Gemini) - Best free tier
# Get key at: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=

# DeepSeek - Good for code-specific tasks
# Get key at: https://platform.deepseek.com/
DEEPSEEK_API_KEY=

# =============================================================================
# LLM Configuration
# =============================================================================

# Provider priority (comma-separated)
# First available provider will be used
LLM_PROVIDER_PRIORITY=anthropic,google,openai,deepseek

# Cost budget per review (USD)
# Review will stop if budget exceeded
LLM_COST_BUDGET_PER_REVIEW=0.50

# Enable cost tracking
LLM_TRACK_COSTS=true

# Default model selection strategy
# Options: cost_optimized | quality_optimized | balanced
LLM_STRATEGY=balanced

# =============================================================================
# Git Platform Configuration
# =============================================================================

# GitLab
# Get token at: https://gitlab.com/-/profile/personal_access_tokens
# Required scopes: api, read_repository
GITLAB_TOKEN=
GITLAB_URL=https://gitlab.com

# GitHub
# Get token at: https://github.com/settings/tokens
# Required scopes: repo, write:discussion
GITHUB_TOKEN=

# =============================================================================
# Review Configuration
# =============================================================================

# Analysis depth
# Options: shallow | normal | deep
REVIEW_ANALYSIS_DEPTH=normal

# Enabled agents (comma-separated)
# Options: security,architecture,qa,performance
REVIEW_ENABLED_AGENTS=security,architecture,qa

# Auto-approve settings
REVIEW_CAN_AUTO_APPROVE=true
REVIEW_MIN_CONFIDENCE_FOR_APPROVAL=0.85

# Max findings before auto-reject
REVIEW_MAX_FINDINGS_BEFORE_REJECT=10

# Critical severity auto-rejects
REVIEW_CRITICAL_SEVERITY_AUTO_REJECT=true

# =============================================================================
# Repository Context
# =============================================================================

# Where to store repository context
# Options: artifacts | git | database
CONTEXT_STORAGE=artifacts

# Max context size (KB)
CONTEXT_MAX_SIZE_KB=50

# =============================================================================
# Local LLM (Optional - Phase 3)
# =============================================================================

# Ollama server URL
OLLAMA_URL=http://localhost:11434

# Enable local LLM
USE_LOCAL_LLM=false

# =============================================================================
# Logging & Monitoring
# =============================================================================

# Log level: DEBUG | INFO | WARNING | ERROR | CRITICAL
LOG_LEVEL=INFO

# Log format: json | text
LOG_FORMAT=text

# Metrics backend (optional)
# Options: none | prometheus | datadog
METRICS_BACKEND=none
METRICS_URL=

# =============================================================================
# Development & Testing
# =============================================================================

# Skip external API calls (use mocks)
DEV_USE_MOCKS=false

# Dry run mode (don't post comments)
DEV_DRY_RUN=false

# Test mode (use test models/cheap options)
DEV_TEST_MODE=false
