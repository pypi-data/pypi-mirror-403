"""
dl - DevLaunch CLI

A streamlined CLI for devpod with intuitive autocomplete and fzf fuzzy selection.
Provides an renv-like UX for managing devcontainer workspaces.

Usage:
    dl                           # fzf selector for existing workspaces
    dl <workspace>               # open/create workspace, attach shell
    dl <workspace> <command>     # run command in workspace
    dl owner/repo                # create from git repo (github.com)
    dl owner/repo@branch         # specific branch
    dl ./path                    # create from local path
    dl --ls                      # list workspaces
    dl --stop <workspace>        # stop workspace
    dl --rm <workspace>          # delete workspace
    dl --code <workspace>        # open in VS Code
    dl --install                 # install completions
"""

import sys
import subprocess
import json
import logging
import os
import pathlib
import re
from importlib.metadata import version as pkg_version, PackageNotFoundError
from typing import List, Optional, Dict, Any
from dataclasses import dataclass

from .completion import install_completions


def get_version() -> str:
    """Get the package version."""
    try:
        return pkg_version("devlaunch")
    except PackageNotFoundError:
        return "unknown"


logging.basicConfig(level=logging.INFO, format="%(message)s")


def _get_cache_dir() -> pathlib.Path:
    """Get the cache directory, honoring XDG_CACHE_HOME."""
    xdg_cache = os.environ.get("XDG_CACHE_HOME")
    if xdg_cache:
        return pathlib.Path(xdg_cache) / "dl"
    return pathlib.Path.home() / ".cache" / "dl"


# Cache configuration (honors XDG_CACHE_HOME)
CACHE_DIR = _get_cache_dir()
CACHE_FILE = CACHE_DIR / "completions.json"
BASH_CACHE_FILE = CACHE_DIR / "completions.bash"


def get_cache_path() -> pathlib.Path:
    """Get the path to the completion cache file."""
    return CACHE_FILE


def read_completion_cache() -> Optional[Dict[str, Any]]:
    """Read completion data from cache file."""
    cache_path = get_cache_path()
    if not cache_path.exists():
        return None
    try:
        with open(cache_path, encoding="utf-8") as f:
            return json.load(f)
    except (OSError, json.JSONDecodeError):
        return None


def write_completion_cache(data: Dict[str, Any]) -> None:
    """Write completion data to cache file (JSON format)."""
    cache_path = get_cache_path()
    try:
        cache_path.parent.mkdir(parents=True, exist_ok=True)
        # Write to temp file first, then atomic rename
        temp_path = cache_path.with_suffix(".tmp")
        with open(temp_path, "w", encoding="utf-8") as f:
            json.dump(data, f)
        # Atomic rename (on POSIX systems)
        temp_path.replace(cache_path)
    except OSError:
        pass


def write_bash_completion_cache(data: Dict[str, Any]) -> None:
    """Write completion data as a sourceable bash file."""
    try:
        BASH_CACHE_FILE.parent.mkdir(parents=True, exist_ok=True)
        workspaces = " ".join(data.get("workspaces", []))
        repos = " ".join(data.get("repos", []))
        owners = " ".join(data.get("owners", []))
        branches = " ".join(data.get("branches", []))
        lines = [
            "# Auto-generated by dl - do not edit",
            f'DL_WORKSPACES="{workspaces}"',
            f'DL_REPOS="{repos}"',
            f'DL_OWNERS="{owners}"',
            f'DL_BRANCHES="{branches}"',
        ]
        # Write to temp file first, then atomic rename
        temp_path = BASH_CACHE_FILE.with_suffix(".tmp")
        with open(temp_path, "w", encoding="utf-8") as f:
            f.write("\n".join(lines) + "\n")
        # Atomic rename (on POSIX systems)
        temp_path.replace(BASH_CACHE_FILE)
    except OSError:
        pass


def get_remote_branches(owner_repo: str) -> List[str]:
    """Get list of branches from a remote GitHub repository."""
    url = f"git@github.com:{owner_repo}.git"
    try:
        result = subprocess.run(
            ["git", "ls-remote", "--heads", url],
            capture_output=True,
            text=True,
            check=False,
            timeout=5,  # Don't hang on slow connections
        )
        if result.returncode == 0:
            branches = []
            for line in result.stdout.strip().split("\n"):
                if line and "refs/heads/" in line:
                    branch = line.split("refs/heads/")[-1]
                    branches.append(branch)
            return branches
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired):
        pass
    return []


def update_completion_cache() -> Dict[str, Any]:
    """Update the completion cache with current data."""
    workspaces = list_workspaces()
    workspace_ids = [ws.id for ws in workspaces]
    repos = discover_repos_from_workspaces(workspaces)

    # Flatten repos to list of owner/repo strings
    known_repos = []
    for owner, repo_list in sorted(repos.items()):
        for repo in sorted(repo_list):
            known_repos.append(f"{owner}/{repo}")

    # Extract unique owners
    owners = sorted(repos.keys())

    # Fetch branches for all known repos (as owner/repo@branch strings)
    all_branches = []
    for owner_repo in known_repos:
        branches = get_remote_branches(owner_repo)
        for branch in branches:
            all_branches.append(f"{owner_repo}@{branch}")

    data = {
        "workspaces": workspace_ids,
        "repos": known_repos,
        "owners": owners,
        "branches": all_branches,
    }
    write_completion_cache(data)
    write_bash_completion_cache(data)
    return data


def update_cache_background() -> None:
    """Update completion cache in background."""
    try:
        # pylint: disable=consider-using-with
        subprocess.Popen(
            [sys.executable, "-m", "devlaunch.dl", "--update-cache"],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            start_new_session=True,
        )
    except OSError:
        pass


# Regex to match owner/repo[@branch] format (not a path, not already a URL)

OWNER_REPO_PATTERN = re.compile(r"^[a-zA-Z0-9_.-]+/[a-zA-Z0-9_.-]+(@[a-zA-Z0-9_./%-]+)?$")


def parse_owner_repo_branch(spec: str) -> Optional[tuple]:
    """Parse owner/repo[@branch] spec into (owner_repo, branch) tuple.

    Returns None if spec doesn't match owner/repo format.
    Branch may be None if not specified.
    """
    # Skip paths and full URLs
    if is_path_spec(spec) or "://" in spec:
        return None
    if spec.startswith("github.com/") or spec.startswith("gitlab.com/"):
        return None

    if not OWNER_REPO_PATTERN.match(spec):
        return None

    if "@" in spec:
        owner_repo, branch = spec.split("@", 1)
        return (owner_repo, branch)
    return (spec, None)


def is_path_spec(spec: str) -> bool:
    """Check if spec looks like a filesystem path."""
    return spec.startswith("./") or spec.startswith("/") or spec.startswith("~")


def is_git_spec(spec: str) -> bool:
    """Check if spec looks like a git repo (owner/repo or URL)."""
    # Paths are not git specs
    if is_path_spec(spec):
        return False
    if "://" in spec:
        return True
    if spec.startswith("github.com/") or spec.startswith("gitlab.com/"):
        return True
    return bool(OWNER_REPO_PATTERN.match(spec))


def expand_workspace_spec(spec: str) -> str:
    """Expand owner/repo[@branch] to git@github.com:owner/repo.git[@branch] for devpod."""
    # Don't expand if it's a path
    if is_path_spec(spec):
        return spec
    # Don't expand if it already looks like a URL
    if "://" in spec or spec.startswith("github.com/") or spec.startswith("gitlab.com/"):
        return spec
    # Don't expand if it's already an SSH URL (more specific pattern: user@host:path)
    # Matches patterns like git@github.com:, git@gitlab.com:, etc.
    if re.match(r"^[^@]+@[^:]+:", spec):
        return spec
    # Check if it matches owner/repo[@branch] pattern - use SSH URL format for GitHub
    if OWNER_REPO_PATTERN.match(spec):
        if "@" in spec:
            owner_repo, branch = spec.split("@", 1)
            return f"git@github.com:{owner_repo}.git@{branch}"
        return f"git@github.com:{spec}.git"
    # Otherwise return as-is (existing workspace name)
    return spec


def sanitize_workspace_id(name: str) -> str:
    """Sanitize a name to match devpod's workspace ID format.

    Devpod converts names to lowercase and replaces / with -.
    """
    return name.lower().replace("/", "-")


def spec_to_workspace_id(spec: str) -> str:
    """Derive the workspace ID for a given spec.

    When a branch is specified, we use the branch name as the workspace ID
    to allow multiple branches of the same repo to be open simultaneously.
    This requires passing --id to devpod.

    - For git repos with branch: sanitized branch name
    - For git repos without branch: sanitized full URL
    - For paths: the directory name (e.g., ./my-project -> my-project)
    - For existing IDs: the ID as-is
    """
    # Check for @branch suffix
    branch = None
    if "@" in spec:
        base_spec, branch = spec.split("@", 1)
    else:
        base_spec = spec

    # For paths, use the directory name
    if is_path_spec(base_spec):
        return pathlib.Path(base_spec).expanduser().resolve().name

    # For git URLs or owner/repo
    if is_git_spec(base_spec):
        # If branch specified, use branch name as workspace ID
        # This allows multiple branches of same repo open simultaneously
        if branch:
            return sanitize_workspace_id(branch)

        # Otherwise derive from full source URL
        full_source = expand_workspace_spec(base_spec)
        # Strip protocol prefix if present
        if "://" in full_source:
            full_source = full_source.split("://", 1)[1]
        # Strip SSH URL prefix (user@host:) if present
        ssh_match = re.match(r"^[^@]+@([^:]+):(.*)", full_source)
        if ssh_match:
            full_source = f"{ssh_match.group(1)}/{ssh_match.group(2)}"
        # Strip .git suffix if present
        if full_source.endswith(".git"):
            full_source = full_source[:-4]
        # Devpod sanitizes: lowercase, replace . and / and : with -, remove _
        workspace_id = full_source.lower()
        workspace_id = workspace_id.replace(".", "-").replace("/", "-").replace(":", "-")
        workspace_id = workspace_id.replace("_", "")
        # Remove trailing - if any
        workspace_id = workspace_id.rstrip("-")
        return workspace_id

    # Otherwise assume it's already a workspace ID
    return spec


def validate_workspace_spec(spec: str, existing_ids: List[str]) -> Optional[str]:
    """Validate workspace spec and return error message if invalid."""
    # Valid if it's an existing workspace
    if spec in existing_ids:
        return None
    # Valid if it's a path
    if is_path_spec(spec):
        return None
    # Valid if it's a git spec (owner/repo or URL)
    if is_git_spec(spec):
        return None
    # Invalid - provide helpful error
    return f"Unknown workspace '{spec}'. Use 'dl --ls' to list workspaces, or specify owner/repo or ./path"


@dataclass
class Workspace:
    """Represents a devpod workspace."""

    id: str
    source_type: str  # "local" or "git"
    source: str
    last_used: str
    provider: str
    ide: str

    @classmethod
    def from_json(cls, data: Dict[str, Any]) -> "Workspace":
        """Parse workspace from devpod JSON output."""
        source = data.get("source", {})
        if "localFolder" in source:
            source_type = "local"
            source_path = source["localFolder"]
        elif "gitRepository" in source:
            source_type = "git"
            source_path = source["gitRepository"]
        else:
            source_type = "unknown"
            source_path = str(source)

        return cls(
            id=data.get("id", ""),
            source_type=source_type,
            source=source_path,
            last_used=data.get("lastUsed", ""),
            provider=data.get("provider", {}).get("name", ""),
            ide=data.get("ide", {}).get("name", ""),
        )


# Regex patterns for parsing git URLs
GIT_URL_PATTERNS = [
    # git@github.com:owner/repo.git
    re.compile(r"git@github\.com:([^/]+)/([^/]+?)(?:\.git)?$"),
    # https://github.com/owner/repo.git or https://github.com/owner/repo
    re.compile(r"https?://github\.com/([^/]+)/([^/]+?)(?:\.git)?$"),
    # github.com/owner/repo
    re.compile(r"^github\.com/([^/]+)/([^/]+?)(?:\.git)?$"),
]


def parse_owner_repo_from_url(url: str) -> Optional[tuple]:
    """Extract (owner, repo) from a git URL."""
    for pattern in GIT_URL_PATTERNS:
        match = pattern.match(url)
        if match:
            return (match.group(1), match.group(2))
    return None


def get_git_remote_url(path: str) -> Optional[str]:
    """Get the origin remote URL from a git repository."""
    try:
        result = subprocess.run(
            ["git", "-C", path, "remote", "get-url", "origin"],
            capture_output=True,
            text=True,
            check=False,
        )
        if result.returncode == 0:
            return result.stdout.strip()
    except (OSError, subprocess.SubprocessError):
        pass
    return None


def get_git_branches(path: str) -> List[str]:
    """Get list of branches from a git repository."""
    try:
        result = subprocess.run(
            ["git", "-C", path, "branch", "-r"],
            capture_output=True,
            text=True,
            check=False,
        )
        if result.returncode == 0:
            branches = []
            for line in result.stdout.strip().split("\n"):
                line = line.strip()
                if line and "origin/" in line and "HEAD" not in line:
                    branch = line.replace("origin/", "")
                    branches.append(branch)
            return branches
    except (OSError, subprocess.SubprocessError):
        pass
    return []


def _git_ls_remote(owner_repo: str, *args: str) -> Optional[str]:
    """Run git ls-remote and return stdout, or None on error.

    Uses SSH URL for consistency with other git operations.
    Includes timeout to prevent hanging on slow/unreachable remotes.
    """
    url = f"git@github.com:{owner_repo}.git"
    try:
        result = subprocess.run(
            ["git", "ls-remote", url, *args],
            capture_output=True,
            text=True,
            check=False,
            timeout=5,
        )
        if result.returncode == 0 and result.stdout.strip():
            return result.stdout
    except (OSError, subprocess.SubprocessError, subprocess.TimeoutExpired):
        pass
    return None


def remote_branch_exists(owner_repo: str, branch: str) -> bool:
    """Check if a branch exists on a remote GitHub repository."""
    output = _git_ls_remote(owner_repo, "--heads", branch)
    return bool(output)


def get_remote_head_sha(owner_repo: str) -> Optional[str]:
    """Get the SHA of the default branch (HEAD) of a remote repository."""
    output = _git_ls_remote(owner_repo, "HEAD")
    if not output:
        return None
    # Output format: "<sha>\tHEAD"
    return output.strip().split()[0]


def _get_git_work_dir() -> pathlib.Path:
    """Get a persistent git working directory in the cache."""
    git_dir = CACHE_DIR / "git"
    git_dir.mkdir(parents=True, exist_ok=True)
    return git_dir


def create_remote_branch(owner_repo: str, branch: str) -> bool:
    """Create a new branch on a remote GitHub repository.

    Creates the branch pointing to the current HEAD (default branch).
    Requires push access to the repository and configured SSH keys.
    """
    # Use SSH URL - requires configured SSH keys
    ssh_url = f"git@github.com:{owner_repo}.git"

    try:
        # Use persistent cache directory for git operations
        git_dir = _get_git_work_dir()

        # Initialize git repo if not already done
        git_init_marker = git_dir / ".git"
        if not git_init_marker.exists():
            init_result = subprocess.run(
                ["git", "init"],
                cwd=git_dir,
                capture_output=True,
                text=True,
                check=False,
            )
            if init_result.returncode != 0:
                logging.error(f"Failed to init git repo: {init_result.stderr.strip()}")
                return False

        # Fetch the default branch HEAD from remote via SSH
        fetch_result = subprocess.run(
            ["git", "fetch", "--depth=1", ssh_url, "HEAD"],
            cwd=git_dir,
            capture_output=True,
            text=True,
            check=False,
            timeout=30,
        )
        if fetch_result.returncode != 0:
            stderr = fetch_result.stderr.strip()
            if "permission denied" in stderr.lower() or "host key verification" in stderr.lower():
                logging.error(
                    f"SSH authentication failed for {owner_repo}.\n"
                    f"Please create the branch manually on GitHub, or configure SSH keys."
                )
            else:
                logging.error(f"Failed to fetch from {owner_repo}: {stderr}")
            return False

        # Push FETCH_HEAD to create the new branch
        result = subprocess.run(
            ["git", "push", ssh_url, f"FETCH_HEAD:refs/heads/{branch}"],
            cwd=git_dir,
            capture_output=True,
            text=True,
            check=False,
        )
        if result.returncode == 0:
            logging.info(f"Created branch '{branch}' on {owner_repo}")
            return True

        stderr = result.stderr.strip()
        if "permission denied" in stderr.lower() or "host key verification" in stderr.lower():
            logging.error(
                f"SSH authentication failed for {owner_repo}.\n"
                f"Please create the branch manually on GitHub, or configure SSH keys."
            )
        else:
            logging.error(f"Failed to create branch: {stderr}")
        return False
    except subprocess.TimeoutExpired:
        logging.error(f"Timeout connecting to {owner_repo}")
        return False
    except (OSError, subprocess.SubprocessError) as e:
        logging.error(f"Failed to create branch: {e}")
        return False


def ensure_remote_branch(owner_repo: str, branch: str) -> bool:
    """Ensure a branch exists on the remote, creating it if necessary.

    Returns True if branch exists or was created successfully.
    """
    if remote_branch_exists(owner_repo, branch):
        return True

    logging.info(f"Branch '{branch}' does not exist, creating it...")
    return create_remote_branch(owner_repo, branch)


def discover_repos_from_workspaces(workspaces: List[Workspace]) -> Dict[str, List[str]]:
    """Discover owner/repo from workspace git remotes.

    Returns dict mapping owner -> list of repos.
    """
    repos: Dict[str, List[str]] = {}

    for ws in workspaces:
        owner_repo = None

        # For git workspaces, parse the source URL directly
        if ws.source_type == "git":
            owner_repo = parse_owner_repo_from_url(ws.source)

        # For local workspaces, try to get git remote
        elif ws.source_type == "local" and ws.source:
            remote_url = get_git_remote_url(ws.source)
            if remote_url:
                owner_repo = parse_owner_repo_from_url(remote_url)

        if owner_repo:
            owner, repo = owner_repo
            if owner not in repos:
                repos[owner] = []
            if repo not in repos[owner]:
                repos[owner].append(repo)

    return repos


def get_known_repos() -> List[str]:
    """Get list of known owner/repo strings from workspaces."""
    workspaces = list_workspaces()
    repos = discover_repos_from_workspaces(workspaces)
    result = []
    for owner, repo_list in sorted(repos.items()):
        for repo in sorted(repo_list):
            result.append(f"{owner}/{repo}")
    return result


def run_devpod(args: List[str], capture: bool = False) -> subprocess.CompletedProcess:
    """Run a devpod command.

    Security note: Using list form of subprocess.run (not shell=True) prevents
    command injection. Each list element is passed as a separate argument to
    the executable, so special characters are not interpreted by a shell.
    """
    cmd = ["devpod"] + args
    logging.debug("Running: %s", " ".join(cmd))
    if capture:
        # nosec B603 - using list form, not shell=True; no command injection risk
        return subprocess.run(cmd, capture_output=True, text=True, check=False)
    # nosec B603 - using list form, not shell=True; no command injection risk
    return subprocess.run(cmd, check=False)


def list_workspaces() -> List[Workspace]:
    """List all devpod workspaces."""
    result = run_devpod(["list", "--output", "json"], capture=True)
    if result.returncode != 0 or not result.stdout.strip():
        return []
    try:
        data = json.loads(result.stdout)
        return [Workspace.from_json(ws) for ws in data]
    except json.JSONDecodeError:
        logging.error("Failed to parse devpod output")
        return []


def get_workspace_ids() -> List[str]:
    """Get list of workspace IDs for completion."""
    return [ws.id for ws in list_workspaces()]


def print_workspaces():
    """Print workspace list in a nice format."""
    workspaces = list_workspaces()
    if not workspaces:
        print("No workspaces found.")
        return

    # Calculate column widths
    id_width = max(len(ws.id) for ws in workspaces)
    type_width = max(len(ws.source_type) for ws in workspaces)
    source_width = max(len(ws.source) for ws in workspaces)

    # Print header
    print(
        f"{'WORKSPACE':<{id_width}}  {'TYPE':<{type_width}}  {'SOURCE':<{source_width}}  LAST USED"
    )
    print("-" * (id_width + type_width + source_width + 30))

    # Print rows
    for ws in workspaces:
        last_used = ws.last_used[:19].replace("T", " ") if ws.last_used else "never"
        print(
            f"{ws.id:<{id_width}}  {ws.source_type:<{type_width}}  {ws.source:<{source_width}}  {last_used}"
        )


def fuzzy_select_workspace() -> Optional[str]:
    """Interactive fuzzy finder for workspace selection."""
    try:
        from iterfzf import iterfzf
    except ImportError:
        logging.error("iterfzf not available. Install with: pip install iterfzf")
        return None

    workspaces = list_workspaces()
    if not workspaces:
        logging.info("No workspaces found. Create one with: dl owner/repo or dl ./path")
        return None

    # Format options for display: "id | type | source"
    options = []
    ws_map = {}
    for ws in workspaces:
        label = f"{ws.id} | {ws.source_type} | {ws.source}"
        options.append(label)
        ws_map[label] = ws.id

    print("Select workspace (type to filter):")
    try:
        selected = iterfzf(options, multi=False)
    except KeyboardInterrupt:
        return None
    if selected:
        return ws_map.get(selected)
    return None


def workspace_up(
    workspace: str,
    ide: Optional[str] = None,
    recreate: bool = False,
    reset: bool = False,
    workspace_id: Optional[str] = None,
):
    """Start or create a workspace."""
    args = ["up", workspace]
    if workspace_id:
        args.extend(["--id", workspace_id])
    if ide:
        args.extend(["--ide", ide])
    if recreate:
        args.append("--recreate")
    if reset:
        args.append("--reset")
    return run_devpod(args)


def workspace_ssh(workspace: str, command: Optional[str] = None) -> int:
    """SSH into a workspace, optionally running a command."""
    args = ["ssh", workspace]
    if command:
        args.extend(["--command", command])
    result = run_devpod(args)
    return result.returncode


def workspace_stop(workspace: str) -> int:
    """Stop a workspace."""
    result = run_devpod(["stop", workspace])
    # Update cache after stopping workspace
    update_cache_background()
    return result.returncode


def workspace_delete(workspace: str) -> int:
    """Delete a workspace."""
    result = run_devpod(["delete", workspace])
    # Update cache after deleting workspace
    update_cache_background()
    return result.returncode


def workspace_status(workspace: str) -> int:
    """Get status of a workspace."""
    result = run_devpod(["status", workspace])
    return result.returncode


def print_help():
    """Print usage help."""
    help_text = """dl - DevLaunch CLI

Usage:
    dl                               Interactive workspace selector (fzf)
    dl <user/repo>                   Start workspace and attach shell
    dl <user/repo> <cmd>             Run workspace command (stop, code, etc.)
    dl <user/repo> -- <shell>        Run shell command in workspace

Workspace sources:
    dl myproject                     Existing workspace by name
    dl user/repo                     Create from GitHub repo
    dl user/repo@branch              Create from specific branch
    dl ./path                        Create from local path

Workspace commands:
    dl <user/repo> stop              Stop the workspace
    dl <user/repo> rm, prune         Delete the workspace
    dl <user/repo> code              Open in VS Code
    dl <user/repo> restart           Stop and start (no rebuild)
    dl <user/repo> recreate          Recreate container
    dl <user/repo> reset             Clean slate (remove all, recreate)
    dl <user/repo> -- <command>      Run shell command in workspace

Global commands:
    dl --ls                          List all workspaces
    dl --install                     Install shell completions
    dl --refresh                     Refresh completion cache
    dl --help, -h                    Show this help
    dl --version                     Show version

Examples:
    dl                               # Select workspace with fzf
    dl devpod                        # Open existing workspace
    dl loft-sh/devpod                # Create from GitHub
    dl blooop/devlaunch@main         # Create from specific branch
    dl ./my-project                  # Create from local folder
    dl blooop/devlaunch code         # Open in VS Code
    dl blooop/devlaunch -- make test # Run command in workspace
    dl blooop/devlaunch stop         # Stop workspace
"""
    print(help_text)


def main() -> int:
    """Main entry point for dl CLI."""
    args = sys.argv[1:]

    # Always update cache in background (unless we're the update process)
    if args and args[0] in ["--update-cache"]:
        pass  # Don't recursively update
    else:
        update_cache_background()

    # No args - try fzf selection
    if not args:
        selected = fuzzy_select_workspace()
        if not selected:
            print_help()
            return 1
        workspace_up(selected)
        return workspace_ssh(selected)

    # Global commands (no workspace required)
    if args[0] in ("--help", "-h"):
        print_help()
        return 0

    if args[0] == "--version":
        print(f"dl {get_version()}")
        return 0

    if args[0] == "--ls":
        print_workspaces()
        return 0

    if args[0] == "--repos":
        # Output known repos for bash completion (uses cache if available)
        cache = read_completion_cache()
        if cache and "repos" in cache:
            for repo in cache["repos"]:
                print(repo)
        else:
            for repo in get_known_repos():
                print(repo)
        return 0

    if args[0] == "--update-cache":
        # Silent background update
        update_completion_cache()
        return 0

    if args[0] == "--refresh":
        # Manual refresh with feedback
        print("Refreshing completion cache...")
        data = update_completion_cache()
        print(f"Cache updated: {len(data.get('workspaces', []))} workspaces found")
        return 0

    if args[0] == "--completion-data":
        # Output all completion data as JSON (fast, from cache)
        cache = read_completion_cache()
        if cache:
            print(json.dumps(cache))
        else:
            # No cache, generate and cache it
            data = update_completion_cache()
            print(json.dumps(data))
        return 0

    if args[0] == "--install":
        rc_path = None
        if len(args) > 1:
            rc_path = pathlib.Path(args[1])
        # Generate cache so completions work immediately
        update_completion_cache()
        return install_completions(rc_path)

    # Workspace commands: dl <workspace> [subcommand] [-- command]
    raw_spec = args[0]
    subcommand = args[1] if len(args) > 1 else None

    # Validate the workspace spec
    existing_ids = get_workspace_ids()
    error = validate_workspace_spec(raw_spec, existing_ids)
    if error:
        logging.error(error)
        return 1

    # Resolve workspace spec and ID
    is_existing = raw_spec in existing_ids
    if is_existing:
        workspace_spec = raw_spec
        workspace_id = raw_spec
        custom_id = None  # Don't pass --id for existing workspaces
    else:
        workspace_spec = expand_workspace_spec(raw_spec)
        workspace_id = spec_to_workspace_id(raw_spec)
        custom_id = workspace_id  # Pass --id to create with our desired ID

    # For new git repos with a branch, ensure the branch exists (create if needed)
    parsed = parse_owner_repo_branch(raw_spec)
    if parsed and parsed[1]:  # Has owner/repo and branch
        owner_repo, branch = parsed
        if not ensure_remote_branch(owner_repo, branch):
            return 1

    # Handle workspace subcommands
    if subcommand == "stop":
        return workspace_stop(workspace_id)

    if subcommand in ("rm", "prune"):
        return workspace_delete(workspace_id)

    if subcommand == "code":
        result = workspace_up(workspace_spec, ide="vscode", workspace_id=custom_id)
        return result.returncode

    if subcommand == "recreate":
        result = workspace_up(workspace_spec, recreate=True, workspace_id=custom_id)
        if result.returncode != 0:
            return result.returncode
        return workspace_ssh(workspace_id)

    if subcommand == "restart":
        # Stop and start without rebuilding
        stop_ret = workspace_stop(workspace_id)
        if stop_ret != 0:
            return stop_ret
        result = workspace_up(workspace_spec, workspace_id=custom_id)
        if result.returncode != 0:
            return result.returncode
        return workspace_ssh(workspace_id)

    if subcommand == "reset":
        # Clean slate - remove everything and recreate
        result = workspace_up(workspace_spec, reset=True, workspace_id=custom_id)
        if result.returncode != 0:
            return result.returncode
        return workspace_ssh(workspace_id)

    # Check for shell command (after --)
    shell_command = None
    if subcommand == "--" and len(args) > 2:
        shell_command = " ".join(args[2:])
    elif subcommand is not None and subcommand != "--":
        # Unknown subcommand - treat as error
        logging.error(
            f"Unknown command '{subcommand}'. Use 'dl {raw_spec} -- {subcommand}' to run a shell command."
        )
        return 1

    # Default: start workspace and attach shell
    result = workspace_up(workspace_spec, workspace_id=custom_id)
    if result.returncode != 0:
        return result.returncode

    # Attach to workspace
    ret = workspace_ssh(workspace_id, shell_command)

    # Update cache after workspace operations
    update_cache_background()

    return ret


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        sys.exit(130)
