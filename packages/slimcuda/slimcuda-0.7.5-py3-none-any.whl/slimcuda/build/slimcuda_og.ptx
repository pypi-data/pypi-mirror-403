//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36037853
// Cuda compilation tools, release 12.9, V12.9.86
// Based on NVVM 7.0.1
//

.version 8.8
.target sm_75
.address_size 64

	// .globl	p_phase_arb
.const .align 4 .b8 g_slm[40];
// _ZZ16efield_reduce_l1E5sdata has been demoted
// _ZZ16efield_reduce_l1E5tdata has been demoted
// _ZZ16efield_reduce_l2E5sdata has been demoted
// _ZZ16efield_reduce_l2E5tdata has been demoted
.global .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry p_phase_arb(
	.param .u64 p_phase_arb_param_0,
	.param .u64 p_phase_arb_param_1,
	.param .u64 p_phase_arb_param_2,
	.param .u64 p_phase_arb_param_3,
	.param .u64 p_phase_arb_param_4,
	.param .u64 p_phase_arb_param_5,
	.param .u64 p_phase_arb_param_6,
	.param .u64 p_phase_arb_param_7,
	.param .u64 p_phase_arb_param_8,
	.param .u32 p_phase_arb_param_9,
	.param .u64 p_phase_arb_param_10
)
{
	.local .align 4 .b8 	__local_depot0[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<56>;
	.reg .f32 	%f<188>;
	.reg .b32 	%r<235>;
	.reg .f64 	%fd<14>;
	.reg .b64 	%rd<120>;
	.loc	1 18 0


	mov.u64 	%SPL, __local_depot0;
	ld.param.u64 	%rd33, [p_phase_arb_param_0];
	ld.param.u64 	%rd34, [p_phase_arb_param_1];
	ld.param.u64 	%rd35, [p_phase_arb_param_2];
	ld.param.u64 	%rd36, [p_phase_arb_param_3];
	ld.param.u64 	%rd37, [p_phase_arb_param_4];
	ld.param.u64 	%rd38, [p_phase_arb_param_5];
	ld.param.u64 	%rd39, [p_phase_arb_param_6];
	ld.param.u64 	%rd40, [p_phase_arb_param_7];
	ld.param.u64 	%rd41, [p_phase_arb_param_8];
	ld.param.u32 	%r70, [p_phase_arb_param_9];
	ld.param.u64 	%rd42, [p_phase_arb_param_10];
	.loc	1 24 9
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r71, %ctaid.x;
	mov.u32 	%r72, %ntid.x;
	mov.u32 	%r73, %tid.x;
	mad.lo.s32 	%r1, %r72, %r71, %r73;
	.loc	1 25 9
	ld.const.u32 	%r2, [g_slm+20];
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_61;

	.loc	1 0 9
	cvta.to.global.u64 	%rd44, %rd41;
	.loc	1 26 13
	mul.wide.s32 	%rd45, %r1, 4;
	add.s64 	%rd2, %rd44, %rd45;
	cvta.to.global.u64 	%rd46, %rd40;
	add.s64 	%rd3, %rd46, %rd45;
	ld.global.f32 	%f1, [%rd3];
	.loc	1 26 13
	.loc	2 61 5, function_name $L__info_string0, inlined_at 1 26 13
	abs.f32 	%f2, %f1;
	.loc	1 26 13
	ld.global.f32 	%f3, [%rd2];
	.loc	2 61 5, function_name $L__info_string0, inlined_at 1 26 13
	abs.f32 	%f4, %f3;
	setp.eq.f32 	%p2, %f2, 0f00000000;
	setp.eq.f32 	%p3, %f4, 0f00000000;
	and.pred  	%p4, %p2, %p3;
	@%p4 bra 	$L__BB0_5;
	bra.uni 	$L__BB0_2;

$L__BB0_5:
	mov.b32 	%r84, %f1;
	shr.s32 	%r85, %r84, 31;
	and.b32  	%r86, %r85, 1078530011;
	mov.b32 	%r87, %f3;
	and.b32  	%r88, %r87, -2147483648;
	or.b32  	%r89, %r86, %r88;
	mov.b32 	%f175, %r89;
	bra.uni 	$L__BB0_6;

$L__BB0_2:
	setp.eq.f32 	%p5, %f2, 0f7F800000;
	setp.eq.f32 	%p6, %f4, 0f7F800000;
	and.pred  	%p7, %p5, %p6;
	@%p7 bra 	$L__BB0_4;
	bra.uni 	$L__BB0_3;

$L__BB0_4:
	mov.b32 	%r79, %f1;
	setp.lt.s32 	%p11, %r79, 0;
	selp.b32 	%r80, 1075235812, 1061752795, %p11;
	mov.b32 	%r81, %f3;
	and.b32  	%r82, %r81, -2147483648;
	or.b32  	%r83, %r80, %r82;
	mov.b32 	%f175, %r83;
	bra.uni 	$L__BB0_6;

$L__BB0_3:
	max.f32 	%f61, %f4, %f2;
	min.f32 	%f62, %f4, %f2;
	div.rn.f32 	%f63, %f62, %f61;
	mul.rn.f32 	%f64, %f63, %f63;
	mov.f32 	%f65, 0fC0B59883;
	mov.f32 	%f66, 0fBF52C7EA;
	fma.rn.f32 	%f67, %f64, %f66, %f65;
	mov.f32 	%f68, 0fC0D21907;
	fma.rn.f32 	%f69, %f67, %f64, %f68;
	mul.f32 	%f70, %f64, %f69;
	mul.f32 	%f71, %f63, %f70;
	add.f32 	%f72, %f64, 0f41355DC0;
	mov.f32 	%f73, 0f41E6BD60;
	fma.rn.f32 	%f74, %f72, %f64, %f73;
	mov.f32 	%f75, 0f419D92C8;
	fma.rn.f32 	%f76, %f74, %f64, %f75;
	rcp.rn.f32 	%f77, %f76;
	fma.rn.f32 	%f78, %f71, %f77, %f63;
	mov.f32 	%f79, 0f3FC90FDB;
	sub.f32 	%f80, %f79, %f78;
	setp.gt.f32 	%p8, %f4, %f2;
	selp.f32 	%f81, %f80, %f78, %p8;
	mov.b32 	%r74, %f1;
	setp.lt.s32 	%p9, %r74, 0;
	mov.f32 	%f82, 0f40490FDB;
	sub.f32 	%f83, %f82, %f81;
	selp.f32 	%f84, %f83, %f81, %p9;
	mov.b32 	%r75, %f84;
	mov.b32 	%r76, %f3;
	and.b32  	%r77, %r76, -2147483648;
	or.b32  	%r78, %r77, %r75;
	mov.b32 	%f85, %r78;
	add.f32 	%f86, %f2, %f4;
	setp.le.f32 	%p10, %f86, 0f7F800000;
	selp.f32 	%f175, %f85, %f86, %p10;

$L__BB0_6:
	.loc	1 28 13
	setp.lt.s32 	%p12, %r70, 1;
	@%p12 bra 	$L__BB0_61;

	.loc	1 0 13
	ld.const.f32 	%f9, [g_slm];
	ld.const.f32 	%f10, [g_slm+4];
	ld.const.f32 	%f11, [g_slm+12];
	cvta.to.global.u64 	%rd4, %rd33;
	cvta.to.global.u64 	%rd5, %rd34;
	cvta.to.global.u64 	%rd6, %rd35;
	cvta.to.global.u64 	%rd7, %rd42;
	cvta.to.global.u64 	%rd8, %rd39;
	cvta.to.global.u64 	%rd9, %rd37;
	cvta.to.global.u64 	%rd10, %rd38;
	cvta.to.global.u64 	%rd11, %rd36;
	.loc	1 26 13
	cvt.f64.f32 	%fd1, %f175;
	add.f64 	%fd2, %fd1, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f12, %fd2;
	mov.u32 	%r221, 0;

$L__BB0_8:
	.loc	1 29 17
	cvt.s64.s32 	%rd12, %r221;
	mul.wide.s32 	%rd47, %r221, 4;
	add.s64 	%rd48, %rd4, %rd47;
	ld.global.f32 	%f87, [%rd48];
	ld.global.f32 	%f88, [%rd3];
	add.s64 	%rd49, %rd5, %rd47;
	ld.global.f32 	%f89, [%rd49];
	ld.global.f32 	%f90, [%rd2];
	mul.f32 	%f91, %f90, %f89;
	fma.rn.f32 	%f92, %f88, %f87, %f91;
	add.s64 	%rd50, %rd6, %rd47;
	ld.global.f32 	%f93, [%rd50];
	mul.f32 	%f94, %f10, %f93;
	mul.f32 	%f95, %f90, %f90;
	fma.rn.f32 	%f96, %f88, %f88, %f95;
	mul.f32 	%f97, %f94, %f96;
	fma.rn.f32 	%f13, %f9, %f92, %f97;
	mad.lo.s32 	%r92, %r2, %r221, %r1;
	mul.wide.s32 	%rd51, %r92, 4;
	add.s64 	%rd13, %rd7, %rd51;
	st.global.f32 	[%rd13], %f13;
	.loc	1 33 17
	add.s64 	%rd52, %rd8, %rd47;
	ld.global.u32 	%r91, [%rd52];
	setp.eq.s32 	%p13, %r91, 1;
	@%p13 bra 	$L__BB0_59;

	setp.ne.s32 	%p14, %r91, 2;
	@%p14 bra 	$L__BB0_60;

	.loc	1 38 21
	ld.global.f32 	%f14, [%rd3];
	shl.b64 	%rd53, %rd12, 2;
	add.s64 	%rd54, %rd9, %rd53;
	ld.global.f32 	%f15, [%rd54];
	.loc	1 38 21
	.loc	2 89 5, function_name $L__info_string1, inlined_at 1 38 21
	mul.f32 	%f98, %f15, 0f3F22F983;
	cvt.rni.s32.f32 	%r234, %f98;
	cvt.rn.f32.s32 	%f99, %r234;
	mov.f32 	%f100, 0fBFC90FDA;
	fma.rn.f32 	%f101, %f99, %f100, %f15;
	mov.f32 	%f102, 0fB3A22168;
	fma.rn.f32 	%f103, %f99, %f102, %f101;
	mov.f32 	%f104, 0fA7C234C5;
	fma.rn.f32 	%f185, %f99, %f104, %f103;
	abs.f32 	%f17, %f15;
	setp.ltu.f32 	%p15, %f17, 0f47CE4780;
	.loc	1 39 21
	.loc	2 257 5, function_name $L__info_string2, inlined_at 1 39 21
	add.s64 	%rd14, %rd1, 24;
	.loc	2 89 5, function_name $L__info_string1, inlined_at 1 38 21
	mov.u32 	%r225, %r234;
	mov.f32 	%f176, %f185;
	@%p15 bra 	$L__BB0_18;

	setp.eq.f32 	%p16, %f17, 0f7F800000;
	@%p16 bra 	$L__BB0_17;
	bra.uni 	$L__BB0_12;

$L__BB0_17:
	mov.f32 	%f107, 0f00000000;
	mul.rn.f32 	%f176, %f15, %f107;
	mov.u32 	%r225, 0;
	bra.uni 	$L__BB0_18;

$L__BB0_59:
	.loc	1 35 21
	shl.b64 	%rd109, %rd12, 2;
	add.s64 	%rd110, %rd11, %rd109;
	ld.global.f32 	%f173, [%rd110];
	fma.rn.f32 	%f174, %f173, %f12, %f13;
	st.global.f32 	[%rd13], %f174;
	bra.uni 	$L__BB0_60;

$L__BB0_12:
	.loc	2 89 5, function_name $L__info_string1, inlined_at 1 38 21
	mov.b32 	%r5, %f15;
	shr.u32 	%r94, %r5, 23;
	and.b32  	%r95, %r94, 255;
	add.s32 	%r6, %r95, -128;
	shl.b32 	%r96, %r5, 8;
	or.b32  	%r7, %r96, -2147483648;
	shr.u32 	%r8, %r6, 5;
	mov.u64 	%rd113, 0;
	mov.u32 	%r222, 0;
	mov.u64 	%rd112, __cudart_i2opi_f;
	mov.u64 	%rd111, %rd1;

$L__BB0_13:
	.pragma "nounroll";
	ld.global.nc.u32 	%r97, [%rd112];
	mad.wide.u32 	%rd57, %r97, %r7, %rd113;
	shr.u64 	%rd113, %rd57, 32;
	st.local.u32 	[%rd111], %rd57;
	add.s64 	%rd112, %rd112, 4;
	add.s64 	%rd111, %rd111, 4;
	add.s32 	%r222, %r222, 1;
	setp.ne.s32 	%p17, %r222, 6;
	@%p17 bra 	$L__BB0_13;

	st.local.u32 	[%rd14], %rd113;
	mov.u32 	%r98, 4;
	sub.s32 	%r11, %r98, %r8;
	mov.u32 	%r99, 6;
	sub.s32 	%r100, %r99, %r8;
	mul.wide.s32 	%rd58, %r100, 4;
	add.s64 	%rd59, %rd1, %rd58;
	ld.local.u32 	%r223, [%rd59];
	ld.local.u32 	%r224, [%rd59+-4];
	and.b32  	%r14, %r6, 31;
	setp.eq.s32 	%p18, %r14, 0;
	@%p18 bra 	$L__BB0_16;

	mov.u32 	%r101, 32;
	sub.s32 	%r102, %r101, %r14;
	shr.u32 	%r103, %r224, %r102;
	shl.b32 	%r104, %r223, %r14;
	add.s32 	%r223, %r103, %r104;
	mul.wide.s32 	%rd60, %r11, 4;
	add.s64 	%rd61, %rd1, %rd60;
	ld.local.u32 	%r105, [%rd61];
	shr.u32 	%r106, %r105, %r102;
	shl.b32 	%r107, %r224, %r14;
	add.s32 	%r224, %r106, %r107;

$L__BB0_16:
	and.b32  	%r108, %r5, -2147483648;
	shr.u32 	%r109, %r224, 30;
	shl.b32 	%r110, %r223, 2;
	or.b32  	%r111, %r109, %r110;
	shr.u32 	%r112, %r111, 31;
	shr.u32 	%r113, %r223, 30;
	add.s32 	%r114, %r112, %r113;
	neg.s32 	%r115, %r114;
	setp.eq.s32 	%p19, %r108, 0;
	selp.b32 	%r225, %r114, %r115, %p19;
	setp.ne.s32 	%p20, %r112, 0;
	xor.b32  	%r116, %r108, -2147483648;
	selp.b32 	%r117, %r116, %r108, %p20;
	selp.b32 	%r118, -1, 0, %p20;
	xor.b32  	%r119, %r111, %r118;
	shl.b32 	%r120, %r224, 2;
	xor.b32  	%r121, %r120, %r118;
	cvt.u64.u32 	%rd62, %r119;
	cvt.u64.u32 	%rd63, %r121;
	bfi.b64 	%rd64, %rd62, %rd63, 32, 32;
	cvt.rn.f64.s64 	%fd3, %rd64;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f105, %fd4;
	setp.eq.s32 	%p21, %r117, 0;
	neg.f32 	%f106, %f105;
	selp.f32 	%f176, %f105, %f106, %p21;

$L__BB0_18:
	add.s32 	%r21, %r225, 1;
	and.b32  	%r22, %r21, 1;
	setp.eq.s32 	%p22, %r22, 0;
	selp.f32 	%f21, %f176, 0f3F800000, %p22;
	mul.rn.f32 	%f22, %f176, %f176;
	mov.f32 	%f177, 0fB94D4153;
	@%p22 bra 	$L__BB0_20;

	mov.f32 	%f109, 0fBAB607ED;
	mov.f32 	%f110, 0f37CBAC00;
	fma.rn.f32 	%f177, %f110, %f22, %f109;

$L__BB0_20:
	selp.f32 	%f111, 0f3C0885E4, 0f3D2AAABB, %p22;
	fma.rn.f32 	%f112, %f177, %f22, %f111;
	selp.f32 	%f113, 0fBE2AAAA8, 0fBEFFFFFF, %p22;
	fma.rn.f32 	%f114, %f112, %f22, %f113;
	mov.f32 	%f115, 0f00000000;
	fma.rn.f32 	%f116, %f22, %f21, %f115;
	fma.rn.f32 	%f178, %f114, %f116, %f21;
	and.b32  	%r123, %r21, 2;
	setp.eq.s32 	%p24, %r123, 0;
	@%p24 bra 	$L__BB0_22;

	mov.f32 	%f118, 0fBF800000;
	fma.rn.f32 	%f178, %f178, %f118, %f115;

$L__BB0_22:
	.loc	1 38 21
	ld.global.f32 	%f28, [%rd2];
	.loc	1 38 21
	.loc	2 257 5, function_name $L__info_string2, inlined_at 1 38 21
	mov.u32 	%r228, %r234;
	mov.f32 	%f179, %f185;
	@%p15 bra 	$L__BB0_30;

	setp.eq.f32 	%p26, %f17, 0f7F800000;
	@%p26 bra 	$L__BB0_29;
	bra.uni 	$L__BB0_24;

$L__BB0_29:
	mov.f32 	%f121, 0f00000000;
	mul.rn.f32 	%f179, %f15, %f121;
	mov.u32 	%r228, 0;
	bra.uni 	$L__BB0_30;

$L__BB0_24:
	mov.b32 	%r23, %f15;
	shr.u32 	%r124, %r23, 23;
	and.b32  	%r125, %r124, 255;
	add.s32 	%r24, %r125, -128;
	shl.b32 	%r126, %r23, 8;
	or.b32  	%r25, %r126, -2147483648;
	shr.u32 	%r26, %r24, 5;
	mov.u64 	%rd114, 0;
	mov.u64 	%rd115, %rd114;

$L__BB0_25:
	.pragma "nounroll";
	shl.b64 	%rd67, %rd114, 2;
	mov.u64 	%rd68, __cudart_i2opi_f;
	add.s64 	%rd69, %rd68, %rd67;
	ld.global.nc.u32 	%r127, [%rd69];
	mad.wide.u32 	%rd70, %r127, %r25, %rd115;
	shr.u64 	%rd115, %rd70, 32;
	add.s64 	%rd71, %rd1, %rd67;
	st.local.u32 	[%rd71], %rd70;
	cvt.u32.u64 	%r128, %rd114;
	add.s32 	%r129, %r128, 1;
	cvt.s64.s32 	%rd114, %r129;
	setp.ne.s32 	%p27, %r129, 6;
	@%p27 bra 	$L__BB0_25;

	st.local.u32 	[%rd14], %rd115;
	mov.u32 	%r130, 4;
	sub.s32 	%r27, %r130, %r26;
	mov.u32 	%r131, 6;
	sub.s32 	%r132, %r131, %r26;
	mul.wide.s32 	%rd72, %r132, 4;
	add.s64 	%rd73, %rd1, %rd72;
	ld.local.u32 	%r226, [%rd73];
	ld.local.u32 	%r227, [%rd73+-4];
	and.b32  	%r30, %r24, 31;
	setp.eq.s32 	%p28, %r30, 0;
	@%p28 bra 	$L__BB0_28;

	mov.u32 	%r133, 32;
	sub.s32 	%r134, %r133, %r30;
	shr.u32 	%r135, %r227, %r134;
	shl.b32 	%r136, %r226, %r30;
	add.s32 	%r226, %r135, %r136;
	mul.wide.s32 	%rd74, %r27, 4;
	add.s64 	%rd75, %rd1, %rd74;
	ld.local.u32 	%r137, [%rd75];
	shr.u32 	%r138, %r137, %r134;
	shl.b32 	%r139, %r227, %r30;
	add.s32 	%r227, %r138, %r139;

$L__BB0_28:
	and.b32  	%r140, %r23, -2147483648;
	shr.u32 	%r141, %r227, 30;
	shl.b32 	%r142, %r226, 2;
	or.b32  	%r143, %r141, %r142;
	shr.u32 	%r144, %r143, 31;
	shr.u32 	%r145, %r226, 30;
	add.s32 	%r146, %r144, %r145;
	neg.s32 	%r147, %r146;
	setp.eq.s32 	%p29, %r140, 0;
	selp.b32 	%r228, %r146, %r147, %p29;
	setp.ne.s32 	%p30, %r144, 0;
	xor.b32  	%r148, %r140, -2147483648;
	selp.b32 	%r149, %r148, %r140, %p30;
	selp.b32 	%r150, -1, 0, %p30;
	xor.b32  	%r151, %r143, %r150;
	shl.b32 	%r152, %r227, 2;
	xor.b32  	%r153, %r152, %r150;
	cvt.u64.u32 	%rd76, %r151;
	cvt.u64.u32 	%rd77, %r153;
	bfi.b64 	%rd78, %rd76, %rd77, 32, 32;
	cvt.rn.f64.s64 	%fd5, %rd78;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f119, %fd6;
	setp.eq.s32 	%p31, %r149, 0;
	neg.f32 	%f120, %f119;
	selp.f32 	%f179, %f119, %f120, %p31;

$L__BB0_30:
	and.b32  	%r37, %r228, 1;
	setp.eq.s32 	%p32, %r37, 0;
	selp.f32 	%f32, %f179, 0f3F800000, %p32;
	mul.rn.f32 	%f33, %f179, %f179;
	mov.f32 	%f180, 0fB94D4153;
	@%p32 bra 	$L__BB0_32;

	mov.f32 	%f123, 0fBAB607ED;
	mov.f32 	%f124, 0f37CBAC00;
	fma.rn.f32 	%f180, %f124, %f33, %f123;

$L__BB0_32:
	selp.f32 	%f125, 0f3C0885E4, 0f3D2AAABB, %p32;
	fma.rn.f32 	%f126, %f180, %f33, %f125;
	selp.f32 	%f127, 0fBE2AAAA8, 0fBEFFFFFF, %p32;
	fma.rn.f32 	%f128, %f126, %f33, %f127;
	mov.f32 	%f129, 0f00000000;
	fma.rn.f32 	%f130, %f33, %f32, %f129;
	fma.rn.f32 	%f181, %f128, %f130, %f32;
	and.b32  	%r155, %r228, 2;
	setp.eq.s32 	%p34, %r155, 0;
	@%p34 bra 	$L__BB0_34;

	mov.f32 	%f132, 0fBF800000;
	fma.rn.f32 	%f181, %f181, %f132, %f129;

$L__BB0_34:
	.loc	1 38 21
	mul.f32 	%f133, %f28, %f181;
	fma.rn.f32 	%f39, %f14, %f178, %f133;
	.loc	1 39 21
	.loc	2 89 5, function_name $L__info_string1, inlined_at 1 39 21
	mov.u32 	%r231, %r234;
	mov.f32 	%f182, %f185;
	@%p15 bra 	$L__BB0_42;

	setp.eq.f32 	%p36, %f17, 0f7F800000;
	@%p36 bra 	$L__BB0_41;
	bra.uni 	$L__BB0_36;

$L__BB0_41:
	mov.f32 	%f136, 0f00000000;
	mul.rn.f32 	%f182, %f15, %f136;
	mov.u32 	%r231, 0;
	bra.uni 	$L__BB0_42;

$L__BB0_36:
	mov.b32 	%r38, %f15;
	shr.u32 	%r156, %r38, 23;
	and.b32  	%r157, %r156, 255;
	add.s32 	%r39, %r157, -128;
	shl.b32 	%r158, %r38, 8;
	or.b32  	%r40, %r158, -2147483648;
	shr.u32 	%r41, %r39, 5;
	mov.u64 	%rd116, 0;
	mov.u64 	%rd117, %rd116;

$L__BB0_37:
	.pragma "nounroll";
	shl.b64 	%rd81, %rd116, 2;
	mov.u64 	%rd82, __cudart_i2opi_f;
	add.s64 	%rd83, %rd82, %rd81;
	ld.global.nc.u32 	%r159, [%rd83];
	mad.wide.u32 	%rd84, %r159, %r40, %rd117;
	shr.u64 	%rd117, %rd84, 32;
	add.s64 	%rd85, %rd1, %rd81;
	st.local.u32 	[%rd85], %rd84;
	cvt.u32.u64 	%r160, %rd116;
	add.s32 	%r161, %r160, 1;
	cvt.s64.s32 	%rd116, %r161;
	setp.ne.s32 	%p37, %r161, 6;
	@%p37 bra 	$L__BB0_37;

	st.local.u32 	[%rd14], %rd117;
	mov.u32 	%r162, 4;
	sub.s32 	%r42, %r162, %r41;
	mov.u32 	%r163, 6;
	sub.s32 	%r164, %r163, %r41;
	mul.wide.s32 	%rd86, %r164, 4;
	add.s64 	%rd87, %rd1, %rd86;
	ld.local.u32 	%r229, [%rd87];
	ld.local.u32 	%r230, [%rd87+-4];
	and.b32  	%r45, %r39, 31;
	setp.eq.s32 	%p38, %r45, 0;
	@%p38 bra 	$L__BB0_40;

	mov.u32 	%r165, 32;
	sub.s32 	%r166, %r165, %r45;
	shr.u32 	%r167, %r230, %r166;
	shl.b32 	%r168, %r229, %r45;
	add.s32 	%r229, %r167, %r168;
	mul.wide.s32 	%rd88, %r42, 4;
	add.s64 	%rd89, %rd1, %rd88;
	ld.local.u32 	%r169, [%rd89];
	shr.u32 	%r170, %r169, %r166;
	shl.b32 	%r171, %r230, %r45;
	add.s32 	%r230, %r170, %r171;

$L__BB0_40:
	and.b32  	%r172, %r38, -2147483648;
	shr.u32 	%r173, %r230, 30;
	shl.b32 	%r174, %r229, 2;
	or.b32  	%r175, %r173, %r174;
	shr.u32 	%r176, %r175, 31;
	shr.u32 	%r177, %r229, 30;
	add.s32 	%r178, %r176, %r177;
	neg.s32 	%r179, %r178;
	setp.eq.s32 	%p39, %r172, 0;
	selp.b32 	%r231, %r178, %r179, %p39;
	setp.ne.s32 	%p40, %r176, 0;
	xor.b32  	%r180, %r172, -2147483648;
	selp.b32 	%r181, %r180, %r172, %p40;
	selp.b32 	%r182, -1, 0, %p40;
	xor.b32  	%r183, %r175, %r182;
	shl.b32 	%r184, %r230, 2;
	xor.b32  	%r185, %r184, %r182;
	cvt.u64.u32 	%rd90, %r183;
	cvt.u64.u32 	%rd91, %r185;
	bfi.b64 	%rd92, %rd90, %rd91, 32, 32;
	cvt.rn.f64.s64 	%fd7, %rd92;
	mul.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f134, %fd8;
	setp.eq.s32 	%p41, %r181, 0;
	neg.f32 	%f135, %f134;
	selp.f32 	%f182, %f134, %f135, %p41;

$L__BB0_42:
	add.s32 	%r52, %r231, 1;
	and.b32  	%r53, %r52, 1;
	setp.eq.s32 	%p42, %r53, 0;
	selp.f32 	%f43, %f182, 0f3F800000, %p42;
	mul.rn.f32 	%f44, %f182, %f182;
	mov.f32 	%f183, 0fB94D4153;
	@%p42 bra 	$L__BB0_44;

	mov.f32 	%f138, 0fBAB607ED;
	mov.f32 	%f139, 0f37CBAC00;
	fma.rn.f32 	%f183, %f139, %f44, %f138;

$L__BB0_44:
	selp.f32 	%f140, 0f3C0885E4, 0f3D2AAABB, %p42;
	fma.rn.f32 	%f141, %f183, %f44, %f140;
	selp.f32 	%f142, 0fBE2AAAA8, 0fBEFFFFFF, %p42;
	fma.rn.f32 	%f143, %f141, %f44, %f142;
	mov.f32 	%f144, 0f00000000;
	fma.rn.f32 	%f145, %f44, %f43, %f144;
	fma.rn.f32 	%f184, %f143, %f145, %f43;
	and.b32  	%r187, %r52, 2;
	setp.eq.s32 	%p44, %r187, 0;
	@%p44 bra 	$L__BB0_46;

	mov.f32 	%f147, 0fBF800000;
	fma.rn.f32 	%f184, %f184, %f147, %f144;

$L__BB0_46:
	.loc	1 39 21
	mul.f32 	%f50, %f28, %f184;
	.loc	2 257 5, function_name $L__info_string2, inlined_at 1 39 21
	@%p15 bra 	$L__BB0_54;

	setp.eq.f32 	%p46, %f17, 0f7F800000;
	@%p46 bra 	$L__BB0_53;
	bra.uni 	$L__BB0_48;

$L__BB0_53:
	mov.f32 	%f150, 0f00000000;
	mul.rn.f32 	%f185, %f15, %f150;
	mov.u32 	%r234, 0;
	bra.uni 	$L__BB0_54;

$L__BB0_48:
	mov.b32 	%r54, %f15;
	shr.u32 	%r188, %r54, 23;
	and.b32  	%r189, %r188, 255;
	add.s32 	%r55, %r189, -128;
	shl.b32 	%r190, %r54, 8;
	or.b32  	%r56, %r190, -2147483648;
	shr.u32 	%r57, %r55, 5;
	mov.u64 	%rd118, 0;
	mov.u64 	%rd119, %rd118;

$L__BB0_49:
	.pragma "nounroll";
	shl.b64 	%rd95, %rd118, 2;
	mov.u64 	%rd96, __cudart_i2opi_f;
	add.s64 	%rd97, %rd96, %rd95;
	ld.global.nc.u32 	%r191, [%rd97];
	mad.wide.u32 	%rd98, %r191, %r56, %rd119;
	shr.u64 	%rd119, %rd98, 32;
	add.s64 	%rd99, %rd1, %rd95;
	st.local.u32 	[%rd99], %rd98;
	cvt.u32.u64 	%r192, %rd118;
	add.s32 	%r193, %r192, 1;
	cvt.s64.s32 	%rd118, %r193;
	setp.ne.s32 	%p47, %r193, 6;
	@%p47 bra 	$L__BB0_49;

	st.local.u32 	[%rd14], %rd119;
	mov.u32 	%r194, 4;
	sub.s32 	%r58, %r194, %r57;
	mov.u32 	%r195, 6;
	sub.s32 	%r196, %r195, %r57;
	mul.wide.s32 	%rd100, %r196, 4;
	add.s64 	%rd101, %rd1, %rd100;
	ld.local.u32 	%r232, [%rd101];
	ld.local.u32 	%r233, [%rd101+-4];
	and.b32  	%r61, %r55, 31;
	setp.eq.s32 	%p48, %r61, 0;
	@%p48 bra 	$L__BB0_52;

	mov.u32 	%r197, 32;
	sub.s32 	%r198, %r197, %r61;
	shr.u32 	%r199, %r233, %r198;
	shl.b32 	%r200, %r232, %r61;
	add.s32 	%r232, %r199, %r200;
	mul.wide.s32 	%rd102, %r58, 4;
	add.s64 	%rd103, %rd1, %rd102;
	ld.local.u32 	%r201, [%rd103];
	shr.u32 	%r202, %r201, %r198;
	shl.b32 	%r203, %r233, %r61;
	add.s32 	%r233, %r202, %r203;

$L__BB0_52:
	and.b32  	%r204, %r54, -2147483648;
	shr.u32 	%r205, %r233, 30;
	shl.b32 	%r206, %r232, 2;
	or.b32  	%r207, %r205, %r206;
	shr.u32 	%r208, %r207, 31;
	shr.u32 	%r209, %r232, 30;
	add.s32 	%r210, %r208, %r209;
	neg.s32 	%r211, %r210;
	setp.eq.s32 	%p49, %r204, 0;
	selp.b32 	%r234, %r210, %r211, %p49;
	setp.ne.s32 	%p50, %r208, 0;
	xor.b32  	%r212, %r204, -2147483648;
	selp.b32 	%r213, %r212, %r204, %p50;
	selp.b32 	%r214, -1, 0, %p50;
	xor.b32  	%r215, %r207, %r214;
	shl.b32 	%r216, %r233, 2;
	xor.b32  	%r217, %r216, %r214;
	cvt.u64.u32 	%rd104, %r215;
	cvt.u64.u32 	%rd105, %r217;
	bfi.b64 	%rd106, %rd104, %rd105, 32, 32;
	cvt.rn.f64.s64 	%fd9, %rd106;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f148, %fd10;
	setp.eq.s32 	%p51, %r213, 0;
	neg.f32 	%f149, %f148;
	selp.f32 	%f185, %f148, %f149, %p51;

$L__BB0_54:
	and.b32  	%r68, %r234, 1;
	setp.eq.s32 	%p52, %r68, 0;
	selp.f32 	%f54, %f185, 0f3F800000, %p52;
	mul.rn.f32 	%f55, %f185, %f185;
	mov.f32 	%f186, 0fB94D4153;
	@%p52 bra 	$L__BB0_56;

	mov.f32 	%f152, 0fBAB607ED;
	mov.f32 	%f153, 0f37CBAC00;
	fma.rn.f32 	%f186, %f153, %f55, %f152;

$L__BB0_56:
	selp.f32 	%f154, 0f3C0885E4, 0f3D2AAABB, %p52;
	fma.rn.f32 	%f155, %f186, %f55, %f154;
	selp.f32 	%f156, 0fBE2AAAA8, 0fBEFFFFFF, %p52;
	fma.rn.f32 	%f157, %f155, %f55, %f156;
	mov.f32 	%f158, 0f00000000;
	fma.rn.f32 	%f159, %f55, %f54, %f158;
	fma.rn.f32 	%f187, %f157, %f159, %f54;
	and.b32  	%r219, %r234, 2;
	setp.eq.s32 	%p54, %r219, 0;
	@%p54 bra 	$L__BB0_58;

	mov.f32 	%f161, 0fBF800000;
	fma.rn.f32 	%f187, %f187, %f161, %f158;

$L__BB0_58:
	.loc	1 39 21
	mul.f32 	%f162, %f14, %f187;
	sub.f32 	%f163, %f50, %f162;
	.loc	1 40 21
	mul.f32 	%f164, %f39, %f39;
	mul.f32 	%f165, %f163, %f163;
	mul.f32 	%f166, %f163, %f165;
	fma.rn.f32 	%f167, %f39, %f164, %f166;
	mul.f32 	%f168, %f11, %f167;
	add.s64 	%rd108, %rd10, %rd53;
	ld.global.f32 	%f169, [%rd108];
	div.rn.f32 	%f170, %f168, %f169;
	fma.rn.f32 	%f171, %f170, 0f40000000, 0f3F800000;
	cvt.f64.f32 	%fd11, %f171;
	cvt.f64.f32 	%fd12, %f13;
	fma.rn.f64 	%fd13, %fd11, 0d400921FB54442D18, %fd12;
	cvt.rn.f32.f64 	%f172, %fd13;
	st.global.f32 	[%rd13], %f172;

$L__BB0_60:
	.loc	1 0 21
	cvt.u32.u64 	%r220, %rd12;
	.loc	1 28 40
	add.s32 	%r221, %r220, 1;
	.loc	1 28 13
	setp.lt.s32 	%p55, %r221, %r70;
	@%p55 bra 	$L__BB0_8;

$L__BB0_61:
	.loc	1 46 5
	ret;

}
	// .globl	wgs_arb
.visible .entry wgs_arb(
	.param .u64 wgs_arb_param_0,
	.param .u64 wgs_arb_param_1,
	.param .u64 wgs_arb_param_2,
	.param .u64 wgs_arb_param_3,
	.param .u64 wgs_arb_param_4,
	.param .u64 wgs_arb_param_5,
	.param .u64 wgs_arb_param_6,
	.param .u32 wgs_arb_param_7,
	.param .u64 wgs_arb_param_8,
	.param .u64 wgs_arb_param_9,
	.param .u64 wgs_arb_param_10,
	.param .u64 wgs_arb_param_11
)
{
	.local .align 4 .b8 	__local_depot1[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<34>;
	.reg .f32 	%f<116>;
	.reg .b32 	%r<132>;
	.reg .f64 	%fd<7>;
	.reg .b64 	%rd<58>;
	.loc	1 48 0


	mov.u64 	%SPL, __local_depot1;
	ld.param.u32 	%r39, [wgs_arb_param_7];
	ld.param.u64 	%rd16, [wgs_arb_param_8];
	ld.param.u64 	%rd17, [wgs_arb_param_9];
	ld.param.u64 	%rd18, [wgs_arb_param_10];
	ld.param.u64 	%rd19, [wgs_arb_param_11];
	.loc	1 54 9
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r40, %ctaid.x;
	mov.u32 	%r41, %ntid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r1, %r41, %r40, %r42;
	.loc	1 55 9
	ld.const.u32 	%r2, [g_slm+20];
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB1_34;

	.loc	1 58 13
	setp.lt.s32 	%p2, %r39, 1;
	mov.f32 	%f113, 0f00000000;
	mov.f32 	%f114, %f113;
	@%p2 bra 	$L__BB1_28;

	.loc	1 0 13
	cvta.to.global.u64 	%rd2, %rd17;
	cvta.to.global.u64 	%rd3, %rd18;
	cvta.to.global.u64 	%rd4, %rd16;
	mov.f32 	%f114, 0f00000000;
	mov.u32 	%r124, 0;
	add.s64 	%rd5, %rd1, 24;
	mov.f32 	%f113, %f114;

$L__BB1_3:
	.loc	1 59 17
	mul.wide.s32 	%rd21, %r124, 4;
	add.s64 	%rd22, %rd4, %rd21;
	ld.global.f32 	%f3, [%rd22];
	mad.lo.s32 	%r44, %r2, %r124, %r1;
	mul.wide.s32 	%rd23, %r44, 4;
	add.s64 	%rd24, %rd3, %rd23;
	add.s64 	%rd25, %rd2, %rd21;
	ld.global.f32 	%f41, [%rd25];
	ld.global.f32 	%f42, [%rd24];
	add.f32 	%f4, %f42, %f41;
	mul.f32 	%f43, %f4, 0f3F22F983;
	cvt.rni.s32.f32 	%r131, %f43;
	cvt.rn.f32.s32 	%f44, %r131;
	mov.f32 	%f45, 0fBFC90FDA;
	fma.rn.f32 	%f46, %f44, %f45, %f4;
	mov.f32 	%f47, 0fB3A22168;
	fma.rn.f32 	%f48, %f44, %f47, %f46;
	mov.f32 	%f49, 0fA7C234C5;
	fma.rn.f32 	%f110, %f44, %f49, %f48;
	abs.f32 	%f6, %f4;
	setp.ltu.f32 	%p3, %f6, 0f47CE4780;
	mov.u32 	%r128, %r131;
	mov.f32 	%f107, %f110;
	@%p3 bra 	$L__BB1_11;

	setp.eq.f32 	%p4, %f6, 0f7F800000;
	@%p4 bra 	$L__BB1_10;
	bra.uni 	$L__BB1_5;

$L__BB1_10:
	mov.f32 	%f52, 0f00000000;
	mul.rn.f32 	%f107, %f4, %f52;
	mov.u32 	%r128, 0;
	bra.uni 	$L__BB1_11;

$L__BB1_5:
	mov.b32 	%r5, %f4;
	shr.u32 	%r46, %r5, 23;
	and.b32  	%r47, %r46, 255;
	add.s32 	%r6, %r47, -128;
	shl.b32 	%r48, %r5, 8;
	or.b32  	%r7, %r48, -2147483648;
	shr.u32 	%r8, %r6, 5;
	mov.u64 	%rd55, 0;
	mov.u32 	%r125, 0;
	mov.u64 	%rd54, __cudart_i2opi_f;
	mov.u64 	%rd53, %rd1;

$L__BB1_6:
	.pragma "nounroll";
	ld.global.nc.u32 	%r49, [%rd54];
	mad.wide.u32 	%rd28, %r49, %r7, %rd55;
	shr.u64 	%rd55, %rd28, 32;
	st.local.u32 	[%rd53], %rd28;
	add.s64 	%rd54, %rd54, 4;
	add.s64 	%rd53, %rd53, 4;
	add.s32 	%r125, %r125, 1;
	setp.ne.s32 	%p5, %r125, 6;
	@%p5 bra 	$L__BB1_6;

	st.local.u32 	[%rd5], %rd55;
	mov.u32 	%r50, 4;
	sub.s32 	%r11, %r50, %r8;
	mov.u32 	%r51, 6;
	sub.s32 	%r52, %r51, %r8;
	mul.wide.s32 	%rd29, %r52, 4;
	add.s64 	%rd30, %rd1, %rd29;
	ld.local.u32 	%r126, [%rd30];
	ld.local.u32 	%r127, [%rd30+-4];
	and.b32  	%r14, %r6, 31;
	setp.eq.s32 	%p6, %r14, 0;
	@%p6 bra 	$L__BB1_9;

	mov.u32 	%r53, 32;
	sub.s32 	%r54, %r53, %r14;
	shr.u32 	%r55, %r127, %r54;
	shl.b32 	%r56, %r126, %r14;
	add.s32 	%r126, %r55, %r56;
	mul.wide.s32 	%rd31, %r11, 4;
	add.s64 	%rd32, %rd1, %rd31;
	ld.local.u32 	%r57, [%rd32];
	shr.u32 	%r58, %r57, %r54;
	shl.b32 	%r59, %r127, %r14;
	add.s32 	%r127, %r58, %r59;

$L__BB1_9:
	and.b32  	%r60, %r5, -2147483648;
	shr.u32 	%r61, %r127, 30;
	shl.b32 	%r62, %r126, 2;
	or.b32  	%r63, %r61, %r62;
	shr.u32 	%r64, %r63, 31;
	shr.u32 	%r65, %r126, 30;
	add.s32 	%r66, %r64, %r65;
	neg.s32 	%r67, %r66;
	setp.eq.s32 	%p7, %r60, 0;
	selp.b32 	%r128, %r66, %r67, %p7;
	setp.ne.s32 	%p8, %r64, 0;
	xor.b32  	%r68, %r60, -2147483648;
	selp.b32 	%r69, %r68, %r60, %p8;
	selp.b32 	%r70, -1, 0, %p8;
	xor.b32  	%r71, %r63, %r70;
	shl.b32 	%r72, %r127, 2;
	xor.b32  	%r73, %r72, %r70;
	cvt.u64.u32 	%rd33, %r71;
	cvt.u64.u32 	%rd34, %r73;
	bfi.b64 	%rd35, %rd33, %rd34, 32, 32;
	cvt.rn.f64.s64 	%fd1, %rd35;
	mul.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f50, %fd2;
	setp.eq.s32 	%p9, %r69, 0;
	neg.f32 	%f51, %f50;
	selp.f32 	%f107, %f50, %f51, %p9;

$L__BB1_11:
	add.s32 	%r21, %r128, 1;
	and.b32  	%r22, %r21, 1;
	setp.eq.s32 	%p10, %r22, 0;
	selp.f32 	%f10, %f107, 0f3F800000, %p10;
	mul.rn.f32 	%f11, %f107, %f107;
	mov.f32 	%f108, 0fB94D4153;
	@%p10 bra 	$L__BB1_13;

	mov.f32 	%f54, 0fBAB607ED;
	mov.f32 	%f55, 0f37CBAC00;
	fma.rn.f32 	%f108, %f55, %f11, %f54;

$L__BB1_13:
	selp.f32 	%f56, 0f3C0885E4, 0f3D2AAABB, %p10;
	fma.rn.f32 	%f57, %f108, %f11, %f56;
	selp.f32 	%f58, 0fBE2AAAA8, 0fBEFFFFFF, %p10;
	fma.rn.f32 	%f59, %f57, %f11, %f58;
	mov.f32 	%f60, 0f00000000;
	fma.rn.f32 	%f61, %f11, %f10, %f60;
	fma.rn.f32 	%f109, %f59, %f61, %f10;
	and.b32  	%r75, %r21, 2;
	setp.eq.s32 	%p12, %r75, 0;
	@%p12 bra 	$L__BB1_15;

	mov.f32 	%f63, 0fBF800000;
	fma.rn.f32 	%f109, %f109, %f63, %f60;

$L__BB1_15:
	fma.rn.f32 	%f113, %f3, %f109, %f113;
	.loc	1 60 17
	@%p3 bra 	$L__BB1_23;

	setp.eq.f32 	%p14, %f6, 0f7F800000;
	@%p14 bra 	$L__BB1_22;
	bra.uni 	$L__BB1_17;

$L__BB1_22:
	mov.f32 	%f66, 0f00000000;
	mul.rn.f32 	%f110, %f4, %f66;
	mov.u32 	%r131, 0;
	bra.uni 	$L__BB1_23;

$L__BB1_17:
	mov.b32 	%r23, %f4;
	shr.u32 	%r76, %r23, 23;
	and.b32  	%r77, %r76, 255;
	add.s32 	%r24, %r77, -128;
	shl.b32 	%r78, %r23, 8;
	or.b32  	%r25, %r78, -2147483648;
	shr.u32 	%r26, %r24, 5;
	mov.u64 	%rd56, 0;
	mov.u64 	%rd57, %rd56;

$L__BB1_18:
	.pragma "nounroll";
	shl.b64 	%rd38, %rd56, 2;
	mov.u64 	%rd39, __cudart_i2opi_f;
	add.s64 	%rd40, %rd39, %rd38;
	ld.global.nc.u32 	%r79, [%rd40];
	mad.wide.u32 	%rd41, %r79, %r25, %rd57;
	shr.u64 	%rd57, %rd41, 32;
	add.s64 	%rd42, %rd1, %rd38;
	st.local.u32 	[%rd42], %rd41;
	cvt.u32.u64 	%r80, %rd56;
	add.s32 	%r81, %r80, 1;
	cvt.s64.s32 	%rd56, %r81;
	setp.ne.s32 	%p15, %r81, 6;
	@%p15 bra 	$L__BB1_18;

	st.local.u32 	[%rd5], %rd57;
	mov.u32 	%r82, 4;
	sub.s32 	%r27, %r82, %r26;
	mov.u32 	%r83, 6;
	sub.s32 	%r84, %r83, %r26;
	mul.wide.s32 	%rd43, %r84, 4;
	add.s64 	%rd44, %rd1, %rd43;
	ld.local.u32 	%r129, [%rd44];
	ld.local.u32 	%r130, [%rd44+-4];
	and.b32  	%r30, %r24, 31;
	setp.eq.s32 	%p16, %r30, 0;
	@%p16 bra 	$L__BB1_21;

	mov.u32 	%r85, 32;
	sub.s32 	%r86, %r85, %r30;
	shr.u32 	%r87, %r130, %r86;
	shl.b32 	%r88, %r129, %r30;
	add.s32 	%r129, %r87, %r88;
	mul.wide.s32 	%rd45, %r27, 4;
	add.s64 	%rd46, %rd1, %rd45;
	ld.local.u32 	%r89, [%rd46];
	shr.u32 	%r90, %r89, %r86;
	shl.b32 	%r91, %r130, %r30;
	add.s32 	%r130, %r90, %r91;

$L__BB1_21:
	and.b32  	%r92, %r23, -2147483648;
	shr.u32 	%r93, %r130, 30;
	shl.b32 	%r94, %r129, 2;
	or.b32  	%r95, %r93, %r94;
	shr.u32 	%r96, %r95, 31;
	shr.u32 	%r97, %r129, 30;
	add.s32 	%r98, %r96, %r97;
	neg.s32 	%r99, %r98;
	setp.eq.s32 	%p17, %r92, 0;
	selp.b32 	%r131, %r98, %r99, %p17;
	setp.ne.s32 	%p18, %r96, 0;
	xor.b32  	%r100, %r92, -2147483648;
	selp.b32 	%r101, %r100, %r92, %p18;
	selp.b32 	%r102, -1, 0, %p18;
	xor.b32  	%r103, %r95, %r102;
	shl.b32 	%r104, %r130, 2;
	xor.b32  	%r105, %r104, %r102;
	cvt.u64.u32 	%rd47, %r103;
	cvt.u64.u32 	%rd48, %r105;
	bfi.b64 	%rd49, %rd47, %rd48, 32, 32;
	cvt.rn.f64.s64 	%fd3, %rd49;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f64, %fd4;
	setp.eq.s32 	%p19, %r101, 0;
	neg.f32 	%f65, %f64;
	selp.f32 	%f110, %f64, %f65, %p19;

$L__BB1_23:
	and.b32  	%r37, %r131, 1;
	setp.eq.s32 	%p20, %r37, 0;
	selp.f32 	%f21, %f110, 0f3F800000, %p20;
	mul.rn.f32 	%f22, %f110, %f110;
	mov.f32 	%f111, 0fB94D4153;
	@%p20 bra 	$L__BB1_25;

	mov.f32 	%f68, 0fBAB607ED;
	mov.f32 	%f69, 0f37CBAC00;
	fma.rn.f32 	%f111, %f69, %f22, %f68;

$L__BB1_25:
	selp.f32 	%f70, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f71, %f111, %f22, %f70;
	selp.f32 	%f72, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f73, %f71, %f22, %f72;
	mov.f32 	%f74, 0f00000000;
	fma.rn.f32 	%f75, %f22, %f21, %f74;
	fma.rn.f32 	%f112, %f73, %f75, %f21;
	and.b32  	%r107, %r131, 2;
	setp.eq.s32 	%p22, %r107, 0;
	@%p22 bra 	$L__BB1_27;

	mov.f32 	%f77, 0fBF800000;
	fma.rn.f32 	%f112, %f112, %f77, %f74;

$L__BB1_27:
	fma.rn.f32 	%f114, %f3, %f112, %f114;
	.loc	1 58 40
	add.s32 	%r124, %r124, 1;
	.loc	1 58 13
	setp.lt.s32 	%p23, %r124, %r39;
	@%p23 bra 	$L__BB1_3;

$L__BB1_28:
	.loc	1 65 13
	.loc	2 61 5, function_name $L__info_string0, inlined_at 1 65 13
	abs.f32 	%f31, %f113;
	setp.eq.f32 	%p24, %f31, 0f00000000;
	abs.f32 	%f32, %f114;
	setp.eq.f32 	%p25, %f32, 0f00000000;
	and.pred  	%p26, %p24, %p25;
	@%p26 bra 	$L__BB1_32;
	bra.uni 	$L__BB1_29;

$L__BB1_32:
	mov.b32 	%r118, %f113;
	shr.s32 	%r119, %r118, 31;
	and.b32  	%r120, %r119, 1078530011;
	mov.b32 	%r121, %f114;
	and.b32  	%r122, %r121, -2147483648;
	or.b32  	%r123, %r120, %r122;
	mov.b32 	%f115, %r123;
	bra.uni 	$L__BB1_33;

$L__BB1_29:
	setp.eq.f32 	%p27, %f31, 0f7F800000;
	setp.eq.f32 	%p28, %f32, 0f7F800000;
	and.pred  	%p29, %p27, %p28;
	@%p29 bra 	$L__BB1_31;
	bra.uni 	$L__BB1_30;

$L__BB1_31:
	mov.b32 	%r113, %f113;
	setp.lt.s32 	%p33, %r113, 0;
	selp.b32 	%r114, 1075235812, 1061752795, %p33;
	mov.b32 	%r115, %f114;
	and.b32  	%r116, %r115, -2147483648;
	or.b32  	%r117, %r114, %r116;
	mov.b32 	%f115, %r117;
	bra.uni 	$L__BB1_33;

$L__BB1_30:
	max.f32 	%f78, %f32, %f31;
	min.f32 	%f79, %f32, %f31;
	div.rn.f32 	%f80, %f79, %f78;
	mul.rn.f32 	%f81, %f80, %f80;
	mov.f32 	%f82, 0fC0B59883;
	mov.f32 	%f83, 0fBF52C7EA;
	fma.rn.f32 	%f84, %f81, %f83, %f82;
	mov.f32 	%f85, 0fC0D21907;
	fma.rn.f32 	%f86, %f84, %f81, %f85;
	mul.f32 	%f87, %f81, %f86;
	mul.f32 	%f88, %f80, %f87;
	add.f32 	%f89, %f81, 0f41355DC0;
	mov.f32 	%f90, 0f41E6BD60;
	fma.rn.f32 	%f91, %f89, %f81, %f90;
	mov.f32 	%f92, 0f419D92C8;
	fma.rn.f32 	%f93, %f91, %f81, %f92;
	rcp.rn.f32 	%f94, %f93;
	fma.rn.f32 	%f95, %f88, %f94, %f80;
	mov.f32 	%f96, 0f3FC90FDB;
	sub.f32 	%f97, %f96, %f95;
	setp.gt.f32 	%p30, %f32, %f31;
	selp.f32 	%f98, %f97, %f95, %p30;
	mov.b32 	%r108, %f113;
	setp.lt.s32 	%p31, %r108, 0;
	mov.f32 	%f99, 0f40490FDB;
	sub.f32 	%f100, %f99, %f98;
	selp.f32 	%f101, %f100, %f98, %p31;
	mov.b32 	%r109, %f101;
	mov.b32 	%r110, %f114;
	and.b32  	%r111, %r110, -2147483648;
	or.b32  	%r112, %r111, %r109;
	mov.b32 	%f102, %r112;
	add.f32 	%f103, %f31, %f32;
	setp.le.f32 	%p32, %f103, 0f7F800000;
	selp.f32 	%f115, %f102, %f103, %p32;

$L__BB1_33:
	.loc	1 65 13
	cvt.f64.f32 	%fd5, %f115;
	add.f64 	%fd6, %fd5, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f104, %fd6;
	cvta.to.global.u64 	%rd50, %rd19;
	mul.wide.s32 	%rd51, %r1, 4;
	add.s64 	%rd52, %rd50, %rd51;
	st.global.f32 	[%rd52], %f104;

$L__BB1_34:
	.loc	1 67 5
	ret;

}
	// .globl	rs_arb
.visible .entry rs_arb(
	.param .u64 rs_arb_param_0,
	.param .u64 rs_arb_param_1,
	.param .u64 rs_arb_param_2,
	.param .u64 rs_arb_param_3,
	.param .u64 rs_arb_param_4,
	.param .u64 rs_arb_param_5,
	.param .u64 rs_arb_param_6,
	.param .u32 rs_arb_param_7,
	.param .u64 rs_arb_param_8,
	.param .u64 rs_arb_param_9,
	.param .u64 rs_arb_param_10,
	.param .u64 rs_arb_param_11
)
{
	.local .align 4 .b8 	__local_depot2[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<34>;
	.reg .f32 	%f<116>;
	.reg .b32 	%r<132>;
	.reg .f64 	%fd<7>;
	.reg .b64 	%rd<58>;
	.loc	1 69 0


	mov.u64 	%SPL, __local_depot2;
	ld.param.u32 	%r39, [rs_arb_param_7];
	ld.param.u64 	%rd16, [rs_arb_param_8];
	ld.param.u64 	%rd17, [rs_arb_param_9];
	ld.param.u64 	%rd18, [rs_arb_param_10];
	ld.param.u64 	%rd19, [rs_arb_param_11];
	.loc	1 76 9
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r40, %ctaid.x;
	mov.u32 	%r41, %ntid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r1, %r41, %r40, %r42;
	.loc	1 77 9
	ld.const.u32 	%r2, [g_slm+20];
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB2_34;

	.loc	1 80 13
	setp.lt.s32 	%p2, %r39, 1;
	mov.f32 	%f113, 0f00000000;
	mov.f32 	%f114, %f113;
	@%p2 bra 	$L__BB2_28;

	.loc	1 0 13
	cvta.to.global.u64 	%rd2, %rd17;
	cvta.to.global.u64 	%rd3, %rd18;
	cvta.to.global.u64 	%rd4, %rd16;
	mov.f32 	%f114, 0f00000000;
	mov.u32 	%r124, 0;
	add.s64 	%rd5, %rd1, 24;
	mov.f32 	%f113, %f114;

$L__BB2_3:
	.loc	1 81 17
	mul.wide.s32 	%rd21, %r124, 4;
	add.s64 	%rd22, %rd4, %rd21;
	ld.global.f32 	%f3, [%rd22];
	mad.lo.s32 	%r44, %r2, %r124, %r1;
	mul.wide.s32 	%rd23, %r44, 4;
	add.s64 	%rd24, %rd3, %rd23;
	add.s64 	%rd25, %rd2, %rd21;
	ld.global.f32 	%f41, [%rd25];
	ld.global.f32 	%f42, [%rd24];
	add.f32 	%f4, %f42, %f41;
	mul.f32 	%f43, %f4, 0f3F22F983;
	cvt.rni.s32.f32 	%r131, %f43;
	cvt.rn.f32.s32 	%f44, %r131;
	mov.f32 	%f45, 0fBFC90FDA;
	fma.rn.f32 	%f46, %f44, %f45, %f4;
	mov.f32 	%f47, 0fB3A22168;
	fma.rn.f32 	%f48, %f44, %f47, %f46;
	mov.f32 	%f49, 0fA7C234C5;
	fma.rn.f32 	%f110, %f44, %f49, %f48;
	abs.f32 	%f6, %f4;
	setp.ltu.f32 	%p3, %f6, 0f47CE4780;
	mov.u32 	%r128, %r131;
	mov.f32 	%f107, %f110;
	@%p3 bra 	$L__BB2_11;

	setp.eq.f32 	%p4, %f6, 0f7F800000;
	@%p4 bra 	$L__BB2_10;
	bra.uni 	$L__BB2_5;

$L__BB2_10:
	mov.f32 	%f52, 0f00000000;
	mul.rn.f32 	%f107, %f4, %f52;
	mov.u32 	%r128, 0;
	bra.uni 	$L__BB2_11;

$L__BB2_5:
	mov.b32 	%r5, %f4;
	shr.u32 	%r46, %r5, 23;
	and.b32  	%r47, %r46, 255;
	add.s32 	%r6, %r47, -128;
	shl.b32 	%r48, %r5, 8;
	or.b32  	%r7, %r48, -2147483648;
	shr.u32 	%r8, %r6, 5;
	mov.u64 	%rd55, 0;
	mov.u32 	%r125, 0;
	mov.u64 	%rd54, __cudart_i2opi_f;
	mov.u64 	%rd53, %rd1;

$L__BB2_6:
	.pragma "nounroll";
	ld.global.nc.u32 	%r49, [%rd54];
	mad.wide.u32 	%rd28, %r49, %r7, %rd55;
	shr.u64 	%rd55, %rd28, 32;
	st.local.u32 	[%rd53], %rd28;
	add.s64 	%rd54, %rd54, 4;
	add.s64 	%rd53, %rd53, 4;
	add.s32 	%r125, %r125, 1;
	setp.ne.s32 	%p5, %r125, 6;
	@%p5 bra 	$L__BB2_6;

	st.local.u32 	[%rd5], %rd55;
	mov.u32 	%r50, 4;
	sub.s32 	%r11, %r50, %r8;
	mov.u32 	%r51, 6;
	sub.s32 	%r52, %r51, %r8;
	mul.wide.s32 	%rd29, %r52, 4;
	add.s64 	%rd30, %rd1, %rd29;
	ld.local.u32 	%r126, [%rd30];
	ld.local.u32 	%r127, [%rd30+-4];
	and.b32  	%r14, %r6, 31;
	setp.eq.s32 	%p6, %r14, 0;
	@%p6 bra 	$L__BB2_9;

	mov.u32 	%r53, 32;
	sub.s32 	%r54, %r53, %r14;
	shr.u32 	%r55, %r127, %r54;
	shl.b32 	%r56, %r126, %r14;
	add.s32 	%r126, %r55, %r56;
	mul.wide.s32 	%rd31, %r11, 4;
	add.s64 	%rd32, %rd1, %rd31;
	ld.local.u32 	%r57, [%rd32];
	shr.u32 	%r58, %r57, %r54;
	shl.b32 	%r59, %r127, %r14;
	add.s32 	%r127, %r58, %r59;

$L__BB2_9:
	and.b32  	%r60, %r5, -2147483648;
	shr.u32 	%r61, %r127, 30;
	shl.b32 	%r62, %r126, 2;
	or.b32  	%r63, %r61, %r62;
	shr.u32 	%r64, %r63, 31;
	shr.u32 	%r65, %r126, 30;
	add.s32 	%r66, %r64, %r65;
	neg.s32 	%r67, %r66;
	setp.eq.s32 	%p7, %r60, 0;
	selp.b32 	%r128, %r66, %r67, %p7;
	setp.ne.s32 	%p8, %r64, 0;
	xor.b32  	%r68, %r60, -2147483648;
	selp.b32 	%r69, %r68, %r60, %p8;
	selp.b32 	%r70, -1, 0, %p8;
	xor.b32  	%r71, %r63, %r70;
	shl.b32 	%r72, %r127, 2;
	xor.b32  	%r73, %r72, %r70;
	cvt.u64.u32 	%rd33, %r71;
	cvt.u64.u32 	%rd34, %r73;
	bfi.b64 	%rd35, %rd33, %rd34, 32, 32;
	cvt.rn.f64.s64 	%fd1, %rd35;
	mul.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f50, %fd2;
	setp.eq.s32 	%p9, %r69, 0;
	neg.f32 	%f51, %f50;
	selp.f32 	%f107, %f50, %f51, %p9;

$L__BB2_11:
	add.s32 	%r21, %r128, 1;
	and.b32  	%r22, %r21, 1;
	setp.eq.s32 	%p10, %r22, 0;
	selp.f32 	%f10, %f107, 0f3F800000, %p10;
	mul.rn.f32 	%f11, %f107, %f107;
	mov.f32 	%f108, 0fB94D4153;
	@%p10 bra 	$L__BB2_13;

	mov.f32 	%f54, 0fBAB607ED;
	mov.f32 	%f55, 0f37CBAC00;
	fma.rn.f32 	%f108, %f55, %f11, %f54;

$L__BB2_13:
	selp.f32 	%f56, 0f3C0885E4, 0f3D2AAABB, %p10;
	fma.rn.f32 	%f57, %f108, %f11, %f56;
	selp.f32 	%f58, 0fBE2AAAA8, 0fBEFFFFFF, %p10;
	fma.rn.f32 	%f59, %f57, %f11, %f58;
	mov.f32 	%f60, 0f00000000;
	fma.rn.f32 	%f61, %f11, %f10, %f60;
	fma.rn.f32 	%f109, %f59, %f61, %f10;
	and.b32  	%r75, %r21, 2;
	setp.eq.s32 	%p12, %r75, 0;
	@%p12 bra 	$L__BB2_15;

	mov.f32 	%f63, 0fBF800000;
	fma.rn.f32 	%f109, %f109, %f63, %f60;

$L__BB2_15:
	fma.rn.f32 	%f113, %f3, %f109, %f113;
	.loc	1 82 17
	@%p3 bra 	$L__BB2_23;

	setp.eq.f32 	%p14, %f6, 0f7F800000;
	@%p14 bra 	$L__BB2_22;
	bra.uni 	$L__BB2_17;

$L__BB2_22:
	mov.f32 	%f66, 0f00000000;
	mul.rn.f32 	%f110, %f4, %f66;
	mov.u32 	%r131, 0;
	bra.uni 	$L__BB2_23;

$L__BB2_17:
	mov.b32 	%r23, %f4;
	shr.u32 	%r76, %r23, 23;
	and.b32  	%r77, %r76, 255;
	add.s32 	%r24, %r77, -128;
	shl.b32 	%r78, %r23, 8;
	or.b32  	%r25, %r78, -2147483648;
	shr.u32 	%r26, %r24, 5;
	mov.u64 	%rd56, 0;
	mov.u64 	%rd57, %rd56;

$L__BB2_18:
	.pragma "nounroll";
	shl.b64 	%rd38, %rd56, 2;
	mov.u64 	%rd39, __cudart_i2opi_f;
	add.s64 	%rd40, %rd39, %rd38;
	ld.global.nc.u32 	%r79, [%rd40];
	mad.wide.u32 	%rd41, %r79, %r25, %rd57;
	shr.u64 	%rd57, %rd41, 32;
	add.s64 	%rd42, %rd1, %rd38;
	st.local.u32 	[%rd42], %rd41;
	cvt.u32.u64 	%r80, %rd56;
	add.s32 	%r81, %r80, 1;
	cvt.s64.s32 	%rd56, %r81;
	setp.ne.s32 	%p15, %r81, 6;
	@%p15 bra 	$L__BB2_18;

	st.local.u32 	[%rd5], %rd57;
	mov.u32 	%r82, 4;
	sub.s32 	%r27, %r82, %r26;
	mov.u32 	%r83, 6;
	sub.s32 	%r84, %r83, %r26;
	mul.wide.s32 	%rd43, %r84, 4;
	add.s64 	%rd44, %rd1, %rd43;
	ld.local.u32 	%r129, [%rd44];
	ld.local.u32 	%r130, [%rd44+-4];
	and.b32  	%r30, %r24, 31;
	setp.eq.s32 	%p16, %r30, 0;
	@%p16 bra 	$L__BB2_21;

	mov.u32 	%r85, 32;
	sub.s32 	%r86, %r85, %r30;
	shr.u32 	%r87, %r130, %r86;
	shl.b32 	%r88, %r129, %r30;
	add.s32 	%r129, %r87, %r88;
	mul.wide.s32 	%rd45, %r27, 4;
	add.s64 	%rd46, %rd1, %rd45;
	ld.local.u32 	%r89, [%rd46];
	shr.u32 	%r90, %r89, %r86;
	shl.b32 	%r91, %r130, %r30;
	add.s32 	%r130, %r90, %r91;

$L__BB2_21:
	and.b32  	%r92, %r23, -2147483648;
	shr.u32 	%r93, %r130, 30;
	shl.b32 	%r94, %r129, 2;
	or.b32  	%r95, %r93, %r94;
	shr.u32 	%r96, %r95, 31;
	shr.u32 	%r97, %r129, 30;
	add.s32 	%r98, %r96, %r97;
	neg.s32 	%r99, %r98;
	setp.eq.s32 	%p17, %r92, 0;
	selp.b32 	%r131, %r98, %r99, %p17;
	setp.ne.s32 	%p18, %r96, 0;
	xor.b32  	%r100, %r92, -2147483648;
	selp.b32 	%r101, %r100, %r92, %p18;
	selp.b32 	%r102, -1, 0, %p18;
	xor.b32  	%r103, %r95, %r102;
	shl.b32 	%r104, %r130, 2;
	xor.b32  	%r105, %r104, %r102;
	cvt.u64.u32 	%rd47, %r103;
	cvt.u64.u32 	%rd48, %r105;
	bfi.b64 	%rd49, %rd47, %rd48, 32, 32;
	cvt.rn.f64.s64 	%fd3, %rd49;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f64, %fd4;
	setp.eq.s32 	%p19, %r101, 0;
	neg.f32 	%f65, %f64;
	selp.f32 	%f110, %f64, %f65, %p19;

$L__BB2_23:
	and.b32  	%r37, %r131, 1;
	setp.eq.s32 	%p20, %r37, 0;
	selp.f32 	%f21, %f110, 0f3F800000, %p20;
	mul.rn.f32 	%f22, %f110, %f110;
	mov.f32 	%f111, 0fB94D4153;
	@%p20 bra 	$L__BB2_25;

	mov.f32 	%f68, 0fBAB607ED;
	mov.f32 	%f69, 0f37CBAC00;
	fma.rn.f32 	%f111, %f69, %f22, %f68;

$L__BB2_25:
	selp.f32 	%f70, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f71, %f111, %f22, %f70;
	selp.f32 	%f72, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f73, %f71, %f22, %f72;
	mov.f32 	%f74, 0f00000000;
	fma.rn.f32 	%f75, %f22, %f21, %f74;
	fma.rn.f32 	%f112, %f73, %f75, %f21;
	and.b32  	%r107, %r131, 2;
	setp.eq.s32 	%p22, %r107, 0;
	@%p22 bra 	$L__BB2_27;

	mov.f32 	%f77, 0fBF800000;
	fma.rn.f32 	%f112, %f112, %f77, %f74;

$L__BB2_27:
	fma.rn.f32 	%f114, %f3, %f112, %f114;
	.loc	1 80 40
	add.s32 	%r124, %r124, 1;
	.loc	1 80 13
	setp.lt.s32 	%p23, %r124, %r39;
	@%p23 bra 	$L__BB2_3;

$L__BB2_28:
	.loc	1 87 13
	.loc	2 61 5, function_name $L__info_string0, inlined_at 1 87 13
	abs.f32 	%f31, %f113;
	setp.eq.f32 	%p24, %f31, 0f00000000;
	abs.f32 	%f32, %f114;
	setp.eq.f32 	%p25, %f32, 0f00000000;
	and.pred  	%p26, %p24, %p25;
	@%p26 bra 	$L__BB2_32;
	bra.uni 	$L__BB2_29;

$L__BB2_32:
	mov.b32 	%r118, %f113;
	shr.s32 	%r119, %r118, 31;
	and.b32  	%r120, %r119, 1078530011;
	mov.b32 	%r121, %f114;
	and.b32  	%r122, %r121, -2147483648;
	or.b32  	%r123, %r120, %r122;
	mov.b32 	%f115, %r123;
	bra.uni 	$L__BB2_33;

$L__BB2_29:
	setp.eq.f32 	%p27, %f31, 0f7F800000;
	setp.eq.f32 	%p28, %f32, 0f7F800000;
	and.pred  	%p29, %p27, %p28;
	@%p29 bra 	$L__BB2_31;
	bra.uni 	$L__BB2_30;

$L__BB2_31:
	mov.b32 	%r113, %f113;
	setp.lt.s32 	%p33, %r113, 0;
	selp.b32 	%r114, 1075235812, 1061752795, %p33;
	mov.b32 	%r115, %f114;
	and.b32  	%r116, %r115, -2147483648;
	or.b32  	%r117, %r114, %r116;
	mov.b32 	%f115, %r117;
	bra.uni 	$L__BB2_33;

$L__BB2_30:
	max.f32 	%f78, %f32, %f31;
	min.f32 	%f79, %f32, %f31;
	div.rn.f32 	%f80, %f79, %f78;
	mul.rn.f32 	%f81, %f80, %f80;
	mov.f32 	%f82, 0fC0B59883;
	mov.f32 	%f83, 0fBF52C7EA;
	fma.rn.f32 	%f84, %f81, %f83, %f82;
	mov.f32 	%f85, 0fC0D21907;
	fma.rn.f32 	%f86, %f84, %f81, %f85;
	mul.f32 	%f87, %f81, %f86;
	mul.f32 	%f88, %f80, %f87;
	add.f32 	%f89, %f81, 0f41355DC0;
	mov.f32 	%f90, 0f41E6BD60;
	fma.rn.f32 	%f91, %f89, %f81, %f90;
	mov.f32 	%f92, 0f419D92C8;
	fma.rn.f32 	%f93, %f91, %f81, %f92;
	rcp.rn.f32 	%f94, %f93;
	fma.rn.f32 	%f95, %f88, %f94, %f80;
	mov.f32 	%f96, 0f3FC90FDB;
	sub.f32 	%f97, %f96, %f95;
	setp.gt.f32 	%p30, %f32, %f31;
	selp.f32 	%f98, %f97, %f95, %p30;
	mov.b32 	%r108, %f113;
	setp.lt.s32 	%p31, %r108, 0;
	mov.f32 	%f99, 0f40490FDB;
	sub.f32 	%f100, %f99, %f98;
	selp.f32 	%f101, %f100, %f98, %p31;
	mov.b32 	%r109, %f101;
	mov.b32 	%r110, %f114;
	and.b32  	%r111, %r110, -2147483648;
	or.b32  	%r112, %r111, %r109;
	mov.b32 	%f102, %r112;
	add.f32 	%f103, %f31, %f32;
	setp.le.f32 	%p32, %f103, 0f7F800000;
	selp.f32 	%f115, %f102, %f103, %p32;

$L__BB2_33:
	.loc	1 87 13
	cvt.f64.f32 	%fd5, %f115;
	add.f64 	%fd6, %fd5, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f104, %fd6;
	cvta.to.global.u64 	%rd50, %rd19;
	mul.wide.s32 	%rd51, %r1, 4;
	add.s64 	%rd52, %rd50, %rd51;
	st.global.f32 	[%rd52], %f104;

$L__BB2_34:
	.loc	1 89 5
	ret;

}
	// .globl	upd_pix
.visible .entry upd_pix(
	.param .u64 upd_pix_param_0,
	.param .u64 upd_pix_param_1,
	.param .u64 upd_pix_param_2,
	.param .u64 upd_pix_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<7>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<15>;
	.loc	1 91 0


	ld.param.u64 	%rd1, [upd_pix_param_0];
	ld.param.u64 	%rd2, [upd_pix_param_1];
	ld.param.u64 	%rd3, [upd_pix_param_2];
	ld.param.u64 	%rd4, [upd_pix_param_3];
	.loc	1 93 9
	mov.u32 	%r2, %tid.x;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r2;
	.loc	1 95 9
	ld.const.u32 	%r5, [g_slm+20];
	setp.ge.s32 	%p1, %r1, %r5;
	@%p1 bra 	$L__BB3_2;

	.loc	1 93 9
	cvta.to.global.u64 	%rd5, %rd2;
	.loc	1 96 13
	mul.wide.s32 	%rd6, %r1, 4;
	add.s64 	%rd7, %rd5, %rd6;
	.loc	1 93 9
	cvta.to.global.u64 	%rd8, %rd1;
	.loc	1 97 13
	add.s64 	%rd9, %rd8, %rd6;
	ld.global.f32 	%f1, [%rd9];
	cvt.f64.f32 	%fd1, %f1;
	div.rn.f64 	%fd2, %fd1, 0d401921FB54442D18;
	.loc	1 93 9
	cvta.to.global.u64 	%rd10, %rd3;
	.loc	1 97 13
	add.s64 	%rd11, %rd10, %rd6;
	ld.global.f32 	%f2, [%rd11];
	cvt.f64.f32 	%fd3, %f2;
	fma.rn.f64 	%fd4, %fd2, 0d4070000000000000, %fd3;
	cvt.rzi.s32.f64 	%r6, %fd4;
	.loc	1 96 13
	ld.global.s32 	%rd12, [%rd7];
	.loc	1 93 9
	cvta.to.global.u64 	%rd13, %rd4;
	.loc	1 98 13
	add.s64 	%rd14, %rd13, %rd12;
	st.global.u8 	[%rd14], %r6;

$L__BB3_2:
	.loc	1 100 5
	ret;

}
	// .globl	upd_pix_simp
.visible .entry upd_pix_simp(
	.param .u64 upd_pix_simp_param_0,
	.param .u64 upd_pix_simp_param_1
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<7>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<9>;
	.loc	1 102 0


	ld.param.u64 	%rd1, [upd_pix_simp_param_0];
	ld.param.u64 	%rd2, [upd_pix_simp_param_1];
	.loc	1 103 9
	mov.u32 	%r2, %tid.x;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r2;
	.loc	1 104 9
	ld.const.u32 	%r5, [g_slm+20];
	setp.ge.s32 	%p1, %r1, %r5;
	@%p1 bra 	$L__BB4_2;

	.loc	1 103 9
	cvta.to.global.u64 	%rd3, %rd1;
	.loc	1 105 13
	cvt.s64.s32 	%rd4, %r1;
	mul.wide.s32 	%rd5, %r1, 4;
	add.s64 	%rd6, %rd3, %rd5;
	ld.global.f32 	%f1, [%rd6];
	cvt.f64.f32 	%fd1, %f1;
	div.rn.f64 	%fd2, %fd1, 0d401921FB54442D18;
	mul.f64 	%fd3, %fd2, 0d4070000000000000;
	cvt.rzi.s32.f64 	%r6, %fd3;
	.loc	1 103 9
	cvta.to.global.u64 	%rd7, %rd2;
	.loc	1 106 13
	add.s64 	%rd8, %rd7, %rd4;
	st.global.u8 	[%rd8], %r6;

$L__BB4_2:
	.loc	1 108 5
	ret;

}
	// .globl	copy_to_2d_apr
.visible .entry copy_to_2d_apr(
	.param .u64 copy_to_2d_apr_param_0,
	.param .u64 copy_to_2d_apr_param_1,
	.param .u64 copy_to_2d_apr_param_2,
	.param .u32 copy_to_2d_apr_param_3,
	.param .u32 copy_to_2d_apr_param_4,
	.param .u32 copy_to_2d_apr_param_5,
	.param .u32 copy_to_2d_apr_param_6
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<12>;
	.loc	1 110 0


	ld.param.u64 	%rd1, [copy_to_2d_apr_param_0];
	ld.param.u64 	%rd2, [copy_to_2d_apr_param_1];
	ld.param.u64 	%rd3, [copy_to_2d_apr_param_2];
	ld.param.u32 	%r2, [copy_to_2d_apr_param_3];
	ld.param.u32 	%r3, [copy_to_2d_apr_param_4];
	ld.param.u32 	%r4, [copy_to_2d_apr_param_5];
	ld.param.u32 	%r5, [copy_to_2d_apr_param_6];
	.loc	1 113 9
	mov.u32 	%r6, %tid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %ntid.x;
	mad.lo.s32 	%r1, %r8, %r7, %r6;
	.loc	1 115 9
	ld.const.u32 	%r9, [g_slm+20];
	setp.ge.s32 	%p1, %r1, %r9;
	@%p1 bra 	$L__BB5_2;

	.loc	1 113 9
	cvta.to.global.u64 	%rd4, %rd2;
	.loc	1 116 13
	mul.wide.s32 	%rd5, %r1, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.u32 	%r10, [%rd6];
	div.s32 	%r11, %r10, %r3;
	.loc	1 117 13
	mul.lo.s32 	%r12, %r11, %r3;
	sub.s32 	%r13, %r10, %r12;
	.loc	1 118 13
	sub.s32 	%r14, %r4, %r2;
	shr.u32 	%r15, %r14, 31;
	add.s32 	%r16, %r14, %r15;
	shr.s32 	%r17, %r16, 1;
	add.s32 	%r18, %r11, %r17;
	.loc	1 119 13
	sub.s32 	%r19, %r5, %r3;
	shr.u32 	%r20, %r19, 31;
	add.s32 	%r21, %r19, %r20;
	shr.s32 	%r22, %r21, 1;
	add.s32 	%r23, %r13, %r22;
	.loc	1 120 13
	mad.lo.s32 	%r24, %r18, %r5, %r23;
	.loc	1 113 9
	cvta.to.global.u64 	%rd7, %rd1;
	.loc	1 121 13
	add.s64 	%rd8, %rd7, %rd5;
	ld.global.f32 	%f1, [%rd8];
	.loc	1 113 9
	cvta.to.global.u64 	%rd9, %rd3;
	.loc	1 121 13
	mul.wide.s32 	%rd10, %r24, 4;
	add.s64 	%rd11, %rd9, %rd10;
	st.global.f32 	[%rd11], %f1;

$L__BB5_2:
	.loc	1 123 5
	ret;

}
	// .globl	copy_to_2d_noapr
.visible .entry copy_to_2d_noapr(
	.param .u64 copy_to_2d_noapr_param_0,
	.param .u64 copy_to_2d_noapr_param_1,
	.param .u32 copy_to_2d_noapr_param_2,
	.param .u32 copy_to_2d_noapr_param_3,
	.param .u32 copy_to_2d_noapr_param_4,
	.param .u32 copy_to_2d_noapr_param_5
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<9>;
	.loc	1 125 0


	ld.param.u64 	%rd1, [copy_to_2d_noapr_param_0];
	ld.param.u64 	%rd2, [copy_to_2d_noapr_param_1];
	ld.param.u32 	%r2, [copy_to_2d_noapr_param_2];
	ld.param.u32 	%r3, [copy_to_2d_noapr_param_3];
	ld.param.u32 	%r4, [copy_to_2d_noapr_param_4];
	ld.param.u32 	%r5, [copy_to_2d_noapr_param_5];
	.loc	1 127 9
	mov.u32 	%r6, %tid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %ntid.x;
	mad.lo.s32 	%r1, %r8, %r7, %r6;
	.loc	1 129 9
	ld.const.u32 	%r9, [g_slm+20];
	setp.ge.s32 	%p1, %r1, %r9;
	@%p1 bra 	$L__BB6_2;

	.loc	1 127 9
	cvta.to.global.u64 	%rd3, %rd1;
	.loc	1 132 13
	sub.s32 	%r10, %r4, %r2;
	shr.u32 	%r11, %r10, 31;
	add.s32 	%r12, %r10, %r11;
	shr.s32 	%r13, %r12, 1;
	.loc	1 130 13
	div.s32 	%r14, %r1, %r3;
	.loc	1 132 13
	add.s32 	%r15, %r14, %r13;
	.loc	1 133 13
	sub.s32 	%r16, %r5, %r3;
	shr.u32 	%r17, %r16, 31;
	add.s32 	%r18, %r16, %r17;
	shr.s32 	%r19, %r18, 1;
	.loc	1 131 13
	mul.lo.s32 	%r20, %r14, %r3;
	sub.s32 	%r21, %r1, %r20;
	.loc	1 133 13
	add.s32 	%r22, %r21, %r19;
	.loc	1 134 13
	mad.lo.s32 	%r23, %r15, %r5, %r22;
	.loc	1 135 13
	mul.wide.s32 	%rd4, %r1, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f32 	%f1, [%rd5];
	.loc	1 127 9
	cvta.to.global.u64 	%rd6, %rd2;
	.loc	1 135 13
	mul.wide.s32 	%rd7, %r23, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB6_2:
	.loc	1 137 5
	ret;

}
	// .globl	efield_reduce_l1
.visible .entry efield_reduce_l1(
	.param .u64 efield_reduce_l1_param_0,
	.param .u64 efield_reduce_l1_param_1,
	.param .u64 efield_reduce_l1_param_2,
	.param .u64 efield_reduce_l1_param_3,
	.param .u32 efield_reduce_l1_param_4,
	.param .u32 efield_reduce_l1_param_5,
	.param .u64 efield_reduce_l1_param_6,
	.param .u64 efield_reduce_l1_param_7,
	.param .u64 efield_reduce_l1_param_8,
	.param .u64 efield_reduce_l1_param_9,
	.param .u64 efield_reduce_l1_param_10,
	.param .u64 efield_reduce_l1_param_11,
	.param .u64 efield_reduce_l1_param_12
)
{
	.local .align 4 .b8 	__local_depot7[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<50>;
	.reg .f32 	%f<197>;
	.reg .b32 	%r<235>;
	.reg .f64 	%fd<9>;
	.reg .b64 	%rd<102>;
	.loc	1 138 0
	// demoted variable
	.shared .align 4 .b8 _ZZ16efield_reduce_l1E5sdata[16384];
	// demoted variable
	.shared .align 4 .b8 _ZZ16efield_reduce_l1E5tdata[16384];

	mov.u64 	%SPL, __local_depot7;
	ld.param.u64 	%rd27, [efield_reduce_l1_param_0];
	ld.param.u64 	%rd28, [efield_reduce_l1_param_1];
	ld.param.u64 	%rd25, [efield_reduce_l1_param_2];
	ld.param.u64 	%rd26, [efield_reduce_l1_param_3];
	ld.param.u32 	%r81, [efield_reduce_l1_param_4];
	ld.param.u32 	%r82, [efield_reduce_l1_param_5];
	cvta.to.global.u64 	%rd1, %rd28;
	cvta.to.global.u64 	%rd2, %rd27;
	.loc	1 152 9
	add.u64 	%rd3, %SPL, 0;
	mov.u32 	%r1, %tid.x;
	.loc	1 154 9
	mov.u32 	%r2, %ntid.x;
	.loc	1 155 9
	setp.lt.s32 	%p1, %r81, 1;
	@%p1 bra 	$L__BB7_65;

	.loc	1 154 9
	shl.b32 	%r84, %r2, 1;
	shl.b32 	%r85, %r1, 2;
	mov.u32 	%r86, _ZZ16efield_reduce_l1E5sdata;
	add.s32 	%r3, %r86, %r85;
	mov.u32 	%r87, _ZZ16efield_reduce_l1E5tdata;
	add.s32 	%r4, %r87, %r85;
	.loc	1 158 13
	mov.u32 	%r5, %ctaid.x;
	mad.lo.s32 	%r6, %r84, %r5, %r1;
	ld.const.u32 	%r7, [g_slm+20];
	.loc	1 154 9
	mov.u32 	%r88, %nctaid.x;
	mul.lo.s32 	%r8, %r84, %r88;
	cvta.to.global.u64 	%rd4, %rd25;
	cvta.to.global.u64 	%rd5, %rd26;
	mov.u32 	%r83, 0;
	mov.u32 	%r220, %r83;

$L__BB7_2:
	.loc	1 156 13
	st.shared.u32 	[%r3], %r83;
	.loc	1 157 13
	st.shared.u32 	[%r4], %r83;
	setp.ge.s32 	%p2, %r6, %r7;
	.loc	1 159 13
	@%p2 bra 	$L__BB7_56;

	.loc	1 0 13
	mul.lo.s32 	%r10, %r7, %r220;
	mov.f32 	%f181, 0f00000000;
	mov.f32 	%f182, %f181;
	mov.u32 	%r221, %r6;

$L__BB7_4:
	.loc	1 160 17
	mul.wide.s32 	%rd30, %r221, 4;
	add.s64 	%rd31, %rd2, %rd30;
	add.s32 	%r90, %r10, %r221;
	mul.wide.s32 	%rd32, %r90, 4;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.f32 	%f57, [%rd33];
	ld.global.f32 	%f58, [%rd31];
	sub.f32 	%f3, %f58, %f57;
	.loc	1 160 17
	.loc	2 89 5, function_name $L__info_string1, inlined_at 1 160 17
	mul.f32 	%f59, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r228, %f59;
	cvt.rn.f32.s32 	%f60, %r228;
	mov.f32 	%f61, 0fBFC90FDA;
	fma.rn.f32 	%f62, %f60, %f61, %f3;
	mov.f32 	%f63, 0fB3A22168;
	fma.rn.f32 	%f64, %f60, %f63, %f62;
	mov.f32 	%f65, 0fA7C234C5;
	fma.rn.f32 	%f186, %f60, %f65, %f64;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p3, %f5, 0f47CE4780;
	.loc	1 165 21
	.loc	2 257 5, function_name $L__info_string2, inlined_at 1 165 21
	add.s64 	%rd6, %rd3, 24;
	.loc	2 89 5, function_name $L__info_string1, inlined_at 1 160 17
	mov.u32 	%r225, %r228;
	mov.f32 	%f183, %f186;
	@%p3 bra 	$L__BB7_12;

	setp.eq.f32 	%p4, %f5, 0f7F800000;
	@%p4 bra 	$L__BB7_11;
	bra.uni 	$L__BB7_6;

$L__BB7_11:
	mov.f32 	%f68, 0f00000000;
	mul.rn.f32 	%f183, %f3, %f68;
	mov.u32 	%r225, 0;
	bra.uni 	$L__BB7_12;

$L__BB7_6:
	mov.b32 	%r13, %f3;
	shr.u32 	%r92, %r13, 23;
	and.b32  	%r93, %r92, 255;
	add.s32 	%r14, %r93, -128;
	shl.b32 	%r94, %r13, 8;
	or.b32  	%r15, %r94, -2147483648;
	shr.u32 	%r16, %r14, 5;
	mov.u64 	%rd95, 0;
	mov.u32 	%r222, 0;
	mov.u64 	%rd94, __cudart_i2opi_f;
	mov.u64 	%rd93, %rd3;

$L__BB7_7:
	.pragma "nounroll";
	ld.global.nc.u32 	%r95, [%rd94];
	mad.wide.u32 	%rd36, %r95, %r15, %rd95;
	shr.u64 	%rd95, %rd36, 32;
	st.local.u32 	[%rd93], %rd36;
	add.s64 	%rd94, %rd94, 4;
	add.s64 	%rd93, %rd93, 4;
	add.s32 	%r222, %r222, 1;
	setp.ne.s32 	%p5, %r222, 6;
	@%p5 bra 	$L__BB7_7;

	st.local.u32 	[%rd6], %rd95;
	mov.u32 	%r96, 4;
	sub.s32 	%r19, %r96, %r16;
	mov.u32 	%r97, 6;
	sub.s32 	%r98, %r97, %r16;
	mul.wide.s32 	%rd37, %r98, 4;
	add.s64 	%rd38, %rd3, %rd37;
	ld.local.u32 	%r223, [%rd38];
	ld.local.u32 	%r224, [%rd38+-4];
	and.b32  	%r22, %r14, 31;
	setp.eq.s32 	%p6, %r22, 0;
	@%p6 bra 	$L__BB7_10;

	mov.u32 	%r99, 32;
	sub.s32 	%r100, %r99, %r22;
	shr.u32 	%r101, %r224, %r100;
	shl.b32 	%r102, %r223, %r22;
	add.s32 	%r223, %r101, %r102;
	mul.wide.s32 	%rd39, %r19, 4;
	add.s64 	%rd40, %rd3, %rd39;
	ld.local.u32 	%r103, [%rd40];
	shr.u32 	%r104, %r103, %r100;
	shl.b32 	%r105, %r224, %r22;
	add.s32 	%r224, %r104, %r105;

$L__BB7_10:
	and.b32  	%r106, %r13, -2147483648;
	shr.u32 	%r107, %r224, 30;
	shl.b32 	%r108, %r223, 2;
	or.b32  	%r109, %r107, %r108;
	shr.u32 	%r110, %r109, 31;
	shr.u32 	%r111, %r223, 30;
	add.s32 	%r112, %r110, %r111;
	neg.s32 	%r113, %r112;
	setp.eq.s32 	%p7, %r106, 0;
	selp.b32 	%r225, %r112, %r113, %p7;
	setp.ne.s32 	%p8, %r110, 0;
	xor.b32  	%r114, %r106, -2147483648;
	selp.b32 	%r115, %r114, %r106, %p8;
	selp.b32 	%r116, -1, 0, %p8;
	xor.b32  	%r117, %r109, %r116;
	shl.b32 	%r118, %r224, 2;
	xor.b32  	%r119, %r118, %r116;
	cvt.u64.u32 	%rd41, %r117;
	cvt.u64.u32 	%rd42, %r119;
	bfi.b64 	%rd43, %rd41, %rd42, 32, 32;
	cvt.rn.f64.s64 	%fd1, %rd43;
	mul.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f66, %fd2;
	setp.eq.s32 	%p9, %r115, 0;
	neg.f32 	%f67, %f66;
	selp.f32 	%f183, %f66, %f67, %p9;

$L__BB7_12:
	add.s32 	%r29, %r225, 1;
	and.b32  	%r30, %r29, 1;
	setp.eq.s32 	%p10, %r30, 0;
	selp.f32 	%f9, %f183, 0f3F800000, %p10;
	mul.rn.f32 	%f10, %f183, %f183;
	mov.f32 	%f184, 0fB94D4153;
	@%p10 bra 	$L__BB7_14;

	mov.f32 	%f70, 0fBAB607ED;
	mov.f32 	%f71, 0f37CBAC00;
	fma.rn.f32 	%f184, %f71, %f10, %f70;

$L__BB7_14:
	selp.f32 	%f72, 0f3C0885E4, 0f3D2AAABB, %p10;
	fma.rn.f32 	%f73, %f184, %f10, %f72;
	selp.f32 	%f74, 0fBE2AAAA8, 0fBEFFFFFF, %p10;
	fma.rn.f32 	%f75, %f73, %f10, %f74;
	mov.f32 	%f76, 0f00000000;
	fma.rn.f32 	%f77, %f10, %f9, %f76;
	fma.rn.f32 	%f185, %f75, %f77, %f9;
	and.b32  	%r121, %r29, 2;
	setp.eq.s32 	%p12, %r121, 0;
	@%p12 bra 	$L__BB7_16;

	mov.f32 	%f79, 0fBF800000;
	fma.rn.f32 	%f185, %f185, %f79, %f76;

$L__BB7_16:
	.loc	1 160 17
	add.f32 	%f182, %f185, %f182;
	.loc	1 161 17
	.loc	2 257 5, function_name $L__info_string2, inlined_at 1 161 17
	@%p3 bra 	$L__BB7_24;

	setp.eq.f32 	%p14, %f5, 0f7F800000;
	@%p14 bra 	$L__BB7_23;
	bra.uni 	$L__BB7_18;

$L__BB7_23:
	mov.f32 	%f82, 0f00000000;
	mul.rn.f32 	%f186, %f3, %f82;
	mov.u32 	%r228, 0;
	bra.uni 	$L__BB7_24;

$L__BB7_18:
	mov.b32 	%r31, %f3;
	shr.u32 	%r122, %r31, 23;
	and.b32  	%r123, %r122, 255;
	add.s32 	%r32, %r123, -128;
	shl.b32 	%r124, %r31, 8;
	or.b32  	%r33, %r124, -2147483648;
	shr.u32 	%r34, %r32, 5;
	mov.u64 	%rd96, 0;
	mov.u64 	%rd97, %rd96;

$L__BB7_19:
	.pragma "nounroll";
	shl.b64 	%rd46, %rd96, 2;
	mov.u64 	%rd47, __cudart_i2opi_f;
	add.s64 	%rd48, %rd47, %rd46;
	ld.global.nc.u32 	%r125, [%rd48];
	mad.wide.u32 	%rd49, %r125, %r33, %rd97;
	shr.u64 	%rd97, %rd49, 32;
	add.s64 	%rd50, %rd3, %rd46;
	st.local.u32 	[%rd50], %rd49;
	cvt.u32.u64 	%r126, %rd96;
	add.s32 	%r127, %r126, 1;
	cvt.s64.s32 	%rd96, %r127;
	setp.ne.s32 	%p15, %r127, 6;
	@%p15 bra 	$L__BB7_19;

	st.local.u32 	[%rd6], %rd97;
	mov.u32 	%r128, 4;
	sub.s32 	%r35, %r128, %r34;
	mov.u32 	%r129, 6;
	sub.s32 	%r130, %r129, %r34;
	mul.wide.s32 	%rd51, %r130, 4;
	add.s64 	%rd52, %rd3, %rd51;
	ld.local.u32 	%r226, [%rd52];
	ld.local.u32 	%r227, [%rd52+-4];
	and.b32  	%r38, %r32, 31;
	setp.eq.s32 	%p16, %r38, 0;
	@%p16 bra 	$L__BB7_22;

	mov.u32 	%r131, 32;
	sub.s32 	%r132, %r131, %r38;
	shr.u32 	%r133, %r227, %r132;
	shl.b32 	%r134, %r226, %r38;
	add.s32 	%r226, %r133, %r134;
	mul.wide.s32 	%rd53, %r35, 4;
	add.s64 	%rd54, %rd3, %rd53;
	ld.local.u32 	%r135, [%rd54];
	shr.u32 	%r136, %r135, %r132;
	shl.b32 	%r137, %r227, %r38;
	add.s32 	%r227, %r136, %r137;

$L__BB7_22:
	and.b32  	%r138, %r31, -2147483648;
	shr.u32 	%r139, %r227, 30;
	shl.b32 	%r140, %r226, 2;
	or.b32  	%r141, %r139, %r140;
	shr.u32 	%r142, %r141, 31;
	shr.u32 	%r143, %r226, 30;
	add.s32 	%r144, %r142, %r143;
	neg.s32 	%r145, %r144;
	setp.eq.s32 	%p17, %r138, 0;
	selp.b32 	%r228, %r144, %r145, %p17;
	setp.ne.s32 	%p18, %r142, 0;
	xor.b32  	%r146, %r138, -2147483648;
	selp.b32 	%r147, %r146, %r138, %p18;
	selp.b32 	%r148, -1, 0, %p18;
	xor.b32  	%r149, %r141, %r148;
	shl.b32 	%r150, %r227, 2;
	xor.b32  	%r151, %r150, %r148;
	cvt.u64.u32 	%rd55, %r149;
	cvt.u64.u32 	%rd56, %r151;
	bfi.b64 	%rd57, %rd55, %rd56, 32, 32;
	cvt.rn.f64.s64 	%fd3, %rd57;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f80, %fd4;
	setp.eq.s32 	%p19, %r147, 0;
	neg.f32 	%f81, %f80;
	selp.f32 	%f186, %f80, %f81, %p19;

$L__BB7_24:
	and.b32  	%r45, %r228, 1;
	setp.eq.s32 	%p20, %r45, 0;
	selp.f32 	%f20, %f186, 0f3F800000, %p20;
	mul.rn.f32 	%f21, %f186, %f186;
	mov.f32 	%f187, 0fB94D4153;
	@%p20 bra 	$L__BB7_26;

	mov.f32 	%f84, 0fBAB607ED;
	mov.f32 	%f85, 0f37CBAC00;
	fma.rn.f32 	%f187, %f85, %f21, %f84;

$L__BB7_26:
	selp.f32 	%f86, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f87, %f187, %f21, %f86;
	selp.f32 	%f88, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f89, %f87, %f21, %f88;
	mov.f32 	%f90, 0f00000000;
	fma.rn.f32 	%f91, %f21, %f20, %f90;
	fma.rn.f32 	%f188, %f89, %f91, %f20;
	and.b32  	%r153, %r228, 2;
	setp.eq.s32 	%p22, %r153, 0;
	@%p22 bra 	$L__BB7_28;

	mov.f32 	%f93, 0fBF800000;
	fma.rn.f32 	%f188, %f188, %f93, %f90;

$L__BB7_28:
	.loc	1 161 17
	add.f32 	%f181, %f188, %f181;
	.loc	1 162 17
	add.s32 	%r46, %r221, %r2;
	setp.ge.u32 	%p23, %r46, %r7;
	@%p23 bra 	$L__BB7_54;

	.loc	1 163 21
	mul.wide.u32 	%rd58, %r46, 4;
	add.s64 	%rd59, %rd2, %rd58;
	add.s32 	%r154, %r10, %r46;
	mul.wide.u32 	%rd60, %r154, 4;
	add.s64 	%rd61, %rd1, %rd60;
	ld.global.f32 	%f94, [%rd61];
	ld.global.f32 	%f95, [%rd59];
	sub.f32 	%f28, %f95, %f94;
	.loc	1 163 21
	.loc	2 89 5, function_name $L__info_string1, inlined_at 1 163 21
	mul.f32 	%f96, %f28, 0f3F22F983;
	cvt.rni.s32.f32 	%r234, %f96;
	cvt.rn.f32.s32 	%f97, %r234;
	mov.f32 	%f98, 0fBFC90FDA;
	fma.rn.f32 	%f99, %f97, %f98, %f28;
	mov.f32 	%f100, 0fB3A22168;
	fma.rn.f32 	%f101, %f97, %f100, %f99;
	mov.f32 	%f102, 0fA7C234C5;
	fma.rn.f32 	%f192, %f97, %f102, %f101;
	abs.f32 	%f30, %f28;
	setp.ltu.f32 	%p24, %f30, 0f47CE4780;
	mov.u32 	%r231, %r234;
	mov.f32 	%f189, %f192;
	@%p24 bra 	$L__BB7_37;

	setp.eq.f32 	%p25, %f30, 0f7F800000;
	@%p25 bra 	$L__BB7_36;
	bra.uni 	$L__BB7_31;

$L__BB7_36:
	mov.f32 	%f105, 0f00000000;
	mul.rn.f32 	%f189, %f28, %f105;
	mov.u32 	%r231, 0;
	bra.uni 	$L__BB7_37;

$L__BB7_31:
	mov.b32 	%r48, %f28;
	shr.u32 	%r155, %r48, 23;
	and.b32  	%r156, %r155, 255;
	add.s32 	%r49, %r156, -128;
	shl.b32 	%r157, %r48, 8;
	or.b32  	%r50, %r157, -2147483648;
	shr.u32 	%r51, %r49, 5;
	mov.u64 	%rd98, 0;
	mov.u64 	%rd99, %rd98;

$L__BB7_32:
	.pragma "nounroll";
	shl.b64 	%rd64, %rd98, 2;
	mov.u64 	%rd65, __cudart_i2opi_f;
	add.s64 	%rd66, %rd65, %rd64;
	ld.global.nc.u32 	%r158, [%rd66];
	mad.wide.u32 	%rd67, %r158, %r50, %rd99;
	shr.u64 	%rd99, %rd67, 32;
	add.s64 	%rd68, %rd3, %rd64;
	st.local.u32 	[%rd68], %rd67;
	cvt.u32.u64 	%r159, %rd98;
	add.s32 	%r160, %r159, 1;
	cvt.s64.s32 	%rd98, %r160;
	setp.ne.s32 	%p26, %r160, 6;
	@%p26 bra 	$L__BB7_32;

	st.local.u32 	[%rd6], %rd99;
	mov.u32 	%r161, 4;
	sub.s32 	%r52, %r161, %r51;
	mov.u32 	%r162, 6;
	sub.s32 	%r163, %r162, %r51;
	mul.wide.s32 	%rd69, %r163, 4;
	add.s64 	%rd70, %rd3, %rd69;
	ld.local.u32 	%r229, [%rd70];
	ld.local.u32 	%r230, [%rd70+-4];
	and.b32  	%r55, %r49, 31;
	setp.eq.s32 	%p27, %r55, 0;
	@%p27 bra 	$L__BB7_35;

	mov.u32 	%r164, 32;
	sub.s32 	%r165, %r164, %r55;
	shr.u32 	%r166, %r230, %r165;
	shl.b32 	%r167, %r229, %r55;
	add.s32 	%r229, %r166, %r167;
	mul.wide.s32 	%rd71, %r52, 4;
	add.s64 	%rd72, %rd3, %rd71;
	ld.local.u32 	%r168, [%rd72];
	shr.u32 	%r169, %r168, %r165;
	shl.b32 	%r170, %r230, %r55;
	add.s32 	%r230, %r169, %r170;

$L__BB7_35:
	and.b32  	%r171, %r48, -2147483648;
	shr.u32 	%r172, %r230, 30;
	shl.b32 	%r173, %r229, 2;
	or.b32  	%r174, %r172, %r173;
	shr.u32 	%r175, %r174, 31;
	shr.u32 	%r176, %r229, 30;
	add.s32 	%r177, %r175, %r176;
	neg.s32 	%r178, %r177;
	setp.eq.s32 	%p28, %r171, 0;
	selp.b32 	%r231, %r177, %r178, %p28;
	setp.ne.s32 	%p29, %r175, 0;
	xor.b32  	%r179, %r171, -2147483648;
	selp.b32 	%r180, %r179, %r171, %p29;
	selp.b32 	%r181, -1, 0, %p29;
	xor.b32  	%r182, %r174, %r181;
	shl.b32 	%r183, %r230, 2;
	xor.b32  	%r184, %r183, %r181;
	cvt.u64.u32 	%rd73, %r182;
	cvt.u64.u32 	%rd74, %r184;
	bfi.b64 	%rd75, %rd73, %rd74, 32, 32;
	cvt.rn.f64.s64 	%fd5, %rd75;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f103, %fd6;
	setp.eq.s32 	%p30, %r180, 0;
	neg.f32 	%f104, %f103;
	selp.f32 	%f189, %f103, %f104, %p30;

$L__BB7_37:
	add.s32 	%r62, %r231, 1;
	and.b32  	%r63, %r62, 1;
	setp.eq.s32 	%p31, %r63, 0;
	selp.f32 	%f34, %f189, 0f3F800000, %p31;
	mul.rn.f32 	%f35, %f189, %f189;
	mov.f32 	%f190, 0fB94D4153;
	@%p31 bra 	$L__BB7_39;

	mov.f32 	%f107, 0fBAB607ED;
	mov.f32 	%f108, 0f37CBAC00;
	fma.rn.f32 	%f190, %f108, %f35, %f107;

$L__BB7_39:
	selp.f32 	%f109, 0f3C0885E4, 0f3D2AAABB, %p31;
	fma.rn.f32 	%f110, %f190, %f35, %f109;
	selp.f32 	%f111, 0fBE2AAAA8, 0fBEFFFFFF, %p31;
	fma.rn.f32 	%f112, %f110, %f35, %f111;
	mov.f32 	%f113, 0f00000000;
	fma.rn.f32 	%f114, %f35, %f34, %f113;
	fma.rn.f32 	%f191, %f112, %f114, %f34;
	and.b32  	%r186, %r62, 2;
	setp.eq.s32 	%p33, %r186, 0;
	@%p33 bra 	$L__BB7_41;

	mov.f32 	%f116, 0fBF800000;
	fma.rn.f32 	%f191, %f191, %f116, %f113;

$L__BB7_41:
	.loc	1 163 21
	add.f32 	%f182, %f191, %f182;
	.loc	2 257 5, function_name $L__info_string2, inlined_at 1 165 21
	@%p24 bra 	$L__BB7_49;

	setp.eq.f32 	%p35, %f30, 0f7F800000;
	@%p35 bra 	$L__BB7_48;
	bra.uni 	$L__BB7_43;

$L__BB7_48:
	mov.f32 	%f119, 0f00000000;
	mul.rn.f32 	%f192, %f28, %f119;
	mov.u32 	%r234, 0;
	bra.uni 	$L__BB7_49;

$L__BB7_43:
	mov.b32 	%r64, %f28;
	shr.u32 	%r187, %r64, 23;
	and.b32  	%r188, %r187, 255;
	add.s32 	%r65, %r188, -128;
	shl.b32 	%r189, %r64, 8;
	or.b32  	%r66, %r189, -2147483648;
	shr.u32 	%r67, %r65, 5;
	mov.u64 	%rd100, 0;
	mov.u64 	%rd101, %rd100;

$L__BB7_44:
	.pragma "nounroll";
	shl.b64 	%rd78, %rd100, 2;
	mov.u64 	%rd79, __cudart_i2opi_f;
	add.s64 	%rd80, %rd79, %rd78;
	ld.global.nc.u32 	%r190, [%rd80];
	mad.wide.u32 	%rd81, %r190, %r66, %rd101;
	shr.u64 	%rd101, %rd81, 32;
	add.s64 	%rd82, %rd3, %rd78;
	st.local.u32 	[%rd82], %rd81;
	cvt.u32.u64 	%r191, %rd100;
	add.s32 	%r192, %r191, 1;
	cvt.s64.s32 	%rd100, %r192;
	setp.ne.s32 	%p36, %r192, 6;
	@%p36 bra 	$L__BB7_44;

	st.local.u32 	[%rd6], %rd101;
	mov.u32 	%r193, 4;
	sub.s32 	%r68, %r193, %r67;
	mov.u32 	%r194, 6;
	sub.s32 	%r195, %r194, %r67;
	mul.wide.s32 	%rd83, %r195, 4;
	add.s64 	%rd84, %rd3, %rd83;
	ld.local.u32 	%r232, [%rd84];
	ld.local.u32 	%r233, [%rd84+-4];
	and.b32  	%r71, %r65, 31;
	setp.eq.s32 	%p37, %r71, 0;
	@%p37 bra 	$L__BB7_47;

	mov.u32 	%r196, 32;
	sub.s32 	%r197, %r196, %r71;
	shr.u32 	%r198, %r233, %r197;
	shl.b32 	%r199, %r232, %r71;
	add.s32 	%r232, %r198, %r199;
	mul.wide.s32 	%rd85, %r68, 4;
	add.s64 	%rd86, %rd3, %rd85;
	ld.local.u32 	%r200, [%rd86];
	shr.u32 	%r201, %r200, %r197;
	shl.b32 	%r202, %r233, %r71;
	add.s32 	%r233, %r201, %r202;

$L__BB7_47:
	and.b32  	%r203, %r64, -2147483648;
	shr.u32 	%r204, %r233, 30;
	shl.b32 	%r205, %r232, 2;
	or.b32  	%r206, %r204, %r205;
	shr.u32 	%r207, %r206, 31;
	shr.u32 	%r208, %r232, 30;
	add.s32 	%r209, %r207, %r208;
	neg.s32 	%r210, %r209;
	setp.eq.s32 	%p38, %r203, 0;
	selp.b32 	%r234, %r209, %r210, %p38;
	setp.ne.s32 	%p39, %r207, 0;
	xor.b32  	%r211, %r203, -2147483648;
	selp.b32 	%r212, %r211, %r203, %p39;
	selp.b32 	%r213, -1, 0, %p39;
	xor.b32  	%r214, %r206, %r213;
	shl.b32 	%r215, %r233, 2;
	xor.b32  	%r216, %r215, %r213;
	cvt.u64.u32 	%rd87, %r214;
	cvt.u64.u32 	%rd88, %r216;
	bfi.b64 	%rd89, %rd87, %rd88, 32, 32;
	cvt.rn.f64.s64 	%fd7, %rd89;
	mul.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f117, %fd8;
	setp.eq.s32 	%p40, %r212, 0;
	neg.f32 	%f118, %f117;
	selp.f32 	%f192, %f117, %f118, %p40;

$L__BB7_49:
	and.b32  	%r78, %r234, 1;
	setp.eq.s32 	%p41, %r78, 0;
	selp.f32 	%f45, %f192, 0f3F800000, %p41;
	mul.rn.f32 	%f46, %f192, %f192;
	mov.f32 	%f193, 0fB94D4153;
	@%p41 bra 	$L__BB7_51;

	mov.f32 	%f121, 0fBAB607ED;
	mov.f32 	%f122, 0f37CBAC00;
	fma.rn.f32 	%f193, %f122, %f46, %f121;

$L__BB7_51:
	selp.f32 	%f123, 0f3C0885E4, 0f3D2AAABB, %p41;
	fma.rn.f32 	%f124, %f193, %f46, %f123;
	selp.f32 	%f125, 0fBE2AAAA8, 0fBEFFFFFF, %p41;
	fma.rn.f32 	%f126, %f124, %f46, %f125;
	mov.f32 	%f127, 0f00000000;
	fma.rn.f32 	%f128, %f46, %f45, %f127;
	fma.rn.f32 	%f194, %f126, %f128, %f45;
	and.b32  	%r218, %r234, 2;
	setp.eq.s32 	%p43, %r218, 0;
	@%p43 bra 	$L__BB7_53;

	mov.f32 	%f130, 0fBF800000;
	fma.rn.f32 	%f194, %f194, %f130, %f127;

$L__BB7_53:
	.loc	1 165 21
	add.f32 	%f181, %f194, %f181;

$L__BB7_54:
	.loc	1 168 17
	add.s32 	%r221, %r221, %r8;
	.loc	1 159 13
	setp.lt.s32 	%p44, %r221, %r7;
	@%p44 bra 	$L__BB7_4;

	.loc	1 163 21
	st.shared.f32 	[%r3], %f182;
	.loc	1 165 21
	st.shared.f32 	[%r4], %f181;

$L__BB7_56:
	.loc	1 0 21
	setp.gt.s32 	%p45, %r1, 127;
	.loc	1 170 13
	bar.sync 	0;
	.loc	1 182 13
	@%p45 bra 	$L__BB7_58;

	.loc	1 183 17
	ld.shared.f32 	%f131, [%r3];
	ld.shared.f32 	%f132, [%r3+512];
	add.f32 	%f133, %f132, %f131;
	st.shared.f32 	[%r3], %f133;
	.loc	1 184 17
	ld.shared.f32 	%f134, [%r4+512];
	ld.shared.f32 	%f135, [%r4];
	add.f32 	%f136, %f134, %f135;
	st.shared.f32 	[%r4], %f136;

$L__BB7_58:
	.loc	1 0 17
	setp.gt.s32 	%p46, %r1, 63;
	.loc	1 186 13
	bar.sync 	0;
	.loc	1 187 13
	@%p46 bra 	$L__BB7_60;

	.loc	1 188 17
	ld.shared.f32 	%f137, [%r3];
	ld.shared.f32 	%f138, [%r3+256];
	add.f32 	%f139, %f138, %f137;
	st.shared.f32 	[%r3], %f139;
	.loc	1 189 17
	ld.shared.f32 	%f140, [%r4+256];
	ld.shared.f32 	%f141, [%r4];
	add.f32 	%f142, %f140, %f141;
	st.shared.f32 	[%r4], %f142;

$L__BB7_60:
	.loc	1 0 17
	setp.gt.s32 	%p47, %r1, 31;
	.loc	1 191 13
	bar.sync 	0;
	.loc	1 193 13
	@%p47 bra 	$L__BB7_62;

	.loc	1 194 17
	.loc	1 10 9, function_name $L__info_string3, inlined_at 1 194 17
	ld.volatile.shared.f32 	%f143, [%r3];
	ld.volatile.shared.f32 	%f144, [%r3+128];
	add.f32 	%f145, %f144, %f143;
	st.volatile.shared.f32 	[%r3], %f145;
	.loc	1 11 9, function_name $L__info_string3, inlined_at 1 194 17
	ld.volatile.shared.f32 	%f146, [%r3];
	ld.volatile.shared.f32 	%f147, [%r3+64];
	add.f32 	%f148, %f147, %f146;
	st.volatile.shared.f32 	[%r3], %f148;
	.loc	1 12 9, function_name $L__info_string3, inlined_at 1 194 17
	ld.volatile.shared.f32 	%f149, [%r3];
	ld.volatile.shared.f32 	%f150, [%r3+32];
	add.f32 	%f151, %f150, %f149;
	st.volatile.shared.f32 	[%r3], %f151;
	.loc	1 13 9, function_name $L__info_string3, inlined_at 1 194 17
	ld.volatile.shared.f32 	%f152, [%r3];
	ld.volatile.shared.f32 	%f153, [%r3+16];
	add.f32 	%f154, %f153, %f152;
	st.volatile.shared.f32 	[%r3], %f154;
	.loc	1 14 9, function_name $L__info_string3, inlined_at 1 194 17
	ld.volatile.shared.f32 	%f155, [%r3];
	ld.volatile.shared.f32 	%f156, [%r3+8];
	add.f32 	%f157, %f156, %f155;
	st.volatile.shared.f32 	[%r3], %f157;
	.loc	1 15 9, function_name $L__info_string3, inlined_at 1 194 17
	ld.volatile.shared.f32 	%f158, [%r3];
	ld.volatile.shared.f32 	%f159, [%r3+4];
	add.f32 	%f160, %f159, %f158;
	st.volatile.shared.f32 	[%r3], %f160;
	.loc	1 195 17
	.loc	1 10 9, function_name $L__info_string3, inlined_at 1 195 17
	ld.volatile.shared.f32 	%f161, [%r4];
	ld.volatile.shared.f32 	%f162, [%r4+128];
	add.f32 	%f163, %f162, %f161;
	st.volatile.shared.f32 	[%r4], %f163;
	.loc	1 11 9, function_name $L__info_string3, inlined_at 1 195 17
	ld.volatile.shared.f32 	%f164, [%r4];
	ld.volatile.shared.f32 	%f165, [%r4+64];
	add.f32 	%f166, %f165, %f164;
	st.volatile.shared.f32 	[%r4], %f166;
	.loc	1 12 9, function_name $L__info_string3, inlined_at 1 195 17
	ld.volatile.shared.f32 	%f167, [%r4];
	ld.volatile.shared.f32 	%f168, [%r4+32];
	add.f32 	%f169, %f168, %f167;
	st.volatile.shared.f32 	[%r4], %f169;
	.loc	1 13 9, function_name $L__info_string3, inlined_at 1 195 17
	ld.volatile.shared.f32 	%f170, [%r4];
	ld.volatile.shared.f32 	%f171, [%r4+16];
	add.f32 	%f172, %f171, %f170;
	st.volatile.shared.f32 	[%r4], %f172;
	.loc	1 14 9, function_name $L__info_string3, inlined_at 1 195 17
	ld.volatile.shared.f32 	%f173, [%r4];
	ld.volatile.shared.f32 	%f174, [%r4+8];
	add.f32 	%f175, %f174, %f173;
	st.volatile.shared.f32 	[%r4], %f175;
	.loc	1 15 9, function_name $L__info_string3, inlined_at 1 195 17
	ld.volatile.shared.f32 	%f176, [%r4];
	ld.volatile.shared.f32 	%f177, [%r4+4];
	add.f32 	%f178, %f177, %f176;
	st.volatile.shared.f32 	[%r4], %f178;

$L__BB7_62:
	.loc	1 0 9
	setp.ne.s32 	%p48, %r1, 0;
	.loc	1 197 13
	@%p48 bra 	$L__BB7_64;

	.loc	1 198 17
	ld.shared.f32 	%f179, [_ZZ16efield_reduce_l1E5sdata];
	mad.lo.s32 	%r219, %r220, %r82, %r5;
	mul.wide.u32 	%rd90, %r219, 4;
	add.s64 	%rd91, %rd4, %rd90;
	st.global.f32 	[%rd91], %f179;
	.loc	1 199 17
	ld.shared.f32 	%f180, [_ZZ16efield_reduce_l1E5tdata];
	add.s64 	%rd92, %rd5, %rd90;
	st.global.f32 	[%rd92], %f180;

$L__BB7_64:
	.loc	1 201 13
	bar.sync 	0;
	.loc	1 155 36
	add.s32 	%r220, %r220, 1;
	.loc	1 155 9
	setp.lt.s32 	%p49, %r220, %r81;
	@%p49 bra 	$L__BB7_2;

$L__BB7_65:
	.loc	1 203 5
	ret;

}
	// .globl	efield_reduce_l2
.visible .entry efield_reduce_l2(
	.param .u64 efield_reduce_l2_param_0,
	.param .u64 efield_reduce_l2_param_1,
	.param .u32 efield_reduce_l2_param_2,
	.param .u64 efield_reduce_l2_param_3,
	.param .u64 efield_reduce_l2_param_4,
	.param .u64 efield_reduce_l2_param_5
)
{
	.reg .pred 	%p<27>;
	.reg .f32 	%f<188>;
	.reg .b32 	%r<81>;
	.reg .b64 	%rd<50>;
	.loc	1 205 0
	// demoted variable
	.shared .align 4 .b8 _ZZ16efield_reduce_l2E5sdata[16384];
	// demoted variable
	.shared .align 4 .b8 _ZZ16efield_reduce_l2E5tdata[16384];

	ld.param.u64 	%rd13, [efield_reduce_l2_param_0];
	ld.param.u64 	%rd14, [efield_reduce_l2_param_1];
	ld.param.u32 	%r33, [efield_reduce_l2_param_2];
	ld.param.u64 	%rd10, [efield_reduce_l2_param_3];
	ld.param.u64 	%rd11, [efield_reduce_l2_param_4];
	ld.param.u64 	%rd12, [efield_reduce_l2_param_5];
	.loc	1 213 9
	cvta.to.global.u64 	%rd1, %rd14;
	cvta.to.global.u64 	%rd3, %rd13;
	.loc	1 215 9
	mov.u32 	%r1, %ntid.x;
	.loc	1 216 9
	mov.u32 	%r2, %ctaid.x;
	.loc	1 213 9
	mov.u32 	%r3, %tid.x;
	.loc	1 218 9
	shl.b32 	%r34, %r3, 2;
	mov.u32 	%r35, _ZZ16efield_reduce_l2E5sdata;
	add.s32 	%r4, %r35, %r34;
	mov.u32 	%r36, 0;
	st.shared.u32 	[%r4], %r36;
	.loc	1 219 9
	mov.u32 	%r37, _ZZ16efield_reduce_l2E5tdata;
	add.s32 	%r5, %r37, %r34;
	st.shared.u32 	[%r5], %r36;
	.loc	1 221 9
	setp.ge.s32 	%p1, %r3, %r33;
	@%p1 bra 	$L__BB8_18;

	.loc	1 215 9
	shl.b32 	%r6, %r1, 1;
	mul.lo.s32 	%r7, %r2, %r33;
	.loc	1 224 13
	not.b32 	%r38, %r3;
	add.s32 	%r39, %r38, %r33;
	div.u32 	%r8, %r39, %r6;
	add.s32 	%r40, %r8, 1;
	and.b32  	%r77, %r40, 3;
	setp.eq.s32 	%p2, %r77, 0;
	mov.f32 	%f175, 0f00000000;
	mov.f32 	%f176, %f175;
	mov.u32 	%r80, %r3;
	@%p2 bra 	$L__BB8_6;

	add.s32 	%r75, %r3, %r1;
	add.s32 	%r76, %r75, %r7;
	add.s32 	%r74, %r3, %r7;
	mov.f32 	%f175, 0f00000000;

$L__BB8_3:
	.pragma "nounroll";
	.loc	1 222 13
	mul.wide.s32 	%rd15, %r74, 4;
	add.s64 	%rd16, %rd3, %rd15;
	ld.global.f32 	%f55, [%rd16];
	add.f32 	%f176, %f55, %f176;
	.loc	1 223 13
	add.s64 	%rd17, %rd1, %rd15;
	ld.global.f32 	%f56, [%rd17];
	add.f32 	%f175, %f56, %f175;
	.loc	1 224 13
	setp.ge.u32 	%p3, %r75, %r33;
	@%p3 bra 	$L__BB8_5;

	.loc	1 225 17
	mul.wide.u32 	%rd18, %r76, 4;
	add.s64 	%rd19, %rd3, %rd18;
	ld.global.f32 	%f57, [%rd19];
	add.f32 	%f176, %f57, %f176;
	.loc	1 226 17
	add.s64 	%rd20, %rd1, %rd18;
	ld.global.f32 	%f58, [%rd20];
	add.f32 	%f175, %f58, %f175;

$L__BB8_5:
	.loc	1 228 13
	add.s32 	%r80, %r75, %r1;
	.loc	1 221 9
	add.s32 	%r76, %r76, %r6;
	add.s32 	%r75, %r75, %r6;
	add.s32 	%r74, %r74, %r6;
	add.s32 	%r77, %r77, -1;
	setp.ne.s32 	%p4, %r77, 0;
	@%p4 bra 	$L__BB8_3;

$L__BB8_6:
	.loc	1 224 13
	setp.lt.u32 	%p5, %r8, 3;
	@%p5 bra 	$L__BB8_17;

	add.s32 	%r23, %r80, %r7;
	.loc	1 222 13
	shl.b32 	%r24, %r1, 3;
	.loc	1 224 13
	mul.wide.s32 	%rd5, %r6, 4;
	mov.u32 	%r79, 0;

$L__BB8_8:
	.loc	1 222 13
	mad.lo.s32 	%r42, %r24, %r79, %r23;
	mul.wide.s32 	%rd6, %r42, 4;
	add.s64 	%rd21, %rd3, %rd6;
	ld.global.f32 	%f59, [%rd21];
	add.f32 	%f178, %f59, %f176;
	.loc	1 223 13
	add.s64 	%rd22, %rd1, %rd6;
	ld.global.f32 	%f60, [%rd22];
	add.f32 	%f177, %f60, %f175;
	.loc	1 224 13
	add.s32 	%r27, %r80, %r1;
	setp.ge.u32 	%p6, %r27, %r33;
	@%p6 bra 	$L__BB8_10;

	.loc	1 225 17
	add.s32 	%r43, %r27, %r7;
	mul.wide.u32 	%rd23, %r43, 4;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.f32 	%f61, [%rd24];
	add.f32 	%f178, %f61, %f178;
	.loc	1 226 17
	add.s64 	%rd25, %rd1, %rd23;
	ld.global.f32 	%f62, [%rd25];
	add.f32 	%f177, %f62, %f177;

$L__BB8_10:
	.loc	1 222 13
	add.s64 	%rd7, %rd5, %rd6;
	add.s64 	%rd26, %rd3, %rd7;
	ld.global.f32 	%f63, [%rd26];
	add.f32 	%f180, %f63, %f178;
	.loc	1 223 13
	add.s64 	%rd27, %rd1, %rd7;
	ld.global.f32 	%f64, [%rd27];
	add.f32 	%f179, %f64, %f177;
	.loc	1 228 13
	add.s32 	%r44, %r27, %r1;
	.loc	1 224 13
	add.s32 	%r28, %r44, %r1;
	setp.ge.u32 	%p7, %r28, %r33;
	@%p7 bra 	$L__BB8_12;

	.loc	1 225 17
	add.s32 	%r45, %r28, %r7;
	mul.wide.u32 	%rd28, %r45, 4;
	add.s64 	%rd29, %rd3, %rd28;
	ld.global.f32 	%f65, [%rd29];
	add.f32 	%f180, %f65, %f180;
	.loc	1 226 17
	add.s64 	%rd30, %rd1, %rd28;
	ld.global.f32 	%f66, [%rd30];
	add.f32 	%f179, %f66, %f179;

$L__BB8_12:
	.loc	1 222 13
	add.s64 	%rd8, %rd5, %rd7;
	add.s64 	%rd31, %rd3, %rd8;
	ld.global.f32 	%f67, [%rd31];
	add.f32 	%f182, %f67, %f180;
	.loc	1 223 13
	add.s64 	%rd32, %rd1, %rd8;
	ld.global.f32 	%f68, [%rd32];
	add.f32 	%f181, %f68, %f179;
	.loc	1 228 13
	add.s32 	%r46, %r28, %r1;
	.loc	1 224 13
	add.s32 	%r29, %r46, %r1;
	setp.ge.u32 	%p8, %r29, %r33;
	@%p8 bra 	$L__BB8_14;

	.loc	1 225 17
	add.s32 	%r47, %r29, %r7;
	mul.wide.u32 	%rd33, %r47, 4;
	add.s64 	%rd34, %rd3, %rd33;
	ld.global.f32 	%f69, [%rd34];
	add.f32 	%f182, %f69, %f182;
	.loc	1 226 17
	add.s64 	%rd35, %rd1, %rd33;
	ld.global.f32 	%f70, [%rd35];
	add.f32 	%f181, %f70, %f181;

$L__BB8_14:
	.loc	1 222 13
	add.s64 	%rd36, %rd5, %rd8;
	add.s64 	%rd37, %rd3, %rd36;
	ld.global.f32 	%f71, [%rd37];
	add.f32 	%f176, %f71, %f182;
	.loc	1 223 13
	add.s64 	%rd38, %rd1, %rd36;
	ld.global.f32 	%f72, [%rd38];
	add.f32 	%f175, %f72, %f181;
	.loc	1 228 13
	add.s32 	%r48, %r29, %r1;
	.loc	1 224 13
	add.s32 	%r30, %r48, %r1;
	setp.ge.u32 	%p9, %r30, %r33;
	@%p9 bra 	$L__BB8_16;

	.loc	1 225 17
	add.s32 	%r49, %r30, %r7;
	mul.wide.u32 	%rd39, %r49, 4;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f32 	%f73, [%rd40];
	add.f32 	%f176, %f73, %f176;
	.loc	1 226 17
	add.s64 	%rd41, %rd1, %rd39;
	ld.global.f32 	%f74, [%rd41];
	add.f32 	%f175, %f74, %f175;

$L__BB8_16:
	.loc	1 228 13
	add.s32 	%r80, %r30, %r1;
	.loc	1 221 9
	setp.lt.s32 	%p10, %r80, %r33;
	add.s32 	%r79, %r79, 1;
	@%p10 bra 	$L__BB8_8;

$L__BB8_17:
	.loc	1 225 17
	st.shared.f32 	[%r4], %f176;
	.loc	1 226 17
	st.shared.f32 	[%r5], %f175;

$L__BB8_18:
	.loc	1 230 9
	bar.sync 	0;
	.loc	1 242 9
	setp.gt.s32 	%p11, %r3, 127;
	@%p11 bra 	$L__BB8_20;

	.loc	1 243 13
	ld.shared.f32 	%f75, [%r4];
	ld.shared.f32 	%f76, [%r4+512];
	add.f32 	%f77, %f76, %f75;
	st.shared.f32 	[%r4], %f77;
	.loc	1 244 13
	ld.shared.f32 	%f78, [%r5+512];
	ld.shared.f32 	%f79, [%r5];
	add.f32 	%f80, %f78, %f79;
	st.shared.f32 	[%r5], %f80;

$L__BB8_20:
	.loc	1 246 9
	bar.sync 	0;
	.loc	1 247 9
	setp.gt.s32 	%p12, %r3, 63;
	@%p12 bra 	$L__BB8_22;

	.loc	1 248 13
	ld.shared.f32 	%f81, [%r4];
	ld.shared.f32 	%f82, [%r4+256];
	add.f32 	%f83, %f82, %f81;
	st.shared.f32 	[%r4], %f83;
	.loc	1 249 13
	ld.shared.f32 	%f84, [%r5+256];
	ld.shared.f32 	%f85, [%r5];
	add.f32 	%f86, %f84, %f85;
	st.shared.f32 	[%r5], %f86;

$L__BB8_22:
	.loc	1 251 9
	bar.sync 	0;
	.loc	1 253 9
	setp.gt.s32 	%p13, %r3, 31;
	@%p13 bra 	$L__BB8_24;

	.loc	1 254 13
	.loc	1 10 9, function_name $L__info_string3, inlined_at 1 254 13
	ld.volatile.shared.f32 	%f87, [%r4];
	ld.volatile.shared.f32 	%f88, [%r4+128];
	add.f32 	%f89, %f88, %f87;
	st.volatile.shared.f32 	[%r4], %f89;
	.loc	1 11 9, function_name $L__info_string3, inlined_at 1 254 13
	ld.volatile.shared.f32 	%f90, [%r4];
	ld.volatile.shared.f32 	%f91, [%r4+64];
	add.f32 	%f92, %f91, %f90;
	st.volatile.shared.f32 	[%r4], %f92;
	.loc	1 12 9, function_name $L__info_string3, inlined_at 1 254 13
	ld.volatile.shared.f32 	%f93, [%r4];
	ld.volatile.shared.f32 	%f94, [%r4+32];
	add.f32 	%f95, %f94, %f93;
	st.volatile.shared.f32 	[%r4], %f95;
	.loc	1 13 9, function_name $L__info_string3, inlined_at 1 254 13
	ld.volatile.shared.f32 	%f96, [%r4];
	ld.volatile.shared.f32 	%f97, [%r4+16];
	add.f32 	%f98, %f97, %f96;
	st.volatile.shared.f32 	[%r4], %f98;
	.loc	1 14 9, function_name $L__info_string3, inlined_at 1 254 13
	ld.volatile.shared.f32 	%f99, [%r4];
	ld.volatile.shared.f32 	%f100, [%r4+8];
	add.f32 	%f101, %f100, %f99;
	st.volatile.shared.f32 	[%r4], %f101;
	.loc	1 15 9, function_name $L__info_string3, inlined_at 1 254 13
	ld.volatile.shared.f32 	%f102, [%r4];
	ld.volatile.shared.f32 	%f103, [%r4+4];
	add.f32 	%f104, %f103, %f102;
	st.volatile.shared.f32 	[%r4], %f104;
	.loc	1 255 13
	.loc	1 10 9, function_name $L__info_string3, inlined_at 1 255 13
	ld.volatile.shared.f32 	%f105, [%r5];
	ld.volatile.shared.f32 	%f106, [%r5+128];
	add.f32 	%f107, %f106, %f105;
	st.volatile.shared.f32 	[%r5], %f107;
	.loc	1 11 9, function_name $L__info_string3, inlined_at 1 255 13
	ld.volatile.shared.f32 	%f108, [%r5];
	ld.volatile.shared.f32 	%f109, [%r5+64];
	add.f32 	%f110, %f109, %f108;
	st.volatile.shared.f32 	[%r5], %f110;
	.loc	1 12 9, function_name $L__info_string3, inlined_at 1 255 13
	ld.volatile.shared.f32 	%f111, [%r5];
	ld.volatile.shared.f32 	%f112, [%r5+32];
	add.f32 	%f113, %f112, %f111;
	st.volatile.shared.f32 	[%r5], %f113;
	.loc	1 13 9, function_name $L__info_string3, inlined_at 1 255 13
	ld.volatile.shared.f32 	%f114, [%r5];
	ld.volatile.shared.f32 	%f115, [%r5+16];
	add.f32 	%f116, %f115, %f114;
	st.volatile.shared.f32 	[%r5], %f116;
	.loc	1 14 9, function_name $L__info_string3, inlined_at 1 255 13
	ld.volatile.shared.f32 	%f117, [%r5];
	ld.volatile.shared.f32 	%f118, [%r5+8];
	add.f32 	%f119, %f118, %f117;
	st.volatile.shared.f32 	[%r5], %f119;
	.loc	1 15 9, function_name $L__info_string3, inlined_at 1 255 13
	ld.volatile.shared.f32 	%f120, [%r5];
	ld.volatile.shared.f32 	%f121, [%r5+4];
	add.f32 	%f122, %f121, %f120;
	st.volatile.shared.f32 	[%r5], %f122;

$L__BB8_24:
	.loc	1 257 9
	setp.ne.s32 	%p14, %r3, 0;
	@%p14 bra 	$L__BB8_31;

	.loc	1 258 13
	ld.const.f32 	%f123, [g_slm+8];
	ld.shared.f32 	%f41, [_ZZ16efield_reduce_l2E5sdata];
	mul.f32 	%f124, %f123, %f41;
	.loc	1 259 13
	ld.shared.f32 	%f42, [_ZZ16efield_reduce_l2E5tdata];
	mul.f32 	%f125, %f123, %f42;
	.loc	1 260 13
	abs.f32 	%f126, %f124;
	abs.f32 	%f127, %f125;
	mov.b32 	%r50, %f127;
	mov.b32 	%r51, %f126;
	min.s32 	%r52, %r50, %r51;
	mov.b32 	%f128, %r52;
	max.s32 	%r53, %r50, %r51;
	mov.b32 	%f129, %r53;
	and.b32  	%r54, %r53, -33554432;
	mov.u32 	%r55, 2122317824;
	sub.s32 	%r56, %r55, %r54;
	mov.b32 	%f130, %r56;
	mul.f32 	%f131, %f128, %f130;
	mul.f32 	%f132, %f129, %f130;
	mul.f32 	%f133, %f131, %f131;
	fma.rn.f32 	%f134, %f132, %f132, %f133;
	sqrt.rn.f32 	%f135, %f134;
	or.b32  	%r57, %r54, 8388608;
	mov.b32 	%f136, %r57;
	mul.f32 	%f137, %f135, %f136;
	setp.eq.f32 	%p15, %f128, 0f00000000;
	selp.f32 	%f138, %f129, %f137, %p15;
	setp.eq.f32 	%p16, %f128, 0f7F800000;
	selp.f32 	%f43, 0f7F800000, %f138, %p16;
	.loc	1 261 13
	cvt.s64.s32 	%rd9, %r2;
	.loc	1 213 9
	cvta.to.global.u64 	%rd42, %rd10;
	.loc	1 261 13
	mul.wide.s32 	%rd43, %r2, 4;
	add.s64 	%rd44, %rd42, %rd43;
	st.global.f32 	[%rd44], %f43;
	.loc	1 262 13
	abs.f32 	%f44, %f41;
	abs.f32 	%f45, %f42;
	setp.eq.f32 	%p17, %f44, 0f00000000;
	setp.eq.f32 	%p18, %f45, 0f00000000;
	and.pred  	%p19, %p17, %p18;
	@%p19 bra 	$L__BB8_29;
	bra.uni 	$L__BB8_26;

$L__BB8_29:
	mov.b32 	%r68, %f41;
	shr.s32 	%r69, %r68, 31;
	and.b32  	%r70, %r69, 1078530011;
	mov.b32 	%r71, %f42;
	and.b32  	%r72, %r71, -2147483648;
	or.b32  	%r73, %r70, %r72;
	mov.b32 	%f187, %r73;
	bra.uni 	$L__BB8_30;

$L__BB8_26:
	setp.eq.f32 	%p20, %f44, 0f7F800000;
	setp.eq.f32 	%p21, %f45, 0f7F800000;
	and.pred  	%p22, %p20, %p21;
	@%p22 bra 	$L__BB8_28;
	bra.uni 	$L__BB8_27;

$L__BB8_28:
	mov.b32 	%r63, %f41;
	setp.lt.s32 	%p26, %r63, 0;
	selp.b32 	%r64, 1075235812, 1061752795, %p26;
	mov.b32 	%r65, %f42;
	and.b32  	%r66, %r65, -2147483648;
	or.b32  	%r67, %r64, %r66;
	mov.b32 	%f187, %r67;
	bra.uni 	$L__BB8_30;

$L__BB8_27:
	max.f32 	%f139, %f45, %f44;
	min.f32 	%f140, %f45, %f44;
	div.rn.f32 	%f141, %f140, %f139;
	mul.rn.f32 	%f142, %f141, %f141;
	mov.f32 	%f143, 0fC0B59883;
	mov.f32 	%f144, 0fBF52C7EA;
	fma.rn.f32 	%f145, %f142, %f144, %f143;
	mov.f32 	%f146, 0fC0D21907;
	fma.rn.f32 	%f147, %f145, %f142, %f146;
	mul.f32 	%f148, %f142, %f147;
	mul.f32 	%f149, %f141, %f148;
	add.f32 	%f150, %f142, 0f41355DC0;
	mov.f32 	%f151, 0f41E6BD60;
	fma.rn.f32 	%f152, %f150, %f142, %f151;
	mov.f32 	%f153, 0f419D92C8;
	fma.rn.f32 	%f154, %f152, %f142, %f153;
	rcp.rn.f32 	%f155, %f154;
	fma.rn.f32 	%f156, %f149, %f155, %f141;
	mov.f32 	%f157, 0f3FC90FDB;
	sub.f32 	%f158, %f157, %f156;
	setp.gt.f32 	%p23, %f45, %f44;
	selp.f32 	%f159, %f158, %f156, %p23;
	mov.b32 	%r58, %f41;
	setp.lt.s32 	%p24, %r58, 0;
	mov.f32 	%f160, 0f40490FDB;
	sub.f32 	%f161, %f160, %f159;
	selp.f32 	%f162, %f161, %f159, %p24;
	mov.b32 	%r59, %f162;
	mov.b32 	%r60, %f42;
	and.b32  	%r61, %r60, -2147483648;
	or.b32  	%r62, %r61, %r59;
	mov.b32 	%f163, %r62;
	add.f32 	%f164, %f44, %f45;
	setp.le.f32 	%p25, %f164, 0f7F800000;
	selp.f32 	%f187, %f163, %f164, %p25;

$L__BB8_30:
	.loc	1 213 9
	cvta.to.global.u64 	%rd45, %rd11;
	.loc	1 262 13
	shl.b64 	%rd46, %rd9, 2;
	add.s64 	%rd47, %rd45, %rd46;
	st.global.f32 	[%rd47], %f187;
	.loc	1 213 9
	cvta.to.global.u64 	%rd48, %rd12;
	.loc	1 263 13
	add.s64 	%rd49, %rd48, %rd46;
	ld.global.f32 	%f165, [%rd49];
	div.rn.f32 	%f166, %f165, %f43;
	st.global.f32 	[%rd49], %f166;

$L__BB8_31:
	.loc	1 265 9
	bar.sync 	0;
	.loc	1 266 5
	ret;

}
	.file	1 "C:\\Users\\mk007\\coding projects\\slmcuda_core\\kernels\\slimcuda_og.cu"
	.file	2 "C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.44.35207\\include\\cmath"
	.section	.debug_str
	{
$L__info_string0:
.b8 95,90,53,97,116,97,110,50,102,102,0
$L__info_string1:
.b8 95,90,51,99,111,115,102,0
$L__info_string2:
.b8 95,90,51,115,105,110,102,0
$L__info_string3:
.b8 119,97,114,112,82,101,100,117,99,101,0

	}
