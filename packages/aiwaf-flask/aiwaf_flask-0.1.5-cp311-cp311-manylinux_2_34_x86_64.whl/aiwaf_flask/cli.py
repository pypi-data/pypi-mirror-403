#!/usr/bin/env python3
"""
AIWAF Flask CLI Management Tool

Provides command-line functions for managing AIWAF data:
- Add/remove IPs from whitelist/blacklist
- View current lists
- Clear data
- Import/export configurations
"""

import argparse
import sys
import json
from collections import Counter
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict, Any
import importlib

def get_storage_instance():
    """Get storage instance based on available configuration."""
    try:
        # Import storage functions directly without importing Flask dependencies
        import csv
        import os
        from pathlib import Path
        
        def _get_data_dir():
            """Get data directory path with automatic configuration."""
            try:
                from .auto_config import get_auto_configured_data_dir, print_auto_config_info
                data_dir, config_info = get_auto_configured_data_dir()
                
                # Only print detailed info in verbose mode or if explicitly requested
                if len(sys.argv) > 1 and '--verbose' in sys.argv:
                    print_auto_config_info(config_info)
                
                return data_dir
            except ImportError:
                # Fallback to original logic if auto_config not available
                return os.environ.get('AIWAF_DATA_DIR', 'aiwaf_data')
        
        def _read_csv_whitelist():
            """Read whitelist from CSV."""
            data_dir = Path(_get_data_dir())
            data_dir.mkdir(exist_ok=True)
            whitelist_file = data_dir / 'whitelist.csv'
            
            whitelist = set()
            if whitelist_file.exists():
                with open(whitelist_file, 'r', newline='') as f:
                    reader = csv.reader(f)
                    next(reader, None)  # Skip header
                    for row in reader:
                        if row and len(row) > 0:
                            whitelist.add(row[0])
            return whitelist
        
        def _read_csv_blacklist():
            """Read blacklist from CSV."""
            data_dir = Path(_get_data_dir())
            data_dir.mkdir(exist_ok=True)
            blacklist_file = data_dir / 'blacklist.csv'
            
            blacklist = {}
            if blacklist_file.exists():
                with open(blacklist_file, 'r', newline='') as f:
                    reader = csv.reader(f)
                    next(reader, None)  # Skip header
                    for row in reader:
                        if row and len(row) >= 2:
                            ip = row[0]
                            timestamp = row[1] if len(row) > 1 else ''
                            reason = row[2] if len(row) > 2 else ''
                            blacklist[ip] = {'timestamp': timestamp, 'reason': reason}
            return blacklist
        
        def _read_csv_keywords():
            """Read keywords from CSV."""
            data_dir = Path(_get_data_dir())
            data_dir.mkdir(exist_ok=True)
            keywords_file = data_dir / 'keywords.csv'
            
            keywords = set()
            if keywords_file.exists():
                with open(keywords_file, 'r', newline='') as f:
                    reader = csv.reader(f)
                    next(reader, None)  # Skip header
                    for row in reader:
                        if row and len(row) > 0:
                            keywords.add(row[0])
            return keywords

        def _read_csv_path_exemptions():
            """Read path exemptions from CSV."""
            data_dir = Path(_get_data_dir())
            data_dir.mkdir(exist_ok=True)
            path_file = data_dir / 'path_exemptions.csv'

            exemptions = {}
            if path_file.exists():
                with open(path_file, 'r', newline='') as f:
                    reader = csv.reader(f)
                    next(reader, None)  # Skip header
                    for row in reader:
                        if row and len(row) > 0:
                            path = row[0].strip()
                            reason = row[1].strip() if len(row) > 1 else ''
                            if path:
                                exemptions[path.lower()] = reason
            return exemptions

        def _read_csv_geo_blocked_countries():
            """Read geo blocked countries from CSV."""
            data_dir = Path(_get_data_dir())
            data_dir.mkdir(exist_ok=True)
            countries_file = data_dir / 'geo_blocked_countries.csv'

            countries = set()
            if countries_file.exists():
                with open(countries_file, 'r', newline='') as f:
                    reader = csv.reader(f)
                    next(reader, None)  # Skip header
                    for row in reader:
                        if row and len(row) > 0:
                            countries.add(row[0].upper())
            return countries
        
        def _append_csv_whitelist(ip):
            """Add IP to whitelist CSV."""
            data_dir = Path(_get_data_dir())
            data_dir.mkdir(exist_ok=True)
            whitelist_file = data_dir / 'whitelist.csv'
            
            # Check if file exists and has header
            file_exists = whitelist_file.exists()
            with open(whitelist_file, 'a', newline='') as f:
                writer = csv.writer(f)
                if not file_exists:
                    writer.writerow(['ip', 'timestamp'])
                writer.writerow([ip, datetime.now().isoformat()])
        
        def _append_csv_blacklist(ip, reason="Manual addition"):
            """Add IP to blacklist CSV."""
            data_dir = Path(_get_data_dir())
            data_dir.mkdir(exist_ok=True)
            blacklist_file = data_dir / 'blacklist.csv'
            
            # Check if file exists and has header
            file_exists = blacklist_file.exists()
            with open(blacklist_file, 'a', newline='') as f:
                writer = csv.writer(f)
                if not file_exists:
                    writer.writerow(['ip', 'timestamp', 'reason'])
                writer.writerow([ip, datetime.now().isoformat(), reason])
        
        def _append_csv_keyword(keyword):
            """Add keyword to keywords CSV."""
            data_dir = Path(_get_data_dir())
            data_dir.mkdir(exist_ok=True)
            keywords_file = data_dir / 'keywords.csv'
            
            # Check if file exists and has header
            file_exists = keywords_file.exists()
            with open(keywords_file, 'a', newline='') as f:
                writer = csv.writer(f)
                if not file_exists:
                    writer.writerow(['keyword', 'timestamp'])
                writer.writerow([keyword, datetime.now().isoformat()])

        def _append_csv_path_exemption(path, reason=""):
            """Add path exemption to CSV."""
            data_dir = Path(_get_data_dir())
            data_dir.mkdir(exist_ok=True)
            path_file = data_dir / 'path_exemptions.csv'

            file_exists = path_file.exists()
            with open(path_file, 'a', newline='') as f:
                writer = csv.writer(f)
                if not file_exists:
                    writer.writerow(['path', 'reason', 'timestamp'])
                writer.writerow([path, reason, datetime.now().isoformat()])

        def _rewrite_csv_path_exemptions(exemptions):
            """Rewrite path exemptions CSV."""
            data_dir = Path(_get_data_dir())
            data_dir.mkdir(exist_ok=True)
            path_file = data_dir / 'path_exemptions.csv'
            with open(path_file, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(['path', 'reason', 'timestamp'])
                for path, reason in exemptions.items():
                    writer.writerow([path, reason, datetime.now().isoformat()])

        def _append_csv_geo_blocked_country(country_code):
            """Add country code to geo blocked countries CSV."""
            data_dir = Path(_get_data_dir())
            data_dir.mkdir(exist_ok=True)
            countries_file = data_dir / 'geo_blocked_countries.csv'

            file_exists = countries_file.exists()
            with open(countries_file, 'a', newline='') as f:
                writer = csv.writer(f)
                if not file_exists:
                    writer.writerow(['country', 'timestamp'])
                writer.writerow([country_code.upper(), datetime.now().isoformat()])

        def _rewrite_csv_geo_blocked_countries(countries):
            """Rewrite geo blocked countries CSV."""
            data_dir = Path(_get_data_dir())
            data_dir.mkdir(exist_ok=True)
            countries_file = data_dir / 'geo_blocked_countries.csv'

            with open(countries_file, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(['country', 'timestamp'])
                for code in sorted(countries):
                    writer.writerow([code, datetime.now().isoformat()])
        
        return {
            'read_whitelist': _read_csv_whitelist,
            'read_blacklist': _read_csv_blacklist,
            'read_keywords': _read_csv_keywords,
            'read_geo_blocked_countries': _read_csv_geo_blocked_countries,
            'read_path_exemptions': _read_csv_path_exemptions,
            'add_whitelist': _append_csv_whitelist,
            'add_blacklist': _append_csv_blacklist,
            'add_keyword': _append_csv_keyword,
            'add_geo_blocked_country': _append_csv_geo_blocked_country,
            'rewrite_geo_blocked_countries': _rewrite_csv_geo_blocked_countries,
            'add_path_exemption': _append_csv_path_exemption,
            'rewrite_path_exemptions': _rewrite_csv_path_exemptions,
            'data_dir': _get_data_dir,
            'mode': 'CSV'
        }
    except Exception as e:
        print(f"‚ö†Ô∏è  Storage not available: {e}")
        return None

class AIWAFManager:
    """AIWAF management class for CLI operations."""
    
    def __init__(self, data_dir: Optional[str] = None):
        self.storage = get_storage_instance()
        if not self.storage:
            print("‚ùå No storage backend available")
            sys.exit(1)
        
        if data_dir:
            # Override data directory if specified
            import os
            os.environ['AIWAF_DATA_DIR'] = data_dir
            print(f"üìÅ Using specified data directory: {data_dir}")
        else:
            # Use auto-configuration
            try:
                from .auto_config import get_auto_configured_data_dir, print_auto_config_info
                auto_dir, config_info = get_auto_configured_data_dir()
                print_auto_config_info(config_info)
            except ImportError:
                print(f"üìÅ Using {self.storage['mode']} storage: {self.storage['data_dir']()}")
    
    def list_whitelist(self) -> List[str]:
        """Get all whitelisted IPs."""
        try:
            whitelist = self.storage['read_whitelist']()
            return sorted(list(whitelist))
        except Exception as e:
            print(f"‚ùå Error reading whitelist: {e}")
            return []
    
    def list_blacklist(self) -> Dict[str, Any]:
        """Get all blacklisted IPs with timestamps."""
        try:
            blacklist = self.storage['read_blacklist']()
            return dict(sorted(blacklist.items()))
        except Exception as e:
            print(f"‚ùå Error reading blacklist: {e}")
            return {}
    
    def list_keywords(self) -> List[str]:
        """Get all blocked keywords."""
        try:
            keywords = self.storage['read_keywords']()
            return sorted(list(keywords))
        except Exception as e:
            print(f"‚ùå Error reading keywords: {e}")
            return []

    def list_geo_blocked_countries(self) -> List[str]:
        """Get all geo blocked countries."""
        try:
            countries = self.storage['read_geo_blocked_countries']()
            return sorted(list(countries))
        except Exception as e:
            print(f"‚ùå Error reading geo blocked countries: {e}")
            return []

    def list_path_exemptions(self) -> Dict[str, str]:
        """Get all path exemptions."""
        try:
            return dict(self.storage['read_path_exemptions']())
        except Exception as e:
            print(f"‚ùå Error reading path exemptions: {e}")
            return {}
    
    def add_to_whitelist(self, ip: str) -> bool:
        """Add IP to whitelist."""
        try:
            self.storage['add_whitelist'](ip)
            print(f"‚úÖ Added {ip} to whitelist")
            return True
        except Exception as e:
            print(f"‚ùå Error adding {ip} to whitelist: {e}")
            return False
    
    def add_to_blacklist(self, ip: str, reason: str = "Manual CLI addition") -> bool:
        """Add IP to blacklist."""
        try:
            self.storage['add_blacklist'](ip, reason)
            print(f"‚úÖ Added {ip} to blacklist")
            return True
        except Exception as e:
            print(f"‚ùå Error adding {ip} to blacklist: {e}")
            return False
    
    def add_keyword(self, keyword: str) -> bool:
        """Add keyword to blocked list."""
        try:
            self.storage['add_keyword'](keyword)
            print(f"‚úÖ Added '{keyword}' to blocked keywords")
            return True
        except Exception as e:
            print(f"‚ùå Error adding keyword '{keyword}': {e}")
            return False

    def add_geo_blocked_country(self, country_code: str) -> bool:
        """Add country to geo blocked list."""
        if not country_code:
            print("‚ùå Country code is required")
            return False

    def add_path_exemption(self, path: str, reason: str = "") -> bool:
        """Add a path exemption."""
        if not path:
            print("‚ùå Path is required")
            return False
        normalized = str(path).strip()
        if not normalized:
            print("‚ùå Path is required")
            return False
        current = self.list_path_exemptions()
        if normalized.lower() in current:
            print(f"‚ö†Ô∏è  Already exempt: {normalized}")
            return True
        try:
            self.storage['add_path_exemption'](normalized, reason)
            print(f"‚úÖ Exempted path: {normalized}")
            return True
        except Exception as e:
            print(f"‚ùå Error adding path exemption: {e}")
            return False

    def remove_path_exemption(self, path: str) -> bool:
        """Remove a path exemption."""
        if not path:
            print("‚ùå Path is required")
            return False
        normalized = str(path).strip()
        if not normalized:
            print("‚ùå Path is required")
            return False
        exemptions = self.list_path_exemptions()
        if normalized.lower() not in exemptions:
            print(f"‚ö†Ô∏è  Not exempt: {normalized}")
            return False
        try:
            exemptions.pop(normalized.lower(), None)
            self.storage['rewrite_path_exemptions'](exemptions)
            print(f"‚úÖ Removed path exemption: {normalized}")
            return True
        except Exception as e:
            print(f"‚ùå Error removing path exemption: {e}")
            return False
        code = str(country_code).strip().upper()
        try:
            current = set(self.list_geo_blocked_countries())
            if code in current:
                print(f"‚ö†Ô∏è  {code} already blocked")
                return True
            self.storage['add_geo_blocked_country'](code)
            print(f"‚úÖ Blocked country added: {code}")
            return True
        except Exception as e:
            print(f"‚ùå Error adding geo blocked country '{code}': {e}")
            return False

    def remove_geo_blocked_country(self, country_code: str) -> bool:
        """Remove country from geo blocked list."""
        if not country_code:
            print("‚ùå Country code is required")
            return False
        code = str(country_code).strip().upper()
        try:
            current = set(self.list_geo_blocked_countries())
            if code not in current:
                print(f"‚ö†Ô∏è  {code} not found in geo blocked countries")
                return False
            current.discard(code)
            self.storage['rewrite_geo_blocked_countries'](current)
            print(f"‚úÖ Blocked country removed: {code}")
            return True
        except Exception as e:
            print(f"‚ùå Error removing geo blocked country '{code}': {e}")
            return False
    
    def remove_from_whitelist(self, ip: str) -> bool:
        """Remove IP from whitelist."""
        try:
            data_dir = Path(self.storage['data_dir']())
            whitelist_file = data_dir / 'whitelist.csv'
            
            if not whitelist_file.exists():
                print(f"‚ùå Whitelist file not found")
                return False
            
            # Read current data
            current = self.list_whitelist()
            if ip not in current:
                print(f"‚ö†Ô∏è  {ip} not found in whitelist")
                return False
            
            # Rewrite file without the IP
            import csv
            with open(whitelist_file, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(['ip', 'timestamp'])
                for existing_ip in current:
                    if existing_ip != ip:
                        writer.writerow([existing_ip, datetime.now().isoformat()])
            
            print(f"‚úÖ Removed {ip} from whitelist")
            return True
        except Exception as e:
            print(f"‚ùå Error removing {ip} from whitelist: {e}")
            return False
    
    def remove_from_blacklist(self, ip: str) -> bool:
        """Remove IP from blacklist."""
        try:
            data_dir = Path(self.storage['data_dir']())
            blacklist_file = data_dir / 'blacklist.csv'
            
            if not blacklist_file.exists():
                print(f"‚ùå Blacklist file not found")
                return False
            
            # Read current data
            current = self.list_blacklist()
            if ip not in current:
                print(f"‚ö†Ô∏è  {ip} not found in blacklist")
                return False
            
            # Rewrite file without the IP
            import csv
            with open(blacklist_file, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(['ip', 'timestamp', 'reason'])
                for existing_ip, data in current.items():
                    if existing_ip != ip:
                        if isinstance(data, dict):
                            timestamp = data.get('timestamp', '')
                            reason = data.get('reason', '')
                        else:
                            # Handle string format (reason only)
                            timestamp = datetime.now().isoformat()
                            reason = str(data) if data else ''
                        writer.writerow([existing_ip, timestamp, reason])
            
            print(f"‚úÖ Removed {ip} from blacklist")
            return True
        except Exception as e:
            print(f"‚ùå Error removing {ip} from blacklist: {e}")
            return False
    
    def show_stats(self):
        """Display statistics about current AIWAF data."""
        whitelist = self.list_whitelist()
        blacklist = self.list_blacklist()
        keywords = self.list_keywords()
        
        print("\nüìä AIWAF Statistics")
        print("=" * 50)
        print(f"Whitelisted IPs: {len(whitelist)}")
        print(f"Blacklisted IPs: {len(blacklist)}")
        print(f"Blocked Keywords: {len(keywords)}")
        print(f"Storage Mode: {self.storage['mode']}")
        print(f"Data Directory: {self.storage['data_dir']()}")
    
    def export_config(self, filename: str):
        """Export current configuration to JSON file."""
        try:
            config = {
                'whitelist': self.list_whitelist(),
                'blacklist': self.list_blacklist(),
                'keywords': self.list_keywords(),
                'exported_at': datetime.now().isoformat(),
                'storage_mode': self.storage['mode']
            }
            
            with open(filename, 'w') as f:
                json.dump(config, f, indent=2)
            
            print(f"‚úÖ Configuration exported to {filename}")
            return True
        except Exception as e:
            print(f"‚ùå Error exporting configuration: {e}")
            return False
    
    def import_config(self, filename: str):
        """Import configuration from JSON file."""
        try:
            with open(filename, 'r') as f:
                config = json.load(f)
            
            success_count = 0
            
            # Import whitelist
            for ip in config.get('whitelist', []):
                if self.add_to_whitelist(ip):
                    success_count += 1
            
            # Import blacklist
            for ip, data in config.get('blacklist', {}).items():
                reason = data.get('reason', 'Imported from config') if isinstance(data, dict) else 'Imported from config'
                if self.add_to_blacklist(ip, reason):
                    success_count += 1
            
            # Import keywords
            for keyword in config.get('keywords', []):
                if self.add_keyword(keyword):
                    success_count += 1
            
            print(f"‚úÖ Imported {success_count} items from {filename}")
            return True
        except Exception as e:
            print(f"‚ùå Error importing configuration: {e}")
            return False
    
    def analyze_logs(self, log_dir: Optional[str] = None, log_format: str = 'combined'):
        """Analyze AIWAF logs and show statistics."""
        try:
            from .logging_middleware import analyze_access_logs
            
            if log_dir:
                actual_log_dir = log_dir
                print(f"üìÅ Using specified log directory: {actual_log_dir}")
            else:
                # Use automatic log directory detection
                try:
                    from .auto_config import get_auto_configured_log_dir
                    actual_log_dir, log_config_info = get_auto_configured_log_dir()
                    print(f"üìÅ Auto-configured log directory: {actual_log_dir}")
                    method = log_config_info.get('detection_method', 'unknown')
                    print(f"üîç Log detection method: {method}")
                except ImportError:
                    # Fallback to relative path
                    actual_log_dir = 'logs'
                    print(f"üìÅ Using default log directory: {actual_log_dir}")
            
            stats = analyze_access_logs(actual_log_dir, log_format)
            
            if 'error' in stats:
                print(f"‚ùå {stats['error']}")
                return False
            
            print("\nüìä AIWAF Access Log Analysis")
            print("=" * 50)
            print(f"Total Requests: {stats['total_requests']}")
            print(f"Blocked Requests: {stats['blocked_requests']}")
            print(f"Unique IPs: {len(stats.get('ips', {}))}")
            print(f"Block Rate: {(stats['blocked_requests']/stats['total_requests']*100):.1f}%" if stats['total_requests'] > 0 else "Block Rate: 0.0%")
            
            # Performance metrics
            if 'avg_response_time' in stats:
                print(f"Average Response Time: {stats['avg_response_time']:.0f}ms")
                print(f"95th Percentile Response Time: {stats.get('p95_response_time', 0):.0f}ms")
            
            # Status code distribution
            if stats.get('status_codes'):
                print(f"\nüìà Status Code Distribution:")
                for code, count in sorted(stats['status_codes'].items()):
                    percentage = (count / stats['total_requests'] * 100) if stats['total_requests'] > 0 else 0
                    print(f"  ‚Ä¢ {code}: {count} ({percentage:.1f}%)")
            
            # Top IPs
            if stats.get('top_ips'):
                print(f"\nüåê Top Client IPs:")
                for ip, count in stats['top_ips'][:5]:
                    percentage = (count / stats['total_requests'] * 100) if stats['total_requests'] > 0 else 0
                    print(f"  ‚Ä¢ {ip}: {count} requests ({percentage:.1f}%)")
            
            # Top paths
            if stats.get('top_paths'):
                print(f"\nÔøΩ Most Requested Paths:")
                for path, count in stats['top_paths'][:5]:
                    print(f"  ‚Ä¢ {path}: {count} requests")
            
            # Blocked request reasons
            if stats.get('blocked_reasons'):
                print(f"\nüö´ Block Reasons:")
                for reason, count in sorted(stats['blocked_reasons'].items(), key=lambda x: x[1], reverse=True):
                    print(f"  ‚Ä¢ {reason}: {count} times")
            
            # Hourly distribution
            if stats.get('hourly_distribution'):
                print(f"\nüïê Hourly Request Distribution:")
                max_requests = max(stats['hourly_distribution'].values()) if stats['hourly_distribution'] else 1
                for hour in sorted(stats['hourly_distribution'].keys()):
                    count = stats['hourly_distribution'][hour]
                    bar_length = int((count / max_requests) * 30)  # Scale to 30 chars max
                    bar = "‚ñà" * bar_length
                    print(f"  {hour}:00 {bar:<30} {count}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error analyzing logs: {e}")
            return False

    def geoip_traffic_summary(self, log_dir: Optional[str] = None, top: int = 10, limit: int = 0):
        """Summarize request traffic by country using the GeoIP database."""
        try:
            from flask import Flask
            from .trainer import _trainer
            from .geoip import lookup_country_name

            top_n = max(1, int(top))
            max_lines = max(0, int(limit))

            if log_dir:
                actual_log_dir = log_dir
            else:
                try:
                    from .auto_config import get_auto_configured_log_dir
                    actual_log_dir, _ = get_auto_configured_log_dir()
                except ImportError:
                    actual_log_dir = 'logs'

            app = Flask(__name__)
            app.config['AIWAF_LOG_DIR'] = actual_log_dir
            _trainer.init_app(app)

            lines = _trainer._read_all_logs()
            if not lines:
                print("No log lines found ‚Äì check AIWAF_LOG_DIR setting.")
                return False

            ip_counts = Counter()
            processed = 0
            for line in lines:
                rec = _trainer._parse(line)
                if not rec:
                    continue
                ip_counts[rec["ip"]] += 1
                processed += 1
                if max_lines and processed >= max_lines:
                    break

            if not ip_counts:
                print("No valid log entries to process.")
                return False

            country_counts = Counter()
            unknown = 0
            for ip, count in ip_counts.items():
                name = lookup_country_name(ip, cache_prefix="aiwaf:geo:summary:", cache_seconds=3600)
                if name:
                    country_counts[name] += count
                else:
                    unknown += count

            print(f"GeoIP traffic summary (top {top_n}):")
            for code, count in country_counts.most_common(top_n):
                print(f"  - {code}: {count}")
            if unknown:
                print(f"  - UNKNOWN: {unknown}")
            return True
        except Exception as e:
            print(f"‚ùå GeoIP summary failed: {e}")
            return False
    
    def train_model(self, log_dir: Optional[str] = None, disable_ai: bool = False, 
                   min_ai_logs: int = 10000, force_ai: bool = False, verbose: bool = False):
        """Train AIWAF AI model from access logs."""
        try:
            from flask import Flask
            from .trainer import train_from_logs
            
            # Determine log directory
            if log_dir:
                actual_log_dir = log_dir
            else:
                # Use automatic log directory detection
                try:
                    from .auto_config import get_auto_configured_log_dir
                    actual_log_dir, log_config_info = get_auto_configured_log_dir()
                    if verbose:
                        method = log_config_info.get('detection_method', 'unknown')
                        print(f"üìÅ Auto-configured log directory: {actual_log_dir}")
                        print(f"üîç Log detection method: {method}")
                except ImportError:
                    # Fallback to relative path
                    actual_log_dir = 'logs'
            
            if verbose:
                print("üöÄ AIWAF Flask Training Tool")
                print("=" * 40)
                print(f"Log directory: {actual_log_dir}")
                print(f"AI training: {'disabled' if disable_ai else 'enabled'}")
                print(f"Min AI logs threshold: {min_ai_logs}")
                print(f"Force AI: {force_ai}")
                print("=" * 40)
            
            # Create minimal Flask app for training
            app = Flask(__name__)
            
            # Configure AIWAF settings
            app.config['AIWAF_LOG_DIR'] = actual_log_dir
            app.config['AIWAF_DYNAMIC_TOP_N'] = 15
            app.config['AIWAF_AI_CONTAMINATION'] = 0.05
            app.config['AIWAF_MIN_AI_LOGS'] = min_ai_logs
            app.config['AIWAF_FORCE_AI'] = force_ai
            
            # Optional settings (can be customized)
            app.config['AIWAF_EXEMPT_PATHS'] = {'/health', '/status', '/favicon.ico'}
            app.config['AIWAF_EXEMPT_KEYWORDS'] = ['health', 'status', 'ping', 'check']
            
            # Set data directory for training
            if hasattr(self, 'storage') and 'data_dir' in self.storage:
                app.config['AIWAF_DATA_DIR'] = self.storage['data_dir']()
            
            # Run training with app context
            with app.app_context():
                train_from_logs(app, disable_ai=disable_ai)
            
            if verbose:
                print("\n‚úÖ Training completed successfully!")
                if not disable_ai:
                    print("ü§ñ AI model saved and ready for anomaly detection")
                else:
                    print("üìö Keyword learning completed")
                print("üõ°Ô∏è  Enhanced protection is now active!")
            else:
                print("‚úÖ Training completed successfully!")
            
            return True
            
        except ImportError as e:
            if 'flask' in str(e).lower():
                print("‚ùå Flask is required for training. Install with: pip install flask")
            else:
                print(f"‚ùå Missing training dependencies: {e}")
                if not disable_ai:
                    print("üí° Try with --disable-ai for keyword-only training")
            return False
        except Exception as e:
            print(f"‚ùå Training failed: {e}")
            if not disable_ai:
                print("üí° Try with --disable-ai if AI dependencies are missing")
            return False
    
    def model_diagnostics(self, check: bool = False, retrain: bool = False, info: bool = False):
        """Run model diagnostics and management."""
        try:
            from pathlib import Path
            import pickle
            import warnings
            
            # Use the same model path function as trainer
            from .trainer import get_default_model_path
            model_path = Path(get_default_model_path())
            
            if info or check:
                print("üîß AIWAF Model Diagnostics")
                print("=" * 50)
                print(f"üìÅ Model path: {model_path}")
                print(f"üìÑ Model exists: {model_path.exists()}")
                
                if not model_path.exists():
                    print("‚ùå No model found")
                    if retrain:
                        print("üîÑ Proceeding with training...")
                        return self.train_model(verbose=True)
                    else:
                        print("üí° Run 'aiwaf train' to create a model")
                        return False
            
            if check or info:
                # Try to load and check the model
                with warnings.catch_warnings(record=True) as w:
                    warnings.simplefilter("always")
                    
                    try:
                        # Use joblib instead of pickle (matches trainer save format)
                        import joblib
                        model_data = joblib.load(model_path)
                        
                        # Check for warnings
                        sklearn_warnings = [warning for warning in w 
                                          if 'sklearn' in str(warning.message).lower()]
                        
                        if sklearn_warnings:
                            print("‚ö†Ô∏è  Sklearn version compatibility warnings:")
                            for warning in sklearn_warnings:
                                print(f"   {warning.message}")
                            
                            if check:
                                print("\nüí° Model loads but may have compatibility issues")
                                print("   Consider retraining: aiwaf model --retrain")
                        else:
                            print("‚úÖ Model loads successfully without warnings")
                        
                        if info:
                            # Show model information
                            if isinstance(model_data, dict):
                                print("\nüìä Model Information:")
                                print(f"   Format: Enhanced (with metadata)")
                                for key, value in model_data.items():
                                    if key == 'model':
                                        print(f"   Model Type: {type(value).__name__}")
                                    else:
                                        print(f"   {key}: {value}")
                            else:
                                print("\nüìä Model Information:")
                                print(f"   Format: Legacy (direct model)")
                                print(f"   Model Type: {type(model_data).__name__}")
                        
                        # Get file stats
                        import os
                        file_stats = os.stat(model_path)
                        file_size = file_stats.st_size
                        modified_time = datetime.fromtimestamp(file_stats.st_mtime)
                        
                        if info:
                            print(f"\nüìÑ File Information:")
                            print(f"   Size: {file_size:,} bytes")
                            print(f"   Modified: {modified_time}")
                            
                            # Try to get sklearn version info
                            try:
                                import sklearn
                                print(f"   Current sklearn: {sklearn.__version__}")
                            except ImportError:
                                print(f"   Current sklearn: Not installed")
                        
                        return True
                        
                    except Exception as e:
                        print(f"‚ùå Error loading model: {e}")
                        if retrain:
                            print("üîÑ Model appears corrupted, proceeding with retraining...")
                            return self.train_model(verbose=True)
                        else:
                            print("üí° Model may be corrupted. Try: aiwaf model --retrain")
                            return False
            
            if retrain:
                print("üîÑ Retraining model with current dependencies...")
                return self.train_model(verbose=True)
            
            return True
            
        except Exception as e:
            print(f"‚ùå Model diagnostics failed: {e}")
            return False


class RouteNode:
    def __init__(self, name, full_path):
        self.name = name
        self.full_path = full_path
        self.children = {}
        self.is_endpoint = False


def _normalize_path(path, trailing_slash=True):
    path = str(path).strip()
    if not path.startswith("/"):
        path = "/" + path
    while "//" in path:
        path = path.replace("//", "/")
    if trailing_slash and not path.endswith("/"):
        path = path + "/"
    return path


def _collect_routes(app):
    routes = []
    for rule in app.url_map.iter_rules():
        if rule.endpoint == "static":
            continue
        routes.append(_normalize_path(rule.rule))
    return routes


def _build_tree(routes):
    root = RouteNode("/", "/")
    for route in routes:
        route = _normalize_path(route)
        parts = [p for p in route.strip("/").split("/") if p]
        node = root
        current = ""
        for part in parts:
            current = _normalize_path(f"{current}/{part}", trailing_slash=True)
            if part not in node.children:
                node.children[part] = RouteNode(part, current)
            node = node.children[part]
        node.is_endpoint = True
    return root


def _sorted_children(node):
    return sorted(node.children.values(), key=lambda n: n.name)


def _load_flask_app(app_path):
    module_path, _, obj = app_path.partition(":")
    if not module_path or not obj:
        raise ValueError("Use --app module:app or module:create_app")
    module = importlib.import_module(module_path)
    target = getattr(module, obj, None)
    if target is None:
        raise ValueError(f"App not found: {app_path}")
    if callable(target):
        return target()
    return target


def _resolve_target(current, arg):
    children = _sorted_children(current)
    if arg.isdigit():
        idx = int(arg) - 1
        if 0 <= idx < len(children):
            return children[idx]
        return None
    for child in children:
        if child.name == arg or f"{child.name}/" == arg:
            return child
    return None


def _route_shell(app, manager):
    routes = _collect_routes(app)
    root = _build_tree(routes)
    stack = [root]

    print("AIWAF route shell. Type 'help' for commands.")
    while True:
        current = stack[-1]
        prompt = f"aiwaf:{current.full_path}$ "
        try:
            raw = input(prompt).strip()
        except (EOFError, KeyboardInterrupt):
            print("\nExiting.")
            break

        if not raw or raw == "ls":
            children = _sorted_children(current)
            if current.is_endpoint and current is not root:
                print("(endpoint) .")
            if not children:
                print("(empty)")
                continue
            for idx, child in enumerate(children, 1):
                suffix = " (endpoint)" if child.is_endpoint else ""
                print(f"{idx}. {child.name}/{suffix}")
            continue

        parts = raw.split()
        cmd = parts[0].lower()
        arg = parts[1] if len(parts) > 1 else None

        if cmd in {"quit", "exit"}:
            break
        if cmd in {"help", "?"}:
            print("AIWAF Path Shell Commands:")
            print("  ls                     # list routes at current level")
            print("  cd <index|name>        # enter a route segment")
            print("  up / cd ..             # go up one level")
            print("  pwd                    # show current path prefix")
            print("  exempt <index|name|.>  # add exemption for selection or current path")
            print("  exit                   # quit")
            continue
        if cmd in {"up", ".."}:
            if len(stack) > 1:
                stack.pop()
            continue
        if cmd == "pwd":
            print(current.full_path)
            continue
        if cmd == "cd":
            if not arg:
                print("Usage: cd <index|name>")
                continue
            if arg == "..":
                if len(stack) > 1:
                    stack.pop()
                continue
            if arg == "/":
                stack[:] = [root]
                continue
            target = _resolve_target(current, arg)
            if not target:
                print(f"Unknown target: {arg}")
                continue
            stack.append(target)
            continue
        if cmd == "exempt":
            if not arg:
                print("Usage: exempt <index|name|.>")
                continue
            target = current if arg == "." else _resolve_target(current, arg)
            if not target:
                print(f"Unknown target: {arg}")
                continue
            path = target.full_path
            existing = set(manager.list_path_exemptions().keys())
            if path.lower() in existing:
                print(f"Already exempt: {path}")
                continue
            reason = input("Reason (optional): ").strip()
            manager.add_path_exemption(path, reason=reason or "Manual exemption")
            continue

        print(f"Unknown command: {cmd}")


def main():
    """Main CLI interface."""
    parser = argparse.ArgumentParser(description='AIWAF Flask Management Tool')
    parser.add_argument('--data-dir', help='Custom data directory path')
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # List commands
    list_parser = subparsers.add_parser('list', help='List current data')
    list_parser.add_argument('type', choices=['whitelist', 'blacklist', 'keywords', 'all'], 
                           help='Type of data to list')
    
    # Add commands
    add_parser = subparsers.add_parser('add', help='Add item to list')
    add_parser.add_argument('type', choices=['whitelist', 'blacklist', 'keyword'], 
                          help='Type of list to add to')
    add_parser.add_argument('value', help='IP address or keyword to add')
    add_parser.add_argument('--reason', help='Reason for blacklisting (blacklist only)')
    
    # Remove commands
    remove_parser = subparsers.add_parser('remove', help='Remove item from list')
    remove_parser.add_argument('type', choices=['whitelist', 'blacklist'], 
                             help='Type of list to remove from')
    remove_parser.add_argument('value', help='IP address to remove')

    # Geo blocked countries commands
    geo_parser = subparsers.add_parser('geo', help='Manage geo blocked countries')
    geo_parser.add_argument('action', choices=['add', 'remove', 'list'],
                            help='Action to perform')
    geo_parser.add_argument('country', nargs='?', help='ISO country code (e.g. US)')

    # Path exemption commands
    path_parser = subparsers.add_parser('exempt-path', help='Manage path exemptions')
    path_parser.add_argument('action', choices=['add', 'remove', 'list'],
                             help='Action to perform')
    path_parser.add_argument('path', nargs='?', help='Path to exempt (e.g. /health)')
    path_parser.add_argument('--reason', default='', help='Reason for exemption')
    
    # Stats command
    subparsers.add_parser('stats', help='Show statistics')
    
    # Log analysis command
    logs_parser = subparsers.add_parser('logs', help='Analyze request logs')
    logs_parser.add_argument('--log-dir', help='Custom log directory path')
    logs_parser.add_argument('--format', choices=['combined', 'common', 'csv', 'json'], 
                           default='combined', help='Log format to analyze')
    
    # Train command
    train_parser = subparsers.add_parser('train', help='Train AI model from logs')
    train_parser.add_argument('--log-dir', help='Custom log directory path (default: logs)')
    train_parser.add_argument('--disable-ai', action='store_true', 
                            help='Disable AI model training (keyword learning only)')
    train_parser.add_argument('--min-ai-logs', type=int, default=10000,
                            help='Minimum log lines required for AI training (default: 10000)')
    train_parser.add_argument('--force-ai', action='store_true',
                            help='Force AI training even with insufficient log data')
    train_parser.add_argument('--verbose', '-v', action='store_true',
                            help='Enable verbose output')
    
    # Model diagnostics command
    model_parser = subparsers.add_parser('model', help='Model diagnostics and management')
    model_parser.add_argument('--check', action='store_true',
                            help='Check model compatibility')
    model_parser.add_argument('--retrain', action='store_true',
                            help='Force retrain model with current dependencies')
    model_parser.add_argument('--info', action='store_true',
                            help='Show model information')
    
    # Export/Import commands
    export_parser = subparsers.add_parser('export', help='Export configuration')
    export_parser.add_argument('filename', help='Output JSON file')
    
    import_parser = subparsers.add_parser('import', help='Import configuration')
    import_parser.add_argument('filename', help='Input JSON file')

    # GeoIP summary command
    geo_summary_parser = subparsers.add_parser('geo-summary', help='GeoIP traffic summary from logs')
    geo_summary_parser.add_argument('--top', type=int, default=10,
                                    help='Number of top countries to display (default: 10)')
    geo_summary_parser.add_argument('--limit', type=int, default=0,
                                    help='Limit number of log lines processed (default: 0, no limit)')
    geo_summary_parser.add_argument('--log-dir', help='Custom log directory path (default: auto)')

    # Route shell command
    route_shell_parser = subparsers.add_parser('route-shell', help='Interactive route browser for exemptions')
    route_shell_parser.add_argument('--app', required=True, help='Flask app import path (module:app)')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # Initialize manager
    manager = AIWAFManager(args.data_dir)
    
    # Execute commands
    if args.command == 'list':
        if args.type == 'whitelist' or args.type == 'all':
            whitelist = manager.list_whitelist()
            print(f"\nüü¢ Whitelisted IPs ({len(whitelist)}):")
            for ip in whitelist:
                print(f"  ‚Ä¢ {ip}")
        
        if args.type == 'blacklist' or args.type == 'all':
            blacklist = manager.list_blacklist()
            print(f"\nüî¥ Blacklisted IPs ({len(blacklist)}):")
            for ip, data in blacklist.items():
                if isinstance(data, dict):
                    reason = data.get('reason', 'Unknown')
                    timestamp = data.get('timestamp', 'Unknown')
                    print(f"  ‚Ä¢ {ip} - {reason} ({timestamp})")
                else:
                    print(f"  ‚Ä¢ {ip}")
        
        if args.type == 'keywords' or args.type == 'all':
            keywords = manager.list_keywords()
            print(f"\nüö´ Blocked Keywords ({len(keywords)}):")
            for keyword in keywords:
                print(f"  ‚Ä¢ {keyword}")
    
    elif args.command == 'add':
        if args.type == 'whitelist':
            manager.add_to_whitelist(args.value)
        elif args.type == 'blacklist':
            reason = args.reason or "Manual CLI addition"
            manager.add_to_blacklist(args.value, reason)
        elif args.type == 'keyword':
            manager.add_keyword(args.value)
    
    elif args.command == 'remove':
        if args.type == 'whitelist':
            manager.remove_from_whitelist(args.value)
        elif args.type == 'blacklist':
            manager.remove_from_blacklist(args.value)

    elif args.command == 'geo':
        if args.action == 'list':
            countries = manager.list_geo_blocked_countries()
            if countries:
                print("Blocked countries: " + ", ".join(countries))
            else:
                print("Blocked countries: (none)")
        else:
            if not args.country:
                print("‚ùå Country code is required")
                return
            if args.action == 'add':
                manager.add_geo_blocked_country(args.country)
            elif args.action == 'remove':
                manager.remove_geo_blocked_country(args.country)

    elif args.command == 'exempt-path':
        if args.action == 'list':
            exemptions = manager.list_path_exemptions()
            if exemptions:
                for path, reason in sorted(exemptions.items()):
                    suffix = f" ({reason})" if reason else ""
                    print(f"{path}{suffix}")
            else:
                print("Path exemptions: (none)")
        else:
            if not args.path:
                print("‚ùå Path is required")
                return
            if args.action == 'add':
                manager.add_path_exemption(args.path, reason=args.reason)
            elif args.action == 'remove':
                manager.remove_path_exemption(args.path)
    
    elif args.command == 'stats':
        manager.show_stats()
    
    elif args.command == 'logs':
        log_format = getattr(args, 'format', 'combined')
        manager.analyze_logs(args.log_dir, log_format)
    
    elif args.command == 'train':
        manager.train_model(args.log_dir, args.disable_ai, args.min_ai_logs, args.force_ai, args.verbose)
    
    elif args.command == 'model':
        # Handle model diagnostics
        if not any([args.check, args.retrain, args.info]):
            # Default to showing info if no specific action
            args.info = True
        manager.model_diagnostics(args.check, args.retrain, args.info)
    
    elif args.command == 'export':
        manager.export_config(args.filename)
    
    elif args.command == 'import':
        manager.import_config(args.filename)

    elif args.command == 'geo-summary':
        manager.geoip_traffic_summary(args.log_dir, args.top, args.limit)

    elif args.command == 'route-shell':
        try:
            app = _load_flask_app(args.app)
        except Exception as e:
            print(f"‚ùå Failed to load app: {e}")
            return
        _route_shell(app, manager)

if __name__ == '__main__':
    main()
