"""Summary generation from indicator execution results."""

from pathlib import Path

import pandas as pd

from process_performance_indicators.constants import StandardColumnNames

SUCCESS_STATUS = "Success"


def _identify_relevant_columns(formatted_event_log: pd.DataFrame) -> set[str]:
    """Identify columns in the event log that are used by indicators."""
    known_columns = {e.value for e in StandardColumnNames}

    # Find which known columns exist in the event log
    existing_columns = set(formatted_event_log.columns)
    return known_columns.intersection(existing_columns)


def _count_by_dimension(results_df: pd.DataFrame, dimension: str) -> tuple[int, int]:
    """Count successful and total indicators for a given dimension."""
    dimension_df = results_df[results_df["dimension"] == dimension]
    success_count = len(dimension_df[dimension_df["status"] == SUCCESS_STATUS])
    total_count = len(dimension_df)
    return success_count, total_count


def _count_by_granularity(results_df: pd.DataFrame, granularity: str) -> tuple[int, int]:
    """Count successful and total indicators for a given granularity."""
    granularity_df = results_df[results_df["granularity"] == granularity]
    success_count = len(granularity_df[granularity_df["status"] == SUCCESS_STATUS])
    total_count = len(granularity_df)
    return success_count, total_count


def summary_to_csv(
    results_csv_path: str,
    output_csv_path: str,
    formatted_event_log_path: str,
) -> pd.DataFrame:
    """
    Generate a summary CSV from indicator execution results.

    Args:
        results_csv_path: Path to the results CSV file generated by run_indicators_to_csv
        output_csv_path: Path where the summary CSV will be saved
        formatted_event_log_path: Path to the formatted event log CSV

    Returns:
        DataFrame containing the summary statistics

    """
    # Read the results and event log
    results_df = pd.read_csv(results_csv_path)
    event_log_df = pd.read_csv(formatted_event_log_path)

    # Derive event log name from results CSV filename
    results_filename = Path(results_csv_path).name
    if results_filename.endswith("_results.csv"):
        event_log_name = results_filename[:-12]
    elif results_filename.endswith(".csv"):
        event_log_name = results_filename[:-4]
    else:
        event_log_name = results_filename

    # Identify relevant columns
    relevant_cols = _identify_relevant_columns(event_log_df)
    total_attributes = 21
    relevant_count = len(relevant_cols)

    # Calculate dimension statistics
    dimensions = ["general", "time", "cost", "quality", "flexibility"]
    dimension_stats = {}
    for dim in dimensions:
        success, total = _count_by_dimension(results_df, dim)
        percentage = (success / total * 100) if total > 0 else 0.0
        dimension_stats[f"{dim}_dimension"] = f"{success} / {total} ({percentage:.1f}%)"

    # Calculate granularity statistics
    granularity_mapping = {
        "instances": "activity_instance_granularity",
        "activities": "activity_granularity",
        "cases": "case_granularity",
        "groups": "group_of_cases_granularity",
    }
    granularity_stats = {}
    for gran, col_name in granularity_mapping.items():
        success, total = _count_by_granularity(results_df, gran)
        percentage = (success / total * 100) if total > 0 else 0.0
        granularity_stats[col_name] = f"{success} / {total} ({percentage:.1f}%)"

    # Calculate overall statistics
    total_success = len(results_df[results_df["status"] == SUCCESS_STATUS])
    total_indicators = len(results_df)
    overall_percentage = (total_success / total_indicators * 100) if total_indicators > 0 else 0.0

    # Build the summary row
    summary_row = {
        "event_log": event_log_name,
        "relevant_attributes": f"{relevant_count} / {total_attributes}",
        **dimension_stats,
        **granularity_stats,
        "overall": f"{total_success} / {total_indicators} ({overall_percentage:.1f}%)",
    }

    # Create DataFrame and save to CSV
    summary_df = pd.DataFrame([summary_row])
    summary_df.to_csv(output_csv_path, index=False)

    return summary_df
