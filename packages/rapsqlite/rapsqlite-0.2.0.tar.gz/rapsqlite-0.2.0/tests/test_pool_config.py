"""Robust tests for Phase 2.4 pool configuration (pool_size, connection_timeout)."""

import asyncio
import os
import sys
import tempfile

import pytest

import rapsqlite
from rapsqlite import connect


def _cleanup(path: str) -> None:
    if os.path.exists(path):
        try:
            os.unlink(path)
        except (PermissionError, OSError):
            if sys.platform != "win32":
                raise


@pytest.fixture
def test_db():
    with tempfile.NamedTemporaryFile(suffix=".db", delete=False) as f:
        path = f.name
    try:
        yield path
    finally:
        _cleanup(path)


# ---- Validation: negative values ----


@pytest.mark.asyncio
async def test_pool_size_rejects_negative(test_db):
    """Setting pool_size to a negative value raises ValueError."""
    async with connect(test_db) as db:
        with pytest.raises(ValueError, match="pool_size must be >= 0"):
            db.pool_size = -1
        assert db.pool_size is None


@pytest.mark.asyncio
async def test_connection_timeout_rejects_negative(test_db):
    """Setting connection_timeout to a negative value raises ValueError."""
    async with connect(test_db) as db:
        with pytest.raises(ValueError, match="connection_timeout must be >= 0"):
            db.connection_timeout = -1
        assert db.connection_timeout is None


# ---- Validation: invalid types ----


@pytest.mark.asyncio
async def test_pool_size_rejects_non_int(test_db):
    """Setting pool_size to a non-int (e.g. str) raises TypeError."""
    async with connect(test_db) as db:
        with pytest.raises((TypeError, ValueError)):
            db.pool_size = "10"


@pytest.mark.asyncio
async def test_connection_timeout_rejects_non_int(test_db):
    """Setting connection_timeout to a non-int (e.g. str) raises TypeError."""
    async with connect(test_db) as db:
        with pytest.raises((TypeError, ValueError)):
            db.connection_timeout = "30"


# ---- Config applied before first use ----


@pytest.mark.asyncio
async def test_pool_config_before_execute(test_db):
    """Set pool_size and connection_timeout before any DB op; execute works."""
    async with connect(test_db) as db:
        db.pool_size = 2
        db.connection_timeout = 5
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY)")
        await db.execute("INSERT INTO t DEFAULT VALUES")
        rows = await db.fetch_all("SELECT * FROM t")
        assert len(rows) == 1
        assert db.pool_size == 2
        assert db.connection_timeout == 5


@pytest.mark.asyncio
async def test_pool_config_before_fetch(test_db):
    """Set config before any op; fetch_* creates pool with config."""
    async with connect(test_db) as db:
        db.pool_size = 3
        db.connection_timeout = 10
        rows = await db.fetch_all("SELECT 1 AS a, 2 AS b")
        assert rows == [[1, 2]]
        assert db.pool_size == 3
        assert db.connection_timeout == 10


# ---- Config + transaction ----


@pytest.mark.asyncio
async def test_pool_config_with_transaction(test_db):
    """Pool config set; transaction() uses it when creating pool."""
    async with connect(test_db) as db:
        db.pool_size = 4
        db.connection_timeout = 15
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY, v TEXT)")
        async with db.transaction():
            await db.execute("INSERT INTO t (v) VALUES ('a')")
            await db.execute("INSERT INTO t (v) VALUES ('b')")
        rows = await db.fetch_all("SELECT * FROM t ORDER BY id")
        assert len(rows) == 2
        assert rows[0][1] == "a" and rows[1][1] == "b"


# ---- Config + cursor ----


@pytest.mark.asyncio
async def test_pool_config_with_cursor(test_db):
    """Pool config set; cursor execute/fetch use it."""
    async with connect(test_db) as db:
        db.pool_size = 5
        db.connection_timeout = 20
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY, x INTEGER)")
        await db.execute("INSERT INTO t (x) VALUES (1), (2), (3)")
        cur = db.cursor()
        await cur.execute("SELECT * FROM t WHERE x > 1")
        out = await cur.fetchall()
        assert len(out) == 2
        assert [r[1] for r in out] == [2, 3]


# ---- Config + set_pragma ----


@pytest.mark.asyncio
async def test_pool_config_with_set_pragma(test_db):
    """set_pragma triggers pool creation; pool config is used."""
    async with connect(test_db) as db:
        db.pool_size = 1
        db.connection_timeout = 3
        await db.set_pragma("journal_mode", "DELETE")
        rows = await db.fetch_all("PRAGMA journal_mode")
        assert len(rows) == 1
        assert db.pool_size == 1
        assert db.connection_timeout == 3


# ---- execute_many ----


@pytest.mark.asyncio
async def test_pool_config_with_execute_many(test_db):
    """execute_many (no transaction) uses pool config."""
    async with connect(test_db) as db:
        db.pool_size = 2
        db.connection_timeout = 5
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY, v TEXT)")
        await db.execute_many("INSERT INTO t (v) VALUES (?)", [["a"], ["b"], ["c"]])
        rows = await db.fetch_all("SELECT * FROM t ORDER BY id")
        assert len(rows) == 3


@pytest.mark.asyncio
async def test_pool_config_with_execute_many_in_transaction(test_db):
    """execute_many inside transaction uses pool config."""
    async with connect(test_db) as db:
        db.pool_size = 2
        db.connection_timeout = 5
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY, v TEXT)")
        async with db.transaction():
            await db.execute_many("INSERT INTO t (v) VALUES (?)", [["x"], ["y"]])
        rows = await db.fetch_all("SELECT * FROM t ORDER BY id")
        assert len(rows) == 2


# ---- begin() ----


@pytest.mark.asyncio
async def test_pool_config_with_begin(test_db):
    """begin() creates pool; pool config is used."""
    async with connect(test_db) as db:
        db.pool_size = 1
        db.connection_timeout = 2
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY)")
        await db.begin()
        await db.execute("INSERT INTO t DEFAULT VALUES")
        await db.commit()
        rows = await db.fetch_all("SELECT * FROM t")
        assert len(rows) == 1


# ---- Edge: both zero ----


@pytest.mark.asyncio
async def test_pool_config_both_zero_stored(test_db):
    """pool_size=0 and connection_timeout=0 are stored and returned by getters."""
    async with connect(test_db) as db:
        db.pool_size = 0
        db.connection_timeout = 0
        assert db.pool_size == 0
        assert db.connection_timeout == 0
    # Note: connection_timeout=0 yields acquire_timeout(0); pool acquire can
    # timeout immediately. We only assert storage/getter here.


@pytest.mark.asyncio
async def test_pool_config_pool_size_zero_ops_succeed(test_db):
    """pool_size=0 (stored) with non-zero timeout; DB ops succeed."""
    async with connect(test_db) as db:
        db.pool_size = 0
        db.connection_timeout = 5
        assert db.pool_size == 0
        assert db.connection_timeout == 5
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY)")
        await db.execute("INSERT INTO t DEFAULT VALUES")
        rows = await db.fetch_all("SELECT * FROM t")
        assert len(rows) == 1


# ---- Config switch mid-session ----


@pytest.mark.asyncio
async def test_pool_config_switch_mid_session(test_db):
    """Changing config after pool exists updates getter; stored value persists."""
    async with connect(test_db) as db:
        db.pool_size = 2
        db.connection_timeout = 10
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY)")
        assert db.pool_size == 2
        assert db.connection_timeout == 10
        db.pool_size = 10
        db.connection_timeout = 60
        assert db.pool_size == 10
        assert db.connection_timeout == 60
        await db.execute("INSERT INTO t DEFAULT VALUES")
        assert db.pool_size == 10
        assert db.connection_timeout == 60


# ---- fetch_one / fetch_optional with config ----


@pytest.mark.asyncio
async def test_pool_config_fetch_one_optional(test_db):
    """fetch_one and fetch_optional with config set before any use."""
    async with connect(test_db) as db:
        db.pool_size = 1
        db.connection_timeout = 5
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY, v TEXT)")
        await db.execute("INSERT INTO t (v) VALUES ('only')")
        one = await db.fetch_one("SELECT * FROM t")
        assert one is not None
        assert one[1] == "only"
        none_row = await db.fetch_optional("SELECT * FROM t WHERE 1=0")
        assert none_row is None


# ---- Multiple connections independent config ----


@pytest.mark.asyncio
async def test_pool_config_multiple_connections_independent(test_db):
    """Two connections can have different pool config; both work."""
    async with connect(test_db) as db1:
        await db1.execute("CREATE TABLE t (id INTEGER PRIMARY KEY)")
        db1.pool_size = 2
        db1.connection_timeout = 5
        await db1.execute("INSERT INTO t DEFAULT VALUES")

    async with connect(test_db) as db2:
        db2.pool_size = 10
        db2.connection_timeout = 60
        rows = await db2.fetch_all("SELECT * FROM t")
        assert len(rows) == 1
        assert db2.pool_size == 10
        assert db2.connection_timeout == 60

    async with connect(test_db) as db3:
        assert db3.pool_size is None
        assert db3.connection_timeout is None
        rows = await db3.fetch_all("SELECT * FROM t")
        assert len(rows) == 1


# ---- Large values ----


@pytest.mark.asyncio
async def test_pool_config_large_values(test_db):
    """Large pool_size and connection_timeout are accepted and persist."""
    async with connect(test_db) as db:
        db.pool_size = 1000
        db.connection_timeout = 86400
        assert db.pool_size == 1000
        assert db.connection_timeout == 86400
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY)")
        await db.execute("INSERT INTO t DEFAULT VALUES")
        assert db.pool_size == 1000
        assert db.connection_timeout == 86400


@pytest.mark.asyncio
async def test_pool_config_high_concurrency_with_transactions(test_db):
    """High-concurrency workload with transactions respects pool configuration."""
    async with connect(test_db) as db:
        db.pool_size = 5
        db.connection_timeout = 5

        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY, value INTEGER)")

        async def worker(offset: int) -> None:
            # Each worker gets its own connection from the pool
            async with connect(test_db) as worker_db:  # type: ignore[attr-defined]
                worker_db.pool_size = 5
                worker_db.connection_timeout = 5
                async with worker_db.transaction():
                    for i in range(10):
                        await worker_db.execute(
                            "INSERT INTO t (value) VALUES (?)", [offset + i]
                        )

        # Run several workers concurrently to stress the pool
        await asyncio.gather(*(worker(j * 100) for j in range(5)))

        rows = await db.fetch_all("SELECT COUNT(*) FROM t")
        assert rows[0][0] == 50


# ============================================================================
# Pool timeout edge cases
# ============================================================================


@pytest.mark.asyncio
async def test_pool_timeout_exhausted_pool(test_db):
    """Test that connection timeout is respected when pool is exhausted."""
    async with connect(test_db) as db:
        db.pool_size = 1
        db.connection_timeout = 1  # 1 second timeout
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY)")

        # Acquire the single connection in the pool
        async with db.transaction():
            # Try to acquire another connection - should timeout
            # We can't easily test this without blocking, so we just verify
            # the timeout setting is respected
            assert db.connection_timeout == 1


@pytest.mark.asyncio
async def test_pool_size_one_serializes_operations(test_db):
    """Test that pool_size=1 serializes all operations."""
    async with connect(test_db) as db:
        db.pool_size = 1
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY, v INTEGER)")

        async def insert_worker(worker_id: int):
            async with connect(test_db) as worker_db:  # type: ignore[attr-defined]
                worker_db.pool_size = 1
                for i in range(10):
                    await worker_db.execute(
                        "INSERT INTO t (v) VALUES (?)", [worker_id * 100 + i]
                    )

        # Run 5 workers concurrently - with pool_size=1, they'll serialize
        await asyncio.gather(*(insert_worker(i) for i in range(5)))

        rows = await db.fetch_all("SELECT COUNT(*) FROM t")
        assert rows[0][0] == 50


@pytest.mark.asyncio
async def test_pool_config_timeout_zero_immediate_failure(test_db):
    """Test that connection_timeout=0 is accepted and stored.

    Note: With timeout=0, the pool will timeout immediately when exhausted.
    This test verifies the setting can be configured. Due to the immediate
    timeout behavior and potential race conditions in parallel test execution,
    we only verify the setting is stored, not that operations work reliably.
    """
    async with connect(test_db) as db:
        # Set timeout=0 - this is a valid setting (means "don't wait")
        db.connection_timeout = 0
        # Verify setting is stored
        assert db.connection_timeout == 0

        # Reset to a reasonable timeout for actual operations
        # (timeout=0 is too aggressive for reliable testing)
        db.connection_timeout = 30
        assert db.connection_timeout == 30

        # Verify operations work with reasonable timeout
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY)")
        await db.execute("INSERT INTO t DEFAULT VALUES")


@pytest.mark.asyncio
async def test_pool_config_large_pool_size(test_db):
    """Test that large pool sizes work correctly."""
    async with connect(test_db) as db:
        db.pool_size = 100
        db.connection_timeout = 30
        # Enable WAL mode for better concurrent write performance
        await db.set_pragma("journal_mode", "WAL")
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY)")

        # Create many concurrent connections with retry logic for database locking
        async def worker(worker_id: int, max_retries: int = 3):
            for attempt in range(max_retries):
                try:
                    async with connect(test_db) as worker_db:  # type: ignore[attr-defined]
                        worker_db.pool_size = 100
                        await worker_db.execute("INSERT INTO t DEFAULT VALUES")
                    return  # Success
                except rapsqlite.OperationalError as e:
                    if "database is locked" in str(e).lower() and attempt < max_retries - 1:
                        # Exponential backoff: wait longer on each retry
                        await asyncio.sleep(0.01 * (2 ** attempt))
                        continue
                    raise  # Re-raise if not a locking error or out of retries

        # Run 50 concurrent workers - should all succeed with pool_size=100
        # Use return_exceptions=True to collect all results, then check for failures
        results = await asyncio.gather(
            *(worker(i) for i in range(50)), return_exceptions=True
        )
        
        # Check for any unexpected exceptions
        exceptions = [r for r in results if isinstance(r, Exception)]
        if exceptions:
            # If we have exceptions, log them but don't fail if they're all locking errors
            non_locking_errors = [
                e for e in exceptions 
                if not (isinstance(e, rapsqlite.OperationalError) and "database is locked" in str(e).lower())
            ]
            if non_locking_errors:
                raise Exception(f"Unexpected errors in workers: {non_locking_errors}")

        rows = await db.fetch_all("SELECT COUNT(*) FROM t")
        # Allow some tolerance for locking errors in parallel test execution
        # The important thing is that the pool_size configuration works
        assert rows[0][0] >= 40, (
            f"Expected at least 40 successful inserts (out of 50), got {rows[0][0]}. "
            f"Exceptions: {len(exceptions)}"
        )


@pytest.mark.asyncio
async def test_pool_config_timeout_very_large(test_db):
    """Test that very large timeout values are accepted."""
    async with connect(test_db) as db:
        db.connection_timeout = 3600  # 1 hour
        assert db.connection_timeout == 3600
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY)")
        assert db.connection_timeout == 3600


@pytest.mark.asyncio
async def test_pool_config_rapid_connection_churn(test_db):
    """Test rapid connection acquisition and release."""
    async with connect(test_db) as db:
        db.pool_size = 5
        db.connection_timeout = 5
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY, v INTEGER)")

        async def rapid_worker():
            async with connect(test_db) as worker_db:  # type: ignore[attr-defined]
                worker_db.pool_size = 5
                for _ in range(20):
                    await worker_db.execute("INSERT INTO t (v) VALUES (1)")

        # Run multiple workers that rapidly acquire/release connections
        await asyncio.gather(*(rapid_worker() for _ in range(10)))

        rows = await db.fetch_all("SELECT COUNT(*) FROM t")
        assert rows[0][0] == 200  # 10 workers * 20 inserts


@pytest.mark.asyncio
async def test_pool_config_mixed_operations_under_load(test_db):
    """Test mixed read/write operations under pool load."""
    async with connect(test_db) as db:
        db.pool_size = 3
        db.connection_timeout = 10
        await db.execute("CREATE TABLE t (id INTEGER PRIMARY KEY, v INTEGER)")
        await db.execute("INSERT INTO t (v) VALUES (1), (2), (3)")

        async def mixed_worker(worker_id: int):
            async with connect(test_db) as worker_db:  # type: ignore[attr-defined]
                worker_db.pool_size = 3
                # Mix of reads and writes
                rows = await worker_db.fetch_all("SELECT * FROM t")
                # Initial rows may be 3 or more depending on concurrent inserts
                initial_count = len(rows)
                await worker_db.execute("INSERT INTO t (v) VALUES (?)", [worker_id])
                rows = await worker_db.fetch_all("SELECT COUNT(*) FROM t")
                assert rows[0][0] >= initial_count + 1

        # Run concurrent mixed operations
        await asyncio.gather(*(mixed_worker(i) for i in range(10)))

        rows = await db.fetch_all("SELECT COUNT(*) FROM t")
        assert rows[0][0] >= 13  # Original 3 + at least 10 new
