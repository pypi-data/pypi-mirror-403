# generated by datamodel-codegen:
#   filename:  governance/workflows/elements/nodes/automatedTask/dataCompletenessTask.json
#   timestamp: 2026-01-30T06:35:57+00:00

from __future__ import annotations

from typing import List, Optional

from pydantic import ConfigDict, Field
from typing_extensions import Annotated

from metadata.ingestion.models.custom_pydantic import BaseModel

from ......type import basic


class InputNamespaceMap(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    relatedEntity: str


class QualityBand(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    name: Annotated[
        str,
        Field(
            description="Name for this quality band (e.g., 'gold', 'excellent', 'tier1')",
            title='Band Name',
        ),
    ]
    minimumScore: Annotated[
        float,
        Field(
            description='Minimum completeness percentage for this band',
            ge=0.0,
            le=100.0,
            title='Minimum Score',
        ),
    ]


class Config(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    fieldsToCheck: Annotated[
        List[str],
        Field(
            description="List of entity field paths to evaluate. Supports dot notation for nested fields (e.g., 'owner.name', 'columns[].description')",
            examples=['name', 'description', 'owner', 'tags', 'columns[].description'],
            min_length=1,
            title='Fields to Check',
        ),
    ]
    qualityBands: Annotated[
        Optional[List[QualityBand]],
        Field(
            [
                {'name': 'excellent', 'minimumScore': 90},
                {'name': 'good', 'minimumScore': 75},
                {'name': 'acceptable', 'minimumScore': 50},
                {'name': 'poor', 'minimumScore': 0},
            ],
            description='Define quality levels based on completeness scores. Bands are evaluated from highest to lowest score.',
            min_length=1,
            title='Quality Bands',
        ),
    ]


class DataCompletenessTaskDefinition(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    type: Optional[str] = 'automatedTask'
    subType: Optional[str] = 'dataCompletenessTask'
    name: Annotated[
        basic.EntityName,
        Field(
            description='Unique name that identifies this node in the workflow',
            title='Node Name',
        ),
    ]
    displayName: Annotated[
        Optional[str],
        Field(
            None,
            description='User-friendly display name for this node',
            title='Display Name',
        ),
    ]
    description: Annotated[
        Optional[basic.Markdown],
        Field(
            None,
            description='Description of what this completeness check does',
            title='Description',
        ),
    ]
    config: Annotated[Config, Field(title='Completeness Configuration')]
    input: Annotated[
        Optional[List[str]], Field(['relatedEntity'], max_length=1, min_length=1)
    ]
    inputNamespaceMap: Optional[InputNamespaceMap] = None
    output: Annotated[
        Optional[List[str]],
        Field(
            [
                'completenessScore',
                'qualityBand',
                'filledFieldsCount',
                'totalFieldsCount',
                'missingFields',
                'filledFields',
                'result',
            ],
            description='Variables this node outputs for use in subsequent nodes',
            title='Output Variables',
        ),
    ]
