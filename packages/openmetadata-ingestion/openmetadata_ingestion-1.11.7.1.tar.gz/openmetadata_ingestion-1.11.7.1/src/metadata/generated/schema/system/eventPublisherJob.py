# generated by datamodel-codegen:
#   filename:  system/eventPublisherJob.json
#   timestamp: 2026-01-30T06:35:57+00:00

from __future__ import annotations

from enum import Enum
from typing import Dict, List, Optional

from pydantic import ConfigDict, Field
from typing_extensions import Annotated

from metadata.ingestion.models.custom_pydantic import BaseModel

from ..configuration import elasticSearchConfiguration
from ..type import basic
from . import indexingError


class Status(Enum):
    started = 'started'
    running = 'running'
    completed = 'completed'
    failed = 'failed'
    active = 'active'
    activeError = 'activeError'
    stopped = 'stopped'
    success = 'success'
    stopInProgress = 'stopInProgress'


class StepStats(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    totalRecords: Annotated[
        Optional[int], Field(0, description='Count of Total Failed Records', ge=0)
    ]
    successRecords: Annotated[
        Optional[int], Field(0, description='Count of Total Successfully Records', ge=0)
    ]
    failedRecords: Annotated[
        Optional[int], Field(0, description='Count of Total Failed Records', ge=0)
    ]


class Stats(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    jobStats: Annotated[
        Optional[StepStats], Field(None, description='Stats for the job')
    ]
    readerStats: Annotated[
        Optional[StepStats],
        Field(None, description='Stats for the reader step (reading from database)'),
    ]
    sinkStats: Annotated[
        Optional[StepStats],
        Field(None, description='Stats for the sink step (writing to search index)'),
    ]
    entityStats: Annotated[
        Optional[Dict[str, StepStats]],
        Field(
            None,
            description='Stats for different entities. Keys should match entity types',
        ),
    ]


class RunMode(Enum):
    stream = 'stream'
    batch = 'batch'


class PublisherType(Enum):
    elasticSearch = 'elasticSearch'
    kafka = 'kafka'


class EventPublisherResult(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    name: Annotated[Optional[str], Field(None, description='Name of the result')]
    timestamp: Optional[basic.Timestamp] = None
    status: Annotated[
        Optional[Status],
        Field(None, description='This schema publisher run job status.'),
    ]
    failure: Annotated[
        Optional[indexingError.IndexingAppError],
        Field(None, description='Failure for the job'),
    ]
    stats: Optional[Stats] = None
    entities: Annotated[
        Optional[List[str]], Field(None, description='List of Entities to Reindex')
    ]
    recreateIndex: Annotated[
        Optional[bool], Field(None, description='This schema publisher run modes.')
    ]
    batchSize: Annotated[
        Optional[int],
        Field(
            100,
            description='Maximum number of events sent in a batch (Default 10).',
            ge=1,
        ),
    ]
    payLoadSize: Annotated[
        Optional[int],
        Field(
            104857600, description='Payload size in bytes depending on config.', ge=1
        ),
    ]
    producerThreads: Annotated[
        Optional[int],
        Field(
            1,
            description='Number of producer threads to use for reindexing',
            ge=1,
            title='Number of Producer Threads to use',
        ),
    ]
    consumerThreads: Annotated[
        Optional[int],
        Field(
            1,
            description='Number of consumer threads to use for reindexing',
            ge=1,
            title='Number of Consumer Threads to use',
        ),
    ]
    queueSize: Annotated[
        Optional[int],
        Field(
            100,
            description='Queue Size to use internally for reindexing.',
            ge=1,
            title='Queue Size to use.',
        ),
    ]
    maxConcurrentRequests: Annotated[
        Optional[int],
        Field(
            100,
            description='Maximum number of concurrent requests to the search index',
            ge=1,
            title='Max Concurrent Requests',
        ),
    ]
    maxRetries: Annotated[
        Optional[int],
        Field(
            5,
            description='Maximum number of retries for a failed request',
            ge=0,
            title='Max Retries',
        ),
    ]
    initialBackoff: Annotated[
        Optional[int],
        Field(
            1000,
            description='Initial backoff time in milliseconds',
            ge=0,
            title='Initial Backoff Millis',
        ),
    ]
    maxBackoff: Annotated[
        Optional[int],
        Field(
            10000,
            description='Maximum backoff time in milliseconds',
            ge=0,
            title='Max Backoff Millis',
        ),
    ]
    searchIndexMappingLanguage: Annotated[
        Optional[elasticSearchConfiguration.SearchIndexMappingLanguage],
        Field(
            elasticSearchConfiguration.SearchIndexMappingLanguage.EN,
            description='Recreate Indexes with updated Language',
        ),
    ]
    afterCursor: Annotated[
        Optional[str],
        Field(
            None,
            description='Provide After in case of failure to start reindexing after the issue is solved',
        ),
    ]
    autoTune: Annotated[
        Optional[bool],
        Field(
            False,
            description='Enable automatic performance tuning based on cluster capabilities and database entity count',
        ),
    ]
    force: Annotated[
        Optional[bool],
        Field(
            False,
            description='Force reindexing even if no index mapping changes are detected',
        ),
    ]
    slackBotToken: Annotated[
        Optional[str],
        Field(
            None,
            description='Optional Slack bot token for sending progress notifications with real-time updates',
        ),
    ]
    slackChannel: Annotated[
        Optional[str],
        Field(
            None,
            description="Slack channel ID or name (required when using bot token, e.g., 'C1234567890' or '#general')",
        ),
    ]
