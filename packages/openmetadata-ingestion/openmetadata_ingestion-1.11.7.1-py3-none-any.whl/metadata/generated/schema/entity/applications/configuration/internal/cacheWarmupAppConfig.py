# generated by datamodel-codegen:
#   filename:  entity/applications/configuration/internal/cacheWarmupAppConfig.json
#   timestamp: 2026-01-30T06:35:57+00:00

from __future__ import annotations

from enum import Enum
from typing import List, Optional

from pydantic import ConfigDict, Field
from typing_extensions import Annotated

from metadata.ingestion.models.custom_pydantic import BaseModel


class CacheWarmupType(Enum):
    CacheWarmup = 'CacheWarmup'


class CacheWarmupApp(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    type: Annotated[
        Optional[CacheWarmupType],
        Field(
            CacheWarmupType.CacheWarmup,
            description='Application Type',
            title='Application Type',
        ),
    ]
    entities: Annotated[
        Optional[List[str]],
        Field(
            ['all'],
            description="List of entity types to warm up in cache. Use 'all' to warm up all entity types.",
            title='Entities',
        ),
    ]
    batchSize: Annotated[
        Optional[int],
        Field(
            100,
            description='Number of entities to process in each batch.',
            ge=10,
            le=1000,
            title='Batch Size',
        ),
    ]
    consumerThreads: Annotated[
        Optional[int],
        Field(
            4,
            description='Number of parallel threads for processing entities and warming cache.',
            ge=1,
            le=10,
            title='Consumer Threads',
        ),
    ]
    queueSize: Annotated[
        Optional[int],
        Field(
            1000,
            description='Internal queue size for entity processing pipeline.',
            ge=100,
            le=10000,
            title='Queue Size',
        ),
    ]
    force: Annotated[
        Optional[bool],
        Field(
            False,
            description='Force cache warmup even if another instance is detected (use with caution).',
            title='Force Warmup',
        ),
    ]
