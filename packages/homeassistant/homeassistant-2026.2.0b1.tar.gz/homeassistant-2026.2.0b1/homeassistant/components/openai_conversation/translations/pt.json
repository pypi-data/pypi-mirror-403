{
    "config": {
        "abort": {
            "already_configured": "Servi\u00e7o j\u00e1 configurado",
            "reauth_successful": "Reautentica\u00e7\u00e3o bem sucedida"
        },
        "error": {
            "cannot_connect": "A liga\u00e7\u00e3o falhou",
            "invalid_auth": "Autentica\u00e7\u00e3o inv\u00e1lida",
            "unknown": "Erro inesperado"
        },
        "step": {
            "reauth_confirm": {
                "data": {
                    "api_key": "Chave da API"
                },
                "data_description": {
                    "api_key": "A sua chave de API OpenAI."
                },
                "description": "Reautentica\u00e7\u00e3o necess\u00e1ria. Introduza a sua chave API atualizada."
            },
            "user": {
                "data": {
                    "api_key": "Chave da API"
                },
                "data_description": {
                    "api_key": "A sua chave de API OpenAI."
                },
                "description": "Configure a integra\u00e7\u00e3o do OpenAI Conversation fornecendo a sua chave da API do OpenAI. As instru\u00e7\u00f5es para obter uma chave de API podem ser encontradas [aqui]({instructions_url})."
            }
        }
    },
    "config_subentries": {
        "ai_task_data": {
            "abort": {
                "entry_not_loaded": "N\u00e3o \u00e9 poss\u00edvel adicionar coisas enquanto a configura\u00e7\u00e3o estiver desativada.",
                "reconfigure_successful": "A reconfigura\u00e7\u00e3o foi bem sucedida"
            },
            "entry_type": "Tarefa de IA",
            "error": {
                "model_not_supported": "Este modelo n\u00e3o \u00e9 suportado. Por favor, selecione um modelo diferente",
                "web_search_minimal_reasoning": "A pesquisa na Web n\u00e3o \u00e9 atualmente suportada com um esfor\u00e7o de racioc\u00ednio m\u00ednimo"
            },
            "initiate_flow": {
                "reconfigure": "Reconfigurar tarefa de IA",
                "user": "Adicionar tarefa de IA"
            },
            "step": {
                "advanced": {
                    "data": {
                        "chat_model": "Modelo",
                        "max_tokens": "M\u00e1ximo de tokens a devolver na resposta",
                        "temperature": "Temperatura",
                        "top_p": "Top P"
                    },
                    "title": "Defini\u00e7\u00f5es avan\u00e7adas"
                },
                "init": {
                    "data": {
                        "name": "Nome",
                        "recommended": "Defini\u00e7\u00f5es de modelo recomendadas"
                    }
                },
                "model": {
                    "data": {
                        "code_interpreter": "Ativar a ferramenta de interpreta\u00e7\u00e3o de c\u00f3digo",
                        "image_model": "Modelo de gera\u00e7\u00e3o de imagens",
                        "inline_citations": "Incluir hiperliga\u00e7\u00f5es nos resultados da pesquisa na Web",
                        "reasoning_effort": "Esfor\u00e7o de racioc\u00ednio",
                        "search_context_size": "Tamanho do contexto de pesquisa",
                        "user_location": "Incluir a localiza\u00e7\u00e3o do domic\u00edlio",
                        "web_search": "Ativar a pesquisa na Web"
                    },
                    "data_description": {
                        "code_interpreter": "Esta ferramenta, tamb\u00e9m conhecida como a ferramenta Python para o modelo, permite executar c\u00f3digo para responder a perguntas",
                        "image_model": "O modelo a utilizar para gerar imagens",
                        "inline_citations": "Se desativado, \u00e9 acrescentado um pedido adicional para que o modelo n\u00e3o inclua cita\u00e7\u00f5es de fontes",
                        "reasoning_effort": "Quantos tokens de racioc\u00ednio o modelo deve gerar antes de criar uma resposta ao pedido",
                        "search_context_size": "Orienta\u00e7\u00e3o de alto n\u00edvel para a quantidade de espa\u00e7o da janela de contexto a utilizar para a pesquisa",
                        "user_location": "Refinar os resultados da pesquisa com base na localiza\u00e7\u00e3o geogr\u00e1fica",
                        "web_search": "Permitir que o modelo procure na Web as informa\u00e7\u00f5es mais recentes antes de gerar uma resposta"
                    },
                    "title": "Op\u00e7\u00f5es espec\u00edficas do modelo"
                }
            }
        },
        "conversation": {
            "abort": {
                "entry_not_loaded": "N\u00e3o \u00e9 poss\u00edvel adicionar coisas enquanto a configura\u00e7\u00e3o estiver desativada.",
                "reconfigure_successful": "A reconfigura\u00e7\u00e3o foi bem sucedida"
            },
            "entry_type": "Agente de conversa\u00e7\u00e3o",
            "error": {
                "model_not_supported": "Este modelo n\u00e3o \u00e9 suportado. Por favor, selecione um modelo diferente",
                "web_search_minimal_reasoning": "A pesquisa na Web n\u00e3o \u00e9 atualmente suportada com um esfor\u00e7o de racioc\u00ednio m\u00ednimo"
            },
            "initiate_flow": {
                "reconfigure": "Reconfigurar o agente de conversa\u00e7\u00e3o",
                "user": "Adicionar agente de conversa\u00e7\u00e3o"
            },
            "step": {
                "advanced": {
                    "data": {
                        "chat_model": "Modelo",
                        "max_tokens": "M\u00e1ximo de tokens a devolver na resposta",
                        "temperature": "Temperatura",
                        "top_p": "Top P"
                    },
                    "title": "Defini\u00e7\u00f5es avan\u00e7adas"
                },
                "init": {
                    "data": {
                        "llm_hass_api": "Controlar Home Assistant",
                        "name": "Nome",
                        "prompt": "Instru\u00e7\u00f5es",
                        "recommended": "Defini\u00e7\u00f5es de modelo recomendadas"
                    },
                    "data_description": {
                        "prompt": "Indicar como o LLM deve responder. Pode ser um modelo."
                    }
                },
                "model": {
                    "data": {
                        "code_interpreter": "Ativar a ferramenta de interpreta\u00e7\u00e3o de c\u00f3digo",
                        "image_model": "Modelo de gera\u00e7\u00e3o de imagens",
                        "inline_citations": "Incluir hiperliga\u00e7\u00f5es nos resultados da pesquisa na Web",
                        "reasoning_effort": "Esfor\u00e7o de racioc\u00ednio",
                        "search_context_size": "Tamanho do contexto de pesquisa",
                        "user_location": "Incluir a localiza\u00e7\u00e3o do domic\u00edlio",
                        "web_search": "Ativar a pesquisa na Web"
                    },
                    "data_description": {
                        "code_interpreter": "Esta ferramenta, tamb\u00e9m conhecida como a ferramenta Python para o modelo, permite executar c\u00f3digo para responder a perguntas",
                        "image_model": "O modelo a utilizar para gerar imagens",
                        "inline_citations": "Se desativado, \u00e9 acrescentado um pedido adicional para que o modelo n\u00e3o inclua cita\u00e7\u00f5es de fontes",
                        "reasoning_effort": "Quantos tokens de racioc\u00ednio o modelo deve gerar antes de criar uma resposta ao pedido",
                        "search_context_size": "Orienta\u00e7\u00e3o de alto n\u00edvel para a quantidade de espa\u00e7o da janela de contexto a utilizar para a pesquisa",
                        "user_location": "Refinar os resultados da pesquisa com base na localiza\u00e7\u00e3o geogr\u00e1fica",
                        "web_search": "Permitir que o modelo procure na Web as informa\u00e7\u00f5es mais recentes antes de gerar uma resposta"
                    },
                    "title": "Op\u00e7\u00f5es espec\u00edficas do modelo"
                }
            }
        }
    },
    "exceptions": {
        "invalid_config_entry": {
            "message": "Entrada de configura\u00e7\u00e3o inv\u00e1lida fornecida. Recebido {config_entry}."
        }
    },
    "issues": {
        "organization_verification_required": {
            "description": "A sua organiza\u00e7\u00e3o tem de ser verificada para utilizar este modelo. V\u00e1 para {platform_settings} e selecione Verificar organiza\u00e7\u00e3o. Se acabou de efetuar a verifica\u00e7\u00e3o, pode demorar at\u00e9 15 minutos para que o acesso seja propagado.",
            "title": "\u00c9 necess\u00e1ria verifica\u00e7\u00e3o da organiza\u00e7\u00e3o"
        }
    },
    "selector": {
        "reasoning_effort": {
            "options": {
                "high": "Alto",
                "low": "Baixo",
                "medium": "M\u00e9dio",
                "minimal": "M\u00ednimo",
                "none": "Nenhum",
                "xhigh": "X-High"
            }
        },
        "search_context_size": {
            "options": {
                "high": "Alto",
                "low": "Baixo",
                "medium": "M\u00e9dio"
            }
        },
        "verbosity": {
            "options": {
                "high": "Alto",
                "low": "Baixo",
                "medium": "M\u00e9dio"
            }
        }
    },
    "services": {
        "generate_content": {
            "description": "Envia uma consulta de conversa\u00e7\u00e3o para o ChatGPT, incluindo quaisquer ficheiros de imagem ou PDF anexados",
            "fields": {
                "config_entry": {
                    "description": "A entrada de configura\u00e7\u00e3o a utilizar para esta a\u00e7\u00e3o",
                    "name": "Entrada de configura\u00e7\u00e3o"
                },
                "filenames": {
                    "description": "Lista de ficheiros a carregar",
                    "name": "Ficheiros"
                },
                "prompt": {
                    "description": "O prompt a enviar",
                    "name": "Prompt"
                }
            },
            "name": "Gerar conte\u00fado"
        },
        "generate_image": {
            "description": "Transforma uma prompt numa imagem",
            "fields": {
                "config_entry": {
                    "description": "A entrada de configura\u00e7\u00e3o a utilizar para esta a\u00e7\u00e3o",
                    "name": "Entrada de configura\u00e7\u00e3o"
                },
                "prompt": {
                    "description": "O texto a transformar numa imagem",
                    "example": "Uma fotografia de um c\u00e3o",
                    "name": "Prompt"
                },
                "quality": {
                    "description": "A qualidade da imagem que ser\u00e1 gerada",
                    "name": "Qualidade"
                },
                "size": {
                    "description": "O tamanho da imagem a gerar",
                    "name": "Tamanho"
                },
                "style": {
                    "description": "O estilo da imagem gerada",
                    "name": "Estilo"
                }
            },
            "name": "Gerar imagem"
        }
    }
}