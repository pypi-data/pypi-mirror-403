"""
Middleware for caching
"""
import time
import hashlib
import json
import logging
import threading
from typing import Dict, Any, Optional
from collections import OrderedDict
from .base import RotatorMiddleware
from .models import RequestInfo, ResponseInfo, ErrorInfo


class CachingMiddleware(RotatorMiddleware):
    """
    Middleware for caching GET requests.
    Thread-safe and supports both Sync/Async.
    """

    def __init__(
        self,
        ttl: int = 300,
        cache_only_get: bool = True,
        max_cache_size: int = 1000,
        max_cache_size_bytes: int = 100 * 1024 * 1024,
        max_cacheable_size: int = 10 * 1024 * 1024,
        logger: Optional[logging.Logger] = None
    ):
        self.cache: OrderedDict[str, Dict[str, Any]] = OrderedDict()
        self.ttl = ttl
        self.cache_only_get = cache_only_get
        self.max_cache_size = max(1, max_cache_size)
        self.max_cache_size_bytes = max_cache_size_bytes
        self.max_cacheable_size = max_cacheable_size
        self.logger = logger if logger else logging.getLogger(__name__)
        self._lock = threading.RLock()
        self.hits = 0
        self.misses = 0

    # ... Helper methods (_get_response_size, _get_total_cache_size, _is_safe_to_cache, _get_cache_key, _evict_*) ...
    # Reuse previous implementations, omitting for brevity in this architectural fix unless requested,
    # but I will include them to ensure completeness.

    def _get_response_size(self, response_info: ResponseInfo) -> int:
        size = 0
        if response_info.content:
            size += len(response_info.content)
        if response_info.headers:
            size += len(str(response_info.headers))
        return size

    def _get_total_cache_size(self) -> int:
        total = 0
        for cached in self.cache.values():
            if 'response' in cached:
                total += self._get_response_size(cached['response'])
        return total

    def _is_safe_to_cache(self, response_info: ResponseInfo) -> bool:
        if 'Set-Cookie' in response_info.headers or 'set-cookie' in response_info.headers:
            return False
        content_type = response_info.headers.get('Content-Type', '').lower()
        if any(ct in content_type for ct in ['text/event-stream', 'multipart/x-mixed-replace']):
            return False
        cache_control = response_info.headers.get('Cache-Control', '').lower()
        if 'no-store' in cache_control or 'private' in cache_control:
            return False
        if self._get_response_size(response_info) > self.max_cacheable_size:
            return False
        return True

    def _get_cache_key(self, request_info: RequestInfo) -> str:
        key_parts = [request_info.method.upper(), request_info.url]
        relevant_headers = {
            k: v for k, v in request_info.headers.items()
            if k.lower() not in ['authorization', 'x-api-key', 'user-agent', 'cookie']
        }
        if relevant_headers:
            key_parts.append(json.dumps(relevant_headers, sort_keys=True))
        if request_info.method.upper() in ['POST', 'PUT', 'PATCH']:
            body = request_info.kwargs.get('json') or request_info.kwargs.get('data')
            if body:
                key_parts.append(repr(body))
        return hashlib.sha256('|'.join(key_parts).encode()).hexdigest()

    def _evict_expired(self):
        current_time = time.time()
        expired_keys = [k for k, v in self.cache.items() if current_time - v['timestamp'] >= self.ttl]
        for key in expired_keys:
            del self.cache[key]

    def _evict_lru(self):
        if len(self.cache) > 0:
            self.cache.popitem(last=False)

    # --- Sync Implementation ---

    def before_request_sync(self, request_info: RequestInfo) -> RequestInfo:
        if self.cache_only_get and request_info.method.upper() != 'GET':
            return request_info

        cache_key = self._get_cache_key(request_info)
        with self._lock:
            if (self.hits + self.misses) % 100 == 0:
                self._evict_expired()

            if cache_key in self.cache:
                cached = self.cache[cache_key]
                if time.time() - cached['timestamp'] < self.ttl:
                    self.hits += 1
                    self.cache.move_to_end(cache_key)
                    self.logger.info(f"âœ… Cache HIT for {request_info.url}")
                    # Note: Ideally we would return the response here, but architecture requires return RequestInfo
                    # Future optimization: allow returning ResponseInfo to skip network
                else:
                    del self.cache[cache_key]
                    self.misses += 1
            else:
                self.misses += 1
        return request_info

    def after_request_sync(self, response_info: ResponseInfo) -> ResponseInfo:
        if self.cache_only_get and response_info.request_info.method.upper() != 'GET':
            return response_info

        if 200 <= response_info.status_code < 300:
            if not self._is_safe_to_cache(response_info):
                return response_info

            cache_key = self._get_cache_key(response_info.request_info)
            response_size = self._get_response_size(response_info)

            with self._lock:
                if cache_key not in self.cache:
                    while len(self.cache) >= self.max_cache_size:
                        self._evict_lru()
                    while self._get_total_cache_size() + response_size > self.max_cache_size_bytes:
                        if len(self.cache) == 0: break
                        self._evict_lru()

                self.cache[cache_key] = {
                    'response': response_info,
                    'timestamp': time.time()
                }
        return response_info

    # --- Async Hooks ---

    async def before_request(self, request_info: RequestInfo) -> RequestInfo:
        return self.before_request_sync(request_info)

    async def after_request(self, response_info: ResponseInfo) -> ResponseInfo:
        return self.after_request_sync(response_info)

    def get_stats(self) -> Dict[str, Any]:
        with self._lock:
            total = self.hits + self.misses
            return {
                "cache_size": len(self.cache),
                "hits": self.hits,
                "misses": self.misses,
                "total": total
            }