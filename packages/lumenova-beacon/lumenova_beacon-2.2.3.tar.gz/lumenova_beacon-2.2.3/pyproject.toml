[project]
name = "lumenova-beacon"
dynamic = ["version"]
description = "Lumenova Beacon SDK - A Python SDK for observability tracing with OpenTelemetry-compatible span export"
readme = "README.md"
requires-python = ">=3.10"
authors = [
    {name = "Lumenova AI", email = "support@lumenova.ai"}
]
maintainers = [
    {name = "Lumenova AI", email = "support@lumenova.ai"}
]
license = "Apache-2.0"
keywords = [
    "observability",
    "tracing",
    "llm",
    "ai",
    "opentelemetry",
    "langchain",
    "monitoring",
    "sdk",
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: Apache Software License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: System :: Monitoring",
    "Typing :: Typed",
]

dependencies = [
    "httpx>=0.27.0",
    "typing-extensions>=4.12.0",
    "tenacity>=9.0.0",
]

[project.urls]
Homepage = "https://lumenova.ai"

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "black>=24.0.0",
    "ruff>=0.4.0",
    "mypy>=1.10.0",
    "ipython>=8.37.0",
]
langchain = [
    "faiss-cpu>=1.13.1",
    "langchain-community>=0.4.1",
    "langchain-core>=0.3.0",
    "langchain-openai>=1.1.5",
    "langgraph>=1.0.5",
]

litellm = [
    "litellm>=1.70.0",
]

strands = [
    "strands-agents>=1.15.0",
    "strands-agents-tools>=0.2.0",
    "boto3>=1.34.0",  # Required for AWS Bedrock model
]

crewai = [
    "crewai>=0.28.0",
    "openinference-instrumentation-crewai>=0.1.0",
    "openinference-instrumentation-litellm>=0.1.0",
]

opentelemetry = [
    "opentelemetry-api==1.38.0",
    "opentelemetry-sdk==1.38.0",
    "opentelemetry-exporter-otlp-proto-grpc==1.38.0",
    "opentelemetry-exporter-otlp-proto-http==1.38.0",
    "opentelemetry-exporter-otlp-proto-common==1.38.0",
]
examples = [
    # OpenTelemetry core instrumentation (base package - required by all instrumentors)
    "opentelemetry-instrumentation==0.59b0",
    # OpenTelemetry instrumentors (all pinned to 0.59b0 for compatibility with SDK 1.38.0)
    "opentelemetry-instrumentation-anthropic>=0.1.0",
    "opentelemetry-instrumentation-openai>=0.1.0",
    "openinference-instrumentation-google-genai>=0.1.0",
    "opentelemetry-instrumentation-httpx==0.59b0",
    "opentelemetry-instrumentation-fastapi==0.59b0",
    "opentelemetry-instrumentation-redis==0.59b0",
    "opentelemetry-instrumentation-requests==0.59b0",
    # OpenInference instrumentors
    "openinference-instrumentation-crewai>=0.1.0",
    "openinference-instrumentation-litellm>=0.1.0",
    "openinference-instrumentation-llama-index>=4.3.8",
    # LLM clients
    "anthropic>=0.40.0",
    "openai>=1.0.0",
    "google-genai>=1.0.0",
    "litellm>=1.70.0",
    # Agent frameworks
    "strands-agents>=1.15.0",
    "strands-agents-tools>=0.2.0",
    "crewai>=0.1.0",
    # RAG frameworks
    "llama-index-core>=0.12.3",
    "llama-index-llms-azure-openai>=0.3.0",
    "llama-index-embeddings-azure-openai>=0.3.0",
    # Web frameworks & HTTP clients
    "fastapi>=0.115.0",
    "requests>=2.31.0",
    # Data stores
    "redis>=5.0.0",
    # Utilities
    "python-dotenv>=1.0.0",
]

[dependency-groups]
dev = [
    "python-dotenv>=1.1.1",
]

[build-system]
requires = ["hatchling", "hatch-vcs"]
build-backend = "hatchling.build"

[tool.hatch.version]
source = "vcs"
