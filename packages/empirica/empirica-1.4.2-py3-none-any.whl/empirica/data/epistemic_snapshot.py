#!/usr/bin/env python3
"""
Epistemic State Snapshot - Universal cross-AI context transfer protocol

Provides 95% token reduction while preserving epistemic state fidelity.
Works across ANY AI provider (Claude, GPT, Qwen, Gemini, etc.)

Key Innovation: Instead of transferring full conversation history (10k+ tokens),
transfer epistemic essence via 13-dimensional vector state (~500 tokens).

Architecture:
- 13 core universal vectors (work across all AIs)
- Delta tracking (what changed from previous state)
- Hybrid semantic + narrative context
- Domain-specific vector extensions
- Compression quality metrics
- Fidelity tracking with degradation alerts

Usage:
    snapshot = EpistemicStateSnapshot(...)
    json_str = snapshot.to_json()  # Export for transfer
    prompt = snapshot.to_context_prompt(level="standard")  # Inject into AI prompt
"""

from dataclasses import dataclass, field, asdict
from typing import Dict, List, Optional, Any
from datetime import datetime
import json
import uuid


@dataclass
class ContextSummary:
    """Hybrid semantic + narrative context summary"""

    semantic: Dict[str, Any] = field(default_factory=dict)
    narrative: str = ""
    evidence_refs: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict:
        """Convert to dictionary for JSON serialization"""
        return {
            'semantic': self.semantic,
            'narrative': self.narrative,
            'evidence_refs': self.evidence_refs
        }

    @classmethod
    def from_dict(cls, data: Dict) -> 'ContextSummary':
        """Create from dictionary"""
        return cls(
            semantic=data.get('semantic', {}),
            narrative=data.get('narrative', ''),
            evidence_refs=data.get('evidence_refs', [])
        )

    def to_prompt(self) -> str:
        """Convert to natural language prompt"""
        output = []

        if self.semantic:
            output.append("**Context Metadata:**")
            for key, value in self.semantic.items():
                output.append(f"- {key}: {value}")
            output.append("")

        if self.narrative:
            output.append("**Context Summary:**")
            output.append(self.narrative)
            output.append("")

        if self.evidence_refs:
            output.append("**Evidence Gathered:**")
            for ref in self.evidence_refs:
                output.append(f"- {ref}")

        return "\n".join(output)


@dataclass
class EpistemicStateSnapshot:
    """
    Universal epistemic state representation for cross-AI transfer

    Core Innovation: Compress full conversation context into epistemic essence
    - 13 universal vectors (0.0-1.0 scale)
    - Delta tracking (what improved/degraded)
    - Hybrid semantic + narrative summary
    - Domain-specific extensions
    - Compression quality metrics
    """

    # Core identification
    snapshot_id: str
    session_id: str
    ai_id: str
    timestamp: str

    # Cascade context
    cascade_phase: Optional[str] = None  # preflight, think, plan, investigate, check, act, postflight
    cascade_id: Optional[str] = None

    # 13 core universal vectors (work across ALL AIs)
    # Foundation: KNOW, DO, CONTEXT
    # Comprehension: CLARITY, COHERENCE, SIGNAL, DENSITY
    # Execution: STATE, CHANGE, COMPLETION, IMPACT
    # Gate: ENGAGEMENT
    # Meta: UNCERTAINTY
    vectors: Dict[str, float] = field(default_factory=dict)

    # Delta from previous state (what changed)
    delta: Optional[Dict[str, float]] = None
    previous_snapshot_id: Optional[str] = None

    # Hybrid context summary (semantic + narrative)
    context_summary: Optional[ContextSummary] = None

    # DB reference for full conversation history (if needed)
    db_session_ref: str = ""

    # Domain-specific vector extensions (EXTENSIBLE!)
    # Example: {"code_analysis": {"COMPLEXITY": 0.7, "SECURITY_RISK": 0.3}}
    domain_vectors: Optional[Dict[str, Dict[str, float]]] = None

    # Compression metadata
    original_context_tokens: int = 0
    snapshot_tokens: int = 0
    compression_ratio: float = 0.0

    # Quality metrics
    information_loss_estimate: float = 0.0  # 0.0-1.0 (lower is better)
    fidelity_score: float = 1.0  # 0.0-1.0 (higher is better)

    # Transfer tracking
    transfer_count: int = 0  # How many AI hops
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())

    def to_dict(self) -> Dict:
        """Convert to dictionary for JSON serialization"""
        data = asdict(self)

        # Handle ContextSummary serialization
        if self.context_summary:
            data['context_summary'] = self.context_summary.to_dict()

        return data

    def to_json(self) -> str:
        """Export as JSON for cross-AI transfer"""
        return json.dumps(self.to_dict(), indent=2)

    @classmethod
    def from_dict(cls, data: Dict) -> 'EpistemicStateSnapshot':
        """Create from dictionary"""
        # Handle ContextSummary deserialization
        if 'context_summary' in data and data['context_summary']:
            data['context_summary'] = ContextSummary.from_dict(data['context_summary'])

        return cls(**data)

    @classmethod
    def from_json(cls, json_str: str) -> 'EpistemicStateSnapshot':
        """Import from JSON"""
        data = json.loads(json_str)
        return cls.from_dict(data)

    def to_context_prompt(self, level: str = "minimal") -> str:
        """
        Convert snapshot to natural language context for AI prompt injection

        Levels:
        - minimal: Core vectors + phase (~500 tokens)
        - standard: + delta + summary (~1000 tokens)
        - full: + evidence + domain vectors (~1500 tokens)
        """
        if level == "minimal":
            return self._minimal_prompt()
        elif level == "standard":
            return self._standard_prompt()
        elif level == "full":
            return self._full_prompt()
        else:
            raise ValueError(f"Invalid level: {level}. Must be minimal, standard, or full")

    def _minimal_prompt(self) -> str:
        """Minimal context injection (~500 tokens)"""
        return f"""# Epistemic State Snapshot

**Session:** {self.session_id}
**AI:** {self.ai_id}
**Phase:** {self.cascade_phase or 'unknown'}
**Timestamp:** {self.timestamp}

## Epistemic Vectors (13-dimensional state)
{self._format_vectors()}

**Context:** This represents the epistemic state from a previous AI interaction.
Use this to maintain context continuity without full conversation history.

**Compression:** {self.compression_ratio:.1%} reduction ({self.original_context_tokens} â†’ {self.snapshot_tokens} tokens)
**Fidelity:** {self.fidelity_score:.2f}
"""

    def _standard_prompt(self) -> str:
        """Standard context with delta and summary (~1000 tokens)"""
        prompt = self._minimal_prompt()

        if self.delta:
            prompt += f"\n## Changes from Previous State\n{self._format_delta()}\n"

        if self.context_summary:
            prompt += f"\n{self.context_summary.to_prompt()}\n"

        return prompt

    def _full_prompt(self) -> str:
        """Full context with all details (~1500 tokens)"""
        prompt = self._standard_prompt()

        if self.domain_vectors:
            prompt += f"\n## Domain-Specific Vectors\n{self._format_domain_vectors()}\n"

        prompt += f"\n## Quality Metrics\n"
        prompt += f"- Information Loss: {self.information_loss_estimate:.1%}\n"
        prompt += f"- Transfer Count: {self.transfer_count} hops\n"
        prompt += f"- DB Reference: {self.db_session_ref}\n"

        return prompt

    def _format_vectors(self) -> str:
        """Format 13 vectors for display with grouping"""
        output = []

        # Group vectors by category
        foundation = ['KNOW', 'DO', 'CONTEXT']
        comprehension = ['CLARITY', 'COHERENCE', 'SIGNAL', 'DENSITY']
        execution = ['STATE', 'CHANGE', 'COMPLETION', 'IMPACT']
        gate = ['ENGAGEMENT']
        meta = ['UNCERTAINTY']

        def format_group(name: str, vectors: List[str]) -> str:
            """Format a group of vectors with name, scores, and visual bars."""
            lines = [f"\n**{name}:**"]
            for v in vectors:
                score = self.vectors.get(v, 0.0)
                bar = self._score_to_bar(score)
                lines.append(f"- {v}: {score:.2f} {bar}")
            return "\n".join(lines)

        output.append(format_group("Foundation", foundation))
        output.append(format_group("Comprehension", comprehension))
        output.append(format_group("Execution", execution))
        output.append(format_group("Gate", gate))
        output.append(format_group("Meta", meta))

        return "\n".join(output)

    def _format_delta(self) -> str:
        """Format delta changes with visual indicators"""
        lines = []
        for name, change in sorted(self.delta.items(), key=lambda x: abs(x[1]), reverse=True):
            if change > 0:
                indicator = "ðŸ“ˆ"
                sign = "+"
            elif change < 0:
                indicator = "ðŸ“‰"
                sign = ""
            else:
                indicator = "âž¡ï¸"
                sign = ""

            lines.append(f"- {name}: {sign}{change:.2f} {indicator}")

        return "\n".join(lines)

    def _format_domain_vectors(self) -> str:
        """Format domain-specific vectors"""
        if not self.domain_vectors:
            return "None"

        # Handle case where domain_vectors might not be a dict
        if not isinstance(self.domain_vectors, dict):
            return f"Invalid format: {type(self.domain_vectors).__name__}"

        output = []
        for domain, vectors in self.domain_vectors.items():
            # Check if vectors is a dict (nested structure) or just a value
            if isinstance(vectors, dict):
                output.append(f"\n**{domain.replace('_', ' ').title()}:**")
                for name, score in vectors.items():
                    bar = self._score_to_bar(score)
                    output.append(f"  - {name}: {score:.2f} {bar}")
            else:
                # Simple key-value pair (flat structure)
                bar = self._score_to_bar(vectors)
                output.append(f"- {domain}: {vectors:.2f} {bar}")

        return "\n".join(output)

    @staticmethod
    def _score_to_bar(score: float, width: int = 10) -> str:
        """Convert score to visual bar graph"""
        filled = int(score * width)
        empty = width - filled
        return "â–ˆ" * filled + "â–‘" * empty

    def calculate_delta(self, previous: 'EpistemicStateSnapshot') -> Dict[str, float]:
        """
        Calculate vector changes from previous snapshot

        Args:
            previous: Previous snapshot to compare against

        Returns:
            Dictionary of vector changes (positive = improvement, negative = degradation)
        """
        delta = {}
        for vector_name, current_value in self.vectors.items():
            previous_value = previous.vectors.get(vector_name, 0.5)
            delta[vector_name] = current_value - previous_value
        return delta

    def increment_transfer_count(self):
        """Increment transfer count (called when snapshot is passed to another AI)"""
        self.transfer_count += 1

    def estimate_memory_reliability(self) -> float:
        """
        Calculate how reliable the compressed snapshot is vs full context

        Factors:
        - Fidelity score (from compression)
        - Number of model transfers (degrades with each hop)
        - Time since original creation (temporal drift)
        - Information loss estimate

        Returns:
            Reliability score (0.0-1.0, higher is better)
        """
        base_reliability = self.fidelity_score

        # Degradation per transfer (3% per hop)
        transfer_penalty = self.transfer_count * 0.03

        # Temporal drift (1% per hour)
        created = datetime.fromisoformat(self.created_at)
        age_hours = (datetime.now() - created).total_seconds() / 3600
        time_penalty = age_hours * 0.01

        # Information loss factor
        info_loss_penalty = self.information_loss_estimate

        reliability = base_reliability - transfer_penalty - time_penalty - info_loss_penalty
        return max(0.0, min(1.0, reliability))

    def should_refresh(self,
                       min_reliability: float = 0.75,
                       max_transfers: int = 5,
                       max_age_hours: int = 24) -> bool:
        """
        Determine if snapshot should be refreshed with full context

        Args:
            min_reliability: Minimum acceptable reliability
            max_transfers: Maximum transfer count before refresh
            max_age_hours: Maximum age in hours before refresh

        Returns:
            True if refresh recommended, False otherwise
        """
        # Check reliability
        if self.estimate_memory_reliability() < min_reliability:
            return True

        # Check transfer count
        if self.transfer_count >= max_transfers:
            return True

        # Check age
        created = datetime.fromisoformat(self.created_at)
        age_hours = (datetime.now() - created).total_seconds() / 3600
        if age_hours >= max_age_hours:
            return True

        return False

    def get_refresh_reason(self) -> Optional[str]:
        """Get reason why refresh is recommended (if applicable)"""
        reliability = self.estimate_memory_reliability()

        if reliability < 0.60:
            return f"CRITICAL: Reliability {reliability:.1%} < 60%"
        elif reliability < 0.75:
            return f"WARNING: Reliability {reliability:.1%} < 75%"

        if self.transfer_count >= 5:
            return f"High transfer count: {self.transfer_count} hops"

        created = datetime.fromisoformat(self.created_at)
        age_hours = (datetime.now() - created).total_seconds() / 3600
        if age_hours >= 24:
            return f"Temporal drift: {age_hours:.1f} hours old"

        return None


def create_snapshot(session_id: str,
                   ai_id: str,
                   vectors: Dict[str, float],
                   context_summary: Optional[ContextSummary] = None,
                   cascade_phase: Optional[str] = None,
                   domain_vectors: Optional[Dict[str, Dict[str, float]]] = None) -> EpistemicStateSnapshot:
    """
    Convenience function to create a new epistemic snapshot

    Args:
        session_id: Session identifier
        ai_id: AI identifier
        vectors: 13 core epistemic vectors
        context_summary: Optional context summary
        cascade_phase: Current cascade phase
        domain_vectors: Optional domain-specific vectors

    Returns:
        EpistemicStateSnapshot
    """
    return EpistemicStateSnapshot(
        snapshot_id=str(uuid.uuid4()),
        session_id=session_id,
        ai_id=ai_id,
        timestamp=datetime.now().isoformat(),
        vectors=vectors,
        context_summary=context_summary,
        cascade_phase=cascade_phase,
        domain_vectors=domain_vectors
    )
