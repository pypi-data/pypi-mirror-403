"""Monitoring command parsers."""


def add_monitor_parsers(subparsers):
    """Add monitoring command parsers"""
    # Unified monitor command (consolidates monitor, monitor-export, monitor-reset, monitor-cost)
    monitor_parser = subparsers.add_parser('monitor', help='Monitoring dashboard and statistics')
    monitor_parser.add_argument('--export', metavar='FILE', help='Export data to file (replaces monitor-export)')
    monitor_parser.add_argument('--reset', action='store_true', help='Reset statistics (replaces monitor-reset)')
    monitor_parser.add_argument('--cost', action='store_true', help='Show cost analysis (replaces monitor-cost)')
    monitor_parser.add_argument('--history', action='store_true', help='Show recent request history')
    monitor_parser.add_argument('--health', action='store_true', help='Include adapter health checks')
    monitor_parser.add_argument('--turtle', action='store_true', help='Show epistemic health: flow state, CASCADE completeness, unknowns/findings')
    monitor_parser.add_argument('--project', action='store_true', help='Show cost projections (with --cost)')
    monitor_parser.add_argument('--output', choices=['json', 'csv'], default='json', help='Export format (with --export)')
    monitor_parser.add_argument('--yes', '-y', action='store_true', help='Skip confirmation (with --reset)')
    monitor_parser.add_argument('--verbose', action='store_true', help='Show detailed stats')

    # Check drift command - detect epistemic drift
    check_drift_parser = subparsers.add_parser('check-drift',
        help='Detect epistemic drift by comparing current state to historical baselines')
    check_drift_parser.add_argument('--session-id', required=True, help='Session UUID to check for drift')
    check_drift_parser.add_argument('--trigger',
        choices=['manual', 'pre_summary', 'post_summary'],
        default='manual',
        help='When check is triggered: manual (default) | pre_summary (save snapshot) | post_summary (compare with snapshot)')
    check_drift_parser.add_argument('--threshold', type=float, default=0.2, help='Drift threshold (default: 0.2)')
    check_drift_parser.add_argument('--lookback', type=int, default=5, help='Number of checkpoints to analyze (default: 5)')
    check_drift_parser.add_argument('--cycle', type=int, help='Investigation cycle number (optional filter)')
    check_drift_parser.add_argument('--round', type=int, help='CHECK round number (optional filter)')
    check_drift_parser.add_argument('--scope-depth', type=float, help='Investigation depth: 0.0=surface scan, 1.0=exhaustive (optional)')
    check_drift_parser.add_argument('--signaling', choices=['basic', 'default', 'full'], default='default',
        help='Signaling detail level: basic (drift+sentinel only), default (key vectors), full (all vectors+context)')
    check_drift_parser.add_argument('--output', choices=['human', 'json'], default='human', help='Output format')
    check_drift_parser.add_argument('--verbose', action='store_true', help='Show detailed output')

    # MCO load command - load Meta-Agent Configuration Object
    mco_load_parser = subparsers.add_parser('mco-load',
        help='Load MCO (Meta-Agent Configuration Object) configuration')
    mco_load_parser.add_argument('--session-id', help='Session UUID (optional, for inference)')
    mco_load_parser.add_argument('--ai-id', help='AI identifier (optional, for model/persona inference)')
    mco_load_parser.add_argument('--snapshot', help='Path to pre_summary snapshot (for post-compact reload)')
    mco_load_parser.add_argument('--model', help='Explicit model override (claude_haiku, claude_sonnet, gpt4, etc.)')
    mco_load_parser.add_argument('--persona', help='Explicit persona override (researcher, implementer, reviewer, etc.)')
    mco_load_parser.add_argument('--output', choices=['human', 'json'], default='human', help='Output format')
    mco_load_parser.add_argument('--verbose', action='store_true', help='Show detailed output')

    # Assess state command - capture sessionless epistemic state
    assess_state_parser = subparsers.add_parser('assess-state',
        help='Capture sessionless epistemic state (for statusline, monitoring, compact boundaries)')
    assess_state_parser.add_argument('--session-id', help='Session UUID (optional, for context)')
    assess_state_parser.add_argument('--prompt', help='Self-assessment context/evidence (optional)')
    assess_state_parser.add_argument('--output', choices=['human', 'json'], default='human', help='Output format')
    assess_state_parser.add_argument('--verbose', action='store_true', help='Show detailed output')
    assess_state_parser.add_argument('--turtle', action='store_true',
        help='Recursive grounding check: verify observer stability before observing (Noetic Handshake)')

    # Trajectory project command - the turtle telescope
    trajectory_parser = subparsers.add_parser('trajectory-project',
        help='Project viable epistemic paths forward based on current grounding (Turtle Telescope)')
    trajectory_parser.add_argument('--session-id', help='Session UUID for context')
    trajectory_parser.add_argument('--turtle', action='store_true',
        help='Include full turtle stack in projection')
    trajectory_parser.add_argument('--depth', type=int, default=3, choices=[1, 2, 3],
        help='Projection depth: 1=immediate, 2=short-term, 3=strategic (default: 3)')
    trajectory_parser.add_argument('--output', choices=['human', 'json'], default='human',
        help='Output format')
    trajectory_parser.add_argument('--verbose', action='store_true',
        help='Show detailed reasoning for each path')

    # REMOVED: monitor-export, monitor-reset, monitor-cost
    # Use: monitor --export FILE, monitor --reset, monitor --cost

    # Compact analysis command - measure epistemic loss during memory compaction
    compact_parser = subparsers.add_parser('compact-analysis',
        help='Analyze epistemic loss during memory compaction',
        description="""
Retroactively analyze pre-compact snapshots vs post-compact assessments
to measure knowledge loss and recovery during Claude Code memory compaction.

Data Quality Filtering (default):
- Excludes test sessions (ai_id: test*, *-test, storage-*)
- Requires sessions with actual work evidence (findings/unknowns)
- Filters rapid-fire sessions (< 5 min duration)
        """)
    compact_parser.add_argument('--include-tests', action='store_true',
        help='Include test sessions in analysis (normally filtered)')
    compact_parser.add_argument('--min-findings', type=int, default=0,
        help='Minimum findings count to include session (default: 0)')
    compact_parser.add_argument('--limit', type=int, default=20,
        help='Maximum compact events to analyze (default: 20)')
    compact_parser.add_argument('--output', choices=['human', 'json'], default='human',
        help='Output format (default: human)')

    # Calibration report command - analyze calibration from vector_trajectories
    calibration_parser = subparsers.add_parser('calibration-report',
        help='Generate calibration report from vector trajectories',
        description="""
Analyze AI self-assessment calibration using vector_trajectories table.
Measures gap from expected (1.0 for most vectors, 0.0 for uncertainty) at session END.

Key outputs:
- Per-vector bias corrections (ADD to self-assessment)
- Sample sizes and confidence intervals
- Trend analysis over time (weekly)
- Recommendations for system prompt updates

Data Quality Filtering (default):
- Uses vector_trajectories as primary source (not polluted bayesian_beliefs)
- Filters test sessions (ai_id: test*, *-test, storage-*)
- Requires meaningful sessions (pattern != 'unknown')
- Excludes 0.5 default values (signs of placeholder data)
        """)
    calibration_parser.add_argument('--ai-id', help='Filter by AI identifier (default: claude-code)')
    calibration_parser.add_argument('--weeks', type=int, default=8,
        help='Number of weeks to analyze (default: 8)')
    calibration_parser.add_argument('--include-tests', action='store_true',
        help='Include test sessions in analysis (normally filtered)')
    calibration_parser.add_argument('--min-samples', type=int, default=10,
        help='Minimum samples per vector for confident analysis (default: 10)')
    calibration_parser.add_argument('--output', choices=['human', 'json', 'markdown'], default='human',
        help='Output format (default: human)')
    calibration_parser.add_argument('--update-prompt', action='store_true',
        help='Generate copy-paste ready calibration table for system prompts')
    calibration_parser.add_argument('--verbose', action='store_true',
        help='Show detailed per-vector analysis')
