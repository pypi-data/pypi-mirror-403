# Data Model: GraphQL API Endpoint

**Feature**: GraphQL API with type-safe schema and DataLoader batching
**Date**: 2025-10-02
**Status**: Design Complete

---

## Overview

The GraphQL API exposes the IRIS NodePK schema through a type-safe GraphQL interface with:
- **Node interface** implemented by all entity types
- **Nested field resolution** with DataLoader batching to prevent N+1 queries
- **Vector similarity** via field resolvers using HNSW index
- **Real-time subscriptions** for entity creation/update events
- **Mutations** with FK validation and ACID transactions

---

## GraphQL Type System

### Node Interface (Base)

All entity types implement the `Node` interface:

```graphql
interface Node {
  id: ID!
  labels: [String!]!
  properties: JSON!
  createdAt: DateTime!
}
```

**Mapping to IRIS Schema**:
- `id` → `nodes.id` (primary key)
- `labels` → `rdf_labels.label` (many-to-one via `node_id` FK)
- `properties` → `rdf_props` table (key-value pairs, JSON aggregated)
- `createdAt` → `nodes.created_at` (timestamp)

---

### Protein Type

```graphql
type Protein implements Node {
  # Node interface fields
  id: ID!
  labels: [String!]!
  properties: JSON!
  createdAt: DateTime!

  # Protein-specific fields (from rdf_props)
  name: String!
  function: String
  organism: String
  confidence: Float

  # Relationship fields (from rdf_edges)
  interactsWith(first: Int = 10, offset: Int = 0): [Protein!]!
  regulatedBy(first: Int = 10, offset: Int = 0): [Gene!]!
  participatesIn(first: Int = 10, offset: Int = 0): [Pathway!]!

  # Vector similarity field (from kg_NodeEmbeddings + HNSW)
  similar(limit: Int = 10, threshold: Float = 0.7): [SimilarProtein!]!
}
```

**Field Resolvers**:
- `name`, `function`, `organism`, `confidence` → Query `rdf_props` WHERE `node_id = ? AND key = ?`
- `interactsWith` → Query `rdf_edges` WHERE `source_id = ? AND type = 'INTERACTS_WITH'`, batch via DataLoader
- `similar` → Query `kg_NodeEmbeddings` with `VECTOR_DOT_PRODUCT`, use HNSW index

---

### Gene Type

```graphql
type Gene implements Node {
  # Node interface fields
  id: ID!
  labels: [String!]!
  properties: JSON!
  createdAt: DateTime!

  # Gene-specific fields
  name: String!
  chromosome: String
  position: Int

  # Relationship fields
  encodes(first: Int = 10, offset: Int = 0): [Protein!]!
  variants(first: Int = 10, offset: Int = 0): [Variant!]!
}
```

---

### Pathway Type

```graphql
type Pathway implements Node {
  # Node interface fields
  id: ID!
  labels: [String!]!
  properties: JSON!
  createdAt: DateTime!

  # Pathway-specific fields
  name: String!
  description: String

  # Relationship fields
  proteins(first: Int = 10, offset: Int = 0): [Protein!]!
  genes(first: Int = 10, offset: Int = 0): [Gene!]!
}
```

---

### Interaction Type

```graphql
type Interaction {
  source: Node!
  target: Node!
  type: String!
  confidence: Float
  qualifiers: JSON
}
```

**Mapping to IRIS Schema**:
- `source` → `rdf_edges.source_id` (FK to nodes)
- `target` → `rdf_edges.target_id` (FK to nodes)
- `type` → `rdf_edges.type`
- `confidence` → `rdf_edges.confidence`
- `qualifiers` → `rdf_edges.qualifiers` (JSON)

---

### SimilarProtein Type

```graphql
type SimilarProtein {
  protein: Protein!
  similarity: Float!
  distance: Float
}
```

**Generated by**:
- `Protein.similar()` field resolver
- Uses HNSW index on `kg_NodeEmbeddings.embedding`
- `similarity` = `VECTOR_DOT_PRODUCT(e1.embedding, e2.embedding)`
- `distance` = `1 - similarity` (optional field)

---

## Input Types (Mutations)

### CreateProteinInput

```graphql
input CreateProteinInput {
  id: ID!
  name: String!
  function: String
  organism: String
  embedding: [Float!]  # 768-dimensional vector
}
```

**Mutation Logic**:
1. Insert into `nodes` table (`id`, `created_at`)
2. Insert into `rdf_labels` table (`node_id`, `label = 'Protein'`)
3. Insert into `rdf_props` table (`node_id`, `key`, `value`) for each property
4. Insert into `kg_NodeEmbeddings` table (`node_id`, `embedding`) if provided
5. Validate FK constraints (ensure `id` is unique)

---

### UpdateProteinInput

```graphql
input UpdateProteinInput {
  name: String
  function: String
  confidence: Float
}
```

**Mutation Logic**:
1. Validate protein exists in `nodes` table
2. Update `rdf_props` table (`UPDATE ... WHERE node_id = ? AND key = ?`)
3. Invalidate resolver cache for this protein
4. Publish `proteinUpdated` subscription event

---

### ProteinFilter (Query Arguments)

```graphql
input ProteinFilter {
  name: String
  organism: String
  confidenceMin: Float
  confidenceMax: Float
}
```

**Query Translation**:
```sql
SELECT DISTINCT n.id
FROM nodes n
JOIN rdf_labels l ON l.node_id = n.id
LEFT JOIN rdf_props p1 ON p1.node_id = n.id AND p1.key = 'name'
LEFT JOIN rdf_props p2 ON p2.node_id = n.id AND p2.key = 'organism'
LEFT JOIN rdf_props p3 ON p3.node_id = n.id AND p3.key = 'confidence'
WHERE l.label = 'Protein'
  AND (? IS NULL OR p1.value LIKE ?)
  AND (? IS NULL OR p2.value = ?)
  AND (? IS NULL OR CAST(p3.value AS FLOAT) >= ?)
  AND (? IS NULL OR CAST(p3.value AS FLOAT) <= ?)
```

---

## Query Results

### ProteinNeighborhood

```graphql
type ProteinNeighborhood {
  center: Protein!
  neighbors: [Protein!]!
  interactions: [Interaction!]!
  depth: Int!
}
```

**Resolver Logic**:
1. Query `center` protein by ID
2. Query `rdf_edges` for 1-hop neighbors (`WHERE source_id = ?`)
3. Use DataLoader to batch fetch neighbor proteins
4. Query interactions for all edges
5. Optionally expand to N hops with cycle detection

---

### Path

```graphql
type Path {
  nodes: [Node!]!
  edges: [Interaction!]!
  length: Int!
}
```

**Used for**:
- Shortest path queries
- Graph traversal results
- Pathway analysis

---

### GraphStats

```graphql
type GraphStats {
  totalNodes: Int!
  totalEdges: Int!
  nodesByLabel: JSON!
  edgesByType: JSON!
}
```

**Resolver Logic**:
```sql
-- totalNodes
SELECT COUNT(*) FROM nodes;

-- totalEdges
SELECT COUNT(*) FROM rdf_edges;

-- nodesByLabel
SELECT label, COUNT(*) FROM rdf_labels GROUP BY label;

-- edgesByType
SELECT type, COUNT(*) FROM rdf_edges GROUP BY type;
```

---

## DataLoader Models

### ProteinLoader

```python
class ProteinLoader(DataLoader):
    """Batch load proteins by ID"""

    async def batch_load_fn(self, keys: list[str]) -> list[Protein]:
        cursor = self.db.cursor()
        cursor.execute(
            "SELECT * FROM nodes WHERE id IN ({})".format(
                ','.join(['?'] * len(keys))
            ),
            keys
        )
        rows = cursor.fetchall()
        # Return in same order as keys
        row_dict = {row['id']: row for row in rows}
        return [row_dict.get(key) for key in keys]
```

**Batching Strategy**:
- Single SQL query: `SELECT * FROM nodes WHERE id IN (?, ?, ?)`
- Reduces N queries to 1 query
- Automatic request-scoped caching

---

### EdgeLoader

```python
class EdgeLoader(DataLoader):
    """Batch load edges by source node ID"""

    async def batch_load_fn(self, keys: list[str]) -> list[list[Edge]]:
        cursor = self.db.cursor()
        cursor.execute(
            "SELECT * FROM rdf_edges WHERE source_id IN ({})".format(
                ','.join(['?'] * len(keys))
            ),
            keys
        )
        rows = cursor.fetchall()

        # Group edges by source_id
        edges_by_source = {key: [] for key in keys}
        for row in rows:
            edges_by_source[row['source_id']].append(row)

        # Return in same order as keys
        return [edges_by_source[key] for key in keys]
```

**Batching Strategy**:
- Single SQL query: `SELECT * FROM rdf_edges WHERE source_id IN (?, ?, ?)`
- Groups results by source node
- Returns list of lists (one per source)

---

### PropertyLoader

```python
class PropertyLoader(DataLoader):
    """Batch load properties by node ID"""

    async def batch_load_fn(self, keys: list[str]) -> list[dict]:
        cursor = self.db.cursor()
        cursor.execute(
            "SELECT * FROM rdf_props WHERE node_id IN ({})".format(
                ','.join(['?'] * len(keys))
            ),
            keys
        )
        rows = cursor.fetchall()

        # Group properties by node_id
        props_by_node = {key: {} for key in keys}
        for row in rows:
            props_by_node[row['node_id']][row['key']] = row['value']

        # Return in same order as keys
        return [props_by_node[key] for key in keys]
```

**Batching Strategy**:
- Single SQL query: `SELECT * FROM rdf_props WHERE node_id IN (?, ?, ?)`
- Aggregates key-value pairs into dictionary
- Returns list of dictionaries (one per node)

---

### LabelLoader

```python
class LabelLoader(DataLoader):
    """Batch load labels by node ID"""

    async def batch_load_fn(self, keys: list[str]) -> list[list[str]]:
        cursor = self.db.cursor()
        cursor.execute(
            "SELECT * FROM rdf_labels WHERE node_id IN ({})".format(
                ','.join(['?'] * len(keys))
            ),
            keys
        )
        rows = cursor.fetchall()

        # Group labels by node_id
        labels_by_node = {key: [] for key in keys}
        for row in rows:
            labels_by_node[row['node_id']].append(row['label'])

        # Return in same order as keys
        return [labels_by_node[key] for key in keys]
```

**Batching Strategy**:
- Single SQL query: `SELECT * FROM rdf_labels WHERE node_id IN (?, ?, ?)`
- Groups labels by node
- Returns list of lists (one per node)

---

## Custom Scalar Types

### JSON

```python
import strawberry
import json

@strawberry.scalar
class JSON:
    """Arbitrary JSON data from rdf_props"""

    @staticmethod
    def serialize(value: dict) -> str:
        return json.dumps(value)

    @staticmethod
    def parse_value(value: str) -> dict:
        return json.loads(value)
```

---

### DateTime

```python
import strawberry
from datetime import datetime

@strawberry.scalar
class DateTime:
    """ISO 8601 datetime"""

    @staticmethod
    def serialize(value: datetime) -> str:
        return value.isoformat()

    @staticmethod
    def parse_value(value: str) -> datetime:
        return datetime.fromisoformat(value)
```

---

## Validation Rules

### FK Constraints
1. **Node ID uniqueness**: `id` must be unique in `nodes` table
2. **Label FK**: `rdf_labels.node_id` must reference `nodes.id`
3. **Property FK**: `rdf_props.node_id` must reference `nodes.id`
4. **Edge FK**: `rdf_edges.source_id` and `target_id` must reference `nodes.id`
5. **Embedding FK**: `kg_NodeEmbeddings.node_id` must reference `nodes.id`

### Input Validation
1. **Embedding dimension**: Must be 768-dimensional vector (if provided)
2. **Confidence range**: Must be 0.0 to 1.0 (if provided)
3. **Pagination**: `first` must be 1-100, `offset` must be ≥0
4. **Similarity threshold**: Must be 0.0 to 1.0

### Query Complexity
1. **Max depth**: 10 levels (configurable via environment variable)
2. **Max results**: 100 per list field (pagination required for more)

---

## State Transitions

### Protein Lifecycle

```
[Non-existent] --[createProtein]--> [Active]
[Active] --[updateProtein]--> [Active]
[Active] --[deleteProtein]--> [Deleted]
```

**State Validation**:
- **Create**: `id` must not exist in `nodes` table
- **Update**: `id` must exist in `nodes` table
- **Delete**: Cascade deletes in `rdf_labels`, `rdf_props`, `rdf_edges`, `kg_NodeEmbeddings` via FK constraints

---

## Performance Characteristics

### Query Performance Targets
- **Simple queries** (<3 levels deep): <10ms
- **Vector similarity** (k=10): <10ms with HNSW
- **N+1 prevention**: DataLoader reduces to ≤2 SQL queries
- **Overhead vs SQL**: Within 10% of hand-written SQL

### DataLoader Batching Impact

**Without DataLoader** (N+1 problem):
```graphql
query {
  proteins(first: 10) {
    name
    interactsWith(first: 5) {
      name
    }
  }
}
```
- 1 query for proteins (10 results)
- 10 queries for interactions (1 per protein)
- 50 queries for nested proteins (5 per interaction)
- **Total: 61 queries**

**With DataLoader**:
- 1 query for proteins (10 results)
- 1 batched query for interactions (WHERE source_id IN (...))
- 1 batched query for nested proteins (WHERE id IN (...))
- **Total: 3 queries** (95% reduction)

---

## Caching Strategy

### Request-scoped Cache
- **DataLoader**: Automatic caching within single GraphQL request
- **Lifetime**: Single request only
- **Invalidation**: None (request-scoped)

### Resolver-level Cache
- **TTL**: 60 seconds
- **Scope**: Cross-request
- **Invalidation**: Manual on mutations
- **Storage**: In-memory (upgradeable to Redis)

### Cache Keys
```
protein:{id}
gene:{id}
pathway:{id}
protein:{id}:interactions
protein:{id}:similar
```

---

## Error Handling

### GraphQL Error Format
```json
{
  "errors": [
    {
      "message": "Protein not found",
      "locations": [{"line": 2, "column": 3}],
      "path": ["protein"],
      "extensions": {
        "code": "NOT_FOUND",
        "proteinId": "PROTEIN:INVALID"
      }
    }
  ]
}
```

### Error Codes
- `NOT_FOUND`: Entity does not exist
- `VALIDATION_ERROR`: Input validation failed
- `FK_CONSTRAINT_VIOLATION`: Foreign key constraint violated
- `MAX_DEPTH_EXCEEDED`: Query depth limit exceeded
- `TIMEOUT`: Query execution timeout
- `INTERNAL_ERROR`: Unexpected server error

---

## Summary

Data model provides:
1. **Type-safe schema** with Node interface and entity-specific types
2. **DataLoader batching** preventing N+1 queries (mandatory)
3. **Vector similarity** integration via field resolvers
4. **Mutations** with FK validation and ACID guarantees
5. **Subscriptions** for real-time updates
6. **Caching** with 60-second TTL and manual invalidation
7. **Complexity limits** preventing DoS attacks

Ready for contract generation.
