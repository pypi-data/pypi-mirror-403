{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of point_layer template_title using point observations from point_obs_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "variable = \"point_variable\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "layer = \"point_layer\"\n",
    "point_source = \"point_obs_source\"\n",
    "# get the units. File inspection could be randomized in case people have put loose files in there...\n",
    "import glob\n",
    "import dill\n",
    "definitions = dill.load(open(glob.glob(f\"data_dir_value/oceanval_matchups/point/{layer}/{variable}/{point_source}/*definitions*.pkl\")[0], \"rb\"))\n",
    "bin_res = definitions[variable].binning\n",
    "try:\n",
    "    vv_name = definitions[variable].long_name \n",
    "except:\n",
    "    pass\n",
    "\n",
    "unit = None\n",
    "if unit is None:\n",
    "    try:\n",
    "        unit = definitions[variable].model_unit \n",
    "    except:\n",
    "        pass\n",
    "if unit is None:\n",
    "    unit = \"unknown unit\"\n",
    "\n",
    "if unit.endswith(\"/d\"):\n",
    "    unit = unit[:-2] + \"/day\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if layer in [\"surface\", \"all\"]:\n",
    "    n_levels = definitions[variable].n_levels\n",
    "    if n_levels > 1:\n",
    "        md(f\"## Performance of model sea surface {vv_name}\")\n",
    "    else:\n",
    "        md(f\"## Performance of model {vv_name}\")\n",
    "    layer_select = \"surface\"\n",
    "#if layer in [\"benthic\"]:\n",
    "chunk_point_surface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if layer == \"all\":\n",
    "    md(f\"## Depth-resolved comparisons of modelled and observed {vv_name}\")\n",
    "\n",
    "    if bin_res is not None:\n",
    "        md(\"The ability of the model to reproduce observed vertical profiles were assessed by comparing model and observational data at depth bins where observations were available.\")\n",
    "        md_markdown(f\"**Note**: the observational and model data were binned to a resolution of {bin_res[0]}° longitude by {bin_res[1]}° latitude and climatological monthly averages were calculated before analysis. This was carried out to reduce the influence of spatial bias on the validation statistics.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "df_raw =  pd.read_csv(glob.glob(f\"data_dir_value/oceanval_matchups/point/{layer}/{variable}/{point_source}/*_{variable}.csv\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if layer == \"all\":\n",
    "    # overall summary\n",
    "    #df_raw\n",
    "    # create bins\n",
    "    # 0-10m\n",
    "    # 10-30m\n",
    "    # 30-60m\n",
    "    # 60-100m\n",
    "    # 100-150m\n",
    "    # 150-300m\n",
    "    # 300-600m\n",
    "    # 600-1000m\n",
    "    # function\n",
    "    def bin_depth(x):\n",
    "        if x <= 10:\n",
    "            return \"0-10m\"\n",
    "        if x <= 30:\n",
    "            return \"10-30m\"\n",
    "        if x <= 60:\n",
    "            return \"30-60m\"\n",
    "        if x <= 100:\n",
    "            return \"60-100m\"\n",
    "        if x <= 150:\n",
    "            return \"100-150m\"\n",
    "        if x <= 300:\n",
    "            return \"150-300m\"\n",
    "        if x <= 600:\n",
    "            return \"300-600m\"\n",
    "        if x <= 1000:\n",
    "            return \"600-1000m\"\n",
    "        return \">1000m\"\n",
    "\n",
    "    df_mapped = (\n",
    "        df_raw\n",
    "        .assign(depth = lambda x: x.depth.apply(bin_depth))\n",
    "        .loc[:,[\"lon\", \"lat\", \"depth\"]]\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop = True)   \n",
    "\n",
    "    )\n",
    "    if bin_res is not None:\n",
    "        grouping = [\"lon\", \"lat\", \"depth\", \"year\", \"month\"]\n",
    "        df_raw = (\n",
    "            df_raw\n",
    "            .assign(\n",
    "                lon = lambda x: bin_value(x.lon, lon_res),\n",
    "                lat = lambda x: bin_value(x.lat, lat_res)\n",
    "            )\n",
    "        )\n",
    "        grouping = [x for x in grouping if x in df_raw.columns]\n",
    "    else:\n",
    "        grouping = [\"lon\", \"lat\", \"depth\", \"year\", \"month\", \"day\"]\n",
    "        grouping = [x for x in grouping if x in df_raw.columns]\n",
    "\n",
    "\n",
    "\n",
    "    df_summary = (\n",
    "        df_raw\n",
    "        .assign(depth = lambda x: x.depth.apply(bin_depth))\n",
    "    )\n",
    "    if bin_res is not None:\n",
    "        df_summary = (\n",
    "            df_summary\n",
    "            .groupby(grouping)\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "    df_summary = (\n",
    "        df_summary\n",
    "        .groupby(\"depth\")\n",
    "        # calculate bias, cor and rmsd between model and observation, and number of observations\n",
    "        .apply(lambda x: pd.Series({\"bias\": x.model.mean() - x.observation.mean(), \"cor\": x.model.corr(x.observation), \"rmsd\": np.sqrt(((x.model - x.observation).pow(2)).mean()), \"n\": len(x)}))   \n",
    "        .reset_index()\n",
    "        # sort depth in original order\n",
    "    )\n",
    "    # make the titles better\n",
    "    df_summary = df_summary.rename(columns={\"depth\": \"Depth\", \"bias\": \"Bias\", \"cor\": \"Correlation\", \"rmsd\": \"RMSD\", \"n\": \"Number of observations\"})\n",
    "    df_summary = df_summary.assign(Depth = pd.Categorical(df_summary.Depth, [\"0-150m\",\"0-10m\", \"10-30m\", \"30-60m\", \"60-100m\", \"100-150m\", \"150-300m\", \"300-600m\", \"600-1000m\", \">1000m\"]))\n",
    "    # now, calculate the total (raw) number of observations per depth bin (not binned in lon/lat)\n",
    "    if bin_res is not None:\n",
    "        n_obs = (\n",
    "            df_raw\n",
    "            .assign(depth = lambda x: x.depth.apply(bin_depth))\n",
    "            .groupby(\"depth\")\n",
    "            .size()\n",
    "            .reset_index(name = \"Total_number\")\n",
    "            .rename(columns={\"depth\": \"Depth\"})\n",
    "        )\n",
    "        # shallow\n",
    "        # add this to df_summary \"total number\" in brackets\n",
    "        df_summary = (df_summary.merge(n_obs)\n",
    "        # add Total_number in brackets to Number of observations\n",
    "        # change Total number to str, with commas\n",
    "        .assign(**{\"Total_number\": lambda x: x[\"Total_number\"].apply(lambda y: \"{:,}\".format(y))})\n",
    "        # Number of observations to str with commas\n",
    "        # number of obs as int\n",
    "        .assign(**{\"Number of observations\": lambda x: x[\"Number of observations\"].astype(int)})\n",
    "        .assign(**{\"Number of observations\": lambda x: x[\"Number of observations\"].apply(lambda y : \"{:,}\".format(y))})\n",
    "        .assign(**{\"Number of observations\": lambda x: x[\"Number of observations\"].astype(str) + \" (\" + x[\"Total_number\"].astype(str) + \")\"}  )  \n",
    "        .drop(columns = \"Total_number\")\n",
    "        )\n",
    "    # sort by depth\n",
    "\n",
    "    df_summary = df_summary.sort_values(\"Depth\")\n",
    "else:\n",
    "    df_mapped = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "map_layer = False\n",
    "if layer == \"all\":\n",
    "    map_layer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_mapped -i map_layer\n",
    "options(warn=-1)\n",
    "options(warn=-1)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(ggtext)\n",
    "\n",
    "if (map_layer){\n",
    "\n",
    "    world_map <- map_data(\"world\")  \n",
    "\n",
    "\n",
    "# make depth a factor\n",
    "df_mapped <- df_mapped %>%\n",
    "    mutate(depth = factor(depth, levels = c(\"0-10m\", \"10-30m\", \"30-60m\", \"60-100m\", \"100-150m\", \"150-300m\", \"300-600m\", \"600-1000m\", \">1000m\")))\n",
    "\n",
    "gg <- df_mapped %>%\n",
    "    ggplot()+\n",
    "    geom_point(aes(lon, lat), size = 0.2)+\n",
    "    theme_gray(base_size = 14)+\n",
    "    coord_fixed(ratio = 1.5, xlim = c(min(df_mapped$lon), max(df_mapped$lon)), ylim = c(min(df_mapped$lat), max(df_mapped$lat)), expand = FALSE) +\n",
    "    facet_wrap(~depth)\n",
    "\n",
    "\n",
    "gg <- gg + \n",
    "    geom_polygon(data = world_map, aes(long, lat, group = group), fill = \"grey60\")\n",
    "\n",
    "# remove x and y axis names\n",
    "gg <- gg +\n",
    "    labs(x = \"\", y = \"\") \n",
    "\n",
    "# ditch the whitespace around the plot\n",
    "gg <- gg + theme(plot.margin=unit(c(0,0,0,0),\"cm\"))\n",
    "\n",
    "gg <- gg +\n",
    "    # remove the x and y axis totally\n",
    "    theme(axis.text.x = element_blank(), axis.text.y = element_blank(),\n",
    "          axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),\n",
    "          axis.title.x = element_blank(), axis.title.y = element_blank()) +\n",
    "    labs(x = \"\", y = \"\") \n",
    "gg\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if layer == \"all\":\n",
    "    md(f\"**Figure {i_figure}**: The geographic distribution of matchups between the model and observational {variable}. The data has been binned into depth ranges. The depth ranges are 0-10m, 10-30m, 30-60m, 60-100m, 100-150m, 150-300m, 300-600m, 600-1000m, and >1000m. The number of observations in each depth range is shown in the tables below.\")\n",
    "    i_figure += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if layer == \"all\":\n",
    "    df_display(df_summary)\n",
    "    # save this to csv in the results directory\n",
    "    ff_out = f\"../../oceanval_results/{variable}_depth_summary.csv\"\n",
    "    # create directory if it does not exist\n",
    "    os.makedirs(os.path.dirname(ff_out), exist_ok=True)\n",
    "    df_summary.assign(unit = unit).to_csv(ff_out, index = False)\n",
    "    \n",
    "    if bin_res is not None:\n",
    "        final_text = \" Numbers in in brackets indicate the total unbinned observations used\"\n",
    "    else:\n",
    "        final_text = \"\"\n",
    "    md(f\"**Table {i_table}:** Average bias ({unit}), root-mean square difference (RMSD) and correlation coefficient of modelled and observed {vv_name} for different depth ranges. The bias is calculated as model - observation. The RMSD is the square root of the mean squared difference. The correlation coefficient is the Pearson correlation coefficient between the model and observed values.{final_text}\")\n",
    "    i_table += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"## Data Sources for validation of {vv_name}\")\n",
    "md_basic(definitions[variable].sources[vv_source_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if test_status:\n",
    "    md(\"This is getting to the end!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
