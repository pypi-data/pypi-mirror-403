{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f533356",
   "metadata": {},
   "source": [
    "# Sea surface template_title validation using gridded observations from source_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4644d99",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "variable = \"template_variable\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a68d5a",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87e968",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "stamp = nc.session_info[\"stamp\"]\n",
    "out = \".trackers/\" + stamp + \".txt\"\n",
    "if not os.path.exists(\".trackers\"):\n",
    "    os.makedirs(\".trackers\")\n",
    "# save out as empty file\n",
    "with open(out, 'w') as f:\n",
    "    f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165557df",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "source = \"source_name\"\n",
    "sub_regions = \"sub_regions_value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d20026",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "ff = glob.glob(f\"data_dir_value/oceanval_matchups/gridded/{variable}/{source}_{variable}_*surface.nc\")\n",
    "ff = [x for x in ff if f\"{source}_\" in x]\n",
    "ff_def = ff[0].replace(\".nc\", \"_definitions.pkl\")\n",
    "with open(ff_def, \"rb\") as f:\n",
    "    definitions = pickle.load(f)\n",
    "model_variable = definitions[variable].model_variable    \n",
    "vv_name = definitions[variable].short_name\n",
    "vv_shortname = definitions[variable].short_name\n",
    "vv_longname = definitions[variable].long_name   \n",
    "md(f\"**Matchup procedure**: The model and observations were matched up as follows. First, the model dataset was cropped by a small amount to make sure cells close to the boundary were removed. The model was then regridded to the observational grid using bilinear remmaping. Only grid cells with model and observational data were maintained. The following model output was used to compare with the observational values: **{model_variable}**.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fa244",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ff_summary = glob.glob(os.path.dirname(ff[0]) + \"/*summary.pkl\")[0]\n",
    "    with open(ff_summary, 'rb') as f:\n",
    "        vv_summary = pickle.load(f)\n",
    "    clim_years = summary[\"clim\"]\n",
    "    clim_years = \" (\" + str(clim_years[0]) + \"-\" + str(clim_years[1]) + \") \"\n",
    "except:\n",
    "    clim_years = \"\"\n",
    "    pass\n",
    "\n",
    "if len(ff) != 1:\n",
    "    raise ValueError(\"Something is wrong with the file\")\n",
    "layer = os.path.basename(ff[0]).split(\"_\")[-1].replace(\".nc\", \"\")\n",
    "if layer == \"surface\":\n",
    "    layer_long = \"sea surface\"\n",
    "ff_vertical = ff[0].replace(\"_surface.nc\", \"_vertical.nc\")\n",
    "ds_model = nc.open_data(ff)\n",
    "ds_model.subset(lon = lon_lim, lat = lat_lim)\n",
    "# change the long_name\n",
    "ds_model.set_precision(\"F32\")\n",
    "ds_model.subset(variable = \"model\")\n",
    "ds_model.tmean(\"month\")\n",
    "ds_model.run()\n",
    "new_name = definitions[variable].long_name \n",
    "new_name = new_name[0].upper() + new_name[1:]   \n",
    "ds_model.set_longnames({ds_model.variables[0]: new_name})\n",
    "ds_year = min(ds_model.years)\n",
    "ds_model.set_year(ds_year)\n",
    "ds_times = ds_model.times\n",
    "df_times = pd.DataFrame({\"year\":[x.year for x in ds_times]}).groupby(\"year\").size().reset_index()\n",
    "df_times.columns = [\"year\", \"count\"]\n",
    "years = list(df_times.query(\"count > 1\").year)\n",
    "ds_model.as_missing(0)\n",
    "# if variable is doc, add 40\n",
    "ds_model.run()\n",
    "ds_annual = ds_model.copy()\n",
    "ds_annual.tmean()\n",
    "# ds_annual.set_longnames({ds_annual.variables[0]: Variable})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b478825b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(\"## Baseline climatologies of sea surface template_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcec28",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# model climatology years can be derived from the vv_summary\n",
    "try:\n",
    "    clim_years = vv_summary[\"clim_years\"]\n",
    "    if clim_years[0] == clim_years[-1]:\n",
    "        clim_text = f\" The model climatology is calculated using the year **{clim_years[0]}**.\"\n",
    "        clim_range = f\" ({clim_years[0]}) \"\n",
    "    else:\n",
    "        clim_text = f\" The model climatology is calculated using the years **{clim_years[0]}-{clim_years[-1]}**.\"\n",
    "        clim_range = f\" ({clim_years[0]}-{clim_years[-1]}) \"\n",
    "except:\n",
    "    clim_text = \"\"\n",
    "    clim_range = \"\"\n",
    "    pass\n",
    "md_markdown(f\"Climatologies of model and observational {layer_long} {vv_name} are shown in the figures below.{clim_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c20a2",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ff = glob.glob(f\"data_dir_value/oceanval_matchups/gridded/{variable}/**_{variable}_*surface.nc\")\n",
    "ff = [x for x in ff if f\"{source}_\" in x]\n",
    "ds_obs = nc.open_data(ff)\n",
    "ds_obs.subset(variable = \"observation\")\n",
    "ds_obs.subset(lon = lon_lim, lat = lat_lim)\n",
    "\n",
    "ds_obs.run()\n",
    "# changte the long_name\n",
    "new_name = definitions[variable].long_name\n",
    "new_name = new_name[0].upper() + new_name[1:]   \n",
    "ds_obs.set_longnames({ds_obs.variables[0]: new_name})\n",
    "ds_obs.set_precision(\"F32\")\n",
    "ds_obs.tmean(\"month\")\n",
    "ds_obs.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6308613",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b885730",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa9db9d",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "n_times = len(ds_obs.times)\n",
    "if n_times > 0:\n",
    "    md(f\"## Can the model reproduce seasonality of {layer_long} {vv_longname}?\")\n",
    "\n",
    "    md(f\"The ability of the model to reproduce seasonality of {layer_long} {vv_name} was assessed by comparing the modelled and observed seasonal cycle of {vv_name}. First, we derive a monthly climatology for the model data. Then, we calculate the Pearson correlation coefficient between the modelled and observed {vv_name} at each grid cell.\")\n",
    "\n",
    "    md(\"Note: we are only assessing the ability of the model to reproduce the ability of the model to reproduce seasonal changes, not long-term trends.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4893bf1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d3c68",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if concise and sub_regions == \"None\": \n",
    "    regional = False\n",
    "n_times = len(ds_obs.times)\n",
    "if n_times < 12:\n",
    "   regional = False\n",
    "if regional:\n",
    "    md(f\"## Regional assessment of model performance for {layer_long} {vv_longname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330779f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(\"We assessed the regional performance of the model by comparing the model with observations in a number of regions. The regions considered are mapped below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d37725",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    lon_name = [x for x in ds_regions.to_xarray().coords if \"lon\" in x][0]\n",
    "    lat_name = [x for x in ds_regions.to_xarray().coords if \"lat\" in x][0]\n",
    "    df_mapped = (\n",
    "        ds_regions\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "        # rename the columns\n",
    "        .rename(columns = {lon_name: \"lon\", lat_name: \"lat\"})\n",
    "        .melt(id_vars = [\"lon\", \"lat\"])\n",
    "        .dropna()\n",
    "        .merge(regions_contents.loc[:,[\"variable\", \"long_name\"]])\n",
    "        .drop(columns = [ \"value\"])\n",
    "    )\n",
    "    bad = [\"Rosa\", \"Locate Shelf\"]\n",
    "    df_mapped = df_mapped.query(\"long_name not in @bad\")\n",
    "    xlim = np.array([df_mapped.lon.min(), df_mapped.lon.max()])\n",
    "    ylim = np.array([df_mapped.lat.min(), df_mapped.lat.max()])\n",
    "\n",
    "    def fix_name(x):\n",
    "        x = x.replace(\"North East\", \"NE\")\n",
    "        x = x.replace(\"North \", \"N \")\n",
    "        if x == \"Channel\":\n",
    "            x = \"English Channel\"\n",
    "        return x\n",
    "\n",
    "    fix_name = np.vectorize(fix_name)\n",
    "\n",
    "\n",
    "    df_mapped.long_name = fix_name(df_mapped.long_name)\n",
    "\n",
    "else:\n",
    "    df_mapped = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c28508",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    df_all = []\n",
    "    df_summary = []\n",
    "    for vv in ds_regions.variables:\n",
    "        ds_rr = ds_regions.copy()\n",
    "        ds_rr.subset(variable = vv)\n",
    "        ds_rr.run()\n",
    "        ds_vv = ds_ts.copy()\n",
    "        time_name = [x for x in list(ds_vv.to_xarray().coords) if \"time\" in x][0]\n",
    "        ds_vv * ds_rr\n",
    "        ds_region = ds_vv.copy()\n",
    "        ds_cor = ds_vv.copy()\n",
    "        ds_cor.tmean()\n",
    "        ds_cor.cor_space(\"model\", \"observation\")\n",
    "        region = list(regions_contents.query(\"variable == @vv\").long_name)[0]\n",
    "        df1 = (\n",
    "            ds_cor\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"cor\"]]\n",
    "            .rename(columns = {\"cor\": \"Spatial correlation\"})\n",
    "            .assign(region = region)\n",
    "        )\n",
    "        # now do the temporal correlation\n",
    "\n",
    "        ds_cor = ds_vv.copy()\n",
    "        ds_cor.cor_time(\"model\", \"observation\")\n",
    "        ds_cor.spatial_mean()\n",
    "        df2 = (\n",
    "            ds_cor\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"cor\"]]\n",
    "            .rename(columns = {\"cor\": \"Temporal correlation\"})\n",
    "            .assign(region = region)\n",
    "        )\n",
    "        df = df1.merge(df2)\n",
    "\n",
    "        ds_vv.spatial_mean()\n",
    "        df_bias = (\n",
    "            ds_vv\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .assign(month = lambda x: x.time.dt.month)\n",
    "            .assign(bias = lambda x: x.model - x.observation)\n",
    "            .assign(region = region)\n",
    "            .groupby(\"region\")\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"region\", \"bias\"]]\n",
    "        )\n",
    "\n",
    "        # now add the RMSD, calculated in the same way as the bias\n",
    "        df_rmsd = (\n",
    "            ds_region\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .assign(month = lambda x: x.time.dt.month)\n",
    "            .assign(rmsd = lambda x: (x.model - x.observation)**2)\n",
    "            .assign(region = region)\n",
    "            .groupby(\"region\")\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"region\", \"rmsd\"]]\n",
    "            .assign(rmsd = lambda x: np.sqrt(x.rmsd))\n",
    "        )\n",
    "\n",
    "        df = df1.merge(df2).merge(df_bias).merge(df_rmsd)\n",
    "        df_summary.append(df)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        df_vv = (\n",
    "            ds_vv\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .melt(\"time\")\n",
    "            .assign(month = lambda x: x.time.dt.month)\n",
    "            .assign(region = vv)\n",
    "        )\n",
    "        df_all.append(df_vv)\n",
    "        ds_region.tmean()\n",
    "        df_region = (\n",
    "            ds_region\n",
    "            .to_dataframe()\n",
    "            .dropna()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"model\", \"observation\"]]\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "    \n",
    "        del ds_rr, ds_vv, ds_region\n",
    "    df_all = pd.concat(df_all).dropna()\n",
    "        \n",
    "    df_all = (\n",
    "        df_all\n",
    "        .merge(df_mapped.loc[:,[\"long_name\", \"variable\"]].drop_duplicates().rename(columns = {\"variable\": \"region\"}))\n",
    "    )\n",
    "    df_summary= pd.concat(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062b1f0",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# restrict df_mapped to regions in df_all\n",
    "if regional:\n",
    "    regions = set(df_all.query(\"value > 0\").region)\n",
    "    df_mapped = df_mapped.query(\"variable in @regions\")\n",
    "else:\n",
    "    # some quick hacks to prevent an error in the next cell\n",
    "    df_mapped = \"foobar\"\n",
    "    xlim = \"foobar\"\n",
    "    ylim = \"foobar\"\n",
    "    global_grid = \"foobar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3287fa8",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i regional -i df_mapped -i xlim -i ylim -i global_grid -w 800 -h 600\n",
    "\n",
    "if (regional){\n",
    "\n",
    "    library(tidyverse)\n",
    "\n",
    "    unique_long_names <- unique(df_mapped$long_name)\n",
    "    if(\"Full Domain\" %in% unique_long_names){\n",
    "        unique_long_names <- unique_long_names[unique_long_names != \"Full Domain\"]\n",
    "        # add Full Domain, but put it first\n",
    "        unique_long_names <- c(\"Full Domain\", unique_long_names)\n",
    "        df_mapped <- df_mapped %>%\n",
    "            mutate(long_name = factor(long_name, levels = unique_long_names)) \n",
    "    }\n",
    "\n",
    "    world_map <- map_data(\"world\")\n",
    "\n",
    "    gg <-  ggplot(df_mapped)+\n",
    "        geom_tile(aes(x = lon, y = lat))+\n",
    "        coord_cartesian(xlim = xlim, ylim = ylim, expand = FALSE)+\n",
    "        theme_bw(base_size = 12)+\n",
    "        facet_wrap(~long_name, ncol = 5)+\n",
    "        theme(axis.title.x = element_blank(),\n",
    "              axis.title.y = element_blank())\n",
    "\n",
    "\n",
    "gg <- gg +\n",
    "    # remove the x and y axis totally\n",
    "    theme(axis.text.x = element_blank(), axis.text.y = element_blank(),\n",
    "          axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),\n",
    "          axis.title.x = element_blank(), axis.title.y = element_blank()) +\n",
    "    labs(x = \"\", y = \"\") \n",
    "\n",
    "gg <- gg + \n",
    "        geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = \"grey\", color = \"grey\")\n",
    "\n",
    "\n",
    "\n",
    "    gg\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc67b9",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"**Figure {i_figure}**: Regions used for validation of {layer_long} {vv_longname}.\")\n",
    "i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec3e2e8",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"Time series were constructed comparing the monthly mean of the spatial average {layer_long} {vv_name} in each region. The spatial average was calculated using the mean of all grid cells within each region, accounting for grid cell area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e077b12",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    out_ts = f\"../../oceanval_results/regionals/{source}_{variable}_regionals.csv\"\n",
    "    # check if directory exists for out_ts\n",
    "    if not os.path.exists(\"../../oceanval_results/regionals\"):\n",
    "        os.makedirs(\"../../oceanval_results/regionals\")\n",
    "    df_all.to_csv(out_ts, index = False)\n",
    "    # store the defintions\n",
    "    ff_def = out_ts.replace(\".csv\", \"_definitions.pkl\")\n",
    "    with open(ff_def, \"wb\") as f:\n",
    "        pickle.dump(definitions, f)\n",
    "    #out_ts = f\"../../oceanval_results/regionals/{source}_{variable}_regionals.csv\"\n",
    "    # save the region name to an empty txt file\n",
    "    out_file = f\"../../oceanval_results/regionals/{sub_regions}.txt\"\n",
    "    with open(out_file, 'w') as f:\n",
    "        f.write(\"\")\n",
    "if not regional:\n",
    "    df_all = False\n",
    "\n",
    "if regional:\n",
    "    try:\n",
    "        units = model_unit \n",
    "    except:\n",
    "        units = ds_ts.contents.unit[0]\n",
    "        units = str(units)\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        units = model_unit\n",
    "    except:\n",
    "        units = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d205e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i df_all -i regional -i vv_name -i units  -w 800 -h 600\n",
    "variable = vv_name\n",
    "\n",
    "# do a seasonal plot\n",
    "if(regional){\n",
    "\n",
    "    # convert long_name to factor\n",
    "    # unique_long_names \n",
    "    unique_long_names <- unique(df_all$long_name)\n",
    "    if(\"Full Domain\" %in% unique_long_names){\n",
    "        unique_long_names <- unique_long_names[unique_long_names != \"Full Domain\"]\n",
    "        # add Full Domain, but put it first\n",
    "        unique_long_names <- c(\"Full Domain\", unique_long_names)\n",
    "    df_all <- df_all %>%\n",
    "        mutate(long_name = factor(long_name, levels = unique_long_names)) \n",
    "    }\n",
    "\n",
    "    x_lab = str_glue(\"Spatial average {variable} ({units})\")\n",
    "    x_lab <- str_replace(x_lab, \"/m\\\\^3\", \"m<sup>-3</sup>\")\n",
    "    x_lab <- str_replace(x_lab, \"/m\\\\^2\", \"m<sup>-2</sup>\")\n",
    "    # handl /yr\n",
    "    x_lab <- str_replace(x_lab, \"/yr\", \" yr<sup>-1</sup>\")\n",
    "    # handle /m2\n",
    "    x_lab <- str_replace(x_lab, \"/m2\", \"m<sup>-2</sup>\")\n",
    "    # handle /m3\n",
    "    x_lab <- str_replace(x_lab, \"/m3\", \"m<sup>-3</sup>\")\n",
    "    # fix /kg to kg^-1\n",
    "    x_lab <- str_replace(x_lab, \"/kg\", \"kg<sup>-1</sup>\")\n",
    "    # CO2\n",
    "    x_lab <- str_replace(x_lab, \"CO2\", \"CO<sub>2</sub>\")\n",
    "    # O_2\n",
    "    x_lab <- str_replace(x_lab, \"O2\", \"O<sub>2</sub>\")\n",
    "    x_lab <- str_replace(x_lab, \"O_2\", \"O<sub>2</sub>\")\n",
    "    \n",
    "\n",
    "    library(tidyverse, warn.conflicts = FALSE)\n",
    "    library(ggplot2, warn.conflicts = FALSE)\n",
    "    library(ggthemes, warn.conflicts = FALSE)\n",
    "    # make variable title\n",
    "    df_all = df_all %>%\n",
    "        mutate(variable = str_to_title(variable))\n",
    "\n",
    "    gg <- ggplot(df_all)+\n",
    "        geom_line(aes(x = month, y = value, colour = variable))+\n",
    "        facet_wrap(~long_name, ncol = 5)+\n",
    "        labs(y = x_lab)+\n",
    "        labs(x = \"Month\")+\n",
    "        theme(legend_position = \"top\")+\n",
    "        scale_color_manual(values = c(\"red\", \"blue\"))+\n",
    "        scale_x_continuous(breaks = c(1, 4, 7, 10), labels = c(\"Jan\", \"Apr\", \"Jul\", \"Oct\"))+ \n",
    "        theme_bw(base_size = 12)+\n",
    "        labs(colour = \"\")+\n",
    "        theme(legend.position = \"top\")+\n",
    "        theme(axis.title.y = ggtext::element_markdown())+\n",
    "        scale_color_fivethirtyeight()\n",
    "\n",
    "        gg\n",
    "\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db278d68",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"**Figure {i_figure}**: Seasonal cycle of {layer_long} {vv_longname} for model and observations for each region. The spatial average is taken over the region.\") \n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5437cd5",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    md(f\"The table below shows the average bias of sea surface {vv_name} in each region. The bias is calculated as the modelled value minus the observed value. A positive bias indicates that the model overestimates the observed value, while a negative bias indicates that the model underestimates the observed value.\")\n",
    "\n",
    "if regional:\n",
    "    # output and hide index\n",
    "    # first average things and tidy\n",
    "    df_summary = (\n",
    "        df_summary\n",
    "        # .loc[:,[\"region\", \"bias\"]]\n",
    "        .groupby(\"region\")\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        # capitalize the columns\n",
    "        .rename(columns = {\"region\": \"Region\", \"bias\": \"Bias\", \"rmsd\": \"RMSD\"})\n",
    "    )\n",
    "    # remove na values\n",
    "    df_summary = df_summary.dropna().reset_index(drop = True)\n",
    "    if not global_grid:\n",
    "        # drop the spatial correlation\n",
    "        df_summary = df_summary.drop(columns = [\"Spatial correlation\"])\n",
    "    df_display(df_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95f9fa",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if regional:\n",
    "    regional_summary = [f\"**Table {i_table}**: Summary of performance of the model sea surface {vv_longname} in each region.\"]\n",
    "    regional_summary.append(f\"The bias ({model_unit}) column represents the spatial average of the annual mean modelled value minus the observed value.\")\n",
    "    regional_summary.append(\"The temporal correlation column represents the spatial mean of the temporal correlation between the model and observations per grid cell.\") \n",
    "    if global_grid:\n",
    "        regional_summary.append(\"The spatial correlation column represents the spatial correlation between the model and observations.\")\n",
    "    regional_summary = \" \".join(regional_summary).replace(\"  \", \" \")\n",
    "    md(regional_summary)\n",
    "    i_table = i_table + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a92e0c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394e52e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"## Can the model reproduce spatial patterns of {layer_long} {vv_longname}?\")\n",
    "\n",
    "md(f\"The ability of the model to reproduce spatial patterns of {layer_long} {vv_name} was assessed by comparing the modelled and observed {vv_name} at each grid cell. We calculated the Pearson correlation coefficient between the modelled and observed {vv_name} at each grid cell.\")\n",
    "md(\"This was carried out monthly and using the annual mean in each grid cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf4cb7",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "ff = glob.glob(f\"data_dir_value/oceanval_matchups/gridded/{variable}/**_{variable}*surface.nc\")\n",
    "ff = [x for x in ff if f\"{source}_\" in x]\n",
    "if len(ff) != 1:\n",
    "    raise ValueError(\"Something is wrong with the file\")\n",
    "layer = os.path.basename(ff[0]).split(\"_\")[-1].replace(\".nc\", \"\")\n",
    "ds_cor = nc.open_data(ff)\n",
    "ds_cor.subset(lon = lon_lim, lat = lat_lim)\n",
    "ds_cor.set_precision(\"F32\")\n",
    "ds_cor.tmean(\"month\")\n",
    "ds_cor.cor_space(\"model\", \"observation\")\n",
    "ds_cor_df = ds_cor.to_dataframe().reset_index()\n",
    "ds_cor_df = ds_cor_df.dropna()\n",
    "time_name = [x for x in list(ds_cor.to_xarray().coords) if \"time\" in x][0]\n",
    "# rename time in dataframe\n",
    "ds_cor_df.rename(columns = {time_name: \"time\"}, inplace = True)\n",
    "# extract the month\n",
    "ds_cor_df[\"month\"] = ds_cor_df.time.dt.month\n",
    "ds_cor_df = ds_cor_df.loc[:,[\"month\", \"cor\"]].drop_duplicates()\n",
    "# change month number to month name\n",
    "ds_cor_df[\"month\"] = ds_cor_df[\"month\"].apply(lambda x: calendar.month_abbr[x])\n",
    "# now do this annually\n",
    "ds_cor = nc.open_data(ff)\n",
    "ds_cor.subset(lon = lon_lim, lat = lat_lim)\n",
    "ds_cor.set_precision(\"F32\")\n",
    "ds_cor.tmean(\"month\")\n",
    "ds_cor.tmean()\n",
    "df_annual = ds_cor.to_dataframe()\n",
    "ds_cor.cor_space(\"model\", \"observation\")\n",
    "ds_cor_df_annual = ds_cor.to_dataframe().reset_index()\n",
    "ds_cor_df_annual = ds_cor_df_annual.dropna()\n",
    "time_name = [x for x in list(ds_cor.to_xarray().coords) if \"time\" in x][0]\n",
    "# rename time in dataframe\n",
    "ds_cor_df_annual.rename(columns = {time_name: \"time\"}, inplace = True)\n",
    "# extract the month\n",
    "ds_cor_df_annual[\"month\"] = ds_cor_df_annual.time.dt.month\n",
    "ds_cor_df_annual = ds_cor_df_annual.loc[:,[\"month\", \"cor\"]].drop_duplicates()\n",
    "# output to csv\n",
    "ds_cor_df_annual = ds_cor_df_annual.assign(month = \"Annual mean\")\n",
    "# merge the two dataframes\n",
    "ds_cor_df = pd.concat([ds_cor_df_annual, ds_cor_df])\n",
    "# change month to period\n",
    "ds_cor_df.rename(columns = {\"month\": \"period\"}, inplace = True)\n",
    "# Give the columns more sensible names\n",
    "ds_cor_df.rename(columns = {\"cor\": \"Correlation coefficient\"}, inplace = True)\n",
    "ds_cor_df.rename(columns = {\"period\": \"Time period\"}, inplace = True)\n",
    "# drop any na\n",
    "ds_cor_df.dropna(inplace = True)\n",
    "df_display(ds_cor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c398f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"**Table {i_table}**: Pearson correlation coefficient between modelled and observed {layer_long} {vv_longname} at each grid cell. The correlation was calculated monthly and using the annual mean in each grid cell.\")\n",
    "i_table += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faff526",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "time_series = False\n",
    "if regional:\n",
    "    ff = glob.glob(f\"data_dir_value/oceanval_matchups/gridded/{variable}/**_{variable}_*surface.nc\")\n",
    "    ff = [x for x in ff if f\"{source}_\" in x]\n",
    "    ds_ts = nc.open_data(ff)\n",
    "    ds_ts.subset(lon = lon_lim, lat = lat_lim)\n",
    "    years = ds_ts.years\n",
    "    year_range = f\"{min(years)}-{max(years)}\"\n",
    "    if len(years) > 1:\n",
    "        ds_ts.tmean(\"year\")\n",
    "        ds_ts.run()\n",
    "        time_series = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b2cfc",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    md(f\"The ability of the model to reproduce multi-year trends in {layer_long} {vv_name} was assessed by comparing the modelled and observed time series of annual {vv_name} across each region.\")\n",
    "    md(f\"The figure below shows the average {vv_name} in each region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41838c",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    df_all = []\n",
    "    for vv in ds_regions.variables:\n",
    "        ds_rr = ds_regions.copy()\n",
    "        ds_rr.subset(variable = vv)\n",
    "        ds_rr.run()\n",
    "        ds_vv = ds_ts.copy()\n",
    "        ds_vv * ds_rr\n",
    "        ds_region = ds_vv.copy()\n",
    "        ds_vv.spatial_mean()\n",
    "        region = list(regions_contents.query(\"variable == @vv\").long_name)[0]\n",
    "        time_name = [x for x in list(ds_vv.to_xarray().coords) if \"time\" in x][0]\n",
    "        df_vv = (\n",
    "            ds_vv\n",
    "            .to_dataframe()\n",
    "            .reset_index()\n",
    "            .rename(columns = {time_name: \"time\"})\n",
    "            .loc[:,[\"time\", \"model\", \"observation\"]]\n",
    "            .melt(\"time\")\n",
    "            .assign(year = lambda x: x.time.dt.year)\n",
    "            .assign(region = vv)\n",
    "        )\n",
    "        df_all.append(df_vv)\n",
    "        ds_region.tmean()\n",
    "        df_region = (\n",
    "            ds_region\n",
    "            .to_dataframe()\n",
    "            .dropna()\n",
    "            .reset_index()\n",
    "            .loc[:,[\"model\", \"observation\"]]\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "    \n",
    "        del ds_rr, ds_vv, ds_region\n",
    "    df_all = pd.concat(df_all).dropna()\n",
    "        \n",
    "    df_all = (\n",
    "        df_all\n",
    "        .merge(df_mapped.loc[:,[\"long_name\", \"variable\"]].drop_duplicates().rename(columns = {\"variable\": \"region\"}))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9eb4dd",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%%R -i time_series -i variable -i df_all\n",
    "if(time_series){\n",
    "library(tidyverse)\n",
    "\n",
    "ylab = str_glue(\"Spatial average {variable} ({units})\")\n",
    "ylab <- str_replace(ylab, \"/m\\\\^3\", \"m<sup>-3</sup>\")\n",
    "ylab <- str_replace(ylab, \"/m\\\\^2\", \"m<sup>-2</sup>\")\n",
    "# handl /yr\n",
    "ylab <- str_replace(ylab, \"/yr\", \" yr<sup>-1</sup>\")\n",
    "# handle /m2\n",
    "ylab <- str_replace(ylab, \"/m2\", \"m<sup>2</sup>\")\n",
    "# handle /m3\n",
    "ylab <- str_replace(ylab, \"/m3\", \"m<sup>3</sup>\")\n",
    "# fix /kg to kg^-1\n",
    "ylab <- str_replace(ylab, \"/kg\", \"kg<sup>-1</sup>\")\n",
    "# CO2\n",
    "ylab <- str_replace(ylab, \"CO2\", \"CO<sub>2</sub>\")\n",
    "# make variable title\n",
    "# pco2\n",
    "ylab <- str_replace(ylab, \"pCO2\", \"pCO<sub>2</sub>\")\n",
    "ylab <- str_replace(ylab, \"pco2\", \"pCO<sub>2</sub>\")\n",
    "# mutam should use greek letters\n",
    "ylab <- str_replace(ylab, \"muatm\", \"µatm\")\n",
    "\n",
    "# create a suitable scale_x_continuous based on year\n",
    "# get the min and max year\n",
    "min_year = min(df_all$year)\n",
    "max_year = max(df_all$year)\n",
    "# create a sequence of years, maximum is 7\n",
    "ceiling((max_year - min_year)/7)\n",
    "seq_year <- seq(min_year, max_year, ceiling((max_year - min_year)/7))\n",
    "\n",
    "\n",
    "gg <- df_all %>%\n",
    "    ggplot(aes(x = year, y = value, colour = variable))+\n",
    "    geom_line()+\n",
    "    facet_wrap(~long_name)+\n",
    "    labs(y = ylab)+\n",
    "    labs(x = \"Year\")+\n",
    "    theme(legend.position = \"top\")+\n",
    "    scale_color_manual(values = c(\"red\", \"blue\"))+\n",
    "    theme_bw(base_size = 10)+\n",
    "    labs(colour = \"\")+\n",
    "    theme(legend.position = \"top\")+\n",
    "    theme(axis.title.y = ggtext::element_markdown())+\n",
    "    scale_color_fivethirtyeight()+\n",
    "    scale_x_continuous(breaks = seq_year, labels = seq_year)\n",
    "\n",
    "    gg\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82c07b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Now do the verticals if needed\n",
    "if os.path.exists(ff_vertical):\n",
    "    verticals = True\n",
    "    md(f\"## How well does the model reproduce vertical profiles of {vv_longname}?\")\n",
    "    text = f\"The ability of the model to reproduce vertical profiles of {vv_name} was assessed by comparing the modelled and observed vertical profiles of {vv_name}. This was carried out by calculating the zonal average vertical profile of {vv_name} for both the model and observation based on annual means.\"\n",
    "    md(text)\n",
    "else:\n",
    "    verticals = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7d1fc",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    regions = ds_regions.variables\n",
    "    # coerce to list\n",
    "    regions = list(regions)\n",
    "    regions.append(\"full_domain\")\n",
    "    regionals = True\n",
    "except:\n",
    "    regionals = True\n",
    "    regions = [\"full_domain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda63af6",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if time_series:\n",
    "    md(f\"**Figure {i_figure}**: Changes in {layer_long} {vv_longname} for model and observations for each region for the period {year_range}. The spatial average is taken over the region.\") \n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8595e91",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if verticals:\n",
    "    ds_verticals = nc.open_data(ff_vertical, checks = False)\n",
    "    ds_verticals.tmean()\n",
    "    ds_verticals.run()\n",
    "    levels = ds_verticals.levels\n",
    "    max_depth = max(levels)\n",
    "    min_depth = min(levels)\n",
    "    # 100 appropriate levels, evenly spaces\n",
    "    new_levels = np.linspace(min_depth, max_depth, 100)\n",
    "    ds_verticals.vertical_interp(new_levels, fixed = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11671e0e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if verticals:\n",
    "    df_zonals = []\n",
    "    for rr in regions:\n",
    "        ds_rr = ds_verticals.copy()\n",
    "        if rr != \"full_domain\":\n",
    "            ds_subset = ds_regions.copy()\n",
    "            ds_subset.as_missing(0)\n",
    "            ds_subset.set_fill(-9999)\n",
    "            ds_subset.subset(variable = rr)\n",
    "            ds_subset.run()\n",
    "            long_name = ds_subset.contents.long_name[0]\n",
    "            ds_subset - 1\n",
    "            ds_rr + ds_subset\n",
    "            ds_rr.zonal_mean()\n",
    "        else:\n",
    "            ds_rr.zonal_mean()\n",
    "            long_name = \"Full domain\"\n",
    "        df_merged = ds_rr.to_dataframe().reset_index(drop = True)\n",
    "        depth_name = [x for x in ds_rr.to_xarray().coords if \"depth\" in x][0]\n",
    "        # rename\n",
    "        df_merged = df_merged.rename(columns = {depth_name: \"depth\"})\n",
    "        lon_name = [x for x in ds_rr.to_xarray().coords if \"lon\" in x][0]\n",
    "        lat_name = [x for x in ds_rr.to_xarray().coords if \"lat\" in x][0]\n",
    "        # ditch lon\n",
    "        df_merged = df_merged.drop(columns = [lon_name])\n",
    "        # rename lat to lat\n",
    "        df_merged = df_merged.rename(columns = {lat_name: \"lat\"})\n",
    "        df_merged = (\n",
    "            df_merged\n",
    "            # melt it\n",
    "            .melt(id_vars = [\"depth\", \"lat\"], value_vars = [\"model\", \"observation\"])\n",
    "        )\n",
    "        df_merged = (df_merged\n",
    "        # variable as title\n",
    "            .assign(variable = lambda x: x.variable.str.title())\n",
    "        ).assign(region = long_name) \n",
    "        df_zonals.append(df_merged)\n",
    "    df_zonals = pd.concat(df_zonals).dropna().reset_index(drop = True)\n",
    "\n",
    "    # Put Full domain first\n",
    "    df_zonals = pd.concat(\n",
    "        [df_zonals.query(\"region == 'Full domain'\"),\n",
    "        df_zonals.query(\"region != 'Full domain'\")]\n",
    "\n",
    "    )\n",
    "\n",
    "    \n",
    "    # only lat, model and observation\n",
    "    # df_rr = df_rr.loc[:,[lat_name, \"depth\", \"model\", \"observation\"]].dropna()\n",
    "else:\n",
    "    df_zonals = pd.DataFrame({\"foo\":[\"bar\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78921829",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%R -i verticals -i regionals -i df_zonals -i vv_name -i units -w 800 -h zonal_height\n",
    "# is df_zonals a dataframe\n",
    "\n",
    "if(\"region\" %in% colnames(df_zonals)){\n",
    "    library(tidyverse)\n",
    "    units <- str_replace(units, \"/m\\\\^3\", \"m<sup>-3</sup>\")\n",
    "    units <- str_replace(units, \"/m\\\\^2\", \"m<sup>-2</sup>\")\n",
    "    units <- str_replace(units, \"/yr\", \" yr<sup>-1</sup>\")\n",
    "    units <- str_replace(units, \"/m2\", \"m<sup>-2</sup>\")\n",
    "    units <- str_replace(units, \"/m3\", \"m<sup>-3</sup>\")\n",
    "    units <- str_replace(units, \"/kg\", \"kg<sup>-1</sup>\")\n",
    "    # CO2\n",
    "\n",
    "    # loop through the regions\n",
    "    i <- 1\n",
    "    big_list = list()\n",
    "    for(rr in unique(df_zonals$region)){\n",
    "\n",
    "    gg <- df_zonals %>%\n",
    "        filter(region == rr) %>%\n",
    "        drop_na() %>%\n",
    "        ggplot()+\n",
    "        geom_raster(aes(x = lat, y = depth, fill = value))+\n",
    "        facet_wrap(~variable)+\n",
    "        scale_y_reverse()+\n",
    "        scale_fill_viridis_c(guide  = guide_colourbar(title.position = \"right\"))+\n",
    "        theme_bw(base_size = 10)+\n",
    "        theme(legend.title = ggtext::element_markdown(angle = -90), legend.title.align = 0.5)+\n",
    "        labs(x = \"Latitude\", y = \"Depth (m)\", fill = str_glue(\"{vv_name} ({units})\"))+\n",
    "        theme(axis.title.y = ggtext::element_markdown())+\n",
    "        theme(axis.title.x = ggtext::element_markdown())+\n",
    "        coord_cartesian(expand = FALSE)+\n",
    "        # ditch the x axis labels\n",
    "\n",
    "        labs(x = \"\", title = rr)\n",
    "\n",
    "    x_breaks <- ggplot_build(gg)$layout$panel_params[[1]]$x$breaks\n",
    "    x_breaks <- na.omit(x_breaks)\n",
    "    x_labels <- paste0(x_breaks, \"°\")\n",
    "    # add N to x_label is x_break > 0\n",
    "    x_labels <- ifelse(x_breaks > 0, paste0(x_breaks, \"°N\"), ifelse(x_breaks < 0, paste0(abs(x_breaks), \"°S\"), \"0°\"))\n",
    "    # add S to x_label is x_break < 0\n",
    "    x_labels <- ifelse(x_breaks < 0, paste0(abs(x_breaks), \"°S\"), x_labels)\n",
    "    # remove  the str \"-\" from x_labels if x_break < 0\n",
    "    x_labels <- gsub(\"-\", \"\", x_labels)\n",
    "\n",
    "# no missing values\n",
    "    gg1 <- gg + scale_x_continuous(breaks = x_breaks, labels= x_labels)\n",
    "\n",
    "    # now do a bias plot\n",
    "    df_bias <- df_zonals %>%\n",
    "        filter(region == rr) %>%\n",
    "        drop_na() %>%\n",
    "        pivot_wider(names_from = variable, values_from = value) %>%\n",
    "        mutate(bias = Model - Observation)\n",
    "    gg2 <- df_bias %>%\n",
    "\n",
    "        ggplot()+\n",
    "        geom_raster(aes(x = lat, y = depth, fill = bias))+\n",
    "        scale_y_reverse()+\n",
    "        scale_fill_gradient2(low = \"blue\", mid = \"white\", high = \"red\", \n",
    "                             guide  = guide_colourbar(title.position = \"right\"))+\n",
    "        theme_bw(base_size = 10)+\n",
    "        theme(legend.title = ggtext::element_markdown(angle = -90), legend.title.align = 0.5)+\n",
    "        labs(x = \"Latitude\", y = \"Depth (m)\", fill = str_glue(\"Bias ({model_unit})\"))+\n",
    "        theme(axis.title.y = ggtext::element_markdown())+\n",
    "        theme(axis.title.x = ggtext::element_markdown())+\n",
    "        coord_cartesian(expand = FALSE)\n",
    "        # ditch the x axis labels\n",
    "    gg2 <- gg2 + labs(x = \"\")\n",
    "    x_breaks <- ggplot_build(gg2)$layout$panel_params[[1]]$x$breaks\n",
    "    x_breaks <- na.omit(x_breaks)\n",
    "    x_labels <- paste0(x_breaks, \"°\")\n",
    "    # add N to x_label is x_break > 0\n",
    "    x_labels <- ifelse(x_breaks > 0, paste0(x_breaks, \"°N\"), ifelse(x_breaks < 0, paste0(abs(x_breaks), \"°S\"), \"0°\"))\n",
    "    # add S to x_label is x_break < 0\n",
    "    x_labels <- ifelse(x_breaks < 0, paste0(abs(x_breaks), \"°S\"), x_labels)\n",
    "    # remove  the str \"-\" from x_labels if x_break < 0\n",
    "    x_labels <- gsub(\"-\", \"\", x_labels)\n",
    "\n",
    "\n",
    "    gg2 <- gg2 + scale_x_continuous(breaks = x_breaks, labels= x_labels)\n",
    "\n",
    "# combine the two plots, use rr as title\n",
    "    gg <- cowplot::plot_grid(gg1, gg2, ncol = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    big_list[[i]] <- gg\n",
    "    i <- i + 1\n",
    "    \n",
    "    }\n",
    "\n",
    "    cowplot::plot_grid(plotlist = big_list, ncol = 1)\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7037ebe8",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if verticals and regionals:\n",
    "    md(f\"**Figure {i_figure}**: Vertical profiles of {layer_long} {vv_longname} for model and observations for each region. The zonal average is taken over the region.\")\n",
    "    i_figure += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280efcca",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "chunk_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbb9fe",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(f\"## Data Sources for validation of {vv_name}\")\n",
    "md_basic(definitions[variable].sources[source])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95ea54",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "if test_status:\n",
    "    md(\"This is getting to the end!\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "oceanval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
