name: Performance Benchmarks

on:
  workflow_dispatch:
    inputs:
      runners:
        description: 'Runners to benchmark (comma-separated: linux,macos or just linux)'
        required: false
        default: 'linux,macos'
        type: string
      benchmark_suite:
        description: 'Benchmark suite to run (fast or full)'
        required: false
        default: 'fast'
        type: choice
        options:
          - fast
          - full
      alert_threshold:
        description: 'Alert threshold percentage (e.g., 150 for 150% degradation)'
        required: false
        default: '150'
        type: string
      baseline_tag:
        description: 'Baseline git tag (leave empty for latest tag)'
        required: false
        default: ''
        type: string
      target_branch:
        description: 'Target branch to benchmark (leave empty for current branch)'
        required: false
        default: ''
        type: string

jobs:
  prepare:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      baseline_tag: ${{ steps.baseline.outputs.tag }}
      target_ref: ${{ steps.target.outputs.ref }}
      benchmark_config: ${{ steps.benchmark-config.outputs.config }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Determine baseline tag
        id: baseline
        run: |
          if [ -n "${{ inputs.baseline_tag }}" ]; then
            BASELINE_TAG="${{ inputs.baseline_tag }}"
            echo "Using user-specified baseline tag: $BASELINE_TAG"
          else
            BASELINE_TAG=$(git tag --sort=-creatordate | head -1)
            if [ -z "$BASELINE_TAG" ]; then
              echo "Error: No git tags found. Please create a tag or specify baseline_tag input."
              exit 1
            fi
            echo "Using latest tag as baseline: $BASELINE_TAG"
          fi
          echo "tag=$BASELINE_TAG" >> $GITHUB_OUTPUT

      - name: Determine target reference
        id: target
        run: |
          if [ -n "${{ inputs.target_branch }}" ]; then
            TARGET_REF="${{ inputs.target_branch }}"
          else
            TARGET_REF="${{ github.ref_name }}"
          fi
          echo "ref=$TARGET_REF" >> $GITHUB_OUTPUT
          echo "Target reference: $TARGET_REF"

      - name: Set up runner matrix
        id: set-matrix
        run: |
          RUNNERS="${{ inputs.runners }}"
          SUITE="${{ inputs.benchmark_suite }}"

          # Build matrix JSON
          MATRIX_JSON='{"include":['

          if [ "$SUITE" == "fast" ]; then
            # Fast mode: GitHub-hosted runners, default to both linux and macos
            if [[ "$RUNNERS" == *"linux"* ]] || [ "$RUNNERS" == "linux" ]; then
              MATRIX_JSON+='{"runner":"linux","labels":"[\"ubuntu-latest\"]","os":"linux","arch":"amd64"},'
            fi

            # For fast mode, if default runners or macos explicitly requested, add macos
            if [[ "$RUNNERS" == *"macos"* ]] || [ "$RUNNERS" == "linux" ]; then
              MATRIX_JSON+='{"runner":"macos","labels":"[\"macos-latest\"]","os":"macos","arch":"arm64"},'
            fi
          else
            # Full mode: Self-hosted runners, respect runners parameter
            if [[ "$RUNNERS" == *"linux"* ]]; then
              MATRIX_JSON+='{"runner":"linux","labels":"[\"self-hosted\",\"Linux\",\"extra-c20m50\"]","os":"linux","arch":"amd64"},'
            fi

            if [[ "$RUNNERS" == *"macos"* ]]; then
              MATRIX_JSON+='{"runner":"macos","labels":"[\"self-hosted\",\"macos\",\"extra-c10m50\"]","os":"macos","arch":"arm64"},'
            fi
          fi

          # Remove trailing comma and close JSON
          MATRIX_JSON="${MATRIX_JSON%,}]}"

          echo "Matrix: $MATRIX_JSON"
          echo "matrix=$MATRIX_JSON" >> $GITHUB_OUTPUT

      - name: Determine benchmark config
        id: benchmark-config
        run: |
          SUITE="${{ inputs.benchmark_suite }}"
          if [ "$SUITE" == "full" ]; then
            CONFIG="conf/benchmark-pull-request.yaml"
          else
            CONFIG="conf/benchmark-pull-request-fast.yaml"
          fi
          echo "Using benchmark config: $CONFIG"
          echo "config=$CONFIG" >> $GITHUB_OUTPUT

  benchmark:
    needs: prepare
    strategy:
      matrix: ${{ fromJson(needs.prepare.outputs.matrix) }}
      fail-fast: false
    runs-on: ${{ fromJson(matrix.labels) }}
    permissions:
      contents: write
      pull-requests: write

    steps:
      - name: Set up PATH for self-hosted runners
        if: ${{ inputs.benchmark_suite == 'full' }}
        run: echo "/home/gha/.local/bin" >> $GITHUB_PATH

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history for tag identification

      - name: Validate threshold
        id: threshold
        run: |
          THRESHOLD="${{ inputs.alert_threshold }}"
          # Validate threshold is a number between 100 and 1000
          if ! [[ "$THRESHOLD" =~ ^[0-9]+(\.[0-9]+)?$ ]]; then
            echo "Error: Threshold must be a number"
            exit 1
          fi
          if (( $(echo "$THRESHOLD < 100" | bc -l) )); then
            echo "Error: Threshold must be >= 100"
            exit 1
          fi
          if (( $(echo "$THRESHOLD > 1000" | bc -l) )); then
            echo "Error: Threshold must be <= 1000"
            exit 1
          fi
          echo "value=$THRESHOLD" >> $GITHUB_OUTPUT
          echo "Using alert threshold: $THRESHOLD%"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install system dependencies (Linux)
        if: ${{ matrix.os == 'linux' }}
        run: |
          sudo apt-get update
          sudo apt-get install -y bedtools jq

      - name: Install system dependencies (macOS)
        if: ${{ matrix.os == 'macos' }}
        run: |
          brew install bedtools jq

      - name: Cache polars-bio-bench repository
        uses: actions/cache@v4
        with:
          path: polars-bio-bench
          key: polars-bio-bench-${{ hashFiles('**/lockfiles') }}

      - name: Clone polars-bio-bench repository
        run: |
          if [ ! -d "polars-bio-bench" ]; then
            git clone https://github.com/biodatageeks/polars-bio-bench.git
          else
            cd polars-bio-bench && git pull && cd ..
          fi

      - name: Install Poetry
        run: |
          curl -sSL https://install.python-poetry.org | python3 -

      - name: Install polars-bio-bench dependencies
        run: |
          cd polars-bio-bench
          # Update lock file to match pyproject.toml
          poetry lock
          # Install dependencies only, not the package itself
          poetry install --no-root

      # ============================================
      # BASELINE BENCHMARK
      # ============================================

      - name: Install baseline polars-bio from PyPI
        run: |
          # For baseline, install the released version from PyPI into poetry virtualenv
          cd polars-bio-bench
          poetry run pip install polars-bio==$(echo "${{ needs.prepare.outputs.baseline_tag }}" | sed 's/^v//')

      - name: Restore benchmark test data cache
        id: cache-benchmark-data
        uses: actions/cache/restore@v4
        with:
          path: /tmp/polars-bio-bench
          key: polars-bio-bench-data-${{ hashFiles('polars-bio-bench/conf/benchmark_small.yaml') }}
          restore-keys: |
            polars-bio-bench-data-

      - name: Set up benchmark environment
        run: |
          export BENCH_DATA_ROOT=/tmp/polars-bio-bench/
          export POLARS_MAX_THREADS=1
          mkdir -p $BENCH_DATA_ROOT

      - name: Run baseline benchmarks
        run: |
          cd polars-bio-bench
          export BENCH_DATA_ROOT=/tmp/polars-bio-bench/
          export POLARS_MAX_THREADS=1
          # Run benchmarks using poetry
          poetry run python src/run-benchmarks.py --bench-config ${{ needs.prepare.outputs.benchmark_config }}
          # List results directory structure
          echo "Results directory contents:"
          ls -laR results/ || echo "No results directory found"
          # Copy results to parent directory with baseline prefix
          mkdir -p ../baseline_results
          if [ -d "results" ] && [ "$(ls -A results)" ]; then
            # Find the latest results subdirectory and copy its contents
            LATEST_RESULTS=$(ls -t results | head -1)
            echo "Copying from results/$LATEST_RESULTS/"
            cp -r "results/$LATEST_RESULTS/"* ../baseline_results/
          else
            echo "No results found to copy"
            exit 1
          fi
        continue-on-error: true

      - name: Verify baseline results
        run: |
          if [ ! -d baseline_results ] || [ -z "$(ls -A baseline_results)" ]; then
            echo "Error: Baseline benchmark did not produce results"
            exit 1
          fi
          echo "Baseline results:"
          ls -la baseline_results/
          find baseline_results/ -name "*.csv" | head -5 | xargs -I {} sh -c 'echo "=== {} ===" && head -10 "{}"'

      # ============================================
      # TARGET/PR BENCHMARK
      # ============================================

      - name: Checkout target code
        run: |
          git checkout ${{ needs.prepare.outputs.target_ref }}

      - name: Clean previous installation
        run: |
          cd polars-bio-bench
          poetry run pip uninstall -y polars-bio || true

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Set Rust build flags
        id: rust-target
        run: |
          if [ "${{ matrix.os }}" == "macos" ]; then
            # macOS: Use apple-m1 target with dynamic_lookup linker flags
            echo "target_cpu=apple-m1" >> $GITHUB_OUTPUT
            echo "rustflags=-Clink-arg=-undefined -Clink-arg=dynamic_lookup -Ctarget-cpu=apple-m1" >> $GITHUB_OUTPUT
          else
            # Linux: Use skylake target
            echo "target_cpu=skylake" >> $GITHUB_OUTPUT
            echo "rustflags=-Ctarget-cpu=skylake" >> $GITHUB_OUTPUT
          fi

      - name: Set up sccache
        uses: mozilla-actions/sccache-action@v0.0.9

      - name: Cache Cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
          key: ${{ runner.os }}-cargo-registry-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-registry-

      - name: Install target polars-bio from source
        env:
          RUSTFLAGS: "${{ steps.rust-target.outputs.rustflags }}"
          CARGO_INCREMENTAL: "1"
        run: |
          # Install maturin in poetry virtualenv
          cd polars-bio-bench
          poetry run pip install maturin
          # Build from repo root with explicit Cargo.toml path
          poetry run maturin develop --release -m ../Cargo.toml

      - name: Run target benchmarks
        run: |
          cd polars-bio-bench
          export BENCH_DATA_ROOT=/tmp/polars-bio-bench/
          export POLARS_MAX_THREADS=1
          # Run benchmarks using poetry
          poetry run python src/run-benchmarks.py --bench-config ${{ needs.prepare.outputs.benchmark_config }}
          # List results directory structure
          echo "Results directory contents:"
          ls -laR results/ || echo "No results directory found"
          # Copy results to parent directory with pr prefix
          mkdir -p ../pr_results
          if [ -d "results" ] && [ "$(ls -A results)" ]; then
            # Find the latest results subdirectory and copy its contents
            LATEST_RESULTS=$(ls -t results | head -1)
            echo "Copying from results/$LATEST_RESULTS/"
            cp -r "results/$LATEST_RESULTS/"* ../pr_results/
          else
            echo "No results found to copy"
            exit 1
          fi
        continue-on-error: true

      - name: Verify target results
        run: |
          if [ ! -d pr_results ] || [ -z "$(ls -A pr_results)" ]; then
            echo "Error: Target benchmark did not produce results"
            exit 1
          fi
          echo "Target results:"
          ls -la pr_results/
          find pr_results/ -name "*.csv" | head -5 | xargs -I {} sh -c 'echo "=== {} ===" && head -10 "{}"'

      - name: Save benchmark test data cache
        if: success()
        uses: actions/cache/save@v4
        with:
          path: /tmp/polars-bio-bench
          key: ${{ steps.cache-benchmark-data.outputs.cache-primary-key }}

      - name: Save runner metadata
        run: |
          cat > runner_info.json <<EOF
          {
            "runner": "${{ matrix.runner }}",
            "os": "${{ matrix.os }}",
            "arch": "${{ matrix.arch }}",
            "benchmark_suite": "${{ inputs.benchmark_suite }}",
            "benchmark_config": "${{ needs.prepare.outputs.benchmark_config }}",
            "timestamp": "$(date -u +"%Y-%m-%d %H:%M:%S UTC")",
            "baseline_tag": "${{ needs.prepare.outputs.baseline_tag }}",
            "target_ref": "${{ needs.prepare.outputs.target_ref }}"
          }
          EOF
          cat runner_info.json

      - name: Upload benchmark results as artifact
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ matrix.runner }}
          path: |
            baseline_results/
            pr_results/
            runner_info.json

  aggregate:
    needs: [prepare, benchmark]
    runs-on: ubuntu-latest
    if: always()  # Run even if some benchmarks fail
    permissions:
      contents: write
      pull-requests: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          fetch-tags: true

      - name: Download all benchmark artifacts
        uses: actions/download-artifact@v4
        with:
          path: all-results/
          pattern: benchmark-results-*
          merge-multiple: false

      - name: List downloaded artifacts
        run: |
          echo "Downloaded artifacts:"
          ls -la all-results/
          find all-results/ -type f | head -20

      - name: Generate multi-runner comparison charts
        run: |
          # Check if we have multiple runners
          RUNNER_COUNT=$(ls -d all-results/benchmark-results-* 2>/dev/null | wc -l)
          echo "Found $RUNNER_COUNT runner(s)"

          python3 benchmarks/generate_comparison_charts.py \
            --multi-runner \
            --results-dir all-results \
            --output comparison_charts/benchmark_comparison.html \
            --baseline-name "${{ needs.prepare.outputs.baseline_tag }}" \
            --pr-name "${{ needs.prepare.outputs.target_ref }}"

      - name: Clone gh-pages branch
        run: |
          # Clone gh-pages branch
          git clone --depth 1 --branch gh-pages https://github.com/${{ github.repository }} gh-pages-repo || {
            echo "gh-pages branch doesn't exist, creating..."
            mkdir -p gh-pages-repo
            cd gh-pages-repo
            git init
            git checkout --orphan gh-pages
            mkdir -p benchmark-data benchmark-comparison
            echo '{"last_updated":"'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'","datasets":[],"tags":[],"latest_tag":null}' > benchmark-data/index.json
            git add .
            git commit -m "Initialize gh-pages"
            git remote add origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}
            git push origin gh-pages
            cd ..
          }

      - name: Store benchmark data to gh-pages
        run: |
          # Determine ref type and storage path
          if [[ "${{ github.ref }}" == refs/tags/* ]]; then
            REF_TYPE="tag"
            REF_NAME="${GITHUB_REF#refs/tags/}"
            IS_LATEST_TAG="true"
          else
            REF_TYPE="branch"
            REF_NAME="${{ github.ref_name }}"
            IS_LATEST_TAG="false"
          fi

          COMMIT_SHA="${{ github.sha }}"
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

          echo "Storing benchmark data for $REF_TYPE: $REF_NAME"

          # Process each runner's results
          for RUNNER_DIR in all-results/benchmark-results-*; do
            if [ ! -d "$RUNNER_DIR" ]; then
              continue
            fi

            # Extract runner name
            RUNNER=$(basename "$RUNNER_DIR" | sed 's/benchmark-results-//')
            echo "Processing runner: $RUNNER"

            # Read runner info if available
            if [ -f "$RUNNER_DIR/runner_info.json" ]; then
              RUNNER_OS=$(jq -r '.os // "linux"' "$RUNNER_DIR/runner_info.json")
              RUNNER_ARCH=$(jq -r '.arch // "amd64"' "$RUNNER_DIR/runner_info.json")
              BENCHMARK_SUITE=$(jq -r '.benchmark_suite // "fast"' "$RUNNER_DIR/runner_info.json")
              BENCHMARK_CONFIG=$(jq -r '.benchmark_config // "conf/benchmark-pull-request-fast.yaml"' "$RUNNER_DIR/runner_info.json")
            else
              echo "Warning: No runner_info.json for $RUNNER, using defaults"
              RUNNER_OS="linux"
              RUNNER_ARCH="amd64"
              BENCHMARK_SUITE="fast"
              BENCHMARK_CONFIG="conf/benchmark-pull-request-fast.yaml"
            fi

            # Determine storage path
            if [ "$REF_TYPE" == "tag" ]; then
              STORAGE_PATH="gh-pages-repo/benchmark-data/tags/$REF_NAME/$RUNNER"
            else
              COMMIT_SHORT="${COMMIT_SHA:0:10}"
              STORAGE_PATH="gh-pages-repo/benchmark-data/commits/$COMMIT_SHORT/$RUNNER"
            fi

            echo "Storage path: $STORAGE_PATH"

            # Create directory
            mkdir -p "$STORAGE_PATH/results"

            # Copy benchmark results (use pr_results as the target/current data)
            if [ -d "$RUNNER_DIR/pr_results" ]; then
              cp "$RUNNER_DIR/pr_results"/*.csv "$STORAGE_PATH/results/" 2>/dev/null || echo "No CSV files to copy from pr_results"
            fi

            # Generate metadata
            python3 scripts/generate_benchmark_metadata.py \
              --ref "$REF_NAME" \
              --ref-type "$REF_TYPE" \
              --commit-sha "$COMMIT_SHA" \
              --runner-os "$RUNNER_OS" \
              --runner-arch "$RUNNER_ARCH" \
              --benchmark-suite "$BENCHMARK_SUITE" \
              --benchmark-config "$BENCHMARK_CONFIG" \
              --timestamp "$TIMESTAMP" \
              --output "$STORAGE_PATH/metadata.json" \
              --verbose

            # Determine runner label
            if [ "$RUNNER" == "linux" ]; then
              RUNNER_LABEL="Linux AMD64"
            elif [ "$RUNNER" == "macos" ]; then
              RUNNER_LABEL="macOS ARM64"
            else
              RUNNER_LABEL="$RUNNER_OS $RUNNER_ARCH"
            fi

            # Determine dataset label (without architecture)
            if [ "$REF_TYPE" == "tag" ]; then
              DATASET_LABEL="$REF_NAME"
            else
              COMMIT_SHORT_SHA="${COMMIT_SHA:0:7}"
              DATASET_LABEL="$REF_NAME ($COMMIT_SHORT_SHA)"
            fi

            # Update master index
            DATASET_ID="$REF_TYPE-$REF_NAME-$RUNNER"
            DATASET_PATH="$(echo $STORAGE_PATH | sed 's|gh-pages-repo/benchmark-data/||')"

            python3 scripts/update_benchmark_index.py \
              --index "gh-pages-repo/benchmark-data/index.json" \
              --dataset-id "$DATASET_ID" \
              --label "$DATASET_LABEL" \
              --ref "$REF_NAME" \
              --ref-type "$REF_TYPE" \
              --runner "$RUNNER" \
              --runner-label "$RUNNER_LABEL" \
              --path "$DATASET_PATH" \
              --timestamp "$TIMESTAMP" \
              --commit-sha "$COMMIT_SHA" \
              $([ "$IS_LATEST_TAG" == "true" ] && echo "--is-latest-tag") \
              --verbose

            echo "âœ… Stored dataset: $DATASET_ID"
          done

      - name: Store baseline benchmark data to gh-pages
        run: |
          # Store baseline data (from baseline_results)
          BASELINE_TAG="${{ needs.prepare.outputs.baseline_tag }}"

          if [ -z "$BASELINE_TAG" ]; then
            echo "No baseline tag specified, skipping baseline data storage"
            exit 0
          fi

          echo "Storing baseline benchmark data for tag: $BASELINE_TAG"

          # Get baseline commit SHA (we need to check it out to get the SHA)
          BASELINE_SHA=$(git rev-parse "$BASELINE_TAG")
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

          # Process each runner's baseline results
          for RUNNER_DIR in all-results/benchmark-results-*; do
            if [ ! -d "$RUNNER_DIR" ]; then
              continue
            fi

            # Extract runner name
            RUNNER=$(basename "$RUNNER_DIR" | sed 's/benchmark-results-//')
            echo "Processing baseline for runner: $RUNNER"

            # Check if baseline_results exists
            if [ ! -d "$RUNNER_DIR/baseline_results" ]; then
              echo "No baseline_results for $RUNNER, skipping"
              continue
            fi

            # Read runner info
            if [ -f "$RUNNER_DIR/runner_info.json" ]; then
              RUNNER_OS=$(jq -r '.os // "linux"' "$RUNNER_DIR/runner_info.json")
              RUNNER_ARCH=$(jq -r '.arch // "amd64"' "$RUNNER_DIR/runner_info.json")
              BENCHMARK_SUITE=$(jq -r '.benchmark_suite // "fast"' "$RUNNER_DIR/runner_info.json")
              BENCHMARK_CONFIG=$(jq -r '.benchmark_config // "conf/benchmark-pull-request-fast.yaml"' "$RUNNER_DIR/runner_info.json")
            else
              RUNNER_OS="linux"
              RUNNER_ARCH="amd64"
              BENCHMARK_SUITE="fast"
              BENCHMARK_CONFIG="conf/benchmark-pull-request-fast.yaml"
            fi

            # Storage path for baseline tag
            STORAGE_PATH="gh-pages-repo/benchmark-data/tags/$BASELINE_TAG/$RUNNER"

            # Skip if already exists (don't overwrite existing tag data)
            if [ -d "$STORAGE_PATH" ] && [ -f "$STORAGE_PATH/metadata.json" ]; then
              echo "Baseline data already exists for $BASELINE_TAG/$RUNNER, skipping"
              continue
            fi

            echo "Storage path: $STORAGE_PATH"

            # Create directory
            mkdir -p "$STORAGE_PATH/results"

            # Copy baseline results
            cp "$RUNNER_DIR/baseline_results"/*.csv "$STORAGE_PATH/results/" 2>/dev/null || echo "No CSV files to copy from baseline_results"

            # Generate metadata for baseline
            python3 scripts/generate_benchmark_metadata.py \
              --ref "$BASELINE_TAG" \
              --ref-type "tag" \
              --commit-sha "$BASELINE_SHA" \
              --runner-os "$RUNNER_OS" \
              --runner-arch "$RUNNER_ARCH" \
              --benchmark-suite "$BENCHMARK_SUITE" \
              --benchmark-config "$BENCHMARK_CONFIG" \
              --timestamp "$TIMESTAMP" \
              --output "$STORAGE_PATH/metadata.json" \
              --verbose

            # Determine runner label
            if [ "$RUNNER" == "linux" ]; then
              RUNNER_LABEL="Linux AMD64"
            elif [ "$RUNNER" == "macos" ]; then
              RUNNER_LABEL="macOS ARM64"
            else
              RUNNER_LABEL="$RUNNER_OS $RUNNER_ARCH"
            fi

            # Update master index for baseline
            DATASET_ID="tag-$BASELINE_TAG-$RUNNER"
            DATASET_PATH="$(echo $STORAGE_PATH | sed 's|gh-pages-repo/benchmark-data/||')"

            python3 scripts/update_benchmark_index.py \
              --index "gh-pages-repo/benchmark-data/index.json" \
              --dataset-id "$DATASET_ID" \
              --label "$BASELINE_TAG" \
              --ref "$BASELINE_TAG" \
              --ref-type "tag" \
              --runner "$RUNNER" \
              --runner-label "$RUNNER_LABEL" \
              --path "$DATASET_PATH" \
              --timestamp "$TIMESTAMP" \
              --commit-sha "$BASELINE_SHA" \
              --is-latest-tag \
              --verbose

            echo "âœ… Stored baseline dataset: $DATASET_ID"
          done

      - name: Generate interactive comparison report
        run: |
          python3 benchmarks/generate_interactive_comparison.py \
            --data-dir gh-pages-repo/benchmark-data \
            --output gh-pages-repo/benchmark-comparison/index.html \
            --verbose

      - name: Publish static comparison chart to gh-pages
        run: |
          # For PR/branch: publish to branch-specific directory
          # For main: skip (interactive report already at root)
          BRANCH_NAME="${{ needs.prepare.outputs.target_ref }}"
          SANITIZED_BRANCH=$(echo "$BRANCH_NAME" | sed 's/[^a-zA-Z0-9-]/-/g')
          OUTPUT_DIR="gh-pages-repo/benchmark-comparison/$SANITIZED_BRANCH"

          # Create output directory
          mkdir -p "$OUTPUT_DIR"

          # Copy the static comparison chart as index.html
          cp comparison_charts/benchmark_comparison.html "$OUTPUT_DIR/index.html"

          echo "âœ… Published static chart to $OUTPUT_DIR/index.html"

      - name: Commit and push all changes to gh-pages
        run: |
          cd gh-pages-repo
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Add all changes (benchmark data and comparison reports)
          git add benchmark-data/
          git add benchmark-comparison/

          # Commit
          REF_NAME="${{ needs.prepare.outputs.target_ref }}"
          git commit -m "Update benchmark data and reports for $REF_NAME" || echo "No changes to commit"

          # Push (force to handle concurrent gh-pages updates from docs workflow)
          git push --force https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }} gh-pages

          echo "âœ… Pushed to gh-pages"
        continue-on-error: true

      - name: Find PR number for branch
        id: find_pr
        run: |
          BRANCH="${{ needs.prepare.outputs.target_ref }}"
          echo "Looking for PR for branch: $BRANCH"

          # Find PR number using GitHub CLI
          PR_NUMBER=$(gh pr list --head "$BRANCH" --json number --jq '.[0].number' 2>/dev/null || echo "")

          if [ -n "$PR_NUMBER" ]; then
            echo "Found PR #$PR_NUMBER for branch $BRANCH"
            echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
            echo "has_pr=true" >> $GITHUB_OUTPUT
          else
            echo "No PR found for branch $BRANCH"
            echo "has_pr=false" >> $GITHUB_OUTPUT
          fi
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Comment PR with comparison results
        if: steps.find_pr.outputs.has_pr == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const prNumber = '${{ steps.find_pr.outputs.pr_number }}';

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('Benchmark Comparison')
            );

            const runId = context.runId;
            const branchName = '${{ needs.prepare.outputs.target_ref }}';
            const baselineTag = '${{ needs.prepare.outputs.baseline_tag }}';
            const sanitizedBranch = branchName.replace(/[^a-zA-Z0-9-]/g, '-');
            const chartUrl = `https://biodatageeks.org/polars-bio/benchmark-comparison/${sanitizedBranch}/`;
            const artifactLink = `[ðŸ“¦ Download Artifacts](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${runId}#artifacts)`;
            const chartLink = `[ðŸ“Š View Interactive Charts](${chartUrl})`;

            const commentBody = `## Benchmark Comparison: ${branchName} vs ${baselineTag}\n\n${chartLink} | ${artifactLink}\n\n---\n*Benchmark comparison generated by polars-bio CI*`;

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: commentBody
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: commentBody
              });
            }
        continue-on-error: true

      - name: Post comparison as workflow summary
        run: |
          if [ -f comparison_report_combined.md ]; then
            cat comparison_report_combined.md >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          echo "## ðŸ“Š Interactive Comparison Charts" >> $GITHUB_STEP_SUMMARY

          # Determine chart URL based on branch
          BRANCH_NAME="${{ needs.prepare.outputs.target_ref }}"
          SANITIZED_BRANCH=$(echo "$BRANCH_NAME" | sed 's/[^a-zA-Z0-9-]/-/g')

          if [ "${{ github.ref }}" == "refs/heads/master" ] || [ "${{ github.ref }}" == "refs/heads/main" ]; then
            CHART_URL="https://biodatageeks.org/polars-bio/benchmark-comparison/"
          else
            CHART_URL="https://biodatageeks.org/polars-bio/benchmark-comparison/$SANITIZED_BRANCH/"
          fi

          echo "ðŸ“Š **[View Interactive Charts Online]($CHART_URL)**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“¦ Download the \`benchmark-results\` artifact from this workflow run to view charts offline." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The charts show baseline vs PR performance for each operation and tool." >> $GITHUB_STEP_SUMMARY

      - name: Fail if regressions detected
        if: steps.comparison.outputs.regression_detected == 'true'
        run: |
          echo "::warning::Performance regressions detected! Check the comparison report for details."
          # Don't fail the workflow, just warn
          # Uncomment the line below to fail on regressions:
          # exit 1
