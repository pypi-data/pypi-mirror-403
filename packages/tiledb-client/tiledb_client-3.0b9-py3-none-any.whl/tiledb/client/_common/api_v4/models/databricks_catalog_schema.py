# coding: utf-8

"""
Specification file for tiledb-server v4 API

This spec is exposed to the public under /v4 route group  # noqa: E501

The version of the OpenAPI document: 0.0.1
Contact: info@tiledb.com
Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from tiledb.client._common.api_v4.configuration import Configuration


class DatabricksCatalogSchema(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        "name": "str",
        "tables": "list[DatabricksCatalogTable]",
        "browse_only": "bool",
        "catalog_name": "str",
        "catalog_type": "str",
        "comment": "str",
        "created_at": "int",
        "created_by": "str",
        "enable_predictive_optimization": "str",
        "full_name": "str",
        "metastore_id": "str",
        "owner": "str",
        "properties": "dict(str, str)",
        "schema_id": "str",
        "storage_location": "str",
        "storage_root": "str",
        "updated_at": "int",
        "updated_by": "str",
    }

    attribute_map = {
        "name": "name",
        "tables": "tables",
        "browse_only": "browse_only",
        "catalog_name": "catalog_name",
        "catalog_type": "catalog_type",
        "comment": "comment",
        "created_at": "created_at",
        "created_by": "created_by",
        "enable_predictive_optimization": "enable_predictive_optimization",
        "full_name": "full_name",
        "metastore_id": "metastore_id",
        "owner": "owner",
        "properties": "properties",
        "schema_id": "schema_id",
        "storage_location": "storage_location",
        "storage_root": "storage_root",
        "updated_at": "updated_at",
        "updated_by": "updated_by",
    }

    def __init__(
        self,
        name=None,
        tables=None,
        browse_only=None,
        catalog_name=None,
        catalog_type=None,
        comment=None,
        created_at=None,
        created_by=None,
        enable_predictive_optimization=None,
        full_name=None,
        metastore_id=None,
        owner=None,
        properties=None,
        schema_id=None,
        storage_location=None,
        storage_root=None,
        updated_at=None,
        updated_by=None,
        local_vars_configuration=None,
    ):  # noqa: E501
        """DatabricksCatalogSchema - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._name = None
        self._tables = None
        self._browse_only = None
        self._catalog_name = None
        self._catalog_type = None
        self._comment = None
        self._created_at = None
        self._created_by = None
        self._enable_predictive_optimization = None
        self._full_name = None
        self._metastore_id = None
        self._owner = None
        self._properties = None
        self._schema_id = None
        self._storage_location = None
        self._storage_root = None
        self._updated_at = None
        self._updated_by = None
        self.discriminator = None

        self.name = name
        self.tables = tables
        if browse_only is not None:
            self.browse_only = browse_only
        if catalog_name is not None:
            self.catalog_name = catalog_name
        if catalog_type is not None:
            self.catalog_type = catalog_type
        if comment is not None:
            self.comment = comment
        if created_at is not None:
            self.created_at = created_at
        if created_by is not None:
            self.created_by = created_by
        if enable_predictive_optimization is not None:
            self.enable_predictive_optimization = enable_predictive_optimization
        if full_name is not None:
            self.full_name = full_name
        if metastore_id is not None:
            self.metastore_id = metastore_id
        if owner is not None:
            self.owner = owner
        if properties is not None:
            self.properties = properties
        if schema_id is not None:
            self.schema_id = schema_id
        if storage_location is not None:
            self.storage_location = storage_location
        if storage_root is not None:
            self.storage_root = storage_root
        if updated_at is not None:
            self.updated_at = updated_at
        if updated_by is not None:
            self.updated_by = updated_by

    @property
    def name(self):
        """Gets the name of this DatabricksCatalogSchema.  # noqa: E501

        Name of schema, relative to parent catalog  # noqa: E501

        :return: The name of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this DatabricksCatalogSchema.

        Name of schema, relative to parent catalog  # noqa: E501

        :param name: The name of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """
        if (
            self.local_vars_configuration.client_side_validation and name is None
        ):  # noqa: E501
            raise ValueError(
                "Invalid value for `name`, must not be `None`"
            )  # noqa: E501

        self._name = name

    @property
    def tables(self):
        """Gets the tables of this DatabricksCatalogSchema.  # noqa: E501

        List of tables in this schema  # noqa: E501

        :return: The tables of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: list[DatabricksCatalogTable]
        """
        return self._tables

    @tables.setter
    def tables(self, tables):
        """Sets the tables of this DatabricksCatalogSchema.

        List of tables in this schema  # noqa: E501

        :param tables: The tables of this DatabricksCatalogSchema.  # noqa: E501
        :type: list[DatabricksCatalogTable]
        """
        if (
            self.local_vars_configuration.client_side_validation and tables is None
        ):  # noqa: E501
            raise ValueError(
                "Invalid value for `tables`, must not be `None`"
            )  # noqa: E501

        self._tables = tables

    @property
    def browse_only(self):
        """Gets the browse_only of this DatabricksCatalogSchema.  # noqa: E501

        Indicates whether the principal is limited to retrieving metadata for the associated object through the BROWSE privilege  # noqa: E501

        :return: The browse_only of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: bool
        """
        return self._browse_only

    @browse_only.setter
    def browse_only(self, browse_only):
        """Sets the browse_only of this DatabricksCatalogSchema.

        Indicates whether the principal is limited to retrieving metadata for the associated object through the BROWSE privilege  # noqa: E501

        :param browse_only: The browse_only of this DatabricksCatalogSchema.  # noqa: E501
        :type: bool
        """

        self._browse_only = browse_only

    @property
    def catalog_name(self):
        """Gets the catalog_name of this DatabricksCatalogSchema.  # noqa: E501

        Name of parent catalog  # noqa: E501

        :return: The catalog_name of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._catalog_name

    @catalog_name.setter
    def catalog_name(self, catalog_name):
        """Sets the catalog_name of this DatabricksCatalogSchema.

        Name of parent catalog  # noqa: E501

        :param catalog_name: The catalog_name of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """

        self._catalog_name = catalog_name

    @property
    def catalog_type(self):
        """Gets the catalog_type of this DatabricksCatalogSchema.  # noqa: E501

        The type of the parent catalog  # noqa: E501

        :return: The catalog_type of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._catalog_type

    @catalog_type.setter
    def catalog_type(self, catalog_type):
        """Sets the catalog_type of this DatabricksCatalogSchema.

        The type of the parent catalog  # noqa: E501

        :param catalog_type: The catalog_type of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """
        allowed_values = [
            "DELTASHARING_CATALOG",
            "FOREIGN_CATALOG",
            "INTERNAL_CATALOG",
            "MANAGED_CATALOG",
            "MANAGED_ONLINE_CATALOG",
            "SYSTEM_CATALOG",
        ]  # noqa: E501
        if (
            self.local_vars_configuration.client_side_validation
            and catalog_type not in allowed_values
        ):  # noqa: E501
            raise ValueError(
                "Invalid value for `catalog_type` ({0}), must be one of {1}".format(  # noqa: E501
                    catalog_type, allowed_values
                )
            )

        self._catalog_type = catalog_type

    @property
    def comment(self):
        """Gets the comment of this DatabricksCatalogSchema.  # noqa: E501

        User-provided free-form text description  # noqa: E501

        :return: The comment of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._comment

    @comment.setter
    def comment(self, comment):
        """Sets the comment of this DatabricksCatalogSchema.

        User-provided free-form text description  # noqa: E501

        :param comment: The comment of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """

        self._comment = comment

    @property
    def created_at(self):
        """Gets the created_at of this DatabricksCatalogSchema.  # noqa: E501

        Time at which this schema was created, in epoch milliseconds  # noqa: E501

        :return: The created_at of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: int
        """
        return self._created_at

    @created_at.setter
    def created_at(self, created_at):
        """Sets the created_at of this DatabricksCatalogSchema.

        Time at which this schema was created, in epoch milliseconds  # noqa: E501

        :param created_at: The created_at of this DatabricksCatalogSchema.  # noqa: E501
        :type: int
        """

        self._created_at = created_at

    @property
    def created_by(self):
        """Gets the created_by of this DatabricksCatalogSchema.  # noqa: E501

        Username of schema creator  # noqa: E501

        :return: The created_by of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._created_by

    @created_by.setter
    def created_by(self, created_by):
        """Sets the created_by of this DatabricksCatalogSchema.

        Username of schema creator  # noqa: E501

        :param created_by: The created_by of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """

        self._created_by = created_by

    @property
    def enable_predictive_optimization(self):
        """Gets the enable_predictive_optimization of this DatabricksCatalogSchema.  # noqa: E501

        Whether predictive optimization should be enabled for this object and objects under it  # noqa: E501

        :return: The enable_predictive_optimization of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._enable_predictive_optimization

    @enable_predictive_optimization.setter
    def enable_predictive_optimization(self, enable_predictive_optimization):
        """Sets the enable_predictive_optimization of this DatabricksCatalogSchema.

        Whether predictive optimization should be enabled for this object and objects under it  # noqa: E501

        :param enable_predictive_optimization: The enable_predictive_optimization of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """
        allowed_values = ["DISABLE", "ENABLE", "INHERIT"]  # noqa: E501
        if (
            self.local_vars_configuration.client_side_validation
            and enable_predictive_optimization not in allowed_values
        ):  # noqa: E501
            raise ValueError(
                "Invalid value for `enable_predictive_optimization` ({0}), must be one of {1}".format(  # noqa: E501
                    enable_predictive_optimization, allowed_values
                )
            )

        self._enable_predictive_optimization = enable_predictive_optimization

    @property
    def full_name(self):
        """Gets the full_name of this DatabricksCatalogSchema.  # noqa: E501

        Full name of schema, in form of __catalog_name__.__schema_name__  # noqa: E501

        :return: The full_name of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._full_name

    @full_name.setter
    def full_name(self, full_name):
        """Sets the full_name of this DatabricksCatalogSchema.

        Full name of schema, in form of __catalog_name__.__schema_name__  # noqa: E501

        :param full_name: The full_name of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """

        self._full_name = full_name

    @property
    def metastore_id(self):
        """Gets the metastore_id of this DatabricksCatalogSchema.  # noqa: E501

        Unique identifier of parent metastore  # noqa: E501

        :return: The metastore_id of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._metastore_id

    @metastore_id.setter
    def metastore_id(self, metastore_id):
        """Sets the metastore_id of this DatabricksCatalogSchema.

        Unique identifier of parent metastore  # noqa: E501

        :param metastore_id: The metastore_id of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """

        self._metastore_id = metastore_id

    @property
    def owner(self):
        """Gets the owner of this DatabricksCatalogSchema.  # noqa: E501

        Username of current owner of schema  # noqa: E501

        :return: The owner of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._owner

    @owner.setter
    def owner(self, owner):
        """Sets the owner of this DatabricksCatalogSchema.

        Username of current owner of schema  # noqa: E501

        :param owner: The owner of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """

        self._owner = owner

    @property
    def properties(self):
        """Gets the properties of this DatabricksCatalogSchema.  # noqa: E501

        A map of key-value properties attached to the securable  # noqa: E501

        :return: The properties of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: dict(str, str)
        """
        return self._properties

    @properties.setter
    def properties(self, properties):
        """Sets the properties of this DatabricksCatalogSchema.

        A map of key-value properties attached to the securable  # noqa: E501

        :param properties: The properties of this DatabricksCatalogSchema.  # noqa: E501
        :type: dict(str, str)
        """

        self._properties = properties

    @property
    def schema_id(self):
        """Gets the schema_id of this DatabricksCatalogSchema.  # noqa: E501

        The unique identifier of the schema  # noqa: E501

        :return: The schema_id of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._schema_id

    @schema_id.setter
    def schema_id(self, schema_id):
        """Sets the schema_id of this DatabricksCatalogSchema.

        The unique identifier of the schema  # noqa: E501

        :param schema_id: The schema_id of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """

        self._schema_id = schema_id

    @property
    def storage_location(self):
        """Gets the storage_location of this DatabricksCatalogSchema.  # noqa: E501

        Storage location for managed tables within schema  # noqa: E501

        :return: The storage_location of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._storage_location

    @storage_location.setter
    def storage_location(self, storage_location):
        """Sets the storage_location of this DatabricksCatalogSchema.

        Storage location for managed tables within schema  # noqa: E501

        :param storage_location: The storage_location of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """

        self._storage_location = storage_location

    @property
    def storage_root(self):
        """Gets the storage_root of this DatabricksCatalogSchema.  # noqa: E501

        Storage root URL for managed tables within schema  # noqa: E501

        :return: The storage_root of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._storage_root

    @storage_root.setter
    def storage_root(self, storage_root):
        """Sets the storage_root of this DatabricksCatalogSchema.

        Storage root URL for managed tables within schema  # noqa: E501

        :param storage_root: The storage_root of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """

        self._storage_root = storage_root

    @property
    def updated_at(self):
        """Gets the updated_at of this DatabricksCatalogSchema.  # noqa: E501

        Time at which this schema was last modified, in epoch milliseconds  # noqa: E501

        :return: The updated_at of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: int
        """
        return self._updated_at

    @updated_at.setter
    def updated_at(self, updated_at):
        """Sets the updated_at of this DatabricksCatalogSchema.

        Time at which this schema was last modified, in epoch milliseconds  # noqa: E501

        :param updated_at: The updated_at of this DatabricksCatalogSchema.  # noqa: E501
        :type: int
        """

        self._updated_at = updated_at

    @property
    def updated_by(self):
        """Gets the updated_by of this DatabricksCatalogSchema.  # noqa: E501

        Username of user who last modified schema  # noqa: E501

        :return: The updated_by of this DatabricksCatalogSchema.  # noqa: E501
        :rtype: str
        """
        return self._updated_by

    @updated_by.setter
    def updated_by(self, updated_by):
        """Sets the updated_by of this DatabricksCatalogSchema.

        Username of user who last modified schema  # noqa: E501

        :param updated_by: The updated_by of this DatabricksCatalogSchema.  # noqa: E501
        :type: str
        """

        self._updated_by = updated_by

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(
                    map(lambda x: x.to_dict() if hasattr(x, "to_dict") else x, value)
                )
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(
                    map(
                        lambda item: (
                            (item[0], item[1].to_dict())
                            if hasattr(item[1], "to_dict")
                            else item
                        ),
                        value.items(),
                    )
                )
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, DatabricksCatalogSchema):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, DatabricksCatalogSchema):
            return True

        return self.to_dict() != other.to_dict()
