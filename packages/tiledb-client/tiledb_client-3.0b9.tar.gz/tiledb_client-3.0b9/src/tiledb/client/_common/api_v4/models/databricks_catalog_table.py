# coding: utf-8

"""
Specification file for tiledb-server v4 API

This spec is exposed to the public under /v4 route group  # noqa: E501

The version of the OpenAPI document: 0.0.1
Contact: info@tiledb.com
Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from tiledb.client._common.api_v4.configuration import Configuration


class DatabricksCatalogTable(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        "name": "str",
        "catalog_name": "str",
        "schema_name": "str",
        "table_type": "str",
        "data_source_format": "str",
        "access_point": "str",
        "browse_only": "bool",
        "columns": "list[DatabricksCatalogTableColumns]",
        "comment": "str",
        "created_at": "int",
        "created_by": "str",
        "data_access_configuration_id": "str",
        "deleted_at": "int",
        "enable_predictive_optimization": "str",
        "full_name": "str",
        "metastore_id": "str",
        "owner": "str",
        "pipeline_id": "str",
        "properties": "dict(str, str)",
        "sql_path": "str",
        "storage_credential_name": "str",
        "storage_location": "str",
        "table_id": "str",
        "updated_at": "int",
        "updated_by": "str",
        "view_definition": "str",
    }

    attribute_map = {
        "name": "name",
        "catalog_name": "catalog_name",
        "schema_name": "schema_name",
        "table_type": "table_type",
        "data_source_format": "data_source_format",
        "access_point": "access_point",
        "browse_only": "browse_only",
        "columns": "columns",
        "comment": "comment",
        "created_at": "created_at",
        "created_by": "created_by",
        "data_access_configuration_id": "data_access_configuration_id",
        "deleted_at": "deleted_at",
        "enable_predictive_optimization": "enable_predictive_optimization",
        "full_name": "full_name",
        "metastore_id": "metastore_id",
        "owner": "owner",
        "pipeline_id": "pipeline_id",
        "properties": "properties",
        "sql_path": "sql_path",
        "storage_credential_name": "storage_credential_name",
        "storage_location": "storage_location",
        "table_id": "table_id",
        "updated_at": "updated_at",
        "updated_by": "updated_by",
        "view_definition": "view_definition",
    }

    def __init__(
        self,
        name=None,
        catalog_name=None,
        schema_name=None,
        table_type=None,
        data_source_format=None,
        access_point=None,
        browse_only=None,
        columns=None,
        comment=None,
        created_at=None,
        created_by=None,
        data_access_configuration_id=None,
        deleted_at=None,
        enable_predictive_optimization=None,
        full_name=None,
        metastore_id=None,
        owner=None,
        pipeline_id=None,
        properties=None,
        sql_path=None,
        storage_credential_name=None,
        storage_location=None,
        table_id=None,
        updated_at=None,
        updated_by=None,
        view_definition=None,
        local_vars_configuration=None,
    ):  # noqa: E501
        """DatabricksCatalogTable - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._name = None
        self._catalog_name = None
        self._schema_name = None
        self._table_type = None
        self._data_source_format = None
        self._access_point = None
        self._browse_only = None
        self._columns = None
        self._comment = None
        self._created_at = None
        self._created_by = None
        self._data_access_configuration_id = None
        self._deleted_at = None
        self._enable_predictive_optimization = None
        self._full_name = None
        self._metastore_id = None
        self._owner = None
        self._pipeline_id = None
        self._properties = None
        self._sql_path = None
        self._storage_credential_name = None
        self._storage_location = None
        self._table_id = None
        self._updated_at = None
        self._updated_by = None
        self._view_definition = None
        self.discriminator = None

        self.name = name
        self.catalog_name = catalog_name
        self.schema_name = schema_name
        self.table_type = table_type
        self.data_source_format = data_source_format
        if access_point is not None:
            self.access_point = access_point
        if browse_only is not None:
            self.browse_only = browse_only
        if columns is not None:
            self.columns = columns
        if comment is not None:
            self.comment = comment
        if created_at is not None:
            self.created_at = created_at
        if created_by is not None:
            self.created_by = created_by
        if data_access_configuration_id is not None:
            self.data_access_configuration_id = data_access_configuration_id
        if deleted_at is not None:
            self.deleted_at = deleted_at
        if enable_predictive_optimization is not None:
            self.enable_predictive_optimization = enable_predictive_optimization
        if full_name is not None:
            self.full_name = full_name
        if metastore_id is not None:
            self.metastore_id = metastore_id
        if owner is not None:
            self.owner = owner
        if pipeline_id is not None:
            self.pipeline_id = pipeline_id
        if properties is not None:
            self.properties = properties
        if sql_path is not None:
            self.sql_path = sql_path
        if storage_credential_name is not None:
            self.storage_credential_name = storage_credential_name
        if storage_location is not None:
            self.storage_location = storage_location
        if table_id is not None:
            self.table_id = table_id
        if updated_at is not None:
            self.updated_at = updated_at
        if updated_by is not None:
            self.updated_by = updated_by
        if view_definition is not None:
            self.view_definition = view_definition

    @property
    def name(self):
        """Gets the name of this DatabricksCatalogTable.  # noqa: E501

        Name of table, relative to parent schema  # noqa: E501

        :return: The name of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this DatabricksCatalogTable.

        Name of table, relative to parent schema  # noqa: E501

        :param name: The name of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """
        if (
            self.local_vars_configuration.client_side_validation and name is None
        ):  # noqa: E501
            raise ValueError(
                "Invalid value for `name`, must not be `None`"
            )  # noqa: E501

        self._name = name

    @property
    def catalog_name(self):
        """Gets the catalog_name of this DatabricksCatalogTable.  # noqa: E501

        Name of parent catalog  # noqa: E501

        :return: The catalog_name of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._catalog_name

    @catalog_name.setter
    def catalog_name(self, catalog_name):
        """Sets the catalog_name of this DatabricksCatalogTable.

        Name of parent catalog  # noqa: E501

        :param catalog_name: The catalog_name of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """
        if (
            self.local_vars_configuration.client_side_validation
            and catalog_name is None
        ):  # noqa: E501
            raise ValueError(
                "Invalid value for `catalog_name`, must not be `None`"
            )  # noqa: E501

        self._catalog_name = catalog_name

    @property
    def schema_name(self):
        """Gets the schema_name of this DatabricksCatalogTable.  # noqa: E501

        Name of parent schema relative to its parent catalog  # noqa: E501

        :return: The schema_name of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._schema_name

    @schema_name.setter
    def schema_name(self, schema_name):
        """Sets the schema_name of this DatabricksCatalogTable.

        Name of parent schema relative to its parent catalog  # noqa: E501

        :param schema_name: The schema_name of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """
        if (
            self.local_vars_configuration.client_side_validation and schema_name is None
        ):  # noqa: E501
            raise ValueError(
                "Invalid value for `schema_name`, must not be `None`"
            )  # noqa: E501

        self._schema_name = schema_name

    @property
    def table_type(self):
        """Gets the table_type of this DatabricksCatalogTable.  # noqa: E501

        The type of table  # noqa: E501

        :return: The table_type of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._table_type

    @table_type.setter
    def table_type(self, table_type):
        """Sets the table_type of this DatabricksCatalogTable.

        The type of table  # noqa: E501

        :param table_type: The table_type of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """
        if (
            self.local_vars_configuration.client_side_validation and table_type is None
        ):  # noqa: E501
            raise ValueError(
                "Invalid value for `table_type`, must not be `None`"
            )  # noqa: E501
        allowed_values = [
            "EXTERNAL",
            "EXTERNAL_SHALLOW_CLONE",
            "FOREIGN",
            "MANAGED",
            "MANAGED_SHALLOW_CLONE",
            "MATERIALIZED_VIEW",
            "STREAMING_TABLE",
            "VIEW",
        ]  # noqa: E501
        if (
            self.local_vars_configuration.client_side_validation
            and table_type not in allowed_values
        ):  # noqa: E501
            raise ValueError(
                "Invalid value for `table_type` ({0}), must be one of {1}".format(  # noqa: E501
                    table_type, allowed_values
                )
            )

        self._table_type = table_type

    @property
    def data_source_format(self):
        """Gets the data_source_format of this DatabricksCatalogTable.  # noqa: E501

        The format of the underlying data  # noqa: E501

        :return: The data_source_format of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._data_source_format

    @data_source_format.setter
    def data_source_format(self, data_source_format):
        """Sets the data_source_format of this DatabricksCatalogTable.

        The format of the underlying data  # noqa: E501

        :param data_source_format: The data_source_format of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """
        if (
            self.local_vars_configuration.client_side_validation
            and data_source_format is None
        ):  # noqa: E501
            raise ValueError(
                "Invalid value for `data_source_format`, must not be `None`"
            )  # noqa: E501
        allowed_values = [
            "AVRO",
            "BIGQUERY_FORMAT",
            "CSV",
            "DATABRICKS_FORMAT",
            "DELTA",
            "DELTASHARING",
            "HIVE_CUSTOM",
            "HIVE_SERDE",
            "JSON",
            "MYSQL_FORMAT",
            "NETSUITE_FORMAT",
            "ORC",
            "PARQUET",
            "POSTGRESQL_FORMAT",
            "REDSHIFT_FORMAT",
            "SALESFORCE_FORMAT",
            "SNOWFLAKE_FORMAT",
            "SQLDW_FORMAT",
            "SQLSERVER_FORMAT",
            "TEXT",
            "UNITY_CATALOG",
            "VECTOR_INDEX_FORMAT",
            "WORKDAY_RAAS_FORMAT",
        ]  # noqa: E501
        if (
            self.local_vars_configuration.client_side_validation
            and data_source_format not in allowed_values
        ):  # noqa: E501
            raise ValueError(
                "Invalid value for `data_source_format` ({0}), must be one of {1}".format(  # noqa: E501
                    data_source_format, allowed_values
                )
            )

        self._data_source_format = data_source_format

    @property
    def access_point(self):
        """Gets the access_point of this DatabricksCatalogTable.  # noqa: E501

        The AWS access point to use when accessing s3 for this external location  # noqa: E501

        :return: The access_point of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._access_point

    @access_point.setter
    def access_point(self, access_point):
        """Sets the access_point of this DatabricksCatalogTable.

        The AWS access point to use when accessing s3 for this external location  # noqa: E501

        :param access_point: The access_point of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._access_point = access_point

    @property
    def browse_only(self):
        """Gets the browse_only of this DatabricksCatalogTable.  # noqa: E501

        Indicates whether the principal is limited to retrieving metadata for the associated object through the BROWSE privilege  # noqa: E501

        :return: The browse_only of this DatabricksCatalogTable.  # noqa: E501
        :rtype: bool
        """
        return self._browse_only

    @browse_only.setter
    def browse_only(self, browse_only):
        """Sets the browse_only of this DatabricksCatalogTable.

        Indicates whether the principal is limited to retrieving metadata for the associated object through the BROWSE privilege  # noqa: E501

        :param browse_only: The browse_only of this DatabricksCatalogTable.  # noqa: E501
        :type: bool
        """

        self._browse_only = browse_only

    @property
    def columns(self):
        """Gets the columns of this DatabricksCatalogTable.  # noqa: E501

        The array of column definitions of the table's columns  # noqa: E501

        :return: The columns of this DatabricksCatalogTable.  # noqa: E501
        :rtype: list[DatabricksCatalogTableColumns]
        """
        return self._columns

    @columns.setter
    def columns(self, columns):
        """Sets the columns of this DatabricksCatalogTable.

        The array of column definitions of the table's columns  # noqa: E501

        :param columns: The columns of this DatabricksCatalogTable.  # noqa: E501
        :type: list[DatabricksCatalogTableColumns]
        """

        self._columns = columns

    @property
    def comment(self):
        """Gets the comment of this DatabricksCatalogTable.  # noqa: E501

        User-provided free-form text description  # noqa: E501

        :return: The comment of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._comment

    @comment.setter
    def comment(self, comment):
        """Sets the comment of this DatabricksCatalogTable.

        User-provided free-form text description  # noqa: E501

        :param comment: The comment of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._comment = comment

    @property
    def created_at(self):
        """Gets the created_at of this DatabricksCatalogTable.  # noqa: E501

        Time at which this table was created, in epoch milliseconds  # noqa: E501

        :return: The created_at of this DatabricksCatalogTable.  # noqa: E501
        :rtype: int
        """
        return self._created_at

    @created_at.setter
    def created_at(self, created_at):
        """Sets the created_at of this DatabricksCatalogTable.

        Time at which this table was created, in epoch milliseconds  # noqa: E501

        :param created_at: The created_at of this DatabricksCatalogTable.  # noqa: E501
        :type: int
        """

        self._created_at = created_at

    @property
    def created_by(self):
        """Gets the created_by of this DatabricksCatalogTable.  # noqa: E501

        Username of table creator  # noqa: E501

        :return: The created_by of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._created_by

    @created_by.setter
    def created_by(self, created_by):
        """Sets the created_by of this DatabricksCatalogTable.

        Username of table creator  # noqa: E501

        :param created_by: The created_by of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._created_by = created_by

    @property
    def data_access_configuration_id(self):
        """Gets the data_access_configuration_id of this DatabricksCatalogTable.  # noqa: E501

        Unique ID of the Data Access Configuration to use with the table data  # noqa: E501

        :return: The data_access_configuration_id of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._data_access_configuration_id

    @data_access_configuration_id.setter
    def data_access_configuration_id(self, data_access_configuration_id):
        """Sets the data_access_configuration_id of this DatabricksCatalogTable.

        Unique ID of the Data Access Configuration to use with the table data  # noqa: E501

        :param data_access_configuration_id: The data_access_configuration_id of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._data_access_configuration_id = data_access_configuration_id

    @property
    def deleted_at(self):
        """Gets the deleted_at of this DatabricksCatalogTable.  # noqa: E501

        Time at which this table was deleted, in epoch milliseconds  # noqa: E501

        :return: The deleted_at of this DatabricksCatalogTable.  # noqa: E501
        :rtype: int
        """
        return self._deleted_at

    @deleted_at.setter
    def deleted_at(self, deleted_at):
        """Sets the deleted_at of this DatabricksCatalogTable.

        Time at which this table was deleted, in epoch milliseconds  # noqa: E501

        :param deleted_at: The deleted_at of this DatabricksCatalogTable.  # noqa: E501
        :type: int
        """

        self._deleted_at = deleted_at

    @property
    def enable_predictive_optimization(self):
        """Gets the enable_predictive_optimization of this DatabricksCatalogTable.  # noqa: E501

        Whether predictive optimization should be enabled for this object and objects under it  # noqa: E501

        :return: The enable_predictive_optimization of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._enable_predictive_optimization

    @enable_predictive_optimization.setter
    def enable_predictive_optimization(self, enable_predictive_optimization):
        """Sets the enable_predictive_optimization of this DatabricksCatalogTable.

        Whether predictive optimization should be enabled for this object and objects under it  # noqa: E501

        :param enable_predictive_optimization: The enable_predictive_optimization of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """
        allowed_values = ["DISABLE", "ENABLE", "INHERIT"]  # noqa: E501
        if (
            self.local_vars_configuration.client_side_validation
            and enable_predictive_optimization not in allowed_values
        ):  # noqa: E501
            raise ValueError(
                "Invalid value for `enable_predictive_optimization` ({0}), must be one of {1}".format(  # noqa: E501
                    enable_predictive_optimization, allowed_values
                )
            )

        self._enable_predictive_optimization = enable_predictive_optimization

    @property
    def full_name(self):
        """Gets the full_name of this DatabricksCatalogTable.  # noqa: E501

        Full name of table, in form of __catalog_name__.__schema_name__.__table_name__  # noqa: E501

        :return: The full_name of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._full_name

    @full_name.setter
    def full_name(self, full_name):
        """Sets the full_name of this DatabricksCatalogTable.

        Full name of table, in form of __catalog_name__.__schema_name__.__table_name__  # noqa: E501

        :param full_name: The full_name of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._full_name = full_name

    @property
    def metastore_id(self):
        """Gets the metastore_id of this DatabricksCatalogTable.  # noqa: E501

        Unique identifier of parent metastore  # noqa: E501

        :return: The metastore_id of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._metastore_id

    @metastore_id.setter
    def metastore_id(self, metastore_id):
        """Sets the metastore_id of this DatabricksCatalogTable.

        Unique identifier of parent metastore  # noqa: E501

        :param metastore_id: The metastore_id of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._metastore_id = metastore_id

    @property
    def owner(self):
        """Gets the owner of this DatabricksCatalogTable.  # noqa: E501

        Username of current owner of table  # noqa: E501

        :return: The owner of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._owner

    @owner.setter
    def owner(self, owner):
        """Sets the owner of this DatabricksCatalogTable.

        Username of current owner of table  # noqa: E501

        :param owner: The owner of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._owner = owner

    @property
    def pipeline_id(self):
        """Gets the pipeline_id of this DatabricksCatalogTable.  # noqa: E501

        The pipeline ID of the table. Applicable for tables created by pipelines  # noqa: E501

        :return: The pipeline_id of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._pipeline_id

    @pipeline_id.setter
    def pipeline_id(self, pipeline_id):
        """Sets the pipeline_id of this DatabricksCatalogTable.

        The pipeline ID of the table. Applicable for tables created by pipelines  # noqa: E501

        :param pipeline_id: The pipeline_id of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._pipeline_id = pipeline_id

    @property
    def properties(self):
        """Gets the properties of this DatabricksCatalogTable.  # noqa: E501

        A map of key-value properties attached to the securable  # noqa: E501

        :return: The properties of this DatabricksCatalogTable.  # noqa: E501
        :rtype: dict(str, str)
        """
        return self._properties

    @properties.setter
    def properties(self, properties):
        """Sets the properties of this DatabricksCatalogTable.

        A map of key-value properties attached to the securable  # noqa: E501

        :param properties: The properties of this DatabricksCatalogTable.  # noqa: E501
        :type: dict(str, str)
        """

        self._properties = properties

    @property
    def sql_path(self):
        """Gets the sql_path of this DatabricksCatalogTable.  # noqa: E501

        List of schemes whose objects can be referenced without qualification  # noqa: E501

        :return: The sql_path of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._sql_path

    @sql_path.setter
    def sql_path(self, sql_path):
        """Sets the sql_path of this DatabricksCatalogTable.

        List of schemes whose objects can be referenced without qualification  # noqa: E501

        :param sql_path: The sql_path of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._sql_path = sql_path

    @property
    def storage_credential_name(self):
        """Gets the storage_credential_name of this DatabricksCatalogTable.  # noqa: E501

        Name of the storage credential, when a storage credential is configured for use with this table  # noqa: E501

        :return: The storage_credential_name of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._storage_credential_name

    @storage_credential_name.setter
    def storage_credential_name(self, storage_credential_name):
        """Sets the storage_credential_name of this DatabricksCatalogTable.

        Name of the storage credential, when a storage credential is configured for use with this table  # noqa: E501

        :param storage_credential_name: The storage_credential_name of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._storage_credential_name = storage_credential_name

    @property
    def storage_location(self):
        """Gets the storage_location of this DatabricksCatalogTable.  # noqa: E501

        Storage root URL for table (for MANAGED, EXTERNAL tables)  # noqa: E501

        :return: The storage_location of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._storage_location

    @storage_location.setter
    def storage_location(self, storage_location):
        """Sets the storage_location of this DatabricksCatalogTable.

        Storage root URL for table (for MANAGED, EXTERNAL tables)  # noqa: E501

        :param storage_location: The storage_location of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._storage_location = storage_location

    @property
    def table_id(self):
        """Gets the table_id of this DatabricksCatalogTable.  # noqa: E501

        The unique identifier of the table  # noqa: E501

        :return: The table_id of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._table_id

    @table_id.setter
    def table_id(self, table_id):
        """Sets the table_id of this DatabricksCatalogTable.

        The unique identifier of the table  # noqa: E501

        :param table_id: The table_id of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._table_id = table_id

    @property
    def updated_at(self):
        """Gets the updated_at of this DatabricksCatalogTable.  # noqa: E501

        Time at which this table was last modified, in epoch milliseconds  # noqa: E501

        :return: The updated_at of this DatabricksCatalogTable.  # noqa: E501
        :rtype: int
        """
        return self._updated_at

    @updated_at.setter
    def updated_at(self, updated_at):
        """Sets the updated_at of this DatabricksCatalogTable.

        Time at which this table was last modified, in epoch milliseconds  # noqa: E501

        :param updated_at: The updated_at of this DatabricksCatalogTable.  # noqa: E501
        :type: int
        """

        self._updated_at = updated_at

    @property
    def updated_by(self):
        """Gets the updated_by of this DatabricksCatalogTable.  # noqa: E501

        Username of user who last modified the table  # noqa: E501

        :return: The updated_by of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._updated_by

    @updated_by.setter
    def updated_by(self, updated_by):
        """Sets the updated_by of this DatabricksCatalogTable.

        Username of user who last modified the table  # noqa: E501

        :param updated_by: The updated_by of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._updated_by = updated_by

    @property
    def view_definition(self):
        """Gets the view_definition of this DatabricksCatalogTable.  # noqa: E501

        View definition SQL (when table_type is VIEW, MATERIALIZED_VIEW, or STREAMING_TABLE)  # noqa: E501

        :return: The view_definition of this DatabricksCatalogTable.  # noqa: E501
        :rtype: str
        """
        return self._view_definition

    @view_definition.setter
    def view_definition(self, view_definition):
        """Sets the view_definition of this DatabricksCatalogTable.

        View definition SQL (when table_type is VIEW, MATERIALIZED_VIEW, or STREAMING_TABLE)  # noqa: E501

        :param view_definition: The view_definition of this DatabricksCatalogTable.  # noqa: E501
        :type: str
        """

        self._view_definition = view_definition

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(
                    map(lambda x: x.to_dict() if hasattr(x, "to_dict") else x, value)
                )
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(
                    map(
                        lambda item: (
                            (item[0], item[1].to_dict())
                            if hasattr(item[1], "to_dict")
                            else item
                        ),
                        value.items(),
                    )
                )
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, DatabricksCatalogTable):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, DatabricksCatalogTable):
            return True

        return self.to_dict() != other.to_dict()
