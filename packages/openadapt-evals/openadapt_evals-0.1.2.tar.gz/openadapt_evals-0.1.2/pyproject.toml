[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "openadapt-evals"
version = "0.1.2"
description = "Evaluation infrastructure for GUI agent benchmarks"
readme = "README.md"
requires-python = ">=3.10"
license = "MIT"
authors = [
    {name = "Richard Abrich", email = "richard@openadapt.ai"}
]
maintainers = [
    {name = "OpenAdaptAI", email = "contact@openadapt.ai"}
]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Testing",
]
keywords = ["gui", "automation", "evaluation", "benchmark", "agent", "ai"]

dependencies = [
    "open-clip-torch>=2.20.0",
    "pillow>=10.0.0",
    "python-dotenv>=1.2.1",
    "tenacity>=8.2.0",
    "requests>=2.28.0",
    "httpx>=0.25.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "ruff>=0.1.0",
]
waa = [
    # Windows Agent Arena dependencies
    "requests>=2.28.0",
]
azure = [
    # Azure ML dependencies for distributed WAA evaluation
    "azure-ai-ml>=1.12.0",
    "azure-identity>=1.15.0",
]
retrieval = [
    # For RetrievalAugmentedAgent with automatic demo selection
    "openadapt-retrieval>=0.1.0",
]
viewer = [
    # For live benchmark viewer API server
    "flask>=3.0.0",
    "flask-cors>=4.0.0",
]
wandb = [
    # Weights & Biases for experiment tracking
    "wandb>=0.16.0",
]
all = [
    "openadapt-evals[dev,waa,azure,retrieval,viewer,wandb]",
]
test = [
    "anthropic>=0.76.0",
]

[project.scripts]
oa = "openadapt_evals.cli.main:main"
# Legacy entry point (kept for backward compatibility)
openadapt-evals = "openadapt_evals.benchmarks.cli:main"

[project.urls]
Homepage = "https://github.com/OpenAdaptAI/openadapt-evals"
Repository = "https://github.com/OpenAdaptAI/openadapt-evals"
Documentation = "https://github.com/OpenAdaptAI/openadapt-evals#readme"
"Bug Tracker" = "https://github.com/OpenAdaptAI/openadapt-evals/issues"

[tool.hatch.build.targets.wheel]
packages = ["openadapt_evals"]

[tool.ruff]
line-length = 100

[tool.semantic_release]
version_toml = ["pyproject.toml:project.version"]
branch = "main"
commit_message = "chore: release {version}"

[tool.semantic_release.commit_parser_options]
allowed_tags = ["build", "chore", "ci", "docs", "feat", "fix", "perf", "refactor", "style", "test"]
minor_tags = ["feat"]
patch_tags = ["fix", "perf"]
